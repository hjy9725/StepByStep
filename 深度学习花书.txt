

















权

衡偏差和方

差以最小化

均方误差 . . .

. . . .

. . . 113

5.4.5 一

致性 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

114

5.5 最大似

然估计 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 115

5.5.1

条件

对数似然和

均方误差 . . .

. . . .

. . . .

. . . .

116

5.5.2 最

大似然的性

质 .

. . . .

. . . .

. . . .

. . . .

. . . 117

5.6 贝叶斯统

计 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 118

5.6.1

最大后验

(MAP) 估计 . .

. . . .

. . . .

. . . .

. . . 121

5.7 监督学

习算法 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 122

5.7.1 概率

监督学习

. . . .

. . . .

. . . .

. . . .

. . . .

. . 122

5.7.2

支

持向量机 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

123

5.7.3 其

他简单的监

督学习算法

. .

. . . .

. . . .

. . . .

. 125

5.8 无监督学习

算法

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 128

5.8.1

主成分

分析 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

128

vi 目录

5.8.2

k-均

值聚类 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

131

5.9 随机

梯度下降 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 132

5.10

构

建机器学习

算法 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 133

5.11 促使深

度学习发展

的挑战

. . . .

. . . .

. . . .

. . . .

. . . .

134

5.11.1 维数

灾难 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 135

5.11.2 局部不

变性和平滑

正则化 . .

. . . .

. . . .

. . . .

. 135

5.11.3 流形

学习

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

139

第二部

分 深度网络

：现代实践 143

第

六章 深度前

馈网络 145

6.1

实例

：学习 XOR . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 148

6.2 基于梯

度的学习 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

152

6.2.1 代

价函数 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 153

6.2.1.1 使用

最大似然学

习条件分布

. . .

. . . .

. . . .

. . 154

6.2.1.2

学习条件统

计量 . . .

. . . .

. . . .

. . . .

. . . .

. 155

6.2.2 输出单

元

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

156

6.2.2.1 用于高斯

输出分布的

线性单元 .

. . . .

. . . .

. . . 156

6.2.2.2 用

于 Bernoulli 输出分布

的

sigmoid 单元 . .

. . . .

157

6.2.2.3 用于

Multinoulli 输出分布的

softmax

单元 . . .

. . 159

6.2.2.4

其他的

输出类型 . . .

. . . .

. . . .

. . . .

. . . .

. 162

6.3 隐

藏单元

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 165

6.3.1 整流

线性单元及

其扩展

. . . .

. . . .

. . . .

. . . .

. 166

6.3.2 logistic

sigmoid 与双

曲正切函数

. . .

. . . .

. . . .

168

6.3.3 其他隐藏单

元 .

. . . .

. . . .

. . . .

. . . .

. . . .

. 169

6.4 架构设计

.

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

170

6.4.1 万能近似性

质和深度 .

. . . .

. . . .

. . . .

. . . .

. 171

6.4.2 其

他架构上的

考虑

. . . .

. . . .

. . . .

. . . .

. . . 174

6.5 反向传

播和其他的

微分算法 . .

. . . .

. . . .

. . . .

. . . .

. 175

6.5.1 计

算图

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 176

6.5.2

微积分

中的链式法

则 . . .

. . . .

. . . .

. . . .

. . . 178

6.5.3 递归地使

用链式法则

来实现反向

传播 . .

. . . .

. . . 179

目录 vii

6.5.4 全

连接

MLP 中的反

向传播计算

. . .

. . . .

. . . .

. 181

6.5.5 符号到符号

的导数

. . . .

. . . .

. . . .

. . . .

. . . 182

6.5.6 一般

化的反向传

播 . .

. . . .

. . . .

. . . .

. . . .

. 185

6.5.7 实例：用于

MLP

训练的反向

传播 . . .

. . . .

. . . 188

6.5.8 复杂化

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 190

6.5.9 深度学习界

以外的微分

. . .

. . . .

. . . .

. . . .

. . 191

6.5.10

高阶微分 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 193

6.6 历

史小记

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 193

第七

章 深度学习

中的正则化

197

7.1 参数范数惩

罚 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 198

7.1.1 L

2 参数正则

化 . .

. . . .

. . . .

. . . .

. . . .

. . . 199

7.1.2 L

1 参数正则

化

. . . .

. . . .

. . . .

. . . .

. . . .

. 202

7.2 作为约束

的范数惩罚

.

. . . .

. . . .

. . . .

. . . .

. . . .

. . 204

7.3

正则化和欠

约束问题 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

206

7.4 数

据集增强 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 207

7.5 噪

声鲁棒性 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 208

7.5.1

向

输出目标注

入噪声 . . .

. . . .

. . . .

. . . .

. . . 209

7.6 半监

督学习 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 209

7.7

多任

务学习 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 210

7.8 提前

终止

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 211

7.9 参数绑

定和参数共

享

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 217

7.9.1 卷积神经

网络 . .

. . . .

. . . .

. . . .

. . . .

. . . .

218

7.10 稀疏表

示 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

218

7.11 Bagging 和其他集

成方法

. . . .

. . . .

. . . .

. . . .

. . . .

. 220

7.12 Dropout

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 222

7.13

对抗

训练 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 230

7.14

切面距

离、正切传播

和流形正切

分类器 . . .

. . . .

. . . .

. . 232

第八

章

深度模型

中的优化 235

8.1 学

习和纯优化

有什么不同

.

. . . .

. . . .

. . . .

. . . .

. . . 235

8.1.1 经验风险最

小化 . .

. . . .

. . . .

. . . .

. . . .

. . 236

8.1.2

代理损

失函数和提

前终止 . . .

. . . .

. . . .

. . . .

237

viii 目录

8.1.3 批量算法和

小批量算法

.

. . . .

. . . .

. . . .

. . . .

237

8.2 神经网络优

化中的挑战

. .

. . . .

. . . .

. . . .

. . . .

. . . .

241

8.2.1 病态 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 242

8.2.2

局部极

小值 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

243

8.2.3 高原、鞍

点和其他平

坦区域 .

. . . .

. . . .

. . . .

. 244

8.2.4 悬崖

和梯度爆炸

.

. . . .

. . . .

. . . .

. . . .

. . . 246

8.2.5 长期依赖 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 247

8.2.6

非

精确梯度 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

248

8.2.7 局

部和全局结

构间的弱对

应 .

. . . .

. . . .

. . . .

. 248

8.2.8 优化的理

论限制

. . . .

. . . .

. . . .

. . . .

. . . .

250

8.3 基本

算法 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

251

8.3.1 随机梯

度下降 .

. . . .

. . . .

. . . .

. . . .

. . . .

. 251

8.3.2 动量

.

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 253

8.3.3

Nesterov 动量 . .

. . . .

. . . .

. . . .

. . . .

. . . 256

8.4 参数初

始化策略 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

256

8.5 自

适应学习率

算法 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 261

8.5.1 AdaGrad . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 261

8.5.2

RMSProp . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 262

8.5.3 Adam

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 262

8.5.4

选择正

确的优化算

法 . . .

. . . .

. . . .

. . . .

. . . 263

8.6 二阶近似

方法 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 265

8.6.1 牛顿法

.

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 266

8.6.2 共轭梯度

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

267

8.6.3 BFGS .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 270

8.7 优

化策略和元

算法

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

271

8.7.1 批标准

化 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 271

8.7.2 坐标下降

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 274

8.7.3 Polyak

平均 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

274

8.7.4 监督预

训练 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 275

8.7.5

设计有

助于优化的

模型 . . .

. . . .

. . . .

. . . .

. . 277

8.7.6

延拓法

和课程学习

. . . .

. . . .

. . . .

. . . .

. . . 278

目录 ix

第九章

卷积网络 281

9.1 卷

积运算 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 282

9.2 动机

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 285

9.3 池化

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

290

9.4 卷积与

池化作为一

种无限强的

先验 .

. . . .

. . . .

. . . .

. . 295

9.5

基本卷

积函数的变

体 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

296

9.6 结构化输

出 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 306

9.7 数据类型

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 307

9.8

高效的卷积

算法 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 309

9.9 随机或

无监督的特

征 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 310

9.10 卷积网络

的神经科学

基础

. . . .

. . . .

. . . .

. . . .

. . . .

311

9.11 卷积网

络与深度学

习的历史 .

. . . .

. . . .

. . . .

. . . .

. . 317

第

十章

序列建

模：循环和递

归网络 319

10.1 展开

计算图

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

320

10.2 循环

神经网络 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 323

10.2.1

导

师驱动过程

和输出循环

网络 . . .

. . . .

. . . .

. . 326

10.2.2

计算循

环神经网络

的梯度 . . .

. . . .

. . . .

. . . .

328

10.2.3 作为

有向图模型

的循环网络

. .

. . . .

. . . .

. . . .

330

10.2.4 基于上下文

的 RNN

序列建模

. . . .

. . . .

. . . .

. 334

10.3 双向

RNN . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 336

10.4

基于编

码-解码的序

列到序列架

构 . . .

. . . .

. . . .

. . . .

. 338

10.5 深度循环

网络

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 340

10.6 递归神

经网络 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 341

10.7 长期

依赖的挑战

.

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 343

10.8 回声状态网

络

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 345

10.9 渗漏单元

和其他多时

间尺度的策

略 . .

. . . .

. . . .

. . . .

. 347

10.9.1 时间维度

的跳跃连接

.

. . . .

. . . .

. . . .

. . . .

. 347

10.9.2 渗漏单元和

一系列不同

时间尺度

. . . .

. . . .

. . . 348

10.9.3 删

除连接 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 348

10.10

长短

期记忆和其

他门控 RNN . .

. . . .

. . . .

. . . .

. . . .

349

10.10.1 LSTM .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 349

10.10.2 其他

门控

RNN . . .

. . . .

. . . .

. . . .

. . . .

. . 351

x

目录

10.11 优

化长期依赖

. .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 352

10.11.1 截断梯度

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

353

10.11.2 引

导信息流的

正则化 .

. . . .

. . . .

. . . .

. . . .

. 355

10.12 外显

记忆

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 355

第十一

章 实践方法

论

359

11.1 性能度量

. .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 360

11.2 默认的基准

模型 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

362

11.3 决定是

否收集更多

数据 .

. . . .

. . . .

. . . .

. . . .

. . . .

. 363

11.4 选择超

参数

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

364

11.4.1 手动调

整超参数 .

. . . .

. . . .

. . . .

. . . .

. . . 364

11.4.2 自

动超参数优

化算法 . .

. . . .

. . . .

. . . .

. . . .

367

11.4.3 网格

搜索 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 368

11.4.4 随机搜

索 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 369

11.4.5

基于模型

的超参数优

化 . . .

. . . .

. . . .

. . . .

. . 370

11.5

调试策略

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 371

11.6 示例：多位数

字识别

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 374

第十

二章 应用 377

12.1

大

规模深度学

习 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 377

12.1.1 快速的 CPU 实

现

. . . .

. . . .

. . . .

. . . .

. . . 378

12.1.2 GPU 实现 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 378

12.1.3 大规

模的分布式

实现 . .

. . . .

. . . .

. . . .

. . . .

380

12.1.4 模型压

缩 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 381

12.1.5 动态结构

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 382

12.1.6 深度网络的

专用硬件实

现

. . . .

. . . .

. . . .

. . . 384

12.2 计算机视

觉 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 385

12.2.1

预处理 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 385

12.2.1.1 对

比度归一化

. . .

. . . .

. . . .

. . . .

. . . .

. . 386

12.2.2

数据集增强

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 389

12.3 语音识别 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 390

12.4 自

然语言处理

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

392

12.4.1 n-gram .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

392

目录 xi

12.4.2

神经语

言模型 . . .

. . . .

. . . .

. . . .

. . . .

. . . 394

12.4.3 高维

输出 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 396

12.4.3.1

使用短

列表 . . .

. . . .

. . . .

. . . .

. . . .

. . . 396

12.4.3.2 分层 Softmax .

. . . .

. . . .

. . . .

. . . .

. . . .

397

12.4.3.3 重

要采样 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 399

12.4.3.4 噪声

对比估计和

排名损失 . .

. . . .

. . . .

. . . .

. 401

12.4.4 结

合

n-gram 和神经语

言模型 . .

. . . .

. . . .

. . . 401

12.4.5 神经

机器翻译 . .

. . . .

. . . .

. . . .

. . . .

. . . .

402

12.4.5.1 使

用注意力机

制并对齐数

据片段 .

. . . .

. . . .

. . 403

12.4.6

历史

展望 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 406

12.5 其他应

用

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 407

12.5.1 推荐系统

.

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 407

12.5.1.1 探索与利用

. . .

. . . .

. . . .

. . . .

. . . .

. . . 409

12.5.2 知识表示、推

理和回答 . .

. . . .

. . . .

. . . .

. . . 410

12.5.2.1 知

识、联系和回

答 . .

. . . .

. . . .

. . . .

. . . .

. 410

第三部分

深度学习研

究 414

第十三章

线性因子模

型 417

13.1 概率

PCA 和因

子分析 . .

. . . .

. . . .

. . . .

. . . .

. . . .

418

13.2 独立

成分分析 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 419

13.3

慢

特征分析 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 421

13.4 稀

疏编码

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 423

13.5 PCA

的流

形解释 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 426

第十

四章

自编码

器 429

14.1 欠完备自

编码器

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 430

14.2

正则

自编码器 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

431

14.2.1 稀

疏自编码器

. .

. . . .

. . . .

. . . .

. . . .

. . . .

431

14.2.2 去噪自编码

器 .

. . . .

. . . .

. . . .

. . . .

. . . .

. 433

14.2.3 惩罚导数

作为正则

. . . .

. . . .

. . . .

. . . .

. . . 434

14.3 表

示能力、层的

大小和深度

. . .

. . . .

. . . .

. . . .

. . . .

434

14.4 随机编码器

和解码器 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 435

xii

目

录

14.5 去噪自编

码器 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 436

14.5.1

得分估

计 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 437

14.5.2 历史展望

.

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 440

14.6 使用自编码

器学习流形

. . .

. . . .

. . . .

. . . .

. . . .

. . . 440

14.7 收缩自编码

器 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 445

14.8 预测稀疏

分解

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 447

14.9 自编码

器的应用 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

448

第

十五章 表示

学习 449

15.1 贪心逐

层无监督预

训练 . .

. . . .

. . . .

. . . .

. . . .

. . . .

450

15.1.1 何时以

及为何无监

督预训练有

效？ .

. . . .

. . . .

. 452

15.2 迁移学习

和领域自适

应

. . . .

. . . .

. . . .

. . . .

. . . .

. . 457

15.3

半监督解

释因果关系

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 461

15.4 分布式表示

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 466

15.5 得益于深度

的指数增益

.

. . . .

. . . .

. . . .

. . . .

. . . .

. 471

15.6 提供发现潜

在原因的线

索

. . . .

. . . .

. . . .

. . . .

. . . .

472

第十六章

深度学习中

的结构化概

率模型 475

16.1

非结

构化建模的

挑战 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

476

16.2 使用图

描述模型结

构 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 479

16.2.1

有向模型

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

480

16.2.2 无向模型 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 482

16.2.3 配

分函数 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 484

16.2.4

基于

能量的模型

. . . .

. . . .

. . . .

. . . .

. . . .

485

16.2.5 分离和 d-分离

.

. . . .

. . . .

. . . .

. . . .

. . . .

487

16.2.6 在有向模型

和无向模型

中转换 .

. . . .

. . . .

. . . .

490

16.2.7 因子

图 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 493

16.3 从图模型

中采样

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 494

16.4

结构

化建模的优

势 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 495

16.5 学习依赖

关系

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 496

16.6 推断和

近似推断 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

497

16.7 结

构化概率模

型的深度学

习方法 .

. . . .

. . . .

. . . .

. . . .

498

16.7.1 实例

：受限玻尔兹

曼机 .

. . . .

. . . .

. . . .

. . . .

499

目录 xiii

第

十七章

蒙特

卡罗方法 502

17.1 采

样和蒙特卡

罗方法

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 502

17.1.1 为什

么需要采样

？ . .

. . . .

. . . .

. . . .

. . . .

. 502

17.1.2 蒙特卡罗采

样的基础

. . . .

. . . .

. . . .

. . . .

. . 503

17.2

重

要采样 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 504

17.3

马尔

可夫链蒙特

卡罗方法 . . .

. . . .

. . . .

. . . .

. . . .

. 506

17.4 Gibbs

采

样 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 510

17.5 不同的峰

值之间的混

合挑战

. . . .

. . . .

. . . .

. . . .

. . . 511

17.5.1 不同

峰值之间通

过回火来混

合 . .

. . . .

. . . .

. . . 513

17.5.2 深度也许

会有助于混

合 . .

. . . .

. . . .

. . . .

. . . 514

第十八章

直面配分函

数 516

18.1 对数似然

梯度

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 516

18.2 随机最

大似然和对

比散度 . .

. . . .

. . . .

. . . .

. . . .

. . 518

18.3

伪似

然 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

524

18.4 得分匹配

和比率匹配

. .

. . . .

. . . .

. . . .

. . . .

. . . .

. 526

18.5 去噪得分匹

配

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 528

18.6 噪声对比

估计 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 529

18.7 估计配

分函数

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 531

18.7.1 退火

重要采样 . .

. . . .

. . . .

. . . .

. . . .

. . . .

533

18.7.2 桥

式采样 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 536

第十

九章 近似推

断 538

19.1

把推断视

作优化问题

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 539

19.2 期望最大化

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 541

19.3 最大后验推

断和稀疏编

码

. . . .

. . . .

. . . .

. . . .

. . . .

542

19.4 变分推断

和变分学习

. .

. . . .

. . . .

. . . .

. . . .

. . . .

. 544

19.4.1 离散型潜变

量

. . . .

. . . .

. . . .

. . . .

. . . .

. . 545

19.4.2

变分法 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 551

19.4.3 连

续型潜变量

. . .

. . . .

. . . .

. . . .

. . . .

. . . 554

19.4.4 学习和推断

之间的相互

作用 . .

. . . .

. . . .

. . . .

556

19.5 学成近

似推断 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 556

19.5.1

醒眠

算法 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 557

xiv 目录

19.5.2 学

成推断的其

他形式 . .

. . . .

. . . .

. . . .

. . . .

557

第二

十章 深度生

成模型 559

20.1 玻尔

兹曼机 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 559

20.2

受限

玻尔兹曼机

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 561

20.2.1

条件分布 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 562

20.2.2 训

练受限玻尔

兹曼机

. . . .

. . . .

. . . .

. . . .

. . 563

20.3

深度

信念网络 . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

564

20.4 深

度玻尔兹曼

机 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 566

20.4.1 有趣的性

质

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 568

20.4.2 DBM 均匀场推

断 .

. . . .

. . . .

. . . .

. . . .

. . 569

20.4.3

DBM 的参数学

习 . .

. . . .

. . . .

. . . .

. . . .

. 571

20.4.4 逐层预训

练

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 572

20.4.5 联合训练

深度玻尔兹

曼机 . .

. . . .

. . . .

. . . .

. 574

20.5 实值数

据上的玻尔

兹曼机

. . . .

. . . .

. . . .

. . . .

. . . .

578

20.5.1 Gaussian-Bernoulli RBM

. . . .

. . . .

. . . .

. . . 578

20.5.2 条件

协方差的无

向模型 . .

. . . .

. . . .

. . . .

. . . 579

20.6 卷积

玻尔兹曼机

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 583

20.7 用于结构化

或序列输出

的玻尔兹曼

机 . .

. . . .

. . . .

. . . .

585

20.8 其他玻尔

兹曼机 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 586

20.9 通过

随机操作的

反向传播

. . . .

. . . .

. . . .

. . . .

. . . .

587

20.9.1 通

过离散随机

操作的反向

传播 .

. . . .

. . . .

. . . .

588

20.10 有向生

成网络 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 591

20.10.1

sigmoid 信念

网络 . .

. . . .

. . . .

. . . .

. . . .

. . 591

20.10.2

可微生

成器网络 . . .

. . . .

. . . .

. . . .

. . . .

. 592

20.10.3 变

分自编码器

.

. . . .

. . . .

. . . .

. . . .

. . . .

. 594

20.10.4 生成式对抗

网络

. . . .

. . . .

. . . .

. . . .

. . . .

597

20.10.5 生成矩

匹配网络 .

. . . .

. . . .

. . . .

. . . .

. . . 600

20.10.6 卷

积生成网络

. . .

. . . .

. . . .

. . . .

. . . .

. . . 601

20.10.7 自回归网络

. . .

. . . .

. . . .

. . . .

. . . .

. . . .

602

20.10.8 线性自回归

网络 .

. . . .

. . . .

. . . .

. . . .

. . . 602

20.10.9 神经自

回归网络 . .

. . . .

. . . .

. . . .

. . . .

. . 603

20.10.10

NADE . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 604

目

录 xv

20.11 从自编码

器采样

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 606

20.11.1

与任

意去噪自编

码器相关的

马尔可夫链

. . . .

. . . .

607

20.11.2 夹合与条件

采样 .

. . . .

. . . .

. . . .

. . . .

. . . 607

20.11.3 回退训

练过程 . .

. . . .

. . . .

. . . .

. . . .

. . . .

608

20.12 生成

随机网络 .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . 609

20.12.1

判

别性 GSN . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 610

20.13 其他生

成方案

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . 610

20.14 评估

生成模型 . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. 611

20.15 结

论

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

. . . .

613

参考文献

615

术语 679

中文版

致谢

首先，我

们要感谢原

作者在本书

翻译时给予

我们的大力

帮助。特别是

，原作者

和我

们分享了书

中的原图和

参考文献库

，这极大节省

了我们的时

间和精力。

本

书涉及的内

容博大且思

想深刻，如果

没有众多同

学和网友的

帮助，我们不

可

能顺利完

成翻译。

我们

才疏学浅而

受此重任，深

知自身水平

难以将本书

翻译得很准

确。因此我们

完

成草稿后

，将书稿公开

于 Github，及早接受

网友的批评

和建议。以下

网友为本书

的翻

译草稿

提供了很多

及时的反馈

和宝贵的修

改意见：@tttwwy @tankeco @fairmiracle

@GageGao

@huangpingchun @MaHongP @acgtyrant @yanhuibin315

@Buttonwood

@titicacafz @weijy026a @RuiZhang1993

@zymiboxpay @xingkongliang @oisc @tielei

@yuduowu @Qingmu @HC-2016 @xiaomingabc

@bengordai @Bojian @JoyFYan

@minoriwww

@khty2000 @gump88 @zdx3578 @PassStory

@imwebson @wlbksy

@roachsinai @Elvinczp

@endymecy @9578577 @linzhp @cnscottzheng

@germany￾zhu @zhangyafeikimi @showgood163 @kangqf

@NeutronT @badpoem @kkpoker

@Seaball

@wheaio @angrymidiao @ZhiweiYang @corenel

@zhaoyu611 @SiriusXDJ

@dfcv24 @EmisXXY

@FlyingFire @vsooda @friskit-china @poerin

@ninesunqian

@JiaqiYao @Sofring @wenlei

@wizyoung @imageslr @indam @XuLYC

@zhouqing￾ping @freedomRen @runPenguin @piantou

在此

期间，我们四

位译者再次

进行了校对

并且相互之

间也校对了

一遍。然而仅

仅通过我们

的校对，实在

难以发现翻

译中存在的

问题。因此，我

们邀请一些

同学和

网友

帮助我们校

对。经过他们

的校对，本书

的翻译质量

得到了极大

的提升。在此

我

们一一列

出，以表示我

们由衷的感

谢！

•

第一章（引

言）：刘畅、许丁

杰、潘雨粟和

NeutronT 对本章进行

了阅读，并对

xvi

目录 xvii

很多语

句提出了不

少修改建议

。林中鹏进行

了校对，他提

出了很多独

到的修改

建

议。

• 第二章（线

性代数）：许丁

杰和骆徐圣

阅读本章，并

修改语句。李

若愚进行了

校

对，提出了

很多细心的

建议。

• 第三章

（概率与信息

论）：许丁杰阅

读本章，并修

改语句。李培

炎和何翊卓

进行

了校对

，并修改了很

多中文用词

，使翻译更加

准确。

• 第四章

（数值计算）：张

亚霏阅读本

章，并对其他

章节也有提

出了一些修

改建

议。张源

源进行了校

对，并指出了

原文可能存

在的问题，非

常仔细。

•

第五

章（机器学习

基础）：郭浩和

黄平春阅读

本章，并修改

语句。李东和

林中鹏

进行

了校对。本章

篇幅较长，能

够有现在的

翻译质量离

不开这四位

的贡献。

• 第六

章（深度前馈

网络）：周卫林

、林中鹏和张

远航阅读本

章，并提出修

改意

见。

• 第七

章（深度学习

中的正则化

）：周柏村进行

了非常细心

的校对，指出

了大量问

题

，令翻译更加

准确。

• 第八章

（深度模型中

的优化）：房晓

宇和吴翔阅

读本章。黄平

春进行了校

对，他

提出的

很多建议让

行文更加流

畅易懂。

•

第九

章（卷积网络

）：赵雨和潘雨

粟阅读本章

，并润色语句

。丁志铭进行

了非常

仔细

的校对，并指

出很多翻译

问题。

• 第十章

（序列建模：循

环和递归网

络）：刘畅阅读

本章。赵雨提

供了详细的

校对

建议，尹

瑞清根据他

的翻译版本

，给我们的版

本提出了很

多建议。虽然

仍存在

一些

分歧，但我们

两个版本的

整合，让翻译

质量提升很

多。

• 第十二章

（应用）：潘雨粟

进行了校对

，在他的校对

之前，本章阅

读起来比较

困

难。他提供

的修改建议

，不仅提高了

行文流畅度

，还提升了译

文的准确度

。

• 第十三章（线

性因子模型

）：贺天行阅读

本章，修改语

句。杨志伟校

对本章，润

色

大量语句。

• 第

十四章（自编

码器）：李雨慧

和黄平春进

行了校对。李

雨慧提升了

语言的流畅

度，黄平春纠

正了不少错

误，提高了准

确性。

xviii 目录

• 第

十五章（表示

学习）：cnscottzheng 阅读本

章，并修改语

句。

•

第十七章

（蒙特卡罗方

法）：张远航提

供了非常细

致的校对，后

续还校对了

一

遍，使译文

质量大大提

升。

• 第十八章

（直面配分函

数）：吴家楠进

行了校对，提

升了译文准

确性和可读

性。

• 第十九章

（近似推断）：黄

浩军、张远航

和张源源进

行了校对。这

章虽篇幅不

大，但内容有

深度，译文在

三位的帮助

下提高了准

确度。

所有校

对的修改建

议都保存在

Github 上，再次感谢

以上同学和

网友的付出

。经

过这五个

多月的修改

，草稿慢慢变

成了初稿。尽

管还有很多

问题，但大部

分内容是

可

读的，并且是

准确的。当然

目前的翻译

仍存在一些

没有及时发

现的问题，因

此翻

译也将

持续更新，不

断修改。我们

非常希望读

者能到 Github

提建

议，并且非常

欢

迎，无论多

么小的修改

建议，都是非

常宝贵的。

此

外，我们还要

感谢魏太云

学长，他帮助

我们与出版

社沟通交流

，并给予了我

们很多排版

上的指导。

最

后，感谢我们

的导师张志

华教授，没有

老师的支持

，我们难以完

成翻译。

原书

致谢

如果没

有他人的贡

献，这本书将

不可能完成

。我们感谢为

本书提出建

议和帮

助组

织内容结构

的人：Guillaume Alain,

Kyunghyun Cho, Çağlar Gülçehre,

David

Krueger, Hugo Larochelle,

Razvan Pascanu and Thomas

Rohée 。

我们感

谢为本书内

容提供反馈

的人。其中一

些人对许多

章都给出了

建议：Martín

Abadi,

Guillaume Alain, Ion Androutsopoulos,

Fred Bertsch, Olexa Bilaniuk,

Ufuk

Can Biçici, Matko

Bošnjak, John Boersma, Greg

Brockman, Alexandre de Brébisson,

Pierre Luc Carrier, Sarath

Chandar, Pawel Chilinski, Mark

Daoust, Oleg Dashevskii,

Laurent

Dinh, Stephan Dreseitl, Jim

Fan, Miao Fan, Meire

Fortunato, Frédéric Fran￾cis, Nando

de Freitas, Çağlar Gülçehre,

Jurgen Van Gael, Javier

Alonso García,

Jonathan Hunt,

Gopi Jeyaram, Chingiz Kabytayev,

Lukasz Kaiser, Varun Kanade,

Asifullah Khan, Akiel Khan,

John King, Diederik P.

Kingma, Yann LeCun, Rudolf

Mathey, Matías Mattamala, Abhinav

Maurya, Kevin Murphy, Oleg

Mürk, Roman

Novak, Augustus

Q. Odena, Simon Pavlik,

Karl Pichotta, Eddie Pierce,

Kari Pulli,

Roussel Rahman,

Tapani Raiko, Anurag Ranjan,

Johannes Roith, Mihaela Rosca,

Halis Sak, César Salgado,

Grigory Sapunov, Yoshinori Sasaki,

Mike Schuster, Ju￾lian Serban,

Nir Shabat, Ken Shirriff,

Andre Simpelo, Scott Stanley,

David Sussillo,

Ilya Sutskever,

Carles Gelada Sáez, Graham

Taylor, Valentin Tolmer, Massimiliano

Tomassoli, An Tran, Shubhendu

Trivedi, Alexey Umnov, Vincent

Vanhoucke, Marco

Visentini-Scarzanella, Martin

Vita, David Warde-Farley, Dustin

Webb, Kelvin Xu,

Wei

Xue, Ke Yang, Li

Yao, Zygmunt Zając and

Ozan Çağlayan.

我们也

要感谢对单

个章节提供

有效反馈的

人：

•

数学符号

：Zhang Yuanhang.

xix

xx

目录

• 第一章

（引言）：Yusuf Akgul,

Sebastien Bratieres, Samira Ebrahimi,

Charlie

Gorichanaz, Brendan Loudermilk,

Eric Morris, Cosmin Pârvulescu

and Alfredo

Solano.

•

第二章

（线性代数）：Amjad Almahairi, Nikola Banić,

Kevin Bennett, Philippe

Castonguay,

Oscar Chang, Eric Fosler-Lussier,

Andrey Khalyavin, Sergey Ore￾shkov,

István Petrás, Dennis Prangle,

Thomas Rohée, Gitanjali Gulve

Sehgal,

Colby Toland, Alessandro

Vitale and Bob Welland.

• 第

三章（概率与

信息论）：John Philip Anderson,

Kai Arulkumaran, Vincent

Dumoulin,

Rui Fa, Stephan Gouws,

Artem Oboturov, Antti Rasmus,

Alexey

Surkov and Volker

Tresp.

• 第四

章（数值计算

）：Tran Lam

AnIan Fischer and Hu

Yuhuang.

• 第五章（机器

学习基础）：Dzmitry Bahdanau,

Justin Domingue, Nikhil Garg,

Makoto Otsuka, Bob Pepin,

Philip Popien, Emmanuel Rayner,

Peter Shepard,

Kee-Bong Song,

Zheng Sun and Andy

Wu.

• 第

六章（深度前

馈网络）：Uriel Berdugo,

Fabrizio Bottarel, Elizabeth Burl,

Is￾han Durugkar, Jeff Hlywa,

Jong Wook Kim, David

Krueger and Aditya Kumar

Praharaj.

• 第七

章（深度学习

中的正则化

）：Morten Kolbæk,

Kshitij Lauria, Inkyu Lee,

Sunil Mohan, Hai Phong

Phan and Joshua Salisbury.

• 第八章（深度

模型中的优

化）：Marcel Ackermann, Peter

Armitage, Rowel

Atienza, Andrew

Brock, Tegan Maharaj, James

Martens, Kashif Rasul, Klaus

Strobl and Nicholas Turner.

• 第九章（卷

积网络）：Martín Arjovsky, Eugene

Brevdo, Konstantin Divilov, Eric

Jensen, Mehdi Mirza, Alex

Paino, Marjorie Sayer, Ryan

Stout and Wentao Wu.

• 第十

章（序列建模

：循环和递归

网络）：Gökçen Eraslan, Steven

Hickson, Razvan

Pascanu, Lorenzo

von Ritter, Rui Rodrigues,

Dmitriy Serdyuk, Dongyu Shi

and

Kaiyu Yang.

•

第十一

章（实践方法

论）：Daniel Beckstein.

目录 xxi

• 第十

二章（应用）：George Dahl, Vladimir

Nekrasov and Ribana Roscher.

• 第

十三章（线性

因子模型）：Jayanth Koushik.

•

第

十五章（表示

学习）：Kunal Ghosh.

• 第十六

章（深度学习

中的结构化

概率模型）：Minh

Lê and Anton Varfolom.

• 第

十八章（直面

配分函数）：Sam Bowman.

•

第

十九章（近似

推断）：Yujia Bao.

• 第二十

章（深度生成

模型）：Nicolas

Chapados, Daniel Galvez, Wenming

Ma,

Fady Medhat, Shakir

Mohamed and Grégoire Montavon.

• 参考文

献：Lukas Michelbacher and

Leslie N. Smith.

我们还要

感谢那些允

许我们从他

们的出版物

中复制图片

、数据的人。我

们在图

片标

题的文字中

注明了他们

的贡献。

我们

还要感谢 Lu Wang

为

我们写了 pdf2htmlEX，我

们用它来制

作这本书的

网

页版本，Lu Wang

还

帮助我们改

进了生成的

HTML 的质量。

我们

还要感谢 Ian

的

妻子 Daniela Flori Goodfellow，在

Ian 的写

作过程中的

耐

心支持和

检查。

我们还

要感谢

Google Brain 团队

提供了学术

环境，从而使

得 Ian

能够花费

大

量时间写

作此书并接

受同行的反

馈和指导。我

们特别感谢

Ian 的前任经理

Greg

Corrado

和他的现任

经理 Samy Bengio 对这个

项目的支持

。最后我们还

要感谢

Geoffrey Hinton 在写

作困难时的

鼓励。

网站

www.deeplearningbook.org

这

本书伴随有

上述网站。网

站提供了各

种补充材料

，包括练习、讲

义幻灯片、错

误更正以及

其他应该对

读者和讲师

有用的资源

。

xxii

数学符号

本

节简要介绍

本书所使用

的数学符号

。我们在第二

章至第四章

中描述大多

数数

学概念

，如果你不熟

悉任何相应

的数学概念

，可以参考对

应的章节。

数

和数组

a

标量

(整数或实数

)

a 向量

A

矩阵

A 张

量

In

n 行 n 列的单

位矩阵

I 维度

蕴含于上下

文的单位矩

阵

e

(i)

标准基向

量 [0, . .

. , 0, 1,

0, . . .

, 0]，其中索引

i 处值

为

1

diag(a) 对角

方阵，其中对

角元素由 a

给

定

a 标量随机

变量

a

向量随

机变量

A 矩阵

随机变量

xxiii

xxiv 目

录

集合和图

A 集合

R 实数集

{0, 1} 包含

0 和 1 的集

合

{0, 1, . .

. , n} 包含

0 和 n 之

间所有整数

的集合

[a, b] 包含

a 和

b 的实数区

间

(a, b]

不包含 a 但

包含 b

的实数

区间

A\B 差集，即

其元素包含

于 A

但不包含

于 B

G 图

P aG(xi) 图 G

中 xi 的

父节点

索引

ai

向量 a 的第 i

个

元素，其中索

引从 1 开始

a−i

除

了第 i 个元素

，a 的所有元素

Ai,j

矩阵 A 的 i,

j 元素

Ai,: 矩阵 A

的第 i 行

A:,i 矩阵

A 的第 i 列

Ai,j,k

3 维张量 A 的

(i, j, k) 元

素

A:,:,i 3 维张量的

2 维切片

ai 随机

向量 a 的第

i 个

元素

目录 xxv

线

性代数中的

操作

A

⊤ 矩阵

A 的

转置

A

+

A 的Moore-Penrose 伪逆

A ⊙

B A 和 B

的逐元素

乘积（Hadamard 乘积）

det(A) A

的

行列式

微积

分

dy

dx

y 关于 x 的导

数

∂y

∂x y 关于

x 的偏

导

∇xy y

关于 x 的梯

度

∇Xy

y 关于 X 的矩

阵导数

∇Xy y 关于

X 求导后的张

量

∂f

∂x

f :

R

n → R

m 的Jacobian矩阵 J ∈

R

m×n

∇2

x

f(x) or H(f)(x) f

在

点 x 处的Hessian矩阵

∫

f(x)dx

x 整个域上的

定积分

∫

S

f(x)dx 集合

S 上关于 x

的定

积分

xxvi 目录

概

率和信息论

a⊥b

a 和 b 相互独立

的随机变量

a⊥b

| c 给定 c

后条件

独立

P(a) 离散变

量上的概率

分布

p(a)

连续变

量（或变量类

型未指定时

）上的概率分

布

a ∼ P

具有分布

P 的随机变量

a

Ex∼P [f(x)]

or Ef(x) f(x) 关于

P(x) 的期望

Var(f(x)) f(x) 在分布

P(x) 下的

方差

Cov(f(x), g(x))

f(x) 和 g(x) 在分

布

P(x) 下的协方

差

H(x) 随机变量

x

的香农熵

DKL(P∥Q) P 和

Q

的KL 散度

N (x;

µ, Σ) 均值

为 µ

协方差为

Σ，x 上的高斯分

布

目录 xxvii

函数

f : A →

B 定义域为 A 值

域为

B 的函数

f

f ◦

g f 和 g

的组合

f(x; θ) 由

θ

参数化，关于

x 的函数（有时

为简化表示

，我

们忽略 θ

记

为 f(x) ）

log

x x 的自然对

数

σ(x)

Logistic sigmoid, 1

1

+ exp(−x)

ζ(x) Softplus,

log(1 + exp(x))

||x||p

x 的 L

p

范数

||x|| x 的

L

2 范数

x

+

x 的正数

部分, 即 max(0,

x)

1condition 如果

条件为真则

为 1，否则为

0

有

时候我们使

用函数 f，它的

参数是一个

标量，但应用

到一个向量

、矩阵或张

量

：f(x),

f(X), or f(X) 。这表示逐元

素地将

f 应用

于数组。例如

，C = σ(X)，则

对于所有

合法的 i、j 和 k，Ci,j,k

= σ(Xi,j,k)。

数

据集和分布

pdata 数据生成分

布

pˆtrain 由训练集

定义的经验

分布

X 训练样

本的集合

x

(i) 数

据集的第 i

个

样本（输入）

y

(i)

or

y

(i) 监

督学习中与

x

(i)

关联的目标

X m × n

的矩阵，其中

行 Xi,: 为输入样

本 x

(i)

xxviii 目录

第一

章

引言

远在

古希腊时期

，发明家就梦

想着创造能

自主思考的

机器。神话人

物皮格马利

翁 (Pygmalion)、代达罗斯

(Daedalus) 和赫淮斯托

斯

(Hephaestus) 可以被看

作传说

中的

发明家，而加

拉蒂亚 (Galatea)、塔洛

斯

(Talos) 和潘多拉

(Pandora) 则可以被

视

为人造生命

(Ovid

and Martin, 2004; Sparkes,

1996; Tandy, 1997)。

当人类第一

次构思可编

程计算机时

，就已经在思

考计算机能

否变得智能

（尽管

这距造

出第一台计

算机还有一

百多年）(Lovelace, 1842)。如今

，人工智能（artificial

intelligence, AI）已

经成为一个

具有众多实

际应用和活

跃研究课题

的领域，并且

正在

蓬勃发

展。我们期望

通过智能软

件自动地处

理常规劳动

、理解语音或

图像、帮助医

学诊断和支

持基础科学

研究。

在人工

智能的早期

，那些对人类

智力来说非

常困难、但对

计算机来说

相对简单

的

问题得到迅

速解决，比如

，那些可以通

过一系列形

式化的数学

规则来描述

的问题。

人工

智能的真正

挑战在于解

决那些对人

来说很容易

执行、但很难

形式化描述

的任务，

如识

别人们所说

的话或图像

中的脸。对于

这些问题，我

们人类往往

可以凭借直

觉轻

易地解

决。

针对这些

比较直观的

问题，本书讨

论一种解决

方案。该方案

可以让计算

机从经

验中

学习，并根据

层次化的概

念体系来理

解世界，而每

个概念则通

过与某些相

对简

单的概

念之间的关

系来定义。让

计算机从经

验获取知识

，可以避免由

人类来给计

算

机形式化

地指定它需

要的所有知

识。层次化的

概念让计算

机构建较简

单的概念来

学

习复杂概

念。如果绘制

出这些概念

如何建立在

彼此之上的

图，我们将得

到一张 ‘‘深’’

（层

次很多）的图

。基于这个原

因，我们称这

种方法为 AI 深

度学习（deep learning）。

AI 许多

早期的成功

发生在相对

朴素且形式

化的环境中

，而且不要求

计算机具

备

很多关于世

界的知识。例

如，IBM 的深蓝（Deep

Blue）国

际象棋系统

在 1997 年

1

2 第一章

引言

击败了

世界冠军Garry Kasparov(Hsu,

2002)。显

然国际象棋

是一个非常

简单的领域

，

因为它仅含

有 64 个位置并

只能以严格

限制的方式

移动

32 个棋子

。设计一种成

功的

国际象

棋策略是巨

大的成就，但

向计算机描

述棋子及其

允许的走法

并不是挑战

的困

难所在

。国际象棋完

全可以由一

个非常简短

的、完全形式

化的规则列

表来描述，并

可以容易地

由程序员事

先准备好。

讽

刺的是，抽象

和形式化的

任务对人类

而言是最困

难的脑力任

务之一，但对

计

算机而言

却属于最容

易的。计算机

早就能够打

败人类最好

的象棋选手

，但直到最近

计算机才在

识别对象或

语音任务中

达到人类平

均水平。一个

人的日常生

活需要关于

世界的巨量

知识。很多这

方面的知识

是主观的、直

观的，因此很

难通过形式

化的方

式表

达清楚。计算

机需要获取

同样的知识

才能表现出

智能。人工智

能的一个关

键挑

战就是

如何将这些

非形式化的

知识传达给

计算机。

一些

人工智能项

目力求将关

于世界的知

识用形式化

的语言进行

硬编码 (hard￾code)。计算

机可以使用

逻辑推理规

则来自动地

理解这些形

式化语言中

的声明。这

就

是众所周知

的人工智能

的 知识库（knowledge

base）方

法。然而，这些

项目最终

都

没有取得重

大的成功。其

中最著名的

项目是 Cyc (Lenat

and Guha, 1989)。Cyc

包括

一个推断引

擎和一个使

用

CycL 语言描述

的声明数据

库。这些声明

是由人类

监

督者输入的

。这是一个笨

拙的过程。人

们设法设计

出足够复杂

的形式化规

则来

精确地

描述世界。例

如，Cyc

不能理解

一个关于名

为 Fred 的人在早

上剃须的故

事 (Linde,

1992)。它的推理

引擎检测到

故事中的不

一致性：它知

道人体的构

成不

包含电

气零件，但由

于 Fred 正拿着一

个电动剃须

刀，它认为实

体

‘‘正在剃须

的

Fred” (“FredWhileShaving”) 含有电气

部件。因此它

产生了这样

的疑问——Fred

在

刮

胡子的时候

是否仍然是

一个人。

依靠

硬编码的知

识体系面对

的困难表明

，AI 系统需要具

备自己获取

知识的能力

，

即从原始数

据中提取模

式的能力。这

种能力被称

为 机器学习

（machine learning）。

引入机器学

习使计算机

能够解决涉

及现实世界

知识的问题

，并能作出看

似主观的决

策。比如，一个

被称为

逻辑

回归（logistic regression）的简单

机器学习算

法可以决定

是否建议剖

腹产 (Mor-Yosef et

al., 1990)。而同样

是简单机器

学习算法的

朴素贝叶

斯

（naive Bayes）则可以区分

垃圾电子邮

件和合法电

子邮件。

这些

简单的机器

学习算法的

性能在很大

程度上依赖

于给定数据

的 表示（repre￾sentation）。例如

，当逻辑回归

被用于判断

产妇是否适

合剖腹产时

，AI 系统不会直

接

检查患者

。相反，医生需

要告诉系统

几条相关的

信息，诸如是

否存在子宫

疤痕。表

示患

者的每条信

息被称为一

个特征。逻辑

回归学习病

人的这些特

征如何与各

种结果

3

相关

联。然而，它丝

毫不能影响

该特征定义

的方式。如果

将病人的 MRI

扫

描作为逻

辑

回归的输入

，而不是医生

正式的报告

，它将无法作

出有用的预

测。MRI 扫描的单

一像素与分

娩过程中并

发症之间的

相关性微乎

其微。

在整个

计算机科学

乃至日常生

活中，对表示

的依赖都是

一个普遍现

象。在计算

机

科学中，如果

数据集合被

精巧地结构

化并被智能

地索引，那么

诸如搜索之

类的操

作的

处理速度就

可以成指数

级地加快。人

们可以很容

易地在阿拉

伯数字的表

示下进

行算

术运算，但在

罗马数字的

表示下运算

会比较耗时

。因此，毫不奇

怪，表示的选

择

会对机器

学习算法的

性能产生巨

大的影响。图

1.1

展示了一个

简单的可视

化例子。

x

Cartesian coordinates

r

Polar coordinates

图

1.1: 不

同表示的例

子：假设我们

想在散点图

中画一条线

来分隔两类

数据。在左图

，我们使用笛

卡尔坐标表

示数据，这个

任务是不可

能的。右图中

，我们用极坐

标表示数据

，可以用垂直

线简单地

解

决这个任务

。（与 David

Warde-Farley 合作画出

此图。）

许多人

工智能任务

都可以通过

以下方式解

决：先提取一

个合适的特

征集，然后

将

这些特征提

供给简单的

机器学习算

法。例如，对于

通过声音鉴

别说话者的

任务来

说，一

个有用的特

征是对其声

道大小的估

计。这个特征

为判断说话

者是男性、女

性

还是儿童

提供了有力

线索。

然而，对

于许多任务

来说，我们很

难知道应该

提取哪些特

征。例如，假设

我们想

编写

一个程序来

检测照片中

的车。我们知

道，汽车有轮

子，所以我们

可能会想用

车

轮的存在

与否作为特

征。不幸的是

，我们难以准

确地根据像

素值来描述

车轮看上去

像什么。虽然

车轮具有简

单的几何形

状，但它的图

像可能会因

场景而异，如

落在车

轮上

的阴影、太阳

照亮的车轮

的金属零件

、汽车的挡泥

板或者遮挡

的车轮一部

分的

前景物

体等等。

y

µ

4 第一

章 引言

解决

这个问题的

途径之一是

使用机器学

习来发掘表

示本身，而不

仅仅把表示

映

射到输出

。这种方法我

们称之为 表

示学习（representation learning）。学习

到的表

示往

往比手动设

计的表示表

现得更好。并

且它们只需

最少的人工

干预，就能让

AI系

统迅速适

应新的任务

。表示学习算

法只需几分

钟就可以为

简单的任务

发现一个很

好

的特征集

，对于复杂任

务则需要几

小时到几个

月。手动为一

个复杂的任

务设计特征

需要耗费大

量的人工时

间和精力；甚

至需要花费

整个社群研

究人员几十

年的时间。

表

示学习算法

的典型例子

是

自编码器

（autoencoder）。自编码器由

一个 编码器

（encoder）函数和一个

解码器（decoder）函数

组合而成。编

码器函数将

输入数据转

换为一种不

同的表示，而

解码器函数

则将这个新

的表示转换

到原来的形

式。我们期

望

当输入数据

经过编码器

和解码器之

后尽可能多

地保留信息

，同时希望新

的表示有

各

种好的特性

，这也是自编

码器的训练

目标。为了实

现不同的特

性，我们可以

设计

不同形

式的自编码

器。

当设计特

征或设计用

于学习特征

的算法时，我

们的目标通

常是分离出

能解释观

察

数据的 变差

因素（factors

of variation）。在此背

景下，‘‘因素’’ 这

个词仅指代

影响

的不同

来源；因素通

常不是乘性

组合。这些因

素通常是不

能被直接观

察到的量。相

反，它们可能

是现实世界

中观察不到

的物体或者

不可观测的

力，但会影响

可观测的

量

。为了对观察

到的数据提

供有用的简

化解释或推

断其原因，它

们还可能以

概念的

形式

存在于人类

的思维中。它

们可以被看

作数据的概

念或者抽象

，帮助我们了

解这

些数据

的丰富多样

性。当分析语

音记录时，变

差因素包括

说话者的年

龄、性别、他们

的口音和他

们正在说的

词语。当分析

汽车的图像

时，变差因素

包括汽车的

位置、它

的颜

色、太阳的角

度和亮度。

在

许多现实的

人工智能应

用中，困难主

要源于多个

变差因素同

时影响着我

们能

够观察

到的每一个

数据。比如，在

一张包含红

色汽车的图

片中，其单个

像素在夜间

可能会非常

接近黑色。汽

车轮廓的形

状取决于视

角。大多数应

用需要我们

理清变差

因

素并忽略我

们不关心的

因素。

显然，从

原始数据中

提取如此高

层次、抽象的

特征是非常

困难的。许多

诸如说话

口

音这样的变

差因素，只能

通过对数据

进行复杂的

、接近人类水

平的理解来

辨识。这

几乎

与获得原问

题的表示一

样困难，因此

，乍一看，表示

学习似乎并

不能帮助我

们。

深度学习

（deep learning）通过其他较

简单的表示

来表达复杂

表示，解决了

表

示学习中

的核心问题

。

深度学习让

计算机通过

较简单概念

构建复杂的

概念。图 1.2 展示

了深度学习

系统

5

Visible layer

(input

pixels)

1st hidden layer

(edges)

2nd hidden layer

(corners and

contours)

3rd

hidden layer

(object parts)

CAR PERSON ANIMAL Output

(object identity)

图 1.2:

深度

学习模型的

示意图。计算

机难以理解

原始感观输

入数据的含

义，如表示为

像素值集合

的图像。将一

组像素映射

到对象标识

的函数非常

复杂。如果直

接处理，学习

或评估此映

射似乎是

不

可能的。深度

学习将所需

的复杂映射

分解为一系

列嵌套的简

单映射（每个

由模型的不

同层描述）

来

解决这一难

题。输入展示

在 可见层（visible

layer），这

样命名的原

因是因为它

包含我们能

观察

到的变

量。然后是一

系列从图像

中提取越来

越多抽象特

征的 隐藏层

（hidden layer）。因为它们的

值不在数据

中给出，所以

将这些层称

为

‘‘隐藏”; 模型

必须确定哪

些概念有利

于解释观察

数据中的

关

系。这里的图

像是每个隐

藏单元表示

的特征的可

视化。给定像

素，第一层可

以轻易地通

过比较相

邻

像素的亮度

来识别边缘

。有了第一隐

藏层描述的

边缘，第二隐

藏层可以容

易地搜索可

识别为角

和

扩展轮廓的

边集合。给定

第二隐藏层

中关于角和

轮廓的图像

描述，第三隐

藏层可以找

到轮廓和

角

的特定集合

来检测特定

对象的整个

部分。最后，根

据图像描述

中包含的对

象部分，可以

识别图

像中

存在的对象

。经 Zeiler

and Fergus (2014) 许可转载

此图。

如何通

过组合较简

单的概念（例

如转角和轮

廓，它们转而

由边线定义

）来表示图像

中人的概念

。深度学习模

型的典型例

子是前馈深

度网络或 多

层感知机（multilayer

perceptron, MLP）。多

层感知机仅

仅是一个将

一组输入值

映射到输出

值的数学函

数。

该函数由

许多较简单

的函数复合

而成。我们可

以认为不同

数学函数的

每一次应用

都

为输入提

供了新的表

示。

6 第一章

引

言

学习数据

的正确表示

的想法是解

释深度学习

的一个视角

。另一个视角

是深度促

使

计算机学习

一个多步骤

的计算机程

序。每一层表

示都可以被

认为是并行

执行另一

组

指令之后计

算机的存储

器状态。更深

的网络可以

按顺序执行

更多的指令

。顺序指

令提

供了极大的

能力，因为后

面的指令可

以参考早期

指令的结果

。从这个角度

上看，

在某层

激活函数里

，并非所有信

息都蕴涵着

解释输入的

变差因素。表

示还存储着

状

态信息，用

于帮助程序

理解输入。这

里的状态信

息类似于传

统计算机程

序中的计数

器或指针。它

与具体的输

入内容无关

，但有助于模

型组织其处

理过程。

目前

主要有两种

度量模型深

度的方式。第

一种方式是

基于评估架

构所需执行

的

顺序指令

的数目。假设

我们将模型

表示为给定

输入后，计算

对应输出的

流程图，则

可

以将这张流

程图中的最

长路径视为

模型的深度

。正如两个使

用不同语言

编写的等

价

程序将具有

不同的长度

；相同的函数

可以被绘制

为具有不同

深度的流程

图，其深

度取

决于我们可

以用来作为

一个步骤的

函数。图

1.3 说明

了语言的选

择如何给相

同的

架构两

个不同的衡

量。

xx11

σ

ww11

⇥

xx22

ww22

⇥

+

Element

Set

+

⇥

σ

x w

Element

Set

Logistic

Regression

Logistic

Regression

图 1.3: 将输入

映射到输出

的计算图表

的示意图，其

中每个节点

执行一个操

作。深度是从

输入到输

出

的最长路径

的长度，但这

取决于可能

的计算步骤

的定义。这些

图中所示的

计算是逻辑

回归模型的

输出，σ(w

T

x)，其中 σ 是

logistic

sigmoid 函数。如果我

们使用加法

、乘法和 logistic sigmoid

作

为

我们计算机

语言的元素

，那么这个模

型深度为三

。如果我们将

逻辑回归视

为元素本身

，那么这

个模

型深度为一

。

另一种是在

深度概率模

型中使用的

方法，它不是

将计算图的

深度视为模

型深度，

而是

将描述概念

彼此如何关

联的图的深

度视为模型

深度。在这种

情况下，计算

每个

概念表

示的计算流

程图的深度

可能比概念

本身的图更

深。这是因为

系统对较简

单概

念的理

解在给出更

复杂概念的

信息后可以

进一步精细

化。例如，一个

AI 系统观察其

7

中一只眼睛

在阴影中的

脸部图像时

，它最初可能

只看到一只

眼睛。但当检

测到脸部

的

存在后，系统

可以推断第

二只眼睛也

可能是存在

的。在这种情

况下，概念的

图仅

包括两

层（关于眼睛

的层和关于

脸的层），但如

果我们细化

每个概念的

估计将需要

额

外的

n 次计

算，即计算的

图将包含 2n 层

。

由于并不总

是清楚计算

图的深度或

概率模型图

的深度哪一

个是最有意

义的，并

且由

于不同的人

选择不同的

最小元素集

来构建相应

的图，因此就

像计算机程

序的长

度不

存在单一的

正确值一样

，架构的深度

也不存在单

一的正确值

。另外，也不存

在

模型多么

深才能被修

饰为

‘‘深’’ 的共

识。但相比传

统机器学习

，深度学习研

究的模型

涉

及更多学到

功能或学到

概念的组合

，这点毋庸置

疑。

总之，这本

书的主题——深

度学习是通

向人工智能

的途径之一

。具体来说，它

是机器学习

的一种，一种

能够使计算

机系统从经

验和数据中

得到提高的

技术。我们

坚

信机器学习

可以构建出

在复杂实际

环境下运行

的 AI 系统，并且

是唯一切实

可行的

方法

。深度学习是

一种特定类

型的机器学

习，具有强大

的能力和灵

活性，它将大

千

世界表示

为嵌套的层

次概念体系

（由较简单概

念间的联系

定义复杂概

念、从一般抽

象概括到高

级抽象表示

）。图1.4 说明了这

些不同的 AI 学

科之间的关

系。图

1.5 展示

了

每个学科如

何工作的高

层次原理。

8

第

一章 引言

AI

Machine

learning

Representation learning

Deep

learning

Example:

Knowledge

bases

Example:

Logistic

regression

Example:

Shallow

autoencoders Example:

MLPs

图

1.4: 维恩图展示

了深度学习

是一种表示

学习，也是一

种机器学习

，可以用于许

多（但不是全

部）

AI 方法。维恩

图的每个部

分包括一个

AI

技术的示例

。

9

Input

Hand￾designed

program

Output

Input

Hand￾designed

features

Mapping from

features

Output

Input

Features

Mapping from 

features

Output

Input

Simple

features

Mapping from

features

Output

Additional

layers of more

abstract 

features

Rule-based

systems

Classic

machine

learning

Representation

learning

Deep

learning

图 1.5: 流程图展

示了 AI

系统的

不同部分如

何在不同的

AI 学科中彼此

相关。阴影框

表示能从数

据中学习的

组件。

10 第一章

引言

1.1 本书面

向的读者

这

本书对各类

读者都有一

定用处，但我

们主要是为

两类受众对

象而写的。其

中

一类受众

对象是学习

机器学习的

大学生（本科

或研究生），包

括那些已经

开始职业

生

涯的深度学

习和人工智

能研究者。另

一类受众对

象是没有机

器学习或统

计背景但

希

望能快速地

掌握这方面

知识并在他

们的产品或

平台中使用

深度学习的

软件工程师

。

深度学习在

许多软件领

域都已被证

明是有用的

，包括计算机

视觉、语音和

音频处理、

自

然语言处理

、机器人技术

、生物信息学

和化学、电子

游戏、搜索引

擎、网络广告

和

金融。

为了

最好地服务

各类读者，我

们将本书组

织为三个部

分。第一部分

介绍基本的

数学工具和

机器学习的

概念。第二部

分介绍最成

熟的深度学

习算法，这些

技术基本

上

已经得到解

决。第三部分

讨论某些具

有展望性的

想法，它们被

广泛地认为

是深度

学习

未来的研究

重点。

读者可

以随意跳过

不感兴趣或

与自己背景

不相关的部

分。熟悉线性

代数、概率

和

基本机器学

习概念的读

者可以跳过

第一部分，例

如，当读者只

是想实现一

个能工

作的

系统则不需

要阅读超出

第二部分的

内容。为了帮

助读者选择

章节，图 1.6

展示

了

这本书的

高层组织结

构的流程图

。

我们假设所

有读者都具

备计算机科

学背景。也假

设读者熟悉

编程，并且对

计算

的性能

问题、复杂性

理论、入门级

微积分和一

些图论术语

有基本的了

解。

1.2 深度学习

的历史趋势

11

1. Introduction

Part I: Applied Math

and Machine Learning Basics

2. Linear Algebra 3.

Probability and 

Information

Theory

4. Numerical

Computation

5. Machine Learning

Basics

Part II: Deep

Networks: Modern Practices

6.

Deep Feedforward 

Networks

7. Regularization 8. Optimization

9. CNNs 10. RNNs

11. Practical 

Methodology

12. Applications

Part III:

Deep Learning Research

13.

Linear Factor 

Models

14. Autoencoders 15. Representation

Learning

16. Structured

Probabilistic Models

17. Monte

Carlo 

Methods

18.

Partition 

Function 19.

Inference

20. Deep Generative

Models

图 1.6: 本书的高

层组织。从一

章到另一章

的箭头表示

前一章是理

解后一章的

必备内容。

1.2 深

度学习的历

史趋势

通过

历史背景了

解深度学习

是最简单的

方式。这里我

们仅指出深

度学习的几

个

关键趋势

，而不是提供

其详细的历

史：

12 第一章 引

言

•

深度学习

有着悠久而

丰富的历史

，但随着许多

不同哲学观

点的渐渐消

逝，与之

对应

的名称也渐

渐尘封。

• 随着

可用的训练

数据量不断

增加，深度学

习变得更加

有用。

• 随着时

间的推移，针

对深度学习

的计算机软

硬件基础设

施都有所改

善，深度学

习

模型的规模

也随之增长

。

•

随着时间的

推移，深度学

习已经解决

日益复杂的

应用，并且精

度不断提高

。

1.2.1 神经网络的

众多名称和

命运变迁

我

们期待这本

书的许多读

者都听说过

深度学习这

一激动人心

的新技术，并

对一

本书提

及一个新兴

领域的 ‘‘历史

’’ 而感到惊讶

。事实上，深度

学习的历史

可以追溯到

20 世纪

40 年代。深

度学习看似

是一个全新

的领域，只不

过因为在目

前流行的前

几

年它是相

对冷门的，同

时也因为它

被赋予了许

多不同的名

称（其中大部

分已经不再

使用），最近才

成为众所周

知的 “深度学

习’’。这个领域

已经更换了

很多名称，它

反映

了不同

的研究人员

和不同观点

的影响。

全面

地讲述深度

学习的历史

超出了本书

的范围。然而

，一些基本的

背景对理解

深

度学习是

有用的。一般

来说，目前为

止深度学习

已经经历了

三次发展浪

潮：20 世纪

40 年代

到 60 年代深度

学习的雏形

出现在

控制

论（cybernetics）中，20 世纪 80 年

代

到 90 年代深

度学习表现

为 联结主义

（connectionism），直到

2006 年，才真

正以深

度学

习之名复兴

。图 1.7

给出了定

量的展示。

我

们今天知道

的一些最早

的学习算法

，是旨在模拟

生物学习的

计算模型，即

大

脑怎样学

习或为什么

能学习的模

型。其结果是

深度学习以

人工神经网

络（artificial

neural

network, ANN）之名而淡

去。彼时，深度

学习模型被

认为是受生

物大脑（无

论

人类大脑或

其他动物的

大脑）所启发

而设计出来

的系统。尽管

有些机器学

习的神

经网

络有时被用

来理解大脑

功能

(Hinton and Shallice, 1991)，但它们

一般都没有

被

设计成生

物功能的真

实模型。深度

学习的神经

观点受两个

主要思想启

发。一个想法

是大脑作为

例子证明智

能行为是可

能的，因此，概

念上，建立智

能的直接途

径是逆

向大

脑背后的计

算原理，并复

制其功能。另

一种看法是

，理解大脑和

人类智能背

后

的原理也

非常有趣，因

此机器学习

模型除了解

决工程应用

的能力，如果

能让人类对

这些基本的

科学问题有

进一步的认

识也将会很

有用。

1.2

深度学

习的历史趋

势 13

1940 1950

1960 1970 1980 1990

2000

Year

0.000000

0.000050

0.000100

0.000150

0.000200

0.000250

cybernetics

(connectionism + neural

networks)

图 1.7: 根据

Google 图

书中短语 “控

制论’’、“联结主

义’’ 或

“神经网

络’’ 频率衡量

的人工神经

网

络研究的

历史浪潮（图

中展示了三

次浪潮的前

两次，第三次

最近才出现

）。第一次浪潮

开始于

20

世纪

40 年代到 20 世纪

60

年代的控制

论，随着生物

学习理论的

发展 (McCulloch and Pitts,

1943; Hebb, 1949) 和第一

个模型的实

现（如感知机

(Rosenblatt,

1958)），能实现单个

神经元的

训

练。第二次浪

潮开始于 1980-1995 年

间的联结主

义方法，可以

使用反向传

播

(Rumelhart et al.,

1986a)

训练具有

一两个隐藏

层的神经网

络。当前第三

次浪潮，也就

是深度学习

，大约始于 2006 年

(Hinton et

al., 2006a; Bengio et

al., 2007a; Ranzato et

al., 2007a)，并且现在在

2016 年以书的形

式出现。另外

两次浪潮类

似地出现在

书中的时间

比相应的科

学活动晚得

多。

现代术语

“深度学习’’

超

越了目前机

器学习模型

的神经科学

观点。它诉诸

于学

习多层

次组合这一

更普遍的原

理，这一原理

也可以应用

于那些并非

受神经科学

启发

的机器

学习框架。

现

代深度学习

的最早前身

是从神经科

学的角度出

发的简单线

性模型。这些

模型

被设计

为使用一组

n 个输入 x1, .

. . , xn

并将

它们与一个

输出 y 相关联

。这些模型希

望学习一组

权重 w1,

. . . ,

wn，并计算

它们的输出

f(x, w) = x1w1

+ · · ·

+ xnwn。如

图 1.7

所示，这

第一波神经

网络研究浪

潮被称为控

制论。

McCulloch-Pitts 神经元

(McCulloch and

Pitts, 1943) 是脑功能的

早期模型。该

线性模型通

过检验函数

f(x, w)

的正负来识

别两种不同

类别的输入

。显然，模型的

权重需要正

确设置后才

能使模型的

输出对应于

期望的类别

。这些权重可

以由操作人

员设定。在 20 世

纪 50

年代，感知

机 (Rosenblatt, 1956, 1958)

成为第一

个能根据

每

个类别的输

入样本来学

习权重的模

型。约在同一

时期，自适应

线性单元 (adaptive

linear

element, ADALINE) 简

单地返回函

数 f(x)

本身的值

来预测一个

实数 (Widrow

and Hoff,

1960)，并且它

还可以学习

从数据预测

这些数。

Frequency of Word

or Phrase

14 第一

章

引言

这些

简单的学习

算法大大影

响了机器学

习的现代景

象。用于调节

ADALINE 权

重的训练

算法是被称

为

随机梯度

下降（stochastic gradient descent）的一种

特例。稍

加改

进后的随机

梯度下降算

法仍然是当

今深度学习

的主要训练

算法。

基于感

知机和 ADALINE 中使

用的函数 f(x,

w) 的

模型被称为

线性模型（linear

model）。尽

管在许多情

况下，这些模

型以不同于

原始模型的

方式进行训

练，但仍是

目

前最广泛使

用的机器学

习模型。

线性

模型有很多

局限性。最著

名的是，它们

无法学习异

或（XOR）函数，即

f([0, 1], w)

= 1 和

f([1, 0],

w) = 1，但 f([1,

1], w) = 0

和 f([0, 0], w)

= 0。观察到

线

性模型这

个缺陷的批

评者对受生

物学启发的

学习普遍地

产生了抵触

(Minsky and

Papert, 1969)。这导致了神

经网络热潮

的第一次大

衰退。

现在，神

经科学被视

为深度学习

研究的一个

重要灵感来

源，但它已不

再是该领

域

的主要指导

。

如今神经科

学在深度学

习研究中的

作用被削弱

，主要原因是

我们根本没

有足够

的关

于大脑的信

息来作为指

导去使用它

。要获得对被

大脑实际使

用算法的深

刻理解，

我们

需要有能力

同时监测（至

少是）数千相

连神经元的

活动。我们不

能够做到这

一

点，所以我

们甚至连大

脑最简单、最

深入研究的

部分都还远

远没有理解

(Olshausen

and Field, 2005)。

神经科学已

经给了我们

依靠单一深

度学习算法

解决许多不

同任务的理

由。神经

学家

们发现，如果

将雪貂的大

脑重新连接

，使视觉信号

传送到听觉

区域，它们可

以学

会用大

脑的听觉处

理区域去 ‘‘看

” (Von

Melchner et al., 2000)。这暗示着大

多数哺乳

动

物的大脑能

够使用单一

的算法就可

以解决其大

脑可以解决

的大部分不

同任务。在

这

个假设之前

，机器学习研

究是比较分

散的，研究人

员在不同的

社群研究自

然语言

处理

、计算机视觉

、运动规划和

语音识别。如

今，这些应用

社群仍然是

独立的，但是

对于深度学

习研究团体

来说，同时研

究许多或甚

至所有这些

应用领域是

很常见的。

我

们能够从神

经科学得到

一些粗略的

指南。仅通过

计算单元之

间的相互作

用而

变得智

能的基本思

想是受大脑

启发的。新认

知机 (Fukushima, 1980) 受哺乳

动物视

觉系

统的结构启

发，引入了一

个处理图片

的强大模型

架构，它后来

成为了现代

卷积

网络的

基础 (LeCun et

al., 1998c)（我们将

会在第 9.10 节看

到）。目前大多

数神经网

络

是基于一个

称为 整流线

性单元（rectified linear unit）的神

经单元模型

。原始认

知机

(Fukushima, 1975) 受我们关于

大脑功能知

识的启发，引

入了一个更

复杂的版

本

。简化的现代

版通过吸收

来自不同观

点的思想而

形成，Nair

and Hinton (2010b)

1.2

深度学

习的历史趋

势 15

和 Glorot

et al. (2011a) 援引神

经科学作为

影响，Jarrett

et al. (2009a) 援引更

多面

向工程

的影响。虽然

神经科学是

灵感的重要

来源，但它不

需要被视为

刚性指导。我

们知道，真实

的神经元计

算着与现代

整流线性单

元非常不同

的函数，但更

接近真实

神

经网络的系

统并没有导

致机器学习

性能的提升

。此外，虽然神

经科学已经

成功地

启发

了一些神经

网络架构，但

我们对用于

神经科学的

生物学习还

没有足够多

的了解，

因此

也就不能为

训练这些架

构用的学习

算法提供太

多的借鉴。

媒

体报道经常

强调深度学

习与大脑的

相似性。的确

，深度学习研

究者比其他

机

器学习领

域（如核方法

或贝叶斯统

计）的研究者

更可能地引

用大脑作为

影响，但是

大

家不应该认

为深度学习

在尝试模拟

大脑。现代深

度学习从许

多领域获取

灵感，特

别是

应用数学的

基本内容如

线性代数、概

率论、信息论

和数值优化

。尽管一些深

度

学习的研

究人员引用

神经科学作

为灵感的重

要来源，然而

其他学者完

全不关心神

经

科学。

值得

注意的是，了

解大脑是如

何在算法层

面上工作的

尝试确实存

在且发展良

好。

这项尝试

主要被称为

‘‘计算神经科

学’’，并且是独

立于深度学

习的领域。研

究人员在

两

个领域之间

来回研究是

很常见的。深

度学习领域

主要关注如

何构建计算

机系统，

从而

成功解决需

要智能才能

解决的任务

，而计算神经

科学领域主

要关注构建

大脑如

何真

实工作的比

较精确的模

型。

在

20 世纪 80 年

代，神经网络

研究的第二

次浪潮在很

大程度上是

伴随一个被

称

为 联结主

义（connectionism）或并行分

布处理 ( parallel

distributed processing) 潮

流

而出现的

(Rumelhart et al., 1986d;

McClelland et al., 1995)。联

结主义是在

认知

科学的

背景下出现

的。认知科学

是理解思维

的跨学科途

径，即它融合

多个不同的

分

析层次。在

20 世纪 80

年代初

期，大多数认

知科学家研

究符号推理

模型。尽管这

很

流行，但符

号模型很难

解释大脑如

何真正使用

神经元实现

推理功能。联

结主义者开

始研究真正

基于神经系

统实现的认

知模型 (Touretzky and

Minton, 1985)，其中

很

多复苏的

想法可以追

溯到心理学

家 Donald

Hebb 在 20 世纪

40 年

代的工作 (Hebb,

1949)。

联

结主义的中

心思想是，当

网络将大量

简单的计算

单元连接在

一起时可以

实现

智能行

为。这种见解

同样适用于

生物神经系

统中的神经

元，因为它和

计算模型中

隐

藏单元起

着类似的作

用。

在上世纪

80

年代的联结

主义期间形

成的几个关

键概念在今

天的深度学

习中仍然

是

非常重要的

。

16 第一章

引言

其中一个概

念是 分布式

表示（distributed representation）(Hinton et

al., 1986)。

其思想

是：系统的每

一个输入都

应该由多个

特征表示，并

且每一个特

征都应该参

与

到多个可

能输入的表

示。例如，假设

我们有一个

能够识别红

色、绿色、或蓝

色的汽

车、卡

车和鸟类的

视觉系统，表

示这些输入

的其中一个

方法是将九

个可能的组

合：红

卡车，红

汽车，红鸟，绿

卡车等等使

用单独的神

经元或隐藏

单元激活。这

需要九个

不

同的神经元

，并且每个神

经必须独立

地学习颜色

和对象身份

的概念。改善

这种情

况的

方法之一是

使用分布式

表示，即用三

个神经元描

述颜色，三个

神经元描述

对象

身份。这

仅仅需要 6 个

神经元而不

是 9

个，并且描

述红色的神

经元能够从

汽车、卡

车和

鸟类的图像

中学习红色

，而不仅仅是

从一个特定

类别的图像

中学习。分布

式表

示的概

念是本书的

核心，我们将

在第十五章

中更加详细

地描述。

联结

主义潮流的

另一个重要

成就是反向

传播在训练

具有内部表

示的深度神

经网

络中的

成功使用以

及反向传播

算法的普及

(Rumelhart et al., 1986c;

LeCun, 1987)。

这个算法虽

然曾黯然失

色不再流行

，但截至写书

之时，它仍是

训练深度模

型的主导

方

法。

在 20 世纪 90

年

代，研究人员

在使用神经

网络进行序

列建模的方

面取得了重

要进展。Hochreiter (1991b) 和 Bengio

et al. (1994a) 指

出了对长序

列进行建模

的一

些根本

性数学难题

，这将在第 10.7 节

中描述。Hochreiter and

Schmidhuber (1997)

引入

长短期记忆

（long short-term

memory, LSTM）网络来解决

这些难题。如

今，

LSTM 在许多序

列建模任务

中广泛应用

，包括

Google 的许多

自然语言处

理任务。

神经

网络研究的

第二次浪潮

一直持续到

上世纪 90

年代

中期。基于神

经网络和其

他AI技术的创

业公司开始

寻求投资，其

做法野心勃

勃但不切实

际。当AI研究不

能实

现这些

不合理的期

望时，投资者

感到失望。同

时，机器学习

的其他领域

取得了进步

。

比如，核方法

(Boser et

al., 1992; Cortes and

Vapnik, 1995; Schölkopf et

al., 1999)

和图模型 (Jordan,

1998) 都

在很多重要

任务上实现

了很好的效

果。这两个因

素导致

了神

经网络热潮

的第二次衰

退，并一直持

续到 2007

年。

在此

期间，神经网

络继续在某

些任务上获

得令人印象

深刻的表现

(LeCun

et al.,

1998c; Bengio et al.,

2001a)。加拿大高级

研究所（CIFAR）通过

其神经计

算

和自适应感

知（NCAP）研究计划

帮助维持神

经网络研究

。该计划联合

了分别

由 Geoffrey

Hinton、Yoshua Bengio和

Yann LeCun 领导的多伦

多大学、蒙特

利尔大

学和

纽约大学的

机器学习研

究小组。这个

多学科的 CIFAR NCAP 研

究计划还囊

括

了神经科

学家、人类和

计算机视觉

专家。

1.2 深度学

习的历史趋

势 17

在那个时

候，人们普遍

认为深度网

络是难以训

练的。现在我

们知道，20 世纪

80

年代就存在

的算法能工

作得非常好

，但是直到在

2006 年前后都没

有体现出来

。这可

能仅仅

由于其计算

代价太高，而

以当时可用

的硬件难以

进行足够的

实验。

神经网

络研究的第

三次浪潮始

于 2006 年的突破

。Geoffrey

Hinton 表明名为深

度信念网络

的神经网络

可以使用一

种称为贪婪

逐层预训练

的策略来有

效地训练

(Hinton et

al., 2006a)，我

们将在第 15.1 节

中更详细地

描述。其他

CIFAR 附

属研究

小组

很快表明，同

样的策略可

以被用来训

练许多其他

类型的深度

网络 (Bengio

and

LeCun, 2007a; Ranzato

et al., 2007b)，并能系

统地帮助提

高在测试样

例上的泛化

能

力。神经网

络研究的这

一次浪潮普

及了

“深度学

习’’ 这一术语

的使用，强调

研究者

现在

有能力训练

以前不可能

训练的比较

深的神经网

络，并着力于

深度的理论

重要

性上

(Bengio and LeCun, 2007b;

Delalleau and Bengio, 2011;

Pascanu et al., 2014a;

Montufar et al., 2014)。此

时，深度神经

网络已经优

于与之竞争

的基于其他

机器学

习技

术以及手工

设计功能的

AI 系统。在写这

本书的时候

，神经网络的

第三次发展

浪

潮仍在继

续，尽管深度

学习的研究

重点在这一

段时间内发

生了巨大变

化。第三次浪

潮已开始着

眼于新的无

监督学习技

术和深度模

型在小数据

集的泛化能

力，但目前更

多的兴趣点

仍是比较传

统的监督学

习算法和深

度模型充分

利用大型标

注数据集的

能

力。

1.2.2 与日俱

增的数据量

人们可能想

问，既然人工

神经网络的

第一个实验

在 20 世纪

50 年代

就完成了，

但

为什么深度

学习直到最

近才被认为

是关键技术

。自 20

世纪 90 年代

以来，深度学

习就已经成

功用于商业

应用，但通常

被视为是一

种只有专家

才可以使用

的艺术而不

是一种技术

，这种观点一

直持续到最

近。确实，要从

一个深度学

习算法获得

良好的

性能

需要一些技

巧。幸运的是

，随着训练数

据的增加，所

需的技巧正

在减少。目前

在复杂的任

务达到人类

水平的学习

算法，与

20 世纪

80 年代努力解

决玩具问题

(toy

problem)

的学习算法

几乎是一样

的，尽管我们

使用这些算

法训练的模

型经历了变

革，

即简化了

极深架构的

训练。最重要

的新进展是

现在我们有

了这些算法

得以成功训

练

所需的资

源。图 1.8

展示了

基准数据集

的大小如何

随着时间的

推移而显著

增加。这

种趋

势是由社会

日益数字化

驱动的。由于

我们的活动

越来越多发

生在计算机

上，我

们做什

么也越来越

多地被记录

。由于我们的

计算机越来

越多地联网

在一起，这些

记

录变得更

容易集中管

理，并更容易

将它们整理

成适于机器

学习应用的

数据集。因为

18

第一章 引言

统计估计的

主要负担（观

察少量数据

以在新数据

上泛化）已经

减轻，‘‘大数据

’’ 时代

使机器

学习更加容

易。截至

2016 年，一

个粗略的经

验法则是，监

督深度学习

算法在

每类

给定约 5000

个标

注样本情况

下一般将达

到可以接受

的性能，当至

少有 1000 万

个标

注样本的数

据集用于训

练时，它将达

到或超过人

类表现。此外

，在更小的数

据

集上获得

成功是一个

重要的研究

领域，为此我

们应特别侧

重于如何通

过无监督或

半

监督学习

充分利用大

量的未标注

样本。

1900 1950

1985 2000 2015

Year

100

101

102

103

104

105

106

107

108

109

Iris

MNIST

Public SVHN

ImageNet

CIFAR-10

ImageNet10k

ILSVRC 2014

Sports-1M

Rotated T vs. C

T vs. G vs.

F

Criminals

Canadian Hansard

WMT

图 1.8: 与日

俱增的数据

量。20

世纪初，统

计学家使用

数百或数千

的手动制作

的度量来研

究数据集

(Garson, 1900; Gosset,

1908; Anderson, 1935; Fisher,

1936)。20 世

纪 50 年代到

80 年

代，受生物

启

发的机器学

习开拓者通

常使用小的

合成数据集

，如低分辨率

的字母位图

，设计为在低

计算成本下

表明神经网

络能够学习

特定功能 (Widrow

and Hoff, 1960; Rumelhart

et al., 1986b)。20 世

纪

80

年代和 90 年

代，机器学习

变得更加统

计，并开始利

用包含成千

上万个样本

的更大数据

集，如手写

扫

描数字的 MNIST 数

据集（如图 1.9

）所

示 (LeCun et al.,

1998c)。在 21 世纪初

的第一个十

年，

相同大小

更复杂的数

据集持续出

现，如

CIFAR-10 数据集

(Krizhevsky and Hinton,

2009) 。在这

十年结

束和下五年

，明显更大的

数据集（包含

数万到数千

万的样例）完

全改变了深

度学习的可

能

实现的事

。这些数据集

包括公共

Street View House Numbers

数

据集 (Netzer et al.,

2011)、各种

版

本的 ImageNet 数据集

(Deng

et al., 2009, 2010a;

Russakovsky et al., 2014a)

以及 Sports-1M

数据集

(Karpathy et

al., 2014)。在图顶部，我

们看到翻译

句子的数据

集通常远大

于其他数据

集，

如根据 Canadian

Hansard 制

作的 IBM 数据集

(Brown

et al., 1990) 和

WMT 2014 英法数据

集

(Schwenk,

2014) 。

Dataset size

(number examples)

1.2 深度学习

的历史趋势

19

图 1.9: MNIST 数据集的

输入样例。“NIST’’

代

表国家标准

和技术研究

所 (National Institute of

Standards and Technology)，是最初收

集这些数据

的机构。“M’’ 代表

‘‘修改的

(Modified)’’，为更

容易地与机

器学习算法

一起使用，数

据已经过预

处理。MNIST 数据集

包括手写数

字的扫描和

相关

标签（描

述每个图像

中包含 0-9

中哪

个数字）。这个

简单的分类

问题是深度

学习研究中

最简单和最

广泛使用的

测试之一。尽

管现代技术

很容易解决

这个问题，它

仍然很受欢

迎。Geoffrey Hinton 将

其描述

为

‘‘机器学习

的果蝇’’，这意

味着机器学

习研究人员

可以在受控

的实验室条

件下研究他

们的

算法，就

像生物学家

经常研究果

蝇一样。

1.2.3 与日

俱增的模型

规模

20 世纪 80 年

代，神经网络

只能取得相

对较小的成

功，而现在神

经网络非常

成

功的另一

个重要原因

是我们现在

拥有的计算

资源可以运

行更大的模

型。联结主义

的

主要见解

之一是，当动

物的许多神

经元一起工

作时会变得

聪明。单独神

经元或小集

合的神经元

不是特别有

用。

20 第一章

引

言

生物神经

元不是特别

稠密地连接

在一起。如图

1.10 所示，几十年

来，我们的机

器学习模型

中每个神经

元的连接数

量已经与哺

乳动物的大

脑在同一数

量级上。

1950

1985 2000 2015

Year

101

102

103

104

1

2

3

4

5

6

7

8

9

10

Fruit fly

Mouse

Cat

Human

图

1.10: 与

日俱增的每

神经元连接

数。最初，人工

神经网络中

神经元之间

的连接数受

限于硬件能

力。而现在，神

经元之间的

连接数大多

是出于设计

考虑。一些人

工神经网络

中每个神经

元的连接

数

与猫一样多

，并且对于其

他神经网络

来说，每个神

经元的连接

与较小哺乳

动物（如小鼠

）一

样多是非

常普遍的。甚

至人类大脑

每个神经元

的连接也没

有过高的数

量。生物神经

网络规模来

自Wikipedia

(2015)。

1. 自适应线

性单元 (Widrow

and Hoff, 1960)

2.

神经

认知机 (Fukushima, 1980)

3.

GPU-加速

卷积网络 (Chellapilla et al.,

2006)

4. 深

度玻尔兹曼

机 (Salakhutdinov

and Hinton, 2009a)

5.

无监督卷

积网络 (Jarrett et al.,

2009b)

6. GPU-加速

多层感知机

(Ciresan et

al., 2010)

7. 分布式自编

码器

(Le et al., 2012)

8. Multi-GPU 卷积网

络 (Krizhevsky

et al., 2012a)

9.

COTS HPC 无监督卷

积网络 (Coates

et al., 2013)

10.

GoogLeNet (Szegedy et al.,

2014a)

如图

1.11 所示，就神经

元的总数目

而言，直到最

近神经网络

都是惊人的

小。自

从隐藏

单元引入以

来，人工神经

网络的规模

大约每

2.4 年扩

大一倍。这种

增长是由

更

大内存、更快

的计算机和

更大的可用

数据集驱动

的。更大的网

络能够在更

复杂的

任务

中实现更高

的精度。这种

趋势看起来

将持续数十

年。除非有能

力迅速扩展

的新

技术，否

则至少要到

21 世纪 50 年代，人

工神经网络

将才能具备

与人脑相同

数量级

的神

经元。生物神

经元表示的

功能可能比

目前的人工

神经元所表

示的更复杂

，因此

Connections per neuron

1.2 深度学

习的历史趋

势 21

生物神经

网络可能比

图中描绘的

甚至要更大

。

1950 1985 2000 2015

2056

Year

10−2

10−1

100

101

102

103

104

105

106

107

108

109

1010

1011

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19 20

Sponge

Roundworm

Leech

Ant

Bee

Frog

Octopus

Human

图 1.11: 与日俱增

的神经网络

规模。自从引

入隐藏单元

，人工神经网

络的大小大

约每 2.4

年翻一

倍。生物神经

网络规模来

自 Wikipedia (2015)。

1.

感知机 (Rosenblatt, 1958, 1962)

2. 自

适应线性单

元 (Widrow and

Hoff, 1960)

3. 神经认知

机

(Fukushima, 1980)

4. 早期后向

传播网络

(Rumelhart et al., 1986b)

5. 用

于语音识别

的循环神经

网络 (Robinson and

Fallside, 1991)

6. 用于语

音识别的多

层感知机

(Bengio et al., 1991)

7. 均

匀场sigmoid信念网

络 (Saul et

al., 1996)

8. LeNet-5

(LeCun et al., 1998c)

9. 回声状态

网络 (Jaeger and

Haas, 2004)

10. 深度信

念网络

(Hinton et al., 2006a)

11. GPU-加速

卷积网络 (Chellapilla et

al., 2006)

12. 深

度玻尔兹曼

机

(Salakhutdinov and Hinton, 2009a)

13. GPU-加速深度

信念网络 (Raina et

al., 2009a)

14. 无

监督卷积网

络

(Jarrett et al., 2009b)

15. GPU-加速多层

感知机 (Ciresan et

al., 2010)

16. OMP-1

网络

(Coates and Ng, 2011)

17. 分布式自编

码器 (Le et

al., 2012)

18. Multi-GPU卷积网

络

(Krizhevsky et al., 2012a)

19. COTS HPC 无监督卷

积网络

(Coates et al., 2013)

20. GoogLeNet (Szegedy et

al., 2014a)

现在

看来，其神经

元比一个水

蛭还少的神

经网络不能

解决复杂的

人工智能问

题

是不足为

奇的。即使现

在的网络，从

计算系统角

度来看它可

能相当大的

，但实际上

它

比相对原始

的脊椎动物

如青蛙的神

经系统还要

小。

Number of neurons

(logarithmic scale)

22 第一章

引

言

由于更快

的 CPU、通用 GPU

的出

现（在第12.1.2 节中

讨论）、更快的

网络连接

和

更好的分布

式计算的软

件基础设施

，模型规模随

着时间的推

移不断增加

是深度学

习

历史中最重

要的趋势之

一。人们普遍

预计这种趋

势将很好地

持续到未来

。

1.2.4 与日俱增的

精度、复杂度

和对现实世

界的冲击

20 世

纪

80 年代以来

，深度学习提

供精确识别

和预测的能

力一直在提

高。而且，

深度

学习持续成

功地被应用

于越来越广

泛的实际问

题中。

最早的

深度模型被

用来识别裁

剪紧凑且非

常小的图像

中的单个对

象

(Rumelhart

et al., 1986d)。此后，神经

网络可以处

理的图像尺

寸逐渐增加

。现代对象识

别网络能

处

理丰富的高

分辨率照片

，并且不需要

在被识别的

对象附近进

行裁剪 (Krizhevsky

et al.,

2012b)。类似

地，最早的网

络只能识别

两种对象（或

在某些情况

下，单类对象

的存在与否

），而这些现代

网络通常能

够识别至少

1000个不同类别

的对象。对象

识别

中最大

的比赛是每

年举行的 ImageNet 大

型视觉识别

挑战（ILSVRC）。深度学

习迅

速崛起

的激动人心

的一幕是卷

积网络第一

次大幅赢得

这一挑战，它

将最高水准

的前

5 错误率

从 26.1%

降到 15.3% (Krizhevsky et

al., 2012b)，这意

味着该卷积

网络针对

每

个图像的可

能类别生成

一个顺序列

表，除了 15.3%

的测

试样本，其他

测试样本的

正确类标都

出现在此列

表中的前 5 项

里。此后，深度

卷积网络连

续地赢得这

些比赛，

截至

写本书时，深

度学习的最

新结果将这

个比赛中的

前

5 错误率降

到了 3.6%，如

图

1.12 所

示。

深度学习

也对语音识

别产生了巨

大影响。语音

识别在 20

世纪

90 年代得到提

高后，直到约

2000 年都停滞不

前。深度学习

的引入 (Dahl

et al., 2010; Deng

et al.,

2010b; Seide

et al., 2011; Hinton

et al., 2012a) 使得

语音识别错

误率陡然下

降，有些

错误

率甚至降低

了一半。我们

将在第 12.3 节更

详细地探讨

这个历史。

深

度网络在行

人检测和图

像分割中也

取得了引人

注目的成功

(Sermanet

et al.,

2013; Farabet

et al., 2013; Couprie

et al., 2013)，并且在交通

标志分类上

取得了超越

人类的表现

(Ciresan et

al., 2012)。

在深度网络

的规模和精

度有所提高

的同时，它们

可以解决的

任务也日益

复杂。

Goodfellow

et al. (2014d) 表明，神

经网络可以

学习输出描

述图像的整

个字符序列

，

而不是仅仅

识别单个对

象。此前，人们

普遍认为，这

种学习需要

对序列中的

单个元

素进

行标注 (Gulcehre and

Bengio, 2013)。循环

神经网络，如

之前提到的

LSTM 序

列模型，现

在用于对序

列和其他序

列之间的关

系进行建模

，而不是仅仅

固定输入之

1.2

深度学习的

历史趋势 23

2010 2011

2012 2013 2014 2015

Year

0.00

0.05

0.10

0.15

0.20

0.25

0.30

图

1.12: 日益降低的

错误率。由于

深度网络达

到了在 ImageNet 大规

模视觉识别

挑战中竞争

所必

需的规

模，它们每年

都能赢得胜

利，并且产生

越来越低的

错误率。数据

来源于 Russakovsky et al.

(2014b) 和 He et

al. (2015)。

间

的关系。这种

序列到序列

的学习似乎

引领着另一

个应用的颠

覆性发展，即

机器翻

译

(Sutskever et al., 2014;

Bahdanau et al., 2015)。

这

种复杂性日

益增加的趋

势已将其推

向逻辑结论

，即神经图灵

机 (Graves et al.,

2014) 的引入，它

能学习读取

存储单元和

向存储单元

写入任意内

容。这样的神

经网

络可以

从期望行为

的样本中学

习简单的程

序。例如，从杂

乱和排好序

的样本中学

习

对一系列

数进行排序

。这种自我编

程技术正处

于起步阶段

，但原则上未

来可以适用

于几乎所有

的任务。

深度

学习的另一

个最大的成

就是其在 强

化学习（reinforcement learning）领域

的扩展。在强

化学习中，一

个自主的智

能体必须在

没有人类操

作者指导的

情况下，通

过

试错来学习

执行任务。DeepMind

表

明，基于深度

学习的强化

学习系统能

够学会玩

Atari 视

频游戏，并在

多种任务中

可与人类匹

敌 (Mnih

et al., 2015)。深度学习

也显

著改善

了机器人强

化学习的性

能

(Finn et al., 2015)。

许多深度

学习应用都

是高利润的

。现在深度学

习被许多顶

级的技术公

司使用，包

括

Google、Microsoft、Facebook、IBM、Baidu、Apple、Adobe、Netflix、NVIDIA

和 NEC

等。

深度学

习的进步也

严重依赖于

软件基础架

构的进展。软

件库如 Theano (Bergstra

et al., 2010a; Bastien

et al., 2012a)、PyLearn2 (Goodfellow

et al., 2013e)、Torch (Col￾lobert

et al., 2011b)、DistBelief (Dean

et al., 2012)、Caffe (Jia,

2013)、MXNet (Chen

ILSVRC classification

error rate

24 第一

章

引言

et al., 2015)

和 TensorFlow (Abadi et

al., 2015) 都

能支持重要

的研究项目

或商业产

品

。

深度学习也

为其他科学

做出了贡献

。用于对象识

别的现代卷

积网络为神

经科

学家们

提供了可以

研究的视觉

处理模型 (DiCarlo, 2013)。深

度学习也为

处理海量

数

据以及在科

学领域作出

有效的预测

提供了非常

有用的工具

。它已成功地

用于预

测分

子如何相互

作用从而帮

助制药公司

设计新的药

物 (Dahl et

al., 2014)，搜索亚

原

子粒子 (Baldi

et al., 2014)，以及

自动解析用

于构建人脑

三维图的显

微镜图像

(Knowles-Barley

et al., 2014) 等

。我们期待深

度学习未来

能够出现在

越来越多的

科

学领域中

。

总之，深度学

习是机器学

习的一种方

法。在过去几

十年的发展

中，它大量借

鉴

了我们关

于人脑、统计

学和应用数

学的知识。近

年来，得益于

更强大的计

算机、更

大的

数据集和能

够训练更深

网络的技术

，深度学习的

普及性和实

用性都有了

极大的

发展

。未来几年充

满了进一步

提高深度学

习并将它带

到新领域的

挑战和机遇

。

第一部分

应

用数学与机

器学习基础

25

26

本书这一部

分将介绍理

解深度学习

所需的基本

数学概念。我

们从应用数

学的一

般概

念开始，这能

使我们定义

许多变量的

函数，找到这

些函数的最

高和最低点

，并

量化信念

度。

接着，我们

描述机器学

习的基本目

标，并描述如

何实现这些

目标。我们需

要指

定代表

某些信念的

模型、设计衡

量这些信念

与现实对应

程度的代价

函数以及使

用训

练算法

最小化这个

代价函数。

这

个基本框架

是广泛多样

的机器学习

算法的基础

，其中也包括

非深度的机

器学

习方法

。在本书的后

续部分，我们

将在这个框

架下开发深

度学习算法

。

第二章 线性

代数

线性代

数作为数学

的一个分支

，广泛应用于

科学和工程

中。然而，因为

线性代数

主

要是面向连

续数学，而非

离散数学，所

以很多计算

机科学家很

少接触它。掌

握好线

性代

数对于理解

和从事机器

学习算法相

关工作是很

有必要的，尤

其对于深度

学习算

法而

言。因此，在开

始介绍深度

学习之前，我

们集中探讨

一些必备的

线性代数知

识。

如果你已

经很熟悉线

性代数，那么

可以轻松地

跳过本章。如

果你已经了

解这些概

念

，但是需要一

份索引表来

回顾一些重

要公式，那么

我们推荐

The Matrix Cookbook

(Petersen

and Pedersen, 2006)。如

果你没有接

触过线性代

数，那么本章

将告诉你本

书所需的线

性代数知识

，不过我们仍

然非常建议

你参考其他

专门讲解线

性代数的文

献，例如 Shilov

(1977)。最后

，本章略去了

很多重要但

是对于理解

深度学习非

必需

的线性

代数知识。

2.1 标

量、向量、矩阵

和张量

学习

线性代数，会

涉及以下几

类数学概念

：

• 标量（scalar）：一个标

量就是一个

单独的数，它

不同于线性

代数中研究

的其他

大部

分对象（通常

是多个数的

数组）。我们用

斜体表示标

量。标量通常

被赋予小

写

的变量名称

。当我们介绍

标量时，会明

确它们是哪

种类型的数

。比如，在定

义

实数标量时

，我们可能会

说 ‘‘令 s

∈ R 表示一

条线的斜率

’’；在定义自然

数标

量时，我

们可能会说

‘‘令

n ∈ N 表示元素

的数目’’。

• 向量

（vector）：一个向量是

一列数。这些

数是有序排

列的。通过次

序中的索

引

，我们可以确

定每个单独

的数。通常我

们赋予向量

粗体的小写

变量名称，比

如 x。向量中的

元素可以通

过带脚标的

斜体表示。向

量

x 的第一个

元素是 x1，

27

28 第二

章 线性代数

第二个元素

是 x2，等等。我们

也会注明存

储在向量中

的元素是什

么类型的。如

果每个元素

都属于

R，并且

该向量有 n 个

元素，那么该

向量属于实

数集 R

的

n 次笛

卡尔乘积构

成的集合，记

为 R

n。当需要明

确表示向量

中的元素时

，我们

会将元

素排列成一

个方括号包

围的纵列：

x =















x

x

1

2

x

.

.

.

n















.

(2.1)

我

们可以把向

量看作空间

中的点，每个

元素是不同

坐标轴上的

坐标。

有时我

们需要索引

向量中的一

些元素。在这

种情况下，我

们定义一个

包含这些

元

素索引的集

合，然后将该

集合写在脚

标处。比如，指

定

x1，x3 和 x6，我们定

义集合 S

= {1, 3, 6}，然后

写作

xS。我们用

符号－表示集

合的补集中

的索引。

比如

x−1 表示 x

中除 x1 外

的所有元素

，x−S 表示

x 中除 x1，x3，x6 外

所有元

素构

成的向量。

• 矩

阵（matrix）：矩阵是一

个二维数组

，其中的每一

个元素被两

个索引（而非

一个）所确定

。我们通常会

赋予矩阵粗

体的大写变

量名称，比如

A。如果一个

实

数矩阵高度

为

m，宽度为 n，那

么我们说 A ∈

R

m×n。我

们在表示矩

阵中的

元素

时，通常以不

加粗的斜体

形式使用其

名称，索引用

逗号间隔。比

如，A1,1

表示

A 左上

的元素，Am,n 表示

A 右下的元素

。我们通过用

“:’’

表示水平坐

标，以表示垂

直坐标 i 中的

所有元素。比

如，Ai,: 表示

A 中垂

直坐标 i 上的

一

横排元素

。这也被称为

A 的第 i 行（row）。同样

地，A:,i

表示 A 的第

i 列

（column）。当我们需

要明确表示

矩阵中的元

素时，我们将

它们写在用

方括号括

起

来的数组中

：

[

A1,1

A1,2

A2,1 A2,2

]

. (2.2)

有时我们需

要矩阵值表

达式的索引

，而不是单个

元素。在这种

情况下，我们

在

表达式后

面接下标，但

不必将矩阵

的变量名称

小写化。比如

，f(A)i,j

表示函数

f 作

用在 A

上输出

的矩阵的第

i 行第 j 列元素

。

• 张量（tensor）：在某些

情况下，我们

会讨论坐标

超过两维的

数组。一般地

，一

个数组中

的元素分布

在若干维坐

标的规则网

格中，我们称

之为张量。我

们使用

字体

A

来表示张量

“A’’。张量 A 中坐标

为 (i,

j, k) 的元素记

作 Ai,j,k。

2.2 矩阵和向

量相乘 29

转置

（transpose）是矩阵的重

要操作之一

。矩阵的转置

是以对角线

为轴的镜像

，

这条从左上

角到右下角

的对角线被

称为 主对角

线（main diagonal）。图2.1 显示了

这

个操作。我

们将矩阵 A 的

转置表示为

A

⊤，定义如下

(A

⊤

)i,j =

Aj,i. (2.3)

向

量可以看作

只有一列的

矩阵。对应地

，向量的转置

可以看作是

只有一行的

矩

阵。有时，我

们通过将向

量元素作为

行矩阵写在

文本行中，然

后使用转置

操作将其

变

为标准的列

向量，来定义

一个向量，比

如 x = [x1,

x2, x3]

⊤.

标量可以

看作是只有

一个元素的

矩阵。因此，标

量的转置等

于它本身，a

= a

⊤。

A

=

2

4

A1,1

A1,2

A2,1 A2,2

A3,1

A3,2

3

5 )

A> =

 A1,1

A2,1 A3,1

A1,2 A2,2

A3,2

&

图

2.1: 矩阵的转置

可以看成以

主对角线为

轴的一个镜

像。

只要矩阵

的形状一样

，我们可以把

两个矩阵相

加。两个矩阵

相加是指对

应位置

的元

素相加，比如

C = A

+ B，其中 Ci,j =

Ai,j + Bi,j。

标量和

矩阵相乘，或

是和矩阵相

加时，我们只

需将其与矩

阵的每个元

素相乘或

相

加，比如 D = a

· B + c，其中

Di,j

= a · Bi,j

+ c。

在深度学习

中，我们也使

用一些不那

么常规的符

号。我们允许

矩阵和向量

相

加，产生另

一个矩阵：C

= A + b，其

中

Ci,j = Ai,j +

bj。换言之，向

量 b 和矩阵

A

的

每一行相加

。这个简写方

法使我们无

需在加法操

作前定义一

个将向量 b 复

制

到每一行

而生成的矩

阵。这种隐式

地复制向量

b

到很多位置

的方式，被称

为 广播

（broadcasting）。

2.2

矩阵

和向量相乘

矩阵乘法是

矩阵运算中

最重要的操

作之一。两个

矩阵 A 和 B

的 矩

阵乘积

（matrix product）是第

三个矩阵

C。为

了使乘法定

义良好，矩阵

A 的列数必须

和矩

阵 B

的行

数相等。如果

矩阵 A 的形状

是 m

× n，矩阵 B 的形

状是

n × p，那么矩

阵

30

第二章 线

性代数

C 的形

状是

m × p。我们可

以通过将两

个或多个矩

阵并列放置

以书写矩阵

乘法，例如

C

= AB. (2.4)

具

体地，该乘法

操作定义为

Ci,j

=

∑

k

Ai,kBk,j

. (2.5)

需要注意的

是，两个矩阵

的标准乘积

不是指两个

矩阵中对应

元素的乘积

。不过，

那样的

矩阵操作确

实是存在的

，被称为

元素

对应乘积（element-wise product）或

者 Hadamard 乘积（Hadamard

product），记为

A ⊙ B。

两个相同维

数的向量

x 和

y 的 点积（dot

product）可看

作是矩阵乘

积 x

⊤y。我

们可以

把矩阵乘积

C

= AB 中计算 Ci,j

的步

骤看作是 A 的

第 i

行和 B 的第

j 列之

间的点

积。

矩阵乘积

运算有许多

有用的性质

，从而使矩阵

的数学分析

更加方便。比

如，矩

阵乘积

服从分配律

：

A(B

+ C) = AB

+ AC. (2.6)

矩阵乘积也

服从结合律

：

A(BC) = (AB)C. (2.7)

不同于标量

乘积，矩阵乘

积并不满足

交换律（AB = BA 的情

况并非总是

满足）。

然而，两

个向量的 点

积（dot product）满足交换

律：

x

⊤y = y

⊤x.

(2.8)

矩阵乘积

的转置有着

简单的形式

：

(AB)

⊤

= B

⊤A

⊤

. (2.9)

利用两个向

量点积的结

果是标量，标

量转置是自

身的事实，我

们可以证明

式 (2.8)

：

x

⊤y =

(

x

⊤y

)⊤

= y

⊤x. (2.10)

由于本书

的重点不是

线性代数，我

们并不试图

展示矩阵乘

积的所有重

要性质，

但读

者应该知道

矩阵乘积还

有很多有用

的性质。

2.3 单位

矩阵和逆矩

阵

31

现在我们

已经知道了

足够多的线

性代数符号

，可以表达下

列线性方程

组：

Ax =

b (2.11)

其中 A

∈ R

m×n 是一

个已知矩阵

，b

∈ R

m 是一个已知

向量，x

∈ R

n 是一个

我们要

求解

的未知向量

。向量 x 的每一

个元素 xi

都是

未知的。矩阵

A 的每一行和

b 中对

应的元

素构成一个

约束。我们可

以把式

(2.11) 重写

为

A1,:x =

b1 (2.12)

A2,:x =

b2 (2.13)

· ·

· (2.14)

Am,:x =

bm (2.15)

或者，更明

确地，写作

A1,1x1

+ A1,2x2 + ·

· · A1,nxn =

b1 (2.16)

A2,1x1 +

A2,2x2 + · ·

· A2,nxn = b2

(2.17)

· · ·

(2.18)

Am,1x1 + Am,2x2

+ · · ·

Am,nxn = bm. (2.19)

矩

阵向量乘积

符号为这种

形式的方程

提供了更紧

凑的表示。

2.3 单

位矩阵和逆

矩阵

线性代

数提供了被

称为

矩阵逆

（matrix inversion）的强大工具

。对于大多数

矩

阵 A，我们都

能通过矩阵

逆解析地求

解式

(2.11) 。

为了描

述矩阵逆，我

们首先需要

定义 单位矩

阵（identity

matrix）的概念。任

意

向量和单

位矩阵相乘

，都不会改变

。我们将保持

n 维向量不变

的单位矩阵

记作 In。

形式上

，In ∈ R

n×n，

∀x ∈ R

n

, Inx = x.

(2.20)

单位矩阵的

结构很简单

：所有沿主对

角线的元素

都是 1，而所有

其他位置的

元素都是

0。如

图

2.2 所示。

32 第二

章

线性代数









1 0 0

0

1 0

0 0

1









图 2.2: 单位矩阵

的一个样例

：这是

I3。

矩阵 A 的

矩阵逆（matrix

inversion）记作

A

−1，其定义的矩

阵满足如下

条件

A

−1A

= In. (2.21)

现在我

们可以通过

以下步骤求

解式

(2.11) ：

Ax =

b (2.22)

A

−1Ax

= A

−1

b

(2.23)

Inx = A

−1

b (2.24)

x

= A

−1

b.

(2.25)

当然，这

取决于我们

能否找到一

个逆矩阵 A

−1。在

接下来的章

节中，我们会

讨

论逆矩阵

A

−1 存在的条件

。

当逆矩阵

A

−1 存

在时，有几种

不同的算法

都能找到它

的闭解形式

。理论上，相

同

的逆矩阵可

用于多次求

解不同向量

b

的方程。然而

，逆矩阵 A

−1 主要

是作为理论

工具使用的

，并不会在大

多数软件应

用程序中实

际使用。这是

因为逆矩阵

A

−1 在数

字计算

机上只能表

现出有限的

精度，有效使

用向量 b

的算

法通常可以

得到更精确

的

x。

2.4 线性相关

和生成子空

间

如果逆矩

阵 A

−1 存在，那么

式

(2.11) 肯定对于

每一个向量

b 恰好存在一

个解。

但是，对

于方程组而

言，对于向量

b

的某些值，有

可能不存在

解，或者存在

无限多

个解

。存在多于一

个解但是少

于无限多个

解的情况是

不可能发生

的；因为如果

x 和

y

都是某方

程组的解，则

z = αx +

(1 − α)y (2.26)

2.4 线性相关和

生成子空间

33

（其中 α

取任意

实数）也是该

方程组的解

。

为了分析方

程有多少个

解，我们可以

将 A 的列向量

看作从

原点

（origin）（元素

都是零

的向量）出发

的不同方向

，确定有多少

种方法可以

到达向量 b。在

这个观点

下

，向量

x 中的每

个元素表示

我们应该沿

着这些方向

走多远，即 xi 表

示我们需要

沿

着第 i 个向

量的方向走

多远：

Ax

=

∑

i

xiA:,i.

(2.27)

一般而

言，这种操作

被称为 线性

组合（linear combination）。形式上

，一组向量的

线

性组合，是

指每个向量

乘以对应标

量系数之后

的和，即：

∑

i

civ

(i)

. (2.28)

一组

向量的

生成

子空间（span）是原

始向量线性

组合后所能

抵达的点的

集合。

确定 Ax =

b 是

否有解相当

于确定向量

b 是否在 A

列向

量的生成子

空间中。这

个

特殊的生成

子空间被称

为 A 的

列空间

（column space）或者 A 的

值域

（range）。

为了使方程

Ax = b

对于任意向

量 b ∈ R

m 都存在解

，我们要求 A 的

列空间构

成

整个 R

m。如果 R

m 中

的某个点不

在 A 的列空间

中，那么该点

对应的

b 会使

得

该方程没

有解。矩阵 A

的

列空间是整

个 R

m 的要求，意

味着

A 至少有

m 列，即

n

≥ m。否则，A 列

空间的维数

会小于 m。例如

，假设

A 是一个

3 × 2

的矩阵。目

标

b 是 3

维的，但是

x 只有 2 维。所以

无论如何修

改

x 的值，也只

能描绘出 R

3

空

间中的二维

平面。当且仅

当向量 b 在该

二维平面中

时，该方程有

解。

不等式

n ≥ m 仅

是方程对每

一点都有解

的必要条件

。这不是一个

充分条件，因

为有些列向

量可能是冗

余的。假设有

一个

R

2×2 中的矩

阵，它的两个

列向量是相

同

的。那么它

的列空间和

它的一个列

向量作为矩

阵的列空间

是一样的。换

言之，虽然

该

矩阵有 2 列，但

是它的列空

间仍然只是

一条线，不能

涵盖整个 R

2 空

间。

正式地说

，这种冗余被

称为 线性相

关（linear

dependence）。如果一组

向量中

的任

意一个向量

都不能表示

成其他向量

的线性组合

，那么这组向

量称为 线性

无关

（linearly

independent）。如果某

个向量是一

组向量中某

些向量的线

性组合，那么

我

们将这个

向量加入这

组向量后不

会增加这组

向量的生成

子空间。这意

味着，如果一

个矩阵的列

空间涵盖整

个 R

m，那么该矩

阵必须包含

至少一组

m 个

线性无关的

向量。

这是式

(2.11) 对于每一个

向量

b 的取值

都有解的充

分必要条件

。值得注意的

是，这

个条件

是说该向量

集恰好有 m

个

线性无关的

列向量，而不

是至少 m 个。不

存在一

34

第二

章 线性代数

个 m 维向量的

集合具有多

于

m 个彼此线

性不相关的

列向量，但是

一个有多于

m 个

列向量的

矩阵有可能

拥有不止一

个大小为

m 的

线性无关向

量集。

要想使

矩阵可逆，我

们还需要保

证式 (2.11)

对于每

一个 b 值至多

有一个解。为

此，我们需要

确保该矩阵

至多有 m

个列

向量。否则，该

方程会有不

止一个解。

综

上所述，这意

味着该矩阵

必须是一个

方阵（square），即 m =

n，并且

所有列

向量

都是线性无

关的。一个列

向量线性相

关的方阵被

称为 奇异的

（singular）。

如果矩阵

A 不

是一个方阵

或者是一个

奇异的方阵

，该方程仍然

可能有解。但

是

我们不能

使用矩阵逆

去求解。

目前

为止，我们已

经讨论了逆

矩阵左乘。我

们也可以定

义逆矩阵右

乘：

AA−1 = I. (2.29)

对于方阵

而言，它的左

逆和右逆是

相等的。

2.5 范数

有时我们需

要衡量一个

向量的大小

。在机器学习

中，我们经常

使用被称为

范数

（norm）的函数

衡量向量大

小。形式上，L

p 范

数定义如下

∥x∥p =

(∑

i

|xi

|

p

)1

p

(2.30)

其中

p ∈ R，p ≥

1。

范数（包

括 L

p

范数）是将

向量映射到

非负值的函

数。直观上来

说，向量 x 的

范

数衡量从原

点到点

x 的距

离。更严格地

说，范数是满

足下列性质

的任意函数

：

• f(x)

= 0 ⇒ x

= 0

• f(x

+ y) ≤ f(x)

+ f(y) （ 三角不等式

（triangle

inequality））

• ∀α ∈

R, f(αx) = |α|f(x)

当 p = 2

时，L

2 范数被

称为 欧几里

得范数（Euclidean

norm）。它表

示从原点

出

发到向量 x 确

定的点的欧

几里得距离

。L

2 范数在机器

学习中出现

地十分频繁

，经

2.5 范数

35

常简

化表示为 ∥x∥，略

去了下标 2。平

方

L

2 范数也经

常用来衡量

向量的大小

，可以

简单地

通过点积

x

⊤x 计

算。

平方

L

2 范数

在数学和计

算上都比 L

2 范

数本身更方

便。例如，平方

L

2 范数对

x 中每

个元素的导

数只取决于

对应的元素

，而 L

2

范数对每

个元素的导

数却和整个

向

量相关。但

是在很多情

况下，平方 L

2

范

数也可能不

受欢迎，因为

它在原点附

近增长

得十

分缓慢。在某

些机器学习

应用中，区分

恰好是零的

元素和非零

但值很小的

元素

是很重

要的。在这些

情况下，我们

转而使用在

各个位置斜

率相同，同时

保持简单的

数学形式的

函数：L

1

范数。L

1 范

数可以简化

如下：

∥x∥1

=

∑

i

|xi

|. (2.31)

当机器

学习问题中

零和非零元

素之间的差

异非常重要

时，通常会使

用 L

1 范数。每当

x 中某个元素

从 0

增加 ϵ，对应

的 L

1

范数也会

增加 ϵ。

有时候

我们会统计

向量中非零

元素的个数

来衡量向量

的大小。有些

作者将这种

函数称为 “L

0 范

数’’，但是这个

术语在数学

意义上是不

对的。向量的

非零元素的

数目

不是范

数，因为对向

量缩放 α

倍不

会改变该向

量非零元素

的数目。因此

，L

1 范数经

常作

为表示非零

元素数目的

替代函数。

另

外一个经常

在机器学习

中出现的范

数是 L∞ 范数，也

被称为 最大

范数（max

norm）。这个范

数表示向量

中具有最大

幅值的元素

的绝对值：

∥x∥∞ = max

i

|xi

|. (2.32)

有

时候我们可

能也希望衡

量矩阵的大

小。在深度学

习中，最常见

的做法是使

用 Frobenius 范数（Frobenius norm），

∥A∥F =

√∑

i,j

A2

i,j , (2.33)

其类

似于向量的

L

2 范数。

两个向

量的

点积（dot product）可

以用范数来

表示。具体地

，

x

⊤y

= ∥x∥2

∥y∥2

cos

θ (2.34)

其中 θ

表示 x 和

y 之间的夹角

。

36 第二章 线性

代数

2.6

特殊类

型的矩阵和

向量

有些特

殊类型的矩

阵和向量是

特别有用的

。

对角矩阵（diagonal matrix）只

在主对角线

上含有非零

元素，其他位

置都是零。

形

式上，矩阵 D 是

对角矩阵，当

且仅当对于

所有的 i

= j，Di,j = 0。我们

已经看到

过

一个对角矩

阵：单位矩阵

，对角元素全

部是 1。我们用

diag(v) 表示一个对

角元素

由向

量

v 中元素给

定的对角方

阵。对角矩阵

受到关注的

部分原因是

对角矩阵的

乘法

计算很

高效。计算乘

法 diag(v)x，我们只需

要将

x 中的每

个元素 xi 放大

vi

倍。换

言之，diag(v)x = v

⊙ x。计

算对角方阵

的逆矩阵也

很高效。对角

方阵的逆矩

阵存在，

当且

仅当对角元

素都是非零

值，在这种情

况下，diag(v)

−1

= diag([1/v1, . .

. , 1/vn]

⊤)。

在很多

情况下，我们

可以根据任

意矩阵导出

一些通用的

机器学习算

法；但通过将

一

些矩阵限

制为对角矩

阵，我们可以

得到计算代

价较低的（并

且简明扼要

的）算法。

不是

所有的对角

矩阵都是方

阵。长方形的

矩阵也有可

能是对角矩

阵。非方阵的

对角矩阵没

有逆矩阵，但

我们仍然可

以高效地计

算它们的乘

法。对于一个

长方形对

角

矩阵

D 而言，乘

法 Dx 会涉及到

x

中每个元素

的缩放，如果

D 是瘦长型矩

阵，

那么在缩

放后的末尾

添加一些零

；如果 D

是胖宽

型矩阵，那么

在缩放后去

掉最后一

些

元素。

对称（symmetric）矩

阵是转置和

自己相等的

矩阵：

A

= A

⊤

.

(2.35)

当某些

不依赖参数

顺序的双参

数函数生成

元素时，对称

矩阵经常会

出现。例如，如

果 A 是一个距

离度量矩阵

，Ai,j

表示点 i 到点

j 的距离，那么

Ai,j

= Aj,i，因为距

离函

数是对称的

。

单位向量（unit

vector）是

具有 单位范

数（unit norm）的向量：

∥x∥2

= 1. (2.36)

如

果

x

⊤y = 0，那么向量

x

和向量 y 互相

正交（orthogonal）。如果两

个向量都

有

非零范数，那

么这两个向

量之间的夹

角是

90 度。在 R

n

中

，至多有 n 个范

数非

零向量

互相正交。如

果这些向量

不仅互相正

交，并且范数

都为

1，那么我

们称它们

是

标准正交（orthonormal）。

2.7 特

征分解

37

正交

矩阵（orthogonal matrix）是指行

向量和列向

量是分别标

准正交的方

阵：

A

⊤A = AA⊤ =

I. (2.37)

这意味着

A

−1

= A

⊤

,

(2.38)

所以正交矩

阵受到关注

是因为求逆

计算代价小

。我们需要注

意正交矩阵

的定义。违

反

直觉的是，正

交矩阵的行

向量不仅是

正交的，还是

标准正交的

。对于行向量

或列

向量互

相正交但不

是标准正交

的矩阵，没有

对应的专有

术语。

2.7 特征分

解

许多数学

对象可以通

过将它们分

解成多个组

成部分或者

找到它们的

一些属性而

更好地理解

，这些属性是

通用的，而不

是由我们选

择表示它们

的方式产生

的。

例如，整数

可以分解为

质因数。我们

可以用十进

制或二进制

等不同方式

表示整

数 12，但

是 12 =

2 × 2 ×

3 永远是对

的。从这个表

示中我们可

以获得一些

有用的信

息

，比如 12

不能被

5 整除，或者 12 的

倍数可以被

3

整除。

正如我

们可以通过

分解质因数

来发现整数

的一些内在

性质，我们也

可以通过分

解矩阵来发

现矩阵表示

成数组元素

时不明显的

函数性质。

特

征分解（eigendecomposition）是使

用最广的矩

阵分解之一

，即我们将矩

阵分

解成一

组特征向量

和特征值。

方

阵 A 的 特征向

量（eigenvector）是指与

A 相

乘后相当于

对该向量进

行缩放

的非

零向量 v：

Av = λv. (2.39)

标量

λ 被称为这个

特征向量对

应的 特征值

（eigenvalue）。（类似地，我们

也可以

定义

左特征向量

（left

eigenvector）v

⊤A = λv

⊤，但是通常我

们更关注 右

特征向量

（right eigenvector））。

如

果 v 是 A

的特征

向量，那么任

何缩放后的

向量 sv (s ∈

R，s = 0) 也是

A 的

特征向量。此

外，sv 和 v

有相同

的特征值。基

于这个原因

，通常我们只

考虑单位特

征向量。

假设

矩阵 A 有

n 个线

性无关的特

征向量 {v

(1)

, . . .

, v

(n)}，对应

着特征值

{λ1,

. . . ,

λn}。我

们将特征向

量连接成一

个矩阵，使得

每一列是一

个特征向量

：

38 第二章 线性

代数

V = [v

(1)

, . . .

, v

(n)

].

类似地

，我们也可以

将特征值连

接成一个向

量 λ = [λ1,

. . . ,

λn]

⊤。

因此 A

的 特

征分解（eigendecomposition）可以

记作

A =

Vdiag(λ)V

−1

. (2.40)

我们已

经看到了构

建具有特定

特征值和特

征向量的矩

阵，能够使我

们在目标方

向上延伸空

间。然而，我们

也常常希望

将矩阵 分解

（decompose）成特征值和

特征向

量。这

样可以帮助

我们分析矩

阵的特定性

质，就像质因

数分解有助

于我们理解

整数。

不是每

一个矩阵都

可以分解成

特征值和特

征向量。在某

些情况下，特

征分解存

在

，但是会涉及

复数而非实

数。幸运的是

，在本书中，我

们通常只需

要分解一类

有

简单分解

的矩阵。具体

来讲，每个实

对称矩阵都

可以分解成

实特征向量

和实特征值

：

A =

QΛQ

⊤

. (2.41)

其中 Q 是 A

的特

征向量组成

的正交矩阵

，Λ 是对角矩阵

。特征值 Λi,i 对应

的特征

向量

是矩阵 Q 的第

i 列，记作

Q:,i。因为

Q 是正交矩阵

，我们可以将

A 看作沿方

向

v

(i) 延展 λi 倍的空

间。如图2.3

所示

的例子。

虽然

任意一个实

对称矩阵 A 都

有特征分解

，但是特征分

解可能并不

唯一。如果

两

个或多个特

征向量拥有

相同的特征

值，那么在由

这些特征向

量产生的生

成子空间

中

，任意一组正

交向量都是

该特征值对

应的特征向

量。因此，我们

可以等价地

从这

些特征

向量中构成

Q 作为替代。按

照惯例，我们

通常按降序

排列

Λ 的元素

。在该

约定下

，特征分解唯

一当且仅当

所有的特征

值都是唯一

的。

矩阵的特

征分解给了

我们很多关

于矩阵的有

用信息。矩阵

是奇异的当

且仅当含

有

零特征值。实

对称矩阵的

特征分解也

可以用于优

化二次方程

f(x) = x

⊤Ax，其中

限制 ∥x∥2 = 1。当

x

等于 A 的某个

特征向量时

，f 将返回对应

的特征值。在

限制条

件下

，函数 f 的最大

值是最大特

征值，最小值

是最小特征

值。

所有特征

值都是正数

的矩阵被称

为

正定（positive definite）；所有

特征值都是

非

负数的矩

阵被称为 半

正定（positive

semidefinite）。同样地

，所有特征值

都是负数的

矩阵被称为

负定（negative definite）；所有特

征值都是非

正数的矩阵

被称为 半负

定

（negative

semidefinite）。半正定矩

阵受到关注

是因为它们

保证 ∀x, x

⊤Ax

≥ 0。此外，

正

定矩阵还保

证 x

⊤Ax = 0 ⇒

x = 0。

2.8

奇异值分

解 39

−3 −2

−1 0 1 2

3

x0

−3

−2

−1

0

1

2

3

v

(1)

v

(2)

Before multiplication

−3

−2 −1 0 1

2 3

x0

0

−3

−2

−1

0

1

2

3

v

(1)

¸1 v

(1)

v

(2)

¸2 v

(2)

After multiplication

Effect

of eigenvectors and eigenvalues

图 2.3: 特征向

量和特征值

的作用效果

。特征向量和

特征值的作

用效果的一

个实例。在这

里，矩阵

A

有两

个标准正交

的特征向量

，对应特征值

为 λ1 的 v

(1) 以及对

应特征值为

λ2 的 v

(2)。(左) 我

们画

出了所有的

单位向量 u

∈ R

2 的

集合，构成一

个单位圆。(右

)

我们画出了

所有的 Au 点的

集

合。通过观

察

A 拉伸单位

圆的方式，我

们可以看到

它将 v

(i)

方向的

空间拉伸了

λi 倍。

2.8 奇异值分

解

在第 2.7 节，我

们探讨了如

何将矩阵分

解成特征向

量和特征值

。还有另一种

分解

矩阵的

方法，被称为

奇异值分解

（singular

value decomposition, SVD），将矩阵分

解

为

奇异向量

（singular vector）和 奇异值（singular value）。通

过奇异值分

解，我

们会得

到一些与特

征分解相同

类型的信息

。然而，奇异值

分解有更广

泛的应用。每

个实数矩阵

都有一个奇

异值分解，但

不一定都有

特征分解。例

如，非方阵的

矩阵没

有特

征分解，这时

我们只能使

用奇异值分

解。

回想一下

，我们使用特

征分解去分

析矩阵 A

时，得

到特征向量

构成的矩阵

V

和特征值构

成的向量 λ，我

们可以重新

将 A

写作

A = Vdiag(λ)V

−1

. (2.42)

x1

0 x1

40 第二

章

线性代数

奇异值分解

是类似的，只

不过这回我

们将矩阵 A 分

解成三个矩

阵的乘积：

A

= UDV⊤

. (2.43)

假

设 A 是一个 m

× n 的

矩阵，那么 U

是

一个 m × m

的矩阵

，D 是一个 m ×

n

的矩

阵，V 是一个 n

× n 矩

阵。

这些矩阵

中的每一个

经定义后都

拥有特殊的

结构。矩阵

U 和

V 都定义为正

交

矩阵，而矩

阵

D 定义为对

角矩阵。注意

，矩阵 D 不一定

是方阵。

对角

矩阵 D 对角线

上的元素被

称为矩阵 A

的

奇异值（singular value）。矩阵

U 的列向量被

称为 左奇异

向量（left

singular vector），矩阵 V 的

列向量被称

右奇异

向量

（right singular vector）。

事实上，我们

可以用与

A 相

关的特征分

解去解释 A 的

奇异值分解

。A

的 左奇

异向

量（left singular

vector）是 AA⊤ 的特征

向量。A 的

右奇

异向量（right singular

vector）是 A

⊤A 的

特征向量。A 的

非零奇异值

是 A

⊤A 特征值的

平方根，同时

也是

AA⊤ 特征值

的平方根。

SVD 最

有用的一个

性质可能是

拓展矩阵求

逆到非方矩

阵上。我们将

在下一节中

探讨。

2.9 Moore-Penrose

伪逆

对

于非方矩阵

而言，其逆矩

阵没有定义

。假设在下面

的问题中，我

们希望通过

矩阵 A 的左逆

B

来求解线性

方程，

Ax = y

(2.44)

等式两

边左乘左逆

B 后，我们得到

x =

By. (2.45)

取决于问题

的形式，我们

可能无法设

计一个唯一

的映射将 A

映

射到 B。

如果矩

阵 A

的行数大

于列数，那么

上述方程可

能没有解。如

果矩阵 A 的行

数

小于列数

，那么上述矩

阵可能有多

个解。

2.10 迹运算

41

Moore-Penrose 伪逆（Moore-Penrose

pseudoinverse）使我们

在这类问题

上

取得了一

定的进展。矩

阵 A 的伪逆定

义为：

A

+ = lim

α↘0

(A

⊤A +

αI)

−1A

⊤

.

(2.46)

计算伪

逆的实际算

法没有基于

这个定义，而

是使用下面

的公式：

A

+

= VD+U

⊤

.

(2.47)

其中

，矩阵 U，D 和

V 是矩

阵 A奇异值分

解后得到的

矩阵。对角矩

阵 D

的伪逆

D

+ 是

其非零元素

取倒数之后

再转置得到

的。

当矩阵 A 的

列数多于行

数时，使用伪

逆求解线性

方程是众多

可能解法中

的一

种。特别

地，x

= A

+

y

是方程所

有可行解中

欧几里得范

数 ∥x∥2 最小的一

个。

当矩阵

A 的

行数多于列

数时，可能没

有解。在这种

情况下，通过

伪逆得到的

x

使得 Ax

和 y 的欧

几里得距离

∥Ax −

y∥2 最小。

2.10 迹运算

迹运算返回

的是矩阵对

角元素的和

：

Tr(A) = ∑

i

Ai,i. (2.48)

迹运算因为

很多原因而

有用。若不使

用求和符号

，有些矩阵运

算很难描述

，而通过矩

阵

乘法和迹运

算符号可以

清楚地表示

。例如，迹运算

提供了另一

种描述矩阵

Frobenius

范数的方式

：

∥A∥F =

√

Tr(AA⊤

). (2.49)

用迹运算表

示表达式，我

们可以使用

很多有用的

等式巧妙地

处理表达式

。例如，

迹运算

在转置运算

下是不变的

：

Tr(A) = Tr(A

⊤

). (2.50)

多个矩阵相

乘得到的方

阵的迹，和将

这些矩阵中

的最后一个

挪到最前面

之后相

乘的

迹是相同的

。当然，我们需

要考虑挪动

之后矩阵乘

积依然定义

良好：

Tr(ABC) = Tr(CAB)

= Tr(BCA). (2.51)

42

第二章

线性代数

或

者更一般地

，

Tr(

n∏

i=1

F

(i)

)

= Tr(F

(n)

n−1

∏

i=1

F

(i)

). (2.52)

即使循环置

换后矩阵乘

积得到的矩

阵形状变了

，迹运算的结

果依然不变

。例如，假

设矩

阵

A ∈ R

m×n，矩阵

B ∈ R

n×m，我们

可以得到

Tr(AB) = Tr(BA) (2.53)

尽

管 AB ∈ R

m×m 和 BA ∈

R

n×n。

另一个

有用的事实

是标量在迹

运算后仍然

是它自己：a =

Tr(a)。

2.11 行

列式

行列式

，记作

det(A)，是一个

将方阵 A 映射

到实数的函

数。行列式等

于矩阵特

征

值的乘积。行

列式的绝对

值可以用来

衡量矩阵参

与矩阵乘法

后空间扩大

或者缩小

了

多少。如果行

列式是 0，那么

空间至少沿

着某一维完

全收缩了，使

其失去了所

有的

体积。如

果行列式是

1，那么这个转

换保持空间

体积不变。

2.12

实

例：主成分分

析

主成分分

析（principal components analysis,

PCA）是一个简

单的机器学

习算

法，可以

通过基础的

线性代数知

识推导。

假设

在 R

n 空间中我

们有 m 个点

{x

(1)

, .

. . , x

(m)}，我

们希望对这

些点进行有

损

压缩。有损

压缩表示我

们使用更少

的内存，但损

失一些精度

去存储这些

点。我们希

望

损失的精度

尽可能少。

一

种编码这些

点的方式是

用低维表示

。对于每个点

x

(i) ∈ R

n，会有一个对

应的

编码向

量 c

(i) ∈

R

l。如果 l 比

n 小

，那么我们便

使用了更少

的内存来存

储原来的数

据。我们希望

找到一个编

码函数，根据

输入返回编

码，f(x) = c；我们也希

望找到一

个

解码函数，给

定编码重构

输入，x ≈ g(f(x))。

PCA

由我们

选择的解码

函数而定。具

体地，为了简

化解码器，我

们使用矩阵

乘

法将编码

映射回 R

n，即

g(c) = Dc，其

中 D

∈ R

n×l 是定义解

码的矩阵。

2.12 实

例：主成分分

析 43

目前为止

所描述的问

题，可能会有

多个解。因为

如果我们按

比例地缩小

所有点

对应

的编码向量

ci，那么我们只

需按比例放

大 D:,i，即可保持

结果不变。为

了使问

题有

唯一解，我们

限制 D

中所有

列向量都有

单位范数。

计

算这个解码

器的最优编

码可能是一

个困难的问

题。为了使编

码问题简单

一些，

PCA 限制

D 的

列向量彼此

正交（注意，除

非 l =

n，否则严格

意义上 D 不是

一个

正交矩

阵）。

为了将这

个基本想法

变为我们能

够实现的算

法，首先我们

需要明确如

何根据每

一

个输入 x 得到

一个最优编

码

c

∗。一种方法

是最小化原

始输入向量

x 和重构向量

g(c

∗

) 之间的距离

。我们使用范

数来衡量它

们之间的距

离。在 PCA 算法中

，我们使

用 L

2 范

数：

c

∗ = arg

min

c

∥x −

g(c)∥2

. (2.54)

我们可以

用平方

L

2 范数

替代 L

2 范数，因

为两者在相

同的值 c 上取

得最小值。

这

是因为 L

2 范数

是非负的，并

且平方运算

在非负值上

是单调递增

的。

c

∗ = arg

min

c

∥x −

g(c)∥

2

2

.

(2.55)

该最小化

函数可以简

化成

(x −

g(c))⊤(x − g(c)) (2.56)

（式(2.30) 中 L

2

范

数的定义）

= x

⊤x

− x

⊤g(c) −

g(c)

⊤x + g(c)

⊤g(c) (2.57)

(分

配律)

=

x

⊤x − 2x

⊤g(c) + g(c)

⊤g(c)

(2.58)

(因为标

量 g(c)

⊤x

的转置等

于自己)

因为

第一项 x

⊤x

不依

赖于 c，所以我

们可以忽略

它，得到如下

的优化目标

：

c

∗

= arg min

c

− 2x

⊤g(c) +

g(c)

⊤g(c). (2.59)

更进一步，我

们代入

g(c) 的定

义：

c

∗

= arg min

c

− 2x

⊤Dc +

c

⊤D

⊤Dc (2.60)

= arg min

c

− 2x

⊤Dc +

c

⊤Ilc (2.61)

44

第二章 线

性代数

(矩阵

D 的正交性和

单位范数约

束)

= arg min

c

− 2x

⊤Dc +

c

⊤c (2.62)

我们可以

通过向量微

积分来求解

这个最优化

问题（如果你

不清楚怎么

做，请参

考第

4.3 节）

∇c(−2x

⊤Dc

+ c

⊤c) =

0 (2.63)

−2D

⊤

x + 2c =

0 (2.64)

c =

D

⊤

x. (2.65)

这使得算

法很高效：最

优编码 x 只需

要一个矩阵

-向量乘法操

作。为了编码

向量，

我们使

用编码函数

：

f(x) = D

⊤

x. (2.66)

进一步使用

矩阵乘法，我

们也可以定

义 PCA

重构操作

：

r(x) = g(f(x))

= DD⊤

x. (2.67)

接下来，我们

需要挑选编

码矩阵 D。要做

到这一点，我

们回顾最小

化输入和

重

构之间 L

2 距离

的这个想法

。因为用相同

的矩阵 D 对所

有点进行解

码，我们不

能

再孤立地看

待每个点。反

之，我们必须

最小化所有

维数和所有

点上的误差

矩阵

的 Frobenius 范数

：

D

∗ = arg

min

D

√∑

i,j

(

x

(

j

i) − r(x

(i))j

)2

subject to D

⊤D = Il

.

(2.68)

为了推导用

于寻求 D

∗

的算

法，我们首先

考虑 l = 1

的情况

。在这种情况

下，D

是一个单

一向量 d。将式

(2.67) 代入式

(2.68) ，简化

D 为 d，问题简化

为

d

∗ = arg

min

d

∑

i



x

(i) − dd⊤

x

(i)

2

2

subject to ∥d∥2 =

1. (2.69)

上述公式

是直接代入

得到的，但不

是文体表述

最舒服的方

式。在上述公

式中，我

们将

标量

d

⊤

x

(i)

放在向

量 d 的右边。将

该标量放在

左边的写法

更为传统。于

是我们

通常

写作

d

∗ = arg

min

d

∑

i



x

(i) − d

⊤

x

(i)d



2

2

subject to

∥d∥2 = 1, (2.70)

2.12 实例：主

成分分析 45

或

者，考虑到标

量的转置和

自身相等，我

们也可以写

作

d

∗ = arg

min

d

∑

i

x

(i) − x

(i)⊤dd

2

2

subject to ∥d∥2 =

1. (2.71)

读者应该

对这些重排

写法慢慢熟

悉起来。

此时

，使用单一矩

阵来重述问

题，比将问题

写成求和形

式更有帮助

。这有助于

我

们使用更紧

凑的符号。将

表示各点的

向量堆叠成

一个矩阵，记

为 X ∈ R

m×n，其中

Xi,: = x

(i)

⊤ 。原问

题可以重新

表述为：

d

∗ = arg min

d

X −

Xdd⊤

2

F

subject

to d

⊤

d

= 1. (2.72)

暂时

不考虑约束

，我们可以将

Frobenius

范数简化成

下面的形式

：

arg min

d



X − Xdd⊤

2

F

(2.73)

= arg

min

d

Tr ((

X − Xdd⊤

)⊤

(

X − Xdd⊤

))

(2.74)

（式(2.49) ）

= arg min

d

Tr (

X

⊤X

− X

⊤Xdd⊤ −

dd⊤X

⊤X + dd⊤X

⊤Xdd⊤

)

(2.75)

=

arg min

d

Tr(X

⊤X) − Tr(X

⊤Xdd⊤

) − Tr(dd⊤X

⊤X)

+ Tr(dd⊤X

⊤Xdd⊤

)

(2.76)

= arg min

d

− Tr(X

⊤Xdd⊤

) − Tr(dd⊤X

⊤X)

+ Tr(dd⊤X

⊤Xdd⊤

)

(2.77)

（因为与 d 无

关的项不影

响

arg min）

= arg

min

d

− 2Tr(X

⊤Xdd⊤

) + Tr(dd⊤X

⊤Xdd⊤

) (2.78)

（因为循环

改变迹运算

中相乘矩阵

的顺序不影

响结果，如式

(2.52)

所示）

= arg min

d

− 2Tr(X

⊤Xdd⊤

) + Tr(X

⊤Xdd⊤

dd⊤

) (2.79)

（再次使

用上述性质

）

此时，我们再

来考虑约束

条件:

arg min

d

− 2Tr(X

⊤Xdd⊤

)

+ Tr(X

⊤Xdd⊤

dd⊤

) subject to d

⊤

d = 1

(2.80)

46 第二章

线性代数

=

arg min

d

−

2Tr(X

⊤Xdd⊤

) +

Tr(X

⊤Xdd⊤

) subject

to d

⊤

d

= 1 (2.81)

(因

为约束条件

)

= arg min

d

− Tr(X

⊤Xdd⊤

)

subject to d

⊤

d = 1 (2.82)

= arg max

d

Tr(X

⊤Xdd⊤

) subject

to d

⊤

d

= 1 (2.83)

=

arg max

d

Tr(d

⊤X

⊤Xd) subject to

d

⊤

d =

1. (2.84)

这个优化问

题可以通过

特征分解来

求解。具体来

讲，最优的 d

是

X

⊤X 最大特

征值

对应的特征

向量。

以上推

导特定于 l = 1

的

情况，仅得到

了第一个主

成分。更一般

地，当我们希

望

得到主成

分的基时，矩

阵 D 由前

l 个最

大的特征值

对应的特征

向量组成。这

个结论

可以

通过归纳法

证明，我们建

议将此证明

作为练习。

线

性代数是理

解深度学习

所必须掌握

的基础数学

学科之一。另

一门在机器

学习

中无处

不在的重要

数学学科是

概率论，我们

将在下一章

探讨。

第三章

概率与信息

论

本章我们

讨论概率论

和信息论。

概

率论是用于

表示不确定

性声明的数

学框架。它不

仅提供了量

化不确定性

的方

法，也提

供了用于导

出新的不确

定性 声明（statement）的

公理。在人工

智能领域，

概

率论主要有

两种用途。首

先，概率法则

告诉我们 AI

系

统如何推理

，据此我们设

计

一些算法

来计算或者

估算由概率

论导出的表

达式。其次，我

们可以用概

率和统计从

理论上分析

我们提出的

AI 系统的行为

。

概率论是众

多科学学科

和工程学科

的基本工具

。我们提供这

一章，是为了

确保

那些背

景偏软件工

程而较少接

触概率论的

读者也可以

理解本书的

内容。

概率论

使我们能够

提出不确定

的声明以及

在不确定性

存在的情况

下进行推理

，

而信息论使

我们能够量

化概率分布

中的不确定

性总量。

如果

你已经对概

率论和信息

论很熟悉了

，那么除了第

3.14

节以外的整

章内容，你

都

可以跳过。而

在第 3.14 节中，我

们会介绍用

来描述机器

学习中结构

化概率模型

的

图。即使你

对这些主题

没有任何的

先验知识，本

章对于完成

深度学习的

研究项目来

说也已经足

够，尽管如此

我们还是建

议你能够参

考一些额外

的资料，例如

Jaynes

(2003)。

3.1 为什么要使

用概率？

计算

机科学的许

多分支处理

的实体大部

分都是完全

确定且必然

的。程序员通

常

可以安全

地假定 CPU 将完

美地执行每

条机器指令

。虽然硬件错

误确实会发

生，但它

们足

够罕见，以致

于大部分软

件应用在设

计时并不需

要考虑这些

因素的影响

。鉴于

许多计

算机科学家

和软件工程

师在一个相

对干净和确

定的环境中

工作，机器学

习对

47

48

第三章

概率与信息

论

于概率论

的大量使用

是很令人吃

惊的。

这是因

为机器学习

通常必须处

理不确定量

，有时也可能

需要处理随

机 (非确定性

的)

量。不确定

性和随机性

可能来自多

个方面。至少

从 20 世纪 80

年代

开始，研究

人

员就对使用

概率论来量

化不确定性

提出了令人

信服的论据

。这里给出的

许多论据

都

是根据 Pearl

(1988) 的工

作总结或启

发得到的。

几

乎所有的活

动都需要一

些在不确定

性存在的情

况下进行推

理的能力。事

实上，

除了那

些被定义为

真的数学声

明，我们很难

认定某个命

题是千真万

确的或者确

保某

件事一

定会发生。

不

确定性有三

种可能的来

源：

1. 被建模系

统内在的随

机性。例如，大

多数量子力

学的解释，都

将亚原子粒

子的

动力学

描述为概率

的。我们还可

以创建一些

我们假设具

有随机动态

的理论情境

，

例如一个假

想的纸牌游

戏，在这个游

戏中我们假

设纸牌被真

正混洗成了

随机顺

序。

2.

不

完全观测。即

使是确定的

系统，当我们

不能观测到

所有驱动系

统行为的变

量

时，该系统

也会呈现随

机性。例如，在

Monty Hall 问题中，一个

游戏节目的

参

与者被要

求在三个门

之间选择，并

且会赢得放

置在选中门

后的奖品。其

中两扇

门通

向山羊，第三

扇门通向一

辆汽车。选手

的每个选择

所导致的结

果是确定的

，

但是站在选

手的角度，结

果是不确定

的。

3.

不完全建

模。当我们使

用一些必须

舍弃某些观

测信息的模

型时，舍弃的

信息会

导致

模型的预测

出现不确定

性。例如，假设

我们制作了

一个机器人

，它可以准

确

地观察周围

每一个对象

的位置。在对

这些对象将

来的位置进

行预测时，如

果

机器人采

用的是离散

化的空间，那

么离散化的

方法将使得

机器人无法

确定对象

们

的精确位置

：因为每个对

象都可能处

于它被观测

到的离散单

元的任何一

个角

落。

在很

多情况下，使

用一些简单

而不确定的

规则要比复

杂而确定的

规则更为实

用，

即使真正

的规则是确

定的并且我

们建模的系

统可以足够

精确地容纳

复杂的规则

。例

如，‘‘多数鸟

儿都会飞’’ 这

个简单的规

则描述起来

很简单很并

且使用广泛

，而正式的

规

则——‘‘除了那些

还没学会飞

翔的幼鸟，因

为生病或是

受伤而失去

了飞翔能力

的

鸟，包括食

火鸟

(cassowary)、鸵鸟 (ostrich)、几

维 (kiwi，一种新西

兰产的无翼

鸟)

3.2

随机变量

49

等不会飞的

鸟类……以外，鸟

儿会飞’’，很难

应用、维护和

沟通，即使经

过这么多的

努力，这个规

则还是很脆

弱而且容易

失效。

尽管我

们的确需要

一种用以对

不确定性进

行表示和推

理的方法，但

是概率论并

不能明显地

提供我们在

人工智能领

域需要的所

有工具。概率

论最初的发

展是为了分

析事件发生

的频率。我们

可以很容易

地看出概率

论，对于像在

扑克牌游戏

中抽出一

手

特定的牌这

种事件的研

究中，是如何

使用的。这类

事件往往是

可以重复的

。当我

们说一

个结果发生

的概率为 p，这

意味着如果

我们反复实

验 (例如，抽取

一手牌) 无

限

次，有 p 的比例

可能会导致

这样的结果

。这种推理似

乎并不立即

适用于那些

不可

重复的

命题。如果一

个医生诊断

了病人，并说

该病人患流

感的几率为

40%，这意味

着非

常不同的事

情——我们既不

能让病人有

无穷多的副

本，也没有任

何理由去相

信

病人的不

同副本在具

有不同的潜

在条件下表

现出相同的

症状。在医生

诊断病人的

例

子中，我们

用概率来表

示一种 信任

度（degree

of belief），其中 1 表示

非常肯定病

人

患有流感

，而 0 表示非常

肯定病人没

有流感。前面

那种概率，直

接与事件发

生的频

率相

联系，被称为

频率派概率

（frequentist

probability）；而后者，涉及

到确定性水

平，被称为 贝

叶斯概率（Bayesian probability）。

关

于不确定性

的常识推理

，如果我们已

经列出了若

干条我们期

望它具有的

性质，

那么满

足这些性质

的唯一一种

方法就是将

贝叶斯概率

和频率派概

率视为等同

的。例

如，如果

我们要在扑

克牌游戏中

根据玩家手

上的牌计算

她能够获胜

的概率，我们

使

用和医生

情境完全相

同的公式，就

是我们依据

病人的某些

症状计算她

是否患病的

概

率。为什么

一小组常识

性假设蕴含

了必须是相

同的公理控

制两种概率

？更多的细节

参见

Ramsey (1926)。

概率可

以被看作是

用于处理不

确定性的逻

辑扩展。逻辑

提供了一套

形式化的规

则，可以在给

定某些命题

是真或假的

假设下，判断

另外一些命

题是真的还

是假的。概

率

论提供了一

套形式化的

规则，可以在

给定一些命

题的似然后

，计算其他命

题为真

的似

然。

3.2 随机变量

随机变量（random variable）是

可以随机地

取不同值的

变量。我们通

常用无格

式

字体 (plain typeface) 中的小

写字母来表

示随机变量

本身，而用手

写体中的小

写字

母来表

示随机变量

能够取到的

值。例如，x1 和 x2 都

是随机变量

x

可能的取值

。对

50 第三章 概

率与信息论

于向量值变

量，我们会将

随机变量写

成

x，它的一个

可能取值为

x。就其本身而

言，

一个随机

变量只是对

可能的状态

的描述；它必

须伴随着一

个概率分布

来指定每个

状

态的可能

性。

随机变量

可以是离散

的或者连续

的。离散随机

变量拥有有

限或者可数

无限多的

状

态。注意这些

状态不一定

非要是整数

；它们也可能

只是一些被

命名的状态

而没有

数值

。连续随机变

量伴随着实

数值。

3.3 概率分

布

概率分布

（probability distribution）用来描述随

机变量或一

簇随机变量

在每一

个可

能取到的状

态的可能性

大小。我们描

述概率分布

的方式取决

于随机变量

是离散

的还

是连续的。

3.3.1 离

散型变量和

概率质量函

数

离散型变

量的概率分

布可以用 概

率质量函数

（probability

mass function, PMF）

1来描述。我们

通常用大写

字母

P 来表示

概率质量函

数。通常每一

个随机变量

都会有

一个

不同的概率

质量函数，并

且读者必须

根据随机变

量来推断所

使用的 PMF，而不

是根据函数

的名称来推

断；例如，P(x)

通常

和 P(y) 不一样。

概

率质量函数

将随机变量

能够取得的

每个状态映

射到随机变

量取得该状

态的概

率。x = x 的

概率用

P(x) 来表

示，概率为 1 表

示

x = x 是确定的

，概率为

0 表示

x = x

是不可能发

生的。有时为

了使得PMF的使

用不相互混

淆，我们会明

确写出随

机

变量的名称

：P(x = x)。有时我们会

先定义一个

随机变量，然

后用

∼ 符号来

说明

它遵循

的分布：x ∼

P(x)。

概率

质量函数可

以同时作用

于多个随机

变量。这种多

个变量的概

率分布被称

为 联合概率

分布（joint probability

distribution）。P(x = x, y

= y) 表示 x

= x 和

y =

y 同时发生的

概率。我们也

可以简写为

P(x, y)。

如果一个函

数

P 是随机变

量 x 的

PMF，必须满

足下面这几

个条件：

• P 的定

义域必须是

x

所有可能状

态的集合。

1译

者注：国内有

些教材也将

它翻译成概

率分布律。

3.3 概

率分布

51

• ∀x ∈

x, 0 ≤ P(x)

≤ 1. 不可

能发生的事

件概率为 0，并

且不存在比

这概率更低

的状态。类似

的，能够确保

一定发生的

事件概率为

1，而且不存在

比这概率更

高的状态。

•

∑

x∈x P(x)

= 1. 我

们把这条性

质称之为 归

一化的（normalized）。如果

没有这

条性

质，当我们计

算很多事件

其中之一发

生的概率时

可能会得到

大于 1 的概

率

。

例如，考虑一

个离散型随

机变量 x 有 k

个

不同的状态

。我们可以假

设 x 是 均匀

分

布（uniform distribution）的（也就是

将它的每个

状态视为等

可能的），通过

将它

的PMF设为

P(x =

xi) = 1

k

(3.1)

对于所有的

i 都成立。我们

可以看出这

满足上述成

为概率质量

函数的条件

。因为 k

是一个

正整数，所以

k

1 是正的。我们

也可以看出

∑

i

P(x = xi) =

∑

i

k

1

=

k

k

=

1, (3.2)

因此分布也

满足归一化

条件。

3.3.2

连续型

变量和概率

密度函数

当

我们研究的

对象是连续

型随机变量

时，我们用 概

率密度函数

（probability

density

function, PDF）而不是概率

质量函数来

描述它的概

率分布。如果

一个函数 p

是

概率密度函

数，必须满足

下面这几个

条件：

• p 的定义

域必须是 x

所

有可能状态

的集合。

• ∀x ∈

x, p(x) ≥ 0.

注意

，我们并不要

求 p(x) ≤ 1。

•

∫

p(x)dx =

1.

概率密度

函数 p(x) 并没有

直接对特定

的状态给出

概率，相对的

，它给出了落

在

面积为 δx 的

无限小的区

域内的概率

为 p(x)δx。

我们可以

对概率密度

函数求积分

来获得点集

的真实概率

质量。特别地

，x 落在

集合 S

中

的概率可以

通过 p(x) 对这个

集合求积分

来得到。在单

变量的例子

中，x 落

在区间

[a, b] 的概率是 ∫

[a,b]

p(x)dx。

52 第

三章

概率与

信息论

为了

给出一个连

续型随机变

量的 PDF 的例子

，我们可以考

虑实数区间

上的均匀

分

布。我们可以

使用函数 u(x; a, b)，其

中

a 和 b 是区间

的端点且满

足

b > a。符号

“;’’

表示

‘‘以什么为参

数’’；我们把 x 作

为函数的自

变量，a 和

b 作为

定义函数的

参

数。为了确

保区间外没

有概率，我们

对所有的 x

̸∈ [a, b]，令

u(x; a,

b) = 0。在 [a,

b]

内，有 u(x; a,

b) = b−

1

a。我们

可以看出任

何一点都非

负。另外，它的

积分为 1。我们

通常用 x ∼

U(a, b) 表示

x 在

[a, b] 上是均匀

分布的。

3.4

边缘

概率

有时候

，我们知道了

一组变量的

联合概率分

布，但想要了

解其中一个

子集的概

率

分布。这种定

义在子集上

的概率分布

被称为 边缘

概率分布（marginal

probability

distribution）。

例

如，假设有离

散型随机变

量 x

和 y，并且我

们知道 P(x, y)。我们

可以依据下

面的

求和法

则（sum rule）来计算 P(x)：

∀x

∈ x, P(x =

x) = ∑

y

P(x = x, y

= y). (3.3)

‘‘边

缘概率’’

的名

称来源于手

算边缘概率

的计算过程

。当 P(x, y) 的每个值

被写

在由每

行表示不同

的 x 值，每列表

示不同的 y

值

形成的网格

中时，对网格

中的每行

求

和是很自然

的事情，然后

将求和的结

果 P(x) 写在每行

右边的纸的

边缘处。

对于

连续型变量

，我们需要用

积分替代求

和：

p(x) = ∫

p(x, y)dy. (3.4)

3.5

条件概率

在很多情况

下，我们感兴

趣的是某个

事件，在给定

其他事件发

生时出现的

概率。这种概

率叫做条件

概率。我们将

给定 x = x，y

= y 发生的

条件概率记

为

P(y

= y | x

= x)。这个条件

概率可以通

过下面的公

式计算：

P(y =

y | x =

x) = P(y =

y, x = x)

P(x = x)

.

(3.5)

3.6 条件

概率的链式

法则 53

条件概

率只在 P(x = x)

> 0 时有

定义。我们不

能计算给定

在永远不会

发生的事件

上

的条件概

率。

这里需要

注意的是，不

要把条件概

率和计算当

采用某个动

作后会发生

什么相混

淆

。假定某个人

说德语，那么

他是德国人

的条件概率

是非常高的

，但是如果随

机选

择的一

个人会说德

语，他的国籍

不会因此而

改变。计算一

个行动的后

果被称为 干

预

查询（intervention query）。干预

查询属于 因

果模型（causal modeling）的范

畴，我

们不会

在本书中讨

论。

3.6 条件概率

的链式法则

任何多维随

机变量的联

合概率分布

，都可以分解

成只有一个

变量的条件

概率相

乘的

形式：

P(x

(1)

, .

. . , x

(n)

) = P(x

(1))Πn

i=2P(x

(i)

|

x

(1)

, .

. . , x

(i−1)). (3.6)

这个规

则被称为概

率的 链式法

则（chain

rule）或者 乘法

法则（product rule）。

它可以

直接从式

(3.5) 条

件概率的定

义中得到。例

如，使用两次

定义可以得

到

P(a, b,

c) = P(a |

b, c)P(b, c)

P(b,

c) = P(b |

c)P(c)

P(a, b, c)

= P(a | b,

c)P(b | c)P(c).

3.7

独立性和

条件独立性

两个随机变

量 x 和 y，如果它

们的概率分

布可以表示

成两个因子

的乘积形式

，并

且一个因

子只包含 x 另

一个因子只

包含 y，我们就

称这两个随

机变量是

相

互独立的

（independent）：

∀x ∈

x, y ∈ y,

p(x = x, y

= y) = p(x

= x)p(y = y).

(3.7)

如

果关于 x 和

y 的

条件概率分

布对于 z 的每

一个值都可

以写成乘积

的形式，

那么

这两个随机

变量 x 和 y

在给

定随机变量

z 时是 条件独

立的（conditionally

54

第三章

概率与信息

论

independent）：

∀x ∈

x, y ∈ y,

z ∈ z, p(x

= x, y =

y | z =

z) = p(x =

x | z =

z)p(y = y |

z = z).

(3.8)

我们可以

采用一种简

化形式来表

示独立性和

条件独立性

：x⊥y 表示 x 和

y 相互

独立，x⊥y | z

表示 x 和

y 在给定

z 时条

件独立。

3.8 期望

、方差和协方

差

函数 f(x) 关于

某分布 P(x)

的 期

望（expectation）或者 期望

值（expected

value）是指，当

x 由

P 产生，f 作用于

x

时，f(x) 的平均值

。对于离散型

随

机变量，这

可以通过求

和得到：

Ex∼P

[f(x)] = ∑

x

P(x)f(x), (3.9)

对于

连续型随机

变量可以通

过求积分得

到：

Ex∼p[f(x)]

= ∫

p(x)f(x)dx. (3.10)

当概率分

布在上下文

中指明时，我

们可以只写

出期望作用

的随机变量

的名称来进

行

简化，例如

Ex[f(x)]。如果期望作

用的随机变

量也很明确

，我们可以完

全不写脚标

，

就像 E[f(x)]。默认地

，我们假设

E[·] 表

示对方括号

内的所有随

机变量的值

求平均。

类似

的，当没有歧

义时，我们还

可以省略方

括号。

期望是

线性的，例如

，

Ex[αf(x) + βg(x)] =

αEx[f(x)] + βEx[g(x)], (3.11)

其中 α 和 β

不依

赖于 x。

方差（variance）衡

量的是当我

们对 x

依据它

的概率分布

进行采样时

，随机变

量 x 的

函数值会呈

现多大的差

异：

Var(f(x)) = E

[

(f(x) − E[f(x)])2

]

. (3.12)

当方差很

小时，f(x) 的值形

成的簇比较

接近它们的

期望值。方差

的平方根被

称为

标

准差

（standard deviation）。

3.9

常用概率分

布 55

协方差（covariance）在

某种意义上

给出了两个

变量线性相

关性的强度

以及这些

变

量的尺度：

Cov(f(x), g(y)) = E[(f(x)

− E[f(x)])(g(y) − E[g(y)])].

(3.13)

协

方差的绝对

值如果很大

则意味着变

量值变化很

大并且它们

同时距离各

自的均值很

远。如果协方

差是正的，那

么两个变量

都倾向于同

时取得相对

较大的值。如

果协方

差是

负的，那么其

中一个变量

倾向于取得

相对较大的

值的同时，另

一个变量倾

向于

取得相

对较小的值

，反之亦然。其

他的衡量指

标如

相关系

数（correlation）将每个变

量的贡献归

一化，为了只

衡量变量的

相关性而不

受各个变量

尺度大小的

影响。

协方差

和相关性是

有联系的，但

实际上是不

同的概念。它

们是有联系

的，因为

两个

变量如果相

互独立那么

它们的协方

差为零，如果

两个变量的

协方差不为

零那么

它们

一定是相关

的。然而，独立

性又是和协

方差完全不

同的性质。两

个变量如果

协

方差为零

，它们之间一

定没有线性

关系。独立性

比零协方差

的要求更强

，因为独立

性

还排除了非

线性的关系

。两个变量相

互依赖但具

有零协方差

是可能的。例

如，假

设我们

首先从区间

[−1, 1]

上的均匀分

布中采样出

一个实数 x。然

后我们对一

个随机

变量

s 进行采样。s

以

1

2 的概率值为

1，否则为-1。我们

可以通过令

y =

sx 来生成

一个

随机变量 y。显

然，x

和 y 不是相

互独立的，因

为 x

完全决定

了 y 的尺度。然

而，Cov(x, y)

= 0。

随机向量

x ∈

R

n 的 协方差矩

阵（covariance

matrix）是一个 n × n

的

矩阵，并

且满

足

Cov(x)i,j =

Cov(xi

, xj ).

(3.14)

协方差矩

阵的对角元

是方差：

Cov(xi

,

xi) = Var(xi). (3.15)

3.9 常用

概率分布

许

多简单的概

率分布在机

器学习的众

多领域中都

是有用的。

56

第

三章 概率与

信息论

3.9.1 Bernoulli

分布

Bernoulli 分布（Bernoulli distribution）是单个

二值随机变

量的分布。它

由单

个参数

ϕ

∈ [0, 1] 控制，ϕ

给出了

随机变量等

于 1 的概率。它

具有如下的

一些性质：

P(x

= 1) = ϕ

(3.16)

P(x = 0)

= 1 − ϕ

(3.17)

P(x = x)

= ϕ

x

(1

− ϕ)

1−x

(3.18)

Ex[x] = ϕ (3.19)

Varx(x) = ϕ(1 −

ϕ) (3.20)

3.9.2 Multinoulli

分

布

Multinoulli 分布（multinoulli distribution）或者

范畴分布（categorical

dis￾tribution）是

指在具有 k 个

不同状态的

单个离散型

随机变量上

的分布，其中

k 是一

个有限

值。2 Multinoulli 分布由向

量 p

∈ [0, 1]k−1 参数化，其

中每一个分

量

pi 表示

第 i

个

状态的概率

。最后的第 k 个

状态的概率

可以通过 1

− 1

⊤p 给

出。注意我们

必

须限制 1

⊤p ≤

1。Multinoulli 分

布经常用来

表示对象分

类的分布，所

以我们很少

假

设状态 1

具

有数值 1 之类

的。因此，我们

通常不需要

去计算 Multinoulli

分布

的随机

变量

的期望和方

差。

Bernoulli 分布和

Multinoulli 分

布足够用来

描述在它们

领域内的任

意分布。它们

能够描述这

些分布，不是

因为它们特

别强大，而是

因为它们的

领域很简单

；它们可

以对

那些，能够将

所有的状态

进行枚举的

离散型随机

变量进行建

模。当处理的

是连

续型随

机变量时，会

有不可数无

限多的状态

，所以任何通

过少量参数

描述的概率

分

布都必须

在分布上加

以严格的限

制。

2

“multinoulli’’ 这个术语

是最近被

Gustavo Lacerdo 发

明、被Murphy (2012)

推广的

。Multinoulli 分布是 多

项

式分布（multinomial

distribution）的一

个特例。多项

式分布是 {0, . .

. , n}

k

中

的向量的分

布，用于表示

当

对 Multinoulli 分布采

样

n 次时 k 个类

中的每一个

被访问的次

数。很多文章

使用

“多项式

分布’’ 而实际

上说的

是 Multinoulli

分

布，但是他们

并没有说是

对 n = 1

的情况，这

点需要注意

。

3.9 常用概率分

布 57

3.9.3 高斯分布

实数上最常

用的分布就

是 正态分布

（normal distribution），也称为

高斯

分布

（Gaussian distribution）：

N

(x; µ, σ2

)

= √

2πσ

1

2

exp (

−

2σ

1

2

(x

− µ)

2

)

. (3.21)

图 3.1

画出

了正态分布

的概率密度

函数。

−2.0 −1.5 −1.0

−0.5 0.0 0.5 1.0

1.5 2.0

x

0.00

0.05

0.10

0.15

0.20

0.25

0.30

0.35

0.40

Maximum at x =

µ

Inflection points at

x = µ ±

σ

图 3.1: 正态

分布。正态分

布

N (x; µ, σ2

) 呈现经典

的 ‘‘钟形曲线

’’ 的形状，其中

中心峰的

x 坐

标

由 µ

给出，峰

的宽度受 σ 控

制。在这个示

例中，我们展

示的是 标准

正态分布（standard

normal

distribution），其

中 µ =

0, σ = 1。

正态分布

由两个参数

控制，µ ∈ R 和

σ ∈ (0, ∞)。参数

µ

给出了中心

峰值的坐

标

，这也是分布

的均值：E[x] = µ。分布

的标准差用

σ

表示，方差用

σ

2 表示。

当我们

要对概率密

度函数求值

时，我们需要

对

σ 平方并且

取倒数。当我

们需要

经常

对不同参数

下的概率密

度函数求值

时，一种更高

效的参数化

分布的方式

是使用

参数

β

∈ (0, ∞)，来控制分布

的 精度（precision）(或方

差的倒数)：

N (x; µ, β−1

) = √

2

β

π

exp (

−

2

1

β(x

− µ)

2

)

. (3.22)

采

用正态分布

在很多应用

中都是一个

明智的选择

。当我们由于

缺乏关于某

个实

数上分

布的先验知

识而不知道

该选择怎样

的形式时，正

态分布是默

认的比较好

的选

择，其中

有两个原因

。

p(x)

58 第三章

概率

与信息论

第

一，我们想要

建模的很多

分布的真实

情况是比较

接近正态分

布的。 中心极

限

定理（central

limit theorem）说明

很多独立随

机变量的和

近似服从正

态分布。这意

味着在实际

中，很多复杂

系统都可以

被成功地建

模成正态分

布的噪声，即

使系统可

以

被分解成一

些更结构化

的部分。

第二

，在具有相同

方差的所有

可能的概率

分布中，正态

分布在实数

上具有最大

的不确定性

。因此，我们可

以认为正态

分布是对模

型加入的先

验知识量最

少的分布。

充

分利用和证

明这个想法

需要更多的

数学工具，我

们推迟到第

19.4.2 节进行讲解

。

正态分布可

以推广到 R

n 空

间，这种情况

下被称为 多

维正态分布

（multivariate

normal

distribution）。它的参数是

一个正定对

称矩阵 Σ：

N (x;

µ, Σ) = √

(2π)

n

1

det(Σ)

exp (

−

2

1

(x − µ)

⊤Σ

−1

(x −

µ)

)

. (3.23)

参数

µ 仍然表示分

布的均值，只

不过现在是

向量值。参数

Σ 给出了分布

的协

方差矩

阵。和单变量

的情况类似

，当我们希望

对很多不同

参数下的概

率密度函数

多

次求值时

，协方差矩阵

并不是一个

很高效的参

数化分布的

方式，因为对

概率密度函

数求值时需

要对 Σ 求逆。我

们可以使用

一个 精度矩

阵（precision

matrix）β 进行替

代

：

N

(x; µ, β

−1

) = √

det(β)

(2π)

n

exp (

−

1

2

(x

− µ)

⊤β(x −

µ)

)

. (3.24)

我们常常把

协方差矩阵

固定成一个

对角阵。一个

更简单的版

本是 各向同

性

（isotropic）高斯分布

，它的协方差

矩阵是一个

标量乘以单

位阵。

3.9.4

指数分

布和 Laplace 分布

在

深度学习中

，我们经常会

需要一个在

x

= 0 点处取得边

界点 (sharp

point) 的

分布

。为了实现这

一目的，我们

可以使用 指

数分布（exponential

distribution）：

p(x; λ) =

λ1x≥0 exp(−λx). (3.25)

指数

分布使用指

示函数(indicator

function)1x≥0 来使

得当 x 取负值

时的概率为

零。

一个联系

紧密的概率

分布是 Laplace 分布

（Laplace distribution），它允许我们

在任意一点

µ

处设置概率

质量的峰值

Laplace(x; µ, γ) =

2

1

γ

exp

(

−

|x −

γ

µ|

)

.

(3.26)

3.9 常用概率分

布 59

3.9.5 Dirac 分布和经

验分布

在一

些情况下，我

们希望概率

分布中的所

有质量都集

中在一个点

上。这可以通

过

Dirac delta 函数（Dirac delta

function）δ(x) 定义

概率密度函

数来实现：

p(x) =

δ(x − µ). (3.27)

Dirac delta 函

数被定义成

在除了 0

以外

的所有点的

值都为 0，但是

积分为 1。Dirac

delta

函数

不像普通函

数一样对 x 的

每一个值都

有一个实数

值的输出，它

是一种不同

类型的数学

对象，被称为

广义函数（generalized function），广

义函数是依

据积分性

质

定义的数学

对象。我们可

以把 Dirac delta 函数想

成一系列函

数的极限点

，这一系

列函

数把除 0 以外

的所有点的

概率密度越

变越小。

通过

把

p(x) 定义成 δ 函

数左移

−µ 个单

位，我们得到

了一个在 x =

µ 处

具有

无限窄

也无限高的

峰值的概率

质量。

Dirac

分布经

常作为 经验

分布（empirical distribution）的一个

组成部分出

现：

pˆ(x)

=

m

1

m∑

i=1

δ(x − x

(i)

) (3.28)

经验分布

将概率密度

m

1 赋给 m 个点

x

(1)

, .

. . , x

(m) 中

的每一个，这

些点是给定

的

数据集或

者采样的集

合。只有在定

义连续型随

机变量的经

验分布时，Dirac delta

函

数才是必要

的。对于离散

型随机变量

，情况更加简

单：经验分布

可以被定义

成一

个 Multinoulli 分布

，对于每一个

可能的输入

，其概率可以

简单地设为

在训练集上

那

个输入值

的 经验频率

（empirical frequency）。

当我们在训

练集上训练

模型时，我们

可以认为从

这个训练集

上得到的经

验分

布指明

了我们采样

来源的分布

。关于经验分

布另外一种

重要的观点

是，它是训练

数

据的似然

最大的那个

概率密度函

数 (见第 5.5

节)。

3.9.6 分

布的混合

通

过组合一些

简单的概率

分布来定义

新的概率分

布也是很常

见的。一种通

用的组

合方

法是构造 混

合分布（mixture distribution）。混合

分布由一些

组件 (component)

分布构

成。每次实验

，样本是由哪

个组件分布

产生的取决

于从一个 Multinoulli 分

布中采样的

结果：

P(x)

= ∑

i

P(c

= i)P(x | c

= i), (3.29)

60

第三章

概率与信息

论

这里 P(c) 是对

各组件的一

个

Multinoulli 分布。

我们

已经看过一

个混合分布

的例子了：实

值变量的经

验分布对于

每一个训练

实

例来说，就

是以

Dirac 分布为

组件的混合

分布。

混合模

型是组合简

单概率分布

来生成更丰

富的分布的

一种简单策

略。在第十

六

章中，我们更

加详细地探

讨从简单概

率分布构建

复杂模型的

技术。

混合模

型使我们能

够一瞥以后

会用到的一

个非常重要

的概念—— 潜变

量

（latent variable）。潜变量是

我们不能直

接观测到的

随机变量。混

合模型的组

件标

识变量

c 就是其中一

个例子。潜变

量在联合分

布中可能和

x 有关，在这种

情况下，

P(x,

c) = P(x |

c)P(c)。潜变

量的分布 P(c) 以

及关联潜变

量和观测变

量的条件分

布

P(x

| c)，共同决定

了分布 P(x) 的形

状，尽管描述

P(x)

时可能并不

需要潜变量

。潜

变量将在

第 16.5 节中深入

讨论。

一个非

常强大且常

见的混合模

型是 高斯混

合模型（Gaussian Mixture Model），

它的

组件 p(x | c

= i) 是高斯

分布。每个组

件都有各自

的参数，均值

µ

(i)

和协方差矩

阵 Σ

(i)。有一些混

合可以有更

多的限制。例

如，协方差矩

阵可以通过

Σ

(i)

= Σ, ∀i 的

形式在组

件之间共享

参数。和单个

高斯分布一

样，高斯混合

模型有时会

限制每个组

件的协方差

矩阵为对角

的或者各向

同性的 (标量

乘以单位矩

阵）。

除了均值

和协方差以

外，高斯混合

模型的参数

指明了给每

个组件 i

的 先

验概率

（prior probability）αi

= P(c = i)。‘‘先验

’’

一词表明了

在观测到 x 之

前传递给模

型关于 c

的信

念。作为对比

，P(c | x) 是

后验概率

（posterior probability），因为它

是在

观测到 x

之后

进行计算的

。高斯混合模

型是概率密

度的 万能近

似器（universal

approximator），在这种

意义下，任何

平滑的概率

密度都可以

用具有足够

多组件的高

斯混合模型

以任意精度

来逼近。

图

3.2 演

示了某个高

斯混合模型

生成的样本

。

3.10 常用函数的

有用性质

61

x1

图

3.2: 来自高斯混

合模型的样

本。在这个示

例中，有三个

组件。从左到

右，第一个组

件具有各向

同性的协方

差矩阵，这意

味着它在每

个方向上具

有相同的方

差。第二个组

件具有对角

的协方差矩

阵，这意味着

它可以沿着

每个轴的对

齐方向单独

控制方差。该

示例中，沿着

x2

轴的方差要

比沿着

x1 轴的

方差大。第三

个组件具有

满秩的协方

差矩阵，使它

能够沿着任

意基的方向

单独地控制

方差。

3.10

常用函

数的有用性

质

某些函数

在处理概率

分布时经常

会出现，尤其

是深度学习

的模型中用

到的概率

分

布。

其中一个

函数是

logistic sigmoid 函数

：

σ(x)

= 1

1 +

exp(−x)

. (3.30)

logistic

sigmoid 函数通常用

来产生 Bernoulli 分布

中的参数

ϕ，因

为它的范围

是

(0, 1)，处在 ϕ

的有

效取值范围

内。图3.3 给出了

sigmoid 函数的图示

。sigmoid 函数

在变量

取绝对值非

常大的正值

或负值时会

出现 饱和（saturate）现

象，意味着函

数会

变得很

平，并且对输

入的微小改

变会变得不

敏感。

另外一

个经常遇到

的函数是

softplus 函

数（softplus function）(Dugas et

al.,

2001)：

ζ(x) =

log(1 + exp(x)). (3.31)

softplus 函数可以

用来产生正

态分布的 β 和

σ

参数，因为它

的范围是 (0, ∞)。当

处

理包含

sigmoid 函

数的表达式

时它也经常

出现。softplus 函数名

来源于它是

另外一个

x2

62 第

三章 概率与

信息论

−10

−5 0 5 10

x

0.0

0.2

0.4

0.6

0.8

1.0

图

3.3: logistic sigmoid函

数。

函数的平

滑（或

‘‘软化’’）形

式，这个函数

是

x

+ =

max(0, x). (3.32)

图

3.4 给出了

softplus 函数的图示

。

−10

−5 0 5 10

x

0

2

4

6

8

10

图

3.4: softplus 函数。

σ(x)

ζ(x)

3.11 贝叶

斯规则 63

下面

一些性质非

常有用，你可

能要记下来

：

σ(x) = exp(x)

exp(x) + exp(0) (3.33)

d

dxσ(x) = σ(x)(1

− σ(x)) (3.34)

1

− σ(x) = σ(−x)

(3.35)

log σ(x) =

−ζ(−x) (3.36)

d

dxζ(x)

= σ(x) (3.37)

∀x

∈ (0, 1), σ−1

(x) = log (

1 −

x

x

)

(3.38)

∀x >

0, ζ−1

(x) =

log(exp(x) − 1) (3.39)

ζ(x) = ∫ x

−∞

σ(y)dy (3.40)

ζ(x)

− ζ(−x) = x

(3.41)

函数 σ

−1

(x) 在统计

学中被称为

分对数（logit），但这

个函数在机

器学习中很

少用到。

式 (3.41)

为

函数名 “softplus’’ 提供

了其他的正

当理由。softplus 函数

被设计成

正

部函数（positive part function）的平

滑版本，这个

正部函数是

指 x

+ = max{0, x}。

与正部函

数相对的是

负部函数（negative part function）x

−

= max{0, −x}。为

了获

得类似

负部函数的

一个平滑函

数，我们可以

使用

ζ(−x)。就像 x 可

以用它的正

部和

负部通

过等式

x

+ − x

− = x 恢复

一样，我们也

可以用同样

的方式对

ζ(x) 和

ζ(−x)

进行操作，就

像式 (3.41)

中那样

。

3.11 贝叶斯规则

我们经常会

需要在已知

P(y |

x) 时计算 P(x |

y)。幸运

的是，如果还

知道 P(x)，

我们可

以用 贝叶斯

规则（Bayes’

rule）来实现

这一目的：

P(x | y)

= P(x)P(y | x)

P(y)

. (3.42)

注

意到

P(y) 出现在

上面的公式

中，它通常使

用 P(y) =

∑

x P(y |

x)P(x) 来计算，

所

以我们并不

需要事先知

道 P(y)

的信息。

64 第

三章 概率与

信息论

贝叶

斯规则可以

从条件概率

的定义直接

推导得出，但

我们最好记

住这个公式

的

名字，因为

很多文献通

过名字来引

用这个公式

。这个公式是

以牧师 Thomas Bayes

的名

字来命名的

，他是第一个

发现这个公

式特例的人

。这里介绍的

一般形式由

Pierre-Simon Laplace 独立发现。

3.12

连

续型变量的

技术细节

连

续型随机变

量和概率密

度函数的深

入理解需要

用到数学分

支 测度论（measure

theory）的

相关内容来

扩展概率论

。测度论超出

了本书的范

畴，但我们可

以简要勾勒

一些测度论

用来解决的

问题。

在第 3.3.2 节

中，我们已经

看到连续型

向量值随机

变量 x

落在某

个集合 S 中的

概率是通过

p(x) 对集合

S 积分

得到的。对于

集合 S 的一些

选择可能会

引起悖论。例

如，构造两个

集合

S1 和 S2 使得

p(x

∈ S1) + p(x

∈ S2) > 1

并且 S1 ∩ S2

= ∅ 是可能

的。这些集合

通常是大量

使用了实数

的无限精度

来构造的，例

如通过构造

分形形状

(fractal-shaped)

的

集合或者是

通过有理数

相关集合的

变换定义的

集合。3 测度论

的

一个重要

贡献就是提

供了一些集

合的特征使

得我们在计

算概率时不

会遇到悖论

。在

本书中，我

们只对相对

简单的集合

进行积分，所

以测度论的

这个方面不

会成为一个

相关考虑。

对

于我们的目

的，测度论更

多的是用来

描述那些适

用于 R

n 上的大

多数点，却不

适用于一些

边界情况的

定理。测度论

提供了一种

严格的方式

来描述那些

非常微小的

点集。这种集

合被称为

“ 零

测度（measure zero）’’ 的。我们

不会在本书

中给出这个

概念的正式

定义。然而，直

观地理解这

个概念是有

用的，我们可

以认为零测

度集在

我们

的度量空间

中不占有任

何的体积。例

如，在 R

2 空间中

，一条直线的

测度为零，

而

填充的多边

形具有正的

测度。类似的

，一个单独的

点的测度为

零。可数多个

零测

度集的

并仍然是零

测度的 (所以

所有有理数

构成的集合

测度为零)。

另

外一个有用

的测度论中

的术语是

“ 几

乎处处（almost everywhere）’’。某个

性

质如果是

几乎处处都

成立的，那么

它在整个空

间中除了一

个测度为零

的集合以外

都

是成立的

。因为这些例

外只在空间

中占有极其

微小的量，它

们在多数应

用中都可以

被放心地忽

略。概率论中

的一些重要

结果对于离

散值成立但

对于连续值

只能是 ‘‘几

乎

处处’’ 成立。

3Banach-Tarski 定

理给出了这

类集合的一

个有趣的例

子。译者注：我

们这里把 “the set

of rational numbers’’ 翻

译成

‘‘有理数

相关集合’’，理

解为 ‘‘一些有

理数组成的

集合’’，如果直

接用后面的

翻译读起来

会比较拗口

。

3.13 信息论

65

连续

型随机变量

的另一技术

细节，涉及到

处理那种相

互之间有确

定性函数关

系

的连续型

变量。假设我

们有两个随

机变量 x

和 y 满

足 y

= g(x)，其中 g 是可

逆的、

连续可

微的函数。可

能有人会想

py(y) = px(g

−1

(y))。但实际上这

并不对。

举一

个简单的例

子，假设我们

有两个标量

值随机变量

x 和 y，并且满足

y

=

x

2

以及

x ∼ U(0, 1)。如果我

们使用

py(y) = px(2y)，那么

py 除了区间

[0,

1

2

]

以

外都为

0，并且

在这个区间

上的值为 1。这

意味着

∫

py(y)dy =

1

2

, (3.43)

而这

违背了概率

密度的定义

(积分为 1)。这个

常见错误之

所以错是因

为它没有考

虑

到引入函

数 g 后造成的

空间变形。回

忆一下，x 落在

无穷小的体

积为

δx 的区域

内的

概率为

p(x)δx。因为 g

可能会

扩展或者压

缩空间，在 x 空

间内的包围

着 x

的无穷小

体积在 y 空间

中可能有不

同的体积。

为

了看出如何

改正这个问

题，我们回到

标量值的情

况。我们需要

保持下面这

个

性质：

|py(g(x))dy| = |px(x)dx|.

(3.44)

求解

上式，我们得

到

py(y) =

px(g

−1

(y))



∂x

∂y



(3.45)

或者等价

地，

px(x) =

py(g(x))

∂g

∂x

(x)



. (3.46)

在高维空

间中，微分运

算扩展为 Jacobian

矩

阵（Jacobian matrix）的行列式

——

矩阵的每个

元素为 Ji,j

= ∂y

∂xi

j

。因此

，对于实值向

量 x 和 y，

px(x) = py(g(x))



det (

∂g

∂

(

x

x)

)



. (3.47)

3.13

信息论

信息论是应

用数学的一

个分支，主要

研究的是对

一个信号包

含信息的多

少进行

量化

。它最初被发

明是用来研

究在一个含

有噪声的信

道上用离散

的字母表来

发送消

息，例

如通过无线

电传输来通

信。在这种情

况下，信息论

告诉我们如

何对消息设

计

最优编码

以及计算消

息的期望长

度，这些消息

是使用多种

不同编码机

制、从特定

66 第

三章 概率与

信息论

的概

率分布上采

样得到的。在

机器学习中

，我们也可以

把信息论应

用于连续型

变量，

此时某

些消息长度

的解释不再

适用。信息论

是电子工程

和计算机科

学中许多领

域的

基础。在

本书中，我们

主要使用信

息论的一些

关键思想来

描述概率分

布或者量化

概

率分布之

间的相似性

。有关信息论

的更多细节

，参见 Cover

and Thomas (2006) 或

者 MacKay (2003)。

信

息论的基本

想法是一个

不太可能的

事件居然发

生了，要比一

个非常可能

的事

件发生

，能提供更多

的信息。消息

说：‘‘今天早上

太阳升起’’ 信

息量是如此

之少以至

于

没有必要发

送，但一条消

息说：‘‘今天早

上有日食’’ 信

息量就很丰

富。

我们想要

通过这种基

本想法来量

化信息。特别

地，

• 非常可能

发生的事件

信息量要比

较少，并且极

端情况下，确

保能够发生

的事件

应该

没有信息量

。

• 较不可能发

生的事件具

有更高的信

息量。

• 独立事

件应具有增

量的信息。例

如，投掷的硬

币两次正面

朝上传递的

信息量，

应该

是投掷一次

硬币正面朝

上的信息量

的两倍。

为了

满足上述三

个性质，我们

定义一个事

件 x =

x 的 自信息

（self-information）

为

I(x) = − log

P(x). (3.48)

在本书中

，我们总是用

log 来表示自然

对数，其底数

为

e。因此我们

定义的 I(x) 单

位

是

奈特（nats）。一奈

特是以 1

e 的概

率观测到一

个事件时获

得的信息量

。其他的材

料

中使用底数

为 2 的对数，单

位是 比特（bit）或

者

香农（shannons）；通过

比特度

量的

信息只是通

过奈特度量

信息的常数

倍。

当 x

是连续

的，我们使用

类似的关于

信息的定义

，但有些来源

于离散形式

的性

质就丢

失了。例如，一

个具有单位

密度的事件

信息量仍然

为 0，但是不能

保证它一定

发生。

自信息

只处理单个

的输出。我们

可以用

香农

熵（Shannon entropy）来对整个

概

率分布中

的不确定性

总量进行量

化：

H(x)

= Ex∼P [I(x)] =

−Ex∼P [log P(x)], (3.49)

也记作 H(P)。换

言之，一个分

布的香农熵

是指遵循这

个分布的事

件所产生的

期望信

息总

量。它给出了

对依据概率

分布 P

生成的

符号进行编

码所需的比

特数在平均

意义

3.13 信息论

67

上的下界

(当

对数底数不

是 2 时，单位将

有所不同)。那

些接近确定

性的分布 (输

出几

乎可以

确定) 具有较

低的熵；那些

接近均匀分

布的概率分

布具有较高

的熵。图 3.5 给

出

了一个说明

。当 x 是连续的

，香农熵被称

为 微分熵（differential

entropy）。

0.0 0.2 0.4

0.6 0.8 1.0

p

0.0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

图

3.5: 二值随机变

量的香农熵

。该图说明了

更接近确定

性的分布是

如何具有较

低的香农熵

，而更

接近均

匀分布的分

布是如何具

有较高的香

农熵。水平轴

是 p，表示二值

随机变量等

于

1 的概率。熵

由 (p −

1)log(1 − p) −

p log p 给出。当

p 接

近 0 时，分布几

乎是确定的

，因为随机变

量几乎总是

0。当

p 接近 1 时，分

布也几乎是

确定的，因为

随机变量几

乎总是

1。当 p = 0.5

时

，熵是最大的

，

因为分布在

两个结果（0 和

1）上是均匀的

。

如果我们对

于同一个随

机变量

x 有两

个单独的概

率分布 P(x) 和

Q(x)，我

们可

以使用

KL 散度（Kullback-Leibler (KL)

divergence）来衡量

这两个分布

的差异：

DKL(P||Q) = Ex∼P

[

log Q

P(

(

x

x

)

)

]

= Ex∼P

[log P(x) − log

Q(x)]. (3.50)

在离

散型变量的

情况下，KL 散度

衡量的是，当

我们使用一

种被设计成

能够使

得概

率分布 Q 产生

的消息的长

度最小的编

码，发送包含

由概率分布

P 产生的符号

的消息时，所

需要的额外

信息量

(如果

我们使用底

数为 2 的对数

时，信息量用

比特衡

量，但

在机器学习

中，我们通常

用奈特和自

然对数。)

KL 散度

有很多有用

的性质，最重

要的是它是

非负的。KL 散度

为 0

当且仅当

P 和 Q 在离散型

变量的情况

下是相同的

分布，或者在

连续型变量

的情况下是

‘‘几乎

处处’’ 相

同的。因为 KL 散

度是非负的

并且衡量的

是两个分布

之间的差异

，它经常

被用

作分布之间

的某种距离

。然而，它并不

是真的距离

因为它不是

对称的：对于

某

些 P 和

Q，DKL(P||Q) = DKL(Q||P)。这种

非对称性意

味着选择 DKL(P||Q)

还

是

Shannon entropy in

nats

68 第三章 概

率与信息论

DKL(Q||P)

影响很大。更

多细节可以

看图 3.6 。

x

q

∗ = argminqDKL(pk

q)

p(x)

q

∗

(x)

x

q

∗

= argminqDKL(qk p)

p(x)

q

∗

(x)

图

3.6: KL 散度

是不对称的

。假设我们有

一个分布 p(x)，并

且希望用另

一个分布

q(x) 来

近似它。

我们

可以选择最

小化 DKL(p||q)

或最小

化 DKL(q||p)。为了说明

每种选择的

效果，我们令

p 是两

个高斯

分布的混合

，令

q 为单个高

斯分布。选择

使用 KL 散度的

哪个方向是

取决于问题

的。一些

应用

需要这个近

似分布 q 在真

实分布 p

放置

高概率的所

有地方都放

置高概率，而

其他应用需

要这

个近似

分布 q 在真实

分布

p 放置低

概率的所有

地方都很少

放置高概率

。KL 散度方向的

选择反映

了

对于每种应

用，优先考虑

哪一种选择

。(左)

最小化 DKL(p||q) 的

效果。在这种

情况下，我们

选

择一个

q 使

得它在 p 具有

高概率的地

方具有高概

率。当

p 具有多

个峰时，q 选择

将这些峰模

糊到

一起，以

便将高概率

质量放到所

有峰上。(右)

最

小化 DKL(q||p) 的效果

。在这种情况

下，我们选

择

一个

q 使得它

在 p 具有低概

率的地方具

有低概率。当

p

具有多个峰

并且这些峰

间隔很宽时

，如

该图所示

，最小化 KL 散度

会选择单个

峰，以避免将

概率质量放

置在

p 的多个

峰之间的低

概率区

域中

。这里，我们说

明当 q

被选择

成强调左边

峰时的结果

。我们也可以

通过选择右

边峰来得到

KL

散度相同的

值。如果这些

峰没有被足

够强的低概

率区域分离

，那么 KL 散度的

这个方向仍

然可能

选择

模糊这些峰

。

一个和 KL 散度

密切联系的

量是

交叉熵

（cross-entropy）H(P, Q) = H(P)

+

DKL(P||Q)，它和 KL 散度很

像但是缺少

左边一项：

H(P, Q) = −Ex∼P

log Q(x). (3.51)

针

对

Q 最小化交

叉熵等价于

最小化 KL 散度

，因为

Q 并不参

与被省略的

那一项。

当我

们计算这些

量时，经常会

遇到 0

log 0 这个表

达式。按照惯

例，在信息论

中，

我们将这

个表达式处

理为

limx→0 x log x

= 0。

Probability Density

Probability Density

3.14 结构化

概率模型

69

3.14 结

构化概率模

型

机器学习

的算法经常

会涉及到在

非常多的随

机变量上的

概率分布。通

常，这些概

率

分布涉及到

的直接相互

作用都是介

于非常少的

变量之间的

。使用单个函

数来描述

整

个联合概率

分布是非常

低效的 (无论

是计算上还

是统计上)。

我

们可以把概

率分布分解

成许多因子

的乘积形式

，而不是使用

单一的函数

来表

示概率

分布。例如，假

设我们有三

个随机变量

a, b 和 c，并且

a 影响

b 的取值，b 影

响

c 的取值，但是

a 和 c

在给定 b 时

是条件独立

的。我们可以

把全部三个

变量的概

率

分布重新表

示为两个变

量的概率分

布的连乘形

式：

p(a, b, c) =

p(a)p(b | a)p(c |

b). (3.52)

这种分解

可以极大地

减少用来描

述一个分布

的参数数量

。每个因子使

用的参数

数

目是它的变

量数目的指

数倍。这意味

着，如果我们

能够找到一

种使每个因

子分布

具有

更少变量的

分解方法，我

们就能极大

地降低表示

联合分布的

成本。

我们可

以用图来描

述这种分解

。这里我们使

用的是图论

中的 ‘‘图’’ 的概

念：由

一些可

以通过边互

相连接的顶

点的集合构

成。当我们用

图来表示这

种概率分布

的分

解，我们

把它称为 结

构化概率模

型（structured probabilistic

model）或者 图模

型

（graphical model）。

有两种主

要的结构化

概率模型：有

向的和无向

的。两种图模

型都使用图

G，其中

图的每

个节点对应

着一个随机

变量，连接两

个随机变量

的边意味着

概率分布可

以表

示成这

两个随机变

量之间的直

接作用。

有向

（directed）模型使用带

有有向边的

图，它们用条

件概率分布

来表示分解

，

就像上面的

例子。特别地

，有向模型对

于分布中的

每一个随机

变量 xi 都包含

着一个

影响

因子，这个组

成

xi条件概率

的影响因子

被称为 xi 的父

节点，记为 P

aG(xi)：

p(x) = ∏

i

p(xi

| P

aG(xi)). (3.53)

图

3.7 给出了一个

有向图的例

子以及它表

示的概率分

布的分解。

无

向（undirected）模型使用

带有无向边

的图，它们将

分解表示成

一组函数；不

像有向模型

那样，这些函

数通常不是

任何类型的

概率分布。G 中

任何满足两

两之

间有边

连接的顶点

的集合被称

为团。无向模

型中的每个

团 C

(i) 都伴随着

一个因子

ϕ

(i)

(C

(i)

)。这

些因子仅仅

是函数，并不

是概率分布

。每个因子的

输出都必须

是非负

70

第三

章 概率与信

息论

a

c

b

e

d

图

3.7: 关于

随机变量 a, b,

c, d 和

e 的有向图模

型。这幅图对

应的概率分

布可以分解

为

p(a, b, c, d,

e) = p(a)p(b |

a)p(c | a, b)p(d

| b)p(e | c).

(3.54)

该图模型

使我们能够

快速看出此

分布的一些

性质。例如，a 和

c 直接相互影

响，但

a 和 e 只有

通

过 c 间接相

互影响。

的，但

是并没有像

概率分布中

那样要求因

子的和或者

积分为

1。

随机

变量的联合

概率与所有

这些因子的

乘积 成比例

（proportional）——意味着

因子

的值越大则

可能性越大

。当然，不能保

证这种乘积

的求和为

1。所

以我们需要

除

以一个归

一化常数 Z 来

得到归一化

的概率分布

，归一化常数

Z

被定义为 ϕ 函

数乘

积的所

有状态的求

和或积分。概

率分布为：

p(x) =

Z

1

∏

i

ϕ

(i)

(

C

(i)

)

. (3.55)

图

3.8 给出了一个

无向图的例

子以及它表

示的概率分

布的分解。

请

记住，这些图

模型表示的

分解仅仅是

描述概率分

布的一种语

言。它们不是

互

相排斥的

概率分布族

。有向或者无

向不是概率

分布的特性

；它是概率分

布的一种特

殊 描述（description）所具

有的特性，而

任何概率分

布都可以用

这两种方式

进行描

述。

在

本书第一部

分和第二部

分中，我们仅

仅将结构化

概率模型视

作一门语言

，来

描述不同

的机器学习

算法选择表

示的直接的

概率关系。在

讨论研究课

题之前，读者

不需要更深

入地理解结

构化概率模

型。在第三部

分的研究课

题中，我们将

更为详尽

地

探讨结构化

概率模型。

本

章复习了概

率论中与深

度学习最为

相关的一些

基本概念。我

们还剩下一

些基

3.14 结构化

概率模型 71

a

c

b

e

d

图

3.8: 关于随机变

量 a, b,

c, d 和 e

的无向

图模型。这幅

图对应的概

率分布可以

分解为

p(a, b, c,

d, e) = 1

Z

ϕ

(1)(a, b,

c)ϕ

(2)(b, d)ϕ

(3)(c,

e). (3.56)

该图

模型使我们

能够快速看

出此分布的

一些性质。例

如，a 和

c 直接相

互影响，但 a 和

e

只有通

过 c 间

接相互影响

。

本的数学工

具需要讨论

：数值方法。

第

四章 数值计

算

机器学习

算法通常需

要大量的数

值计算。这通

常是指通过

迭代过程更

新解的估

计

值来解决数

学问题的算

法，而不是通

过解析过程

推导出公式

来提供正确

解的方法。

常

见的操作包

括优化（找到

最小化或最

大化函数值

的参数）和线

性方程组的

求解。

对数字

计算机来说

实数无法在

有限内存下

精确表示，因

此仅仅是计

算涉及实数

的函

数也是

困难的。

4.1 上溢

和下溢

连续

数学在数字

计算机上的

根本困难是

，我们需要通

过有限数量

的位模式来

表

示无限多

的实数。这意

味着我们在

计算机中表

示实数时，几

乎总会引入

一些近似误

差。在许多情

况下，这仅仅

是舍入误差

。舍入误差会

导致一些问

题，特别是当

许多

操作复

合时，即使是

理论上可行

的算法，如果

在设计时没

有考虑最小

化舍入误差

的

累积，在实

践时也可能

会导致算法

失效。

一种极

具毁灭性的

舍入误差是

下溢（underflow）。当接近

零的数被四

舍五入为

零

时发生下溢

。许多函数在

其参数为零

而不是一个

很小的正数

时才会表现

出质的不

同

。例如，我们通

常要避免被

零除（一些软

件环境将在

这种情况下

抛出异常，有

些

会返回一

个非数字 (not-a-number, NaN)

的

占位符）或避

免取零的对

数（这通常被

视为 −∞，进一步

的算术运算

会使其变成

非数字）。

另一

个极具破坏

力的数值错

误形式是 上

溢（overflow）。当大量级

的数被近似

为

∞ 或 −∞ 时发生

上溢。进一步

的运算通常

会导致这些

无限值变为

非数字。

必须

对上溢和下

溢进行数值

稳定的一个

例子是 softmax 函数

（softmax func-

72

4.2 病态条件 73

tion）。softmax 函

数经常用于

预测与 Multinoulli 分布

相关联的概

率，定义为

softmax(x)i =

exp(xi)

∑n

j=1 exp(xj )

.

(4.1)

考

虑一下当所

有 xi 都等于某

个常数

c 时会

发生什么。从

理论分析上

说，我们可以

发

现所有的

输出都应该

为 n

1。从数值计

算上说，当 c 量

级很大时，这

可能不会发

生。如

果

c 是很

小的负数，exp(c) 就

会下溢。这意

味着 softmax

函数的

分母会变成

0，所以

最后的

结果是未定

义的。当 c 是非

常大的正数

时，exp(c)

的上溢再

次导致整个

表达

式未定

义。这两个困

难能通过计

算 softmax(z) 同时解决

，其中

z = x −

maxi xi。简

单的

代数计算表

明，softmax 解析上的

函数值不会

因为从输入

向量减去或

加上标量

而

改变。减去 maxi xi 导

致

exp 的最大参

数为 0，这排除

了上溢的可

能性。同样地

，

分母中至少

有一个值为

1

的项，这就排

除了因分母

下溢而导致

被零除的可

能性。

还有一

个小问题。分

子中的下溢

仍可以导致

整体表达式

被计算为零

。这意味着，

如

果我们在计

算 log

softmax(x) 时，先计算

softmax 再把结果传

给 log

函数，会错

误地得到 −∞。相

反，我们必须

实现一个单

独的函数，并

以数值稳定

的方式计算

log softmax。我们可以使

用相同的技

巧来稳定 log

softmax 函

数。

在大多数

情况下，我们

没有明确地

对本书描述

的各种算法

所涉及的数

值考虑进

行

详细说明。底

层库的开发

者在实现深

度学习算法

时应该牢记

数值问题。本

书的大

多数

读者可以简

单地依赖保

证数值稳定

的底层库。在

某些情况下

，我们有可能

在实

现一个

新的算法时

自动保持数

值稳定。Theano (Bergstra et

al., 2010a; Bastien et

al.,

2012a) 就是

这样软件包

的一个例子

，它能自动检

测并稳定深

度学习中许

多常见的数

值不稳定的

表达式。

4.2

病态

条件

条件数

表征函数相

对于输入的

微小变化而

变化的快慢

程度。输入被

轻微扰动而

迅速改变的

函数对于科

学计算来说

可能是有问

题的，因为输

入中的舍入

误差可能导

致输出的巨

大变化。

考虑

函数 f(x)

= A

−1

x。当

A ∈ R

n×n

具有

特征值分解

时，其条件数

为

max

i,j



λi

λj



. (4.2)

74

第四章 数

值计算

这是

最大和最小

特征值的模

之比1。当该数

很大时，矩阵

求逆对输入

的误差特别

敏感。

这种敏

感性是矩阵

本身的固有

特性，而不是

矩阵求逆期

间舍入误差

的结果。即

使

我们乘以完

全正确的矩

阵逆，病态条

件的矩阵也

会放大预先

存在的误差

。在实践

中，该

错误将与求

逆过程本身

的数值误差

进一步复合

。

4.3 基于梯度的

优化方法

大

多数深度学

习算法都涉

及某种形式

的优化。优化

指的是改变

x 以最小化或

最

大化某个

函数 f(x)

的任务

。我们通常以

最小化 f(x) 指代

大多数最优

化问题。最大

化可经由最

小化算法最

小化 −f(x)

来实现

。

我们把要最

小化或最大

化的函数称

为 目标函数

（objective function）或

准则

（criterion）。当我

们对其进行

最小化时，我

们也把它称

为 代价函数

（cost function）、

损失函数（loss function）或

误差函数（error function）。虽

然有些机器

学习著作赋

予这些名称

特殊的意义

，但在这本书

中我们交替

使用这些术

语。

我们通常

使用一个上

标

∗ 表示最小

化或最大化

函数的 x 值。如

我们记

x

∗ =

arg

min f(x)。

我们

假设读者已

经熟悉微积

分，这里简要

回顾微积分

概念如何与

优化联系。

假

设我们有一

个函数

y = f(x)，其中

x 和

y 是实数。这

个函数的 导

数（derivative）

记为

f

′

(x) 或

dx

dy。导

数 f

′

(x) 代表 f(x) 在点

x

处的斜率。换

句话说，它表

明如何缩

放

输入的小变

化才能在输

出获得相应

的变化：f(x + ϵ)

≈ f(x) + ϵf′

(x)。

因此

导数对于最

小化一个函

数很有用，因

为它告诉我

们如何更改

x 来略微地改

善 y。例如，我们

知道对于足

够小的

ϵ 来说

，f(x − ϵsign(f

′

(x))) 是比 f(x)

小的。因

此我们可以

将 x 往导数的

反方向移动

一小步来减

小 f(x)。这种技术

被称为

梯度

下降

（gradient descent）(Cauchy, 1847)。图

4.1 展示

了一个例子

。

当 f

′

(x) = 0，导数无法

提供往哪个

方向移动的

信息。f

′

(x) = 0

的点称

为 临界

点（critical point）或

驻点（stationary

point）。一个 局

部极小点（local minimum）

意

味着这个点

的

f(x) 小于所有

邻近点，因此

不可能通过

移动无穷小

的步长来减

小

f(x)。一个 局部

极大点（local

maximum）意味

着这个点的

f(x) 大于所有邻

近点，因

此不

可能通过移

动无穷小的

步长来增大

f(x)。有些临界点

既不是最小

点也不是最

大

1译者注：与

通常的条件

数定义有所

不同。

4.3 基于梯

度的优化方

法 75

−2.0

−1.5 −1.0 −0.5 0.0

0.5 1.0 1.5 2.0

x

−2.0

−1.5

−1.0

−0.5

0.0

0.5

1.0

1.5

2.0

Global minimum

at x = 0.

Since f

0 (x)

= 0, gradient

descent

halts here.

For x

< 0, we have

f

0 (x) <

0,

so we can

decrease f by

moving

rightward.

For x >

0, we have f

0 (x) > 0,

so we can decrease

f by

moving leftward.

f(x) = 1

2

x

2

f

0

(x) = x

图

4.1: 梯度下

降。梯度下降

算法如何使

用函数导数

的示意图，即

沿着函数的

下坡方向（导

数反方

向）直

到最小。

点。这

些点被称为

鞍点（saddle

point）。见图4.2 给

出的各种临

界点的例子

。

Minimum Maximum

Saddle point 图 4.2:

临界点的

类型。一维情

况下，三种临

界点的示例

。临界点是斜

率为零的点

。这样的点可

以

是 局部极

小点（local minimum），其值低

于相邻点;

局

部极大点（local maximum），其

值高于相

邻

点; 或鞍点，同

时存在更高

和更低的相

邻点。

使 f(x) 取得

绝对的最小

值（相对所有

其他值）的点

是 全局最小

点（global

76 第四章 数

值计算

minimum）。函数

可能只有一

个全局最小

点或存在多

个全局最小

点，还可能存

在不是

全局

最优的局部

极小点。在深

度学习的背

景下，我们要

优化的函数

可能含有许

多不

是最优

的局部极小

点，或者还有

很多处于非

常平坦的区

域内的鞍点

。尤其是当输

入

是多维的

时候，所有这

些都将使优

化变得困难

。因此，我们通

常寻找使 f

非

常小的

点，但

这在任何形

式意义下并

不一定是最

小。见图 4.3 的例

子。

x

Ideally, we would

like

to arrive at

the global

minimum, but

this

might not be

possible.

This local minimum

performs nearly as well

as

the global one,

so it is an

acceptable

halting point.

This

local minimum performs

poorly

and should be avoided.

图 4.3: 近似最

小化。当存在

多个局部极

小点或平坦

区域时，优化

算法可能无

法找到全局

最小点。

在深

度学习的背

景下，即使找

到的解不是

真正最小的

，但只要它们

对应于代价

函数显著低

的值，我

们通

常就能接受

这样的解。

我

们经常最小

化具有多维

输入的函数

：f : R

n → R。为了使 ‘‘最小

化’’

的概念有

意义，输出必

须是一维的

(标量)。

针对具

有多维输入

的函数，我们

需要用到 偏

导数（partial derivative）的概念

。

偏导数 ∂

∂

xi

f(x) 衡量

点 x 处只有

xi 增

加时 f(x) 如何变

化。

梯度（gradient）是相

对一个向量

求导的导数

:f 的导数是包

含所有偏导

数的向量，记

为 ∇xf(x)。梯度的第

i 个元素是

f 关

于 xi 的偏导数

。在多维情况

下，临界点是

梯度中所有

元素都为零

的

点。

在 u（单位

向量）方向的

方向导数（directional derivative）是

函数

f 在 u 方向

的斜率。换句

话说，方向导

数是函数

f(x + αu) 关

于

α 的导数（在

α = 0

时取得）。

使用

链式法则，我

们可以看到

当 α =

0 时，∂α

∂

f(x

+ αu) = u

⊤∇xf(x)。

f(x)

4.3 基于梯

度的优化方

法

77

为了最小

化 f，我们希望

找到使 f

下降

得最快的方

向。计算方向

导数：

min

u,u⊤u=1

u

⊤∇xf(x) (4.3)

= min

u,u⊤u=1

∥u∥2∥∇xf(x)∥2 cos θ

(4.4)

其中 θ 是

u

与梯度的夹

角。将 ∥u∥2 = 1

代入，并

忽略与 u 无关

的项，就能简

化得

到

min

u

cos θ。这在

u

与梯度方向

相反时取得

最小。换句话

说，梯度向量

指向上坡，

负

梯度向量指

向下坡。我们

在负梯度方

向上移动可

以减小 f。这被

称为最速下

降法

(method

of steepest descent) 或

梯度

下降（gradient descent）。

最速下

降建议新的

点为

x

′ = x −

ϵ∇xf(x) (4.5)

其中 ϵ

为

学习率（learning rate），是一

个确定步长

大小的正标

量。我们可以

通过几

种不

同的方式选

择 ϵ。普遍的方

式是选择一

个小常数。有

时我们通过

计算，选择使

方

向导数消

失的步长。还

有一种方法

是根据几个

ϵ 计算 f(x −

ϵ∇xf(x))，并选择

其中

能产生

最小目标函

数值的 ϵ。这种

策略被称为

线搜索。

最速

下降在梯度

的每一个元

素为零时收

敛（或在实践

中，很接近零

时）。在某些

情

况下，我们也

许能够避免

运行该迭代

算法，并通过

解方程 ∇xf(x) = 0

直接

跳到临

界点

。

虽然梯度下

降被限制在

连续空间中

的优化问题

，但不断向更

好的情况移

动一小

步（即

近似最佳的

小移动）的一

般概念可以

推广到离散

空间。递增带

有离散参数

的目标函数

被称为

爬山

（hill climbing）算法 (Russel and

Norvig, 2003)。

4.3.1 梯度之

上：Jacobian

和 Hessian 矩阵

有

时我们需要

计算输入和

输出都为向

量的函数的

所有偏导数

。包含所有这

样的

偏导数

的矩阵被称

为 Jacobian 矩阵。具体

来说，如果我

们有一个函

数：f :

R

m → R

n，

f 的 Jacobian

矩阵 J ∈ R

n×m 定

义为 Ji,j =

∂

∂

xj

f(x)i。

有时，我

们也对导数

的导数感兴

趣，即 二阶导

数（second derivative）。例如，有

一

个函数

f : R

m

→ R，f 的一

阶导数(关于

xj )

关于 xi 的导数

记为 ∂

2

∂xi∂xj

f。在一维

情况下，我们

可以将 ∂

∂

x

2

2

f 为 f

′′(x)。二

阶导数告诉

我们，一阶导

数将如何随

着输入

的变

化而改变。它

表示只基于

梯度信息的

梯度下降步

骤是否会产

生如我们预

期的那

78 第四

章 数值计算

样大的改善

，因此它是重

要的。我们可

以认为，二阶

导数是对曲

率的衡量。假

设我

们有一

个二次函数

（虽然很多实

践中的函数

都不是二次

的，但至少在

局部可以很

好

地用二次

近似）。如果这

样的函数具

有零二阶导

数，那就没有

曲率。也就是

一条完全

平

坦的线，仅用

梯度就可以

预测它的值

。我们使用沿

负梯度方向

大小为 ϵ

的下

降步，

当该梯

度是 1 时，代价

函数将下降

ϵ。如果二阶导

数是负的，函

数曲线向下

凹陷

(向

上凸

出)，因此代价

函数将下降

的比 ϵ 多。如果

二阶导数是

正的，函数曲

线是向上凹

陷

(向下凸出

)，因此代价函

数将下降的

比 ϵ 少。从图4.4 可

以看出不同

形式的曲率

如

何影响基

于梯度的预

测值与真实

的代价函数

值的关系。

x

Negative curvature

x

No curvature

x

Positive curvature

图

4.4: 二阶导数确

定函数的曲

率。这里我们

展示具有各

种曲率的二

次函数。虚线

表示我们仅

根据

梯度信

息进行梯度

下降后预期

的代价函数

值。对于负曲

率，代价函数

实际上比梯

度预测下降

得更

快。没有

曲率时，梯度

正确预测下

降值。对于正

曲率，函数比

预期下降得

更慢，并且最

终会开始增

加，因此太大

的步骤实际

上可能会无

意地增加函

数值。

当我们

的函数具有

多维输入时

，二阶导数也

有很多。我们

可以将这些

导数合并

成

一个矩阵，称

为

Hessian 矩阵。Hessian 矩阵

H(f)(x) 定义为

H(f)(x)i,j =

∂

2

∂xi∂xj

f(x). (4.6)

Hessian

等价

于梯度的 Jacobian 矩

阵。

微分算子

在任何二阶

偏导连续的

点处可交换

，也就是它们

的顺序可以

互换：

∂

2

∂xi∂xj

f(x)

= ∂

2

∂xj∂xi

f(x). (4.7) f(x)

f(x)

f(x)

4.3 基于梯

度的优化方

法 79

这意味着

Hi,j = Hj,i，因此 Hessian

矩阵在

这些点上是

对称的。在深

度学习背景

下，

我们遇到

的大多数函

数的 Hessian 几乎处

处都是对称

的。因为

Hessian 矩阵

是实对

称的

，我们可以将

其分解成一

组实特征值

和一组特征

向量的正交

基。在特定方

向 d

上的二阶

导数可以写

成 d

⊤Hd。当 d

是 H 的一

个特征向量

时，这个方向

的二阶导

数

就是对应的

特征值。对于

其他的方向

d，方向二阶导

数是所有特

征值的加权

平均，

权重在

0 和 1 之间，且与

d

夹角越小的

特征向量的

权重越大。最

大特征值确

定最

大二阶

导数，最小特

征值确定最

小二阶导数

。

我们可以通

过（方向）二阶

导数预期一

个梯度下降

步骤能表现

得多好。我们

在

当前点

x

(0) 处

作函数 f(x)

的近

似二阶泰勒

级数：

f(x) ≈ f(x

(0)) + (x −

x

(0))

⊤g +

1

2

(x −

x

(0))

⊤H(x −

x

(0)), (4.8)

其中

g 是

梯度，H 是 x

(0) 点的

Hessian。如果我们使

用学习率 ϵ，那

么新的点 x

将

会是 x

(0) −

ϵg。代入上

述的近似，可

得

f(x

(0) −

ϵg) ≈ f(x

(0))

− ϵg

⊤g +

1

2

ϵ

2

g

⊤Hg. (4.9)

其中有

3 项

：函数的原始

值、函数斜率

导致的预期

改善、函数曲

率导致的校

正。当

最后一

项太大时，梯

度下降实际

上是可能向

上移动的。当

g

⊤Hg

为零或负时

，近似

的泰勒

级数表明增

加 ϵ 将永远使

f

下降。在实践

中，泰勒级数

不会在 ϵ 大的

时候也

保持

准确，因此在

这种情况下

我们必须采

取更启发式

的选择。当

g

⊤Hg 为

正时，通

过计

算可得，使近

似泰勒级数

下降最多的

最优步长为

ϵ

∗ =

g

⊤g

g⊤Hg. (4.10)

最坏的情况

下，g 与

H 最大特

征值 λmax 对应的

特征向量对

齐，则最优步

长是

λ

1

max。

我们要

最小化的函

数能用二次

函数很好地

近似的情况

下，Hessian

的特征值

决定了学

习

率的量级。

二

阶导数还可

以被用于确

定一个临界

点是否是局

部极大点、局

部极小点或

鞍点。

回想一

下，在临界点

处

f

′

(x) =

0。而 f

′′(x) >

0 意味着

f

′

(x)

会随着我们

移向右边

而

增加，移向左

边而减小，也

就是 f

′

(x − ϵ) <

0 和 f

′

(x + ϵ) >

0 对足

够小的 ϵ 成立

。

换句话说，当

我们移向右

边，斜率开始

指向右边的

上坡，当我们

移向左边，斜

率开

始指向

左边的上坡

。因此我们得

出结论，当 f

′

(x) = 0 且

f

′′(x) > 0 时，x

是一个局

部极小点。同

样，当 f

′

(x)

= 0 且 f

′′(x) < 0 时，x

是

一个局部极

大点。这就是

所谓

80 第四章

数值计算

的

二阶导数测

试（second

derivative test）。不幸的是

，当 f

′′(x)

= 0 时测试是

不确

定的。在

这种情况下

，x

可以是一个

鞍点或平坦

区域的一部

分。

在多维情

况下，我们需

要检测函数

的所有二阶

导数。利用 Hessian 的

特征值分

解

，我们可以将

二阶导数测

试扩展到多

维情况。在临

界点处（∇xf(x) = 0），我们

通

过检测

Hessian 的

特征值来判

断该临界点

是一个局部

极大点、局部

极小点还是

鞍点。

当 Hessian

是正

定的（所有特

征值都是正

的），则该临界

点是局部极

小点。因为方

向二阶导数

在任意方向

都是正的，参

考单变量的

二阶导数测

试就能得出

此结论。同

样

的，当 Hessian 是负定

的（所有特征

值都是负的

），这个点就是

局部极大点

。在多

维情况

下，实际上我

们可以找到

确定该点是

否为鞍点的

积极迹象（某

些情况下）。如

果 Hessian 的特征值

中至少一个

是正的且至

少一个是负

的，那么 x

是 f 某

个横截面

的

局部极大点

，却是另一个

横截面的局

部极小点。见

图

4.5 中的例子

。最后，多维二

阶导数测试

可能像单变

量版本那样

是不确定的

。当所有非零

特征值是同

号的且至少

有一个特征

值是 0 时，这个

检测就是不

确定的。这是

因为单变量

的二阶导数

测试在

零特

征值对应的

横截面上是

不确定的。

−15 0

15

−15

0

15

−500

0

500

图

4.5: 既有正曲率

又有负曲率

的鞍点。示例

中的函数是

f(x)

= x

2

1

− x

2

2。函数沿

x1 轴向

上弯

曲。x1 轴是

Hessian

的一个特征

向量，并且具

有正特征值

。函数沿 x2 轴向

下弯曲。该方

向对应

于

Hessian 负

特征值的特

征向量。名称

“鞍点’’ 源自该

处函数的鞍

状形状。这是

具有鞍点函

数的典

型示

例。维度多于

一个时，鞍点

不一定要具

有

0 特征值：仅

需要同时具

有正特征值

和负特征值

。我

们可以想

象这样一个

鞍点（具有正

负特征值）在

一个横截面

内是局部极

大点，而在另

一个横截面

内是局部极

小点。

多维情

况下，单个点

处每个方向

上的二阶导

数是不同。Hessian

的

条件数衡量

这些二阶导

数的变化范

围。当 Hessian 的条件

数很差时，梯

度下降法也

会表现得很

x2

f(x

;x ) 1 2

x1

4.3 基于梯度的

优化方法 81

差

。这是因为一

个方向上的

导数增加得

很快，而在另

一个方向上

增加得很慢

。梯度

下降不

知道导数的

这种变化，所

以它不知道

应该优先探

索导数长期

为负的方向

。病

态条件也

导致很难选

择合适的步

长。步长必须

足够小，以免

冲过最小而

向具有较强

正曲率的方

向上升。这通

常意味着步

长太小，以致

于在其他较

小曲率的方

向上进展

不

明显。见图

4.6 的

例子。

−30 −20

−10 0 10 20

x1

−30

−20

−10

0

10

20

图

4.6: 梯度

下降无法利

用包含在 Hessian 矩

阵中的曲率

信息。这里我

们使用梯度

下降来最小

化

Hessian 矩阵条件

数为 5 的二次

函数

f(x)。这意味

着最大曲率

方向具有比

最小曲率方

向多五倍

的

曲率。在这种

情况下，最大

曲率在 [1, 1]⊤

方向

上，最小曲率

在 [1, −1]⊤ 方向上。红

线表示梯度

下降的路径

。这个非常细

长的二次函

数类似一个

长峡谷。梯度

下降把时间

浪费于在峡

谷壁反复下

降，因为它们

是最陡峭的

特征。由于步

长有点大，有

超过函数底

部的趋势，因

此需要在下

一次迭代

时

在对面的峡

谷壁下降。与

指向该方向

的特征向量

对应的 Hessian 的大

的正特征值

表示该方向

上

的导数快

速增加，因此

基于

Hessian 的优化

算法可以预

测，在此情况

下最陡峭方

向实际上不

是有

前途的

搜索方向。

我

们可以使用

Hessian

矩阵的信息

来指导搜索

，以解决这个

问题。其中最

简单

的方法

是 牛顿法（Newton’s method）。牛

顿法基于一

个二阶泰勒

展开来近似

x

(0) 附

近的 f(x)：

f(x) ≈ f(x

(0))

+ (x − x

(0))

⊤∇xf(x

(0)) +

1

2

(x −

x

(0))

⊤H(f)(x

(0))(x

− x

(0)). (4.11)

接着

通过计算，我

们可以得到

这个函数的

临界点：

x

∗ =

x

(0) − H(f)(x

(0))

−1∇xf(x

(0)). (4.12)

当 f 是

一个正定二

次函数时，牛

顿法只要应

用一次式 (4.12)

就

能直接跳到

函数的最

小

点。如果 f 不是

一个真正二

次但能在局

部近似为正

定二次，牛顿

法则需要多

次迭

x2

82 第四章

数值计算

代

应用式

(4.12) 。迭代

地更新近似

函数和跳到

近似函数的

最小点可以

比梯度下降

更

快地到达

临界点。这在

接近局部极

小点时是一

个特别有用

的性质，但是

在鞍点附近

是有害的。如

式(8.2.3) 所讨论的

，当附近的临

界点是最小

点（Hessian

的所有特

征值

都是正

的）时牛顿法

才适用，而梯

度下降不会

被吸引到鞍

点(除非梯度

指向鞍点)。

仅

使用梯度信

息的优化算

法被称为 一

阶优化算法

(first-order

optimization al￾gorithms)，如梯度下降

。使用 Hessian 矩阵的

优化算法被

称为

二阶最

优化算法

(second-order optimization algorithms)(Nocedal

and Wright, 2006)，如

牛顿法。

在本

书大多数上

下文中使用

的优化算法

适用于各种

各样的函数

，但几乎都没

有

保证。因为

在深度学习

中使用的函

数族是相当

复杂的，所以

深度学习算

法往往缺乏

保证。在许多

其他领域，优

化的主要方

法是为有限

的函数族设

计优化算法

。

在深度学习

的背景下，限

制函数满足

Lipschitz 连续（Lipschitz continuous）或

其导

数Lipschitz连续可以

获得一些保

证。Lipschitz 连续函数

的变化速度

以 Lipschitz

常数（Lipschitz

constant）L 为界

：

∀x, ∀y,

|f(x) − f(y)| ≤

L∥x − y∥2. (4.13)

这个属性允

许我们量化

我们的假设

——梯度下降等

算法导致的

输入的微小

变化将使

输

出只产生微

小变化，因此

是很有用的

。Lipschitz 连续性也是

相当弱的约

束，并

且深度

学习中很多

优化问题经

过相对较小

的修改后就

能变得

Lipschitz 连续

。

最成功的特

定优化领域

或许是 凸优

化（Convex

optimization）。凸优化通

过更强

的限

制提供更多

的保证。凸优

化算法只对

凸函数适用

，即 Hessian 处处半正

定的函

数。因

为这些函数

没有鞍点而

且其所有局

部极小点必

然是全局最

小点，所以表

现很

好。然而

，深度学习中

的大多数问

题都难以表

示成凸优化

的形式。凸优

化仅用作一

些深度学习

算法的子程

序。凸优化中

的分析思路

对证明深度

学习算法的

收敛性非常

有用，然而一

般来说，深度

学习背景下

凸优化的重

要性大大减

少。有关凸优

化的详

细信

息，详见 Boyd

and Vandenberghe (2004) 或

Rockafellar (1997)。

4.4 约

束优化

有时

候，在 x 的所有

可能值下最

大化或最小

化一个函数

f(x) 不是我们所

希望

的。相反

，我们可能希

望在 x 的某些

集合 S

中找 f(x) 的

最大值或最

小值。这被称

为 约束优化

（constrained

optimization）。在约束优化

术语中，集合

S 内的点 x 被称

4.4

约束优化 83

为

可行（feasible）点。

我们

常常希望找

到在某种意

义上小的解

。针对这种情

况下的常见

方法是强加

一

个范数约

束，如 ∥x∥ ≤ 1。

约束优

化的一个简

单方法是将

约束考虑在

内后简单地

对梯度下降

进行修改。如

果我们使用

一个小的恒

定步长 ϵ，我们

可以先取梯

度下降的单

步结果，然后

将结果投

影

回 S。如果我们

使用线搜索

，我们只能在

步长为

ϵ 范围

内搜索可行

的新 x 点，或者

我们可以将

线上的每个

点投影到约

束区域。如果

可能的话，在

梯度下降或

线搜索前

将

梯度投影到

可行域的切

空间会更高

效 (Rosen, 1960)。

一个更复

杂的方法是

设计一个不

同的、无约束

的优化问题

，其解可以转

化成原

始约

束优化问题

的解。例如，我

们要在 x ∈ R

2 中最

小化 f(x)，其中 x

约

束为具有单

位 L

2 范数。我们

可以关于

θ 最

小化 g(θ) =

f([cos θ,sin θ]

⊤)，最后返

回

[cos θ,sin θ]

作为原问

题的解。这种

方法需要创

造性；优化问

题之间的转

换必须专门

根据我们遇

到的每一种

情况进行设

计。

Karush–Kuhn–Tucker（KKT）方法2是针

对约束优化

非常通用的

解决方案。

为

介绍KKT方法，我

们引入一个

称为 广义 Lagrangian（generalized

Lagrangian）

或

广义 Lagrange 函数（generalized

Lagrange function）的

新函数。

为了

定义Lagrangian，我们先

要通过等式

和不等式的

形式描述 S。我

们希望通

过

m 个函数 g

(i)

和 n 个

函数 h

(j) 描述 S，那

么 S

可以表示

为 S = {x

| ∀i, g(i)

(x)

=

0 and ∀j,

h(j)

(x) ≤ 0}。其中涉及

g

(i) 的等式称为

等式约束（equality constraint），

涉

及

h

(j) 的不等式

称为 不等式

约束（inequality

constraint）。

我们为

每个约束引

入新的变量

λi 和 αj，这些新变

量被称为

KKT 乘

子。广义

Lagrangian 可以

如下定义：

L(x,λ, α) = f(x)

+∑

i

λig

(i)

(x) +∑

j

αjh

(j)

(x). (4.14)

现

在，我们可以

通过优化无

约束的广义

Lagrangian

解决约束最

小化问题。只

要

存在至少

一个可行点

且 f(x) 不允许取

∞，那么

min

x

max

λ

max

α,α≥0

L(x,λ, α)

(4.15)

2KKT 方法是

Lagrange 乘子法（只允

许等式约束

）的推广。

84 第四

章 数值计算

与如下函数

有相同的最

优目标函数

值和最优点

集 x

min

x∈S

f(x). (4.16)

这是因为

当约束满足

时，

max

λ

max

α,α≥0

L(x,λ, α) =

f(x), (4.17)

而违反任

意约束时，

max

λ

max

α,α≥0

L(x,λ,

α) = ∞. (4.18)

这

些性质保证

不可行点不

会是最佳的

，并且可行点

范围内的最

优点不变。

要

解决约束最

大化问题，我

们可以构造

−f(x) 的广义 Lagrange

函数

，从而导

致以

下优化问题

：

min

x

max

λ

max

α,α≥0

− f(x) +∑

i

λig

(i)

(x) +∑

j

αjh

(j)

(x).

(4.19)

我们也可将

其转换为在

外层最大化

的问题：

max

x

min

λ

min

α,α≥0

f(x) +∑

i

λig

(i)

(x) −

∑

j

αjh

(j)

(x).

(4.20)

等式

约束对应项

的符号并不

重要；因为优

化可以自由

选择每个 λi 的

符号，我们可

以

随意将其

定义为加法

或减法。

不等

式约束特别

有趣。如果 h

(i)

(x

∗

) =

0，我

们就说这个

约束 h

(i)

(x)

是活跃

(active) 的。如果约束

不是活跃的

，则有该约束

的问题的解

与去掉该约

束的问题的

解至少存在

一个相同的

局部解。一个

不活跃约束

有可能排除

其他解。例如

，整个区

域（代

价相等的宽

平区域）都是

全局最优点

的凸问题可

能因约束消

去其中的某

个子

区域，或

在非凸问题

的情况下，收

敛时不活跃

的约束可能

排除了较好

的局部驻点

。

然而，无论不

活跃的约束

是否被包括

在内，收敛时

找到的点仍

然是一个驻

点。因为

一个

不活跃的约

束 h

(i)

必有负值

，那么 min

x

max

λ

max

α,α≥0

L(x,λ,

α) 中的 αi =

0。因

此，我们可以

观察到在该

解中 α ⊙ h(x)

= 0。换句话

说，对于所有

的 i，αi ≥

0 或

h

(j)

(x) ≤ 0 在收敛

时必有一个

是活跃的。为

了获得关于

这个想法的

一些直观解

释，

我们可以

说这个解是

由不等式强

加的边界，我

们必须通过

对应的 KKT 乘子

影响 x

的解，或

者不等式对

解没有影响

，我们则归零

KKT 乘子。

4.5 实例：线

性最小二乘

85

我们可以使

用一组简单

的性质来描

述约束优化

问题的最优

点。这些性质

称

为 Karush–Kuhn–Tucker（KKT）条件 (Karush,

1939; Kuhn and Tucker,

1951)。

这

些是确定一

个点是最优

点的必要条

件，但不一定

是充分条件

。这些条件是

：

• 广义

Lagrangian 的梯度

为零。

• 所有关

于

x 和 KKT 乘子的

约束都满足

。

• 不等式约束

显示的 ‘‘互补

松弛性’’：α ⊙

h(x) = 0。

有关

KKT

方法的详细

信息，请参阅

Nocedal and Wright (2006)。

4.5 实例：线性最

小二乘

假设

我们希望找

到最小化下

式的 x

值

f(x) = 1

2

∥Ax − b∥

2

2

. (4.21)

存在

专门的线性

代数算法能

够高效地解

决这个问题

；但是，我们也

可以探索如

何使

用基于

梯度的优化

来解决这个

问题，这可以

作为这些技

术是如何工

作的一个简

单例

子。

首先

，我们计算梯

度：

∇xf(x) = A

⊤

(Ax − b) =

A

⊤Ax − A

⊤

b. (4.22)

然后，我们

可以采用小

的步长，并按

照这个梯度

下降。见算法

4.1

中的详细信

息。

算法 4.1 从任

意点

x 开始，使

用梯度下降

关于 x 最小化

f(x)

= 1

2

||Ax

− b||2

2 的算

法。

将步

长 (ϵ) 和容差

(δ) 设

为小的正数

。

while ||A

⊤Ax − A

⊤

b||2 > δ do

x ← x −

ϵ

(

A

⊤Ax

− A

⊤

b

)

end while

我们也可以

使用牛顿法

解决这个问

题。因为在这

个情况下，真

实函数是二

次的，

牛顿法

所用的二次

近似是精确

的，该算法会

在一步后收

敛到全局最

小点。

86 第四章

数值计算

现

在假设我们

希望最小化

同样的函数

，但受

x

⊤x ≤ 1

的约束

。要做到这一

点，

我们引入

Lagrangian

L(x, λ)

= f(x) + λ(x

⊤x − 1). (4.23)

现在，我们解

决以下问题

min

x

max

λ,λ≥0

L(x, λ). (4.24)

我们可以用

Moore-Penrose

伪逆：x = A

+

b 找到无

约束最小二

乘问题的最

小范

数解。如

果这一点是

可行，那么这

也是约束问

题的解。否则

，我们必须找

到约束是活

跃的解。关于

x 对

Lagrangian 微分，我们

得到方程

A

⊤Ax

− A

⊤

b

+ 2λx = 0.

(4.25)

这

就告诉我们

，该解的形式

将会是

x =

(A

⊤A + 2λI)

−1A

⊤

b. (4.26)

λ 的选

择必须使结

果服从约束

。我们可以关

于 λ 进行梯度

上升找到这

个值。为了做

到这一点，观

察

∂

∂λL(x, λ) =

x

⊤x − 1.

(4.27)

当 x 的范数

超过

1 时，该导

数是正的，所

以为了跟随

导数上坡并

相对 λ 增

加 Lagrangian，我

们需要增加

λ。因为 x

⊤x

的惩罚

系数增加了

，求解关于 x 的

线性方程现

在将得到具

有较小范数

的解。求解线

性方程和调

整 λ

的过程将

一直持续

到

x 具有正确的

范数并且关

于 λ

的导数是

0。

本章总结了

开发机器学

习算法所需

的数学基础

。现在，我们已

经准备好建

立和

分析一

些成熟的学

习系统。

第五

章

机器学习

基础

深度学

习是机器学

习的一个特

定分支。我们

要想充分理

解深度学习

，必须对机器

学习的基本

原理有深刻

的理解。本章

将探讨贯穿

本书其余部

分的一些机

器学习重要

原理。我们建

议新手读者

或是希望更

全面了解的

读者参考一

些更全面覆

盖基础知识

的机器学习

参考书，例如

Murphy (2012) 或者

Bishop (2006)。如果你

已经熟知机

器

学习，可以

跳过前面的

部分，前往第

5.11 节。第

5.11 节涵盖

了一些传统

机器学习技

术观点，这些

技术对深度

学习的发展

有着深远影

响。

首先，我们

将介绍学习

算法的定义

，并介绍一个

简单的示例

：线性回归算

法。接

下来，我

们会探讨拟

合训练数据

与寻找能够

泛化到新数

据的模式存

在哪些不同

的挑

战。大部

分机器学习

算法都有超

参数（必须在

学习算法外

设定）；我们将

探讨如何使

用额外的数

据设置超参

数。机器学习

本质上属于

应用统计学

，更多地关注

于如何用

计

算机统计地

估计复杂函

数，不太关注

为这些函数

提供置信区

间；因此我们

会探讨

两种

统计学的主

要方法：频率

派估计和贝

叶斯推断。大

部分机器学

习算法可以

分成监

督学

习和无监督

学习两类；我

们将探讨不

同的分类，并

为每类提供

一些简单的

机器

学习算

法作为示例

。大部分深度

学习算法都

是基于被称

为随机梯度

下降的算法

求解

的。我们

将介绍如何

组合不同的

算法部分，例

如优化算法

、代价函数、模

型和数据

集

，来建立一个

机器学习算

法。最后在第

5.11 节，我们会介

绍一些限制

传统机器学

习泛化能力

的因素。这些

挑战促进了

解决这些问

题的深度学

习算法的发

展。

5.1 学习算法

机器学习算

法是一种能

够从数据中

学习的算法

。然而，我们所

谓的 ‘‘学习’’ 是

什

么意思呢

？Mitchell (1997) 提供了一个

简洁的定义

：‘‘对于某类任

务 T

和性能度

量

P，一个计算

机程序被认

为可以从经

验 E 中学习是

指，通过经验

E

改进后，它在

任

87

88 第五章

机

器学习基础

务 T 上由性能

度量 P

衡量的

性能有所提

升。” 经验 E，任务

T 和性能度量

P

的定

义范围

非常宽广，在

本书中我们

并不会试图

去解释这些

定义的具体

意义。相反，我

们会在接下

来的章节中

提供直观的

解释和示例

来介绍不同

的任务、性能

度量和经验

，

这些将被用

来构建机器

学习算法。

5.1.1

任

务 T

机器学习

可以让我们

解决一些人

为设计和使

用确定性程

序很难解决

的问题。从

科

学和哲学的

角度来看，机

器学习受到

关注是因为

提高我们对

机器学习的

认识需要

提

高我们对智

能背后原理

的理解。

从 ‘‘任

务’’ 的相对正

式的定义上

说，学习过程

本身不能算

是任务。学习

是我们所

谓

的获取完成

任务的能力

。例如，我们的

目标是使机

器人能够行

走，那么行走

便是

任务。我

们可以编程

让机器人学

会如何行走

，或者可以人

工编写特定

的指令来指

导

机器人如

何行走。

通常

机器学习任

务定义为机

器学习系统

应该如何处

理

样本（example）。样本

是

指我们从

某些希望机

器学习系统

处理的对象

或事件中收

集到的已经

量化的 特征

（feature）的集合。我们

通常会将样

本表示成一

个向量 x

∈ R

n，其中

向量的每一

个元

素

xi 是一

个特征。例如

，一张图片的

特征通常是

指这张图片

的像素值。

机

器学习可以

解决很多类

型的任务。一

些非常常见

的机器学习

任务列举如

下：

•

分类：在这

类任务中，计

算机程序需

要指定某些

输入属于 k 类

中的哪一类

。

为了完成这

个任务，学习

算法通常会

返回一个函

数

f : R

n

→ {1, . .

. , k}。当

y

= f(x) 时，模型

将向量 x

所代

表的输入分

类到数字码

y 所代表的类

别。还有

一些

其他的分类

问题，例如，f 输

出的是不同

类别的概率

分布。分类任

务中有

一个

任务是对象

识别，其中输

入是图片（通

常由一组像

素亮度值表

示），输出

是表

示图片物体

的数字码。例

如，Willow Garage PR2

机器人能

像服务员一

样

识别不同

饮料，并送给

点餐的顾客

(Goodfellow et al.,

2010)。目前，最好的

对

象识别工

作正是基于

深度学习的

(Krizhevsky et al.,

2012a; Ioffe and Szegedy,

2015)。对象识别同

时也是计算

机识别人脸

的基本技术

，可用于标记

相片合辑中

的人脸 (Taigman et al.,

2014)，有助

于计算机更

自然地与用

户交互。

• 输入

缺失分类：当

输入向量的

每个度量不

被保证的时

候，分类问题

将会变得更

有挑战性。为

了解决分类

任务，学习算

法只需要定

义一个从输

入向量映射

到输

5.1

学习算

法 89

出类别的

函数。当一些

输入可能丢

失时，学习算

法必须学习

一组函数，而

不是

单个分

类函数。每个

函数对应着

分类具有不

同缺失输入

子集的

x。这种

情况在

医疗

诊断中经常

出现，因为很

多类型的医

学测试是昂

贵的，对身体

有害的。有

效

地定义这样

一个大集合

函数的方法

是学习所有

相关变量的

概率分布，然

后通

过边缘

化缺失变量

来解决分类

任务。使用

n 个

输入变量，我

们现在可以

获得每

个可

能的缺失输

入集合所需

的所有 2

n 个不

同的分类函

数，但是计算

机程序仅

需

要学习一个

描述联合概

率分布的函

数。参见 Goodfellow

et al. (2013d) 了解

以这种方式

将深度概率

模型应用于

这类任务的

示例。本节中

描述的许多

其他任

务也

可以推广到

缺失输入的

情况; 缺失输

入分类只是

机器学习能

够解决的问

题

的一个示

例。

•

回归：在这

类任务中，计

算机程序需

要对给定输

入预测数值

。为了解决这

个任

务，学习

算法需要输

出函数 f :

R

n → R。除了

返回结果的

形式不一样

外，这类

问题

和分类问题

是很像的。这

类任务的一

个示例是预

测投保人的

索赔金额（用

于设置保险

费），或者预测

证券未来的

价格。这类预

测也用在算

法交易中。

• 转

录：这类任务

中，机器学习

系统观测一

些相对非结

构化表示的

数据，并转

录

信息为离散

的文本形式

。例如，光学字

符识别要求

计算机程序

根据文本图

片

返回文字

序列（ASCII 码或者

Unicode 码）。谷歌街景

以这种方式

使用深度学

习处理街道

编号 (Goodfellow

et al., 2014d)。另一个

例子是语音

识别，计算机

程序输入一

段音频波形

，输出一序列

音频记录中

所说的字符

或单词 ID

的编

码。

深度学习

是现代语音

识别系统的

重要组成部

分，被各大公

司广泛使用

，包括微

软，IBM 和

谷歌

(Hinton et al., 2012b)。

• 机器翻

译：在机器翻

译任务中，输

入是一种语

言的符号序

列，计算机程

序必须

将其

转化成另一

种语言的符

号序列。这通

常适用于自

然语言，如将

英语译成

法

语。最近，深度

学习已经开

始在这个任

务上产生重

要影响

(Sutskever et al.,

2014;

Bahdanau et al., 2015)。

• 结构

化输出：结构

化输出任务

的输出是向

量或者其他

包含多个值

的数据结构

，

并且构成输

出的这些不

同元素间具

有重要关系

。这是一个很

大的范畴，包

括上

述转录

任务和翻译

任务在内的

很多其他任

务。例如语法

分析——映射自

然语言

句子

到语法结构

树，并标记树

的节点为动

词、名词、副词

等等。参考 Collobert

(2011) 将

深度学习应

用到语法分

析的示例。另

一个例子是

图像的像素

级分割，

将每

一个像素分

配到特定类

别。例如，深度

学习可用于

标注航拍照

片中的道路

90 第五章 机器

学习基础

位

置

(Mnih and Hinton, 2010)。在这些标

注型的任务

中，输出的结

构形式不

需

要和输入尽

可能相似。例

如，在为图片

添加描述的

任务中，计算

机程序观察

到一幅图，输

出描述这幅

图的自然语

言句子 (Kiros et al.,

2014a,b; Mao et al.,

2014; Vinyals et al.,

2015b; Donahue et al.,

2014; Karpathy and Li,

2015; Fang

et al.,

2015; Xu et al.,

2015)。这类

任务被称为

结构化输出

任务是因为

输出值之

间

内部紧密相

关。例如，为图

片添加标题

的程序输出

的单词必须

组合成一个

通

顺的句子

。

•

异常检测：在

这类任务中

，计算机程序

在一组事件

或对象中筛

选，并标记不

正

常或非典

型的个体。异

常检测任务

的一个示例

是信用卡欺

诈检测。通过

对你的

购买

习惯建模，信

用卡公司可

以检测到你

的卡是否被

滥用。如果窃

贼窃取你的

信用卡或信

用卡信息，窃

贼采购物品

的分布通常

和你的不同

。当该卡发生

了不

正常的

购买行为时

，信用卡公司

可以尽快冻

结该卡以防

欺诈。参考

Chandola

et al. (2009)

了

解欺诈检测

方法。

• 合成和

采样：在这类

任务中，机器

学习程序生

成一些和训

练数据相似

的新样本。

通

过机器学习

，合成和采样

可能在媒体

应用中非常

有用，可以避

免艺术家大

量

昂贵或者

乏味费时的

手动工作。例

如，视频游戏

可以自动生

成大型物体

或风景

的纹

理，而不是让

艺术家手动

标记每个像

素 (Luo et

al., 2013)。在某些情

况下，

我们希

望采样或合

成过程可以

根据给定的

输入生成一

些特定类型

的输出。例如

，

在语音合成

任务中，我们

提供书写的

句子，要求程

序输出这个

句子语音的

音频

波形。这

是一类结构

化输出任务

，但是多了每

个输入并非

只有一个正

确输出的

条

件，并且我们

明确希望输

出有很多变

化，这可以使

结果看上去

更加自然和

真

实。

•

缺失值

填补：在这类

任务中，机器

学习算法给

定一个新样

本 x ∈ R

n，x 中某些

元

素 xi

缺失。算法

必须填补这

些缺失值。

• 去

噪：在这类任

务中，机器学

习算法的输

入是，干净样

本 x

∈ R

n 经过未知

损

坏过程后

得到的损坏

样本 x˜ ∈ R

n。算法根

据损坏后的

样本 x˜ 预测干

净的样本

x，或

者更一般地

预测条件概

率分布

p(x | x˜)。

•

密度

估计或概率

质量函数估

计：在密度估

计问题中，机

器学习算法

学习函数

pmodel : R

n → R，其

中 pmodel(x)

可以解释

成样本采样

空间的概率

密度函数（如

果 x 是连续的

）或者概率质

量函数（如果

x 是离散的）。要

做好这样的

任务

5.1 学习算

法 91

（当我们讨

论性能度量

P

时，我们会明

确定义任务

是什么），算法

需要学习观

测

到的数据

的结构。算法

必须知道什

么情况下样

本聚集出现

，什么情况下

不太可

能出

现。以上描述

的大多数任

务都要求学

习算法至少

能隐式地捕

获概率分布

的

结构。密度

估计可以让

我们显式地

捕获该分布

。原则上，我们

可以在该分

布上

计算以

便解决其他

任务。例如，如

果我们通过

密度估计得

到了概率分

布 p(x)，

我们可以

用该分布解

决缺失值填

补任务。如果

xi 的值是缺失

的，但是其他

的变

量值 x−i 已

知，那么我们

可以得到条

件概率分布

p(xi

|

x−i)。实际情况中

，密

度估计并

不能够解决

所有这类问

题，因为在很

多情况下 p(x) 是

难以计算的

。

当然，还有很

多其他同类

型或其他类

型的任务。这

里我们列举

的任务类型

只是

用来介

绍机器学习

可以做哪些

任务，并非严

格地定义机

器学习任务

分类。

5.1.2 性能度

量

P

为了评估

机器学习算

法的能力，我

们必须设计

其性能的定

量度量。通常

性能度

量 P

是

特定于系统

执行的任务

T 而言的。

对于

诸如分类、缺

失输入分类

和转录任务

，我们通常度

量模型的 准

确率（accu￾racy）。准确率

是指该模型

输出正确结

果的样本比

率。我们也可

以通过

错误

率（error

rate）得到相同

的信息。错误

率是指该模

型输出错误

结果的样本

比率。我们通

常把错

误率

称为 0

− 1损失的

期望。在一个

特定的样本

上，如果结果

是对的，那么

0 − 1损

失是 0；否则

是 1。但是对于

密度估计这

类任务而言

，度量准确率

，错误率或者

其他

类型的

0

− 1损失是没有

意义的。反之

，我们必须使

用不同的性

能度量，使模

型对每

个样

本都输出一

个连续数值

的得分。最常

用的方法是

输出模型在

一些样本上

概率对

数的

平均值。

通常

，我们会更加

关注机器学

习算法在未

观测数据上

的性能如何

，因为这将决

定其在实际

应用中的性

能。因此，我们

使用 测试集

（test set）数据来评估

系统性能，

将

其与训练机

器学习系统

的训练集数

据分开。

性能

度量的选择

或许看上去

简单且客观

，但是选择一

个与系统理

想表现对应

的性能度量

通常是很难

的。

在某些情

况下，这是因

为很难确定

应该度量什

么。例如，在执

行转录任务

时，我

们是应

该度量系统

转录整个序

列的准确率

，还是应该用

一个更细粒

度的指标，对

序

列中正确

的部分元素

以正面评价

？在执行回归

任务时，我们

应该更多地

惩罚频繁犯

92

第五章 机器

学习基础

一

些中等错误

的系统，还是

较少犯错但

是犯很大错

误的系统？这

些设计的选

择取决

于应

用。

还有一些

情况，我们知

道应该度量

哪些数值，但

是度量它们

不太现实。这

种情

况经常

出现在密度

估计中。很多

最好的概率

模型只能隐

式地表示概

率分布。在许

多

这类模型

中，计算空间

中特定点的

概率是不可

行的。在这些

情况下，我们

必须设计

一

个仍然对应

于设计对象

的替代标准

，或者设计一

个理想标准

的良好近似

。

5.1.3 经验 E

根据学

习过程中的

不同经验，机

器学习算法

可以大致分

类为

无监督

（unsuper￾vised）算法和 监督

（supervised）算法。

本书中

的大部分学

习算法可以

被理解为在

整个 数据集

（dataset）上获取经验

。

数据集是指

很多样本组

成的集合，如

第 5.1.1 节所定义

的。有时我们

也将样本称

为 数

据点（data point）。

Iris（鸢

尾花卉）数据

集 (Fisher,

1936) 是统计学

家和机器学

习研究者使

用了很

久的

数据集。它是

150 个鸢尾花卉

植物不同部

分测量结果

的集合。每个

单独的植物

对应一个样

本。每个样本

的特征是该

植物不同部

分的测量结

果：萼片长度

、萼片宽

度、花

瓣长度和花

瓣宽度。这个

数据集也记

录了每个植

物属于什么

品种，其中共

有

三个不同

的品种。

无监

督学习算法

（unsupervised learning

algorithm）训练含有很

多特征的数

据

集，然后学

习出这个数

据集上有用

的结构性质

。在深度学习

中，我们通常

要学习生

成

数据集的整

个概率分布

，显式地，比如

密度估计，或

是隐式地，比

如合成或去

噪。

还有一些

其他类型的

无监督学习

任务，例如聚

类，将数据集

分成相似样

本的集合。

监

督学习算法

（supervised learning algorithm）训练含有很

多特征的数

据集，不

过数

据集中的样

本都有一个

标签（label）或

目标

（target）。例如，Iris 数据集

注明

了每个

鸢尾花卉样

本属于什么

品种。监督学

习算法通过

研究 Iris

数据集

，学习如何

根

据测量结果

将样本划分

为三个不同

品种。

大致说

来，无监督学

习涉及到观

察随机向量

x 的好几个样

本，试图显式

或隐式

地学

习出概率分

布 p(x)，或者是该

分布一些有

意思的性质

；而监督学习

包含观察随

机向量 x 及其

相关联的值

或向量

y，然后

从 x 预测 y，通常

是估计

p(y | x)。术语

监

督学习（supervised

learning）源

自这样一个

视角，教员或

者老师提供

目标 y 给机器

5.1 学习算法

93

学

习系统，指导

其应该做什

么。在无监督

学习中，没有

教员或者老

师，算法必须

学会

在没有

指导的情况

下理解数据

。

无监督学习

和监督学习

不是严格定

义的术语。它

们之间界线

通常是模糊

的。很

多机器

学习技术可

以用于这两

个任务。例如

，概率的链式

法则表明对

于向量 x ∈ R

n，

联合

分布可以分

解成

p(x) =

n∏

i=1

p(xi

|

x1, . . .

, xi−1). (5.1)

该分解

意味着我们

可以将其拆

分成

n 个监督

学习问题，来

解决表面上

的无监督学

习

p(x)。另外，我们

求解监督学

习问题 p(y

| x) 时，也

可以使用传

统的无监督

学习策略

学

习联合分布

p(x,

y)，然后推断

p(y | x)

= p(x, y)

∑

y′ p(x, y′)

.

(5.2)

尽

管无监督学

习和监督学

习并非完全

没有交集的

正式概念，它

们确实有助

于粗略分

类

我们研究机

器学习算法

时遇到的问

题。传统地，人

们将回归、分

类或者结构

化输

出问题

称为监督学

习。支持其他

任务的密度

估计通常被

称为无监督

学习。

学习范

式的其他变

种也是有可

能的。例如，半

监督学习中

，一些样本有

监督目

标，但

其他样本没

有。在多实例

学习中，样本

的整个集合

被标记为含

有或者不含

有

该类的样

本，但是集合

中单独的样

本是没有标

记的。参考 Kotzias

et al. (2015) 了

解

最近深度

模型进行多

实例学习的

示例。

有些机

器学习算法

并不是训练

于一个固定

的数据集上

。例如， 强化学

习（rein￾forcement learning）算法会和

环境进行交

互，所以学习

系统和它的

训练过程会

有反

馈回路

。这类算法超

出了本书的

范畴。请参考

Sutton and Barto (1998)

或 Bertsekas

and Tsitsiklis

(1996) 了解强化

学习相关知

识，Mnih et al.

(2013) 介绍了强

化学习方

向

的深度学习

方法。

大部分

机器学习算

法简单地训

练于一个数

据集上。数据

集可以用很

多不同方式

来表示。在所

有的情况下

，数据集都是

样本的集合

，而样本是特

征的集合。

表

示数据集的

常用方法是

设计矩阵（design matrix）。设

计矩阵的每

一行包含

一

个不同的样

本。每一列对

应不同的特

征。例如，Iris 数据

集包含

150 个样

本，每

个样本

有 4

个特征。这

意味着我们

可以将该数

据集表示为

设计矩阵 X ∈ R

150×4，其

中 Xi,1 表示第 i

个

植物的萼片

长度，Xi,2 表示第

i 个植物的萼

片宽度等等

。我们在

本书

中描述的大

部分学习算

法都是讲述

它们是如何

运行在设计

矩阵数据集

上的。

94 第五章

机器学习基

础

当然，每一

个样本都能

表示成向量

，并且这些向

量的维度相

同，才能将一

个数

据集表

示成设计矩

阵。这一点并

非永远可能

。例如，你有不

同宽度和高

度的照片的

集合，那么不

同的照片将

会包含不同

数量的像素

。因此不是所

有的照片都

可以表示

成

相同长度的

向量。第 9.7 节和

第十章将会

介绍如何处

理这些不同

类型的异构

数据。

在上述

这类情况下

，我们不会将

数据集表示

成

m 行的矩阵

，而是表示成

m 个元素

的结

合：{x

(1)

, x

(2)

, . . .

, x

(m)}。这种表示

方式意味着

样本向量 x

(i) 和

x

(j) 可以有不

同

的大小。

在监

督学习中，样

本包含一个

标签或目标

和一组特征

。例如，我们希

望使用学

习

算法从照片

中识别对象

。我们需要明

确哪些对象

会出现在每

张照片中。我

们或许

会用

数字编码表

示，如

0 表示人

、1 表示车、2 表示

猫等等。通常

在处理包含

观测特

征的

设计矩阵 X 的

数据集时，我

们也会提供

一个标签向

量 y，其中

yi 表示

样本 i

的标签

。

当然，有时标

签可能不止

一个数。例如

，如果我们想

要训练语音

模型转录整

个

句子，那么

每个句子样

本的标签是

一个单词序

列。

正如监督

学习和无监

督学习没有

正式的定义

，数据集或者

经验也没有

严格的区

分

。这里介绍的

结构涵盖了

大多数情况

，但始终有可

能为新的应

用设计出新

的结构。

5.1.4 示例

：线性回归

我

们将机器学

习算法定义

为，通过经验

以提高计算

机程序在某

些任务上性

能的

算法。这

个定义有点

抽象。为了使

这个定义更

具体点，我们

展示一个简

单的机器学

习示例：线性

回归（linear

regression）。当我们

介绍更多有

助于理解机

器学习特性

的

概念时，我

们会反复回

顾这个示例

。

顾名思义，线

性回归解决

回归问题。换

言之，我们的

目标是建立

一个系统，将

向

量

x ∈ R

n

作为输

入，预测标量

y ∈ R 作为输出。线

性回归的输

出是其输入

的线性函

数

。令 yˆ 表示模型

预测 y

应该取

的值。我们定

义输出为

yˆ = w

⊤x, (5.3)

其

中 w

∈ R

n 是

参数（parameter）向

量。

参数是控

制系统行为

的值。在这种

情况下，wi 是系

数，会和特征

xi 相乘之

后全

部相加起来

。我们可以将

w 看作是一组

决定每个特

征如何影响

预测的 权重

（weight）。如果特征 xi

对

应的权重 wi 是

正的，那么特

征的值增加

，我们的预测

值

5.1

学习算法

95

yˆ 也会增加。如

果特征 xi

对应

的权重 wi 是负

的，那么特征

的值增加，我

们的预测

值

yˆ

会减少。如果

特征权重的

大小很大，那

么它对预测

有很大的影

响；如果特征

权

重的大小

是零，那么它

对预测没有

影响。

因此，我

们可以定义

任务 T：通过输

出

yˆ = w⊤x 从

x 预测 y。接

下来我们需

要

定义性能

度量——P。

假设我

们有 m 个输入

样本组成的

设计矩阵，我

们不用它来

训练模型，而

是评

估模型

性能如何。我

们也有每个

样本对应的

正确值

y 组成

的回归目标

向量。因为这

个数据集只

是用来评估

性能，我们称

之为 测试集

（test set）。我们将输入

的设计矩

阵

记作 X

(test)，回归目

标向量记作

y

(test)。

度量模型性

能的一种方

法是计算模

型在测试集

上的 均方误

差（mean squared

error）。如果

yˆ

(test) 表示

模型在测试

集上的预测

值，那么均方

误差表示为

：

MSEtest

=

m

1 ∑

i

(yˆ

(test) −

y

(test)

)

2

i

. (5.4)

直观上，当

yˆ

(test) = y

(test) 时

，我们会发现

误差降为 0。我

们也可以看

到

MSEtest

=

1

m



yˆ

(test) − y

(test)

2

2

,

(5.5)

所以当预

测值和目标

值之间的欧

几里得距离

增加时，误差

也会增加。

为

了构建一个

机器学习算

法，我们需要

设计一个算

法，通过观察

训练集

(X

(train)

, y

(train)

) 获得

经验，减少 MSEtest 以

改进权重

w。一

种直观方式

（我们

将在后

续的第 5.5.1 节说

明其合法性

）是最小化训

练集上的均

方误差，即

MSEtrain。

最

小化 MSEtrain，我们可

以简单地求

解其导数为

0 的情况：

∇wMSEtrain = 0 (5.6)

⇒ ∇w

1

m



yˆ

(train) − y

(train)

2

2

=

0 (5.7)

⇒

1

m

∇w

X

(train)w − y

(train)



2

2

= 0

(5.8)

⇒ ∇w

(

X

(train)w − y

(train)

)⊤ (

X

(train)w − y

(train)

)

= 0 (5.9)

⇒ ∇w

(

w

⊤X

(train)⊤X

(train)w −

2w

⊤X

(train)⊤

y

(train) + y

(train)⊤y

(train)

)

= 0

(5.10)

⇒ 2X

(train)⊤X

(train)w − 2X

(train)⊤

y

(train) = 0

(5.11)

96 第五

章 机器学习

基础

⇒ w =

(

X

(train)⊤X

(train)

)−1

X

(train)⊤

y

(train)

(5.12)

通过式

(5.12) 给出解的系

统方程被称

为 正规方程

（normal

equation）。计算

式 (5.12) 构成

了一个简单

的机器学习

算法。图

5.1 展示

了线性回归

算法的使用

示例。

−1.0 −0.5

0.0 0.5 1.0

x1

−3

−2

−1

0

1

2

3

Linear

regression example

0.5 1.0

1.5

w1

0.20

0.25

0.30

0.35

0.40

0.45

0.50

0.55

Optimization of

w

图 5.1: 一个

线性回归问

题，其中训练

集包括十个

数据点，每个

数据点包含

一个特征。因

为只有一

个

特征，权重向

量 w 也只有一

个要学习的

参数 w1。(左)

我们

可以观察到

线性回归学

习 w1，从而

使得

直线 y

= w1x 能够尽

量接近穿过

所有的训练

点。(右) 标注的

点表示由正

规方程学习

到的

w1

的值，我

们发现它可

以最小化训

练集上的均

方误差。

值得

注意的是，术

语 线性回归

（linear

regression）通常用来指

稍微复杂一

些，

附加额外

参数（截距项

b）的模型。在这

个模型中，

yˆ =

w

⊤x + b,

(5.13)

因

此从参数到

预测的映射

仍是一个线

性函数，而从

特征到预测

的映射是一

个仿射函

数

。如此扩展到

仿射函数意

味着模型预

测的曲线仍

然看起来像

是一条直线

，只是这

条直

线没必要经

过原点。除了

通过添加偏

置参数

b，我们

还可以使用

仅含权重的

模

型，但是 x 需

要增加一项

永远为

1 的元

素。对应于额

外 1 的权重起

到了偏置参

数的

作用。当

我们在本书

中提到仿射

函数时，我们

会经常使用

术语 ‘‘线性’’。

截

距项 b

通常被

称为仿射变

换的 偏置（bias）参

数。这个术语

的命名源自

该变

换的输

出在没有任

何输入时会

偏移 b。它和统

计偏差中指

代统计估计

算法的某个

量的

期望估

计偏离真实

值的意思是

不一样的。

线

性回归当然

是一个极其

简单且有局

限的学习算

法，但是它提

供了一个说

明学

习算法

如何工作的

例子。在接下

来的小节中

，我们将会介

绍一些设计

学习算法的

基

y

(train) MSE

5.2 容量、过拟

合和欠拟合

97

本原则，并说

明如何使用

这些原则来

构建更复杂

的学习算法

。

5.2 容量、过拟合

和欠拟合

机

器学习的主

要挑战是我

们的算法必

须能够在先

前未观测的

新输入上表

现良好，

而不

只是在训练

集上表现良

好。在先前未

观测到的输

入上表现良

好的能力被

称为 泛

化（generalization）。

通

常情况下，当

我们训练机

器学习模型

时，我们可以

使用某个训

练集，在训练

集上计算一

些被称为

训

练误差（training error）的度

量误差，目标

是降低训练

误差。

目前为

止，我们讨论

的是一个简

单的优化问

题。机器学习

和优化不同

的地方在于

，我

们也希望

泛化误差（generalization

error）（也

被称为 测试

误差（test error））很低。

泛

化误差被定

义为新输入

的误差期望

。这里，期望的

计算基于不

同的可能输

入，这

些输入

采自于系统

在现实中遇

到的分布。

通

常，我们度量

模型在训练

集中分出来

的 测试集（test set）样

本上的性能

，来

评估机器

学习模型的

泛化误差。

在

我们的线性

回归示例中

，我们通过最

小化训练误

差来训练模

型，

1

m(train)



X

(train)w − y

(train)

2

2

,

(5.14)

但是我们

真正关注的

是测试误差

1

m(test)



X

(test)w − y

(test)

2

2

。

当我们只能

观测到训练

集时，我们如

何才能影响

测试集的性

能呢？ 统计学

习理

论（statistical learning

theory）提供

了一些答案

。如果训练集

和测试集的

数据是任

意

收集的，那么

我们能够做

的确实很有

限。如果我们

可以对训练

集和测试集

数据的

收集

方式有些假

设，那么我们

能够对算法

做些改进。

训

练集和测试

集数据通过

数据集上被

称为

数据生

成过程（data generating pro￾cess）的概

率分布生成

。通常，我们会

做一系列被

统称为 独立

同分布假设

（i.i.d.

assumption）的假设。该假

设是说，每个

数据集中的

样本都是彼

此 相互独立

的（in￾dependent），并且训练

集和测试集

是 同分布的

（identically distributed），采样自相

同

的分布。这个

假设使我们

能够在单个

样本的概率

分布描述数

据生成过程

。然后相

同的

分布可以用

来生成每一

个训练样本

和每一个测

试样本。我们

将这个共享

的潜在

分布

称为 数据生

成分布（data

generating distribution），记作

pdata。这个概率框

架

和独立同

分布假设允

许我们从数

学上研究训

练误差和测

试误差之间

的关系。

98

第五

章 机器学习

基础

我们能

观察到训练

误差和测试

误差之间的

直接联系是

，随机模型训

练误差的期

望和该模型

测试误差的

期望是一样

的。假设我们

有概率分布

p(x, y)，从中重复采

样

生成训练

集和测试集

。对于某个固

定的 w，训练集

误差的期望

恰好和测试

集误差的

期

望一样，这是

因为这两个

期望的计算

都使用了相

同的数据集

生成过程。这

两种情

况的

唯一区别是

数据集的名

字不同。

当然

，当我们使用

机器学习算

法时，我们不

会提前固定

参数，然后采

样得到两

个

数据集。我们

采样得到训

练集，然后挑

选参数去降

低训练集误

差，然后采样

得到测

试集

。在这个过程

中，测试误差

期望会大于

或等于训练

误差期望。以

下是决定机

器

学习算法

效果是否好

的因素：

1. 降低

训练误差。

2. 缩

小训练误差

和测试误差

的差距。

这两

个因素对应

机器学习的

两个主要挑

战： 欠拟合（underfitting）和

过拟合

（overfitting）。欠拟

合是指模型

不能在训练

集上获得足

够低的误差

。而过拟合是

指训

练误差

和和测试误

差之间的差

距太大。

通过

调整模型的

容量（capacity），我们可

以控制模型

是否偏向于

过拟合或者

欠

拟合。通俗

地，模型的容

量是指其拟

合各种函数

的能力。容量

低的模型可

能很难拟

合

训练集。容量

高的模型可

能会过拟合

，因为记住了

不适用于测

试集的训练

集性质。

一种

控制训练算

法容量的方

法是选择

假

设空间（hypothesis space），即学

习算

法可以

选择为解决

方案的函数

集。例如，线性

回归算法将

关于其输入

的所有线性

函

数作为假

设空间。广义

线性回归的

假设空间包

括多项式函

数，而非仅有

线性函数。这

样做就增加

了模型的容

量。

一次多项

式提供了我

们已经熟悉

的线性回归

模型，其预测

如下：

yˆ = b

+ wx. (5.15)

通过引

入

x

2 作为线性

回归模型的

另一个特征

，我们能够学

习关于 x

的二

次函数模

型

：

yˆ =

b + w1x +

w2x

2

. (5.16)

尽管该模型

是输入的二

次函数，但输

出仍是参数

的线性函数

。因此我们仍

然可以用正

规方程得到

模型的闭解

。我们可以继

续添加 x 的更

高幂作为额

外特征，例如

下面的

5.2

容量

、过拟合和欠

拟合 99

9 次多项

式：

yˆ = b +

9

∑

i=1

wix

i

. (5.17)

当机器学

习算法的容

量适合于所

执行任务的

复杂度和所

提供训练数

据的数量时

，

算法效果通

常会最佳。容

量不足的模

型不能解决

复杂任务。容

量高的模型

能够解决

复

杂的任务，但

是当其容量

高于任务所

需时，有可能

会过拟合。

图

5.2 展示了这个

原理的使用

情况。我们比

较了线性，二

次和

9 次预测

器拟合真

实

二次函数的

效果。线性函

数无法刻画

真实函数的

曲率，所以欠

拟合。9 次函数

能够

表示正

确的函数，但

是因为训练

参数比训练

样本还多，所

以它也能够

表示无限多

个

刚好穿越

训练样本点

的很多其他

函数。我们不

太可能从这

很多不同的

解中选出一

个

泛化良好

的。在这个问

题中，二次模

型非常符合

任务的真实

结构，因此它

可以很好

地

泛化到新数

据上。

x0

Underfitting

x0

Appropriate

capacity

x0

Overfitting

图

5.2: 我们

用三个模型

拟合了这个

训练集的样

本。训练数据

是通过随机

抽取 x 然后用

二次函数确

定性地生成

y

来合成的。(左

) 用一个线性

函数拟合数

据会导致欠

拟合——它无法

捕捉数据中

的曲

率信息

。(中) 用二次函

数拟合数据

在未观察到

的点上泛化

得很好。这并

不会导致明

显的欠拟合

或

者过拟合

。(右) 一个 9 阶的

多项式拟合

数据会导致

过拟合。在这

里我们使用

Moore-Penrose

伪

逆来解这

个欠定的正

规方程。得出

的解能够精

确地穿过所

有的训练点

，但可惜我们

无法提取有

效

的结构信

息。在两个数

据点之间它

有一个真实

的函数所不

包含的深谷

。在数据的左

侧，它也会急

剧增长，而在

这一区域真

实的函数却

是下降的。

目

前为止，我们

探讨了通过

改变输入特

征的数目和

加入这些特

征对应的参

数，改

变模型

的容量。事实

上，还有很多

方法可以改

变模型的容

量。容量不仅

取决于模型

的选择。模型

规定了调整

参数降低训

练目标时，学

习算法可以

从哪些函数

族中选择

y

y

y

100 第

五章 机器学

习基础

函数

。这被称为模

型的

表示容

量（representational capacity）。在很多情

况下，从这

些

函数中挑选

出最优函数

是非常困难

的优化问题

。实际中，学习

算法不会真

的找到

最优

函数，而仅是

找到一个可

以大大降低

训练误差的

函数。额外的

限制因素，比

如

优化算法

的不完美，意

味着学习算

法的 有效容

量（effective capacity）可能小于

模型

族的表

示容量。

提高

机器学习模

型泛化的现

代思想可以

追溯到早在

托勒密时期

的哲学家的

思

想。许多早

期的学者提

出一个简约

原则，现在广

泛被称为 奥

卡姆剃刀（Occam’s

razor）（c.

1287-1387）。该

原则指出，在

同样能够解

释已知观测

现象的假设

中，我们

应该

挑选 ‘‘最简单

’’ 的那一个。这

个想法是在

20

世纪，由统计

学习理论创

始人形式

化

并精确化的

(Vapnik and Chervonenkis,

1971; Vapnik, 1982; Blumer

et al., 1989;

Vapnik,

1995)。

统计学习理

论提供了量

化模型容量

的不同方法

。在这些中，最

有名的是 Vapnik￾Chervonenkis 维

度（Vapnik-Chervonenkis

dimension, VC）。VC维度量二

元分类

器的

容量。VC维定义

为该分类器

能够分类的

训练样本的

最大数目。假

设存在 m

个

不

同 x 点的训练

集，分类器可

以任意地标

记该

m 个不同

的 x 点，VC维被定

义为

m

的最大

可能值。

量化

模型的容量

使得统计学

习理论可以

进行量化预

测。统计学习

理论中最重

要

的结论阐

述了训练误

差和泛化误

差之间差异

的上界随着

模型容量增

长而增长，但

随着训练样

本增多而下

降

(Vapnik and Chervonenkis, 1971;

Vapnik, 1982; Blumer

et

al., 1989; Vapnik, 1995)。这些边界

为机器学习

算法可以有

效解决问题

提供了理论

验证，但是它

们很少应用

于实际中的

深度学习算

法。一部分原

因是边界太

松，另一

部分

原因是很难

确定深度学

习算法的容

量。由于有效

容量受限于

优化算法的

能力，

确定深

度学习模型

容量的问题

特别困难。而

且对于深度

学习中的一

般非凸优化

问题，

我们只

有很少的理

论分析。

我们

必须记住虽

然更简单的

函数更可能

泛化（训练误

差和测试误

差的差距小

），

但我们仍然

需要选择一

个充分复杂

的假设以达

到低的训练

误差。通常，当

模型容量

上

升时，训练误

差会下降，直

到其渐近最

小可能误差

（假设误差度

量有最小值

）。通

常，泛化误

差是一个关

于模型容量

的 U

形曲线函

数。如图 5.3 所示

。

为考虑容量

任意高的极

端情况，我们

介绍

非参数

（non-parametric）模型的概

念

。至此，我们只

探讨过参数

模型，例如线

性回归。参数

模型学习的

函数在观测

到新

数据前

，参数向量的

分量个数是

有限且固定

的。非参数模

型没有这些

限制。

5.2

容量、过

拟合和欠拟

合 101

0 Optimal

Capacity

Capacity

Underfitting zone

Overfitting zone

Generalization gap

Training error

Generalization error

图 5.3: 容量和

误差之间的

典型关系。训

练误差和测

试误差表现

得非常不同

。在图的左端

，训练误

差和

泛化误差都

非常高。这是

欠拟合机制

（underfitting

regime）。当我们增加

容量时，训练

误差减

小，但

是训练误差

和泛化误差

之间的间距

却不断扩大

。最终，这个间

距的大小超

过了训练误

差的下

降，我

们进入到了

过拟合机制

（overfitting regime），其中容量过

大，超过了

最

佳容量（optimal

capacity）。

有时

，非参数模型

仅是一些不

能实际实现

的理论抽象

（比如搜索所

有可能概率

分布的算法

）。然而，我们也

可以设计一

些实用的非

参数模型，使

它们的复杂

度和训

练集

大小有关。这

种算法的一

个示例是

最

近邻回归（nearest neighbor regression）。

不

像线性回归

有固定长度

的向量作为

权重，最近邻

回归模型存

储了训练集

中所有的

X 和

y。当需要为测

试点 x 分类时

，模型会查询

训练集中离

该点最近的

点，并返回

相

关的回归目

标。换言之，yˆ = yi 其

中

i = arg min

∥Xi,: − x∥

2

2。该算法也

可以扩展

成

L

2 范数以外的

距离度量，例

如学成距离

度量

(Goldberger et al., 2005)。在最近

向

量不唯一

的情况下，如

果允许算法

对所有离 x 最

近的 Xi,:

关联的

yi 求平均，那么

该算法会在

任意回归数

据集上达到

最小可能的

训练误差（如

果存在两个

相同的输入

对应不同的

输出，那么训

练误差可能

会大于零）。

最

后，我们也可

以将参数学

习算法嵌入

另一个增加

参数数目的

算法来创建

非参

数学习

算法。例如，我

们可以想象

这样一个算

法，外层循环

调整多项式

的次数，内

层

循环通过线

性回归学习

模型。

理想模

型假设我们

能够预先知

道生成数据

的真实概率

分布。然而这

样的模型仍

然会在很多

问题上发生

一些错误，因

为分布中仍

然会有一些

噪声。在监督

学习中，从

x 到

y

的映射可能

内在是随机

的，或者 y 可能

是其他变量

（包括 x

在内）的

确定性

Error

102 第五

章

机器学习

基础

函数。从

预先知道的

真实分布 p(x, y)

预

测而出现的

误差被称为

贝叶斯误差

（Bayes

error）。

训练误差和

泛化误差会

随训练集的

大小发生变

化。泛化误差

的期望从不

会因训

练样

本数目的增

加而增加。对

于非参数模

型而言，更多

的数据会得

到更好的泛

化能

力，直到

达到最佳可

能的泛化误

差。任何模型

容量小于最

优容量的固

定参数模型

会

渐近到大

于贝叶斯误

差的误差值

。如图 5.4 所示。值

得注意的是

，具有最优容

量的模

型仍

然有可能在

训练误差和

泛化误差之

间存在很大

的差距。在这

种情况下，我

们可

以通过

收集更多的

训练样本来

缩小差距。

5.2.1 没

有免费午餐

定理

学习理

论表明机器

学习算法能

够在有限个

训练集样本

中很好地泛

化。这似乎违

背一些基本

的逻辑原则

。归纳推理，或

是从一组有

限的样本中

推断一般的

规则，在

逻辑

上不是很有

效。为了逻辑

地推断一个

规则去描述

集合中的元

素，我们必须

具有

集合中

每个元素的

信息。

在一定

程度上，机器

学习仅通过

概率法则就

可以避免这

个问题，而无

需使用纯

逻

辑推理整个

确定性法则

。机器学习保

证找到一个

在所关注的

大多数样本

上可能正

确

的规则。

可惜

，即使这样也

不能解决整

个问题。机器

学习的 没有

免费午餐定

理（no

free

lunch theorem）表明 (Wolpert,

1996)，在所

有可能的数

据生成分布

上平均之后

，每

一个分类

算法在未事

先观测的点

上都有相同

的错误率。换

言之，在某种

意义上，没

有

一个机器学

习算法总是

比其他的要

好。我们能够

设想的最先

进的算法和

简单地将

所

有点归为同

一类的简单

算法有着相

同的平均性

能（在所有可

能的任务上

）。

幸运的是，这

些结论仅在

我们考虑所

有可能的数

据生成分布

时才成立。在

真实

世界应

用中，如果我

们对遇到的

概率分布进

行假设的话

，那么我们可

以设计在这

些

分布上效

果良好的学

习算法。

这意

味着机器学

习研究的目

标不是找一

个通用学习

算法或是绝

对最好的学

习算

法。反之

，我们的目标

是理解什么

样的分布与

人工智能获

取经验的 ‘‘真

实世界’’ 相

关

，什么样的学

习算法在我

们关注的数

据生成分布

上效果最好

。

5.2 容量、过拟合

和欠拟合 103

10

0

10

1

10

2

10

3

10

4

10

5

Number

of training examples

0.0

0.5

1.0

1.5

2.0

2.5

3.0

3.5

Bayes

error

Train (quadratic)

Test

(quadratic)

Test (optimal capacity)

Train (optimal capacity)

10

0

10

1

10

2

10

3

10

4

10

5

Number

of training examples

0

5

10

15

20

图

5.4: 训练集大小

对训练误差

，测试误差以

及最佳容量

的影响。通过

给一个 5 阶多

项式添加适

当

大小的噪

声，我们构造

了一个合成

的回归问题

，生成单个测

试集，然后生

成一些不同

尺寸的训练

集。为了描述

95% 置信区间的

误差条，对于

每一个尺寸

，我们生成了

40 个不同的训

练集。(上)

两个

不同的模型

上训练集和

测试集的

MSE，一

个二次模型

，另一个模型

的阶数通过

最小化测试

误

差来选择

。两个模型都

是用闭式解

来拟合。对于

二次模型来

说，当训练集

增加时训练

误差也随之

增大。这是由

于越大的数

据集越难以

拟合。同时，测

试误差随之

减小，因为关

于训练数据

的不正确

的

假设越来越

少。二次模型

的容量并不

足以解决这

个问题，所以

它的测试误

差趋近于一

个较高的

值

。最佳容量点

处的测试误

差趋近于贝

叶斯误差。训

练误差可以

低于贝叶斯

误差，因为训

练算法有

能

力记住训练

集中特定的

样本。当训练

集趋向于无

穷大时，任何

固定容量的

模型（在这里

指的是

二次

模型）的训练

误差都至少

增至贝叶斯

误差。(下) 当训

练集大小增

大时，最佳容

量（在这里是

用最优多项

式回归器的

阶数衡量的

）也会随之增

大。最佳容量

在达到足够

捕捉模型复

杂度之后就

不再增长了

。

Error

(MSE) Optimal capacity (polynomial

degree)

104 第五章 机器

学习基础

5.2.2 正

则化

没有免

费午餐定理

暗示我们必

须在特定任

务上设计性

能良好的机

器学习算法

。

我们建立一

组学习算法

的偏好来达

到这个要求

。当这些偏好

和我们希望

算法解决的

学习问题相

吻合时，性能

会更好。

至此

，我们具体讨

论修改学习

算法的方法

只有，通过增

加或减少学

习算法可选

假设空间的

函数来增加

或减少模型

的表示容量

。我们列举的

一个具体示

例是线性回

归增加或减

少多项式的

次数。目前为

止讨论的观

点都是过度

简化的。

算法

的效果不仅

很大程度上

受影响于假

设空间的函

数数量，也取

决于这些函

数

的具体形

式。我们已经

讨论的学习

算法（线性回

归）具有包含

其输入的线

性函数集

的

假设空间。对

于输入和输

出确实接近

线性相关的

问题，这些线

性函数是很

有用的。

对于

完全非线性

的问题它们

不太有效。例

如，我们用线

性回归，从 x 预

测 sin(x)，效

果不会

好。因此我们

可以通过两

种方式控制

算法的性能

，一是允许使

用的函数种

类，

二是这些

函数的数量

。

在假设空间

中，相比于某

一个学习算

法，我们可能

更偏好另一

个学习算法

。这

意味着两

个函数都是

符合条件的

，但是我们更

偏好其中一

个。只有非偏

好函数比偏

好函数在训

练数据集上

效果明显好

很多时，我们

才会考虑非

偏好函数。

例

如，我们可以

加入 权重衰

减（weight decay）来修改线

性回归的训

练标准。带

权

重衰减的线

性回归最小

化训练集上

的均方误差

和正则项的

和

J(w)，其偏好于

平方

L

2 范数较

小的权重。具

体如下：

J(w) = MSEtrain +

λw

⊤w, (5.18)

其中

λ

是提前挑选

的值，控制我

们偏好小范

数权重的程

度。当 λ = 0，我们没

有任

何偏好

。越大的 λ 偏好

范数越小的

权重。最小化

J(w) 可以看作是

拟合训练数

据和

偏好小

权重范数之

间的权衡。这

会使得解决

方案的斜率

较小，或是将

权重放在较

少

的特征上

。我们可以训

练具有不同

λ 值的高次多

项式回归模

型，来举例说

明如何通

过

权重衰减控

制模型欠拟

合或过拟合

的趋势。如图

5.5

所示。

更一般

地，正则化一

个学习函数

f(x; θ) 的模型，我们

可以给代价

函数添加被

称

为 正则化

项（regularizer）的惩罚。在

权重衰减的

例子中，正则

化项是 Ω(w) =

w⊤w。

在第

七章，我们将

看到很多其

他可能的正

则化项。

表示

对函数的偏

好是比增减

假设空间的

成员函数更

一般的控制

模型容量的

方法。

我们可

以将去掉假

设空间中的

某个函数看

作是对不赞

成这个函数

的无限偏好

。

5.3 超参数和验

证集 105

x0

Underfitting

(Excessive ¸)

x0

Appropriate weight decay

(Medium

¸)

x0

Overfitting

(¸!0)

图 5.5: 我们

使用高阶多

项式回归模

型来拟合图

5.2 中训练样本

。真实函数是

二次的，但是

在这里

我们

只使用 9 阶多

项式。我们通

过改变权重

衰减的量来

避免高阶模

型的过拟合

问题。(左) 当

λ 非

常大时，我们

可以强迫模

型学习到了

一个没有斜

率的函数。由

于它只能表

示一个常数

函数，所以

会

导致欠拟合

。(中) 取一个适

当的

λ 时，学习

算法能够用

一个正常的

形状来恢复

曲率。即使模

型

能够用更

复杂的形状

来来表示函

数，权重衰减

鼓励用一个

带有更小参

数的更简单

的模型来描

述它。

(右)

当权

重衰减趋近

于 0（即使用 Moore-Penrose 伪

逆来解这个

带有最小正

则化的欠定

问题）时，

这个

9 阶多项式会

导致严重的

过拟合，这和

我们在图5.2中

看到的一样

。

在我们权重

衰减的示例

中，通过在最

小化的目标

中额外增加

一项，我们明

确地

表示了

偏好权重较

小的线性函

数。有很多其

他方法隐式

或显式地表

示对不同解

的偏

好。总而

言之，这些不

同的方法都

被称为 正则

化（regularization）。正则化是

指我们

修改

学习算法，使

其降低泛化

误差而非训

练误差。正则

化是机器学

习领域的中

心问

题之一

，只有优化能

够与其重要

性相媲。

没有

免费午餐定

理已经清楚

地阐述了没

有最优的学

习算法，特别

地，没有最优

的正则化形

式。反之，我们

必须挑选一

个非常适合

于我们所要

解决的任务

的正则形

式

。深度学习中

普遍的（特别

是本书中的

）理念是大量

任务（例如所

有人类能做

的

智能任务

）也许都可以

使用非常通

用的正则化

形式来有效

解决。

5.3

超参数

和验证集

大

多数机器学

习算法都有

超参数，可以

设置来控制

算法行为。超

参数的值不

是

通过学习

算法本身学

习出来的（尽

管我们可以

设计一个嵌

套的学习过

程，一个学习

y

y

y

106 第五章 机器

学习基础

算

法为另一个

学习算法学

出最优超参

数）。

在图 5.2 所示

的多项式回

归示例中，有

一个超参数

：多项式的次

数，作为容量

超

参数。控制

权重衰减程

度的 λ 是另一

个超参数。

有

时一个选项

被设为学习

算法不用学

习的超参数

，是因为它太

难优化了。更

多

的情况是

，该选项必须

是超参数，因

为它不适合

在训练集上

学习。这适用

于控制模

型

容量的所有

超参数。如果

在训练集上

学习超参数

，这些超参数

总是趋向于

最大可

能的

模型容量，导

致过拟合（参

考图 5.3

）。例如，相

比低次多项

式和正的权

重衰减

设定

，更高次的多

项式和权重

衰减参数设

定 λ =

0 总能在训

练集上更好

地拟合。

为了

解决这个问

题，我们需要

一个训练算

法观测不到

的 验证集（validation

set）

样

本。

早先我们

讨论过和训

练数据相同

分布的样本

组成的测试

集，它可以用

来估计学

习

过程完成之

后的学习器

的泛化误差

。其重点在于

测试样本不

能以任何形

式参与到

模

型的选择中

，包括设定超

参数。基于这

个原因，测试

集中的样本

不能用于验

证集。

因此，我

们总是从训

练数据中构

建验证集。特

别地，我们将

训练数据分

成两个不相

交的子集。其

中一个用于

学习参数。另

一个作为验

证集，用于估

计训练中或

训练后

的泛

化误差，更新

超参数。用于

学习参数的

数据子集通

常仍被称为

训练集，尽管

这

会和整个

训练过程用

到的更大的

数据集相混

。用于挑选超

参数的数据

子集被称为

验

证集（validation set）。通常

，80% 的训练数据

用于训练，20% 用

于验证。由于

验证

集是用

来 ‘‘训练’’ 超参

数的，尽管验

证集的误差

通常会比训

练集误差小

，验证集会低

估泛化误差

。所有超参数

优化完成之

后，泛化误差

可能会通过

测试集来估

计。

在实际中

，当相同的测

试集已在很

多年中重复

地用于评估

不同算法的

性能，并

且考

虑学术界在

该测试集上

的各种尝试

，我们最后可

能也会对测

试集有着乐

观的估

计。基

准会因之变

得陈旧，而不

能反映系统

的真实性能

。值得庆幸的

是，学术界往

往

会移到新

的（通常会更

巨大、更具挑

战性）基准数

据集上。

5.3.1

交叉

验证

将数据

集分成固定

的训练集和

固定的测试

集后，若测试

集的误差很

小，这将是

有

问题的。一个

小规模的测

试集意味着

平均测试误

差估计的统

计不确定性

，使得很

难判

断算法

A 是否

比算法 B 在给

定的任务上

做得更好。

当

数据集有十

万计或者更

多的样本时

，这不会是一

个严重的问

题。当数据集

太

5.3 超参数和

验证集 107

小时

，也有替代方

法允许我们

使用所有的

样本估计平

均测试误差

，代价是增加

了计

算量。这

些过程是基

于在原始数

据上随机采

样或分离出

的不同数据

集上重复训

练和

测试的

想法。最常见

的是 k-折交叉

验证过程，如

算法

5.1 所示，将

数据集分成

k 个

不重合的

子集。测试误

差可以估计

为

k 次计算后

的平均测试

误差。在第 i 次

测试时，

数据

的第 i 个子集

用于测试集

，其他的数据

用于训练集

。带来的一个

问题是不存

在

平均误差

方差的无偏

估计

(Bengio and Grandvalet, 2004)，但是我

们通常会使

用近

似来解

决。

算法 5.1 k-折交

叉验证算法

。当给定数据

集

D 对于简单

的训练/测试

或训练/验证

分

割而言太

小难以产生

泛化误差的

准确估计时

（因为在小的

测试集上，L 可

能具有过

高

的方差），k-折交

叉验证算法

可以用于估

计学习算法

A 的泛化误差

。数据集 D 包

含

的元素是抽

象的样本 z

(i)（对

于第 i

个样本

），在监督学习

的情况代表

（输入，目

标）对

z

(i) =

(x

(i)

, y(i)

) ，或者无监督

学习的情况

下仅用于输

入 z

(i)

= x

(i)。该算法

返

回

D 中每个示

例的误差向

量 e，其均值是

估计的泛化

误差。单个样

本上的误差

可

用于计算

平均值周围

的置信区间

（式

(5.47) ）。虽然这些

置信区间在

使用交叉验

证之

后不能

很好地证明

，但是通常的

做法是只有

当算法 A

误差

的置信区间

低于并且不

与

算法 B 的置

信区间相交

时，我们才声

明算法

A 比算

法 B 更好。

Define KFoldXV(D, A, L,

k):

Require: D 为给

定数据集，其

中元素为

z

(i)

Require: A

为

学习算法，可

视为一个函

数（使用数据

集作为输入

，输出一个学

好的

函数）

Require: L

为

损失函数，可

视为来自学

好的函数 f，将

样本 z

(i)

∈ D 映射到

R 中

标量的函

数

Require: k 为折数

将

D 分为 k 个互斥

子集

Di，它们的

并集为 D

for i

from 1 to k

do

fi = A(D\Di)

for z

(j)

in

Di do

ej =

L(fi

, z

(j)

)

end for

end

for

Return e

108

第五

章 机器学习

基础

5.4 估计、偏

差和方差

统

计领域为我

们提供了很

多工具来实

现机器学习

目标，不仅可

以解决训练

集上

的任务

，还可以泛化

。基本的概念

，例如参数估

计、偏差和方

差，对于正式

地刻画泛

化

、欠拟合和过

拟合都非常

有帮助。

5.4.1

点估

计

点估计试

图为一些感

兴趣的量提

供单个 ‘‘最优

’’ 预测。一般地

，感兴趣的量

可以

是单个

参数，或是某

些参数模型

中的一个向

量参数，例如

第 5.1.4 节线性回

归中的权

重

，但是也有可

能是整个函

数。

为了区分

参数估计和

真实值，我们

习惯将参数

θ 的点估计表

示为 θˆ。

令

{x

(1)

, .

. . , x

(m)} 是 m 个

独立同分布

（i.i.d.）的数据点。

点

估计（point esti￾mator）或 统计

量（statistics）是这些数

据的任意函

数：

θˆm

= g(x

(1)

,

. . . ,

x

(m)

). (5.19)

这个定义

不要求 g 返回

一个接近真

实 θ

的值，或者

g 的值域恰好

是 θ 的允许取

值

范围。点估

计的定义非

常宽泛，给了

估计量的设

计者极大的

灵活性。虽然

几乎所有

的

函数都可以

称为估计量

，但是一个良

好的估计量

的输出会接

近生成训练

数据的真

实

参数 θ。

现在，我

们采取频率

派在统计上

的观点。换言

之，我们假设

真实参数 θ 是

固定

但未知

的，而点估计

θˆ

是数据的函

数。由于数据

是随机过程

采样出来的

，数据的任

何

函数都是随

机的。因此 θˆ 是

一个随机变

量。

点估计也

可以指输入

和目标变量

之间关系的

估计。我们将

这种类型的

点估计称

为

函数估计。

函

数估计 有时

我们会关注

函数估计（或

函数近似）。这

时我们试图

从输入向量

x

预

测变量 y。我

们假设有一

个函数 f(x)

表示

y 和 x 之间的近

似关系。例如

，我们可能

假

设 y = f(x)

+ ϵ，其中 ϵ 是

y 中

未能从 x 预测

的一部分。在

函数估计中

，我们感

兴趣

的是用模型

估计去近似

f，或者估计 f

ˆ。函

数估计和估

计参数 θ

是一

样的；函

数估

计 f

ˆ

是函数空

间中的一个

点估计。线性

回归示例（第

5.1.4 节中讨论的

）和多项

5.4 估计

、偏差和方差

109

式回归示例

（第5.2 节中讨论

的）都既可以

被解释为估

计参数 w，又可

以被解释为

估

计从

x 到 y 的

函数映射

f

ˆ。

现

在我们回顾

点估计最常

研究的性质

，并探讨这些

性质说明了

估计的哪些

特点。

5.4.2

偏差

估

计的偏差被

定义为：

bias(θˆm) =

E(θˆm) − θ, (5.20)

其中

期望作用在

所有数据（看

作是从随机

变量采样得

到的）上，θ 是用

于定义数

据

生成分布的

θ 的真实值。如

果

bias(θˆm) = 0，那么估计

量 θˆm

被称为是

无偏

（unbiased），这意味

着 E(θˆm) =

θ。如果 limm→∞ bias(θˆm) =

0，那么

估计量 θˆm 被

称

为是

渐近无

偏（asymptotically unbiased），这意味着

limm→∞ E(θˆm) =

θ。

示例：伯努利

分布 考虑一

组服从均值

为 θ

的伯努利

分布的独立

同分布的样

本

{x

(1), .

. . , x(m)}：

P(x

(i)

; θ)

= θ

x

(i)

(1 − θ)

(1−x

(i)

)

. (5.21)

这个分布

中参数 θ 的常

用估计量是

训练样本的

均值：

θ

ˆm =

m

1

m∑

i=1

x

(i)

. (5.22)

判断这

个估计量是

否有偏，我们

将式 (5.22)

代入式

(5.20) ：

bias(θ

ˆm)

= E[θ

ˆm] −

θ (5.23)

= E

[

m

1

m∑

i=1

x

(i)

]

− θ (5.24)

=

m

1

m∑

i=1

E

[

x

(i)

]

− θ (5.25)

=

1

m

m∑

i=1

1

∑

x(i)=0

(

x

(i)

θ

x

(i)

(1 −

θ)

(1−x

(i)

)

)

− θ (5.26)

=

m

1

m∑

i=1

(θ) − θ

(5.27)

= θ −

θ = 0 (5.28)

110 第五章 机器

学习基础

因

为

bias(θ

ˆ) = 0，我们称估

计

θ

ˆ 是无偏的

。

示例：均值的

高斯分布估

计

现在，考虑

一组独立同

分布的样本

{x

(1), . .

. , x(m)} 服

从高斯分

布 p(x

(i)

)

= N (x

(i)

; µ, σ2

)，其中

i ∈ {1, .

. . , m}。回顾

高斯概率密

度函数如

下

：

p(x

(i)

;

µ, σ2

) =

√

2

1

πσ2

exp (

−

1

2

(x

(i)

σ

−

2

µ)

2

)

. (5.29)

高斯均值参

数的常用估

计量被称为

样本均值（sample

mean）：

µˆm =

m

1

m∑

i=1

x

(i)

(5.30)

判

断样本均值

是否有偏，我

们再次计算

它的期望：

bias(ˆµm)

= E[ˆµm] − µ

(5.31)

= E

[

m

1

m∑

i=1

x

(i)

]

−

µ (5.32)

=

(

m

1

m∑

i=1

E

[

x

(i)

]

)

− µ

(5.33)

=

(

m

1

m∑

i=1

µ

)

− µ (5.34)

= µ − µ

= 0 (5.35)

因

此我们发现

样本均值是

高斯均值参

数的无偏估

计量。

示例：高

斯分布方差

估计 本例中

，我们比较高

斯分布方差

参数 σ

2

的两个

不同估

计。我

们探讨是否

有一个是有

偏的。

我们考

虑的第一个

方差估计被

称为 样本方

差（sample

variance）：

σˆm

2 =

1

m

m∑

i=1

(

x

(i) −

µˆm

)2

, (5.36)

其中 µˆm 是样

本均值。更形

式地，我们对

计算感兴趣

bias(ˆσm

2

) = E[ˆσm

2

] − σ

2

. (5.37)

5.4 估计、偏差和

方差

111

我们首

先估计项 E[ˆσm

2

]：

E[ˆσm

2

]

= E

[

m

1

m∑

i=1

(

x

(i) − µˆm

)2

]

(5.38)

=

m − 1

m

σ

2

(5.39)

回

到式

(5.37) ，我们可

以得出 σˆm

2

的偏

差是 −σ

2/m。因此样

本方差是有

偏估计。

无偏

样本方差（unbiased

sample variance）估

计

σ˜m

2

=

1

m −

1

m∑

i=1

(

x

(i) − µˆm

)2

(5.40)

提供了另

一种可选方

法。正如名字

所言，这个估

计是无偏的

。换言之，我们

会发现

E[˜σm

2

] = σ

2：

E[˜σm

2

]

= E

[

m

1

− 1

m∑

i=1

(

x

(i)

− µˆm

)2

]

(5.41)

=

m

m

− 1

E[ˆσm

2

] (5.42)

=

m

m

− 1

(

m

m

− 1

σ

2

)

(5.43)

= σ

2

.

(5.44)

我们

有两个估计

量：一个是有

偏的，另一个

是无偏的。尽

管无偏估计

显然是令

人

满意的，但它

并不总是 ‘‘最

好’’

的估计。我

们将看到，经

常会使用其

他具有重要

性

质的有偏

估计。

5.4.3 方差和

标准差

我们

有时会考虑

估计量的另

一个性质是

它作为数据

样本的函数

，期望的变化

程

度是多少

。正如我们可

以计算估计

量的期望来

决定它的偏

差，我们也可

以计算它的

方差。估计量

的 方差（variance）就是

一个方差

Var(θ

ˆ) (5.45)

其

中随机变量

是训练集。另

外，方差的平

方根被称为

标准差（standard error），记作

SE(θ

ˆ)。

112 第五章 机器

学习基础

估

计量的方差

或标准差告

诉我们，当独

立地从潜在

的数据生成

过程中重采

样数

据集时

，如何期望估

计的变化。正

如我们希望

估计的偏差

较小，我们也

希望其方差

较小。

当我们

使用有限的

样本计算任

何统计量时

，真实参数的

估计都是不

确定的，在

这

个意义下，从

相同的分布

得到其他样

本时，它们的

统计量也会

不一样。任何

方差

估计量

的期望程度

是我们想量

化的误差的

来源。

均值的

标准差被记

作

SE(ˆµm) =

v

u

u t

Var [

m

1

m∑

i=1

x

(i)

]

= √

σ

m

, (5.46)

其中

σ

2 是样

本 x

(i) 的真实方

差。标准差通

常被记作 σ。可

惜，样本方差

的平方根和

方差无偏估

计的平方根

都不是标准

差的无偏估

计。这两种计

算方法都倾

向于低估真

实的标准差

，但仍用于实

际中。相较而

言，方差无偏

估计的平方

根较少被低

估。对于

较大

的

m，这种近似

非常合理。

均

值的标准差

在机器学习

实验中非常

有用。我们通

常用测试集

样本的误差

均值

来估计

泛化误差。测

试集中样本

的数量决定

了这个估计

的精确度。中

心极限定理

告

诉我们均

值会接近一

个高斯分布

，我们可以用

标准差计算

出真实期望

落在选定区

间

的概率。例

如，以均值 µˆm 为

中心的 95%

置信

区间是

(ˆµm − 1.96SE(ˆµm),

µˆm + 1.96SE(ˆµm)), (5.47)

以上

区间是基于

均值 µˆm 和方差

SE(ˆµm)

2

的高斯分布

。在机器学习

实验中，我们

通

常说算法

A 比算法 B

好，是

指算法 A 的误

差的 95%

置信区

间的上界小

于算法 B

的误

差的 95%

置信区

间的下界。

示

例：伯努利分

布 我们再次

考虑从伯努

利分布（回顾

P(x

(i)

; θ) = θ

x

(i)

(1−θ)

1−x

(i)）

中独立同分

布采样出来

的一组样本

{x

(1), .

. . , x(m)}。这次我们关

注估计

θ

ˆm =

5.4

估计

、偏差和方差

113

1

m

∑m

i=1 x

(i) 的方差：

Var (

θ

ˆm

)

= Var (

m

1

m∑

i=1

x

(i)

)

(5.48)

=

m

1

2

m∑

i=1

Var (

x

(i)

)

(5.49)

=

m

1

2

m∑

i=1

θ(1 −

θ) (5.50)

=

1

m2 mθ(1 − θ)

(5.51)

=

1

m

θ(1 − θ) (5.52)

估计

量方差的下

降速率是关

于数据集样

本数目 m 的函

数。这是常见

估计量的普

遍性

质，在探

讨一致性（参

考第

5.4.5 节）时，我

们会继续讨

论。

5.4.4 权衡偏差

和方差以最

小化均方误

差

偏差和方

差度量着估

计量的两个

不同误差来

源。偏差度量

着偏离真实

函数或参

数

的误差期望

。而方差度量

着数据上任

意特定采样

可能导致的

估计期望的

偏差。

当我们

可以在一个

偏差更大的

估计和一个

方差更大的

估计中进行

选择时，会发

生什么呢？我

们该如何选

择？例如，想象

我们希望近

似图 5.2

中的函

数，我们只可

以

选择一个

偏差较大的

估计或一个

方差较大的

估计，我们该

如何选择呢

？

判断这种权

衡最常用的

方法是交叉

验证。经验上

，交叉验证在

真实世界的

许多任

务中

都非常成功

。另外，我们也

可以比较这

些估计的

均

方误差（mean squared error,

MSE）：

MSE = E[(θ

ˆm

− θ)

2

]

(5.53)

= Bias(θ

ˆm)

2 + Var(θ

ˆm)

(5.54)

MSE 度量

着估计和真

实参数 θ

之间

平方误差的

总体期望偏

差。如式 (5.54) 所示

，

MSE

估计包含了

偏差和方差

。理想的估计

具有较小的

MSE 或是在检查

中会稍微约

束它们的偏

差和方差。

偏

差和方差的

关系和机器

学习容量、欠

拟合和过拟

合的概念紧

密相联。用MSE 度

量泛化误差

（偏差和方差

对于泛化误

差都是有意

义的）时，增加

容量会增加

方差，降

114 第五

章 机器学习

基础

低偏差

。如图

5.6 所示，我

们再次在关

于容量的函

数中，看到泛

化误差的 U 形

曲线。

Capacity

Bias Generalization

error

Variance

Optimal

capacity

Overfitting

zone Underfitting zone

图

5.6: 当容

量增大（x 轴）时

，偏差（用点表

示）随之减小

，而方差（虚线

）随之增大，使

得泛

化误差

（加粗曲线）产

生了另一种

U

形。如果我们

沿着轴改变

容量，会发现

最佳容量，当

容量小

于最

佳容量会呈

现欠拟合，大

于时导致过

拟合。这种关

系与第 5.2 节以

及图

5.3 中讨论

的容量、欠

拟

合和过拟合

之间的关系

类似。

5.4.5

一致性

目前我们已

经探讨了固

定大小训练

集下不同估

计量的性质

。通常，我们也

会关

注训练

数据增多后

估计量的效

果。特别地，我

们希望当数

据集中数据

点的数量 m 增

加时，点估计

会收敛到对

应参数的真

实值。更形式

地，我们想要

plimm→∞θ

ˆm = θ. (5.55)

符号 plim 表示依

概率收敛，即

对于任意的

ϵ >

0，当 m → ∞

时，有 P(|θ

ˆm −

θ| >

ϵ) →

0。式(5.55) 表

示的条件被

称为 一致性

（consistency）。有时它是指

弱一致性，

强

一致性是指

几乎必然（almost

sure）从

θ

ˆ 收敛到 θ。

几乎

必然收敛（almost sure

convergence）是

指当 p(limm→∞

x

(m) = x)

= 1 时，随机

变量序列 x

(1)，x

(2)，. . .

收

敛到 x。

一致性

保证了估计

量的偏差会

随数据样本

数目的增多

而减少。然而

，反过来是

不

正确的——渐近

无偏并不意

味着一致性

。例如，考虑用

包含

m 个样本

的数据集

{x

(1),

. . . ,

x(m)} 估

计正态分布

N (x; µ,

σ2

) 的均值参数

µ。我们可以使

用数据集的

第

5.5

最大似然

估计 115

一个样

本 x

(1) 作为无偏

估计量：θ

ˆ =

x

(1)。在该

情况下，E(θ

ˆm) =

θ，所以

不管观测

到

多少数据点

，该估计量都

是无偏的。然

而，这不是一

个一致估计

，因为它不满

足当

m →

∞ 时，θ

ˆm →

θ。

5.5 最大

似然估计

之

前，我们已经

看过常用估

计的定义，并

分析了它们

的性质。但是

这些估计是

从哪里来的

呢？我们希望

有些准则可

以让我们从

不同模型中

得到特定函

数作为好的

估计，而不是

猜测某些函

数可能是好

的估计，然后

分析其偏差

和方差。

最常

用的准则是

最大似然估

计。

考虑一组

含有 m 个样本

的数据集

X = {x

(1)

, . . .

, x

(m)}，独

立地由未知

的真实数

据

生成分布

pdata(x) 生

成。

令 pmodel(x;

θ) 是一族

由 θ 确定在相

同空间上的

概率分布。换

言之，pmodel(x;

θ)

将任意

输入 x 映射到

实数来估计

真实概率

pdata(x)。

对

θ 的最大似然

估计被定义

为：

θML

= arg max

θ

pmodel(X; θ), (5.56)

=

arg max

θ

m∏

i=1

pmodel(x

(i)

;

θ). (5.57)

多个概率

的乘积会因

很多原因不

便于计算。例

如，计算中很

可能会出现

数值

下溢。为

了得到一个

便于计算的

等价优化问

题，我们观察

到似然对数

不会改变其

arg

max 但是将乘积

转化成了便

于计算的求

和形式：

θML =

arg max

θ

m∑

i=1

log pmodel(x

(i)

; θ). (5.58)

因为

当我们重新

缩放代价函

数时

arg max 不会改

变，我们可以

除以 m

得到和

训练数

据经

验分布 pˆdata 相关

的期望作为

准则：

θML = arg max

θ

Ex∼pˆdata log pmodel(x;

θ). (5.59)

一种解

释最大似然

估计的观点

是将它看作

最小化训练

集上的经验

分布 pˆdata

和模

116 第

五章 机器学

习基础

型分

布之间的差

异，两者之间

的差异程度

可以通过 KL 散

度度量。KL 散度

被定义为

DKL(ˆpdata∥pmodel) = Ex∼pˆdata [log

pˆdata(x) − log pmodel(x)].

(5.60)

左

边一项仅涉

及到数据生

成过程，和模

型无关。这意

味着当我们

训练模型最

小化 KL

散度时

，我们只需要

最小化

− Ex∼pˆdata [log pmodel(x)],

(5.61)

当然

，这和式 (5.59) 中最

大化是相同

的。

最小化 KL 散

度其实就是

在最小化分

布之间的交

叉熵。许多作

者使用术语

“交

叉熵’’

特定

表示伯努利

或 softmax 分布的负

对数似然，但

那是用词不

当的。任何一

个由负对数

似然组成的

损失都是定

义在训练集

上的经验分

布和定义在

模型上的概

率

分布之间

的交叉熵。例

如，均方误差

是经验分布

和高斯模型

之间的交叉

熵。

我们可以

将最大似然

看作是使模

型分布尽可

能地和经验

分布 pˆdata 相匹配

的尝

试。理想

情况下，我们

希望匹配真

实的数据生

成分布

pdata，但我

们没法直接

知道这

个分

布。

虽然最优

θ 在最大化似

然或是最小

化

KL 散度时是

相同的，但目

标函数值是

不

一样的。在

软件中，我们

通常将两者

都称为最小

化代价函数

。因此最大化

似然变成

了

最小化负对

数似然（NLL)，或者

等价的是最

小化交叉熵

。将最大化似

然看作最小

化

KL 散度的视

角在这个情

况下是有帮

助的，因为已

知 KL 散度最小

值是零。当

x

取

实数时，负对

数似然是负

值。

5.5.1 条件对数

似然和均方

误差

最大似

然估计很容

易扩展到估

计条件概率

P(y | x; θ)，从而给定

x 预

测 y。实

际上这

是最常见的

情况，因为这

构成了大多

数监督学习

的基础。如果

X

表示所有的

输入，Y 表示我

们观测到的

目标，那么条

件最大似然

估计是

θML =

arg max

θ

P(Y

| X; θ). (5.62)

如果

假设样本是

独立同分布

的，那么这可

以分解成

θML = arg

max

θ

m∑

i=1

log P(y

(i)

|

x

(i)

; θ).

(5.63)

5.5 最

大似然估计

117

示例：线性回

归作为最大

似然

第 5.1.4 节介

绍的线性回

归，可以被看

作是最大似

然

过程。之前

，我们将线性

回归作为学

习从输入

x 映

射到输出 yˆ 的

算法。从

x 到 yˆ 的

映射选自最

小化均方误

差（我们或多

或少介绍的

一个标准）。现

在，我们以最

大似然

估计

的角度重新

审视线性回

归。我们现在

希望模型能

够得到条件

概率 p(y | x)，而不

只

是得到一个

单独的预测

yˆ。想象有一个

无限大的训

练集，我们可

能会观测到

几个训

练样

本有相同的

输入 x 但是不

同的

y。现在学

习算法的目

标是拟合分

布 p(y | x)

到和

x 相匹

配的不同的

y。为了得到我

们之前推导

出的相同的

线性回归算

法，我们定义

p(y |

x) = N (y;

ˆy(x; w), σ2

)。函数

yˆ(x; w) 预测高

斯的均值。在

这个例子中

，我们假

设方

差是用户固

定的某个常

量

σ

2。这种函数

形式 p(y |

x) 会使得

最大似然估

计得出

和之

前相同的学

习算法。由于

假设样本是

独立同分布

的，条件对数

似然（式 (5.63)

）

如下

m∑

i=1

log

p(y

(i)

| x

(i)

; θ) (5.64)

= − m log

σ −

m

2

log(2π) −

m∑

i=1

ˆy

(i)

2

−

σ

2

y

(i)

2

, (5.65)

其中 yˆ

(i) 是线性

回归在第

i 个

输入 x

(i)

上的输

出，m 是训练样

本的数目。对

比均方

误差

和对数似然

，

MSEtrain

=

m

1

m∑

i=1

yˆ

(i) − y

(i)

2

, (5.66)

我们立刻可

以看出最大

化关于

w 的对

数似然和最

小化均方误

差会得到相

同的参数估

计 w。但是对于

相同的最优

w，这两个准则

有着不同的

值。这验证了

MSE 可以用

于最

大似然估计

。正如我们将

看到的，最大

似然估计有

几个理想的

性质。

5.5.2 最大似

然的性质

最

大似然估计

最吸引人的

地方在于，它

被证明当样

本数目

m → ∞ 时，就

收敛

率而言

是最好的渐

近估计。

在合

适的条件下

，最大似然估

计具有一致

性（参考第 5.4.5 节

），意味着训练

样

本数目趋

向于无穷大

时，参数的最

大似然估计

会收敛到参

数的真实值

。这些条件是

：

• 真实分布 pdata

必

须在模型族

pmodel(·; θ) 中。否则，没有

估计可以还

原 pdata。

118 第五章 机

器学习基础

• 真实分布

pdata 必

须刚好对应

一个 θ 值。否则

，最大似然估

计恢复出真

实分布

pdata 后，也

不能决定数

据生成过程

使用哪个 θ。

除

了最大似然

估计，还有其

他的归纳准

则，其中许多

共享一致估

计的性质。然

而，一致估计

的

统计效率

（statistic efficiency）可能区别很

大。某些一致

估计可能会

在固定数目

的样本上获

得一个较低

的泛化误差

，或者等价地

，可能只需要

较少的样

本

就能达到一

个固定程度

的泛化误差

。

统计效率通

常用于

有参

情况（parametric case）的研究

中（例如线性

回归）。有

参情

况中我们的

目标是估计

参数值（假设

有可能确定

真实参数），而

不是函数值

。一

种度量我

们和真实参

数相差多少

的方法是计

算均方误差

的期望，即计

算

m 个从数据

生成分布中

出来的训练

样本上的估

计参数和真

实参数之间

差值的平方

。有参均方误

差估计随着

m 的增加而减

少，当 m

较大时

，Cramér-Rao 下界 (Rao, 1945;

Cramér,

1946) 表明不

存在均方误

差低于最大

似然估计的

一致估计。

因

为这些原因

（一致性和统

计效率），最大

似然通常是

机器学习中

的首选估计

。

当样本数目

小到会发生

过拟合时，正

则化策略如

权重衰减可

用于获得训

练数据有限

时方差较小

的最大似然

有偏版本。

5.6 贝

叶斯统计

至

此我们已经

讨论了

频率

派统计（frequentist statistics）方法

和基于估计

单一

值 θ

的方

法，然后基于

该估计作所

有的预测。另

一种方法是

在做预测时

会考虑所有

可能的 θ。后者

属于 贝叶斯

统计（Bayesian statistics）的范畴

。

正如第 5.4.1 节中

讨论的，频率

派的视角是

真实参数 θ

是

未知的定值

，而点估计

θˆ 是

考虑数据集

上函数（可以

看作是随机

的）的随机变

量。

贝叶斯统

计的视角完

全不同。贝叶

斯用概率反

映知识状态

的确定性程

度。数据

集能

够被直接观

测到，因此不

是随机的。另

一方面，真实

参数 θ 是未知

或不确定的

，

因此可以表

示成随机变

量。

在观察到

数据前，我们

将 θ 的已知知

识表示成 先

验概率分布

（prior

probability

distribution），p(θ)（有时简单地

称为 ‘‘先验’’）。一

般而言，机器

学习实践者

会选择

一个

相当宽泛的

（即，高熵的）先

验分布，反映

在观测到任

何数据前参

数

θ 的高度

不

确定性。例如

，我们可能会

假设先验 θ

在

有限区间中

均匀分布。许

多先验偏好

于

5.6 贝叶斯统

计 119

‘‘更简单’’ 的

解（如小幅度

的系数，或是

接近常数的

函数）。

现在假

设我们有一

组数据样本

{x

(1),

. . . ,

x(m)}。通过贝叶斯

规则结合数

据似然

p(x

(1), .

. . , x(m)

| θ) 和先

验，我们可以

恢复数据对

我们关于 θ

信

念的影响：

p(θ | x

(1), . . .

, x(m)

) =

p(x

(1), . .

. , x(m)

|

θ)p(θ)

p(x

(1), .

. . , x(m))

(5.67)

在

贝叶斯估计

常用的情景

下，先验开始

是相对均匀

的分布或高

熵的高斯分

布，观测

数据

通常会使后

验的熵下降

，并集中在参

数的几个可

能性很高的

值。

相对于最

大似然估计

，贝叶斯估计

有两个重要

区别。第一，不

像最大似然

方法预

测时

使用 θ 的点估

计，贝叶斯方

法使用 θ

的全

分布。例如，在

观测到 m 个样

本后，

下一个

数据样本

x

(m+1) 的

预测分布如

下：

p(x

(m+1) | x

(1),

. . . ,

x(m)

) = ∫

p(x

(m+1) | θ)p(θ

| x

(1), .

. . , x(m)

) dθ. (5.68)

这里，每个

具有正概率

密度的

θ 的值

有助于下一

个样本的预

测，其中贡献

由后验密

度

本身加权。在

观测到数据

集 {x

(1), . . .

, x(m)} 之后，如果

我们仍然非

常不确定 θ

的

值，那么这个

不确定性会

直接包含在

我们所做的

任何预测中

。

在第 5.4 节中，我

们已经探讨

频率派方法

解决给定点

估计

θ 的不确

定性的方法

是评估方差

，估计的方差

评估了观测

数据重新从

观测数据中

采样后，估计

可能如何

变

化。对于如何

处理估计不

确定性的这

个问题，贝叶

斯派的答案

是积分，这往

往会

防止过

拟合。当然，积

分仅仅是概

率法则的应

用，使贝叶斯

方法容易验

证，而频率

派

机器学习基

于相当特别

的决定构建

了一个估计

，将数据集里

的所有信息

归纳到一

个

单独的点估

计。

贝叶斯方

法和最大似

然方法的第

二个最大区

别是由贝叶

斯先验分布

造成的。先

验

能够影响概

率质量密度

朝参数空间

中偏好先验

的区域偏移

。实践中，先验

通常表

现为

偏好更简单

或更光滑的

模型。对贝叶

斯方法的批

判认为先验

是人为主观

判断影

响预

测的来源。

当

训练数据很

有限时，贝叶

斯方法通常

泛化得更好

，但是当训练

样本数目很

大

时，通常会

有很大的计

算代价。

示例

：贝叶斯线性

回归 我们使

用贝叶斯估

计方法学习

线性回归的

参数。在线性

回

归中，我们

学习从输入

向量 x

∈ R

n 预测标

量

y ∈ R 的线性映

射。该预测由

向量

120 第五章

机器学习基

础

w ∈

R

n 参数化：

yˆ

= w

⊤x. (5.69)

给

定一组 m 个训

练样本 (X

(train)

, y

(train)

)，我们

可以表示整

个训练集对

y 的预测：

yˆ

(train)

= X

(train)w. (5.70)

表示

为 y

(train) 上的高斯

条件分布，我

们得到

p(y

(train)

| X

(train)

, w) =

N (y

(train)

;

X

(train)w, I) (5.71)

∝ exp (

−

1

2

(y

(train)

− X

(train)w)

⊤(y

(train) − X

(train)w)

)

,

(5.72)

其中

，我们根据标

准的

MSE 公式假

设 y 上的高斯

方差为

1。在下

文中，为减少

符号

负担，我

们将 (X

(train)

, y

(train)

)

简单表

示为 (X, y)。

为确定

模型参数向

量

w 的后验分

布，我们首先

需要指定一

个先验分布

。先验应

该反

映我们对这

些参数取值

的信念。虽然

有时将我们

的先验信念

表示为模型

的参数

很难

或很不自然

，但在实践中

我们通常假

设一个相当

广泛的分布

来表示

θ 的高

度不

确定性

。实数值参数

通常使用高

斯作为先验

分布：

p(w)

= N (w; µ0,

Λ0) ∝ exp (

−

1

2

(w

− µ0)

⊤Λ

−

0

1

(w −

µ0)

)

, (5.73)

其中，µ0 和

Λ0 分别是先验

分布的均值

向量和协方

差矩阵。1

确定

好先验后，我

们现在可以

继续确定模

型参数的后

验分布。

p(w | X, y)

∝ p(y | X,

w)p(w) (5.74)

∝ exp

(

−

1

2

(y − Xw)

⊤(y

− Xw)

)

exp

(

−

2

1

(w − µ0)

⊤Λ

−

0

1

(w

− µ0)

)

(5.75)

∝ exp (

−

1

2

(

−2y

⊤Xw + w

⊤X

⊤Xw + w

⊤Λ

−

0

1w −

2µ

⊤

0 Λ

−

0

1w

)

)

.

(5.76)

1除非

有理由使用

协方差矩阵

的特定结构

，我们通常假

设其为对角

协方差矩阵

Λ0

= diag(λ0)。

5.6 贝叶斯统计

121

现在我们定

义 Λm = (X

⊤X + Λ

−

0

1

)

−1

和 µm = Λm(X

⊤

y + Λ

−

0

1µ0)。使用这

些新的

变量

，我们发现后

验可改写为

高斯分布：

p(w | X, y)

∝ exp (

−

2

1

(w −

µm)

⊤Λ

−

m

1

(w − µm)

+ 1

2

µ

⊤

mΛ

−

m

1µm

)

(5.77)

∝

exp (

−

1

2

(w − µm)

⊤Λ

−

m

1

(w − µm)

)

. (5.78)

分

布的积分必

须归一这个

事实意味着

要删去所有

不包括参数

向量 w

的项。式

(3.23) 显

示了如何

标准化多元

高斯分布。

检

查此后验分

布可以让我

们获得贝叶

斯推断效果

的一些直觉

。大多数情况

下，

我们设置

µ0 = 0。如果我们设

置 Λ0

= α

1

I，那么

µm 对 w 的

估计就和频

率派带权重

衰减惩罚

αw⊤w 的

线性回归的

估计是一样

的。一个区别

是若 α 设为

0 则

贝叶斯估

计

是未定义的

——我们不能将

贝叶斯学习

过程初始化

为一个无限

宽的 w

先验。更

重

要的区别

是贝叶斯估

计会给出一

个协方差矩

阵，表示 w 所有

不同值的可

能范围，而

不

仅是估计 µm。

5.6.1 最

大后验

(MAP) 估计

原则上，我们

应该使用参

数 θ 的完整贝

叶斯后验分

布进行预测

，但单点估计

常常也是需

要的。希望使

用点估计的

一个常见原

因是，对于大

多数有意义

的模型而

言

，大多数涉及

到贝叶斯后

验的计算是

非常棘手的

，点估计提供

了一个可行

的近似

解。我

们仍然可以

让先验影响

点估计的选

择来利用贝

叶斯方法的

优点，而不是

简单

地回到

最大似然估

计。一种能够

做到这一点

的合理方式

是选择 最大

后验（Maximum

A Posteriori, MAP）点估计

。MAP 估计选择后

验概率最大

的点（或在

θ 是

连续值

的更

常见情况下

，概率密度最

大的点）：

θMAP

= arg max

θ

p(θ | x) =

arg max

θ

log

p(x | θ) +

log p(θ). (5.79)

我们

可以认出上

式右边的

log p(x | θ)

对

应着标准的

对数似然项

，log p(θ) 对应着先

验

分布。

例如，考

虑具有高斯

先验权重 w 的

线性回归模

型。如果先验

是 N

(w; 0,

λ

1

I

2

)，

那么式

(5.79) 的

对数先验项

正比于熟悉

的权重衰减

惩罚 λw⊤w，加上一

个不依赖于

w 也不会影响

学习过程的

项。因此，具有

高斯先验权

重的MAP

贝叶斯

推断对应着

权

重衰减。

122 第

五章

机器学

习基础

正如

全贝叶斯推

断，MAP 贝叶斯推

断的优势是

能够利用来

自先验的信

息，这些

信息

无法从训练

数据中获得

。该附加信息

有助于减少

最大后验点

估计的方差

（相比

于 ML 估计

）。然而，这个优

点的代价是

增加了偏差

。

许多正规化

估计方法，例

如权重衰减

正则化的最

大似然学习

，可以被解释

为贝

叶斯推

断的 MAP 近似。这

个适应于正

则化时加到

目标函数的

附加项对应

着 log

p(θ)。

并非所有

的正则化惩

罚都对应着

MAP 贝叶斯推断

。例如，有些正

则化项可能

不是一

个概

率分布的对

数。还有些正

则化项依赖

于数据，当然

也不会是一

个先验概率

分布。

MAP 贝叶斯

推断提供了

一个直观的

方法来设计

复杂但可解

释的正则化

项。例

如，更复

杂的惩罚项

可以通过混

合高斯分布

作为先验得

到，而不是一

个单独的高

斯

分布

(Nowlan and Hinton, 1992)。

5.7 监督

学习算法

回

顾第 5.1.3

节，粗略

地说，监督学

习算法是给

定一组输入

x 和输出 y 的训

练

集，学习如

何关联输入

和输出。在许

多情况下，输

出 y 很难自动

收集，必须由

人来

提供

‘‘监

督’’，不过该术

语仍然适用

于训练集目

标可以被自

动收集的情

况。

5.7.1 概率监督

学习

本书的

大部分监督

学习算法都

是基于估计

概率分布

p(y | x) 的

。我们可以使

用最

大似然

估计找到对

于有参分布

族 p(y | x;

θ) 最好的参

数向量 θ。

我们

已经看到，线

性回归对应

于分布族

p(y | x; θ)

= N (y; θ

⊤x, I). (5.80)

通

过定义一族

不同的概率

分布，我们可

以将线性回

归扩展到分

类情况中。如

果我们

有两

个类，类 0 和类

1，那么我们只

需要指定这

两类之一的

概率。类 1

的概

率决定

了类

0 的概率，因为

这两个值加

起来必须等

于 1。

我们用于

线性回归的

实数正态分

布是用均值

参数化的。我

们提供这个

均值的任

何

值都是有效

的。二元变量

上的分布稍

微复杂些，因

为它的均值

必须始终在

0 和 1

之间。解决

这个问题的

一种方法是

使用 logistic sigmoid 函数将

线性函数的

输出压缩

5.7 监

督学习算法

123

进区间 (0,

1)。该值

可以解释为

概率：

p(y = 1

| x; θ) =

σ(θ

⊤x). (5.81)

这个方

法被称为

逻

辑回归（logistic regression），这个

名字有点奇

怪，因为该模

型用

于分类

而非回归。

线

性回归中，我

们能够通过

求解正规方

程以找到最

佳权重。相比

而言，逻辑回

归会更困难

些。其最佳权

重没有闭解

。反之，我们必

须最大化对

数似然来搜

索最优

解。我

们可以通过

梯度下降算

法最小化负

对数似然来

搜索。

通过确

定正确的输

入和输出变

量上的有参

条件概率分

布族，相同的

策略基本上

可以用于任

何监督学习

问题。

5.7.2 支持向

量机

支持向

量机（support vector machine, SVM）是监督

学习中最有

影响力的方

法

之一 (Boser et al.,

1992; Cortes and Vapnik,

1995)。类似

于逻辑回归

，这个模型也

是基于线性

函数 w⊤x + b

的。不同

于逻辑回归

的是，支持向

量机不输出

概率，只输

出

类别。当 w⊤x +

b 为正

时，支持向量

机预测属于

正类。类似地

，当 w⊤x +

b 为负

时，支

持向量机预

测属于负类

。

支持向量机

的一个重要

创新是

核技

巧（kernel trick）。核技巧观

察到许多机

器学

习算法

都可以写成

样本间点积

的形式。例如

，支持向量机

中的线性函

数可以重写

为

w

⊤x + b =

b +

m∑

i=1

αix

⊤x

(i)

,

(5.82)

其中，x

(i) 是训

练样本，α

是系

数向量。学习

算法重写为

这种形式允

许我们将 x 替

换为特征函

数 ϕ(x)

的输出，点

积替换为被

称为 核函数

（kernel function）的函数

k(x,

x

(i)

) =

ϕ(x) · ϕ(x

(i)

)。运算

符 · 表示类似

于 ϕ(x)

⊤ϕ(x

(i)

) 的点积。对

于某些特

征

空间，我们可

能不会书面

地使用向量

内积。在某些

无限维空间

中，我们需要

使用

其他类

型的内积，如

基于积分而

非加和的内

积。这种类型

内积的完整

介绍超出了

本

书的范围

。

使用核估计

替换点积之

后，我们可以

使用如下函

数进行预测

f(x)

= b +

∑

i

αik(x, x

(i)

). (5.83)

124 第五章

机器

学习基础

这

个函数关于

x 是非线性的

，关于 ϕ(x)

是线性

的。α 和 f(x) 之间的

关系也是线

性

的。核函数

完全等价于

用 ϕ(x) 预处理所

有的输入，然

后在新的转

换空间学习

线性模

型。

核

技巧十分强

大有两个原

因。首先，它使

我们能够使

用保证有效

收敛的凸优

化

技术来学

习非线性模

型（关于 x 的函

数）。这是可能

的，因为我们

可以认为

ϕ 是

固

定的，仅优

化 α，即优化算

法可以将决

策函数视为

不同空间中

的线性函数

。其二，核

函数

k 的实现方法

通常有比直

接构建 ϕ(x) 再算

点积高效很

多。

在某些情

况下，ϕ(x) 甚至可

以是无限维

的，对于普通

的显式方法

而言，这将是

无限的计算

代价。在很多

情况下，即使

ϕ(x) 是难算的，k(x, x

′

) 却

会是一个关

于 x

非线性的

、易算的函数

。举个无限维

空间易算的

核的例子，我

们构建一个

作用于非

负

整数 x 上的特

征映射

ϕ(x)。假设

这个映射返

回一个由开

头 x 个 1，随后是

无限个

0 的向

量。我们可以

写一个核函

数 k(x, x(i)

) = min(x, x(i)

)，完全等价

于对应的无

限

维点积。

最

常用的核函

数是 高斯核

（Gaussian

kernel），

k(u, v) =

N (u − v;

0, σ2

I), (5.84)

其中 N (x; µ,

Σ) 是标准

正态密度。这

个核也被称

为 径向基函

数（radial basis

func￾tion, RBF）核，因为其

值沿 v 中从

u 向

外辐射的方

向减小。高斯

核对应于无

限维空

间中

的点积，但是

该空间的推

导没有整数

上最小核的

示例那么直

观。

我们可以

认为高斯核

在执行一种

模板匹配

(template matching)。训

练标签 y 相

关

的训练样本

x 变成了类别

y 的模版。当测

试点 x

′ 到 x 的欧

几里得距离

很小，对

应的

高斯核响应

很大时，表明

x

′ 和模版 x

非常

相似。该模型

进而会赋予

相对应的训

练标签 y 较大

的权重。总的

来说，预测将

会组合很多

这种通过训

练样本相似

度加权

的训

练标签。

支持

向量机不是

唯一可以使

用核技巧来

增强的算法

。许多其他的

线性模型也

可以通过这

种方式来增

强。使用核技

巧的算法类

别被称为 核

机器（kernel machine）

或

核方

法（kernel method）(Williams and Rasmussen,

1996; Schölkopf et al.,

1999)。

核机器的

一个主要缺

点是计算决

策函数的成

本关于训练

样本的数目

是线性的。

因

为第 i

个样本

贡献 αik(x, x

(i)

) 到决策

函数。支持向

量机能够通

过学习主要

包含零

的向

量 α，以缓和这

个缺点。那么

判断新样本

的类别仅需

要计算非零

αi

对应的训

练

样本的核函

数。这些训练

样本被称为

支持向量（support vector）。

5.7

监

督学习算法

125

当数据集很

大时，核机器

的计算量也

会很大。我们

将会在第 5.9 节

回顾这个想

法。带通用核

的核机器致

力于泛化得

更好。我们将

在第

5.11 节解释

原因。现代深

度学习的设

计旨在克服

核机器的这

些限制。当前

深度学习的

复兴始于 Hinton et

al.

(2006b) 表

明神经网络

能够在 MNIST

基准

数据上胜过

RBF 核的支持向

量机。

5.7.3 其他简

单的监督学

习算法

我们

已经简要介

绍过另一个

非概率监督

学习算法，最

近邻回归。更

一般地，k-最

近

邻是一类可

用于分类或

回归的技术

。作为一个非

参数学习算

法，k-最近邻并

不局

限于固

定数目的参

数。我们通常

认为 k-最近邻

算法没有任

何参数，而是

使用训练数

据的简单函

数。事实上，它

甚至也没有

一个真正的

训练阶段或

学习过程。反

之，在

测试阶

段我们希望

在新的测试

输入 x 上产生

y，我们需要在

训练数据 X

上

找到 x 的

k-最近

邻。然后我们

返回训练集

上对应的

y 值

的平均值。这

几乎适用于

任何类型可

以确定 y 值平

均值的监督

学习。在分类

情况中，我们

可以关于

one-hot 编

码向量 c

求平

均，其中

cy = 1，其他

的 i

值取 ci = 0。然后

，我们可以解

释这些

one-hot 编码

的均值为类

别的概率分

布。作为一个

非参数学习

算法，k-近邻能

达到非常高

的容量。

例如

，假设我们有

一个用 0-1

误差

度量性能的

多分类任务

。在此设定中

，当训练样

本

数目趋向于

无穷大时，1-最

近邻收敛到

两倍贝叶斯

误差。超出贝

叶斯误差的

原因

是它会

随机从等距

离的临近点

中随机挑一

个。而存在无

限的训练数

据时，所有测

试

点

x 周围距

离为零的邻

近点有无限

多个。如果我

们使用所有

这些临近点

投票的决策

方式，而不是

随机挑选一

个，那么该过

程将会收敛

到贝叶斯错

误率。k-最近邻

的高容

量使

其在训练样

本数目大时

能够获取较

高的精度。然

而，它的计算

成本很高，另

外

在训练集

较小时泛化

能力很差。k-最

近邻的一个

弱点是它不

能学习出哪

一个特征比

其他更具识

别力。例如，假

设我们要处

理一个的回

归任务，其中

x

∈ R

100 是从各向

同

性的高斯分

布中抽取的

，但是只有一

个变量 x1 和结

果相关。进一

步假设该特

征直

接决定

了输出，即在

所有情况中

y

= x1。最近邻回归

不能检测到

这个简单模

式。大

多数点

x 的最近邻将

取决于

x2 到 x100 的

大多数特征

，而不是单独

取决于特征

x1。

因此，小训练

集上的输出

将会非常随

机。

决策树（decision tree）及

其变种是另

一类将输入

空间分成不

同的区域，每

个区

域有独

立参数的算

法

(Breiman et al., 1984)。如图

5.7 所示

，决策树的每

个节点都与

输入空间的

一个区域相

关联，并且内

部节点继续

将区域分成

子节点下的

子区域（通

常

使用坐标轴

拆分区域）。空

间由此细分

成不重叠的

区域，叶节点

和输入区域

之间形

126

第五

章 机器学习

基础

成一一

对应的关系

。每个叶结点

将其输入区

域的每个点

映射到相同

的输出。决策

树

通常有特

定的训练算

法，超出了本

书的范围。如

果允许学习

任意大小的

决策树，那

么

它可以被视

作非参数算

法。然而实践

中通常有大

小限制，作为

正则化项将

其转变

成有

参模型。由于

决策树通常

使用坐标轴

相关的拆分

，并且每个子

节点关联到

常数

输出，因

此有时解决

一些对于逻

辑回归很简

单的问题很

费力。例如，假

设有一个二

分类问题，当

x2 >

x1 时分为正类

，则决策树的

分界不是坐

标轴对齐的

。因此，决策

树

将需要许多

节点近似决

策边界，坐标

轴对齐使其

算法步骤不

断地来回穿

梭于真正

的

决策函数。

正

如我们已经

看到的，最近

邻预测和决

策树都有很

多的局限性

。尽管如此，在

计算资源受

限制时，它们

都是很有用

的学习算法

。通过思考复

杂算法和 k-最

近邻或

决策

树之间的相

似性和差异

，我们可以建

立对更复杂

学习算法的

直觉。

读者可

以参考

Murphy (2012); Bishop (2006);

Hastie et al. (2001)

或其

他机器

学习

教科书了解

更多的传统

监督学习算

法。

5.7 监督学习

算法

127

0

1

01

111

0 1

011

1111 1110

110

10

010

00

1110 1111

110

10 01 00

010 011

11

111

11

图 5.7: 描述

一个决策树

如何工作的

示意图。(上)

树

中每个节点

都选择将输

入样本送到

左子节点

(0) 或

者右子节点

(1)。内部的节点

用圆圈表示

，叶节点用方

块表示。每一

个节点可以

用一个二值

的

字符串识

别并对应树

中的位置，这

个字符串是

通过给起父

亲节点的字

符串添加一

个位元来实

现的

（0 表示选

择左或者上

，1 表示选择右

或者下）。(下) 这

个树将空间

分为区域。这

个二维平面

说明决

策树

可以分割 R

2。这

个平面中画

出了树的节

点，每个内部

点穿过分割

线并用来给

样本分类，叶

节

点画在样

本所属区域

的中心。结果

是一个分块

常数函数，每

一个叶节点

一个区域。每

个叶需要至

少一个训练

样本来定义

，所以决策树

不可能用来

学习一个局

部极大值比

训练样本数

量还多的函

数。

128 第五章 机

器学习基础

5.8 无监督学习

算法

回顾第

5.1.3 节，无监督算

法只处理 “特

征’’，不操作监

督信号。监督

和无监督

算

法之间的区

别没有规范

严格的定义

，因为没有客

观的判断来

区分监督者

提供的值

是

特征还是目

标。通俗地说

，无监督学习

的大多数尝

试是指从不

需要人为注

释的样

本的

分布中抽取

信息。该术语

通常与密度

估计相关，学

习从分布中

采样、学习从

分

布中去噪

、寻找数据分

布的流形或

是将数据中

相关的样本

聚类。

一个经

典的无监督

学习任务是

找到数据的

‘‘最佳’’

表示。‘‘最

佳’’ 可以是不

同的

表示，但

是一般来说

，是指该表示

在比本身表

示的信息更

简单或更易

访问而受到

一

些惩罚或

限制的情况

下，尽可能地

保存关于

x 更

多的信息。

有

很多方式定

义较简单的

表示。最常见

的三种包括

低维表示、稀

疏表示和独

立

表示。低维

表示尝试将

x

中的信息尽

可能压缩在

一个较小的

表示中。稀疏

表示将数

据

集嵌入到输

入项大多数

为零的表示

中 (Barlow, 1989;

Olshausen and Field, 1996;

Hinton and Ghahramani, 1997)。稀疏表示

通常用于需

要增加表示

维数的情况

，使得

大部分

为零的表示

不会丢失很

多信息。这会

使得表示的

整体结构倾

向于将数据

分布

在表示

空间的坐标

轴上。独立表

示试图分开

数据分布中

变化的来源

，使得表示的

维

度是统计

独立的。

当然

这三个标准

并非相互排

斥的。低维表

示通常会产

生比原始的

高维数据具

有

较少或较

弱依赖关系

的元素。这是

因为减少表

示大小的一

种方式是找

到并消除冗

余。

识别并去

除更多的冗

余使得降维

算法在丢失

更少信息的

同时显现更

大的压缩。

表

示的概念是

深度学习核

心主题之一

，因此也是本

书的核心主

题之一。本节

会

介绍表示

学习算法中

的一些简单

示例。总的来

说，这些示例

算法会说明

如何实施上

面的三个标

准。剩余的大

部分章节会

介绍额外的

表示学习算

法，它们以不

同方式处

理

这三个标准

或是引入其

他标准。

5.8.1 主成

分分析

在第

2.12

节中，我们看

到 PCA 算法提供

了一种压缩

数据的方式

。我们也可以

将 PCA

视为学习

数据表示的

无监督学习

算法。这种表

示基于上述

简单表示的

两个标

准。 PCA 学

习一种比原

始输入维数

更低的表示

。它也学习了

一种元素之

间彼此没有

线性相关的

表示。这是学

习表示中元

素统计独立

标准的第一

步。要实现完

全独立性，

表

示学习算法

也必须去掉

变量间的非

线性关系。

5.8 无

监督学习算

法 129

如图 5.8 所示

，PCA 将输入

x 投影

表示成 z，学习

数据的正交

线性变换。在

第 2.12

节中，我们

看到了如何

学习重建原

始数据的最

佳一维表示

（就均方误差

而

言），这种表

示其实对应

着数据的第

一个主要成

分。因此，我们

可以用 PCA 作为

保

留数据尽

可能多信息

的降维方法

（再次就最小

重构误差平

方而言）。在下

文中，我们

将

研究 PCA 表示如

何使原始数

据表示

X 去相

关的.

−20 −10

0 10 20

x1

−20

−10

0

10

20

−20 −10 0

10 20

z1

−20

−10

0

10

20

图 5.8: PCA 学习

一种线性投

影，使最大方

差的方向和

新空间的轴

对齐。(左)

原始

数据包含了

x

的样本。在这

个空间中，方

差的方向与

轴的方向并

不是对齐的

。(右) 变换过的

数据 z

= x

⊤W 在

轴 z1 的

方向上有最

大的变化。第

二大变化方

差的方向沿

着轴 z2。

假设有

一个 m × n

的设计

矩阵 X，数据的

均值为零，E[x ] =

0。若

非如此，通

过

预处理步骤

使所有样本

减去均值，数

据可以很容

易地中心化

。

X 对应的无偏

样本协方差

矩阵给定如

下

Var[x ] = 1

m − 1

X

⊤X. (5.85)

PCA 通过线性

变换找到一

个

Var[z] 是对角矩

阵的表示 z =

W⊤

x。

在

第 2.12

节，我们已

知设计矩阵

X 的主成分由

X

⊤X 的特征向量

给定。从这个

角度，我们有

X

⊤X = WΛW⊤

.

(5.86)

本节中，我们

会探索主成

分的另一种

推导。主成分

也可以通过

奇异值分解

(SVD) 得

到。具体来

说，它们是

X 的

右奇异向量

。为了说明这

点，假设 W 是奇

异值分解

X = UΣW⊤ 的

右奇异向量

。以

W 作为特征

向量基，我们

可以得到原

来的特征向

量

x2

z2

130 第五章 机

器学习基础

方程：

X

⊤X =

(

UΣW⊤

)⊤

UΣW⊤ = WΣ

2W⊤

. (5.87)

SVD

有助于

说明 PCA 后的 Var[z]

是

对角的。使用

X 的 SVD 分解，X

的方

差

可以表示

为

Var[x] =

1

m − 1

X

⊤X (5.88)

=

1

m − 1

(

UΣW⊤

)⊤

UΣW⊤

(5.89)

=

1

m

− 1

WΣ

⊤U

⊤UΣW⊤

(5.90)

=

1

m − 1

WΣ

2W⊤

, (5.91)

其中，我们

使用

U

⊤U = I，因为根

据奇异值的

定义矩阵

U 是

正交的。这表

明 z 的

协方差

满足对角的

要求：

Var[z] = 1

m − 1

Z

⊤Z (5.92)

=

1

m − 1

W⊤X

⊤XW (5.93)

=

1

m − 1

W⊤WΣ

2W⊤W (5.94)

=

1

m − 1

Σ

2

, (5.95)

其中，再

次使用

SVD 的定

义有 W⊤W =

I。

以上分

析指明当我

们通过线性

变换 W 将数据

x

投影到 z 时，得

到的数据表

示

的协方差

矩阵是对角

的（即

Σ

2），立刻可

得 z 中的元素

是彼此无关

的。

PCA 这种将数

据变换为元

素之间彼此

不相关表示

的能力是 PCA 的

一个重要性

质。它是消除

数据中未知

变化因素的

简单表示示

例。在

PCA 中，这个

消除是通过

寻

找输入空

间的一个旋

转（由 W

确定），使

得方差的主

坐标和 z 相关

的新表示空

间的

基对齐

。

虽然相关性

是数据元素

间依赖关系

的一个重要

范畴，但我们

对于能够消

除更复

杂形

式的特征依

赖的表示学

习也很感兴

趣。对此，我们

需要比简单

线性变换更

强的

工具。

5.8

无

监督学习算

法 131

5.8.2 k-均值聚类

另外一个简

单的表示学

习算法是

k-均

值聚类。k-均值

聚类算法将

训练集分成

k

个靠近彼此

的不同样本

聚类。因此我

们可以认为

该算法提供

了 k-维的 one-hot

编码

向量 h 以表示

输入 x。当

x 属于

聚类 i 时，有

hi = 1，h 的

其他项为零

。

k-均值聚类提

供的 one-hot 编码也

是一种稀疏

表示，因为每

个输入的表

示中大

部分

元素为零。之

后，我们会介

绍能够学习

更灵活的稀

疏表示的一

些其他算法

（表

示中每个

输入 x 不只一

个非零项）。one-hot 编

码是稀疏表

示的一个极

端示例，丢失

了很多分布

式表示的优

点。one-hot

编码仍然

有一些统计

优点（自然地

传达了相同

聚

类中的样

本彼此相似

的观点），也具

有计算上的

优势，因为整

个表示可以

用一个单独

的整数表示

。

k-均值聚类初

始化 k

个不同

的中心点 {µ

(1)

,

. . . ,

µ

(k)}，然

后迭代交换

两个不同

的

步骤直到收

敛。步骤一，每

个训练样本

分配到最近

的中心点 µ

(i) 所

代表的聚类

i。

步骤二，每一

个中心点 µ

(i) 更

新为聚类 i 中

所有训练样

本

x

(j) 的均值。

关

于聚类的一

个问题是聚

类问题本身

是病态的。这

是说没有单

一的标准去

度量

聚类的

数据在真实

世界中效果

如何。我们可

以度量聚类

的性质，例如

类中元素到

类

中心点的

欧几里得距

离的均值。这

使我们可以

判断从聚类

分配中重建

训练数据的

效

果如何。然

而我们不知

道聚类的性

质是否很好

地对应到真

实世界的性

质。此外，可

能

有许多不同

的聚类都能

很好地对应

到现实世界

的某些属性

。我们可能希

望找到和

一

个特征相关

的聚类，但是

得到了一个

和任务无关

的，同样是合

理的不同聚

类。例

如，假设

我们在包含

红色卡车图

片、红色汽车

图片、灰色卡

车图片和灰

色汽车图片

的数据集上

运行两个聚

类算法。如果

每个聚类算

法聚两类，那

么可能一个

算法将汽

车

和卡车各聚

一类，另一个

根据红色和

灰色各聚一

类。假设我们

还运行了第

三个聚

类算

法，用来决定

类别的数目

。这有可能聚

成了四类，红

色卡车、红色

汽车、灰色卡

车和灰色汽

车。现在这个

新的聚类至

少抓住了属

性的信息，但

是丢失了相

似性信息。

红

色汽车和灰

色汽车在不

同的类中，正

如红色汽车

和灰色卡车

也在不同的

类中。该

聚类

算法没有告

诉我们灰色

汽车和红色

汽车的相似

度比灰色卡

车和红色汽

车的相似

度

更高。我们只

知道它们是

不同的。

这些

问题说明了

一些我们可

能更偏好于

分布式表示

（相对于

one-hot 表示

而言）

的原因

。分布式表示

可以对每个

车辆赋予两

个属性——一个

表示它颜色

，一个表示

它

是汽车还是

卡车。目前仍

然不清楚什

么是最优的

分布式表示

（学习算法如

何知道

我们

关心的两个

属性是颜色

和是否汽车

或卡车，而不

是制造商和

车龄？），但是多

个

132 第五章 机

器学习基础

属性减少了

算法去猜我

们关心哪一

个属性的负

担，允许我们

通过比较很

多属性而非

测试一个单

一属性来细

粒度地度量

相似性。

5.9 随机

梯度下降

几

乎所有的深

度学习算法

都用到了一

个非常重要

的算法： 随机

梯度下降

（stochastic gradient descent, SGD）。随

机梯度下降

是第

4.3 节介绍

的梯度下降

算

法的一个

扩展。

机器学

习中反复出

现的一个问

题是好的泛

化需要大的

训练集，但大

的训练集的

计算代价也

更大。

机器学

习算法中的

代价函数通

常可以分解

成每个样本

的代价函数

的总和。例如

，

训练数据的

负条件对数

似然可以写

成

J(θ) =

Ex,y∼pˆdata L(x, y, θ)

=

m

1

m∑

i=1

L(x

(i)

,

y(i)

, θ), (5.96)

其中 L 是每

个样本的损

失L(x, y,

θ) = − log

p(y | x; θ)。

对于这些

相加的代价

函数，梯度下

降需要计算

∇θJ(θ) = 1

m

m∑

i=1

∇θL(x

(i)

, y(i)

, θ).

(5.97)

这个运算的

计算代价是

O(m)。随着训练集

规模增长为

数十亿的样

本，计算一步

梯度

也会消

耗相当长的

时间。

随机梯

度下降的核

心是，梯度是

期望。期望可

使用小规模

的样本近似

估计。具

体而

言，在算法的

每一步，我们

从训练集中

均匀抽出一

小批量（minibatch）样本

B = {x

(1)

, . . .

, x

(m′

)}。小批量的数

目

m′ 通常是一

个相对较小

的数，从一到

几百。重

要的

是，当训练集

大小 m

增长时

，m′ 通常是固定

的。我们可能

在拟合几十

亿的样

本时

，每次更新计

算只用到几

百个样本。

梯

度的估计可

以表示成

g =

1

m′

∇θ

m′ ∑

i=1

L(x

(i)

, y(i)

, θ). (5.98)

使

用来自小批

量

B 的样本。然

后，随机梯度

下降算法使

用如下的梯

度下降估计

：

θ ←

θ − ϵg, (5.99)

5.10 构建机器学

习算法 133

其中

，ϵ

是学习率。

梯

度下降往往

被认为很慢

或不可靠。以

前，将梯度下

降应用到非

凸优化问题

被

认为很鲁

莽或没有原

则。现在，我们

知道梯度下

降用于本书

第二部分中

的训练时效

果不错。优化

算法不一定

能保证在合

理的时间内

达到一个局

部最小值，但

它通常能

及

时地找到代

价函数一个

很小的值，并

且是有用的

。

随机梯度下

降在深度学

习之外有很

多重要的应

用。它是在大

规模数据上

训练大

型线

性模型的主

要方法。对于

固定大小的

模型，每一步

随机梯度下

降更新的计

算量

不取决

于训练集的

大小 m。在实践

中，当训练集

大小增长时

，我们通常会

使用一个

更

大的模型，但

这并非是必

须的。达到收

敛所需的更

新次数通常

会随训练集

规模增

大而

增加。然而，当

m 趋向于无穷

大时，该模型

最终会在随

机梯度下降

抽样完训练

集上的所有

样本之前收

敛到可能的

最优测试误

差。继续增加

m 不会延长达

到模型可

能

的最优测试

误差的时间

。从这点来看

，我们可以认

为用 SGD 训练模

型的渐近代

价

是关于

m 的

函数的 O(1) 级别

。

在深度学习

兴起之前，学

习非线性模

型的主要方

法是结合核

技巧的线性

模型。

很多核

学习算法需

要构建一个

m × m

的矩阵 Gi,j = k(x

(i)

, x

(j)

)。构建

这个矩阵的

计

算量是 O(m2

)。当

数据集是几

十亿个样本

时，这个计算

量是不能接

受的。在学术

界，

深度学习

从 2006 年开始受

到关注的原

因是，在数以

万计样本的

中等规模数

据集上，

深度

学习在新样

本上比当时

很多热门算

法泛化得更

好。不久后，深

度学习在工

业界

受到了

更多的关注

，因为其提供

了一种训练

大数据集上

的非线性模

型的可扩展

方式。

我们将

会在第八章

继续探讨随

机梯度下降

及其很多改

进方法。

5.10 构建

机器学习算

法

几乎所有

的深度学习

算法都可以

被描述为一

个相当简单

的配方：特定

的数据集、

代

价函数、优化

过程和模型

。

例如，线性回

归算法由以

下部分组成

：X 和

y 构成的数

据集，代价函

数

J(w, b)

= −Ex,y∼pˆdata log pmodel(y

| x), (5.100)

模型是

pmodel(y | x) =

N (y; x

⊤w

+ b, 1)，在

大多数情况

下，优化算法

可以定义为

求

解代价函

数梯度为零

的正规方程

。

意识到我们

可以替换独

立于其他组

件的大多数

组件，因此我

们能得到很

多不同

134 第五

章 机器学习

基础

的算法

。

通常代价函

数至少含有

一项使学习

过程进行统

计估计的成

分。最常见的

代价函

数是

负对数似然

，最小化代价

函数导致的

最大似然估

计。

代价函数

也可能含有

附加项，如正

则化项。例如

，我们可以将

权重衰减加

到线

性回归

的代价函数

中

J(w, b) =

λ ∥w∥

2

2

− Ex,y∼pˆdata log pmodel(y

| x). (5.101)

该优化仍

然有闭解。

如

果我们将该

模型变成非

线性的，那么

大多数代价

函数不再能

通过闭解优

化。

这就要求

我们选择一

个迭代数值

优化过程，如

梯度下降等

。

组合模型、代

价和优化算

法来构建学

习算法的配

方同时适用

于监督学习

和无监

督学

习。线性回归

示例说明了

如何适用于

监督学习的

。无监督学习

时，我们需要

定

义一个只

包含 X 的数据

集、一个合适

的无监督代

价和一个模

型。例如，通过

指定如

下损

失函数可以

得到

PCA 的第一

个主向量

J(w) =

Ex∼pˆdata ∥x − r(x;

w)∥

2

2

(5.102)

模

型定义为重

构函数 r(x) = w⊤x

w，并且

w 有范数为 1 的

限制。

在某些

情况下，由于

计算原因，我

们不能实际

计算代价函

数。在这种情

况下，只

要我

们有近似其

梯度的方法

，那么我们仍

然可以使用

迭代数值优

化近似最小

化目标。

尽管

有时候不显

然，但大多数

学习算法都

用到了上述

配方。如果一

个机器学习

算

法看上去

特别独特或

是手动设计

的，那么通常

需要使用特

殊的优化方

法进行求解

。

有些模型，如

决策树或 k-均

值，需要特殊

的优化，因为

它们的代价

函数有平坦

的区

域，使其

不适合通过

基于梯度的

优化去最小

化。在我们认

识到大部分

机器学习算

法

可以使用

上述配方描

述之后，我们

可以将不同

算法视为出

于相同原因

解决相关问

题

的一类方

法，而不是一

长串各个不

同的算法。

5.11 促

使深度学习

发展的挑战

本章描述的

简单机器学

习算法在很

多不同的重

要问题上效

果都良好。但

是它们

不能

成功解决人

工智能中的

核心问题，如

语音识别或

者对象识别

。

5.11 促使深度学

习发展的挑

战 135

深度学习

发展动机的

一部分原因

是传统学习

算法在这类

人工智能问

题上泛化能

力不足。

本节

介绍为何处

理高维数据

时在新样本

上泛化特别

困难，以及为

何在传统机

器

学习中实

现泛化的机

制不适合学

习高维空间

中复杂的函

数。这些空间

经常涉及巨

大

的计算代

价。深度学习

旨在克服这

些以及其他

一些难题。

5.11.1

维

数灾难

当数

据的维数很

高时，很多机

器学习问题

变得相当困

难。这种现象

被称为 维数

灾难（curse of

dimensionality）。特别值

得注意的是

，一组变量不

同的可能配

置数量

会随

着变量数目

的增加而指

数级增长。

维

数灾难发生

在计算机科

学的许多地

方，在机器学

习中尤其如

此。

由维数灾

难带来的一

个挑战是统

计挑战。如图

5.9

所示，统计挑

战产生于 x 的

可能配置数

目远大于训

练样本的数

目。为了充分

理解这个问

题，我们假设

输入空间

如

图所示被分

成单元格。空

间是低维时

，我们可以用

由大部分数

据占据的少

量单元

格去

描述这个空

间。泛化到新

数据点时，通

过检测和新

输入点在相

同单元格中

的训

练样本

，我们可以判

断如何处理

新数据点。例

如，如果要估

计某点 x 处的

概率密度，

我

们可以返回

x 处单位体积

单元格内训

练样本的数

目除以训练

样本的总数

。如果我

们希

望对一个样

本进行分类

，我们可以返

回相同单元

格中训练样

本最多的类

别。如

果我们

是做回归分

析，我们可以

平均该单元

格中样本对

应的目标值

。但是，如果该

单

元格中没

有样本，该怎

么办呢？因为

在高维空间

中参数配置

数目远大于

样本数目，大

部分单元格

中没有样本

。我们如何能

在这些新配

置中找到一

些有意义的

东西呢？许

多

传统机器学

习算法只是

简单地假设

在一个新点

的输出应大

致和最接近

的训练点的

输出相同。

5.11.2 局

部不变性和

平滑正则化

为了更好地

泛化，机器学

习算法需要

由先验信念

引导应该学

习什么类型

的函数。

此前

，我们已经看

到过由模型

参数的概率

分布形成的

先验。通俗地

讲，我们也可

以说

先验信

念直接影响

函数本身，而

仅仅通过它

们对函数的

影响来间接

改变参数。此

外，

我们还能

通俗地说，先

验信念还间

接地体现在

选择一些偏

好某类函数

的算法，尽管

这些偏好并

没有通过我

们对不同函

数置信程度

的概率分布

表现出来（也

许根本没法

136 第五章

机器

学习基础

图

5.9: 当数据的相

关维度增大

时（从左向右

），我们感兴趣

的配置数目

会随之指数

级增长。(左) 在

这个一维的

例子中，我们

用一个变量

来区分所感

兴趣的

10 个区

域。当每个区

域都有足够

的样本数

时

（每个区域对

应图中的一

个单元格），学

习算法能够

轻易地泛化

得很好。泛化

的一个直接

方法是

估计

目标函数在

每个区域的

值（可能是在

相邻区域之

间插值）。(中)

在

二维情况下

，对每个变量

区

分 10 个不同

的值更加困

难。我们需要

追踪

10 × 10 =

100 个区域

，至少需要很

多样本来覆

盖所有

的区

域。(右) 三维情

况下，区域数

量增加到了

103

= 1000，至少需要那

么多的样本

。对于需要区

分的 d 维以及

v

个值来说，我

们需要 O(v

d

)

个区

域和样本。这

就是维数灾

难的一个示

例。感谢由

Nicolas Chapados 提

供的图片。

表

现）。

其中最广

泛使用的隐

式 ‘‘先验’’ 是

平

滑先验（smoothness prior），或 局

部不变

性先

验（local

constancy prior）。这个先验

表明我们学

习的函数不

应在小区域

内发生

很大

的变化。

许多

简单算法完

全依赖于此

先验达到良

好的泛化，其

结果是不能

推广去解决

人

工智能级

别任务中的

统计挑战。本

书中，我们将

介绍深度学

习如何引入

额外的（显

式

或隐式的）先

验去降低复

杂任务中的

泛化误差。这

里，我们解释

为什么仅依

靠平

滑先验

不足以应对

这类任务。

有

许多不同的

方法来显式

或隐式地表

示学习函数

应该具有光

滑或局部不

变的先

验。所

有这些不同

的方法都旨

在鼓励学习

过程能够学

习出函数 f

∗，对

于大多数设

置

x

和小变动

ϵ，都满足条件

f

∗

(x) ≈

f

∗

(x +

ϵ). (5.103)

换言之，如果

我们知道对

应输入 x

的答

案（例如，x 是个

有标签的训

练样本），那么

该答案对于

x 的邻域应该

也适用。如果

在有些邻域

中我们有几

个好答案，那

么我们

可以

组合它们（通

过某种形式

的平均或插

值法）以产生

一个尽可能

和大多数输

入一

5.11 促使深

度学习发展

的挑战 137

致的

答案。

局部不

变方法的一

个极端例子

是 k-最近邻系

列的学习算

法。当一个区

域里的所

有

点 x

在训练集

中的 k 个最近

邻是一样的

，那么对这些

点的预测也

是一样的。当

k =

1 时，不同区域

的数目不会

比训练样本

还多。

虽然 k-最

近邻算法复

制了附近训

练样本的输

出，大部分核

机器也是在

和附近训

练

样本相关的

训练集输出

上插值。一类

重要的核函

数是 局部核

（local kernel），其核

函数

k(u, v) 在

u =

v 时很大，当 u 和

v

距离拉大时

而减小。局部

核可以看作

是执

行模版

匹配的相似

函数，用于度

量测试样本

x 和每个训练

样本 x

(i) 有多么

相似。近

年来

深度学习的

很多推动力

源自研究局

部模版匹配

的局限性，以

及深度学习

如何克

服这

些局限性

(Bengio et al., 2006a)。

决

策树也有平

滑学习的局

限性，因为它

将输入空间

分成和叶节

点一样多的

区间，

并在每

个区间使用

单独的参数

（或者有些决

策树的拓展

有多个参数

）。如果目标函

数

需要至少

拥有 n

个叶节

点的树才能

精确表示，那

么至少需要

n 个训练样本

去拟合。

需要

几倍于 n

的样

本去达到预

测输出上的

某种统计置

信度。

总的来

说，区分输入

空间中 O(k) 个区

间，所有的这

些方法需要

O(k)

个样本。

通常

会有 O(k) 个参数

，O(1)

参数对应于

O(k) 区间之一。最

近邻算法中

，每个训

练样

本至多用于

定义一个区

间，如图 5.10

所示

。

图 5.10: 最近邻算

法如何划分

输入空间的

示例。每个区

域内的一个

样本（这里用

圆圈表示）定

义了

区域边

界（这里用线

表示）。每个样

本相关的 y 值

定义了对应

区域内所有

数据点的输

出。由最近

邻

定义并且匹

配几何模式

的区域被称

为

Voronoi 图。这些连

续区域的数

量不会比训

练样本的数

量

增加得更

快。尽管此图

具体说明了

最近邻算法

的效果，其他

的单纯依赖

局部光滑先

验的机器学

习

算法也表

现出了类似

的泛化能力

：每个训练样

本仅仅能告

诉学习者如

何在其周围

的相邻区域

泛化。

138 第五章

机器学习基

础

有没有什

么方法能表

示区间数目

比训练样本

数目还多的

复杂函数？显

然，只是

假设

函数的平滑

性不能做到

这点。例如，想

象目标函数

作用在西洋

跳棋盘上。棋

盘包

含许多

变化，但只有

一个简单的

结构。想象一

下，如果训练

样本数目远

小于棋盘上

的黑白方块

数目，那么会

发生什么。基

于局部泛化

和平滑性或

局部不变性

先验，如

果新

点和某个训

练样本位于

相同的棋盘

方块中，那么

我们能够保

证正确地预

测新点

的颜

色。但如果新

点所在的方

块没有训练

样本，学习器

不一定能举

一反三。如果

仅

依靠这个

先验，一个样

本只能告诉

我们它所在

的方块的颜

色。获得整个

棋盘颜色的

唯一方法是

其上的每个

方块至少要

有一个样本

。

只要在要学

习的真实函

数的峰值和

谷值处有足

够多的样本

，那么平滑性

假设和

相关

的无参数学

习算法的效

果都非常好

。当要学习的

函数足够平

滑，并且只在

少数

几维变

化，这样做一

般没问题。在

高维空间中

，即使是非常

平滑的函数

，也会在不

同

维度上有不

同的变化方

式。如果函数

在不同的区

间中表现不

一样，那么就

非常难

用一

组训练样本

去刻画函数

。如果函数是

复杂的（我们

想区分多于

训练样本数

目的

大量区

间），有希望很

好地泛化么

？

这些问题，即

是否可以有

效地表示复

杂的函数以

及所估计的

函数是否可

以很好

地泛

化到新的输

入，答案是有

。关键观点是

，只要我们通

过额外假设

生成数据的

分

布来建立

区域间的依

赖关系，那么

O(k) 个样本足以

描述多如 O(2k

)

的

大量区间。通

过这种方式

，我们确实能

做到非局部

的泛化 (Bengio and Monperrus,

2005; Bengio

et al.,

2006b)。为了

利用这些优

势，许多不同

的深度学习

算法都提出

了一些适用

于多

种 AI 任务

的隐式或显

式的假设。

一

些其他的机

器学习方法

往往会提出

更强的，针对

特定问题的

假设。例如，假

设目标函数

是周期性的

，我们很容易

解决棋盘问

题。通常，神经

网络不会包

含这些很

强

的（针对特定

任务的）假设

，因此神经网

络可以泛化

到更广泛的

各种结构中

。人

工智能任

务的结构非

常复杂，很难

限制到简单

的、人工手动

指定的性质

，如周期性，

因

此我们希望

学习算法具

有更通用的

假设。深度学

习的核心思

想是假设数

据由因素

或

特征组合产

生，这些因素

或特征可能

来自一个层

次结构的多

个层级。许多

其他类

似的

通用假设进

一步提高了

深度学习算

法。这些很温

和的假设允

许了样本数

目和可

区分

区间数目之

间的指数增

益。这类指数

增益将在第

6.4.1 节、第

15.4 节和第

15.5 节

中更详尽

地介绍。深度

的分布式表

示带来的指

数增益有效

地解决了维

数灾难带来

的

挑战。

5.11 促使

深度学习发

展的挑战 139

5.11.3 流

形学习

流形

是一个机器

学习中很多

想法内在的

重要概念。

流

形（manifold）指连接在

一起的区域

。数学上，它是

指一组点，且

每个点都

有

其邻域。给定

一个任意的

点，其流形局

部看起来像

是欧几里得

空间。日常生

活中，

我们将

地球视为二

维平面，但实

际上它是三

维空间中的

球状流形。

每

个点周围邻

域的定义暗

示着存在变

换能够从一

个位置移动

到其邻域位

置。例

如在地

球表面这个

流形中，我们

可以朝东南

西北走。

尽管

术语 “流形’’ 有

正式的数学

定义，但是机

器学习倾向

于更松散地

定义一组

点

，只需要考虑

少数嵌入在

高维空间中

的自由度或

维数就能很

好地近似。每

一维都

对应

着局部的变

化方向。如图

5.11 所示，训练数

据位于二维

空间中的一

维流形中。

在

机器学习中

，我们允许流

形的维数从

一个点到另

一个点有所

变化。这经常

发生于

流形

和自身相交

的情况中。例

如，数字

“8’’ 形状

的流形在大

多数位置只

有一维，但

在

中心的相交

处有两维。

0.5

1.0 1.5 2.0 2.5

3.0 3.5 4.0

−1.0

−0.5

0.0

0.5

1.0

1.5

2.0

2.5

图

5.11:

从一个二维

空间的分布

中抽取的数

据样本，这些

样本实际上

聚集在一维

流形附近，像

一个

缠绕的

带子。实线代

表学习器应

该推断的隐

式流形。

如果

我们希望机

器学习算法

学习整个 R

n 上

有趣变化的

函数，那么很

多机器学

习

问题看上去

都是无望的

。流形学习（manifold learning）算

法通过一个

假设来克服

这个障碍，该

假设认为

R

n 中

大部分区域

都是无效的

输入，有意义

的输入只分

布在包

含少

量数据点的

子集构成的

一组流形中

，而学习函数

的输出中，有

意义的变化

都沿

着流形

的方向或仅

发生在我们

切换到另一

流形时。流形

学习最初用

于连续数值

和无

140 第五章

机器学习基

础

监督学习

的环境，尽管

这个概率集

中的想法也

能够泛化到

离散数据和

监督学习的

设

定下：关键

假设仍然是

概率质量高

度集中。

图 5.12: 随

机地均匀抽

取图像（根据

均匀分布随

机地选择每

一个像素）会

得到噪声图

像。尽管在人

工智能应用

中以这种方

式生成一个

脸或者其他

物体的图像

是非零概率

的，但是实际

上我们从来

没

有观察到

这种现象。这

也意味着人

工智能应用

中遇到的图

像在所有图

像空间中的

占比可以是

忽略

不计的

。

数据位于低

维流形的假

设并不总是

对的或者有

用的。我们认

为在人工智

能的一

些场

景中，如涉及

到处理图像

、声音或者文

本时，流形假

设至少是近

似对的。这个

假设的支持

证据包含两

类观察结果

。

第一个支持

流形假设（manifold hypothesis）的

观察是现实

生活中的图

像、文

本、声音

的概率分布

都是高度集

中的。均匀的

噪声从来不

会与这类领

域的结构化

输

5.11

促使深度

学习发展的

挑战 141

入类似

。图 5.12

显示均匀

采样的点看

上去像是没

有信号时模

拟电视上的

静态模式。

同

样，如果我们

均匀地随机

抽取字母来

生成文件，能

有多大的概

率得到一个

有意义

的英

语文档？几乎

是零。因为大

部分字母长

序列不对应

着自然语言

序列：自然语

言

序列的分

布只占了字

母序列的总

空间里非常

小的一部分

。

当然，集中的

概率分布不

足以说明数

据位于一个

相当小的流

形中。我们还

必须

确保，我

们遇到的样

本和其他样

本相互连接

，每个样本被

其他高度相

似的样本包

围，

而这些高

度相似的样

本可以通过

变换来遍历

该流形得到

。支持流形假

设的第二个

论

点是，我们

至少能够非

正式地想象

这些邻域和

变换。在图像

中，我们当然

会认为有

很

多可能的变

换仍然允许

我们描绘出

图片空间的

流形：我们可

以逐渐变暗

或变亮光

泽

、逐步移动或

旋转图中对

象、逐渐改变

对象表面的

颜色等等。在

大多数应用

中很

有可能

会涉及到多

个流形。例如

，人脸图像的

流形不太可

能连接到猫

脸图像的流

形。

这些支持

流形假设的

思维实验传

递了一些支

持它的直观

理由。更严格

的实

验 (Cayton, 2005; Narayanan

and Mitter, 2010; Schölkopf

et al., 1998a; Roweis

and

Saul, 2000; Tenenbaum

et al., 2000; Brand,

2003a; Belkin and Niyogi,

2003b; Donoho

and Grimes,

2003; Weinberger and Saul,

2004a) 在人

工智能中备

受关注的一

大类数

据集

上支持了这

个假设。

当数

据位于低维

流形中时，使

用流形中的

坐标而非

R

n 中

的坐标表示

机器学习数

据更为自然

。日常生活中

，我们可以认

为道路是嵌

入在三维空

间的一维流

形。我们

用一

维道路中的

地址号码确

定地址，而非

三维空间中

的坐标。提取

这些流形中

的坐

标是非

常具有挑战

性的，但是很

有希望改进

许多机器学

习算法。这个

一般性原则

能

够用在很

多情况中。图

5.13 展示了包含

人脸的数据

集的流形结

构。在本书的

最后，

我们会

介绍一些学

习这样的流

形结构的必

备方法。在图

20.6

中，我们将看

到机器学

习

算法如何成

功完成这个

目标。

第一部

分介绍了数

学和机器学

习中的基本

概念，这将用

于本书其他

章节中。至

此

，我们已经做

好了研究深

度学习的准

备。

142 第五章 机

器学习基础

图 5.13:

QMUL Multiview Face 数据集中

的训练样本

(Gong

et al., 2000)，其中的物体

是移动

的从

而覆盖对应

两个旋转角

度的二维流

形。我们希望

学习算法能

够发现并且

理出这些流

形坐标。

图 20.6 提

供了这样一

个示例。

第二

部分

深度网

络：现代实践

143

144

本书这一部

分总结现代

深度学习用

于解决实际

应用的现状

。

深度学习有

着悠久的历

史和许多愿

景。数种提出

的方法尚未

完全结出果

实。数

个雄心

勃勃的目标

尚未实现。这

些较不发达

的深度学习

分支将出现

在本书的最

后部

分。

这一

部分仅关注

那些基本上

已在工业中

大量使用的

技术方法。

现

代深度学习

为监督学习

提供了一个

强大的框架

。通过添加更

多层以及向

层内

添加更

多单元，深度

网络可以表

示复杂性不

断增加的函

数。给定足够

大的模型和

足

够大的标

注训练数据

集，我们可以

通过深度学

习将输入向

量映射到输

出向量，完成

大多数对人

来说能迅速

处理的任务

。其他任务，比

如不能被描

述为将一个

向量与另

一

个相关联的

任务，或者对

于一个人来

说足够困难

并需要时间

思考和反复

琢磨才能

完

成的任务，现

在仍然超出

了深度学习

的能力范围

。

本书这一部

分描述参数

化函数近似

技术的核心

，几乎所有现

代实际应用

的深度

学习

背后都用到

了这一技术

。首先，我们描

述用于表示

这些函数的

前馈深度网

络模

型。接着

，我们提出正

则化和优化

这种模型的

高级技术。将

这些模型扩

展到大输入

（如高分辨率

图像或长时

间序列）需要

专门化。我们

将会介绍扩

展到大图像

的卷积网

络

和用于处理

时间序列的

循环神经网

络。最后，我们

提出实用方

法的一般准

则，有

助于设

计、构建和配

置一些涉及

深度学习的

应用，并回顾

其中一些应

用。

这些章节

对于从业者

来说是最重

要的，也就是

现在想开始

实现和使用

深度学

习算

法解决现实

问题的人需

要阅读这些

章节。

第六章

深度前馈网

络

深度前馈

网络（deep feedforward network），也叫作

前馈神经网

络（feedforward

neural

network）或者 多层

感知机（multilayer perceptron, MLP），是典

型的深度学

习模型。前馈

网络的目标

是近似某个

函数

f

∗。例如，对

于分类器，y = f

∗

(x) 将

输入

x

映射到

一个类别 y。前

馈网络定义

了一个映射

y = f(x;

θ)，并且学习参

数 θ 的值，

使它

能够得到最

佳的函数近

似。

这种模型

被称为 前向

（feedforward）的，是因为信

息流过 x 的函

数，流经用于

定义

f 的中间

计算过程，最

终到达输出

y。在模型的输

出和模型本

身之间没有

反馈

（feedback）连接。当

前馈神经网

络被扩展成

包含反馈连

接时，它们被

称为 循环神

经

网络（recurrent neural network），在第

十章介绍。

前

馈网络对于

机器学习的

从业者是极

其重要的。它

们是许多重

要商业应用

的基

础。例如

，用于对照片

中的对象进

行识别的卷

积神经网络

就是一种专

门的前馈网

络。

前馈网络

是通往循环

网络之路的

概念基石，后

者在自然语

言的许多应

用中发挥着

巨

大作用。

前

馈神经网络

被称作

网络

（network）是因为它们

通常用许多

不同函数复

合

在一起来

表示。该模型

与一个有向

无环图相关

联，而图描述

了函数是如

何复

合在一

起的。例如，我

们有三个函

数 f

(1), f(2) 和 f

(3) 连接在

一个链上以

形成

f(x) =

f

(3)(f

(2)(f

(1)(x)))。这些链

式结构是神

经网络中最

常用的结构

。在这种情况

下，f

(1) 被称为网

络的 第一层

（first layer），f

(2) 被称为 第二

层（second layer），以

此类推

。链的全长称

为模型的 深

度（depth）。正是因为

这个术语才

出现了 ‘‘深度

学

习’’

这个名

字。前馈网络

的最后一层

被称为 输出

层（output layer）。在神经网

络训练

的过

程中，我们让

f(x)

去匹配 f

∗

(x)

的值

。训练数据为

我们提供了

在不同训练

点上

取值的

、含有噪声的

f

∗

(x)

的近似实例

。每个样本 x 都

伴随着一个

标签 y

≈ f

∗

(x)。

训练样

本直接指明

了输出层在

每一点 x 上必

须做什么；它

必须产生一

个接近 y

的值

。

145

146 第六章

深度

前馈网络

但

是训练数据

并没有直接

指明其他层

应该怎么做

。学习算法必

须决定如何

使用这些

层

来产生想要

的输出，但是

训练数据并

没有说每个

单独的层应

该做什么。相

反，学

习算法

必须决定如

何使用这些

层来最好地

实现

f

∗ 的近似

。因为训练数

据并没有给

出

这些层中

的每一层所

需的输出，所

以这些层被

称为

隐藏层

（hidden layer）。

最后，这些网

络被称为神

经网络是因

为它们或多

或少地受到

神经科学的

启

发。网络中

的每个隐藏

层通常都是

向量值的。这

些隐藏层的

维数决定了

模型的

宽度

（width）。向量的每个

元素都可以

被视为起到

类似一个神

经元的作用

。除了将层想

象成向量到

向量的单个

函数，我们也

可以把层想

象成由许多

并行操作的

单元（unit）

组成，每

个单元表示

一个向量到

标量的函数

。每个单元在

某种意义上

类似一个神

经

元，它接收

的输入来源

于许多其他

的单元，并计

算它自己的

激活值。使用

多层向量值

表示的想法

来源于神经

科学。用于计

算这些表示

的函数 f

(i)

(x) 的选

择，也或多或

少

地受到神

经科学观测

的指引，这些

观测是关于

生物神经元

计算功能的

。然而，现代

的

神经网络研

究受到更多

的是来自许

多数学和工

程学科的指

引，并且神经

网络的目

标

并不是完美

地给大脑建

模。我们最好

将前馈神经

网络想成是

为了实现统

计泛化而

设

计出的函数

近似机，它偶

尔从我们了

解的大脑中

提取灵感，但

并不是大脑

功能的

模型

。

一种理解前

馈网络的方

式是从线性

模型开始，并

考虑如何克

服它的局限

性。线

性模型

，例如逻辑回

归和线性回

归，是非常吸

引人的，因为

无论是通过

闭解形式还

是使用凸优

化，它们都能

高效且可靠

地拟合。线性

模型也有明

显的缺陷，那

就是该

模型

的能力被局

限在线性函

数里，所以它

无法理解任

何两个输入

变量间的相

互作用。

为了

扩展线性模

型来表示

x 的

非线性函数

，我们可以不

把线性模型

用于 x 本身，

而

是用在一个

变换后的输

入 ϕ(x) 上，这里 ϕ

是

一个非线性

变换。同样，我

们可以

使用

第 5.7.2 节中描述

的核技巧，来

得到一个基

于隐含地使

用

ϕ 映射的非

线性学习算

法。我们可以

认为 ϕ 提供了

一组描述

x 的

特征，或者认

为它提供了

x 的一个新的

表

示。

剩下的

问题就是如

何选择映射

ϕ。

1. 其中一种选

择是使用一

个通用的 ϕ，例

如无限维的

ϕ，它隐含地用

在基

于 RBF 核的

核机器上。如

果 ϕ(x)

具有足够

高的维数，我

们总是有足

够的能力

来

拟合训练集

，但是对于测

试集的泛化

往往不佳。非

常通用的特

征映射通常

只

基于局部

光滑的原则

，并且没有将

足够的先验

信息进行编

码来解决高

级问题。

2.

另一

种选择是手

动地设计 ϕ。在

深度学习出

现以前，这一

直是主流的

方法。这

147

种方

法对于每个

单独的任务

都需要人们

数十年的努

力，从业者各

自擅长特定

的

领域（如语

音识别或计

算机视觉），并

且不同领域

之间很难迁

移 (transfer)。

3. 深度学习

的策略是去

学习

ϕ。在这种

方法中，我们

有一个模型

y = f(x; θ,

w) =

ϕ(x; θ)

⊤w。我们现在有

两种参数：用

于从一大类

函数中学习

ϕ 的参数 θ，以及

用于将 ϕ(x)

映射

到所需的输

出的参数 w。这

是深度前馈

网络的一个

例子，其

中 ϕ

定

义了一个隐

藏层。这是三

种方法中唯

一一种放弃

了训练问题

的凸性的，

但

是利大于弊

。在这种方法

中，我们将表

示参数化为

ϕ(x; θ)，并且使用优

化算

法来寻

找

θ，使它能够

得到一个好

的表示。如果

我们想要的

话，这种方法

也可

以通过

使它变得高

度通用以获

得第一种方

法的优点——我

们只需使用

一个非常

广

泛的函数族

ϕ(x; θ)。这种方法也

可以获得第

二种方法的

优点。人类专

家可以

将他

们的知识编

码进网络来

帮助泛化，他

们只需要设

计那些他们

期望能够表

现

优异的函

数族 ϕ(x; θ)

即可。这

种方法的优

点是人类设

计者只需要

寻找正确的

函数族即可

，而不需要去

寻找精确的

函数。

这种通

过学习特征

来改善模型

的一般化原

则不仅仅适

用于本章描

述的前馈神

经

网络。它是

深度学习中

反复出现的

主题，适用于

全书描述的

所有种类的

模型。前馈

神

经网络是这

个原则的应

用，它学习从

x

到 y 的确定性

映射并且没

有反馈连接

。后

面出现的

其他模型会

把这些原则

应用到学习

随机映射、学

习带有反馈

的函数以及

学

习单个向

量的概率分

布。

本章我们

先从前馈网

络的一个简

单例子说起

。接着，我们讨

论部署一个

前馈网

络所

需的每个设

计决策。首先

，训练一个前

馈网络至少

需要做和线

性模型同样

多的设

计决

策：选择一个

优化模型、代

价函数以及

输出单元的

形式。我们先

回顾这些基

于梯

度学习

的基本知识

，然后去面对

那些只出现

在前馈网络

中的设计决

策。前馈网络

已经

引入了

隐藏层的概

念，这需要我

们去选择用

于计算隐藏

层值的 激活

函数（activation

function）。我们还

必须设计网

络的结构，包

括网络应该

包含多少层

、这些层应该

如

何连接，以

及每一层包

含多少单元

。在深度神经

网络的学习

中需要计算

复杂函数的

梯度。我们给

出 反向传播

（back propagation）算法和它的

现代推广，它

们可以用来

高效地计算

这些梯度。最

后，我们以某

些历史观点

来结束这一

章。

148

第六章 深

度前馈网络

6.1 实例：学习 XOR

为

了使前馈网

络的想法更

加具体，我们

首先从一个

可以完整工

作的前馈网

络说

起。这个

例子解决一

个非常简单

的任务：学习

XOR 函数。

XOR

函数（‘‘异

或’’ 逻辑）是两

个二进制值

x1 和 x2

的运算。当

这些二进制

值

中恰好有

一个为 1 时，XOR

函

数返回值为

1。其余情况下

返回值为 0。XOR 函

数提

供了我

们想要学习

的目标函数

y

= f

∗

(x)。我们的模型

给出了一个

函数

y = f(x; θ)

并且我

们的学习算

法会不断调

整参数 θ 来使

得 f

尽可能接

近 f

∗。

在这个简

单的例子中

，我们不会关

心统计泛化

。我们希望网

络在这四个

点

X = {[0, 0]⊤,

[0, 1]⊤, [1, 0]⊤,

[1, 1]⊤} 上表现正

确。我们会用

全部这四个

点来训练我

们

的网络，唯

一的挑战是

拟合训练集

。

我们可以把

这个问题当

作是回归问

题，并使用均

方误差损失

函数。我们选

择这

个损失

函数是为了

尽可能简化

本例中用到

的数学。在应

用领域，对于

二进制数据

建

模时，MSE通常

并不是一个

合适的损失

函数。更加合

适的方法将

在第 6.2.2.2

节中讨

论。

评估整个

训练集上表

现的 MSE 损失函

数为

J(θ) = 1

4

∑

x∈X

(f

∗

(x) − f(x; θ))2

. (6.1)

我们现

在必须要选

择我们模型

f(x; θ)

的形式。假设

我们选择一

个线性模型

，θ

包含 w 和

b，那么

我们的模型

被定义成

f(x; w, b)

= x

⊤w +

b. (6.2)

我

们可以使用

正规方程关

于 w

和 b 最小化

J(θ)，来得到一个

闭式解。

解正

规方程以后

，我们得到

w = 0 以

及

b = 2

1。线性模型

仅仅是在任

意一点都输

出

0.5。为什么会

发生这种事

？图 6.1 演示了线

性模型为什

么不能用来

表示 XOR

函

数。解

决这个问题

的其中一种

方法是使用

一个模型来

学习一个不

同的特征空

间，在

这个空

间上线性模

型能够表示

这个解。

具体

来说，我们这

里引入一个

非常简单的

前馈神经网

络，它有一层

隐藏层并且

隐

藏层中包

含两个单元

。见图 6.2 中对该

模型的解释

。这个前馈网

络有一个通

过函数

f

(1)(x;W, c) 计算

得到的隐藏

单元的向量

h。这些隐藏单

元的值随后

被用作第二

层的

输入。第

二层就是这

个网络的输

出层。输出层

仍然只是一

个线性回归

模型，只不过

6.1

实例：学习 XOR 149

0

1

x1

0

1

Original x space

0

1 2

h1

0

1

Learned h space

图

6.1: 通过学习一

个表示来解

决 XOR 问题。图上

的粗体数字

标明了学得

的函数必须

在每个点输

出的值。(左)

直

接应用于原

始输入的线

性模型不能

实现 XOR 函数。当

x1 =

0 时，模型的输

出必

须随着

x2 的增大而增

大。当

x1 = 1 时，模型

的输出必须

随着

x2 的增大

而减小。线性

模型必须对

x2 使用固定的

系数 w2。因此，线

性模型不能

使用

x1 的值来

改变 x2 的系数

，从而不能解

决这个

问题

。(右) 在由神经

网络提取的

特征表示的

变换空间中

，线性模型现

在可以解决

这个问题了

。在

我们的示

例解决方案

中，输出必须

为 1

的两个点

折叠到了特

征空间中的

单个点。换句

话说，非线

性

特征将 x =

[1, 0]⊤ 和 x

= [0, 1]⊤ 都

映射到了特

征空间中的

单个点

h = [1, 0]⊤。线性

模型现在可

以将函数描

述为

h1 增大和

h2 减小。在该示

例中，学习特

征空间的动

机仅仅是使

得模型的能

力更

大，使得

它可以拟合

训练集。在更

现实的应用

中，学习的表

示也可以帮

助模型泛化

。

现在它作用

于 h 而不是 x。网

络现在包含

链接在一起

的两个函数

：h

= f

(1)(x;W, c)

和 y = f

(2)(h; w, b)，完整的模

型是 f(x;W,

c, w, b) =

f

(2)(f

(1)(x))。

f

(1) 应该是

哪种函数？线

性模型到目

前为止都表

现不错，让 f

(1)

也

是线性的似

乎很有诱惑

力。可惜的是

，如果 f

(1) 是线性

的，那么前馈

网络作为一

个整体对于

输

入仍然是

线性的。暂时

忽略截距项

，假设 f

(1)(x) =

W⊤

x 并且 f

(2)(h) = h

⊤

w，那

么

f(x) = w⊤W⊤

x。我们可以

将这个函数

重新表示成

f(x) = x

⊤w′

其中 w′ = Ww。

显然，我

们必须用非

线性函数来

描述这些特

征。大多数神

经网络通过

仿射变换之

后紧跟着一

个被称为激

活函数的固

定非线性函

数来实现这

个目标，其中

仿射变换由

学得的参数

控制。我们这

里使用这种

策略，定义 h = g(W⊤

x + c)，其

中 W

是线性

变

换的权重矩

阵，c 是偏置。此

前，为了描述

线性回归模

型，我们使用

权重向量和

一

个标量的

偏置参数来

描述从输入

向量到输出

标量的仿射

变换。现在，因

为我们描述

的是向量

x 到

向量 h 的仿射

变换，所以我

们需要一整

个向量的偏

置参数。激活

函数

g 通常选

择对每个元

素分别起作

用的函数，有

hi = g(x

⊤W:,i + ci)。在现代神经

网络

x2

h2

150 第六章

深度前馈网

络

y

h

x

W

w

y

hh11

xx11

hh22

xx22

图 6.2: 使用两

种不同样式

绘制的前馈

网络的示例

。具体来说，这

是我们用来

解决

XOR 问题的

前

馈网络。它

有单个隐藏

层，包含两个

单元。(左) 在这

种样式中，我

们将每个单

元绘制为图

中的一个

节

点。这种风格

是清楚而明

确的，但对于

比这个例子

更大的网络

，它可能会消

耗太多的空

间。(右)

在这种

样式中，我们

将表示每一

层激活的整

个向量绘制

为图中的一

个节点。这种

样式更加紧

凑。有

时，我们

对图中的边

使用参数名

进行注释，这

些参数是用

来描述两层

之间的关系

的。这里，我们

用

矩阵

W 描述

从 x 到

h 的映射

，用向量 w 描述

从

h 到 y 的映射

。当标记这种

图时，我们通

常省

略与每

个层相关联

的截距参数

。

中，默认的推

荐是使用由

激活函数 g(z) =

max{0, z} 定

义的 整流线

性单元（rectified

linear unit）或者

称为 ReLU (Jarrett

et al., 2009b; Nair

and Hinton, 2010a; Glorot

et al., 2011a)，如图 6.3

所

示。

我们现在

可以指明我

们的整个网

络是

f(x;W, c,

w, b) = w

⊤ max{0,W⊤

x +

c} + b. (6.3)

我们现

在可以给出

XOR 问题的一个

解。令

W =

[

1 1

1

1]

, (6.4)

c

=

[

−

0

1

]

, (6.5)

w =

[

−

1

2

]

,

(6.6)

以及 b =

0。

我

们现在可以

了解这个模

型如何处理

一批输入。令

X 表示设计矩

阵，它包含二

6.1 实例：学习

XOR 151

0

z

0

图

6.3: 整流线性激

活函数。该激

活函数是被

推荐用于大

多数前馈神

经网络的默

认激活函数

。将此

函数用

于线性变换

的输出将产

生非线性变

换。然而，函数

仍然非常接

近线性，在这

种意义上它

是

具有两个

线性部分的

分段线性函

数。由于整流

线性单元几

乎是线性的

，因此它们保

留了许多使

得

线性模型

易于使用基

于梯度的方

法进行优化

的属性。它们

还保留了许

多使得线性

模型能够泛

化良

好的属

性。计算机科

学的一个通

用原则是，我

们可以从最

小的组件构

建复杂的系

统。就像图灵

机

的内存只

需要能够存

储

0 或 1 的状态

，我们可以从

整流线性函

数构建一个

万能函数近

似器。

进制输

入空间中全

部的四个点

，每个样本占

一行，那么矩

阵表示为：

X =













0 0

0

1

1 0

1

1













.

(6.7)

神

经网络的第

一步是将输

入矩阵乘以

第一层的权

重矩阵：

XW =













0 0

1 1

1 1

2 2













. (6.8)

然后

，我们加上偏

置向量 c，得到













0

1 0

−1

1 0

2

1













.

(6.9)

g(z) = max{0,

z}

152 第六章 深度

前馈网络

在

这个空间中

，所有的样本

都处在一条

斜率为 1 的直

线上。当我们

沿着这条直

线移

动时，输

出需要从

0 升

到 1，然后再降

回 0。线性模型

不能实现这

样一种函数

。为了

用 h 对每

个样本求值

，我们使用整

流线性变换

：













0 0

1

0

1 0

2

1













.

(6.10)

这个变换改

变了样本间

的关系。它们

不再处于同

一条直线上

了。如图 6.1 所示

，

它们现在处

在一个可以

用线性模型

解决的空间

上。

我们最后

乘以一个权

重向量 w:













0

1

1

0













.

(6.11)

神经

网络对这一

批次中的每

个样本都给

出了正确的

结果。

在这个

例子中，我们

简单地指定

了解决方案

，然后说明它

得到的误差

为零。在

实际

情况中，可能

会有数十亿

的模型参数

以及数十亿

的训练样本

，所以不能像

我们

这里做

的那样进行

简单地猜解

。与之相对的

，基于梯度的

优化算法可

以找到一些

参

数使得产

生的误差非

常小。我们这

里给出的 XOR 问

题的解处在

损失函数的

全局最

小点

，所以梯度下

降算法可以

收敛到这一

点。梯度下降

算法还可以

找到 XOR 问题一

些其他的等

价解。梯度下

降算法的收

敛点取决于

参数的初始

值。在实践中

，梯度下

降通

常不会找到

像我们这里

给出的那种

干净的、容易

理解的、整数

值的解。

6.2 基于

梯度的学习

设计和训练

神经网络与

使用梯度下

降训练其他

任何机器学

习模型并没

有太大不

同

。在第 5.10

节中，我

们描述了如

何通过指定

一个优化过

程、代价函数

和一个模型

族来构建一

个机器学习

算法。

我们到

目前为止看

到的线性模

型和神经网

络的最大区

别，在于神经

网络的非线

性导致大多

数我们感兴

趣的代价函

数都变得非

凸。这意味着

神经网络的

训练通常使

6.2 基于梯度的

学习 153

用迭代

的、基于梯度

的优化，仅仅

使得代价函

数达到一个

非常小的值

；而不是像用

于

训练线性

回归模型的

线性方程求

解器，或者用

于训练逻辑

回归或 SVM 的凸

优化算

法那

样保证全局

收敛。凸优化

从任何一种

初始参数出

发都会收敛

（理论上如此

——

在实践中也

很鲁棒但可

能会遇到数

值问题）。用于

非凸损失函

数的随机梯

度下降没有

这种收敛性

保证，并且对

参数的初始

值很敏感。对

于前馈神经

网络，将所有

的权重

值初

始化为小随

机数是很重

要的。偏置可

以初始化为

零或者小的

正值。这种用

于训

练前馈

神经网络以

及几乎所有

深度模型的

迭代的基于

梯度的优化

算法会在第

八章详

细介

绍，参数初始

化会在第 8.4 节

中具体说明

。就目前而言

，只需要懂得

，训练算法

几

乎总是基于

使用梯度来

使得代价函

数下降的各

种方法即可

。一些特别的

算法是对

梯

度下降思想

的改进和提

纯（在第 4.3 节中

介绍）还有一

些更特别的

，大多数是对

随

机梯度下

降算法的改

进（在第

5.9 节中

介绍）。

我们当

然也可以用

梯度下降来

训练诸如线

性回归和支

持向量机之

类的模型，并

且事实上当

训练集相当

大时这是很

常用的。从这

点来看，训练

神经网络和

训练其他

任

何模型并没

有太大区别

。计算梯度对

于神经网络

会略微复杂

一些，但仍然

可以很

高效

而精确地实

现。第 6.5 节将会

介绍如何用

反向传播算

法以及它的

现代扩展算

法来

求得梯

度。

和其他的

机器学习模

型一样，为了

使用基于梯

度的学习方

法我们必须

选择一个

代

价函数，并且

我们必须选

择如何表示

模型的输出

。现在，我们重

温这些设计

上的

考虑，并

且特别强调

神经网络的

情景。

6.2.1

代价函

数

深度神经

网络设计中

的一个重要

方面是代价

函数的选择

。幸运的是，神

经网络

的代

价函数或多

或少是和其

他的参数模

型例如线性

模型的代价

函数相同的

。

在大多数情

况下，我们的

参数模型定

义了一个分

布

p(y | x; θ)

并且我们

简单地

使用

最大似然原

理。这意味着

我们使用训

练数据和模

型预测间的

交叉熵作为

代价函

数。

有

时，我们使用

一个更简单

的方法，不是

预测

y 的完整

概率分布，而

是仅仅预

测

在给定 x

的条

件下 y 的某种

统计量。某些

专门的损失

函数允许我

们来训练这

些估

计量的

预测器。

用于

训练神经网

络的完整的

代价函数，通

常在我们这

里描述的基

本代价函数

的

154 第六章 深

度前馈网络

基础上结合

一个正则项

。我们已经在

第

5.2.2 节中看到

正则化应用

到线性模型

中的一

些简

单的例子。用

于线性模型

的权重衰减

方法也直接

适用于深度

神经网络，而

且是

最流行

的正则化策

略之一。用于

神经网络的

更高级的正

则化策略将

在第七章中

讨论。

6.2.1.1 使用最

大似然学习

条件分布

大

多数现代的

神经网络使

用最大似然

来训练。这意

味着代价函

数就是负的

对数

似然，它

与训练数据

和模型分布

间的交叉熵

等价。这个代

价函数表示

为

J(θ) = −Ex,y∼pˆdata log

pmodel(y | x). (6.12)

代价函数

的具体形式

随着模型而

改变，取决于

log pmodel 的具体形式

。上述方程

的

展开形式通

常会有一些

项不依赖于

模型的参数

，我们可以舍

去。例如，正如

我们

在第 5.1.1 节

中看到的，如

果 pmodel(y

| x) = N

(y; f(x; θ), I)，那么我们

就重新得到

了均方误差

代价，

J(θ) = 1

2

Ex,y∼pˆdata ||y − f(x;

θ)||2 + const, (6.13)

至少系

数 1

2 和常数项

不依赖于

θ。舍

弃的常数是

基于高斯分

布的方差，在

这种情况

下

我们选择不

把它参数化

。之前，我们看

到了对输出

分布的最大

似然估计和

对线性

模型

均方误差的

最小化之间

的等价性，但

事实上，这种

等价性并不

要求 f(x;

θ) 用于

预

测高斯分布

的均值。

使用

最大似然来

导出代价函

数的方法的

一个优势是

，它减轻了为

每个模型设

计

代价函数

的负担。明确

一个模型 p(y | x)

则

自动地确定

了一个代价

函数 log p(y |

x)。

贯穿神

经网络设计

的一个反复

出现的主题

是代价函数

的梯度必须

足够的大和

具

有足够的

预测性，来为

学习算法提

供一个好的

指引。饱和（变

得非常平）的

函数破

坏了

这一目标，因

为它们把梯

度变得非常

小。这在很多

情况下都会

发生，因为用

于

产生隐藏

单元或者输

出单元的输

出的激活函

数会饱和。负

的对数似然

帮助我们在

很

多模型中

避免这个问

题。很多输出

单元都会包

含一个指数

函数，这在它

的变量取绝

对值非常大

的负值时会

造成饱和。负

对数似然代

价函数中的

对数函数消

除了某些输

出单元中的

指数效果。我

们将会在第

6.2.2 节中讨论代

价函数和输

出单元的选

择间的

相互

作用。

用于实

现最大似然

估计的交叉

熵代价函数

有一个不同

寻常的特性

，那就是当它

被应用于实

践中经常遇

到的模型时

，它通常没有

最小值。对于

离散型输出

变量，大

6.2 基于

梯度的学习

155

多数模型以

一种特殊的

形式来参数

化，即它们不

能表示概率

零和一，但是

可以无限

接

近。逻辑回归

是其中一个

例子。对于实

值的输出变

量，如果模型

可以控制输

出分

布的密

度（例如，通过

学习高斯输

出分布的方

差参数），那么

它可能对正

确的训练集

输出赋予极

其高的密度

，这将导致交

叉熵趋向负

无穷。第七章

中描述的正

则化技术

提

供了一些不

同的方法来

修正学习问

题，使得模型

不会通过这

种方式来获

得无限制

的

收益。

6.2.1.2 学习条

件统计量

有

时我们并不

是想学习一

个完整的概

率分布 p(y

| x; θ)，而仅

仅是想学习

在给定

x

时 y 的

某个条件统

计量。

例如，我

们可能有一

个预测器

f(x; θ)，我

们想用它来

预测 y 的均值

。如果我

们使

用一个足够

强大的神经

网络，我们可

以认为这个

神经网络能

够表示一大

类函

数中的

任何一个函

数 f，这个类仅

仅被一些特

征所限制，例

如连续性和

有界，而不

是

具有特殊的

参数形式。从

这个角度来

看，我们可以

把代价函数

看作是一个

泛函

（functional）而不仅

仅是一个函

数。泛函是函

数到实数的

映射。我们因

此可以将学

习

看作是选

择一个函数

而不仅仅是

选择一组参

数。我们可以

设计代价泛

函在我们想

要

的某些特

殊函数处取

得最小值。例

如，我们可以

设计一个代

价泛函，使它

的最小值处

于一个特殊

的函数上，这

个函数将 x

映

射到给定 x 时

y 的期望值。对

函数求解优

化

问题需要

用到 变分法

（calculus of variations）这个数学工

具，我们将在

第

19.4.2 节

中讨论

。理解变分法

对于理解本

章的内容不

是必要的。目

前，只需要知

道变分法可

以被用来导

出下面的两

个结果。

我们

使用变分法

导出的第一

个结果是解

优化问题

f

∗ = arg

min

f

Ex,y∼pdata ||y

− f(x)||2

(6.14)

得

到

f

∗

(x) =

Ey∼pdata(y|x)

[y], (6.15)

要求这个

函数处在我

们要优化的

类里。换句话

说，如果我们

能够用无穷

多的、来源

于

真实的数据

生成分布的

样本进行训

练，最小化均

方误差代价

函数将得到

一个函数，

它

可以用来对

每个 x 的值预

测出

y 的均值

。

156 第六章

深度

前馈网络

不

同的代价函

数给出不同

的统计量。第

二个使用变

分法得到的

结果是

f

∗

= arg min

f

Ex,y∼pdata ||y − f(x)||1

(6.16)

将得

到一个函数

可以对每个

x 预测 y

取值的

中位数，只要

这个函数在

我们要优化

的

函数族里

。这个代价函

数通常被称

为 平均绝对

误差（mean absolute

error）。

可惜的

是，均方误差

和平均绝对

误差在使用

基于梯度的

优化方法时

往往成效不

佳。一些饱和

的输出单元

当结合这些

代价函数时

会产生非常

小的梯度。这

就是为什

么

交叉熵代价

函数比均方

误差或者平

均绝对误差

更受欢迎的

原因之一了

，即使是在

没

必要估计整

个

p(y | x) 分布时。

6.2.2 输

出单元

代价

函数的选择

与输出单元

的选择紧密

相关。大多数

时候，我们简

单地使用数

据分布和模

型分布间的

交叉熵。选择

如何表示输

出决定了交

叉熵函数的

形式。

任何可

用作输出的

神经网络单

元，也可以被

用作隐藏单

元。这里，我们

着重讨

论将

这些单元用

作模型输出

时的情况，不

过原则上它

们也可以在

内部使用。我

们将

在第 6.3 节

中重温这些

单元，并且给

出当它们被

用作隐藏单

元时一些额

外的细节。

在

本节中，我们

假设前馈网

络提供了一

组定义为 h = f(x;

θ) 的

隐藏特征。输

出

层的作用

是随后对这

些特征进行

一些额外的

变换来完成

整个网络必

须完成的任

务。

6.2.2.1

用于高斯

输出分布的

线性单元

一

种简单的输

出单元是基

于仿射变换

的输出单元

，仿射变换不

具有非线性

。这

些单元往

往被直接称

为线性单元

。

给定特征

h，线

性输出单元

层产生一个

向量 yˆ = W⊤

h + b。

线性输

出层经常被

用来产生条

件高斯分布

的均值：

p(y | x) =

N (y; yˆ, I).

(6.17)

最大

化其对数似

然此时等价

于最小化均

方误差。

最大

似然框架也

使得学习高

斯分布的协

方差矩阵更

加容易，或更

容易地使高

斯

分布的协

方差矩阵作

为输入的函

数。然而，对于

所有输入，协

方差矩阵都

必须被限

6.2 基

于梯度的学

习 157

定成一个

正定矩阵。线

性输出层很

难满足这种

限定，所以通

常使用其他

的输出单元

来对协方差

参数化。对协

方差建模的

方法将在第

6.2.2.4

节中简要介

绍。

因为线性

模型不会饱

和，所以它们

易于采用基

于梯度的优

化算法，甚至

可以使

用其

他多种优化

算法。

6.2.2.2

用于 Bernoulli 输

出分布的 sigmoid

单

元

许多任务

需要预测二

值型变量 y 的

值。具有两个

类的分类问

题可以归结

为这种

形式

。

此时最大似

然的方法是

定义 y 在

x 条件

下的 Bernoulli 分布。

Bernoulli 分

布仅需单个

参数来定义

。神经网络只

需要预测 P(y =

1 | x) 即

可。

为了使这

个数是有效

的概率，它必

须处在区间

[0, 1] 中。

为满足该

约束条件需

要一些细致

的设计工作

。假设我们打

算使用线性

单元，并

且通

过阈值来限

制它成为一

个有效的概

率：

P(y = 1

| x) = max

{

0, min{1, w

⊤h + b}

}

. (6.18)

这的确定

义了一个有

效的条件概

率分布，但我

们无法使用

梯度下降来

高效地训练

它。

当

w⊤h + b 处于单

位区间外时

，模型的输出

对其参数的

梯度都将为

0。梯度为

0 通

常

是有问题的

，因为学习算

法对于如何

改善相应的

参数不再具

有指导意义

。

相反，最好是

使用一种新

的方法来保

证无论何时

模型给出了

错误的答案

时，总

能有一

个较大的梯

度。这种方法

是基于使用

sigmoid 输出单元结

合最大似然

来实现

的。

sigmoid

输

出单元定义

为

yˆ = σ

(

w

⊤h +

b

)

, (6.19)

这里 σ 是第

3.10 节中介绍的

logistic

sigmoid 函数。

我们可

以认为 sigmoid

输出

单元具有两

个部分。首先

，它使用一个

线性层来计

算 z = w⊤h

+ b。接着，它使

用 sigmoid 激活函数

将

z 转化成概

率。

我们暂时

忽略对于 x

的

依赖性，只讨

论如何用 z 的

值来定义 y

的

概率分布。

sigmoid 可

以通过构造

一个非归一

化（和不为 1）的

概率分布

P˜(y) 来

得到。我们可

以随后除以

一个合适的

常数来得到

有效的概率

分布。如果我

们假定非归

一化的对数

158 第六章 深度

前馈网络

概

率对 y 和 z

是线

性的，可以对

它取指数来

得到非归一

化的概率。我

们然后对它

归

一化，可以

发现这服从

Bernoulli 分布，该分布

受 z

的 sigmoid 变换控

制：

log

P˜(y) = yz, (6.20)

P˜(y) = exp(yz), (6.21)

P(y) = exp(yz)

∑1

y′=0 exp(y

′z)

,

(6.22)

P(y) = σ((2y

− 1)z). (6.23)

基于指数

和归一化的

概率分布在

统计建模的

文献中很常

见。用于定义

这种二值型

变

量分布的

变量 z 被称为

分对数（logit）。

这种

在对数空间

里预测概率

的方法可以

很自然地使

用最大似然

学习。因为用

于

最大似然

的代价函数

是 − log P(y

| x)，代价函数

中的 log 抵消了

sigmoid

中的 exp。

如果没

有这个效果

，sigmoid 的饱和性会

阻止基于梯

度的学习做

出好的改进

。我们使

用最

大似然来学

习一个由 sigmoid 参

数化的 Bernoulli

分布

，它的损失函

数为

J(θ) = −

log P(y | x)

(6.24)

= − log

σ((2y − 1)z) (6.25)

= ζ((1 − 2y)z).

(6.26)

这个推

导使用了第

3.10 节中的一些

性质。通过将

损失函数写

成 softplus

函数的

形

式，我们可以

看到它仅仅

在 (1 −

2y)z 取绝对值

非常大的负

值时才会饱

和。因此饱

和

只会出现在

模型已经得

到正确答案

时——当 y

= 1 且 z

取非

常大的正值

时，或者

y = 0

且 z 取

非常小的负

值时。当 z

的符

号错误时，softplus 函

数的变量 (1 −

2y)z

可

以简化为 |z|。当

|z| 变得很大并

且

z 的符号错

误时，softplus 函数渐

近地趋向于

它

的变量

|z|。对

z 求导则渐近

地趋向于 sign(z)，所

以，对于极限

情况下极度

不正确的

z，softplus

函

数完全不会

收缩梯度。这

个性质很有

用，因为它意

味着基于梯

度的学

习可

以很快地改

正错误的 z。

当

我们使用其

他的损失函

数，例如均方

误差之类的

，损失函数会

在

σ(z) 饱和时

饱

和。sigmoid 激活函数

在

z 取非常小

的负值时会

饱和到 0，当 z

取

非常大的正

值时

会饱和

到 1。这种情况

一旦发生，梯

度会变得非

常小以至于

不能用来学

习，无论此时

模型给出的

是正确还是

错误的答案

。因此，最大似

然几乎总是

训练 sigmoid

输出单

元的优选方

法。

6.2 基于梯度

的学习 159

理论

上，sigmoid 的对数总

是确定和有

限的，因为 sigmoid 的

返回值总是

被限制

在开

区间 (0, 1) 上，而不

是使用整个

闭区间

[0, 1] 的有

效概率。在软

件实现时，为

了

避免数值

问题，最好将

负的对数似

然写作

z 的函

数，而不是 yˆ =

σ(z) 的

函数。如

果 sigmoid

函

数下溢到零

，那么之后对

yˆ 取对数会得

到负无穷。

6.2.2.3 用

于

Multinoulli 输出分布

的 softmax 单元

任何

时候当我们

想要表示一

个具有 n 个可

能取值的离

散型随机变

量的分布时

，

我们都可以

使用

softmax 函数。它

可以看作是

sigmoid 函数的扩展

，其中 sigmoid

函

数用

来表示二值

型变量的分

布。

softmax 函数最常

用作分类器

的输出，来表

示

n 个不同类

上的概率分

布。比较

少见

的是，softmax 函数可

以在模型内

部使用，例如

如果我们想

要在某个内

部变量的

n 个

不同选项中

进行选择。

在

二值型变量

的情况下，我

们希望计算

一个单独的

数

yˆ

= P(y = 1

| x). (6.27)

因为这个

数需要处在

0

和 1 之间，并且

我们想要让

这个数的对

数可以很好

地用于对

数

似然的基于

梯度的优化

，我们选择去

预测另外一

个数

z = log Pˆ(y

= 1 | x)。对其

指

数化和归一

化，我们就得

到了一个由

sigmoid 函数控制的

Bernoulli 分布。

为了推

广到具有

n 个

值的离散型

变量的情况

，我们现在需

要创造一个

向量 yˆ，

它的每

个元素是

yˆi = P(y =

i | x)。我

们不仅要求

每个 yˆi

元素介

于 0 和 1

之间，还

要使得整个

向量的和为

1，使得它表示

一个有效的

概率分布。用

于 Bernoulli 分布的

方

法同样可以

推广到

Multinoulli 分布

。首先，线性层

预测了未归

一化的对数

概率：

z =

W⊤

h + b,

(6.28)

其中 zi =

log Pˆ(y = i

| x)。softmax 函

数然后可以

对 z

指数化和

归一化来获

得需要

的 yˆ。最

终，softmax 函数的形

式为

softmax(z)i =

exp(zi)

∑

j

exp(zj )

.

(6.29)

和 logistic sigmoid一样

，当使用最大

化对数似然

训练

softmax 来输出

目标值 y

时，使

用指数函数

工作地非常

好。这种情况

下，我们想要

最大化

log P(y = i;

z) =

160 第六

章

深度前馈

网络

log softmax(z)i。将 softmax

定义

成指数的形

式是很自然

的因为对数

似然中的 log 可

以抵消 softmax

中的

exp：

log softmax(z)i =

zi − log∑

j

exp(zj ). (6.30)

式

(6.30) 中的第一

项表示输入

zi 总是对代价

函数有直接

的贡献。因为

这一项不

会

饱和，所以即

使

zi 对式 (6.30) 的第

二项的贡献

很小，学习依

然可以进行

。当最大化

对

数似然时，第

一项鼓励 zi 被

推高，而第二

项则鼓励所

有的 z

被压低

。为了对第二

项

log∑

j

exp(zj

) 有一个直

观的理解，注

意到这一项

可以大致近

似为 maxj zj。这种近

似

是基于对

任何明显小

于 maxj zj 的

zk，exp(zk) 都是不

重要的。我们

能从这种近

似中

得到的

直觉是，负对

数似然代价

函数总是强

烈地惩罚最

活跃的不正

确预测。如果

正确

答案已

经具有了

softmax 的

最大输入，那

么 −zi 项和

log∑

j

exp(zj )

≈ maxj zj =

zi

项将

大致抵消。这

个样本对于

整体训练代

价贡献很小

，这个代价主

要由其他未

被正

确分类

的样本产生

。

到目前为止

我们只讨论

了一个例子

。总体来说，未

正则化的最

大似然会驱

动模

型去学

习一些参数

，而这些参数

会驱动 softmax 函数

来预测在训

练集中观察

到的每

个结

果的比率：

softmax(z(x; θ))i ≈

∑m

j=1 1y(j)=i,x

(j)=x ∑m

j=1 1x

(j)=x

.

(6.31)

因

为最大似然

是一致的估

计量，所以只

要模型族能

够表示训练

的分布，这就

能保证

发生

。在实践中，有

限的模型能

力和不完美

的优化将意

味着模型只

能近似这些

比率。

除了对

数似然之外

的许多目标

函数对

softmax 函数

不起作用。具

体来说，那些

不使用对数

来抵消 softmax 中的

指数的目标

函数，当指数

函数的变量

取非常小的

负

值时会造

成梯度消失

，从而无法学

习。特别是，平

方误差对于

softmax 单元来说是

一

个很差的

损失函数，即

使模型做出

高度可信的

不正确预测

，也不能训练

模型改变其

输出 (Bridle,

1990)。要理解

为什么这些

损失函数可

能失败，我们

需要检查 softmax

函

数本身。

像

sigmoid 一

样，softmax 激活函数

可能会饱和

。sigmoid 函数具有单

个输出，

当它

的输入极端

负或者极端

正时会饱和

。对于 softmax 的情况

，它有多个输

出值。

当输入

值之间的差

异变得极端

时，这些输出

值可能饱和

。当

softmax 饱和时，基

于

softmax 的许多代

价函数也饱

和，除非它们

能够转化饱

和的激活函

数。

为了说明

softmax 函数对于输

入之间差异

的响应，观察

到当对所有

的输入都加

6.2 基于梯度的

学习 161

上一个

相同常数时

softmax 的输出不变

：

softmax(z) =

softmax(z + c). (6.32)

使用这个性

质，我们可以

导出一个数

值方法稳定

的 softmax 函数的变

体：

softmax(z)

= softmax(z − max

i

zi). (6.33)

变换后的

形式允许我

们在对

softmax 函数

求值时只有

很小的数值

误差，即使是

当 z

包含极正

或者极负的

数时。观察

softmax 数

值稳定的变

体，可以看到

softmax 函数

由它的

变量偏离

maxi zi 的

量来驱动。

当

其中一个输

入是最大（zi

= maxi zi）并

且 zi

远大于其

他的输入时

，相应的

输出

softmax(z)i 会饱和到 1。当

zi

不是最大值

并且最大值

非常大时，相

应的输出

softmax(z)i 也

会饱和到 0。这

是

sigmoid 单元饱和

方式的一般

化，并且如果

损失函

数不

被设计成对

其进行补偿

，那么也会造

成类似的学

习困难。

softmax

函数

的变量 z 可以

通过两种方

式产生。最常

见的是简单

地使神经网

络

较早的层

输出

z 的每个

元素，就像先

前描述的使

用线性层 z =

W⊤h + b。虽

然很直

观，但

这种方法是

对分布的过

度参数化。n

个

输出总和必

须为 1 的约束

意味着只有

n −

1 个参数是必

要的；第 n 个概

率值可以通

过

1 减去前面

n − 1

个概率来获

得。因

此，我们

可以强制要

求 z 的一个元

素是固定的

。例如，我们可

以要求

zn = 0。事实

上，这正是 sigmoid

单

元所做的。定

义 P(y = 1

| x) = σ(z)

等价于用

二维的 z 以及

z1 =

0 来定义 P(y =

1 | x) =

softmax(z)1。无论

是 n − 1

个变量还

是 n 个变量的

方

法，都描述

了相同的概

率分布，但会

产生不同的

学习机制。在

实践中，无论

是过度

参数

化的版本还

是限制的版

本都很少有

差别，并且实

现过度参数

化的版本更

为简单。

从神

经科学的角

度看，有趣的

是认为 softmax 是一

种在参与其

中的单元之

间形

成竞争

的方式：softmax 输出

总是和为 1，所

以一个单元

的值增加必

然对应着其

他单

元值的

减少。这与被

认为存在于

皮质中相邻

神经元间的

侧抑制类似

。在极端情况

下

（当最大的

ai 和其他的在

幅度上差异

很大时），它变

成了 赢者通

吃（winner-take-all）

的形式（其

中一个输出

接近

1，其他的

接近 0）。

“softmax’’ 的名称

可能会让人

产生困惑。这

个函数更接

近于

argmax 函数而

不是

max 函数。“soft’’

这

个术语来源

于 softmax 函数是连

续可微的。“argmax’’ 函

数的结

果表

示为一个one-hot向

量（只有一个

元素为 1，其余

元素都为 0 的

向量），不是连

续

和可微的

。softmax 函数因此提

供了 argmax 的

‘‘软化

’’ 版本。max 函数相

应的软化

版

本是

softmax(z)

⊤z。可能最

好是把 softmax 函数

称为

“softargmax’’，但当前

名称

162 第六章

深度前馈网

络

已经是一

个根深蒂固

的习惯了。

6.2.2.4 其

他的输出类

型

之前描述

的线性、sigmoid 和

softmax 输

出单元是最

常见的。神经

网络可以推

广

到我们希

望的几乎任

何种类的输

出层。最大似

然原则给如

何为几乎任

何种类的输

出

层设计一

个好的代价

函数提供了

指导。

一般的

，如果我们定

义了一个条

件分布 p(y | x;

θ)，最大

似然原则建

议我们使用

− log p(y |

x; θ) 作为代价函

数。

一般来说

，我们可以认

为神经网络

表示函数

f(x; θ)。这

个函数的输

出不是对 y

值

的直接预测

。相反，f(x;

θ) = ω 提供了

y

分布的参数

。我们的损失

函数就可以

表

示成 − log

p(y; ω(x))。

例如

，我们想要学

习在给定 x

时

，y 的条件高斯

分布的方差

。简单情况下

，方

差 σ

2 是一个

常数，此时有

一个解析表

达式，这是因

为方差的最

大似然估计

量仅仅是

观

测值 y

与它们

的期望值的

差值的平方

平均。一种计

算上代价更

加高但是不

需要写

特殊

情况代码的

方法是简单

地将方差作

为分布 p(y |

x) 的其

中一个属性

，这个分布

由

ω =

f(x; θ) 控制。负对数

似然 −

log p(y; ω(x)) 将为代

价函数提供

一个必要的

合

适项来使

我们的优化

过程可以逐

渐地学到方

差。在标准差

不依赖于输

入的简单情

况

下，我们可

以在网络中

创建一个直

接复制到 ω 中

的新参数。这

个新参数可

以是

σ 本

身，或

者可以是表

示 σ

2 的参数 v，或

者可以是表

示 σ

1

2 的参数 β，取

决于我们怎

样

对分布参

数化。我们可

能希望模型

对不同的 x 值

预测出 y

不同

的方差。这被

称为 异

方差

（heteroscedastic）模型。在异方

差情况下，我

们简单地把

方差指定为

f(x; θ)

其中一个输

出值。实现它

的典型方法

是使用精度

而不是方差

来表示高斯

分布，就像

式

(3.22) 所描述的。在

多维变量的

情况下，最常

见的是使用

一个对角精

度矩阵

diag(β).

(6.34)

这个

公式适用于

梯度下降，因

为由 β 参数化

的高斯分布

的对数似然

的公式仅涉

及

βi

的乘法和

log βi 的加法。乘法

、加法和对数

运算的梯度

表现良好。相

比之下，如果

我们用方差

来参数化输

出，我们需要

用到除法。除

法函数在零

附近会变得

任意陡峭。

虽

然大梯度可

以帮助学习

，但任意大的

梯度通常导

致不稳定。如

果我们用标

准差来

参数

化输出，对数

似然仍然会

涉及除法，并

且还将涉及

平方。通过平

方运算的梯

度

可能在零

附近消失，这

使得学习被

平方的参数

变得困难。无

论我们使用

的是标准差

，

6.2

基于梯度的

学习 163

方差还

是精度，我们

必须确保高

斯分布的协

方差矩阵是

正定的。因为

精度矩阵的

特

征值是协

方差矩阵特

征值的倒数

，所以这等价

于确保精度

矩阵是正定

的。如果我们

使用对角矩

阵，或者是一

个常数乘以

单位矩阵1，那

么我们需要

对模型输出

强加的唯

一

条件是它的

元素都为正

。如果我们假

设 a 是用于确

定对角精度

的模型的原

始激活，

那么

可以用

softplus 函数

来获得正的

精度向量：β = ζ(a)。这

种相同的策

略对于方

差

或标准差同

样适用，也适

用于常数乘

以单位阵的

情况。

学习一

个比对角矩

阵具有更丰

富结构的协

方差或者精

度矩阵是很

少见的。如果

协方差矩阵

是满的和有

条件的，那么

参数化的选

择就必须要

保证预测的

协方差矩阵

是正定的。这

可以通过写

成 Σ(x) =

B(x)B

⊤

(x) 来实现，这

里

B 是一个无

约束的方

阵

。如果矩阵是

满秩的，那么

一个实际问

题是计算似

然的代价是

很高的，计算

一个

d

× d 的矩阵

的行列式或

者 Σ(x)

的逆（或者

等价地并且

更常用地，对

它特征值分

解

或者 B(x) 的特

征值分解）需

要

O(d

3

) 的计算量

。

我们经常想

要执行多峰

回归 (multimodal regression)，即预测

条件分布 p(y

| x)

的

实值，该条件

分布对于相

同的 x

值在 y 空

间中有多个

不同的峰值

。在这种情况

下，

高斯混合

是输出的自

然表示

(Jacobs et al., 1991;

Bishop, 1994)。将高

斯混合作为

其

输出的神

经网络通常

被称为 混合

密度网络（mixture

density network）。具

有 n 个分

量的

高斯混合输

出由下面的

条件分布定

义：

p(y | x)

=

n∑

i=1

p(c

= i | x)N

(y; µ

(i)

(x),

Σ

(i)

(x)). (6.35)

神经网络

必须有三个

输出：定义 p(c = i

| x) 的

向量，对所有

的 i

给出 µ

(i)

(x)

的矩

阵，以及对所

有的 i 给出 Σ

(i)

(x) 的

张量。这些输

出必须满足

不同的约束

：

1.

混合组件 p(c = i

| x)：它

们由潜变量

2

c 关联着，在

n 个

不同组件上

形

成 Multinoulli

分布。这

个分布通常

可以由 n 维向

量的 softmax

来获得

，以确

保这些

输出是正的

并且和为 1。

2.

均

值 µ

(i)

(x)：它们指明

了与第

i 个高

斯组件相关

联的中心或

者均值，并且

是无

约束的

（通常对于这

些输出单元

完全没有非

线性）。如果 y

是

个 d 维向量，那

1译者注：这里

原文是 “If

we use a diagonal

matrix, or a scalar

times the diagonal matrix...’’

即 ‘‘如

果我们使

用

对角矩阵，或

者是一个标

量乘以对角

矩阵...’’，但一个

标量乘以对

角矩阵和对

角矩阵没区

别，结合上下

文可以看出

，

这里原作者

误把

“identity’’ 写成了

“diagonal matrix’’，因此这里采

用 ‘‘常数乘以

单位矩阵’’

的

译法。

2我们之

所以认为 c 是

潜在的，是因

为我们不能

直接在数据

中观测到它

：给定输入

x 和

目标 y，不可能

确切地知道

是哪个高斯

组件产生 y，但

我们可以想

象

y 是通过选

择其中一个

来产生的，并

且将那个未

被观测到的

选择作为随

机变

量。

164

第六

章 深度前馈

网络

么网络

必须输出一

个由 n

个这种

d 维向量组成

的 n ×

d 的矩阵。用

最大似然来

学习这些均

值要比学习

只有一个输

出模式的分

布的均值稍

稍复杂一些

。我们只

想更

新那个真正

产生观测数

据的组件的

均值。在实践

中，我们并不

知道是哪个

组件产生了

观测数据。负

对数似然表

达式将每个

样本对每个

组件的贡献

进行赋

权，权

重的大小由

相应的组件

产生这个样

本的概率来

决定。

3. 协方差

Σ

(i)

(x)：它们指明了

每个组件

i 的

协方差矩阵

。和学习单个

高斯组件时

一样，我们通

常使用对角

矩阵来避免

计算行列式

。和学习混合

均值时一样

，最

大似然是

很复杂的，它

需要将每个

点的部分责

任分配给每

个混合组件

。如果给

定了

混合模型的

正确的负对

数似然，梯度

下降将自动

地遵循正确

的过程。

有报

告说基于梯

度的优化方

法对于混合

条件高斯（作

为神经网络

的输出）可能

是不

可靠的

，部分是因为

涉及到除法

（除以方差）可

能是数值不

稳定的（当某

个方差对于

特定的实例

变得非常小

时，会导致非

常大的梯度

）。一种解决方

法是 梯度截

断（clip

gradient）（见第

10.11.1 节），另

外一种是启

发式缩放梯

度 (Murray and

Larochelle,

2014)。

高斯混合

输出在语音

生成模型 (Schuster,

1999) 和

物理运动 (Graves, 2013)

中

特

别有效。混

合密度策略

为网络提供

了一种方法

来表示多种

输出模式，并

且控制输出

的方差，这对

于在这些实

数域中获得

高质量的结

果是至关重

要的。混合密

度网络的

一

个实例如图

6.4 所示。

一般的

，我们可能希

望继续对包

含更多变量

的、更大的向

量 y 来建模，并

在

这些输出

变量上施加

更多更丰富

的结构。例如

，我们可能希

望神经网络

输出字符序

列形成一个

句子。在这些

情况下，我们

可以继续使

用最大似然

原理应用到

我们的模

型

p(y; ω(x)) 上，但我们用

来描述 y

的模

型会变得非

常复杂，超出

了本章的范

畴。

第十章描

述了如何使

用循环神经

网络来定义

这种序列上

的模型，第三

部分描述了

对

任意概率

分布进行建

模的高级技

术。

6.3

隐藏单元

165

x

图 6.4:

从具有混

合密度输出

层的神经网

络中抽取的

样本。输入 x 从

均匀分布中

采样，输出 y

从

pmodel(y | x) 中采样。神经

网络能够学

习从输入到

输出分布的

参数的非线

性映射。这些

参数包括控

制三个组件

中的哪一个

将产生输出

的概率，以及

每个组件各

自的参数。每

个混合组件

都是高斯分

布，具有预测

的均值和方

差。输出分布

的这些方面

都能够相对

输入

x 变化，并

且以非线性

的方式

改变

。

6.3

隐藏单元

到

目前为止，我

们集中讨论

了神经网络

的设计选择

，这对于使用

基于梯度的

优化

方法来

训练的大多

数参数化机

器学习模型

都是通用的

。现在我们转

向一个前馈

神经

网络独

有的问题：该

如何选择隐

藏单元的类

型，这些隐藏

单元用在模

型的隐藏层

中。

隐藏单元

的设计是一

个非常活跃

的研究领域

，并且还没有

许多明确的

指导性理

论

原则。

整流线

性单元是隐

藏单元极好

的默认选择

。许多其他类

型的隐藏单

元也是可用

的。决定何时

使用哪种类

型的隐藏单

元是困难的

事（尽管整流

线性单元通

常是一个

可

接受的选择

）。我们这里描

述对于每种

隐藏单元的

一些基本直

觉。这些直觉

可以用

来建

议我们何时

来尝试一些

单元。通常不

可能预先预

测出哪种隐

藏单元工作

得最好。

设计

过程充满了

试验和错误

，先直觉认为

某种隐藏单

元可能表现

良好，然后用

它组

成神经

网络进行训

练，最后用验

证集来评估

它的性能。

这

里列出的一

些隐藏单元

可能并不是

在所有的输

入点上都是

可微的。例如

，整

流线性单

元 g(z) = max{0,

z} 在 z =

0 处不可

微。这似乎使

得 g 对于基于

梯度的学

习

算法无效。在

实践中，梯度

下降对这些

机器学习模

型仍然表现

得足够好。部

分原因

y

166 第六

章

深度前馈

网络

是神经

网络训练算

法通常不会

达到代价函

数的局部最

小值，而是仅

仅显著地减

小它

的值，如

图 4.3

所示。这些

想法会在第

八章中进一

步描述。因为

我们不再期

望训练能

够

实际到达梯

度为 0 的点，所

以代价函数

的最小值对

应于梯度未

定义的点是

可以接

受的

。不可微的隐

藏单元通常

只在少数点

上不可微。一

般来说，函数

g(z) 具有左导

数

和右导数，左

导数定义为

紧邻在 z

左边

的函数的斜

率，右导数定

义为紧邻在

z 右

边的函数

的斜率。只有

当函数在 z

处

的左导数和

右导数都有

定义并且相

等时，函数

在

z 点处才是可

微的。神经网

络中用到的

函数通常对

左导数和右

导数都有定

义。在

g(z)

= max{0, z} 的情况

下，在

z = 0 处的左

导数是

0，右导

数是 1。神经网

络训练

的软

件实现通常

返回左导数

或右导数的

其中一个，而

不是报告导

数未定义或

产生一

个错

误。这可以通

过观察到在

数字计算机

上基于梯度

的优化总是

会受到数值

误差的

影响

来启发式地

给出理由。当

一个函数被

要求计算 g(0) 时

，底层值真正

为 0

是不太

可

能的。相对的

，它可能是被

舍入为 0 的一

个小量

ϵ。在某

些情况下，理

论上有更好

的理由，但这

些通常对神

经网络训练

并不适用。重

要的是，在实

践中，我们可

以放

心地忽

略下面描述

的隐藏单元

激活函数的

不可微性。

除

非另有说明

，大多数的隐

藏单元都可

以描述为接

受输入向量

x，计算仿射变

换 z

= W⊤

x +

b，然后使用

一个逐元素

的非线性函

数 g(z)。大多数隐

藏单元的区

别

仅仅在于

激活函数 g(z)

的

形式。

6.3.1 整流线

性单元及其

扩展

整流线

性单元使用

激活函数

g(z) = max{0, z}。

整

流线性单元

易于优化，因

为它们和线

性单元非常

类似。线性单

元和整流线

性

单元的唯

一区别在于

整流线性单

元在其一半

的定义域上

输出为零。这

使得只要整

流

线性单元

处于激活状

态，它的导数

都能保持较

大。它的梯度

不仅大而且

一致。整流

操

作的二阶导

数几乎处处

为

0，并且在整

流线性单元

处于激活状

态时，它的一

阶导数

处处

为 1。这意味着

相比于引入

二阶效应的

激活函数来

说，它的梯度

方向对于学

习来

说更加

有用。

整流线

性单元通常

作用于仿射

变换之上：

h = g(W⊤

x + b). (6.36)

当

初始化仿射

变换的参数

时，可以将 b 的

所有元素设

置成一个小

的正值，例如

0.1。

这使得整流

线性单元很

可能初始时

就对训练集

中的大多数

输入呈现激

活状态，并且

6.3

隐藏单元 167

允

许导数通过

。

有很多整流

线性单元的

扩展存在。大

多数这些扩

展的表现比

得上整流线

性单元，

并且

偶尔表现得

更好。

整流线

性单元的一

个缺陷是它

们不能通过

基于梯度的

方法学习那

些使它们激

活

为零的样

本。整流线性

单元的各种

扩展保证了

它们能在各

个位置都接

收到梯度。

整

流线性单元

的三个扩展

基于当

zi < 0 时使

用一个非零

的斜率

αi：hi =

g(z, α)i

= max(0, zi) +

αi min(0, zi)。 绝对

值整流（absolute

value rectification）固

定

αi =

−1 来得到 g(z) =

|z|。它用

于图像中的

对象识别 (Jarrett et al.,

2009a)，其

中

寻找在输

入照明极性

反转下不变

的特征是有

意义的。整流

线性单元的

其他扩展比

这

应用地更

广泛。渗漏整

流线性单元

（Leaky ReLU）(Maas

et al., 2013) 将

αi 固定成

一

个类似 0.01

的小

值， 参数化整

流线性单元

（parametric ReLU）或者 PReLU

将

αi 作为

学习的参数

(He et

al., 2015)。

maxout 单元（maxout

unit）(Goodfellow et al., 2013a)

进一步

扩展了整流

线

性单元。maxout 单

元将 z

划分为

每组具有 k 个

值的组，而不

是使用作用

于每个元

素

的函数

g(z)。每个

maxout 单元则输出

每组中的最

大元素：

g(z)i =

max

j∈G(i)

zj (6.37)

这里

G(i) 是组 i 的输入

索引集

{(i − 1)k +

1, . . .

, ik}。这提

供了一种方

法来学习对

输

入 x

空间中

多个方向响

应的分段线

性函数。

maxout 单元

可以学习具

有多达 k

段的

分段线性的

凸函数。maxout 单元

因此可

以视

为学习激活

函数本身而

不仅仅是单

元之间的关

系。使用足够

大的 k，maxout

单

元可

以以任意的

精确度来近

似任何凸函

数。特别地，具

有两块的 maxout 层

可以学

习实

现和传统层

相同的输入

x 的函数，这些

传统层可以

使用整流线

性激活函数

、绝

对值整流

、渗漏整流线

性单元 或参

数化整流线

性单元，或者

可以学习实

现与这些都

不同的函数

。maxout

层的参数化

当然也将与

这些层不同

，所以即使是

maxout 学习

去实现

和其他种类

的层相同的

x 的函数这种

情况下，学习

的机理也是

不一样的。

每

个 maxout 单元现在

由 k

个权重向

量来参数化

，而不仅仅是

一个，所以 maxout

单

元通常比整

流线性单元

需要更多的

正则化。如果

训练集很大

并且每个单

元的块数

保

持很低的话

，它们可以在

没有正则化

的情况下工

作得不错

(Cai et al., 2013)。

maxout 单

元还有一些

其他的优点

。在某些情况

下，要求更少

的参数可以

获得一

些统

计和计算上

的优点。具体

来说，如果由

n 个不同的线

性过滤器描

述的特征可

以

168 第六章 深

度前馈网络

在不损失信

息的情况下

，用每一组 k

个

特征的最大

值来概括的

话，那么下一

层可以

获得

k 倍更少的权

重数。

因为每

个单元由多

个过滤器驱

动，maxout

单元具有

一些冗余来

帮助它们抵

抗一

种被称

为 灾难遗忘

（catastrophic forgetting）的现象，这个

现象是说神

经网络忘记

了如何执行

它们过去训

练的任务

(Goodfellow et al., 2014a)。

整

流线性单元

和它们的这

些扩展都是

基于一个原

则，那就是如

果它们的行

为更

接近线

性，那么模型

更容易优化

。使用线性行

为更容易优

化的一般性

原则同样也

适

用于除深

度线性网络

以外的情景

。循环网络可

以从序列中

学习并产生

状态和输出

的

序列。当训

练它们时，需

要通过一些

时间步来传

播信息，当其

中包含一些

线性计算

（具

有大小接近

1 的某些方向

导数）时，这会

更容易。作为

性能最好的

循环网络结

构

之一，LSTM 通过

求和在时间

上传播信息

，这是一种特

别直观的线

性激活。它将

在

第 10.10 节中进

一步讨论。

6.3.2

logistic sigmoid与

双曲正切函

数

在引入整

流线性单元

之前，大多数

神经网络使

用 logistic

sigmoid 激活函数

g(z) = σ(z)

(6.38)

或者是双曲

正切激活函

数

g(z) =

tanh(z). (6.39)

这些激活

函数紧密相

关，因为 tanh(z)

= 2σ(2z) − 1。

我们

已经看过 sigmoid 单

元作为输出

单元用来预

测二值型变

量取值为 1

的

概率。

与分段

线性单元不

同，sigmoid 单元在其

大部分定义

域内都饱和

——当 z

取绝对值

很大的正值

时，它们饱和

到一个高值

，当 z 取绝对值

很大的负值

时，它们饱和

到一

个低值

，并且仅仅当

z

接近 0 时它们

才对输入强

烈敏感。sigmoid 单元

的广泛饱和

性会使得基

于梯度的学

习变得非常

困难。因为这

个原因，现在

不鼓励将它

们用作前

馈

网络中的隐

藏单元。当使

用一个合适

的代价函数

来抵消 sigmoid 的饱

和性时，它

们

作为输出单

元可以与基

于梯度的学

习相兼容。

当

必须要使用

sigmoid 激活函数时

，双曲正切激

活函数通常

要比 logistic sig￾moid

函数表

现更好。在 tanh(0) = 0

而

σ(0) = 1

2

的意义上，它

更像是单位

函数。因

为 tanh 在

0

附近与单位

函数类似，训

练深层神经

网络 yˆ = w⊤tanh(U

⊤

tanh(V

⊤

x))

6.3 隐藏单

元 169

类似于训

练一个线性

模型

yˆ = w⊤U

⊤V

⊤

x，只要网

络的激活能

够被保持地

很小。这

使得

训练 tanh

网络更

加容易。

sigmoid 激活

函数在除了

前馈网络以

外的情景中

更为常见。循

环网络、许多

概率

模型以

及一些自编

码器有一些

额外的要求

使得它们不

能使用分段

线性激活函

数，并

且使得

sigmoid 单元更具有

吸引力，尽管

它存在饱和

性的问题。

6.3.3 其

他隐藏单元

也存在许多

其他种类的

隐藏单元，但

它们并不常

用。

一般来说

，很多种类的

可微函数都

表现得很好

。许多未发布

的激活函数

与流行

的激

活函数表现

得一样好。为

了提供一个

具体的例子

，作者在 MNIST 数据

集上使

用 h = cos(Wx

+ b) 测

试了一个前

馈网络，并获

得了小于 1%

的

误差率，这可

以与

更为传

统的激活函

数获得的结

果相媲美。在

新技术的研

究和开发期

间，通常会测

试

许多不同

的激活函数

，并且会发现

许多标准方

法的变体表

现非常好。这

意味着，通

常

新的隐藏单

元类型只有

在被明确证

明能够提供

显著改进时

才会被发布

。新的隐藏

单

元类型如果

与已有的隐

藏单元表现

大致相当的

话，那么它们

是非常常见

的，不会

引起

别人的兴趣

。

列出文献中

出现的所有

隐藏单元类

型是不切实

际的。我们只

对一些特别

有用和

独特

的类型进行

强调。

其中一

种是完全没

有激活函数

g(z)。也可以认为

这是使用单

位函数作为

激活函

数的

情况。我们已

经看过线性

单元可以用

作神经网络

的输出。它也

可以用作隐

藏单

元。如果

神经网络的

每一层都仅

由线性变换

组成，那么网

络作为一个

整体也将是

线

性的。然而

，神经网络的

一些层是纯

线性也是可

以接受的。考

虑具有

n 个输

入和 p

个输出

的神经网络

层

h = g(W⊤

x

+ b)。我们可以

用两层来代

替它，一层使

用权重矩

阵

U，另一层使用

权重矩阵 V。如

果第一层没

有激活函数

，那么我们对

基于

W 的

原始

层的权重矩

阵进行因式

分解。分解方

法是计算 h

= g(V

⊤U

⊤

x + b)。如

果 U

产

生了 q 个

输出，那么

U 和

V 一起仅包含

(n +

p)q 个参数，而 W 包

含

np 个参数。

如

果 q

很小，这可

以在很大程

度上节省参

数。这是以将

线性变换约

束为低秩的

代价

来实现

的，但这些低

秩关系往往

是足够的。线

性隐藏单元

因此提供了

一种减少网

络

中参数数

量的有效方

法。

softmax

单元是另

外一种经常

用作输出的

单元（如第 6.2.2.3 节

中所描述的

），但

170

第六章 深

度前馈网络

有时也可以

用作隐藏单

元。softmax 单元很自

然地表示具

有 k

个可能值

的离散型随

机变量的概

率分布，所以

它们可以用

作一种开关

。这些类型的

隐藏单元通

常仅用于

明

确地学习操

作内存的高

级结构中，将

在第 10.12 节中描

述。

其他一些

常见的隐藏

单元类型包

括：

• 径向基函

数（radial basis

function, RBF）：hi = exp

(

−

1

σ

2

i

||W:,i −

x||2

)

。这个

函数

在

x 接近模板

W:,i 时更加活跃

。因为它对大

部分 x

都饱和

到 0，因此很

难

优化。

•

softplus函数：g(a) = ζ(a) =

log(1 + e

a

)。这

是整流线性

单元的平滑

版本，

由 Dugas et

al. (2001) 引入

用于函数近

似，由 Nair

and Hinton (2010a) 引入用

于无向概率

模型的条件

分布。Glorot

et al. (2011a) 比较了

softplus

和整流线性

单元，发现后

者的结果更

好。通常不鼓

励使用 softplus 函数

。softplus 表明隐藏

单

元类型的性

能可能是非

常反直觉的

——因为它处处

可导或者因

为它不完全

饱

和，人们可

能希望它具

有优于整流

线性单元的

点，但根据经

验来看，它并

没有。

• 硬双曲

正切函数（hard

tanh）：它

的形状和 tanh 以

及整流线性

单元类似，但

是

不同于后

者，它是有界

的，g(a)

= max(−1, min(1, a))。它由

Collobert (2004)

引入

。

隐藏单元的

设计仍然是

一个活跃的

研究领域，许

多有用的隐

藏单元类型

仍有待

发现

。

6.4 架构设计

神

经网络设计

的另一个关

键点是确定

它的架构。

架

构（architecture）一词是指

网络的整体

结构：它应该

具有多少单

元，以及这些

单元应该如

何连接。

大多

数神经网络

被组织成称

为层的单元

组。大多数神

经网络架构

将这些层布

置

成链式结

构，其中每一

层都是前一

层的函数。在

这种结构中

，第一层由下

式给出：

h

(1) = g

(1)

(

W(1)⊤

x +

b

(1))

; (6.40)

第二

层由

h

(2) =

g

(2) (

W(2)⊤

h

(1) + b

(2))

; (6.41)

6.4

架构设

计 171

给出，以此

类推。

在这些

链式架构中

，主要的架构

考虑是选择

网络的深度

和每一层的

宽度。我们

将

会看到，即使

只有一个隐

藏层的网络

也足够适应

训练集。更深

层的网络通

常能够

对每

一层使用更

少的单元数

和更少的参

数，并且经常

容易泛化到

测试集，但是

通常

也更难

以优化。对于

一个具体的

任务，理想的

网络架构必

须通过实验

，观测在验证

集上的误差

来找到。

6.4.1

万能

近似性质和

深度

线性模

型，通过矩阵

乘法将特征

映射到输出

，顾名思义，仅

能表示线性

函数。它

具有

易于训练的

优点，因为当

使用线性模

型时，许多损

失函数会导

出凸优化问

题。可

惜的是

，我们经常希

望我们的系

统学习非线

性函数。

乍一

看，我们可能

认为学习非

线性函数需

要为我们想

要学习的那

种非线性专

门设计一类

模型族。幸运

的是，具有隐

藏层的前馈

网络提供了

一种万能近

似框架。

具体

来说， 万能近

似定理（universal approximation

theorem）(Hornik et al., 1989;

Cybenko, 1989) 表明

，一个前馈神

经网络如果

具有线性输

出层和至少

一层具有任

何

一种

‘‘挤压

’’ 性质的激活

函数（例如logistic sigmoid激

活函数）的隐

藏层，只要给

予

网络足够

数量的隐藏

单元，它可以

以任意的精

度来近似任

何从一个有

限维空间到

另

一个有限

维空间的 Borel 可

测函数。前馈

网络的导数

也可以任意

好地来近似

函数的

导数

(Hornik

et al., 1990)。Borel 可测的概念

超出了本书

的范畴；对于

我们想要实

现的目标，只

需要知道定

义在

R

n 的有界

闭集上的任

意连续函数

是 Borel

可测的，

因

此可以用神

经网络来近

似。神经网络

也可以近似

从任何有限

维离散空间

映射到另

一

个的任意函

数。虽然原始

定理最初以

具有特殊激

活函数的单

元的形式来

描述，这

个激

活函数当变

量取绝对值

非常大的正

值和负值时

都会饱和，万

能近似定理

也已经

被证

明对于更广

泛类别的激

活函数也是

适用的，其中

就包括现在

常用的整流

线性单

元 (Leshno et

al., 1993)。

万

能近似定理

意味着无论

我们试图学

习什么函数

，我们知道一

个大的 MLP

一

定

能够表示这

个函数。然而

，我们不能保

证训练算法

能够学得这

个函数。即使

MLP

能够表示该

函数，学习也

可能因两个

不同的原因

而失败。首先

，用于训练的

优化算

法可

能找不到用

于期望函数

的参数值。其

次，训练算法

可能由于过

拟合而选择

了错

误的函

数。回忆第 5.2.1 节

中的 ‘‘没有免

费的午餐’’

定

理，说明了没

有普遍优越

的机

器学习

算法。前馈网

络提供了表

示函数的万

能系统，在这

种意义上，给

定一个函数

，

172 第六章

深度

前馈网络

存

在一个前馈

网络能够近

似该函数。不

存在万能的

过程既能够

验证训练集

上的特殊

样

本，又能够选

择一个函数

来扩展到训

练集上没有

的点。

万能近

似定理说明

了，存在一个

足够大的网

络能够达到

我们所希望

的任意精度

，

但是定理并

没有说这个

网络有多大

。Barron (1993) 提供了单层

网络近似一

大类函数

所

需大小的一

些界。不幸的

是，在最坏情

况下，可能需

要指数数量

的隐藏单元

（可

能一个隐

藏单元对应

着一个需要

区分的输入

配置）。这在二

进制值的情

况下很容易

看

到：向量 v ∈

{0, 1}

n 上

的可能的二

值型函数的

数量是

2

2

n，并且

选择一个这

样的函

数需

要

2

n 位，这通常

需要 O(2n

) 的自由

度。

总之，具有

单层的前馈

网络足以表

示任何函数

，但是网络层

可能大得不

可实现，

并且

可能无法正

确地学习和

泛化。在很多

情况下，使用

更深的模型

能够减少表

示期

望函数

所需的单元

的数量，并且

可以减少泛

化误差。

存在

一些函数族

能够在网络

的深度大于

某个值 d 时被

高效地近似

，而当深度被

限制到小于

或等于

d 时需

要一个远远

大于之前的

模型。在很多

情况下，浅层

模型所

需的

隐藏单元的

数量是 n

的指

数级。这个结

果最初被证

明是在那些

不与连续可

微的

神经网

络类似的机

器学习模型

中出现，但现

在已经扩展

到了这些模

型。第一个结

果

是关于逻

辑门电路的

(Håstad, 1986)。后来的工作

将这些结果

扩展到了具

有非负权

重

的线性阈值

单元 (Håstad and Goldmann,

1991; Hajnal et al.,

1993)，然后扩

展到

了具有

连续值激活

的网络 (Maass, 1992;

Maass et al., 1994)。许多

现代神经网

络使

用整流

线性单元。Leshno et al. (1993)

证

明带有一大

类非多项式

激活函数族

的浅层

网络

，包括整流线

性单元，具有

万能的近似

性质，但是这

些结果并没

有强调深度

或

效率的问

题——它们仅指

出足够宽的

整流网络能

够表示任意

函数。Montufar et

al.

(2014) 指出一

些用深度整

流网络表示

的函数可能

需要浅层网

络（一个隐藏

层）指数

级的

隐藏单元才

能表示。更确

切的说，他们

说明分段线

性网络（可以

通过整流非

线

性或 maxout 单元

获得）可以表

示区域的数

量是网络深

度的指数级

的函数。图 6.5

解

释了带有绝

对值整流的

网络是如何

创建函数的

镜像图像的

，这些函数在

某些隐藏单

元的顶部计

算，作用于隐

藏单元的输

入。每个隐藏

单元指定在

哪里折叠输

入空间，来

创

造镜像响应

（在绝对值非

线性的两侧

）。通过组合这

些折叠操作

，我们获得指

数级

的分段

线性区域，他

们可以概括

所有种类的

规则模式（例

如，重复）。

Montufar

et al. (2014) 的主

要定理指出

，具有

d 个输入

、深度为 l、每个

隐藏

6.4

架构设

计 173

图 6.5:

关于更

深的整流网

络具有指数

优势的一个

直观的几何

解释，来自 Montufar et al.

(2014)。

(左

)绝对值整流

单元对其输

入中的每对

镜像点有相

同的输出。镜

像的对称轴

由单元的权

重和偏置

定

义的超平面

给出。在该单

元顶部计算

的函数（绿色

决策面）将是

横跨该对称

轴的更简单

模式的

一个

镜像。(中)

该函

数可以通过

折叠对称轴

周围的空间

来得到。(右) 另

一个重复模

式可以在第

一

个的顶部

折叠（由另一

个下游单元

）以获得另外

的对称性（现

在重复四次

，使用了两个

隐藏层）。

经

Montufar et al. (2014)

许

可改编此图

。

层具有 n 个单

元的深度整

流网络可以

描述的线性

区域的数量

是

O

((

n

d

)d(l−1)

n

d

)

, (6.42)

意味着，这

是深度 l

的指

数级。在每个

单元具有 k 个

过滤器的 maxout

网

络中，线

性区

域的数量是

O

(

k

(l−1)+d

)

. (6.43)

当然，我们不

能保证在机

器学习（特别

是 AI）的应用中

我们想要学

得的函数类

型享有这样

的属性。

我们

还可能出于

统计原因来

选择深度模

型。任何时候

，当我们选择

一个特定的

机

器学习算

法时，我们隐

含地陈述了

一些先验，这

些先验是关

于算法应该

学得什么样

的

函数的。选

择深度模型

默许了一个

非常普遍的

信念，那就是

我们想要学

得的函数应

该

涉及几个

更加简单的

函数的组合

。这可以从表

示学习的观

点来解释，我

们相信学习

的

问题包含

发现一组潜

在的变差因

素，它们可以

根据其他更

简单的潜在

的变差因素

来

描述。或者

，我们可以将

深度结构的

使用解释为

另一种信念

，那就是我们

想要学得的

函数是包含

多个步骤的

计算机程序

，其中每个步

骤使用前一

步骤的输出

。这些中间

输

出不一定是

变差因素，而

是可以类似

于网络用来

组织其内部

处理的计数

器或指针。

根

据经验，更深

的模型似乎

确实在广泛

的任务中泛

化得更好 (Bengio et

al., 2007b;

174 第

六章

深度前

馈网络

Erhan et al.,

2009; Bengio, 2009; Mesnil

et al., 2011; Ciresan

et al., 2012; Krizhevsky

et al., 2012a; Sermanet

et al., 2013; Farabet

et al., 2013; Couprie

et al., 2013; Kahou

et al., 2013; Goodfellow

et al., 2014d; Szegedy

et al., 2014a)。图 6.6

和

图 6.7 展示了

一

些实验结果

的例子。这表

明使用深层

架构确实在

模型学习的

函数空间上

表示了一

个

有用的先验

。

3 4 5

6 7 8 9

10 11

Number of

hidden layers

92.0

92.5

93.0

93.5

94.0

94.5

95.0

95.5

96.0

96.5

图 6.6: 深度的影

响。实验结果

表明，当从地

址照片转录

多位数字时

，更深层的网

络能够更好

地泛

化。数据

来自

Goodfellow et al. (2014d)。测试集

上的准确率

随着深度的

增加而不断

增加。图

6.7 给

出

了一个对照

实验，它说明

了对模型尺

寸其他方面

的增加并不

能产生相同

的效果。

6.4.2

其他

架构上的考

虑

目前为止

，我们都将神

经网络描述

成层的简单

链式结构，主

要的考虑因

素是网

络的

深度和每层

的宽度。在实

践中，神经网

络显示出相

当的多样性

。

许多神经网

络架构已经

被开发用于

特定的任务

。用于计算机

视觉的卷积

神经网

络的

特殊架构将

在第九章中

介绍。前馈网

络也可以推

广到用于序

列处理的循

环神经

网络

，但有它们自

己的架构考

虑，将在第十

章中介绍。

一

般的，层不需

要连接在链

中，尽管这是

最常见的做

法。许多架构

构建了一个

主链，但随后

又添加了额

外的架构特

性，例如从层

i 到层

i + 2 或者更

高层的跳跃

连

接。这些跳

跃连接使得

梯度更容易

从输出层流

向更接近输

入的层。

架构

设计考虑的

另外一个关

键点是如何

将层与层之

间连接起来

。默认的神经

网

络层采用

矩阵 W

描述的

线性变换，每

个输入单元

连接到每个

输出单元。在

之后章节

Test accuracy (percent)

6.5 反

向传播和其

他的微分算

法 175

0.0

0.2 0.4 0.6 0.8

1.0

Number of parameters

×108

91

92

93

94

95

96

97

3, convolutional

3, fully

connected

11, convolutional

图

6.7: 参数数

量的影响。更

深的模型往

往表现更好

。这不仅仅是

因为模型更

大。Goodfellow et al.

(2014d) 的这项实

验表明，增加

卷积网络层

中参数的数

量，但是不增

加它们的深

度，在提升测

试集

性能方

面几乎没有

效果，如此图

所示。图例标

明了用于画

出每条曲线

的网络深度

，以及曲线表

示

的是卷积

层还是全连

接层的大小

变化。我们可

以观察到，在

这种情况下

，浅层模型在

参数数量达

到

2000 万时就过

拟合，而深层

模型在参数

数量超过 6000 万

时仍然表现

良好。这表明

，使用深层

模

型表达出了

对模型可以

学习的函数

空间的有用

偏好。具体来

说，它表达了

一种信念，即

该函数

应该

由许多更简

单的函数复

合在一起而

得到。这可能

导致学习由

更简单的表

示所组成的

表示（例

如，由

边所定义的

角）或者学习

具有顺序依

赖步骤的程

序（例如，首先

定位一组对

象，然后分割

它

们，之后识

别它们）。

中的

许多专用网

络具有较少

的连接，使得

输入层中的

每个单元仅

连接到输出

层单元

的一

个小子集。这

些用于减少

连接数量的

策略减少了

参数的数量

以及用于评

估网络

的计

算量，但通常

高度依赖于

问题。例如，第

九章描述的

卷积神经网

络使用对于

计

算机视觉

问题非常有

效的稀疏连

接的专用模

式。在这一章

中，很难对通

用神经网络

的架构给出

更多具体的

建议。我们在

随后的章节

中介绍一些

特殊的架构

策略，可以

在

不同的领域

工作良好。

6.5 反

向传播和其

他的微分算

法

当我们使

用前馈神经

网络接收输

入

x 并产生输

出 yˆ 时，信息通

过网络向前

流

动。输入 x 提

供初始信息

，然后传播到

每一层的隐

藏单元，最终

产生输出 yˆ。这

称

之为 前向

传播（forward propagation）。在训练

过程中，前向

传播可以持

续向前直

到

它产生一个

标量代价函

数

J(θ)。 反向传播

（back propagation）算法 (Rumelhart

Test accuracy (percent)

176

第六章

深度前馈网

络

et al., 1986c)，经常简称

为backprop，允许来自

代价函数的

信息通过网

络向后流动

，

以便计算梯

度。

计算梯度

的解析表达

式是很直观

的，但是数值

化地求解这

样的表达式

在计算上

的

代价可能很

大。反向传播

算法使用简

单和廉价的

程序来实现

这个目标。

反

向传播这个

术语经常被

误解为用于

多层神经网

络的整个学

习算法。实际

上，

反向传播

仅指用于计

算梯度的方

法，而另一种

算法，例如随

机梯度下降

，使用该梯度

来进行学习

。此外，反向传

播经常被误

解为仅适用

于多层神经

网络，但是原

则上它

可以

计算任何函

数的导数（对

于一些函数

，正确的响应

是报告函数

的导数是未

定义

的）。特别

地，我们会描

述如何计算

一个任意函

数 f

的梯度 ∇xf(x, y)，其

中 x

是一

组变

量，我们需要

它们的导数

，而 y 是函数的

另外一组输

入变量，但我

们并不需要

它们的导数

。在学习算法

中，我们最常

需要的梯度

是代价函数

关于参数的

梯度，即

∇θJ(θ)。许多

机器学习任

务需要计算

其他导数，来

作为学习过

程的一部分

，或者用

来分

析学得的模

型。反向传播

算法也适用

于这些任务

，不局限于计

算代价函数

关于

参数的

梯度。通过在

网络中传播

信息来计算

导数的想法

非常普遍，它

还可以用于

计

算诸如多

输出函数

f 的

Jacobian 的值。我们这

里描述的是

最常用的情

况，其中 f

只有

单个输出。

6.5.1 计

算图

目前为

止，我们已经

用相对非正

式的图形语

言讨论了神

经网络。为了

更精确地

描

述反向传播

算法，使用更

精确的 计算

图（computational graph）语言是很

有帮助

的。

将

计算形式化

为图形的方

法有很多。

这

里，我们使用

图中的每一

个节点来表

示一个变量

。变量可以是

标量、向量、矩

阵、张量、或者

甚至是另一

类型的变量

。

为了形式化

我们的图形

，我们还需引

入 操作（operation）这一

概念。操作是

指

一个或多

个变量的简

单函数。我们

的图形语言

伴随着一组

被允许的操

作。我们可以

通过将多个

操作复合在

一起来描述

更为复杂的

函数。

不失一

般性，我们定

义一个操作

仅返回单个

输出变量。这

并没有失去

一般性，是

因

为输出变量

可以有多个

条目，例如向

量。反向传播

的软件实现

通常支持具

有多个

输出

的操作，但是

我们在描述

中避免这种

情况，因为它

引入了对概

念理解不重

要的

6.5 反向传

播和其他的

微分算法 177

许

多额外细节

。

如果变量 y 是

变量 x

通过一

个操作计算

得到的，那么

我们画一条

从 x 到 y

的有

向

边。我们有时

用操作的名

称来注释输

出的节点，当

上下文很明

确时，有时也

会省

略这个

标注。

计算图

的实例可以

参考图

6.8 。

z

x

y

(a)

⇥

x

w

(b)

uu(1) (1)

dot

b

uu(2) (2)

+

yyˆˆ

σ

(c)

X W

UU(1) (1)

matmul

b

UU(2) (2)

+

H

relu

x

w

(d)

yyˆˆ

dot

λ

uu(1) (1)

sqr

uu(2) (2)

sum

uu(3)

(3)

⇥

图 6.8:

一

些计算图的

示例。(a) 使用 × 操

作计算

z = xy 的图

。(b)

用于逻辑回

归预测 yˆ =

σ(x

⊤w + b) 的图

。一些中间表

达式在代数

表达式中没

有名称，但在

图形中却需

要。我们简单

地将

第 i 个这

样的变量命

名为 u

(i)。(c) 表达式

H = max{0,

XW + b} 的计算图，在

给定包含小

批量

输入数

据的设计矩

阵 X 时，它计算

整流线性单

元激活的设

计矩阵 H。(d)

示例

a-c 对每个变量

最

多只实施

一个操作，但

是对变量实

施多个操作

也是可能的

。这里我们展

示一个计算

图，它对线性

回归模型的

权重 w

实施多

个操作。这个

权重不仅用

于预测 yˆ，也用

于权重衰减

罚项 λ

∑

i wi

2。

178

第六章

深度前馈网

络

6.5.2 微积分中

的链式法则

微积分中的

链式法则（为

了不与概率

中的链式法

则相混淆）用

于计算复合

函数

的导数

。反向传播是

一种计算链

式法则的算

法，使用高效

的特定运算

顺序。

设 x 是实

数，f 和

g 是从实

数映射到实

数的函数。假

设 y =

g(x) 并且 z =

f(g(x)) = f(y)。那么

链式法则是

说

dz

dx =

dz

dy

dy

dx. (6.44)

我们可以

将这种标量

情况进行扩

展。假设

x ∈ R

m,

y ∈ R

n，g

是从

R

m 到 R

n 的

映射，f 是

从

R

n 到 R

的映射

。如果 y = g(x)

并且 z = f(y)，那

么

∂z

∂xi

=

∑

j

∂y

∂z

j

∂yj

∂xi

. (6.45)

使用向量

记法，可以等

价地写成

∇xz =

(

∂

∂

y

x

)⊤

∇yz, (6.46)

这

里

∂

∂

y

x

是 g 的 n

× m 的 Jacobian

矩

阵。

从这里我

们看到，变量

x 的梯度可以

通过 Jacobian

矩阵∂

∂

y

x

和

梯度 ∇yz 相乘来

得到。反向传

播算法由图

中每一个这

样的 Jacobian

梯度的

乘积操作所

组成。

通常我

们将反向传

播算法应用

于任意维度

的张量，而不

仅仅用于向

量。从概念

上

讲，这与使用

向量的反向

传播完全相

同。唯一的区

别是如何将

数字排列成

网格以

形成

张量。我们可

以想象，在我

们运行反向

传播之前，将

每个张量变

平为一个向

量，

计算一个

向量值梯度

，然后将该梯

度重新构造

成一个张量

。从这种重新

排列的观点

上看，反向传

播仍然只是

将 Jacobian 乘以梯度

。

为了表示值

z

关于张量 X 的

梯度，我们记

为 ∇Xz，就像

X 是向

量一样。X 的

索

引现在有多

个坐标——例如

，一个

3 维的张

量由三个坐

标索引。我们

可以通过

使

用单个变量

i 来表示完整

的索引元组

，从而完全抽

象出来。对所

有可能的元

组

i，

(∇Xz)i 给出 ∂

∂z

Xi。这与

向量中索引

的方式完全

一致，(∇xz)i 给出 ∂x

∂z

i。使

用这种记

法

，我们可以写

出适用于张

量的链式法

则。如果 Y

= g(X) 并且

z =

f(Y)，那么

∇Xz =

∑

j

(∇XYj )

∂z

∂Yj

. (6.47)

6.5

反向传

播和其他的

微分算法 179

6.5.3 递

归地使用链

式法则来实

现反向传播

使用链式规

则，我们可以

直接写出某

个标量关于

计算图中任

何产生该标

量的节

点的

梯度的代数

表达式。然而

，实际在计算

机中计算该

表达式时会

引入一些额

外的

考虑。

具

体来说，许多

子表达式可

能在梯度的

整个表达式

中重复若干

次。任何计算

梯

度的程序

都需要选择

是存储这些

子表达式还

是重新计算

它们几次。图

6.9

给出了一个

例子来说明

这些重复的

子表达式是

如何出现的

。在某些情况

下，计算两次

相同的子

表

达式纯粹是

浪费。在复杂

图中，可能存

在指数多的

这种计算上

的浪费，使得

简单

的链式

法则不可实

现。在其他情

况下，计算两

次相同的子

表达式可能

是以较高的

运

行时间为

代价来减少

内存开销的

有效手段。

我

们首先给出

一个版本的

反向传播算

法，它指明了

梯度的直接

计算方式（算

法 6.2 以及相关

的正向计算

的算法 6.1

），按照

它实际完成

的顺序并且

递归地使用

链

式法则。我

们可以直接

执行这些计

算或者将算

法的描述视

为用于计算

反向传播的

计

算图的符

号表示。然而

，这些公式并

没有明确地

操作和构造

用于计算梯

度的符号图

。

这些公式将

在后面的第

6.5.6

节和算法 6.5 中

给出，其中我

们还推广到

了包含任意

张

量的节点

。

首先考虑描

述如何计算

单个标量 u

(n)（例

如训练样本

上的损失函

数）的计算图

。

我们想要计

算这个标量

对

ni 个输入节

点 u

(1)

到 u

(ni) 的梯度

。换句话说，我

们希望

对所

有的 i ∈ {1,

2, . . .

, ni} 计算 ∂u

∂u

(

(

n

i)

)。在

使用反向传

播计算梯度

来实现参数

的梯度

下降

时，u

(n)

将对应单

个或者小批

量实例的代

价函数，而 u

(1) 到

u

(ni) 则对应于模

型

的参数。

我

们假设图的

节点已经以

一种特殊的

方式被排序

，使得我们可

以一个接一

个地

计算他

们的输出，从

u

(ni+1) 开始，一直上

升到 u

(n)。如算法

6.1 中所定义的

，每个

节点 u

(i) 与

操作 f

(i)

相关联

，并且通过对

以下函数求

值来得到

u

(i) =

f(A

(i)

), (6.48)

其

中 A

(i) 是

u

(i) 所有父

节点的集合

。

该算法详细

说明了前向

传播的计算

，我们可以将

其放入图

G 中

。为了执行反

向

传播，我们

可以构造一

个依赖于 G

并

添加额外一

组节点的计

算图。这形成

了一个子

图

B，它的每个节

点都是 G 的节

点。B

中的计算

和 G 中的计算

顺序完全相

反，而且

B

中的

每个节点计

算导数 ∂u

∂u

(

(

n

i)

)

与前

向图中的节

点 u

(i) 相关联。这

通过对标量

输出

180 第六章

深度前馈网

络

算法 6.1

计算

将 ni 个输入 u

(1) 到

u

(ni) 映射到一个

输出

u

(n) 的程序

。这定义了一

个计算图，其

中每个节点

通过将函数

f

(i)

应用到变量

集合 A

(i) 上来计

算

u

(i) 的值，

A

(i) 包含

先前节点 u

(j)

的

值满足 j < i

且 j ∈ P

a(u

(i)

)。计

算图的输入

是向量 x，并

且

被分配给前

ni 个节点 u

(1)

到 u

(ni)。计

算图的输出

可以从最后

一个（输出）节

点

u

(n) 读出。

for i

= 1, . .

. , ni do

u

(i) ← xi

end for

for i

= ni + 1,

. . . ,

n do

A

(i)

← {u

(j)

|

j ∈ P a(u

(i)

)}

u

(i)

← f

(i)

(A

(i)

)

end for

return u

(n)

u

(n) 使用

链式法则来

完成：

∂u(n)

∂u(j)

=

∑

i:j∈P a(u(i))

∂u(n)

∂u(i)

∂u(i)

∂u(j)

(6.49)

这在算

法 6.2 中详细说

明。子图

B 恰好

包含每一条

对应着 G 中从

节点

u

(j) 到节点

u

(i)

的边。从 u

(j) 到

u

(i) 的

边对应着计

算 ∂u

∂u

(

(

j

i)

)。另外，对于

每个节点都

要执行一个

内积，内积的

一个因子是

对于 u

j

子节点

u

(i) 的已经计算

的梯度，另一

个因子是对

于

相同子节

点

u

(i) 的偏导数

∂u

∂u

(

(

j

i)

) 组成的向量

。总而言之，执

行反向传播

所需的计算

量

与 G

中的边

的数量成比

例，其中每条

边的计算包

括计算偏导

数（节点关于

它的一个

父

节点的偏导

数）以及执行

一次乘法和

一次加法。下

面，我们将此

分析推广到

张量

值节点

，这只是在同

一节点中对

多个标量值

进行分组并

能够更高效

地实现。

反向

传播算法被

设计为减少

公共子表达

式的数量而

不考虑存储

的开销。具体

来

说，它大约

对图中的每

个节点执行

一个 Jacobian 乘积。这

可以从算法

6.2 中看出，反

向

传播算法访

问了图中的

节点 u

(j) 到节点

u

(i) 的每条边一

次，以获得相

关的偏导数

∂u(i)

∂u(j)。反向传播因

此避免了重

复子表达式

的指数爆炸

。然而，其他算

法可能通过

对

计算图进

行简化来避

免更多的子

表达式，或者

也可能通过

重新计算而

不是存储这

些

子表达式

来节省内存

。我们将在描

述完反向传

播算法本身

后再重新审

视这些想法

。

6.5 反向传播和

其他的微分

算法 181

z

x

y

w

f

f

f

图

6.9: 计算

梯度时导致

重复子表达

式的计算图

。令 w ∈

R 为图的输

入。我们对链

中的每一步

使

用相同的

操作函数 f

: R → R，这

样

x = f(w), y

= f(x), z =

f(y)。为了计算

∂w

∂z ，我们应用

式

(6.44)

得到：

∂z

∂w (6.50)

=

∂z

∂y

∂y

∂x

∂x

∂w (6.51)

=f

′

(y)f

′

(x)f

′

(w) (6.52)

=f

′

(f(f(w)))f

′

(f(w))f

′

(w). (6.53)

式 (6.52) 建议

我们采用的

实现方式是

，仅计算 f(w)

的值

一次并将它

存储在变量

x 中。这是反

向

传播算法所

采用的方法

。式 (6.53)

提出了一

种替代方法

，其中子表达

式 f(w) 出现了不

止一

次。在替

代方法中，每

次只在需要

时重新计算

f(w)。当存储这些

表达式的值

所需的存储

较少时，

式 (6.52) 的

反向传播方

法显然是较

优的，因为它

减少了运行

时间。然而，式

(6.53) 也是链式法

则的

有效实

现，并且当存

储受限时它

是有用的。

6.5.4 全

连接 MLP

中的反

向传播计算

为了阐明反

向传播的上

述定义，让我

们考虑一个

与全连接的

多层 MLP 相关联

的特定图。

算

法

6.3 首先给出

了前向传播

，它将参数映

射到与单个

训练样本（输

入，目标）

(x, y)

相关

联的监督损

失函数 L(yˆ, y)，其中

yˆ 是当

x 提供输

入时神经网

络的输出。

算

法 6.4

随后说明

了将反向传

播应用于该

图所需的相

关计算。

182 第六

章 深度前馈

网络

算法 6.2 反

向传播算法

的简化版本

，用于计算 u

(n) 关

于图中变量

的导数。这个

示

例旨在通

过演示所有

变量都是标

量的简化情

况来进一步

理解反向传

播算法，这里

我

们希望计

算关于

u

(1), . .

. , u(ni) 的导

数。这个简化

版本计算了

关于图中所

有节点的导

数。假定与每

条边相关联

的偏导数计

算需要恒定

的时间的话

，该算法的计

算成本与

图

中边的数量

成比例。这与

前向传播的

计算次数具

有相同的阶

。每个 ∂u

∂u

(

(

j

i)

)

是 u

(i) 的

父

节点 u

(j) 的函数

，从而将前向

图的节点链

接到反向传

播图中添加

的节点。

运行

前向传播 (对

于此例是算

法 6.1 )

获得网络

的激活。

初始

化 grad_table，用于存储

计算好的导

数的数据结

构。grad_table[u

(i)

] 将存

储 ∂u

∂u

(

(

n

i)

) 计

算好的值。

grad_table[u

(n)

] ← 1

for j = n

− 1 down to

1 do

下

一行使用存

储的值计算

∂u

∂u

(

(

n

j)

)

=

∑

i:j∈P

a(u(i))

∂u(n)

∂u(i)

∂u(i)

∂u(j)：

grad_table[u

(j)

]

←

∑

i:j∈P a(u(i))

grad_table[u

(i)

]

∂u

∂u

(

(

j

i)

)

end for

return {grad_table[u

(i)

]

| i = 1,

. . . ,

ni}

算法 6.3 和算法

6.4

是简单而直

观的演示。然

而，它们专门

针对特定的

问题。

现在的

软件实现基

于之后第 6.5.6 节

中描述的一

般形式的反

向传播，它可

以通过

显式

地操作表示

符号计算的

数据结构，来

适应任何计

算图。

6.5.5 符号到

符号的导数

代数表达式

和计算图都

对 符号（symbol）或不

具有特定值

的变量进行

操作。这

些代

数或者基于

图的表达式

被称为 符号

表示（symbolic representation）。当我们

实

际使用或

者训练神经

网络时，我们

必须给这些

符号赋特定

的值。我们用

一个特定

的

数值（numeric value）来替代

网络的符号

输入 x，例如 [1.2,

3, 765, −1.8]⊤。

一

些反向传播

的方法采用

计算图和一

组用于图的

输入的数值

，然后返回在

这些

输入值

处梯度的一

组数值。我们

将这种方法

称为 符号到

数值的微分

。这种方法用

在

诸如 Torch

(Collobert et al., 2011b)

和 Caffe (Jia, 2013)

之

类的库中。

另

一种方法是

采用计算图

以及添加一

些额外的节

点到计算图

中，这些额外

的节

点提供

了我们所需

导数的符号

描述。这是 Theano

(Bergstra et al., 2010b;

Bastien

6.5 反

向传播和其

他的微分算

法 183

算法 6.3 典型

深度神经网

络中的前向

传播和代价

函数的计算

。损失函数 L(yˆ,

y) 取

决于输出 yˆ 和

目标

y（参考第

6.2.1.1 节中损失函

数的示例）。为

了获得总代

价 J，损

失函数

可以加上正

则项

Ω(θ)，其中 θ 包

含所有参数

（权重和偏置

）。算法 6.4

说明了

如何计算 J 关

于参数 W

和 b 的

梯度。为简单

起见，该演示

仅使用单个

输入样本 x。

实

际应用应该

使用小批量

。请参考第6.5.7 节

以获得更加

真实的演示

。

Require: 网络深度，l

Require: W(i)

, i

∈ {1, . .

. , l}，模

型的权重矩

阵

Require:

b

(i)

, i

∈ {1, . .

. , l}，模型的偏

置参数

Require:

x，程序

的输入

Require: y，目标

输出

h

(0) = x

for

k = 1, .

. . , l

do

a

(k) =

b

(k) + W(k)

h

(k−1)

h

(k)

= f(a

(k)

)

end for

yˆ =

h

(l)

J =

L(yˆ, y) + λΩ(θ)

et al., 2012b) 和

TensorFlow (Abadi et al.,

2015) 所采

用的方法。图

6.10 给出了该方

法如何工作

的一个例子

。这种方法的

主要优点是

导数可以使

用与原始表

达式相同的

语言来描述

。因为导数只

是另外一张

计算图，我们

可以再次运

行反向传播

，对导数

再进

行求导就能

得到更高阶

的导数。高阶

导数的计算

在第

6.5.10 节中描

述。

我们将使

用后一种方

法，并且使用

构造导数的

计算图的方

法来描述反

向传播算

法

。图的任意子

集之后都可

以使用特定

的数值来求

值。这允许我

们避免精确

地指明

每个

操作应该在

何时计算。相

反，通用的图

计算引擎只

要当一个节

点的父节点

的值

都可用

时就可以进

行求值。

基于

符号到符号

的方法的描

述包含了符

号到数值的

方法。符号到

数值的方法

可

以理解为

执行了与符

号到符号的

方法中构建

图的过程中

完全相同的

计算。关键的

区

别是符号

到数值的方

法不会显示

出计算图。

184 第

六章 深度前

馈网络

算法

6.4 深度神经网

络中算法 6.3 的

反向计算，它

不止使用了

输入

x 和目标

y。该

计算对于

每一层 k

都产

生了对激活

a

(k) 的梯度，从输

出层开始向

后计算一直

到第一

个隐

藏层。这些梯

度可以看作

是对每层的

输出应如何

调整以减小

误差的指导

，根据

这些梯

度可以获得

对每层参数

的梯度。权重

和偏置上的

梯度可以立

即用作随机

梯度

更新的

一部分（梯度

算出后即可

执行更新），或

者与其他基

于梯度的优

化方法一起

使

用。

在前向

计算完成后

，计算顶层的

梯度：

g ← ∇ˆyJ =

∇ˆyL(yˆ, y)

for k

= l, l −

1, . . .

, 1 do

将关于

层输出的梯

度转换为非

线性激活输

入前的梯度

（如果

f 是逐元

素的，则

逐元

素地相乘）：

g

← ∇a(k)J = g

⊙ f

′

(a

(k)

)

计

算关于权重

和偏置的梯

度（如果需要

的话，还要包

括正则项）：

∇b

(k)J = g +

λ∇b

(k)Ω(θ)

∇W(k)J =

g h(k−1)⊤ + λ∇W(k)Ω(θ)

关

于下一更低

层的隐藏层

传播梯度：

g ← ∇h

(k−1)J = W(k)⊤

g

end for

6.5 反

向传播和其

他的微分算

法

185

z

x

y

w

f

f

f

z

x

y

w

f

f

f

dz

dy

dz

dy

f0

dy

dx

dy

dx

f0

dz

dx

dz

dx

⇥

dx

dw

dx

dw

f0

dz

dw

dz

dw

⇥

图 6.10: 使用符

号到符号的

方法计算导

数的示例。在

这种方法中

，反向传播算

法不需要访

问任何实

际

的特定数值

。相反，它将节

点添加到计

算图中来描

述如何计算

这些导数。通

用图形求值

引擎可

以在

随后计算任

何特定数值

的导数。(左) 在

这个例子中

，我们从表示

z = f(f(f(w)))

的图开始。

(右

) 我们运行反

向传播算法

，指导它构造

表达式 dw

dz 对应

的图。在这个

例子中，我们

不解释反向

传播算法如

何工作。我们

的目的只是

说明想要的

结果是什么

：符号描述的

导数的计算

图。

6.5.6 一般化的

反向传播

反

向传播算法

非常简单。为

了计算某个

标量 z 关于图

中它的一个

祖先 x

的梯

度

，我们首先观

察到它关于

z 的梯度由 dz

dz = 1 给

出。然后，我们

可以计算对

图中

z

的每个

父节点的梯

度，通过现有

的梯度乘以

产生 z 的操作

的

Jacobian。我们继续

乘

以 Jacobian，以这种

方式向后穿

过图，直到我

们到达 x。对于

从

z 出发可以

经过两

个或

更多路径向

后行进而到

达的任意节

点，我们简单

地对该节点

来自不同路

径上的

梯度

进行求和。

更

正式地，图 G 中

的每个节点

对应着一个

变量。为了实

现最大的一

般化，我们

将

这个变量描

述为一个张

量

V。张量通常

可以具有任

意维度，并且

包含标量、向

量

和矩阵。

我

们假设每个

变量 V

与下列

子程序相关

联：

• get_operation(V)：它返回用

于计算 V

的操

作，代表了在

计算图中流

入 V

的边。例如

，可能有一个

Python 或者

C++ 的类表

示矩阵乘法

操作，以

及 get_operation

函

数。假设我们

的一个变量

是由矩阵乘

法产生的，C = AB。

186

第

六章 深度前

馈网络

那么

，get_operation(V) 返回一个指

向相应

C++ 类的

实例的指针

。

• get_consumers(V,

G)：它返回一组

变量，是计算

图 G 中 V

的子节

点。

• get_inputs(V, G)：它返回一

组变量，是计

算图

G 中 V 的父

节点。

每个操

作 op 也与 bprop

操作

相关联。该 bprop 操

作可以计算

如式 (6.47)

所描

述

的 Jacobian 向量积。这

是反向传播

算法能够实

现很大通用

性的原因。每

个操作负

责

了解如何通

过它参与的

图中的边来

反向传播。例

如，我们可以

使用矩阵乘

法操作

来产

生变量 C =

AB。假设

标量 z 关于 C

的

梯度是 G。矩阵

乘法操作负

责定义两

个

反向传播规

则，每个规则

对应于一个

输入变量。如

果我们调用

bprop 方法来请求

关于

A 的梯度

，那么在给定

输出的梯度

为 G 的情况下

，矩阵乘法操

作的

bprop 方

法必

须说明关于

A 的梯度是

GB⊤。类

似的，如果我

们调用 bprop 方法

来请求关

于

B

的梯度，那么

矩阵操作负

责实现 bprop 方法

并指定希望

的梯度是 A

⊤G。反

向

传播算法

本身并不需

要知道任何

微分法则。它

只需要使用

正确的参数

调用每个操

作

的 bprop

方法即

可。正式地， op.bprop(inputs, X, G)

必

须返回

∑

i

(∇Xop.f(inputs)i)Gi

, (6.54)

这只

是如式 (6.47)

所表

达的链式法

则的实现。这

里，inputs 是提供给

操作的一组

输

入，op.f 是操作

实现的数学

函数，X

是输入

，我们想要计

算关于它的

梯度，G 是操

作

对于输出的

梯度。

op.bprop

方法应

该总是假装

它的所有输

入彼此不同

，即使它们不

是。例如，如

果

mul 操作传递两

个 x

来计算 x

2，op.bprop 方

法应该仍然

返回

x 作为对

于两个输

入

的导数。反向

传播算法后

面会将这些

变量加起来

获得 2x，这是

x 上

总的正确的

导

数。

反向传

播算法的软

件实现通常

提供操作和

其

bprop 方法，所以

深度学习软

件库

的用户

能够对使用

诸如矩阵乘

法、指数运算

、对数运算等

等常用操作

构建的图进

行

反向传播

。构建反向传

播新实现的

软件工程师

或者需要向

现有库添加

自己的操作

的

高级用户

通常必须手

动为新操作

推导 op.bprop 方法。

反

向传播算法

的正式描述

参考算法

6.5 。

在

第 6.5.2

节中，我们

使用反向传

播作为一种

策略来避免

多次计算链

式法则中的

相同子表达

式。由于这些

重复子表达

式的存在，简

单的算法可

能具有指数

运行时间。

现

在我们已经

详细说明了

反向传播算

法，我们可以

去理解它的

计算成本。如

果我们

6.5 反向

传播和其他

的微分算法

187

算法 6.5 反向传

播算法最外

围的骨架。这

部分做简单

的设置和清

理工作。大多

数重

要的工

作发生在算

法

6.6 的子程序

build_grad 中。

Require:

T，需要计算

梯度的目标

变量集

Require: G，计算

图

Require:

z，要微分的

变量

令 G

′

为 G 剪

枝后的计算

图，其中仅包

括 z

的祖先以

及 T 中节点的

后代。

初始化

grad_table，它是关联张

量和对应导

数的数据结

构。

grad_table[z] ← 1

for

V in T do

build_grad(V, G, G

′

, grad_table)

end for

Return grad_table restricted to

T

假设每个

操作的执行

都有大致相

同的开销，那

么我们可以

依据执行操

作的数量来

分

析计算成

本。注意这里

我们将一个

操作记为计

算图的基本

单位，它实际

可能包含许

多算术运算

（例如，我们可

能将矩阵乘

法视为单个

操作）。在具有

n 个节点的图

中计

算梯度

，将永远不会

执行超过 O(n

2

)

个

操作，或者存

储超过 O(n

2

)

个操

作的输出。

这

里我们是对

计算图中的

操作进行计

数，而不是由

底层硬件执

行的单独操

作，所以

重要

的是要记住

每个操作的

运行时间可

能是高度可

变的。例如，两

个矩阵相乘

可能

对应着

图中的一个

单独的操作

，但这两个矩

阵可能每个

都包含数百

万个元素。我

们

可以看到

，计算梯度至

多需要 O(n

2

)

的操

作，因为在最

坏的情况下

，前向传播的

步

骤将在原

始图的全部

n 个节点上运

行（取决于我

们想要计算

的值，我们可

能不需要

执

行整个图）。反

向传播算法

在原始图的

每条边添加

一个

Jacobian 向量积

，可以用

O(1) 个节

点来表达。因

为计算图是

有向无环图

，它至多有

O(n

2

) 条

边。对于实践

中

常用图的

类型，情况会

更好。大多数

神经网络的

代价函数大

致是链式结

构的，使得

反

向传播只有

O(n) 的成本。这远

远胜过简单

的方法，简单

方法可能需

要在指数级

的节点上运

算。这种潜在

的指数级代

价可以通过

非递归地扩

展和重写递

归链式法则

（式(6.49) ）来看出：

∂u(n)

∂u(j)

=

∑

path(u

(π1)

,u(π2)

,...,u(πt)

),

from π1=j to

πt=n

t∏

k=2

∂u(πk)

∂u(πk−1)

. (6.55)

由

于节点

j 到节

点 n 的路径数

目可以关于

这些路径的

长度上指数

地增长，所以

上述

188 第六章

深度前馈网

络

算法 6.6

反向

传播算法的

内循环子程

序 build_grad(V, G, G

′

, grad_table)，由算

法

6.5 中

定义的反向

传播算法调

用。

Require: V，应该被加

到

G 和 grad_table 的变量

。

Require: G，要修改的图

。

Require: G

′，根据参与梯

度的节点 G 的

受限图。

Require:

grad_table，将节

点映射到对

应梯度的数

据结构。

if V is

in grad_table then

Return

grad_table[V]

end if

i

← 1

for C

in get_consumers(V, G

′

) do

op ←

get_operation(C)

D ← build_grad(C,

G, G

′

,

grad_table)

G

(i) ←

op.bprop(get_inputs(C, G

′

),

V, D)

i ←

i + 1

end

for

G ←

∑

i G

(i)

grad_table[V]

= G

插入

G 和将其生成

到

G 中的操作

Return G

求和符号中

的项数（这些

路径的数目

），可能以前向

传播图的深

度的指数级

增长。会

产生

如此大的成

本是因为对

于 ∂u

∂u

(

(

j

i)

)，相同的计

算会重复进

行很多次。为

了避免这种

重新计算，我

们可以将反

向传播看作

一种表填充

算法，利用存

储的中间结

果

∂u

∂u

(

(

n

i)

) 来

对表进

行填充。图中

的每个节点

对应着表中

的一个位置

，这个位置存

储对该节点

的

梯度。通过

顺序填充这

些表的条目

，反向传播算

法避免了重

复计算许多

公共子表达

式。这种表填

充策略有时

被称为 动态

规划（dynamic programming）。

6.5.7 实例：用

于 MLP 训练的反

向传播

作为

一个例子，我

们利用反向

传播算法来

训练多层感

知机。

这里，我

们考虑一个

具有单个隐

藏层的非常

简单的多层

感知机。为了

训练这个

6.5 反

向传播和其

他的微分算

法

189

模型，我们

将使用小批

量随机梯度

下降算法。反

向传播算法

用于计算单

个小批量上

的代价的梯

度。具体来说

，我们使用训

练集上的一

小批量实例

，将其规范化

为一个设

计

矩阵 X

以及相

关联的类标

签向量 y。网络

计算隐藏特

征层 H =

max{0, XW(1)}。

为了简

化表示，我们

在这个模型

中不使用偏

置。假设我们

的图语言包

含 relu

操作，

该操

作可以对 max{0, Z}

表

达式的每个

元素分别进

行计算。类的

非归一化对

数概率

的预

测将随后由

HW(2) 给出。假设我

们的图语言

包含 cross_entropy

操作，用

以

计算目标

y 和由这些未

归一化对数

概率定义的

概率分布间

的交叉熵。所

得到的交叉

熵定义了代

价函数 JMLE。最小

化这个交叉

熵将执行对

分类器的最

大似然估计

。然而，

为了使

得这个例子

更加真实，我

们也包含一

个正则项。总

的代价函数

为

J = JMLE

+ λ

(∑

i,j

(

Wi,j

(1))2

+

∑

i,j

(

Wi,j

(2))2

)

(6.56)

包含了交

叉熵和系数

为

λ 的权重衰

减项。它的计

算图在图 6.11 中

给出。

X WW(1) (1)

UU(1)

(1)

matmul

H

relu

UU(3) (3)

sqr uu(4)

(4)

sum

λ uu(7)

(7) WW(2) (2)

UU(2)

(2)

matmul

y

JJMLE

MLE

cross_entropy

UU(5) (5)

sqr uu(6) (6)

sum

uu(8) (8)

J

+

⇥

+

图 6.11:

用于

计算代价函

数的计算图

，这个代价函

数是使用交

叉熵损失以

及权重衰减

训练我们的

单层 MLP 示例所

产生的。

这个

示例的梯度

计算图实在

太大，以致绘

制或者阅读

都将是乏味

的。这显示出

了反向传播

算法的优点

之一，即它可

以自动生成

梯度，而这种

计算对于软

件工程师

190 第

六章 深度前

馈网络

来说

需要进行直

观但冗长的

手动推导。

我

们可以通过

观察图 6.11 中的

正向传播图

来粗略地描

述反向传播

算法的行为

。

为了训练，我

们希望计算

∇W(1)J

和 ∇W(2)J。有两种不

同的路径从

J 后退到权重

：

一条通过交

叉熵代价，另

一条通过权

重衰减代价

。权重衰减代

价相对简单

，它总是

对 W(i) 上

的梯度贡献

2λW(i)。

另一条通过

交叉熵代价

的路径稍微

复杂一些。令

G

是由 cross_entropy 操作

提

供的对未归

一化对数概

率

U

(2) 的梯度。反

向传播算法

现在需要探

索两个不同

的分

支。在较

短的分支上

，它使用对矩

阵乘法的第

二个变量的

反向传播规

则，将

H

⊤G 加

到

W(2) 的

梯度上。另一

条更长些的

路径沿着网

络逐步下降

。首先，反向传

播算法使

用

对矩阵乘法

的第一个变

量的反向传

播规则，计算

∇HJ =

GW(2)⊤。接下来，relu

操作

使用其反向

传播规则对

先前梯度的

部分位置清

零，这些位置

对应着 U

(1)

中所

有

小于 0 的元

素。记上述结

果为

G

′。反向传

播算法的最

后一步是使

用对 matmul 操作

的

第二个变量

的反向传播

规则，将 X

⊤G

′

加到

W(1) 的梯度上。

在

计算了这些

梯度以后，梯

度下降算法

或者其他优

化算法所要

做的就是使

用这

些梯度

来更新参数

。

对于 MLP，计算成

本主要来源

于矩阵乘法

。在前向传播

阶段，我们乘

以每个权

重

矩阵，得到了

O(w) 数量的乘-加

，其中

w 是权重

的数量。在反

向传播阶段

，我们

乘以每

个权重矩阵

的转置，这具

有相同的计

算成本。算法

主要的存储

成本是我们

需

要将输入

存储到隐藏

层的非线性

中去。这些值

从被计算时

开始存储，直

到反向过程

回到了同一

点。因此存储

成本是

O(mnh)，其中

m 是小批量中

样本的数目

，nh 是隐

藏单元

的数量。

6.5.8 复杂

化

我们这里

描述的反向

传播算法要

比实践中实

际使用的实

现要简单。

正

如前面提到

的，我们将操

作的定义限

制为返回单

个张量的函

数。大多数软

件

实现需要

支持可以返

回多个张量

的操作。例如

，如果我们希

望计算张量

中的最大值

和该值的索

引，则最好在

单次运算中

计算两者，因

此将该过程

实现为具有

两个输出

的

操作效率更

高。

我们还没

有描述如何

控制反向传

播的内存消

耗。反向传播

经常涉及将

许多张量

加

在一起。在朴

素方法中，将

分别计算这

些张量中的

每一个，然后

在第二步中

对所

6.5 反向传

播和其他的

微分算法 191

有

这些张量求

和。朴素方法

具有过高的

存储瓶颈，可

以通过保持

一个缓冲器

，并且

在计算

时将每个值

加到该缓冲

器中来避免

该瓶颈。

反向

传播的现实

实现还需要

处理各种数

据类型，例如

32 位浮点数、64 位

浮点

数和整

型。处理这些

类型的策略

需要特别的

设计考虑。

一

些操作具有

未定义的梯

度，并且重要

的是跟踪这

些情况并且

确定用户请

求的

梯度是

否是未定义

的。

各种其他

技术的特性

使现实世界

的微分更加

复杂。这些技

术性并不是

不可逾越

的

，本章已经描

述了计算微

分所需的关

键知识工具

，但重要的是

要知道还有

许多的

精妙

之处存在。

6.5.9 深

度学习界以

外的微分

深

度学习界在

某种程度上

已经与更广

泛的计算机

科学界隔离

开来，并且在

很大

程度上

发展了自己

关于如何进

行微分的文

化态度。更一

般地， 自动微

分（automatic

differentiation）领域关心

如何以算法

方式计算导

数。这里描述

的反向传播

算法只是

自

动微分的一

种方法。它是

一种称为 反

向模式累加

（reverse mode accumulation）的

更广泛类

型的技术的

特殊情况。其

他方法以不

同的顺序来

计算链式法

则的子表达

式。

一般来说

，确定一种计

算的顺序使

得计算开销

最小，是困难

的问题。找到

计算梯度

的

最优操作序

列是 NP

完全问

题 (Naumann, 2008)，在这种意

义上，它可能

需要将

代数

表达式简化

为它们最廉

价的形式。

例

如，假设我们

有变量 p1, p2 .

. . , pn

表示

概率，以及变

量 z1, z2, .

. . , zn

表示未

归

一化的对数

概率。假设我

们定义

qi =

exp(zi)

∑

i

exp(zi)

, (6.57)

其中

我们通过指

数化、求和与

除法运算构

建 softmax

函数，并构

造交叉熵损

失函

数 J =

−

∑

i

pi

log qi。人类

数学家可以

观察到 J 对

zi 的

导数有一个

非常简单的

形

式：qi −

pi 反向传

播算法不能

够以这种方

式来简化梯

度，而是会通

过原始图中

的所

有对数

和指数操作

显式地传播

梯度。一些软

件库如 Theano

(Bergstra et al., 2010b;

Bastien et al., 2012b)

能够

执行某些种

类的代数替

换来改进由

纯反向传播

算法提出的

图。

当前向图

G 具有单个输

出节点，并且

每个偏导数

∂u

∂u

(

(

j

i)

) 都可以用恒

定的计算量

来计算时，反

向传播保证

梯度计算的

计算数目和

前向计算的

计算数目是

同一个量级

：

192 第六章

深度

前馈网络

这

可以在算法

6.2 中看出，因为

每个局部偏

导数 ∂u

∂u

(

(

j

i)

) 以及递

归链式公式

（式(6.49) ）

中相关的

乘和加都只

需计算一次

。因此，总的计

算量是 O(#edges)。然而

，可能通过

对

反向传播算

法构建的计

算图进行简

化来减少这

些计算量，并

且这是 NP

完全

问题。

诸如 Theano 和

TensorFlow

的实现使用

基于匹配已

知简化模式

的试探法，以

便重复

地尝

试去简化图

。我们定义反

向传播仅用

于计算标量

输出的梯度

，但是反向传

播可

以扩展

到计算 Jacobian

矩阵

（该 Jacobian 矩阵或者

来源于图中

的 k

个不同标

量节

点，或者

来源于包含

k 个值的张量

值节点）。朴素

的实现可能

需要 k

倍的计

算：对于

原始

前向图中的

每个内部标

量节点，朴素

的实现计算

k 个梯度而不

是单个梯度

。当

图的输出

数目大于输

入的数目时

，有时更偏向

于使用另外

一种形式的

自动微分，称

为

前向模式

累加（forward mode accumulation）。前向模

式计算已经

被提出用于

循

环神经网

络梯度的实

时计算，例如

(Williams

and Zipser, 1989)。这也避免了

存储整

个图

的值和梯度

的需要，是计

算效率和内

存使用的折

中。前向模式

和后向模式

的关

系类似

于左乘和右

乘一系列矩

阵之间的关

系，例如

ABCD, (6.58)

其中

的矩阵可以

认为是

Jacobian 矩阵

。例如，如果 D 是

列向量，而

A 有

很多行，

那么

这对应于一

幅具有单个

输出和多个

输入的图，并

且从最后开

始乘，反向进

行，只

需要矩

阵-向量的乘

积。这对应着

反向模式。相

反，从左边开

始乘将涉及

一系列的矩

阵-矩阵乘积

，这使得总的

计算变得更

加昂贵。然而

，如果

A 的行数

小于 D 的列数

，

则从左到右

乘更为便宜

，这对应着前

向模式。

在机

器学习以外

的许多社区

中，更常见的

是使用传统

的编程语言

来直接实现

微

分软件，例

如用 Python

或者 C 来

编程，并且自

动生成使用

这些语言编

写的不同函

数的程序。在

深度学习界

中，计算图通

常使用由专

用库创建的

明确的数据

结构表示。

专

用方法的缺

点是需要库

开发人员为

每个操作定

义

bprop 方法，并且

限制了库的

用

户仅使用

定义好的那

些操作。然而

，专用方法也

允许定制每

个操作的反

向传播规则

，

允许开发者

以非显而易

见的方式提

高速度或稳

定性，对于这

种方式自动

的过程可能

不能复制。

因

此，反向传播

不是计算梯

度的唯一方

式或最佳方

式，但它是一

个非常实用

的

方法，继续

为深度学习

社区服务。在

未来，深度网

络的微分技

术可能会提

高，因为

深度

学习的从业

者更加懂得

了更广泛的

自动微分领

域的进步。

6.6

历

史小记 193

6.5.10 高阶

微分

一些软

件框架支持

使用高阶导

数。在深度学

习软件框架

中，这至少包

括 Theano

和 TensorFlow。这些库

使用一种数

据结构来描

述要被微分

的原始函数

，它们使用相

同类型的数

据结构来描

述这个函数

的导数表达

式。这意味着

符号微分机

制可以应用

于导数（从而

产生高阶导

数）。

在深度学

习的相关领

域，很少会计

算标量函数

的单个二阶

导数。相反，我

们通

常对 Hessian 矩

阵的性质比

较感兴趣。如

果我们有函

数

f : R

n

→ R，那么 Hessian

矩阵

的大小是

n × n。在

典型的深度

学习应用中

，n 将是模型的

参数数量，可

能很容

易达

到数十亿。因

此，完整的 Hessian 矩

阵甚至不能

表示。

典型的

深度学习方

法是使用

Krylov 方

法（Krylov method），而不是显

式地计

算

Hessian 矩

阵。Krylov 方法是用

于执行各种

操作的一组

迭代技术，这

些操作包括

像近似求解

矩阵的逆、或

者近似矩阵

的特征值或

特征向量等

，而不使用矩

阵-向量乘

法

以外的任何

操作。

为了在

Hesssian 矩阵上使用

Krylov 方法，我们只

需要能够计

算 Hessian

矩阵

H 和一

个任意向量

v 间的乘积即

可。实现这一

目标的一种

直观方法

(Christianson,

1992) 是

Hv =

∇x

[

(∇xf(x))⊤v

]

. (6.59)

该表达式中

两个梯度的

计算都可以

由适当的软

件库自动完

成。注意，外部

梯度表达

式

是内部梯度

表达式的函

数的梯度。

如

果 v 本身是由

计算图产生

的一个向量

，那么重要的

是指定自动

微分软件不

要

对产生

v 的

图进行微分

。

虽然计算 Hessian

通

常是不可取

的，但是可以

使用 Hessian 向量积

。可以对

所有

的

i = 1, .

. . , n

简单地计

算 He(i)，其中 e

(i)

是 e

(

i

i) = 1 并

且其他元素

都为

0

的one-hot向量

。

6.6 历史小记

前

馈网络可以

被视为一种

高效的非线

性函数近似

器，它以使用

梯度下降来

最小

化函数

近似误差为

基础。从这个

角度来看，现

代前馈网络

是一般函数

近似任务的

几

个世纪进

步的结晶。

194

第

六章 深度前

馈网络

处于

反向传播算

法底层的链

式法则是 17

世

纪发明的 (Leibniz, 1676; L’Hôpital,

1696)。微

积分和代数

长期以来被

用于求解优

化问题的封

闭形式，但梯

度下降直到

19

世纪才作为

优化问题的

一种迭代近

似的求解方

法被引入 (Cauchy, 1847)。

从

20 世纪 40 年代开

始，这些函数

近似技术被

用于导出诸

如感知机的

机器学习

模

型。然而，最早

的模型都是

基于线性模

型。来自包括

Marvin Minsky 的批评指出

了线性模型

族的几个缺

陷，例如它无

法学习 XOR

函数

，这导致了对

整个神经网

络方

法的抵

制。

学习非线

性函数需要

多层感知机

的发展和计

算该模型梯

度的方法。基

于动态规

划

的链式法则

的高效应用

开始出现在

20

世纪 60 年代和

70 年代，主要用

于控制领

域

(Kelley, 1960; Bryson and

Denham, 1961; Dreyfus, 1962;

Bryson and Ho, 1969;

Dreyfus, 1973)，也用于灵敏

度分析 (Linnainmaa, 1976)。Werbos

(1981) 提出

应用这

些技

术来训练人

工神经网络

。这个想法以

不同的方式

被独立地重

新发现后 (LeCun,

1985; Parker, 1985; Rumelhart

et al., 1986a)，最

终在实践中

得以发展。 并

行分布式

处

理（Parallel Distributed Processing）一书在其

中一章提供

了第一次成

功使用反向

传播的一些

实验的结果

(Rumelhart et

al., 1986b)，这对反向传

播的普及做

出了巨大

的

贡献，并且开

启了一个研

究多层神经

网络非常活

跃的时期。然

而，该书作者

提出

的想法

，特别是

Rumelhart 和 Hinton 提

出的想法远

远超过了反

向传播。它们

包括一

些关

键思想，关于

可能通过计

算实现认知

和学习的几

个核心方面

，后来被冠以

“ 联

结主义’’ 的

名称，因为它

强调了神经

元之间的连

接作为学习

和记忆的轨

迹的重要性

。

特别地，这些

想法包括分

布式表示的

概念 (Hinton et al.,

1986)。

在反向

传播的成功

之后，神经网

络研究获得

了普及，并在

20 世纪 90

年代初

达

到高峰。随

后，其他机器

学习技术变

得更受欢迎

，直到 2006 年开始

的现代深度

学习

复兴。

现

代前馈网络

的核心思想

自 20 世纪

80 年代

以来没有发

生重大变化

。仍然使用

相

同的反向传

播算法和相

同的梯度下

降方法。1986 年至

2015

年神经网络

性能的大

部

分改进可归

因于两个因

素。首先，较大

的数据集减

少了统计泛

化对神经网

络的挑

战的

程度。第二，神

经网络由于

更强大的计

算机和更好

的软件基础

设施已经变

得更

大。然而

，少量算法上

的变化也显

著改善了神

经网络的性

能。

其中一个

算法上的变

化是用交叉

熵族损失函

数替代均方

误差损失函

数。均方误

差

在 20 世纪

80 年代

和 90 年代流行

，但逐渐被交

叉熵损失替

代，并且最大

似然原

理的

想法在统计

学界和机器

学习界之间

广泛传播。使

用交叉熵损

失大大提高

了具

6.6 历史小

记 195

有 sigmoid 和 softmax

输出

的模型的性

能，而当使用

均方误差损

失时会存在

饱和和

学习

缓慢的问题

。

另一个显著

改善前馈网

络性能的算

法上的主要

变化是使用

分段线性隐

藏单元来

替

代

sigmoid 隐藏单元

，例如用整流

线性单元。使

用 max{0, z}

函数的整

流在早期

神

经网络中已

经被引入，并

且至少可以

追溯到认知

机（Cognitron）和神经认

知机

(Neocognitron)(Fukushima, 1975,

1980)。这些早

期的模型没

有使用整流

线性单元，

而

是将整流用

于非线性函

数。尽管整流

在早期很普

及，在 20 世纪

80 年

代，整流很

大

程度上被 sigmoid

所

取代，也许是

因为当神经

网络非常小

时，sigmoid 表现更好

。

到 21

世纪初，由

于有些迷信

的观念，认为

必须避免具

有不可导点

的激活函数

，所

以避免了

整流线性单

元。这在 2009 年开

始发生改变

。Jarrett

et al. (2009b) 观察到，

在神

经网络结构

设计的几个

不同因素中

‘‘使用整流非

线性是提高

识别系统性

能的最

重要

的唯一因素

’’。

对于小的数

据集，Jarrett et

al. (2009b) 观察到

，使用整流非

线性甚至比

学习隐

藏层

的权重值更

加重要。随机

的权重足以

通过整流网

络传播有用

的信息，允许

在顶

部的分

类器层学习

如何将不同

的特征向量

映射到类标

识。

当有更多

数据可用时

，学习开始提

取足够的有

用知识来超

越随机选择

参数的性

能

。Glorot et

al. (2011a) 说明，在深度

整流网络中

的学习比在

激活函数具

有曲率或

两

侧饱和的深

度网络中的

学习更容易

。

整流线性单

元还具有历

史意义，因为

它们表明神

经科学继续

对深度学习

算法的

发展

产生影响。Glorot et al.

(2011a) 从

生物学考虑

整流线性单

元的导出。半

整流非

线性

旨在描述生

物神经元的

这些性质：(1) 对

于某些输入

，生物神经元

是完全不活

跃的。(2)

对于某

些输入，生物

神经元的输

出和它的输

入成比例。(3) 大

多数时间，

生

物神经元是

在它们不活

跃的状态下

进行操作（即

它们应该具

有 稀疏激活

（sparse

activation））。

当 2006 年深度学

习开始现代

复兴时，前馈

网络仍然有

不良的声誉

。从

2006 年

至 2012

年，人

们普遍认为

，前馈网络不

会表现良好

，除非它们得

到其他模型

的辅助，

例如

概率模型。现

在已经知道

，只要具备适

当的资源和

工程实践，前

馈网络表现

得

非常好。今

天，前馈网络

中基于梯度

的学习被用

作发展概率

模型的工具

，例如第二

十

章中描述的

变分自编码

器和生成式

对抗网络。前

馈网络中基

于梯度的学

习自

2012

年以来

一直被视为

一种强大的

技术，并应用

于许多其他

机器学习任

务，而不是被

视

为必须由

其他技术支

持的不可靠

技术。在 2006

年，业

内使用无监

督学习来支

持监督

196 第六

章 深度前馈

网络

学习，现

在更讽刺的

是，更常见的

是使用监督

学习来支持

无监督学习

。

前馈网络还

有许多未实

现的潜力。未

来，我们期望

它们用于更

多的任务，优

化

算法和模

型设计的进

步将进一步

提高它们的

性能。本章主

要描述了神

经网络模型

族。

在接下来

的章节中，我

们将讨论如

何使用这些

模型——如何对

它们进行正

则化和训

练

。

第七章 深度

学习中的正

则化

机器学

习中的一个

核心问题是

设计不仅在

训练数据上

表现好，并且

能在新输入

上泛化好的

算法。在机器

学习中，许多

策略显式地

被设计来减

少测试误差

（可能会

以增

大训练误差

为代价）。这些

策略被统称

为正则化。我

们将在后文

看到，深度学

习工作者可

以使用许多

不同形式的

正则化策略

。事实上，开发

更有效的正

则化策略

已

成为本领域

的主要研究

工作之一。

第

五章介绍了

泛化、欠拟合

、过拟合、偏差

、方差和正则

化的基本概

念。如果你

不

熟悉这些概

念，请参考该

章节再继续

阅读本章。

在

本章中，我们

会更详细地

介绍正则化

，重点介绍深

度模型（或组

成深度模型

的模块）的正

则化策略。

本

章中的某些

章节涉及机

器学习中的

标准概念。如

果你已经熟

悉了这些概

念，

可以随意

跳过相关章

节。然而，本章

的大多数内

容是关于这

些基本概念

在特定神经

网络中的扩

展概念。

在第

5.2.2

节中，我们将

正则化定义

为 ‘‘对学习算

法的修改——旨

在减少泛化

误

差而不是

训练误差’’。目

前有许多正

则化策略。有

些策略向机

器学习模型

添加限制参

数值的额外

约束。有些策

略向目标函

数增加额外

项来对参数

值进行软约

束。如果我

们

细心选择，这

些额外的约

束和惩罚可

以改善模型

在测试集上

的表现。有时

侯，这些

约束

和惩罚被设

计为编码特

定类型的先

验知识；其他

时候，这些约

束和惩罚被

设计

为偏好

简单模型，以

便提高泛化

能力。有时，惩

罚和约束对

于确定欠定

的问题是必

要的。其他形

式的正则化

，如被称为集

成的方法，则

结合多个假

说来解释训

练数据。

在深

度学习的背

景下，大多数

正则化策略

都会对估计

进行正则化

。估计的正则

化以偏差的

增加换取方

差的减少。一

个有效的正

则化是有利

的 ‘‘交易’’，也就

是能显

著减

少方差而不

过度增加偏

差。我们在第

五章中讨论

泛化和过拟

合时，主要侧

重模

197

198 第七章

深度学习中

的正则化

型

族训练的 3 个

情形：（1）不包括

真实的数据

生成过程——对

应欠拟合和

含有偏

差的

情况，（2）匹配真

实数据生成

过程，（3）除了包

括真实的数

据生成过程

，还包

括许多

其他可能的

生成过程——方

差（而不是偏

差）主导的过

拟合。正则化

的目标

是使

模型从第三

种情况转化

为第二种情

况。

在实践中

，过于复杂的

模型族不一

定包括目标

函数或真实

数据生成过

程，甚至

也不

包括近似过

程。我们几乎

从未知晓真

实数据的生

成过程，所以

我们永远不

知道

被估计

的模型族是

否包括生成

过程。然而，深

度学习算法

的大多数应

用都是针对

这

样的情况

，其中真实数

据的生成过

程几乎肯定

在模型族之

外。深度学习

算法通常应

用于极为复

杂的领域，如

图像、音频序

列和文本，本

质上这些领

域的真实生

成过程

涉及

模拟整个宇

宙。从某种程

度上说，我们

总是持方枘

（数据生成过

程）而欲内圆

凿（我们的模

型族）。

这意味

着控制模型

的复杂度不

是找到合适

规模的模型

（带有正确的

参数个数）

这

样一个简单

的事情。相反

，我们可能会

发现，或者说

在实际的深

度学习场景

中我

们几乎

总是会发现

，最好的拟合

模型（从最小

化泛化误差

的意义上）是

一个适当正

则化的大型

模型。

现在我

们回顾几种

策略，以创建

这些正则化

的大型深度

模型。

7.1

参数范

数惩罚

正则

化在深度学

习的出现前

就已经被使

用了数十年

。线性模型，如

线性回归和

逻

辑回归可

以使用简单

、直接、有效的

正则化策略

。

许多正则化

方法通过对

目标函数

J 添

加一个参数

范数惩罚 Ω(θ)，限

制模型

（如神

经网络、线性

回归或逻辑

回归）的学习

能力。我们将

正则化后的

目标函数记

为

J˜：

J˜(θ; X, y)

= J(θ; X, y)

+ αΩ(θ), (7.1)

其中

α ∈ [0, ∞)

是权

衡范数惩罚

项 Ω 和标准目

标函数 J(X;

θ) 相对

贡献的超参

数。

将 α

设为 0 表

示没有正则

化。α 越大，对应

正则化惩罚

越大。

当我们

的训练算法

最小化正则

化后的目标

函数 J˜ 时，它会

降低原始目

标 J

关于

训练

数据的误差

并同时减小

在某些衡量

标准下参数

θ（或参数子集

）的规模。选择

不同的参数

范数 Ω 会偏好

不同的解。在

本节中，我们

会讨论各种

范数惩罚对

模型的

7.1 参数

范数惩罚 199

影

响。

在探究不

同范数的正

则化表现之

前，我们需要

说明一下，在

神经网络中

，参数包

括每

一层仿射变

换的权重和

偏置，我们通

常只对权重

做惩罚而不

对偏置做正

则惩罚。

精确

拟合偏置所

需的数据通

常比拟合权

重少得多。每

个权重会指

定两个变量

如何相

互作

用。我们需要

在各种条件

下观察这两

个变量才能

良好地拟合

权重。而每个

偏置仅

控制

一个单变量

。这意味着，我

们不对其进

行正则化也

不会导致太

大的方差。另

外，

正则化偏

置参数可能

会导致明显

的欠拟合。因

此，我们使用

向量 w 表示所

有应受范

数

惩罚影响的

权重，而向量

θ 表示所有参

数 (包括 w

和无

需正则化的

参数)。

在神经

网络的情况

下，有时希望

对网络的每

一层使用单

独的惩罚，并

分配不同

的

α 系数。寻找合

适的多个超

参数的代价

很大，因此为

了减少搜索

空间，我们会

在

所有层使

用相同的权

重衰减。

7.1.1 L

2

参数

正则化

在第

5.2 节中我们已

经看到过最

简单而又最

常见的参数

范数惩罚，即

通常被称

为

权重衰减（weight

decay）的

L

2 参数范数惩

罚。这个正则

化策略通过

向目标函

数

添加一个正

则项

Ω(θ) = 1

2

∥w∥

2

2，使权重

更加接近原

点1。在其他学

术圈，L

2

也被

称

为岭回归或

Tikhonov 正则。

我们可

以通过研究

正则化后目

标函数的梯

度，洞察一些

权重衰减的

正则化表现

。

为了简单起

见，我们假定

其中没有偏

置参数，因此

θ 就是 w。这样一

个模型具有

以

下总的目

标函数：

J˜(w; X, y) =

α

2

w

⊤w

+ J(w; X, y),

(7.2)

与之

对应的梯度

为

∇w

˜J(w;

X, y) = αw

+ ∇wJ(w; X, y).

(7.3)

使用单步

梯度下降更

新权重，即执

行以下更新

：

w ←

w − ϵ(αw +

∇wJ(w; X, y)). (7.4)

1更一般地，我

们可以将参

数正则化为

接近空间中

的任意特定

点，令人惊讶

的是这样也

仍有正则化

效果，但是特

定

点越接近

真实值结果

越好。当我们

不知道正确

的值应该是

正还是负时

，零是有意义

的默认值。由

于模型参数

正则化为

零

的情况更为

常见，我们将

只探讨这种

特殊情况。

200

第

七章 深度学

习中的正则

化

换种写法

就是：

w

← (1 − ϵα)w

− ϵ∇wJ(w; X, y).

(7.5)

我们可

以看到，加入

权重衰减后

会引起学习

规则的修改

，即在每步执

行通常的梯

度更

新之前

先收缩权重

向量（将权重

向量乘以一

个常数因子

）。这是单个步

骤发生的变

化。但是，在训

练的整个过

程会发生什

么呢？

我们进

一步简化分

析，令

w∗ 为未正

则化的目标

函数取得最

小训练误差

时的权

重向

量，即 w∗

= arg minw J(w)，并在

w∗ 的

邻域对目标

函数做二次

近似。如果目

标函数确实

是二次的 (如

以均方误差

拟合线性回

归模型的情

况)，则该近似

是完美的。

近

似的

Jˆ(θ) 如下

Jˆ(θ) =

J(w

∗

) +

1

2

(w −

w

∗

)

⊤H(w

− w

∗

),

(7.6)

其

中 H 是

J 在 w∗ 处计

算的

Hessian 矩阵 (关

于 w)。因为

w∗ 被定

义为最优，即

梯

度消失为

0，所以该二次

近似中没有

一阶项。同样

地，因为 w∗

是 J 的

一个最优点

，

我们可以得

出

H 是半正定

的结论。

当 Jˆ

取

得最小时，其

梯度

∇wJˆ(w) = H(w

− w

∗

)

(7.7)

为 0。

为了

研究权重衰

减带来的影

响，我们在式

(7.7)

中添加权重

衰减的梯度

。现在我

们探

讨最小化正

则化后的 Jˆ。我

们使用变量

w˜ 表示此时的

最优点:

αw˜ + H(w˜ −

w

∗

) =

0 (7.8)

(H +

αI)w˜ = Hw∗

(7.9)

w˜ = (H +

αI)

−1Hw∗

(7.10)

当

α 趋

向于 0 时，正则

化的解

w˜ 会趋

向 w∗。那么当 α

增

加时会发生

什么呢？

因为

H 是实对称的

，所以我们可

以将其分解

为一个对角

矩阵 Λ

和一组

特征向量的

标准正交基

Q，并且有 H = QΛQ

⊤。将其

应用于式 (7.10) ，可

得：

w˜

= (QΛQ

⊤ +

αI)

−1QΛQ

⊤

w

∗

(7.11)

= [Q(Λ

+ αI)Q

⊤

]

−1QΛQ

⊤

w

∗

(7.12)

= Q(Λ +

αI)

−1ΛQ

⊤

w

∗

. (7.13)

7.1

参数范数

惩罚 201

我们可

以看到权重

衰减的效果

是沿着由 H

的

特征向量所

定义的轴缩

放 w∗。具体来

说

，我们会根据

λ

λi

i+α 因子缩放与

H 第 i

个特征向

量对齐的 w∗ 的

分量。（不妨查

看图 2.3

回顾这

种缩放的原

理）。

沿着 H 特征

值较大的方

向

(如 λi ≫ α)正则化

的影响较小

。而

λi ≪ α 的分量将

会收缩到几

乎为零。这种

效应如图

7.1 所

示。

w1

w∗

w˜

图 7.1: L

2（或权重

衰减）正则化

对最佳 w 值的

影响。实线椭

圆表示没有

正则化目标

的等值线。虚

线圆圈表示

L

2

正则化项的

等值线。在 w˜ 点

，这两个竞争

目标达到平

衡。目标函数

J 的

Hessian 的

第一维

特征值很小

。当从 w

∗ 水平移

动时，目标函

数不会增加

得太多。因为

目标函数对

这个方向没

有强烈的偏

好，所以正则

化项对该轴

具有强烈的

影响。正则化

项将 w1 拉向零

。而目标函数

对沿着

第二

维远离 w

∗ 的移

动非常敏感

。对应的特征

值较大，表示

高曲率。因此

，权重衰减对

w2

的位置

影响

相对较小。

只

有在显著减

小目标函数

方向上的参

数会保留得

相对完好。在

无助于目标

函

数减小的

方向（对应

Hessian 矩

阵较小的特

征值）上改变

参数不会显

著增加梯度

。这

种不重要

方向对应的

分量会在训

练过程中因

正则化而衰

减掉。

目前为

止，我们讨论

了权重衰减

对优化一个

抽象通用的

二次代价函

数的影响。

这

些影响具体

是怎么和机

器学习关联

的呢？我们可

以研究线性

回归，它的真

实代价

函数

是二次的，因

此我们可以

使用相同的

方法分析。再

次应用分析

，我们会在这

种

情况下得

到相同的结

果，但这次我

们使用训练

数据的术语

表述。线性回

归的代价函

数是平方误

差之和：

(Xw

− y)

⊤(Xw −

y). (7.14)

w2

202

第七

章 深度学习

中的正则化

我们添加 L

2

正

则项后，目标

函数变为

(Xw − y)

⊤(Xw − y) +

1

2

αw

⊤w.

(7.15)

这

将普通方程

的解从

w =

(X

⊤X)

−1X

⊤

y (7.16)

变为

w =

(X

⊤X + αI)

−1X

⊤

y. (7.17)

式 (7.16) 中的矩阵

X

⊤X

与协方差矩

阵 m

1 X

⊤X 成正比。L

2 正

则项将这个

矩阵替换

为

式 (7.17) 中的 (X

⊤X + αI)

−1

这个

新矩阵与原

来的是一样

的，不同的仅

仅是在对

角

加了 α。这个矩

阵的对角项

对应每个输

入特征的方

差。我们可以

看到，L

2正则化

能

让学习算

法 ‘‘感知’’ 到具

有较高方差

的输入 x，因此

与输出目标

的协方差较

小（相对

增加

方差）的特征

的权重将会

收缩。

7.1.2 L

1

参数正

则化

L

2权重衰

减是权重衰

减最常见的

形式，我们还

可以使用其

他的方法限

制模型参

数

的规模。一个

选择是使用

L

1正则化。

形式

地，对模型参

数 w 的

L

1正则化

被定义为：

Ω(θ) =

∥w∥1 =

∑

i

|wi

|, (7.18)

即

各个参数的

绝对值之和

2。接着我们将

讨论

L

1正则化

对简单线性

回归模型的

影响，

与分析

L

2正则化时一

样不考虑偏

置参数。我们

尤其感兴趣

的是找出

L

1 和

L

2正则

化之间

的差异。与 L

2权

重衰减类似

，我们也可以

通过缩放惩

罚项 Ω

的正超

参数 α

来控制

L

1权重衰减的

强度。因此，正

则化的目标

函数

J˜(w; X, y) 如下所

示

˜J(w; X, y) =

α∥w∥1 + J(w; X,

y), (7.19)

对应的梯

度 (实际上是

次梯度)：

∇w

˜J(w; X, y)

= αsign(w) + ∇wJ(w;

X, y), (7.20)

2如同

L

2正则化，我们

能将参数正

则化到其他

非零值 w

(o)。在这

种情况下，L

1正

则化将会引

入不同的项

Ω(θ)

= ∥w − w

(o)∥1 =

∑

i

|wi − wi

(o)

|。

7.1 参数范数惩

罚 203

其中 sign(w) 只是

简单地取 w

各

个元素的正

负号。

观察式

(7.20) ，我们立刻发

现 L

1 的正则化

效果与 L

2

大不

一样。具体来

说，我

们可以

看到正则化

对梯度的影

响不再是线

性地缩放每

个 wi；而是添加

了一项与

sign(wi)

同

号的常数。使

用这种形式

的梯度之后

，我们不一定

能得到 J(X, y; w)

二

次

近似的直接

算术解（L

2正则

化时可以）。

简

单线性模型

具有二次代

价函数，我们

可以通过泰

勒级数表示

。或者我们可

以

设想，这是

逼近更复杂

模型的代价

函数的截断

泰勒级数。在

这个设定下

，梯度由下

式

给出

∇wJˆ(w) =

H(w − w

∗

), (7.21)

同样，H 是

J

在 w∗ 处的Hessian矩阵

(关于 w)。

由于 L

1 惩

罚项在完全

一般化的

Hessian 的

情况下，无法

得到直接清

晰的代数表

达式，因此我

们将进一步

简化假设 Hessian 是

对角的，即

H = diag([H1,1, .

. . , Hn,n])，

其

中每个 Hi,i > 0。如果

线性回归问

题中的数据

已被预处理

（如可以使用

PCA），去

除了输入

特征之间的

相关性，那么

这一假设成

立。

我们可以

将 L

1正则化目

标函数的二

次近似分解

成关于参数

的求和：

Jˆ(w; X, y) =

J(w

∗

; X,

y) +∑

i

[

2

1

Hi,i(wi −

wi

∗

)

2

+ α|wi

|

]

. (7.22)

如下

列形式的解

析解（对每一

维 i）可以最小

化这个近似

代价函数：

wi = sign(wi

∗

) max {

|wi

∗

| −

H

α

i,i

, 0

}

. (7.23)

对

每个

i, 考虑 wi

∗

> 0 的

情形，会有两

种可能结果

：

1.

wi

∗ ≤

α

Hi,i 的情况。正则

化后目标中

的 wi 最优值是

wi

= 0。这是因为在

方向 i

上

J(w; X, y) 对

Jˆ(w; X, y) 的

贡献被抵消

，L

1正则化项将

wi 推至 0。

2.

wi

∗ > H

α

i,i 的情况

。在这种情况

下，正则化不

会将 wi

的最优

值推至 0，而仅

仅

在那个方

向上移动 H

α

i,i 的

距离。

wi

∗ < 0 的情况

与之类似，但

是

L

1 惩罚项使

wi 更接近

0(增加

H

α

i,i

)

或者为 0。

相比

L

2正则化，L

1正则

化会产生更

稀疏（sparse）的解。此

处稀疏性指

的是

最优值

中的一些参

数为 0。和 L

2正则

化相比，L

1正则

化的稀疏性

具有本质的

不同。

204 第七章

深度学习中

的正则化

式

(7.13) 给出了 L

2正则

化的解

w˜。如果

我们使用 Hessian 矩

阵 H

为对角正

定矩阵

的假

设（与 L

1正则化

分析时一样

），重新考虑这

个等式，我们

发现

w˜i = H

Hi,i

i,i+α wi

∗。

如果

wi

∗ 不

是零，那么 w˜i

也

会保持非零

。这表明 L

2正则

化不会使参

数变得稀疏

，而

L

1正则化有

可能通过足

够大的 α 实现

稀疏。

由

L

1正则

化导出的稀

疏性质已经

被广泛地用

于 特征选择

（feature selection）机

制。特征选

择从可用的

特征子集选

择出有意义

的特征，化简

机器学习问

题。著名的

LASSO (Tibshirani, 1995)（Least

Absolute Shrinkage and Selection

Operator）模

型将 L

1 惩罚和

线性模型结

合，并使用最

小二乘代价

函数。L

1 惩罚使

部分子集的

权

重为零，表

明相应的特

征可以被安

全地忽略。

在

第

5.6.1 节，我们看

到许多正则

化策略可以

被解释为 MAP 贝

叶斯推断，特

别

是 L

2正则化

相当于权重

是高斯先验

的 MAP

贝叶斯推

断。对于 L

1正则

化，用于正则

化代价函数

的惩罚项 αΩ(w)

= α

∑

i

|wi

| 与

通过 MAP

贝叶斯

推断最大化

的对数先

验

项是等价的

（w ∈ R

n 并且权重先

验是各向同

性的拉普拉

斯分布（式 (3.26) ））：

log p(w) = ∑

i

log Laplace(wi

;

0,

α

1

)

= −α ∥w∥1 +

n log α −

n log 2. (7.24)

因

为是关于 w 最

大化进行学

习，我们可以

忽略 log

α − log 2

项，因为

它们与 w 无关

。

7.2

作为约束的

范数惩罚

考

虑经过参数

范数正则化

的代价函数

：

J˜(θ; X,

y) = J(θ; X,

y) + αΩ(θ). (7.25)

回顾第 4.4 节我

们可以构造

一个广义 Lagrange

函

数来最小化

带约束的函

数，即

在原始

目标函数上

添加一系列

惩罚项。每个

惩罚是一个

被称为 Karush–Kuhn–

Tucker（Karush–Kuhn–Tucker）乘子

的系数以及

一个表示约

束是否满足

的函数之

间

的乘积。如果

我们想约束

Ω(θ) 小于某个常

数 k，我们可以

构建广义 Lagrange

函

数

L(θ, α; X,

y) = J(θ; X,

y) + α(Ω(θ) −

k). (7.26)

这个约束

问题的解由

下式给出

θ

∗ = arg min

θ

max

α,α≥0

L(θ,

α). (7.27)

7.2 作

为约束的范

数惩罚

205

如第

4.4 节中描述的

，解决这个问

题我们需要

对 θ

和 α 都做出

调整。第4.5 节给

出了一个带

L

2 约束的线性

回归实例。还

有许多不同

的优化方法

，有些可能会

使用梯

度下

降而其他可

能会使用梯

度为 0

的解析

解，但在所有

过程中 α 在 Ω(θ)

> k 时

必

须增加，在

Ω(θ)

< k 时必须减小

。所有正值的

α 都鼓励

Ω(θ) 收缩

。最优值 α

∗

也

将

鼓励 Ω(θ) 收缩，但

不会强到使

得

Ω(θ) 小于 k。

为了

洞察约束的

影响，我们可

以固定

α

∗，把这

个问题看成

只跟 θ 有关的

函数：

θ

∗ = arg

min

θ

L(θ, α∗

) = arg min

θ

J(θ; X, y)

+ α

∗Ω(θ). (7.28)

这和最

小化 J˜ 的正则

化训练问题

是完全一样

的。因此，我们

可以把参数

范数惩罚看

作对权重强

加的约束。如

果 Ω

是 L

2 范数，那

么权重就是

被约束在一

个

L

2 球中。如

果

Ω

是 L

1 范数，那么

权重就是被

约束在一个

L

1 范数限制的

区域中。通常

我们不

知道

权重衰减系

数 α

∗ 约束的区

域大小，因为

α

∗ 的值不直接

告诉我们

k 的

值。原则

上我

们可以解得

k，但 k

和 α

∗ 之间的

关系取决于

J

的形式。虽然

我们不知道

约束

区域的

确切大小，但

我们可以通

过增加或者

减小 α 来大致

扩大或收缩

约束区域。较

大的

α，将得到

一个较小的

约束区域。较

小的 α，将得到

一个较大的

约束区域。

有

时候，我们希

望使用显式

的限制，而不

是惩罚。如第

4.4 节所述，我们

可以修

改下

降算法（如随

机梯度下降

算法），使其先

计算 J(θ) 的下降

步，然后将 θ

投

影到

满足 Ω(θ) <

k 的

最近点。如果

我们知道什

么样的 k 是合

适的，而不想

花时间寻找

对

应于此 k 处

的 α

值，这会非

常有用。

另一

个使用显式

约束和重投

影而不是使

用惩罚强加

约束的原因

是惩罚可能

会导

致目标

函数非凸而

使算法陷入

局部极小 (对

应于小的

θ）。当

训练神经网

络时，这通

常

表现为训练

带有几个 ‘‘死

亡单元’’ 的神

经网络。这些

单元不会对

网络学到的

函数

有太大

影响，因为进

入或离开它

们的权重都

非常小。当使

用权重范数

的惩罚训练

时，

即使可以

通过增加权

重以显著减

少 J，这些配置

也可能是局

部最优的。因

为重投影

实

现的显式约

束不鼓励权

重接近原点

，所以在这些

情况下效果

更好。通过重

投影实

现的

显式约束只

在权重变大

并试图离开

限制区域时

产生作用。

最

后，因为重投

影的显式约

束还对优化

过程增加了

一定的稳定

性，所以这是

另

一个好处

。当使用较高

的学习率时

，很可能进入

正反馈，即大

的权重诱导

大梯度，然

后

使得权重获

得较大更新

。如果这些更

新持续增加

权重的大小

，θ

就会迅速增

大，直

到离原

点很远而发

生溢出。重投

影的显式约

束可以防止

这种反馈环

引起权重无

限制

地持续

增加。Hinton et

al. (2012c) 建议结

合使用约束

和高学习速

率，这样能更

快地

探索参

数空间，并保

持一定的稳

定性。

206 第七章

深度学习中

的正则化

Hinton et

al. (2012c) 尤

其推荐由Srebro and

Shraibman (2005) 引

入的策略：约

束神经网络

层的权重矩

阵每列的范

数，而不是限

制整个权重

矩阵的 Frobenius

范数

。

分别限制每

一列的范数

可以防止某

一隐藏单元

有非常大的

权重。如果我

们将此约束

转换成 Lagrange 函数

中的一个惩

罚，这将与

L

2 权

重衰减类似

但每个隐藏

单元的权

重

都具有单独

的

KKT 乘子。每个

KKT 乘子分别会

被动态更新

，以使每个隐

藏单

元服从

约束。在实践

中，列范数的

限制总是通

过重投影的

显式约束来

实现。

7.3 正则化

和欠约束问

题

在某些情

况下，为了正

确定义机器

学习问题，正

则化是必要

的。机器学习

中许

多线性

模型，包括线

性回归和

PCA，都

依赖于对矩

阵 X

⊤X 求逆。只要

X

⊤X 是奇

异的，这

些方法就会

失效。当数据

生成分布在

一些方向上

确实没有差

异时，或因为

例子较少（即

相对输入特

征的维数来

说）而在一些

方向上没有

观察到方差

时，这个

矩阵

就是奇异的

。在这种情况

下，正则化的

许多形式对

应求逆

X

⊤X + αI。这个

正则

化矩阵

可以保证是

可逆的。

相关

矩阵可逆时

，这些线性问

题有闭式解

。没有闭式解

的问题也可

能是欠定的

。

一个例子是

应用于线性

可分问题的

逻辑回归。如

果权重向量

w 能够实现完

美分类，

那么

2w 也会以更高

似然实现完

美分类。类似

随机梯度下

降的迭代优

化算法将持

续

增加 w

的大

小，理论上永

远不会停止

。在实践中，数

值实现的梯

度下降最终

会达到

导致

数值溢出的

超大权重，此

时的行为将

取决于程序

员如何处理

这些不是真

正数字

的值

。

大多数形式

的正则化能

够保证应用

于欠定问题

的迭代方法

收敛。例如，当

似然

的斜率

等于权重衰

减的系数时

，权重衰减将

阻止梯度下

降继续增加

权重的大小

。

使用正则化

解决欠定问

题的想法不

局限于机器

学习。同样的

想法在几个

基本线

性代

数问题中也

非常有用。

正

如我们在第

2.9

节看到的，我

们可以使用

Moore-Penrose 求解欠定线

性方程。

回想

X 伪逆

X

+ 的一个

定义：

X

+ = lim

α↘0

(X

⊤X + αI)

−1X

⊤

. (7.29)

现在我

们可以将第

7.29 节看作进行

具有权重衰

减的线性回

归。具体来说

，当正则化系

数趋向 0 时，式

(7.29)

是式 (7.17) 的极限

。因此，我们可

以将伪逆解

释为使用正

则

7.4

数据集增

强 207

化来稳定

欠定问题。

7.4

数

据集增强

让

机器学习模

型泛化得更

好的最好办

法是使用更

多的数据进

行训练。当然

，在

实践中，我

们拥有的数

据量是很有

限的。解决这

个问题的一

种方法是创

建假数据并

添加到训练

集中。对于一

些机器学习

任务，创建新

的假数据相

当简单。

对分

类来说这种

方法是最简

单的。分类器

需要一个复

杂的高维输

入

x，并用单

个

类别标识 y 概

括

x。这意味着

分类面临的

一个主要任

务是要对各

种各样的变

换保

持不变

。我们可以轻

易通过转换

训练集中的

x 来生成新的

(x, y)

对。

这种方法

对于其他许

多任务来说

并不那么容

易。例如，除非

我们已经解

决了密

度估

计问题，否则

在密度估计

任务中生成

新的假数据

是很困难的

。

数据集增强

对一个具体

的分类问题

来说是特别

有效的方法

：对象识别。图

像是

高维的

并包括各种

巨大的变化

因素，其中有

许多可以轻

易地模拟。即

使模型已使

用

卷积和池

化技术（第九

章）对部分平

移保持不变

，沿训练图像

每个方向平

移几个像

素

的操作通常

可以大大改

善泛化。许多

其他操作如

旋转图像或

缩放图像也

已被证明

非

常有效。

我们

必须要小心

，不能使用会

改变类别的

转换。例如，光

学字符识别

任务需要

认

识到 “b’’ 和

“d’’ 以及

“6’’ 和 “9’’

的区别，所

以对这些任

务来说，水平

翻转和旋转

180◦ 并不是合适

的数据集增

强方式。

能保

持我们希望

的分类不变

，但不容易执

行的转换也

是存在的。例

如，平面外

绕

轴转动难以

通过简单的

几何运算在

输入像素上

实现。

数据集

增强对语音

识别任务也

是有效的 (Jaitly and Hinton,

2013)。

在

神经网络的

输入层注入

噪声 (Sietsma and

Dow, 1991) 也可以

被看作是数

据增

强的一

种方式。对于

许多分类甚

至一些回归

任务而言，即

使小的随机

噪声被加到

输

入，任务仍

应该是能够

被解决的。然

而，神经网络

被证明对噪

声不是非常

健壮 (Tang

and Eliasmith,

2010)。改善神

经网络健壮

性的方法之

一是简单地

将随机噪声

添加到

输入

再进行训练

。输入噪声注

入是一些无

监督学习算

法的一部分

，如去噪自编

码

器(Vincent et

al., 2008a)。向隐藏

单元施加噪

声也是可行

的，这可以被

看作在多个

抽

象层上进

行的数据集

增强。Poole et

al. (2014) 最近表

明，噪声的幅

度被细心调

整后，

208

第七章

深度学习中

的正则化

该

方法是非常

高效的。我们

将在第 7.12 节介

绍一个强大

的正则化策

略

Dropout，该

策略可

以被看作是

通过与噪声

相乘构建新

输入的过程

。

在比较机器

学习基准测

试的结果时

，考虑其采取

的数据集增

强是很重要

的。通

常情况

下，人工设计

的数据集增

强方案可以

大大减少机

器学习技术

的泛化误差

。将

一个机器

学习算法的

性能与另一

个进行对比

时，对照实验

是必要的。在

比较机器学

习算法 A 和机

器学习算法

B 时，应该确保

这两个算法

使用同一人

工设计的数

据集增

强方

案。假设算法

A 在没有数据

集增强时表

现不佳，而 B 结

合大量人工

转换的数

据

后表现良好

。在这样的情

况下，很可能

是合成转化

引起了性能

改进，而不是

机器

学习算

法 B 比算法

A 更

好。有时候，确

定实验是否

已经适当控

制需要主观

判断。例

如，向

输入注入噪

声的机器学

习算法是执

行数据集增

强的一种形

式。通常，普适

操

作（例如，向

输入添加高

斯噪声）被认

为是机器学

习算法的一

部分，而特定

于一个

应用

领域（如随机

地裁剪图像

）的操作被认

为是独立的

预处理步骤

。

7.5 噪声鲁棒性

第 7.4

节已经提

出将噪声作

用于输入，作

为数据集增

强策略。对于

某些模型而

言，

向输入添

加方差极小

的噪声等价

于对权重施

加范数惩罚

(Bishop, 1995a,b)。在一般情

况

下，注入噪声

远比简单地

收缩参数强

大，特别是噪

声被添加到

隐藏单元时

会更加强

大

。向隐藏单元

添加噪声是

值得单独讨

论重要的话

题；在第 7.12 节所

述 Dropout

算

法是这

种做法的主

要发展方向

。

另一种正则

化模型的噪

声使用方式

是将其加到

权重。这项技

术主要用于

循环神

经网

络

(Jim et al., 1996;

Graves, 2011)。这可以被

解释为关于

权重的贝叶

斯推断的

随

机实现。贝叶

斯学习过程

将权重视为

不确定的，并

且可以通过

概率分布表

示这种

不确

定性。向权重

添加噪声是

反映这种不

确定性的一

种实用的随

机方法。

在某

些假设下，施

加于权重的

噪声可以被

解释为与更

传统的正则

化形式等同

，

鼓励要学习

的函数保持

稳定。我们研

究回归的情

形，也就是训

练将一组特

征 x 映射

成一

个标量的函

数 yˆ(x)，并使用最

小二乘代价

函数衡量模

型预测值 yˆ(x) 与

真实值

y

的误

差：

J =

Ep(x,y)

[(ˆy(x) − y)

2

]. (7.30)

训练集包

含

m 对标注样

例 {(x

(1),

y(1)), . . .

,(x

(m)

, y(m)

)}。

7.6 半监督学

习 209

现在我们

假设对每个

输入表示，网

络权重添加

随机扰动 ϵw ∼ N

(ϵ; 0, ηI )。想

象

我们有一

个标准的 l 层

MLP。我们将扰动

模型记为 yˆϵW

(x)。尽

管有噪声注

入，我们

仍然

希望减少网

络输出误差

的平方。因此

目标函数变

为：

˜JW =

Ep(x,y,ϵW)

[(ˆyϵW (x) −

y)

2

] (7.31)

= Ep(x,y,ϵW)

[ˆyϵ

2

W

(x) − 2yyˆϵW

(x) + y

2

]. (7.32)

对于小的

η，最小化带权

重噪声（方差

为 ηI

）的 J 等同于

最小化附加

正则化项：

ηEp(x,y)

[∥∇W yˆ(x)∥

2

]

的

J。这种形式的

正则化鼓励

参数进入权

重小扰动对

输出相对

影

响较小的参

数空间区域

。换句话说，它

推动模型进

入对权重小

的变化相对

不敏感

的区

域，找到的点

不只是极小

点，还是由平

坦区域所包

围的极小点

(Hochreiter and

Schmidhuber, 1995)。在简化的线

性回归中（例

如，yˆ(x) = w⊤x

+ b），正则项退

化为

ηEp(x)

[∥x∥

2

]，这与函

数的参数无

关，因此不会

对 J˜

w

关于模型

参数的梯度

有影响。

7.5.1 向输

出目标注入

噪声

大多数

数据集的

y 标

签都有一定

错误。错误的

y 不利于最大

化 log

p(y | x)。避

免这种

情况的一种

方法是显式

地对标签上

的噪声进行

建模。例如，我

们可以假设

，对

于一些小

常数 ϵ，训练集

标记 y 是正确

的概率是

1 − ϵ，（以

ϵ 的概率）任何

其他可能

的

标签也可能

是正确的。这

个假设很容

易就能解析

地与代价函

数结合，而不

用显式

地抽

取噪声样本

。例如，标签平

滑（label smoothing）通过把确

切分类目标

从 0

和

1 替换成

k

ϵ

−1 和 1 −

ϵ，正则化具

有 k 个输出的

softmax 函数

的模型

。标准交叉熵

损失可以用

在这些非确

切目标的输

出上。使用 softmax 函

数 和明确目

标的最大似

然

学习可能

永远不会收

敛——softmax 函数 永远

无法真正预

测 0

概率或 1 概

率，因此

它会

继续学习越

来越大的权

重，使预测更

极端。使用如

权重衰减等

其他正则化

策略

能够防

止这种情况

。标签平滑的

优势是能够

防止模型追

求确切概率

而不影响模

型学

习正确

分类。这种策

略自 20 世纪

80 年

代就已经被

使用，并在现

代神经网络

继续保

持显

著特色 (Szegedy

et al., 2015)。

7.6

半监

督学习

在半

监督学习的

框架下，P(x) 产生

的未标记样

本和 P(x,

y) 中的标

记样本都用

于估计 P(y |

x) 或者

根据 x 预测

y。

210 第

七章 深度学

习中的正则

化

在深度学

习的背景下

，半监督学习

通常指的是

学习一个表

示 h = f(x)。学习表

示

的目的是使

相同类中的

样本有类似

的表示。无监

督学习可以

为如何在表

示空间聚

集

样本提供有

用线索。在输

入空间紧密

聚集的样本

应该被映射

到类似的表

示。在许

多情

况下，新空间

上的线性分

类器可以达

到较好的泛

化 (Belkin

and Niyogi, 2002;

Chapelle

et al., 2003)。这种方法

的一个经典

变种是使用

主成分分析

作为分类前

（在

投影后的

数据上分类

）的预处理步

骤。

我们可以

构建这样一

个模型，其中

生成模型 P(x) 或

P(x, y)

与判别模型

P(y | x)

共享参数，而

不用分离无

监督和监督

部分。我们权

衡监督模型

准则

− log P(y |

x)

和无监

督或生成模

型准则（如 − log

P(x) 或

− log P(x,

y)）。生成模型准

则表达了

对

监督学习问

题解的特殊

形式的先验

知识 (Lasserre et

al., 2006)，即 P(x) 的结

构通

过某种

共享参数的

方式连接到

P(y | x)。通过控制在

总准则中的

生成准则，我

们可

以获得

比纯生成或

纯判别训练

准则更好的

权衡

(Lasserre et al., 2006;

Larochelle and

Bengio, 2008a)。

Salakhutdinov and Hinton (2008)

描述了

一种学习回

归核机器中

核函数的方

法，

其中建模

P(x) 时使用的未

标记样本大

大提高了 P(y

| x) 的

效果。

更多半

监督学习的

信息，请参阅

Chapelle

et al. (2006)。

7.7

多任务学习

多任务学习

(Caruana, 1993) 是通过合并

几个任务中

的样例（可以

视为对参数

施加的软约

束）来提高泛

化的一种方

式。正如额外

的训练样本

能够将模型

参数推向

具

有更好泛化

能力的值一

样，当模型的

一部分被多

个额外的任

务共享时，这

部分将

被约

束为良好的

值（如果共享

合理），通常会

带来更好的

泛化能力。

图

7.2 展示了多任

务学习中非

常普遍的一

种形式，其中

不同的监督

任务（给定 x

预

测 y

(i)）共享相同

的输入 x

以及

一些中间层

表示 h

(share)，能学习

共同的因素

池。

该模型通

常可以分为

两类相关的

参数：

1. 具体任

务的参数（只

能从各自任

务的样本中

实现良好的

泛化）。如图 7.2 中

的上

层。

2. 所有

任务共享的

通用参数（从

所有任务的

汇集数据中

获益）。如图7.2 中

的下层。

因为

共享参数，其

统计强度可

大大提高（共

享参数的样

本数量相对

于单任务模

7.8 提前终止 211

hh(1)

(1) hh(2) (2) hh(3)

(3)

yy(1) (1) yy(2)

(2)

hh(shared) (shared)

x

图

7.2: 多任务学习

在深度学习

框架中可以

以多种方式

进行，该图说

明了任务共

享相同输入

但涉及

不同

目标随机变

量的常见情

况。深度网络

的较低层（无

论是监督前

馈的，还是包

括向下箭头

的生

成组件

）可以跨这样

的任务共享

，而任务特定

的参数（分别

与从

h

(1) 和 h

(2) 进入

和发出的权

重）

可以在共

享表示 h

(shared) 之上

学习。这里的

基本假设是

存在解释输

入 x 变化的共

同因素池，而

每

个任务与

这些因素的

子集相关联

。在该示例中

，额外假设顶

层隐藏单元

h

(1) 和 h

(2) 专用于每

个任

务（分别

预测 y

(1) 和 y

(2)），而一

些中间层表

示

h

(shared) 在所有任

务之间共享

。在无监督学

习情

况下，一

些顶层因素

不与输出任

务

(h

(3)) 的任意一

个关联是有

意义的：这些

因素可以解

释一些输

入

变化但与预

测

y

(1) 或 y

(2) 不相关

。

式增加的比

例），并能改善

泛化和泛化

误差的范围

(Baxter, 1995)。当然，仅当不

同

的任务之

间存在某些

统计关系的

假设是合理

（意味着某些

参数能通过

不同任务共

享）

时才会发

生这种情况

。

从深度学习

的观点看，底

层的先验知

识如下：能解

释数据变化

（在与之相关

联

的不同任

务中观察到

）的因素中，某

些因素是跨

两个或更多

任务共享的

。

7.8 提前终止

当

训练有足够

的表示能力

甚至会过拟

合的大模型

时，我们经常

观察到，训练

误

差会随着

时间的推移

逐渐降低但

验证集的误

差会再次上

升。图

7.3 是这些

现象的一个

例子，这种现

象几乎一定

会出现。

这意

味着我们只

要返回使验

证集误差最

低的参数设

置，就可以获

得验证集误

差

更低的模

型（并且因此

有希望获得

更好的测试

误差）。在每次

验证集误差

有所改善

212 第

七章 深度学

习中的正则

化

后，我们存

储模型参数

的副本。当训

练算法终止

时，我们返回

这些参数而

不是最新

的

参数。当验证

集上的误差

在事先指定

的循环次数

内没有进一

步改善时，算

法就会

终止

。此过程在算

法 7.1 中有更正

式的说明。

这

种策略被称

为 提前终止

（early stopping）。这可能是深

度学习中最

常用的正

则

化形式。它的

流行主要是

因为有效性

和简单性。

算

法 7.1 用于确定

最佳训练时

间量的提前

终止元算法

。这种元算法

是一种通用

策略，

可以很

好地在各种

训练算法和

各种量化验

证集误差的

方法上工作

。

令 n 为评估间

隔的步数。

令

p

为 ‘‘耐心 (patience)’’，即观

察到较坏的

验证集表现

p 次后终止。

令

θo 为初始参数

。

θ ←

θo

i ← 0

j ← 0

v

← ∞

θ

∗

← θ

i

∗

← i

while j

< p do

运行训练算

法

n 步，更新 θ 。

i ← i +

n

v

′ ←

ValidationSetError(θ)

if v

′

< v then

j

← 0

θ

∗

← θ

i

∗

← i

v ←

v

′

else

j

← j + 1

end if

end while

最

佳参数为 θ

∗，最

佳训练步数

为 i

∗

我们可以

认为提前终

止是非常高

效的超参数

选择算法。按

照这种观点

，训练步

7.8 提前

终止

213

数仅是

另一个超参

数。我们从图

7.3 可以看到，这

个超参数在

验证集上具

有 U

型性能

曲

线。很多控制

模型容量的

超参数在验

证集上都是

这样的 U 型性

能曲线，如图

5.3

。

在提前终止

的情况下，我

们通过控制

拟合训练集

的步数来控

制模型的有

效容量。大

多

数超参数的

选择必须使

用高代价的

猜测和检查

过程，我们需

要在训练开

始时猜测

一

个超参数，然

后运行几个

步骤检查它

的训练效果

。‘‘训练时间’’

是

唯一只要跑

一次

训练就

能尝试很多

值的超参数

。通过提前终

止自动选择

超参数的唯

一显著的代

价是

训练期

间要定期评

估验证集。在

理想情况下

，这可以并行

在与主训练

过程分离的

机

器上，或独

立的

CPU，或独立

的 GPU 上完成。如

果没有这些

额外的资源

，可以使

用比

训练集小的

验证集或较

不频繁地评

估验证集来

减小评估代

价，较粗略地

估算取

得最

佳的训练时

间。

另一个提

前终止的额

外代价是需

要保持最佳

的参数副本

。这种代价一

般是可忽

略

的，因为可以

将它储存在

较慢较大的

存储器上（例

如，在 GPU

内存中

训练，但将

最

佳参数存储

在主存储器

或磁盘驱动

器上）。由于最

佳参数的写

入很少发生

而且从不

在

训练过程中

读取，这些偶

发的慢写入

对总训练时

间的影响不

大。

0

50 100 150 200

250

Time (epochs)

0.00

0.05

0.10

0.15

0.20

Training set loss

Validation

set loss

图 7.3:

学习曲

线显示负对

数似然损失

如何随时间

变化（表示为

遍历数据集

的训练迭代

数，或 轮数

（epochs））。在

这个例子中

，我们在 MNIST

上训

练了一个 maxout 网

络。我们可以

观察到训练

目

标随时间

持续减小，但

验证集上的

平均损失最

终会再次增

加，形成不对

称的

U 形曲线

。

提前终止是

一种非常不

显眼的正则

化形式，它几

乎不需要改

变基本训练

过程、

目标函

数或一组允

许的参数值

。这意味着，无

需破坏学习

动态就能很

容易地使用

提

前终止。相

对于权重衰

减，必须小心

不能使用太

多的权重衰

减，以防网络

陷入不良局

部极小点(对

应于病态的

小权重)。

Loss (negative log-likelihood)

214 第七

章 深度学习

中的正则化

提前终止可

单独使用或

与其他的正

则化策略结

合使用。即使

为鼓励更好

泛化，使

用正

则化策略改

进目标函数

，在训练目标

的局部极小

点达到最好

泛化也是非

常罕见

的。

提

前终止需要

验证集，这意

味着某些训

练数据不能

被馈送到模

型。为了更好

地

利用这一

额外的数据

，我们可以在

完成提前终

止的首次训

练之后，进行

额外的训练

。

在第二轮，即

额外的训练

步骤中，所有

的训练数据

都被包括在

内。有两个基

本的策

略都

可以用于第

二轮训练过

程。

一个策略

（算法 7.2 ）是再次

初始化模型

，然后使用所

有数据再次

训练。在这个

第二轮训练

过程中，我们

使用第一轮

提前终止训

练确定的最

佳步数。此过

程有一些

细

微之处。例如

，我们没有办

法知道重新

训练时，对参

数进行相同

次数的更新

和对

数据集

进行相同次

数的遍历哪

一个更好。由

于训练集变

大了，在第二

轮训练时，每

一次遍历数

据集将会更

多次地更新

参数。

另一个

策略是保持

从第一轮训

练获得的参

数，然后使用

全部的数据

继续训练。

在

这个阶段，已

经没有验证

集指导我们

需要在训练

多少步后终

止。取而代之

，我们

可以监

控验证集的

平均损失函

数，并继续训

练，直到它低

于提前终止

过程终止时

的

目标值。此

策略避免了

重新训练模

型的高成本

，但表现并没

有那么好。例

如，验证

集的

目标不一定

能达到之前

的目标值，所

以这种策略

甚至不能保

证终止。我们

会在

算法

7.3 中

更正式地介

绍这个过程

。

提前终止对

减少训练过

程的计算成

本也是有用

的。除了由于

限制训练的

迭代次

数而

明显减少的

计算成本，还

带来了正则

化的益处（不

需要添加惩

罚项的代价

函

数或计算

这种附加项

的梯度）。

算法

7.2 使用提前终

止确定训练

步数，然后在

所有数据上

训练的元算

法。

令

X

(train) 和 y

(train) 为训

练集。

将 X

(train) 和 y

(train)

分

别分割为 (X

(subtrain)

,

X

(valid)

) 和

(y

(subtrain)

, y

(valid)

)。

从随机 θ 开始

，使用

X

(subtrain) 和 y

(subtrain) 作为

训练集，X

(valid) 和

y

(valid) 作

为

验证集，运

行

(算法 7.1 )。这将

返回最佳训

练步数 i

∗。

将 θ 再

次设为随机

值。

在 X

(train) 和

y

(train) 上训

练 i

∗ 步。

7.8 提前终

止

215

算法 7.3 使用

提前终止确

定将会过拟

合的目标值

，然后在所有

数据上训练

直到再次

达

到该值的元

算法。

令 X

(train)

和 y

(train) 为

训练集。

将 X

(train) 和

y

(train) 分别分割为

(X

(subtrain)

,

X

(valid)

) 和

(y

(subtrain)

, y

(valid)

)。

从随机 θ

开

始，使用 X

(subtrain) 和

y

(subtrain) 作

为训练集，X

(valid)

和

y

(valid) 作为

验证集

，运行

(算法 7.1 )。这

会更新 θ。

ϵ ← J(θ, X

(subtrain)

, y

(subtrain)

)

while J(θ, X

(valid)

, y

(valid)

) > ϵ do

在 X

(train) 和

y

(train) 上训练 n 步。

end while

提

前终止为何

具有正则化

效果: 目前为

止，我们已经

声明提前终

止是一种正

则化策

略，但

我们只通过

展示验证集

误差的学习

曲线是一个

U 型曲线来支

持这种说法

。

提前终止正

则化模型的

真正机制是

什么呢？Bishop (1995a)

和 Sjöberg and Ljung

(1995) 认

为提前终止

可以将优化

过程的参数

空间限制在

初始参数值

θ0 的小邻域内

。

更具体地，想

象用学习率

ϵ

进行 τ 个优化

步骤（对应于

τ 个训练迭代

）。我们可以

将

ϵτ 作为有效容

量的度量。假

设梯度有界

，限制迭代的

次数和学习

速率能够限

制从

θ0 到达的

参数空间的

大小，如图

7.4 所

示。在这个意

义上，ϵτ 的效果

就好像是权

重

衰减系数

的倒数。

事实

上，在二次误

差的简单线

性模型和简

单的梯度下

降情况下，我

们可以展示

提

前终止相

当于 L

2正则化

。

为了与经典

L

2正则化比较

，我们只考察

唯一的参数

是线性权重

（θ = w）的简

单情形

。我们在权重

w 的经验最佳

值 w∗ 附近以二

次近似建模

代价函数

J：

Jˆ(θ) = J(w

∗

) + 1

2

(w − w

∗

)

⊤H(w −

w

∗

), (7.33)

其

中 H 是 J

关于 w 在

w∗ 点的Hessian。鉴于假

设

w∗ 是 J(w) 的最小

点，我们知

道

H 为半正定。在

局部泰勒级

数逼近下，梯

度由下式给

出：

∇wJˆ(w) =

H(w − w

∗

). (7.34)

接下来我

们研究训练

时参数向量

的轨迹。为简

化起见，我们

将参数向量

初始化

为原

点3，也就是

w(0) = 0。我

们通过分析

Jˆ 上的梯度下

降来研究

J 上

近似的梯度

3对于神经网

络，我们需要

打破隐藏单

元间的对称

平衡因此不

能将所有参

数都初始化

为 0（如第 6.2

节所

讨论的）。

216 第七

章 深度学习

中的正则化

w1

w∗

w˜

w1

w∗

w˜

图 7.4: 提前终止

效果的示意

图。(左)

实线轮

廓线表示负

对数似然的

轮廓。虚线表

示从原点开

始

的 SGD 所经过

的轨迹。提前

终止的轨迹

在较早的点

w˜

处停止，而不

是停止在最

小化代价的

点 w

∗

处。(右)

为了

对比，使用 L

2正

则化效果的

示意图。虚线

圆圈表示 L

2 惩

罚的轮廓，L

2 惩

罚使得总

代

价的最小值

比非正则化

代价的最小

值更靠近原

点。

下降的效

果：

w

(τ)

= w

(τ−1) −

ϵ∇wJˆ(w

(τ−1)) (7.35)

=

w

(τ−1) − ϵH(w

(τ−1) − w

∗

), (7.36)

w

(τ)

− w

∗ =

(I − ϵH)(w

(τ−1)

− w

∗

).

(7.37)

现在让我

们在 H 特征向

量的空间中

改写表达式

，利用

H 的特征

分解：H = QΛQ

⊤，

其中 Λ 是

对角矩阵，Q

是

特征向量的

一组标准正

交基。

w

(τ) −

w

∗ = (I

− ϵQΛQ

⊤

)(w

(τ−1) − w

∗

) (7.38)

Q

⊤

(w

(τ) − w

∗

) = (I

− ϵΛ)Q

⊤

(w

(τ−1) − w

∗

) (7.39)

假定 w(0)

= 0 并

且 ϵ

选择得足

够小以保证

|1 − ϵλi

|

< 1，经过 τ 次参数

更新后轨迹

如下：

Q

⊤

w

(τ)

= [I − (I

− ϵΛ)

τ

]Q

⊤

w

∗

.

(7.40)

现在，式

(7.13) 中 Q

⊤

w˜ 的表达式

能被重写为

：

Q

⊤

w˜ = (Λ

+ αI)

−1ΛQ

⊤

w

∗

, (7.41)

Q

⊤

w˜ =

[I − (Λ +

αI)

−1α]Q

⊤

w

∗

. (7.42)

然而，对于其

他任何初始

值

w(0) 该论证都

成立

w2

w2

7.9 参数绑

定和参数共

享 217

比较式

(7.40) 和

式(7.42) ，我们能够

发现，如果超

参数 ϵ,

α 和 τ 满足

如下：

(I − ϵΛ)

τ

= (Λ + αI)

−1α, (7.43)

那么 L

2 正

则化和提前

终止可以被

看作是等价

的（至少在目

标函数的二

次近似下）。

进

一步取对数

，使用 log

(1 + x) 的级数

展开，我们可

以得出结论

：如果所有

λi 是

小的（即 ϵλi ≪

1 且 λi/α ≪

1），那

么

τ ≈

1

ϵα

, (7.44)

α

≈

1

τ ϵ

. (7.45)

也就是说

，在这些假设

下，训练迭代

次数 τ

起着与

L

2 参数成反比

的作用，τ ϵ

的倒

数与权重衰

减系数的作

用类似。

在大

曲率（目标函

数）方向上的

参数值受正

则化影响小

于小曲率方

向。当然，

在提

前终止的情

况下，这实际

上意味着在

大曲率方向

的参数比较

小曲率方向

的参数

更早

地学习到。

本

节中的推导

表明长度为

τ 的轨迹结束

于 L

2正则化目

标的极小点

。当然，提前

终

止比简单的

轨迹长度限

制更丰富；取

而代之，提前

终止通常涉

及监控验证

集误差，

以便

在空间特别

好的点处终

止轨迹。因此

提前终止比

权重衰减更

具有优势，提

前终

止能自

动确定正则

化的正确量

，而权重衰减

需要进行多

个不同超参

数值的训练

实验。

7.9

参数绑

定和参数共

享

目前为止

，本章讨论对

参数添加约

束或惩罚时

，一直是相对

于固定的区

域或点。

例如

，L

2正则化（或权

重衰减）对参

数偏离零的

固定值进行

惩罚。然而，有

时我们

可能

需要其他的

方式来表达

我们对模型

参数适当值

的先验知识

。有时候，我们

可能

无法准

确地知道应

该使用什么

样的参数，但

我们根据相

关领域和模

型结构方面

的知

识得知

模型参数之

间应该存在

一些相关性

。

我们经常想

要表达的一

种常见依赖

是某些参数

应当彼此接

近。考虑以下

情形：

我们有

两个模型执

行相同的分

类任务（具有

相同类别），但

输入分布稍

有不同。形式

地，我们有参

数为 w(A) 的模型

A 和参数为

w(B) 的

模型 B。这两种

模型将输入

映射

到两个

不同但相关

的输出：yˆ

(A) = f(w(A)

,

x) 和 yˆ

(B)

= f(w(B)

, x)。

218 第

七章 深度学

习中的正则

化

我们可以

想象，这些任

务会足够相

似（或许具有

相似的输入

和输出分布

），因

此我们认

为模型参数

应彼此靠近

：∀i, wi

(A) 应该与

wi

(B) 接近

。我们可以通

过正则

化利

用此信息。具

体来说，我们

可以使用以

下形式的参

数范数惩罚

：Ω(w(A)

, w(B)

) =

w(A)

− w(B)

2

2。在这里我们

使用 L

2

惩罚，但

也可以使用

其他选择。

这

种方法由Lasserre et al.

(2006) 提

出，正则化一

个模型（监督

模式下训练

的分

类器）的

参数，使其接

近另一个无

监督模式下

训练的模型

（捕捉观察到

的输入数据

的分布）的参

数。构造的这

种架构使得

分类模型中

的许多参数

能与无监督

模型中对

应

的参数匹配

。

参数范数惩

罚是正则化

参数使其彼

此接近的一

种方式，而更

流行的方法

是使用

约束

：强迫某些参

数相等。由于

我们将各种

模型或模型

组件解释为

共享唯一的

一组

参数，这

种正则化方

法通常被称

为 参数共享

（parameter

sharing）。和正则化参

数使

其接近

（通过范数惩

罚）相比，参数

共享的一个

显著优点是

，只有参数（唯

一一个集

合

）的子集需要

被存储在内

存中。对于某

些特定模型

，如卷积神经

网络，这可能

可

以显著减

少模型所占

用的内存。

7.9.1 卷

积神经网络

目前为止，最

流行和广泛

使用的参数

共享出现在

应用于计算

机视觉的 卷

积神经

网络

（CNN）中。

自然图像

有许多统计

属性是对转

换不变的。例

如，猫的照片

即使向右边

移了一

个像

素，仍保持猫

的照片。CNN通过

在图像多个

位置共享参

数来考虑这

个特性。相

同

的特征（具有

相同权重的

隐藏单元）在

输入的不同

位置上计算

获得。这意味

着无

论猫出

现在图像中

的第

i 列或 i +

1 列

，我们都可以

使用相同的

猫探测器找

到猫。

参数共

享显著降低

了CNN模型的参

数数量，并显

著提高了网

络的大小而

不需要

相应

地增加训练

数据。它仍然

是将领域知

识有效地整

合到网络架

构的最佳范

例之一。

我们

将会在第九

章中更详细

地讨论卷积

神经网络。

7.10 稀

疏表示

前文

所述的权重

衰减直接惩

罚模型参数

。另一种策略

是惩罚神经

网络中的激

活

单元，稀疏

化激活单元

。这种策略间

接地对模型

参数施加了

复杂惩罚。

7.10 稀

疏表示 219

我们

已经讨论过

（在第7.1.2 节中）L

1 惩

罚如何诱导

稀疏的参数

，即许多参数

为

零（或接近

于零）。另一方

面，表示的稀

疏描述了许

多元素是零

（或接近零）的

表示。

我们可

以线性回归

的情况下简

单说明这种

区别：



















18

15

5

−

−

9

3



















y

∈ Rm

=



















4 0 0 −2

0 0

0 0

−1 0 3 0

0 5 0 0

0 0

1 0

0 −1 0 −4

1 0 0 0

−5 0



















A

∈ Rm×n























2

3

−2

−5

1

4























x ∈

Rn

(7.46)



















−14

19

1

23

2



















y ∈ Rm

=



















3 −1

2 −5 4 1

4 2 −3 −1

1 3

−1 5

4 2 −3 −2

3 1 2 −3

0 −3

−5 4

−2 2 −5 −1



















B ∈ Rm×n























0

2

0

0

−

0

3























h ∈ Rn

(7.47)

第一个

表达式是参

数稀疏的线

性回归模型

的例子。第二

个表达式是

数据 x 具

有稀

疏表示 h 的线

性回归。也就

是说，h 是

x 的一

个函数，在某

种意义上表

示存在

于 x

中

的信息，但只

是用一个稀

疏向量表示

。

表示的正则

化可以使用

参数正则化

中同种类型

的机制实现

。

表示的范数

惩罚正则化

是通过向损

失函数 J

添加

对表示的范

数惩罚来实

现的。

我们将

这个惩罚记

作 Ω(h)。和以前一

样，我们将正

则化后的损

失函数记作

J˜：

J˜(θ;

X, y) = J(θ;

X, y) + αΩ(h),

(7.48)

其中 α ∈

[0, ∞] 权衡范

数惩罚项的

相对贡献，越

大的 α

对应越

多的正则化

。

正如对参数

的 L

1

惩罚诱导

参数稀疏性

，对表示元素

的 L

1 惩罚诱导

稀疏的表示

：

Ω(h) = ∥h∥1 =

∑

i

|hi

|。当然

L

1 惩罚是

使表示稀疏

的方法之一

。其他方法还

包括

从表示

上的Student-t

先验导

出的惩罚 (Olshausen and Field,

1996; Bergstra, 2011)

和

KL

散度惩罚 (Larochelle and Bengio,

2008b)，这

些方法对于

将表示中的

元素约束

于

单位区间上

特别有用。Lee et al.

(2008) 和

Goodfellow et al.

(2009) 都提供了正

则

化几个样

本平均激活

的例子，即令

m

1

∑

i

h

(i)

接近某些目

标值（如每项

都是 .01 的向

220

第

七章 深度学

习中的正则

化

量）。

还有一

些其他方法

通过激活值

的硬性约束

来获得表示

稀疏。例如，正

交匹配追

踪

(orthogonal matching pursuit)(Pati et

al., 1993) 通过解决以

下约束优化

问题将输

入

值

x 编码成表

示 h

arg

min

h,∥h∥0<k

∥x −

Wh∥

2

, (7.49)

其中 ∥h∥0 是 h

中

非零项的个

数。当 W 被约束

为正交时，我

们可以高效

地解决这个

问题。这种方

法通常被称

为OMP-k，通过 k

指定

允许的非零

特征数量。Coates and

Ng (2011)

证

明OMP-1 可以成为

深度架构中

非常有效的

特征提取器

。

含有隐藏单

元的模型在

本质上都能

变得稀疏。在

本书中，我们

将看到在各

种情

况下使

用稀疏正则

化的例子。

7.11 Bagging 和

其他集成方

法

Bagging（bootstrap

aggregating）是通过结

合几个模型

降低泛化误

差的技术

(Breiman, 1994)。主

要想法是分

别训练几个

不同的模型

，然后让所有

模型表决测

试样例的输

出。这是机器

学习中常规

策略的一个

例子，被称为

模型平均（model

averaging）。采

用这种策略

的技术被称

为集成方法

。

模型平均（model averaging）奏

效的原因是

不同的模型

通常不会在

测试集上产

生完全相同

的误差。

假设

我们有 k

个回

归模型。假设

每个模型在

每个例子上

的误差是 ϵi，这

个误差

服从

零均值方差

为 E[ϵ

2

i

] =

v 且协方差

为 E[ϵiϵj ]

= c 的多维正

态分布。通过

所有集

成模

型的平均预

测所得误差

是

k

1 ∑

i

ϵi。集成预测

器平方误差

的期望是

E

[(k

1

∑

i

ϵi

)2]

=

k

1

2

E

[∑

i

(

ϵ

2

i +

∑

j=i

ϵiϵj

)],

(7.50)

=

1

k

v +

k −

1

k

c. (7.51)

在

误差完全相

关即 c = v

的情况

下，均方误差

减少到 v，所以

模型平均没

有任何帮

助

。在错误完全

不相关即 c

= 0 的

情况下，该集

成平方误差

的期望仅为

k

1

v。这意味

着集

成平方误差

的期望会随

着集成规模

增大而线性

减小。换言之

，平均上，集成

至

7.11 BAGGING

和其他集

成方法 221

少与

它的任何成

员表现得一

样好，并且如

果成员的误

差是独立的

，集成将显著

地比

其成员

表现得更好

。

不同的集成

方法以不同

的方式构建

集成模型。例

如，集成的每

个成员可以

使用

不同的

算法和目标

函数训练成

完全不同的

模型。Bagging是一种

允许重复多

次使用同

一

种模型、训练

算法和目标

函数的方法

。

具体来说，Bagging涉

及构造

k 个不

同的数据集

。每个数据集

从原始数据

集中重

复采

样构成，和原

始数据集具

有相同数量

的样例。这意

味着，每个数

据集以高概

率

缺少一些

来自原始数

据集的例子

，还包含若干

重复的例子

（如果所得训

练集与原始

数据集大小

相同，那所得

数据集中大

概有原始数

据集

2/3 的实例

）。模型 i 在数据

集

i 上训练。每

个数据集所

含样本的差

异导致了训

练模型之间

的差异。图 7.5 是

一个例

子。

8

8

First

ensemble member

Second ensemble

member

Original dataset

First

resampled dataset

Second resampled

dataset

图

7.5: 描述Bagging如何工

作的草图。假

设我们在上

述数据集（包

含一个 8、一个

6

和一个 9）上

训

练数字 8

的检

测器。假设我

们制作了两

个不同的重

采样数据集

。Bagging训练程序通

过有放回采

样构建这些

数据集。第一

个数据集忽

略 9 并重复 8。在

这个数据集

上，检测器得

知数字顶部

有一

个环就

对应于一个

8。第二个数据

集中，我们忽

略 6 并重复 9。在

这种情况下

，检测器得知

数字底

部有

一个环就对

应于一个 8。这

些单独的分

类规则中的

每一个都是

不可靠的，但

如果我们平

均它们

的输

出，就能得到

鲁棒的检测

器，只有当 8

的

两个环都存

在时才能实

现最大置信

度。

神经网络

能找到足够

多的不同的

解，意味着他

们可以从模

型平均中受

益 (即使所

有

模型都在同

一数据集上

训练)。神经网

络中随机初

始化的差异

、小批量的随

机选择、

超参

数的差异或

不同输出的

非确定性实

现往往足以

使得集成中

的不同成员

具有部分

独

立的误差。

模

型平均是一

个减少泛化

误差的非常

强大可靠的

方法。在作为

科学论文算

法的

222

第七章

深度学习中

的正则化

基

准时，它通常

是不鼓励使

用的，因为任

何机器学习

算法都可以

从模型平均

中大幅

获益

（以增加计算

和存储为代

价）。

机器学习

比赛中的取

胜算法通常

是使用超过

几十种模型

平均的方法

。最近一个

突

出的例子是

Netflix Grand Prize(Koren, 2009)。

不是所有构

建集成的技

术都是为了

让集成模型

比单一模型

更加正则化

。例如，一

种被

称为 Boosting 的技术

(Freund

and Schapire, 1996b,a) 构建比单个

模型容量更

高的集成模

型。通过向集

成逐步添加

神经网络，Boosting已

经被应用于

构建神经网

络

的集成(Schwenk and Bengio, 1998)。通

过逐渐增加

神经网络的

隐藏单元，Boosting也

可以将单个

神经网络解

释为一个集

成。

7.12 Dropout

Dropout (Srivastava

et al., 2014) 提供了正

则化一大类

模型的方法

，计算方便

但

功能强大。在

第一种近似

下，Dropout可以被认

为是集成大

量深层神经

网络的实

用

Bagging方法。Bagging涉及训

练多个模型

，并在每个测

试样本上评

估多个模型

。

当每个模型

都是一个很

大的神经网

络时，这似乎

是不切实际

的，因为训练

和评估

这样

的网络需要

花费很多运

行时间和内

存。通常我们

只能集成五

至十个神经

网络，

如Szegedy et al. (2014a)集成

了六个神经

网络赢得

ILSVRC，超

过这个数量

就会迅速

变

得难以处理

。Dropout提供了一种

廉价的Bagging集成

近似，能够训

练和评估指

数

级数量的

神经网络。

具

体而言，Dropout训练

的集成包括

所有从基础

网络除去非

输出单元后

形成的子

网

络，如图 7.6 所示

。最先进的神

经网络基于

一系列仿射

变换和非线

性变换，我们

只

需将一些

单元的输出

乘零就能有

效地删除一

个单元。这个

过程需要对

模型（如径向

基函数网络

，单元的状态

和参考值之

间存在一定

区别）进行一

些修改。为了

简单起

见，我

们在这里提

出乘零的简

单Dropout算法，但是

它被简单修

改后，可以与

从网络

中移

除单元的其

他操作结合

使用。

回想一

下Bagging学习，我们

定义 k

个不同

的模型，从训

练集有放回

采样构造

k 个

不同的数据

集，然后在训

练集 i

上训练

模型 i。Dropout的目标

是在指数级

数量

的神经

网络上近似

这个过程。具

体来说，在训

练中使用Dropout时

，我们会使用

基

于小批量

产生较小步

长的学习算

法，如随机梯

度下降等。我

们每次在小

批量中加载

一个样本，然

后随机抽样

应用于网络

中所有输入

和隐藏单元

的不同二值

掩码。对于

7.12 DROPOUT 223

y

hh11 hh22

xx11 xx22

y

hh11 hh22

xx11

xx22

y

hh11 hh22

xx22

y

hh11 hh22

xx11

y

hh22

xx11

xx22

y

hh11

xx11

xx22

y

hh11 hh22

y

xx11 xx22

y

hh22

xx22

y

hh11

xx11

y

hh11

xx22

y

hh22

xx11

y

xx11

y

xx22

y

hh22

y

hh11

y

Base network

Ensemble of

subnetworks

图

7.6: Dropout训练由所有

子网络组成

的集成，其中

子网络通过

从基本网络

中删除非输

出单元构

建

。我们从具有

两个可见单

元和两个隐

藏单元的基

本网络开始

。这四个单元

有十六个可

能的子集。

右

图展示了从

原始网络中

丢弃不同的

单元子集而

形成的所有

十六个子网

络。在这个小

例子中，所

得

到的大部分

网络没有输

入单元或没

有从输入连

接到输出的

路径。当层较

宽时，丢弃所

有从输入

到

输出的可能

路径的概率

变小，所以这

个问题不太

可能在出现

层较宽的网

络中。

每个单

元，掩码是独

立采样的。掩

码值为

1 的采

样概率（导致

包含一个单

元）是训

练开

始前一个固

定的超参数

。它不是模型

当前参数值

或输入样本

的函数。通常

在每

一个小

批量训练的

神经网络中

，一个输入单

元被包括的

概率为

0.8，一个

隐藏单元被

包括的概率

为 0.5。然后，我们

运行和之前

一样的前向

传播、反向传

播以及学习

更新。

图 7.7

说明

了在Dropout下的前

向传播。

更正

式地说，假设

一个掩码向

量 µ 指定被包

括的单元，J(θ,

µ) 是

由参数 θ 和掩

码

µ 定义的模

型代价。那么

Dropout训练的目标

是最小化 EµJ(θ, µ)。这

个期望包含

224

第七章 深度

学习中的正

则化

xxˆˆ11

µµxx11

xx11 xx22 µµxx22

hh11

hh22 µµhh11 µµhh22

hhˆˆ

11 hhˆˆ

22

y

y

hh11 hh22

xx11

xx22

图 7.7: 在使

用Dropout的前馈网

络中前向传

播的示例。(顶

部)

在此示例

中，我们使用

具有两个输

入

单元，具有

两个隐藏单

元的隐藏层

以及一个输

出单元的前

馈网络。(底部

) 为了执行具

有Dropout的

前向传

播，我们随机

地对向量

µ 进

行采样，其中

网络中的每

个输入或隐

藏单元对应

一项。µ 中的

每

项都是二值

的且独立于

其他项采样

。超参数的采

样概率为

1，隐

藏层的采样

概率通常为

0.5，输

入的采样

概率通常为

0.8。网络中的每

个单元乘以

相应的掩码

，然后正常地

继续沿着网

络的其余部

分前向传播

。这相当于从

图 7.6 中随机选

择一个子网

络并沿着前

向传播。

多达

指数级的项

，但我们可以

通过抽样 µ 获

得梯度的无

偏估计。

Dropout训练

与Bagging训练不太

一样。在Bagging的情

况下，所有模

型都是独立

xxˆˆ22

7.12 DROPOUT 225

的。在Dropout的情况

下，所有模型

共享参数，其

中每个模型

继承父神经

网络参数

的

不同子集。参

数共享使得

在有限可用

的内存下表

示指数级数

量的模型变

得可能。

在Bagging的

情况下，每一

个模型在其

相应训练集

上训练到收

敛。在Dropout的情况

下，通常大部

分模型都没

有显式地被

训练，因为通

常父神经网

络会很大，以

致于到

宇宙

毁灭都不可

能采样完所

有的子网络

。取而代之的

是，在单个步

骤中我们训

练一

小部分

的子网络，参

数共享会使

得剩余的子

网络也能有

好的参数设

定。这些是仅

有

的区别。除

了这些，Dropout与Bagging算

法一样。例如

，每个子网络

中遇到的训

练

集确实是

有放回采样

的原始训练

集的一个子

集。

Bagging集成必须

根据所有成

员的累积投

票做一个预

测。在这种背

景下，我们

将

这个过程称

为

推断（inference）。目前

为止，我们在

介绍Bagging和Dropout时没

有要求模型

具有明确的

概率。现在，我

们假定该模

型的作用是

输出一个概

率分布。

在Bagging的

情况下，每个

模型 i 产生一

个概率分布

p

(i)

(y | x)。集成的预测

由这些

分布

的算术平均

值给出，

k

1

k

∑

i=1

p

(i)

(y | x). (7.52)

在Dropout的

情况下，通过

掩码 µ 定义每

个子模型的

概率分布 p(y

| x, µ)。所

有掩码的算

术平均值由

下式给出

∑

µ

p(µ)p(y | x,

µ), (7.53)

其

中 p(µ)

是训练时

采样 µ 的概率

分布。

因为这

个求和包含

多达指数级

的项，除非该

模型的结构

允许某种形

式的简化，

否

则是不可能

计算的。目前

为止，无法得

知深度神经

网络是否允

许某种可行

的简化。

相反

，我们可以通

过采样近似

推断，即平均

许多掩码的

输出。即使是

10 − 20

个掩

码就足

以获得不错

的表现。

然而

，一个更好的

方法能不错

地近似整个

集成的预测

，且只需一个

前向传播

的

代价。要做到

这一点，我们

改用集成成

员预测分布

的几何平均

而不是算术

平均。

Warde-Farley et al. (2014)

提出的

论点和经验

证据表明，在

这个情况下

几何平均与

算术平均表

现得差不多

。

多个概率分

布的几何平

均不能保证

是一个概率

分布。为了保

证结果是一

个概率

分布

，我们要求没

有子模型给

某一事件分

配概率 0，并重

新标准化所

得分布。通过

几

226 第七章 深

度学习中的

正则化

何平

均直接定义

的非标准化

概率分布由

下式给出

˜pensemble(y | x) =

2

d

√∏

µ

p(y | x, µ),

(7.54)

其

中 d 是可被丢

弃的单元数

。这里为简化

介绍，我们使

用均匀分布

的

µ，但非均匀

分布也是可

以的。为了作

出预测，我们

必须重新标

准化集成：

pensemble(y | x)

= ˜pensemble(y | x)

∑

y′ p˜ensemble(y

′

| x)

. (7.55)

涉

及Dropout的一个重

要观点 (Hinton et al.,

2012c) 是，我

们可以通过

评估模型

中

p(y |

x) 来近似 pensemble：该模

型具有所有

单元，但我们

将单元 i

的输

出的权重乘

以单元 i 的被

包含概率。这

个修改的动

机是得到从

该单元输出

的正确期望

值。我们

把这

种方法称为

权重比例推

断规则（weight

scaling inference rule）。目前

还没有在

深

度非线性网

络上对这种

近似推断规

则的准确性

作任何理论

分析，但经验

上表现得

很

好。

因为我们

通常使用 2

1

的

包含概率，权

重比例规则

一般相当于

在训练结束

后将权

重除

2，然后像平常

一样使用模

型。实现相同

结果的另一

种方法是在

训练期间将

单元

的状态

乘 2。无论哪种

方式，我们的

目标是确保

在测试时一

个单元的期

望总输入与

在

训练时该

单元的期望

总输入是大

致相同的（即

使近半单位

在训练时丢

失）。

对许多不

具有非线性

隐藏单元的

模型族而言

，权重比例推

断规则是精

确的。举

个简

单的例子，考

虑softmax 函数回归

分类，其中由

向量

v 表示 n 个

输入变量：

P(y = y |

v) = softmax(W⊤

v

+ b

)

y

. (7.56)

我

们可以根据

二值向量 d

逐

元素的乘法

将一类子模

型进行索引

：

P(y = y

| v; d) =

softmax(W⊤

(d ⊙ v)

+ b

)

y

. (7.57)

集成预测器

被定义为重

新标准化所

有集成成员

预测的几何

平均：

Pensemble(y

= y | v)

= P˜

ensemble(y =

y | v)

∑

y′ P˜

ensemble(y =

y

′

| v)

, (7.58)

其中

˜Pensemble(y

= y | v)

= 2n

√ ∏

d∈{0,1}n

P(y = y

| v; d). (7.59)

7.12 DROPOUT 227

为

了证明权重

比例推断规

则是精确的

，我们简化

P˜

ensemble：

˜Pensemble(y =

y | v) =

2n

√ ∏

d∈{0,1}n

P(y = y |

v; d) (7.60)

=

2n

√ ∏

d∈{0,1}n

softmax(W⊤

(d ⊙ v)

+ b)y (7.61)

=

2n

v

uut ∏

d∈{0,1}n

exp(W⊤

y,:

(d

⊙ v) + by)

∑

y′ exp(W⊤

y′

,;

(d ⊙ v)

+ by′ )

(7.62)

=

2n

√∏

d∈{0,1}n

exp(W⊤

y,:

(d ⊙

v) + by)

2n√∏

d∈{0,1}n

∑

y′ exp(W⊤

y′

,:

(d ⊙

v) + by′ )

(7.63)

由

于 P˜ 将被标准

化，我们可以

放心地忽略

那些相对

y 不

变的乘法：

˜Pensemble(y =

y | v) ∝

2n

√ ∏

d∈{0,1}n

exp(W⊤

y,:

(d ⊙

v) + by) (7.64)

= exp (

2

1

n

∑

d∈{0,1}n

W⊤

y,;

(d ⊙

v) + by

)

(7.65)

= exp (1

2

W⊤

y,:v +

by

)

. (7.66)

将

其代入式(7.58) ，我

们得到了一

个权重为 1

2W

的

softmax 函数分类器

。

权重比例推

断规则在其

他设定下也

是精确的，包

括条件正态

输出的回归

网络以

及那

些隐藏层不

包含非线性

的深度网络

。然而，权重比

例推断规则

对具有非线

性的

深度模

型仅仅是一

个近似。虽然

这个近似尚

未有理论上

的分析，但在

实践中往往

效

果很好。Goodfellow et al.

(2013b) 实

验发现，在对

集成预测的

近似方面，权

重比例

推断

规则比蒙特

卡罗近似更

好（就分类精

度而言）。即使

允许蒙特卡

罗近似采样

多达

1000

子网络

时也比不过

权重比例推

断规则。Gal and Ghahramani (2015)

发现

一些

模型可

以通过二十

个样本和蒙

特卡罗近似

获得更好的

分类精度。似

乎推断近似

的最

佳选择

是与问题相

关的。

Srivastava

et al. (2014) 显示，Dropout比

其他标准的

计算开销小

的正则化方

法

（如权重衰

减、过滤器范

数约束和稀

疏激活的正

则化）更有效

。Dropout也可以与其

他形式的正

则化合并，得

到进一步的

提升。

计算方

便是Dropout的一个

优点。训练过

程中使用Dropout产

生 n 个随机二

进制

数与状

态相乘，每个

样本每次更

新只需 O(n) 的计

算复杂度。根

据实现，也可

能需要

228

第七

章 深度学习

中的正则化

O(n) 的存储空间

来持续保存

这些二进制

数（直到反向

传播阶段）。使

用训练好的

模

型推断时

，计算每个样

本的代价与

不使用Dropout是一

样的，尽管我

们必须在开

始运

行推断

前将权重除

以 2。

Dropout的另一个

显著优点是

不怎么限制

适用的模型

或训练过程

。几乎在所有

使用分布式

表示且可以

用随机梯度

下降训练的

模型上都表

现很好。包括

前馈神经网

络、概率模型

，如受限玻尔

兹曼机(Srivastava et

al., 2014)，以及

循环神经网

络(Bayer

and Osendorfer,

2014; Pascanu et al.,

2014a)。许多效果

差不多的其

他正则化策

略对

模型结

构的限制更

严格。

虽然Dropout在

特定模型上

每一步的代

价是微不足

道的，但在一

个完整的系

统

上使用Dropout的

代价可能非

常显著。因为

Dropout是一个正则

化技术，它减

少了模

型的

有效容量。为

了抵消这种

影响，我们必

须增大模型

规模。不出意

外的话，使

用

Dropout时最佳验证

集的误差会

低很多，但这

是以更大的

模型和更多

训练算法的

迭

代次数为

代价换来的

。对于非常大

的数据集，正

则化带来的

泛化误差减

少得很小。在

这些情况下

，使用Dropout和更大

模型的计算

代价可能超

过正则化带

来的好处。

只

有极少的训

练样本可用

时，Dropout不会很有

效。在只有不

到

5000 的样本

的

Alternative Splicing数据集上

(Xiong et al., 2011)，贝

叶斯神经网

络

(Neal, 1996)

比Dropout表现得

更好 (Srivastava

et al., 2014)。当有其

他未分类的

数据可用时

，无

监督特征

学习也比Dropout更

有优势。

Wager et al. (2013)

表明

，当Dropout作用于线

性回归时，相

当于每个输

入特征

具有

不同权重衰

减系数的 L

2权

重衰减。每个

特征的权重

衰减系数的

大小是由其

方差

来确定

的。其他线性

模型也有类

似的结果。而

对于深度模

型而言，Dropout与权

重衰

减是不

等同的。

使用

Dropout训练时的随

机性不是这

个方法成功

的必要条件

。它仅仅是近

似所有

子模

型总和的一

个方法。Wang

and Manning (2013) 导出

了近似这种

边缘分布的

解

析解。他们

的近似被称

为 快速 Dropout（fast dropout），减小

梯度计算中

的随机性

而

获得更快的

收敛速度。这

种方法也可

以在测试时

应用，能够比

权重比例推

断规则更

合

理地（但计算

也更昂贵）近

似所有子网

络的平均。快

速 Dropout在小神经

网络上

的性

能几乎与标

准的Dropout相当，但

在大问题上

尚未产生显

著改善或尚

未应用。

随机

性对实现Dropout的

正则化效果

不是必要的

，同时也不是

充分的。为了

证明

这一点

，Warde-Farley et al.

(2014) 使用一种被

称为 Dropout Boosting

的方法

设

计了一个

对照实验，具

有与传统Dropout方

法完全相同

的噪声掩码

，但缺乏正则

化效

7.12 DROPOUT

229

果。Dropout Boosting训练

整个集成以

最大化训练

集上的似然

。从传统Dropout类

似

于Bagging的角度来

看，这种方式

类似于Boosting。如预

期一样，和单

一模型训

练

整个网络相

比，Dropout Boosting几乎没有

正则化效果

。这表明，使用

Bagging解

释Dropout比使用

稳健性噪声

解释Dropout更好。只

有当随机抽

样的集成成

员相互独

立

地训练好后

，才能达到Bagging集

成的正则化

效果。

Dropout启发其

他以随机方

法训练指数

量级的共享

权重的集成

。DropConnect是

Dropout的一个特

殊情况，其中

一个标量权

重和单个隐

藏单元状态

之间的每个

乘积

被认为

是可以丢弃

的一个单元

(Wan et

al., 2013)。随机池化是

构造卷积神

经网络集

成

的一种随机

化池化的形

式 (见第

9.3 节)，其

中每个卷积

网络参与每

个特征图的

不同

空间位

置。目前为止

，Dropout仍然是最广

泛使用的隐

式集成方法

。

一个关于Dropout的

重要见解是

，通过随机行

为训练网络

并平均多个

随机决定进

行预测，实现

了一种参数

共享的Bagging形式

。早些时候，我

们将Dropout描述为

通

过包括或

排除单元形

成模型集成

的Bagging。然而，这种

参数共享策

略不一定要

基于

包括和

排除。原则上

，任何一种随

机的修改都

是可接受的

。在实践中，我

们必须选

择

让神经网络

能够学习对

抗的修改类

型。在理想情

况下，我们也

应该使用可

以快速

近似

推断的模型

族。我们可以

认为由向量

µ

参数化的任

何形式的修

改，是对 µ 所有

可能的值训

练 p(y

| x, µ) 的集成。注

意，这里不要

求

µ 具有有限

数量的值。例

如，

µ 可以是实

值。Srivastava

et al. (2014) 表明，权重

乘以

µ ∼ N (1,

I) 比基于

二值掩

码Dropout表

现得更好。由

于 E[µ]

= 1，标准网络

自动实现集

成的近似推

断，而不需

要

权重比例推

断规则。

目前

为止，我们将

Dropout介绍为一种

纯粹高效近

似Bagging的方法。然

而，还

有比这

更进一步的

Dropout观点。Dropout不仅仅

是训练一个

Bagging的集成模型

，并

且是共享

隐藏单元的

集成模型。这

意味着无论

其他隐藏单

元是否在模

型中，每个隐

藏

单元必须

都能够表现

良好。隐藏单

元必须准备

好进行模型

之间的交换

和互换。Hinton

et

al. (2012d) 由生

物学的想法

受到启发：有

性繁殖涉及

到两个不同

生物体之间

交换

基因，进

化产生的压

力使得基因

不仅是良好

的而且要准

备好不同有

机体之间的

交换。

这样的

基因和这些

特点对环境

的变化是非

常稳健的，因

为它们一定

会正确适应

任何

一个有

机体或模型

不寻常的特

性。因此Dropout正则

化每个隐藏

单元不仅是

一个很好

的

特征，更要在

许多情况下

是良好的特

征。Warde-Farley et

al. (2014) 将Dropout与

大集

成的训练相

比并得出结

论：相比独立

模型集成获

得泛化误差

改进，Dropout会带

来

额外的改进

。

Dropout强大的大部

分原因来自

施加到隐藏

单元的掩码

噪声，了解这

一事实是重

230 第七章 深度

学习中的正

则化

要的。这

可以看作是

对输入内容

的信息高度

智能化、自适

应破坏的一

种形式，而不

是对输入原

始值的破坏

。例如，如果模

型学得通过

鼻检测脸的

隐藏单元 hi，那

么丢

失 hi

对应

于擦除图像

中有鼻子的

信息。模型必

须学习另一

种 hi，要么是鼻

子存在的

冗

余编码，要么

是像嘴这样

的脸部的另

一特征。传统

的噪声注入

技术，在输入

端加

非结构

化的噪声不

能够随机地

从脸部图像

中抹去关于

鼻子的信息

，除非噪声的

幅度

大到几

乎能抹去图

像中所有的

信息。破坏提

取的特征而

不是原始值

，让破坏过程

充

分利用该

模型迄今获

得的关于输

入分布的所

有知识。

Dropout的另

一个重要方

面是噪声是

乘性的。如果

是固定规模

的加性噪声

，那么

加了噪

声

ϵ 的整流线

性隐藏单元

可以简单地

学会使 hi 变得

很大（使增加

的噪声

ϵ 变

得

不显著）。乘性

噪声不允许

这样病态地

解决噪声鲁

棒性问题。

另

一种深度学

习算法——批标

准化，在训练

时向隐藏单

元引入加性

和乘性噪声

重新参数化

模型。批标准

化的主要目

的是改善优

化，但噪声具

有正则化的

效果，有

时没

必要再使用

Dropout。批标准化将

会在第 8.7.1 节中

被更详细地

讨论。

7.13

对抗训

练

在许多情

况下，神经网

络在独立同

分布的测试

集上进行评

估已经达到

了人类表

现

。因此，我们自

然要怀疑这

些模型在这

些任务上是

否获得了真

正的人类层

次的理

解。为

了探索网络

对底层任务

的理解层次

，我们可以探

索这个模型

错误分类的

例子。

Szegedy et al. (2014b)

发现，在

精度达到人

类水平的神

经网络上通

过优化过程

故意

构造数

据点，其上的

误差率接近

100%，模型在这个

输入点 x

′

的输

出与附近的

数据

点 x 非常

不同。在许多

情况下，x

′ 与 x 非

常近似，人类

观察者不会

察觉原始样

本

和 对抗样

本（adversarial example）之间的差

异，但是网络

会作出非常

不同的预测

。

见图

7.8 中的例

子。

对抗样本

在很多领域

有很多影响

，例如计算机

安全，这超出

了本章的范

围。然

而，它们

在正则化的

背景下很有

意思，因为我

们可以通过

对抗训练（adversarial

training）减

少原有独立

同分布的测

试集的错误

率——在对抗扰

动的训练集

样本上训

练

网络 (Szegedy et

al., 2014b; Goodfellow et

al., 2014b)。

Goodfellow et

al. (2014b) 表明，这

些对抗样本

的主要原因

之一是过度

线性。神

经网

络主要是基

于线性块构

建的。因此在

一些实验中

，它们实现的

整体函数被

证明

是高度

线性的。这些

线性函数很

容易优化。不

幸的是，如果

一个线性函

数具有许多

7.13 对抗训练 231

+

.007 × =

x

sign(∇xJ(θ, x, y))

x

+

ϵsign(∇xJ(θ, x, y))

y =“panda” “nematode” “gibbon”

w/ 57.7%

confidence

w/

8.2%

confidence

w/ 99.3

%

confidence

图

7.8: 在

ImageNet 上应用 GoogLeNet (Szegedy

et al., 2014a) 的

对抗样本生

成的演示。通

过添

加一个

不可察觉的

小向量（其中

元素等于代

价函数相对

于输入的梯

度元素的符

号），我们可以

改变

GoogLeNet 对此图

像的分类结

果。经Goodfellow et

al. (2014b) 许可转

载。

输入，那么

它的值可以

非常迅速地

改变。如果我

们用

ϵ 改变每

个输入，那么

权重为

w 的线

性函数可以

改变

ϵ ∥w∥1 之多，如

果 w

是高维的

这会是一个

非常大的数

。对

抗训练通

过鼓励网络

在训练数据

附近的局部

区域恒定来

限制这一高

度敏感的局

部线

性行为

。这可以被看

作是一种明

确地向监督

神经网络引

入局部恒定

先验的方法

。

对抗训练有

助于体现积

极正则化与

大型函数族

结合的力量

。纯粹的线性

模型，

如逻辑

回归，由于它

们被限制为

线性而无法

抵抗对抗样

本。神经网络

能够将函数

从

接近线性

转化为局部

近似恒定，从

而可以灵活

地捕获到训

练数据中的

线性趋势同

时

学习抵抗

局部扰动。

对

抗样本也提

供了一种实

现半监督学

习的方法。在

与数据集中

的标签不相

关联

的点 x 处

，模型本身为

其分配一些

标签 yˆ。模型的

标记

yˆ 未必是

真正的标签

，但如

果模型

是高品质的

，那么 yˆ

提供正

确标签的可

能性很大。我

们可以搜索

一个对抗样

本 x

′，导致分类

器输出一个

标签 y

′ 且 y

′

= ˆy。不使

用真正的标

签，而是由训

练好

的模型

提供标签产

生的对抗样

本被称为 虚

拟对抗样本

（virtual

adversarial example）

(Miyato et

al., 2015)。我们可以训

练分类器为

x 和 x

′ 分配相同

的标签。这鼓

励分类

器学

习一个沿着

未标签数据

所在流形上

任意微小变

化都很鲁棒

的函数。驱动

这种方

法的

假设是，不同

的类通常位

于分离的流

形上，并且小

扰动不会使

数据点从一

个类

的流形

跳到另一个

类的流形上

。

232 第七章 深度

学习中的正

则化

7.14 切面距

离、正切传播

和流形正切

分类器

如第

5.11.3 节所述，许多

机器学习通

过假设数据

位于低维流

形附近来克

服维数

灾难

。

一个利用流

形假设的早

期尝试是 切

面距离（tangent distance）算法

(Simard

et al., 1993, 1998)。它是一种非

参数的最近

邻算法，其中

使用的度量

不是通用的

欧几

里德距

离，而是根据

邻近流形关

于聚集概率

的知识导出

的。这个算法

假设我们尝

试

分类的样

本和同一流

形上的样本

具有相同的

类别。由于分

类器应该对

局部因素（对

应于流形上

的移动）的变

化保持不变

，一种合理的

度量是将点

x1 和 x2

各自所在

流

形 M1 和

M2 的距

离作为点 x1 和

x2

之间的最近

邻距离。然而

这可能在计

算上是困

难

的（它需要解

决一个寻找

M1 和 M2

最近点对

的优化问题

），一种局部合

理的廉价

替

代是使用 xi 点

处切平面近

似

Mi，并测量两

条切平面或

一个切平面

和点之间的

距

离。这可以

通过求解一

个低维线性

系统（就流形

的维数而言

）来实现。当然

，这种算

法需

要指定那些

切向量。

受相

关启发，正切

传播（tangent

prop）算法 (Simard et al.,

1992)（图

7.9 ）训

练带有额

外惩罚的神

经网络分类

器，使神经网

络的每个输

出 f(x)

对已知的

变化因素

是

局部不变的

。这些变化因

素对应于沿

着的相同样

本聚集的流

形的移动。这

里实现

局部

不变性的方

法是要求 ∇xf(x)

与

已知流形的

切向 v

(i) 正交，或

者等价地通

过正

则化惩

罚 Ω 使 f

在 x 的 v

(i) 方

向的导数较

小：

Ω(f) =

∑

i

(

(∇xf(x)

⊤v

(i)

)

)2

. (7.67)

这个正则

化项当然可

以通过适当

的超参数缩

放，并且对于

大多数神经

网络，我们需

要对许多输

出求和 (此处

为描述简单

，f(x)

为唯一输出

)。与切面距离

算法一样，我

们根据切向

量推导先验

，通常从变换

（如平移、旋转

和缩放图像

）的效果获得

形式知

识。正

切传播不仅

用于监督学

习(Simard et al.,

1992)，还在强化

学习(Thrun, 1995)

中有所

应用。

正切传

播与数据集

增强密切相

关。在这两种

情况下，该算

法的用户通

过指定一组

应当不会改

变网络输出

的转换，将其

先验知识编

码至算法中

。不同的是在

数据集增

强

的情况下，网

络显式地训

练正确分类

这些施加大

量变换后产

生的不同输

入。正切

传播

不需要显式

访问一个新

的输入点。取

而代之，它解

析地对模型

正则化从而

在指

定转换

的方向抵抗

扰动。虽然这

种解析方法

是聪明优雅

的，但是它有

两个主要的

缺

点。首先，模

型的正则化

只能抵抗无

穷小的扰动

。显式的数据

集增强能抵

抗较大的扰

7.14

切面距离、正

切传播和流

形正切分类

器 233

x1

Normal

Tangent

图 7.9: 正切传

播算法

(Simard et al., 1992)

和流

形正切分类

器主要思想

的示意图 (Rifai et al.,

2011c)，它

们都正则化

分类器的输

出函数 f(x)。每条

曲线表示不

同类别的流

形，这里表示

嵌入二

维空

间中的一维

流形。在一条

曲线上，我们

选择单个点

并绘制一个

与类别流形

（平行并接触

流形）

相切的

向量以及与

类别流形（与

流形正交）垂

直的向量。在

多维情况下

，可以存在许

多切线方向

和

法线方向

。我们希望分

类函数在垂

直于流形方

向上快速改

变，并且在类

别流形的方

向上保持不

变。

正切传播

和流形正切

分类器都会

正则化 f(x)，使其

不随 x

沿流形

的移动而剧

烈变化。正切

传播需

要用

户手动指定

正切方向的

计算函数（例

如指定小平

移后的图像

保留在相同

类别的流形

中），而流

形正

切分类器通

过训练自编

码器拟合训

练数据来估

计流形的正

切方向。我们

将在第十四

章中讨论

使

用自编码器

来估计流形

。

动。其次，我们

很难在基于

整流线性单

元的模型上

使用无限小

的方法。这些

模型只能

通

过关闭单元

或缩小它们

的权重才能

缩小它们的

导数。它们不

能像sigmoid或tanh单

元

一样通过较

大权重在高

值处饱和以

收缩导数。数

据集增强在

整流线性单

元上工作

得

很好，因为不

同的整流单

元会在每一

个原始输入

的不同转换

版本上被激

活。

正切传播

也和双反向

传播(Drucker and LeCun, 1992)

以及对

抗训练(Szegedy

et al., 2014b;

Goodfellow et al., 2014b)

有关

联。双反向传

播正则化使

Jacobian矩阵

偏小，而

对抗训练找

到原输入附

近的点，训练

模型在这些

点上产生与

原来输入相

同的

输出。正

切传播和手

动指定转换

的数据集增

强都要求模

型在输入变

化的某些特

定的

方向上

保持不变。双

反向传播和

对抗训练都

要求模型对

输入所有方

向中的变化

（只

要该变化

较小）都应当

保持不变。正

如数据集增

强是正切传

播非无限小

的版本，对

抗

训练是双反

向传播非无

限小的版本

。

流形正切分

类器 (Rifai

et al., 2011d) 无需知

道切线向量

的先验。我们

将在第十

四

章看到，自编

码器可以估

算流形的切

向量。流形正

切分类器使

用这种技术

来避免

x2

234 第七

章

深度学习

中的正则化

用户指定切

向量。如图 14.10 所

示，这些估计

的切向量不

仅对图像经

典几何变换

（如

转化、旋转

和缩放）保持

不变，还必须

掌握对特定

对象（如正在

移动的身体

某些部

分）保

持不变的因

素。因此根据

流形正切分

类器提出的

算法相当简

单：（1）使用自

编

码器通过无

监督学习来

学习流形的

结构，以及（2）如

正切传播（式

(7.67) ）一样

使用这

些切面正则

化神经网络

分类器。

在本

章中，我们已

经描述了大

多数用于正

则化神经网

络的通用策

略。正则化是

机

器学习的

中心主题，因

此我们将不

时在其余各

章中重新回

顾。机器学习

的另一个中

心主题是优

化，我们将在

下一章描述

。

第八章 深度

模型中的优

化

深度学习

算法在许多

情况下都涉

及到优化。例

如，模型中的

进行推断（如

PCA）

涉及到求解

优化问题。我

们经常使用

解析优化去

证明或设计

算法。在深度

学习涉及

到

的诸多优化

问题中，最难

的是神经网

络训练。甚至

是用几百台

机器投入几

天到几

个月

来解决单个

神经网络训

练问题，也是

很常见的。因

为这其中的

优化问题很

重要，

代价也

很高，因此研

究者们开发

了一组专门

为此设计的

优化技术。本

章会介绍神

经

网络训练

中的这些优

化技术。

如果

你不熟悉基

于梯度优化

的基本原则

，我们建议回

顾第四章。该

章简要概述

了一般的数

值优化。

本章

主要关注这

一类特定的

优化问题：寻

找神经网络

上的一组参

数

θ，它能显

著

地降低代价

函数 J(θ)，该代价

函数通常包

括整个训练

集上的性能

评估和额外

的正

则化项

。

首先，我们会

介绍在机器

学习任务中

作为训练算

法使用的优

化与纯优化

有哪些

不同

。接下来，我们

会介绍导致

神经网络优

化困难的几

个具体挑战

。然后，我们会

介

绍几个实

用算法，包括

优化算法本

身和初始化

参数的策略

。更高级的算

法能够在训

练中自适应

调整学习率

，或者使用代

价函数二阶

导数包含的

信息。最后，我

们会介

绍几

个将简单优

化算法结合

成高级过程

的优化策略

，以此作为总

结。

8.1 学习和纯

优化有什么

不同

用于深

度模型训练

的优化算法

与传统的优

化算法在几

个方面有所

不同。机器学

习通常是间

接作用的。在

大多数机器

学习问题中

，我们关注某

些性能度量

P，其定

义于测

试集上并且

可能是不可

解的。因此，我

们只是间接

地优化

P。我们

希望通过

235

236 第

八章

深度模

型中的优化

降低代价函

数 J(θ) 来提高 P。这

一点与纯优

化不同，纯优

化最小化目

标

J 本身。训

练

深度模型的

优化算法通

常也会包括

一些针对机

器学习目标

函数的特定

结构进行的

特化。

通常，代

价函数可写

为训练集上

的平均，如

J(θ) = E(x,y)∼pˆdata L(f(x;

θ), y), (8.1)

其

中

L 是每个样

本的损失函

数，f(x; θ) 是输入

x 时

所预测的输

出，pˆdata 是经验分

布。监督学习

中，y 是目标输

出。在本章中

，我们会介绍

不带正则化

的监督学习

，L

的变量是 f(x; θ) 和

y。不难将这种

监督学习扩

展成其他形

式，如包括

θ 或

者 x 作

为参数

，或是去掉参

数 y，以发展不

同形式的正

则化或是无

监督学习。

式

(8.1) 定义了训练

集上的目标

函数。通常，我

们更希望最

小化取自数

据生成分

布

pdata 的期望，而不

仅仅是有限

训练集上的

对应目标函

数：

J

∗

(θ) = E(x,y)∼pdata L(f(x;

θ), y). (8.2)

8.1.1

经验风险

最小化

机器

学习算法的

目标是降低

式 (8.2) 所示的期

望泛化误差

。这个数据量

被称为

风

险

（risk）。在这里，我们

强调该期望

取自真实的

潜在分布 pdata。如

果我们知道

了真

实分布

pdata(x,

y)，那么最小化

风险变成了

一个可以被

优化算法解

决的优化问

题。然

而，我们

遇到的机器

学习问题，通

常是不知道

pdata(x, y)，只知道训练

集中的样本

。

将机器学习

问题转化回

一个优化问

题的最简单

方法是最小

化训练集上

的期望损

失

。这意味着用

训练集上的

经验分布 pˆ(x, y) 替

代真实分布

p(x,

y)。现在，我们将

最

小化 经验

风险（empirical risk）：

Ex,y∼pˆdata [L(f(x; θ), y)]

=

m

1

m∑

i=1

L(f(x

(i)

;

θ), y(i)

), (8.3)

其中 m 表

示训练样本

的数目。

基于

最小化这种

平均训练误

差的训练过

程被称为

经

验风险最小

化（empirical

risk minimization）。在这种情

况下，机器学

习仍然和传

统的直接优

化很相似。我

们

并不直接

最优化风险

，而是最优化

经验风险，希

望也能够很

大地降低风

险。一系列

不

同的理论构

造了一些条

件，使得在这

些条件下真

实风险的期

望可以下降

不同的量。

8.1 学

习和纯优化

有什么不同

237

然而，经验风

险最小化很

容易导致过

拟合。高容量

的模型会简

单地记住训

练集。

在很多

情况下，经验

风险最小化

并非真的可

行。最有效的

现代优化算

法是基于梯

度

下降的，但

是很多有用

的损失函数

，如 0 −

1 损失，没有

有效的导数

（导数要么为

零，要么处处

未定义）。这两

个问题说明

，在深度学习

中我们很少

使用经验风

险最小

化。反

之，我们会使

用一个稍有

不同的方法

，我们真正优

化的目标会

更加不同于

我

们希望优

化的目标。

8.1.2 代

理损失函数

和提前终止

有时，我们真

正关心的损

失函数（比如

分类误差）并

不能被高效

地优化。例如

，

即使对于线

性分类器而

言，精确地最

小化 0

− 1 损失通

常是不可解

的（复杂度是

输入

维数的

指数级别）(Marcotte

and Savard, 1992)。在

这种情况下

，我们通常会

优化 代

理损

失函数（surrogate loss function）。代理

损失函数作

为原目标的

代理，还具备

一

些优点。例

如，正确类别

的负对数似

然通常用作

0

− 1 损失的替代

。负对数似然

允许

模型估

计给定样本

的类别的条

件概率，如果

该模型效果

好，那么它能

够输出期望

最

小分类误

差所对应的

类别。

在某些

情况下，代理

损失函数比

原函数学到

的更多。例如

，使用对数似

然替代

函数

时，在训练集

上的 0

− 1 损失达

到 0

之后，测试

集上的 0 − 1

损失

还能持续下

降

很长一段

时间。这是因

为即使 0 −

1 损失

期望是零时

，我们还能拉

开不同类别

的距离

以改

进分类器的

鲁棒性，获得

一个更强壮

的、更值得信

赖的分类器

，从而，相对于

简单地最小

化训练集上

的平均 0

− 1 损失

，它能够从训

练数据中抽

取更多信息

。

一般的优化

和我们用于

训练算法的

优化有一个

重要不同：训

练算法通常

不会

停止在

局部极小点

。反之，机器学

习通常优化

代理损失函

数，但是在基

于提前终止

（第7.8 节）的收敛

条件满足时

停止。通常，提

前终止使用

真实潜在损

失函数，如验

证集上的 0 −

1 损

失，并设计为

在过拟合发

生之前终止

。与纯优化不

同的是，提前

终

止时代理

损失函数仍

然有较大的

导数，而纯优

化终止时导

数较小。

8.1.3

批量

算法和小批

量算法

机器

学习算法和

一般优化算

法不同的一

点是，机器学

习算法的目

标函数通常

可

以分解为

训练样本上

的求和。机器

学习中的优

化算法在计

算参数的每

一次更新时

通

常仅使用

整个代价函

数中一部分

项来估计代

价函数的期

望值。

238 第八章

深度模型中

的优化

例如

，最大似然估

计问题可以

在对数空间

中分解成各

个样本的总

和：

θML

= arg max

θ

m∑

i=1

log pmodel(x

(i)

, y(i)

;

θ). (8.4)

最大化这

个总和等价

于最大化训

练集在经验

分布上的期

望：

J(θ)

= Ex,y∼pˆdata log pmodel(x,

y; θ). (8.5)

优化算法

用到的目标

函数J

中的大

多数属性也

是训练集上

的期望。例如

，最常

用的属

性是梯度：

∇θJ(θ) =

Ex,y∼pˆdata∇θ log pmodel(x, y;

θ). (8.6)

准

确计算这个

期望的计算

代价非常大

，因为我们需

要在整个数

据集上的每

个样

本上评

估模型。在实

践中，我们可

以从数据集

中随机采样

少量的样本

，然后计算这

些样本上的

平均值。

回想

一下，n 个样本

均值的标准

差（式 (5.46) ）是

σ/

√

n，其中

σ 是样本值真

实

的标准差

。分母 √

n 表明使

用更多样本

来估计梯度

的方法的回

报是低于线

性的。比

较两

个假想的梯

度计算，一个

基于 100 个样本

，另一个基于

10, 000

个样本。后者

需

要的计算

量是前者的

100 倍，但却只降

低了 10

倍的均

值标准差。如

果能够快速

地

计算出梯

度估计值，而

不是缓慢地

计算准确值

，那么大多数

优化算法会

收敛地更快

（就总的计算

量而言，而不

是指更新次

数）。

另一个促

使我们从小

数目样本中

获得梯度的

统计估计的

动机是训练

集的冗余。

在

最坏的情况

下，训练集中

所有的

m 个样

本都是彼此

相同的拷贝

。基于采样的

梯度

估计可

以使用单个

样本计算出

正确的梯度

，而比原来的

做法少花了

m 倍时间。实践

中，我们不太

可能真的遇

到这种最坏

情况，但我们

可能会发现

大量样本都

对梯度做

出

了非常相似

的贡献。

使用

整个训练集

的优化算法

被称为 批量

（batch）或 确定性（deterministic）梯

度算法，因为

它们会在一

个大批量中

同时处理所

有样本。这个

术语可能有

点令人困

惑

，因为这个词

“批量’’ 也经常

被用来描述

小批量随机

梯度下降算

法中用到的

小批

量样本

。通常，术语 “批

量梯度下降

’’

指使用全部

训练集，而术

语 “批量’’ 单独

出现

时指一

组样本。例如

，我们普遍使

用术语

“批量

大小’’ 表示小

批量的大小

。

每次只使用

单个样本的

优化算法有

时被称为 随

机（stochastic）或者

在线

（on￾line）算法。术语 “在

线’’ 通常是指

从连续产生

样本的数据

流中抽取样

本的情况，而

不是从一个

固定大小的

训练集中遍

历多次采样

的情况。

8.1

学习

和纯优化有

什么不同 239

大

多数用于深

度学习的算

法介于以上

两者之间，使

用一个以上

，而又不是全

部

的训练样

本。传统上，这

些会被称为

小批量（minibatch）或

小

批量随机（minibatch

stochastic）方

法，现在通常

将它们简单

地称为 随机

（stochastic）方法。

随机方

法的典型示

例是随机梯

度下降，这将

在第8.3.1

节中详

细描述。

小批

量的大小通

常由以下几

个因素决定

：

• 更大的批量

会计算更精

确的梯度估

计，但是回报

却是小于线

性的。

• 极小批

量通常难以

充分利用多

核架构。这促

使我们使用

一些绝对最

小批量，低

于

这个值的小

批量处理不

会减少计算

时间。

•

如果批

量处理中的

所有样本可

以并行地处

理（通常确是

如此），那么内

存消耗

和批

量大小会正

比。对于很多

硬件设施，这

是批量大小

的限制因素

。

• 在某些硬件

上使用特定

大小的数组

时，运行时间

会更少。尤其

是在使用GPU

时

，

通常使用 2 的

幂数作为批

量大小可以

获得更少的

运行时间。一

般，2

的幂数的

取值范围是

32 到 256，16 有时在尝

试大模型时

使用。

• 可能是

由于小批量

在学习过程

中加入了噪

声，它们会有

一些正则化

效果 (Wilson

and

Martinez, 2003)。泛化误

差通常在批

量大小为 1 时

最好。因为梯

度估计的

高

方差，小批量

训练需要较

小的学习率

以保持稳定

性。因为降低

的学习率和

消

耗更多步

骤来遍历整

个训练集都

会产生更多

的步骤，所以

会导致总的

运行时间

非

常大。

不同的

算法使用不

同的方法从

小批量中获

取不同的信

息。有些算法

对采样误差

比其他算法

更敏感，这通

常有两个可

能原因。一个

是它们使用

了很难在少

量样本上

精

确估计的信

息，另一个是

它们以放大

采样误差的

方式使用了

信息。仅基于

梯度 g

的更新

方法通常相

对鲁棒，并能

使用较小的

批量获得成

功，如 100。使用Hessian矩

阵

H，计算如 H

−1

g

更

新的二阶方

法通常需要

更大的批量

，如 10, 000。这些大批

量需要最小

化估计 H

−1

g 的波

动。假设 H

被精

确估计，但是

有病态条件

数。乘以 H

或是

其逆会放大

之前存在的

误差（这个示

例中是指 g

的

估计误差）。即

使 H 被精确

估

计，g

中非常小

的变化也会

导致更新值

H

−1

g 中非常大的

变化。当然，我

们通常只

会

近似地估计

H，因此相对于

我们使用具

有较差条件

的操作去估

计 g，更新 H

−1

g

会含

有更多的误

差。

240 第八章

深

度模型中的

优化

小批量

是随机抽取

的这点也很

重要。从一组

样本中计算

出梯度期望

的无偏估计

要求这些样

本是独立的

。我们也希望

两个连续的

梯度估计是

互相独立的

，因此两个连

续的小批量

样本也应该

是彼此独立

的。很多现实

的数据集自

然排列，从而

使得连续

的

样本之间具

有高度相关

性。例如，假设

我们有一个

很长的血液

样本测试结

果清单。

清单

上的数据有

可能是这样

获取的，头五

个血液样本

于不同时间

段取自第一

个病人，

接下

来三个血液

样本取自第

二个病人，再

随后的血液

样本取自第

三个病人，等

等。如

果我们

从这个清单

上顺序抽取

样本，那么我

们的每个小

批量数据的

偏差都很大

，因

为这个小

批量很可能

只代表着数

据集上众多

患者中的某

一个患者。在

这种数据集

中

的顺序有

很大影响的

情况下，很有

必要在抽取

小批量样本

前打乱样本

顺序。对于非

常大的数据

集，如数据中

心含有几十

亿样本的数

据集，我们每

次构建小批

量样本时

都

将样本完全

均匀地抽取

出来是不太

现实的。幸运

的是，实践中

通常将样本

顺序打

乱一

次，然后按照

这个顺序存

储起来就足

够了。之后训

练模型时会

用到的一组

组小

批量连

续样本是固

定的，每个独

立的模型每

次遍历训练

数据时都会

重复使用这

个顺

序。然而

，这种偏离真

实随机采样

的方法并没

有很严重的

有害影响。不

以某种方式

打乱样本顺

序才会极大

地降低算法

的性能。

很多

机器学习上

的优化问题

都可以分解

成并行地计

算不同样本

上单独的更

新。

换言之，我

们在计算小

批量样本 X 上

最小化

J(X) 的更

新时，同时可

以计算其他

小

批量样本

上的更新。这

类异步并行

分布式方法

将在第12.1.3 节中

进一步讨论

。

小批量随机

梯度下降的

一个有趣动

机是，只要没

有重复使用

样本，它将遵

循着

真实泛

化误差（式 (8.2) ）的

梯度。很多小

批量随机梯

度下降方法

的实现都会

打乱数

据顺

序一次，然后

多次遍历数

据来更新参

数。第一次遍

历时，每个小

批量样本都

用

来计算真

实泛化误差

的无偏估计

。第二次遍历

时，估计将会

是有偏的，因

为它重新

抽

取了已经用

过的样本，而

不是从和原

先样本相同

的数据生成

分布中获取

新的无偏

的

样本。

我们不

难从在线学

习的情况中

看出随机梯

度下降最小

化泛化误差

的原因。这时

样本或者小

批量都是从

数据 流（stream）中抽

取出来的。换

言之，学习器

好像是一

个

每次看到新

样本的人，每

个样本 (x,

y) 都来

自数据生成

分布 pdata(x, y)，而不是

使

用大小固

定的训练集

。这种情况下

，样本永远不

会重复；每次

更新的样本

是从分布

pdata 中

采样获得的

无偏样本。

在

x

和 y 是离散时

，以上的等价

性很容易得

到。在这种情

况下，泛化误

差

8.2

神经网络

优化中的挑

战 241

（式(8.2) ）可以表

示为

J

∗

(θ) =

∑

x

∑

y

pdata(x, y)L(f(x; θ), y),

(8.7)

上式的

准确梯度为

g = ∇θJ

∗

(θ) = ∑

x

∑

y

pdata(x,

y)∇θL(f(x; θ), y). (8.8)

在式 (8.5) 和式 (8.6)

中

，我们已经在

对数似然中

看到了相同

的结果；现在

我们发现这

一点在包括

似然的其他

函数 L 上也是

成立的。在一

些关于 pdata

和 L 的

温和假设下

，

在

x 和 y 是连续

时也能得到

类似的结果

。

因此，我们可

以从数据生

成分布 pdata 抽取

小批量样本

{x

(1)

, . . .

, x

(m)} 以及对

应的

目标 y

(i)，然后计

算该小批量

上损失函数

关于对应参

数的梯度

gˆ

=

1

m

∇θ

∑

i

L(f(x

(i)

; θ), y(i)

).

(8.9)

以

此获得泛化

误差准确梯

度的无偏估

计。最后，在泛

化误差上使

用 SGD 方法在方

向

gˆ 上更新 θ。

当

然，这个解释

只能用于样

本没有重复

使用的情况

。然而，除非训

练集特别大

，

通常最好是

多次遍历训

练集。当多次

遍历数据集

更新时，只有

第一遍满足

泛化误差梯

度的无偏估

计。但是，额外

的遍历更新

当然会由于

减小训练误

差而得到足

够的好处，

以

抵消其带来

的训练误差

和测试误差

间差距的增

加。

随着数据

集的规模迅

速增长，超越

了计算能力

的增速，机器

学习应用每

个样本

只使

用一次的情

况变得越来

越常见，甚至

是不完整地

使用训练集

。在使用一个

非常

大的训

练集时，过拟

合不再是问

题，而欠拟合

和计算效率

变成了主要

的顾虑。读者

也可以参考

Bottou and Bousquet (2008a)

中关于训练

样本数目增

长时，泛化误

差上

计算瓶

颈影响的讨

论。

8.2 神经网络

优化中的挑

战

优化通常

是一个极其

困难的任务

。传统的机器

学习会小心

设计目标函

数和约束，

以

确保优化问

题是凸的，从

而避免一般

优化问题的

复杂度。在训

练神经网络

时，我

们肯定

会遇到一般

的非凸情况

。即使是凸优

化，也并非没

有任何问题

。在这一节中

，

我们会总结

几个训练深

度模型时会

涉及到的主

要挑战。

242 第八

章 深度模型

中的优化

8.2.1

病

态

在优化凸

函数时，会遇

到一些挑战

。这其中最突

出的是 Hessian 矩阵

H

的病

态。这是

数值优化、凸

优化或其他

形式的优化

中普遍存在

的问题，更多

细节请回顾

第 4.3.1 节。

病态问

题一般被认

为存在于神

经网络训练

过程中。病态

体现在随机

梯度下降会

‘‘卡’’ 在某些情

况，此时即使

很小的更新

步长也会增

加代价函数

。

回顾式 (4.9)

，代价

函数的二阶

泰勒级数展

开预测梯度

下降中的 −ϵg 会

增加

1

2

ϵ

2

g

⊤Hg − ϵg

⊤g

(8.10)

到代价

中。当 2

1

ϵ

2g

⊤Hg 超过

ϵg

⊤g 时

，梯度的病态

会成为问题

。判断病态是

否不利

于神

经网络训练

任务，我们可

以监测平方

梯度范数

g

⊤g 和

g

⊤Hg。在很多情况

中，

梯度范数

不会在训练

过程中显著

缩小，但是 g

⊤Hg 的

增长会超过

一个数量级

。其结

果是尽

管梯度很强

，学习会变得

非常缓慢，因

为学习率必

须收缩以弥

补更强的曲

率。

如图 8.1 所示

，成功训练的

神经网络中

，梯度显著增

加。

−50 0 50 100

150 200 250

Training

time (epochs)

−2

0

2

4

6

8

10

12

14

16

0 50 100 150

200 250

Training time

(epochs)

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

图

8.1: 梯度下

降通常不会

到达任何类

型的临界点

。此示例中，在

用于对象检

测的卷积网

络的整个

训

练期间，梯度

范数持续增

加。(左) 各个梯

度计算的范

数如何随时

间分布的散

点图。为了方

便作

图，每轮

仅绘制一个

梯度范数。我

们将所有梯

度范数的移

动平均绘制

为实曲线。梯

度范数明显

随时

间增加

，而不是如我

们所期望的

那样随训练

过程收敛到

临界点而减

小。(右) 尽管梯

度递增，训练

过程却相当

成功。验证集

上的分类误

差可以降低

到较低水平

。

尽管病态还

存在于除了

神经网络训

练的其他情

况中，有些适

用于其他情

况的解

决病

态的技术并

不适用于神

经网络。例如

，牛顿法在解

决带有病态

条件的 Hessian 矩

Gradient

norm

Classification error rate

8.2 神

经网络优化

中的挑战 243

阵

的凸优化问

题时，是一个

非常优秀的

工具，但是我

们将会在以

下小节中说

明牛顿

法运

用到神经网

络时需要很

大的改动。

8.2.2 局

部极小值

凸

优化问题的

一个突出特

点是其可以

简化为寻找

一个局部极

小点的问题

。任何

一个局

部极小点都

是全局最小

点。有些凸函

数的底部是

一个平坦的

区域，而不是

单

一的全局

最小点，但该

平坦区域中

的任意点都

是一个可以

接受的解。优

化一个凸问

题时，若发现

了任何形式

的临界点，我

们都会知道

已经找到了

一个不错的

可行解。

对于

非凸函数时

，如神经网络

，有可能会存

在多个局部

极小值。事实

上，几乎所

有

的深度模型

基本上都会

有非常多的

局部极小值

。然而，我们会

发现这并不

是主要

问题

。

由于 模型可

辨识性（model identifiability）问题

，神经网络和

任意具有多

个等

效参数

化潜变量的

模型都会具

有多个局部

极小值。如果

一个足够大

的训练集可

以唯

一确定

一组模型参

数，那么该模

型被称为可

辨认的。带有

潜变量的模

型通常是不

可

辨认的，因

为通过相互

交换潜变量

我们能得到

等价的模型

。例如，考虑神

经网络的

第

一层，我们可

以交换单元

i

和单元 j 的传

入权重向量

、传出权重向

量而得到等

价

的模型。如

果神经网络

有

m 层，每层有

n 个单元，那么

会有 n!

m 种排列

隐藏单元的

方式。这种不

可辨认性被

称为 权重空

间对称性（weight space

symmetry）。

除

了权重空间

对称性，很多

神经网络还

有其他导致

不可辨认的

原因。例如，在

任意整流线

性网络或者

maxout 网络中，我们

可以将传入

权重和偏置

扩大 α

倍，然

后

将传出权重

扩大 α

1

倍，而保

持模型等价

。这意味着，如

果代价函数

不包括如权

重

衰减这种

直接依赖于

权重而非模

型输出的项

，那么整流线

性网络或者

maxout 网络

的每一

个局部极小

点都在等价

的局部极小

值的

(m × n) 维双曲

线上。

这些模

型可辨识性

问题意味着

神经网络代

价函数具有

非常多、甚至

不可数无限

多的局部极

小值。然而，所

有这些由于

不可辨识性

问题而产生

的局部极小

值都有相

同

的代价函数

值。因此，这些

局部极小值

并非是非凸

所带来的问

题。

如果局部

极小值相比

全局最小点

拥有很大的

代价，局部极

小值会带来

很大的隐

患

。我们可以构

建没有隐藏

单元的小规

模神经网络

，其局部极小

值的代价比

全局最

小点

的代价大很

多 (Sontag and Sussman,

1989; Brady et al.,

1989; Gori and Tesi,

1992)。如果具有

很大代价的

局部极小值

是常见的，那

么这将给基

于梯度的优

化算法

244 第八

章 深度模型

中的优化

带

来极大的问

题。

对于实际

中感兴趣的

网络，是否存

在大量代价

很高的局部

极小值，优化

算法是

否会

碰到这些局

部极小值，都

是尚未解决

的公开问题

。多年来，大多

数从业者认

为局

部极小

值是困扰神

经网络优化

的常见问题

。如今，情况有

所变化。这个

问题仍然是

学

术界的热

点问题，但是

学者们现在

猜想，对于足

够大的神经

网络而言，大

部分局部极

小值都具有

很小的代价

函数，我们能

不能找到真

正的全局最

小点并不重

要，而是需

要

在参数空间

中找到一个

代价很小（但

不是最小）的

点 (Saxe et

al., 2013; Dauphin

et

al., 2014; Goodfellow et

al., 2015; Choromanska et

al., 2014)。

很多从业

者将神经网

络优化中的

所有困难都

归结于局部

极小值。我们

鼓励从业

者

要仔细分析

特定的问题

。一种能够排

除局部极小

值是主要问

题的检测方

法是画出

梯

度范数随时

间的变化。如

果梯度范数

没有缩小到

一个微小的

值，那么该问

题既不

是局

部极小值，也

不是其他形

式的临界点

。在高维空间

中，很难明确

证明局部极

小

值是导致

问题的原因

。许多并非局

部极小值的

结构也具有

很小的梯度

。

8.2.3

高原、鞍点和

其他平坦区

域

对于很多

高维非凸函

数而言，局部

极小值（以及

极大值）事实

上都远少于

另一

类梯度

为零的点：鞍

点。鞍点附近

的某些点比

鞍点有更大

的代价，而其

他点则有更

小的代价。在

鞍点处，Hessian 矩阵

同时具有正

负特征值。位

于正特征值

对应的特征

向量方向的

点比鞍点有

更大的代价

，反之，位于负

特征值对应

的特征向量

方向的点

有

更小的代价

。我们可以将

鞍点视为代

价函数某个

横截面上的

局部极小点

，同时也

可以

视为代价函

数某个横截

面上的局部

极大点。图 4.5 给

了一个示例

。

多类随机函

数表现出以

下性质：低维

空间中，局部

极小值很普

遍。在更高维

空

间中，局部

极小值很罕

见，而鞍点则

很常见。对于

这类函数 f :

R

n → R

而

言，鞍

点和局

部极小值的

数目比率的

期望随 n 指数

级增长。我们

可以从直觉

上理解这种

现

象——Hessian 矩阵在

局部极小点

处只有正特

征值。而在鞍

点处，Hessian 矩阵则

同

时具有正

负特征值。试

想一下，每个

特征值的正

负号由抛硬

币决定。在一

维情况下，

很

容易抛硬币

得到正面朝

上一次而获

取局部极小

点。在 n-维空间

中，要抛掷 n 次

硬

币都正面

朝上的难度

是指数级的

。具体可以参

考 Dauphin et al.

(2014)，它回顾了

相

关的理论

工作。

很多随

机函数一个

惊人性质是

，当我们到达

代价较低的

区间时，Hessian 矩阵

的特征值为

正的可能性

更大。和抛硬

币类比，这意

味着如果我

们处于低代

价的临界

8.2 神

经网络优化

中的挑战 245

点

时，抛掷硬币

正面朝上

n 次

的概率更大

。这也意味着

，局部极小值

具有低代价

的可

能性比

高代价要大

得多。具有高

代价的临界

点更有可能

是鞍点。具有

极高代价的

临

界点就很

可能是局部

极大值了。

以

上现象出现

在许多种类

的随机函数

中。那么是否

在神经网络

中也有发生

呢？

Baldi and Hornik

(1989) 从理论上

证明，不具非

线性的浅层

自编码器（第

十四章中

将

介绍的一种

将输出训练

为输入拷贝

的前馈网络

）只有全局极

小值和鞍点

，没有代

价比

全局极小值

更大的局部

极小值。他们

还发现这些

结果能够扩

展到不具非

线性的

更深

的网络上，不

过没有证明

。这类网络的

输出是其输

入的线性函

数，但它们仍

然有

助于分

析非线性神

经网络模型

，因为它们的

损失函数是

关于参数的

非凸函数。这

类

网络本质

上是多个矩

阵组合在一

起。Saxe et

al. (2013) 精确解析

了这类网络

中完整

的学

习动态，表明

这些模型的

学习能够捕

捉到许多在

训练具有非

线性激活函

数的深

度模

型时观察到

的定性特征

。Dauphin et al. (2014)

通过实验表

明，真实的神

经网

络也存

在包含很多

高代价鞍点

的损失函数

。Choromanska et al.

(2014) 提供了额外

的理论论点

，表明另一类

和神经网络

相关的高维

随机函数也

满足这种情

况。

鞍点激增

对于训练算

法来说有哪

些影响呢？对

于只使用梯

度信息的一

阶优化算

法

而言，目前情

况还不清楚

。鞍点附近的

梯度通常会

非常小。另一

方面，实验中

梯度

下降似

乎可以在许

多情况下逃

离鞍点。Goodfellow et al. (2015)

可视

化了最新神

经

网络的几

个学习轨迹

，图 8.2 给了一个

例子。这些可

视化显示，在

突出的鞍点

附近，

代价函

数都是平坦

的，权重都为

零。但是他们

也展示了梯

度下降轨迹

能够迅速逸

出

该区间。Goodfellow et al.

(2015) 也

主张，应该可

以通过分析

来表明连续

时间的梯度

下降会逃离

而不是吸引

到鞍点，但对

梯度下降更

现实的使用

场景来说，情

况或许会

有

所不同。

对于

牛顿法而言

，鞍点显然是

一个问题。梯

度下降旨在

朝

‘‘下坡’’ 移动

，而非

明确寻

求临界点。而

牛顿法的目

标是寻求梯

度为零的点

。如果没有适

当的修改，牛

顿法就会跳

进一个鞍点

。高维空间中

鞍点的激增

或许解释了

在神经网络

训练中为什

么二阶方法

无法成功取

代梯度下降

。Dauphin et

al. (2014) 介绍了二阶

优化的 无鞍

牛顿法（saddle-free

Newton method），并表

明和传统算

法相比有显

著改进。二阶

方

法仍然难

以扩展到大

型神经网络

，但是如果这

类无鞍算法

能够扩展的

话，还是很有

希望的。

除了

极小值和鞍

点，还存在其

他梯度为零

的点。例如从

优化的角度

看与鞍点很

相似的极大

值，很多算法

不会被吸引

到极大值，除

了未经修改

的牛顿法。和

极小值一

样

，许多种类的

随机函数的

极大值在高

维空间中也

是指数级稀

少。

246 第八章 深

度模型中的

优化

图 8.2: 神经

网络代价函

数的可视化

。这些可视化

对应用于真

实对象识别

和自然语言

处理任务的

前

馈神经网

络、卷积网络

和循环网络

而言是类似

的。令人惊讶

的是，这些可

视化通常不

会显示出很

多

明显的障

碍。大约 2012 年，在

随机梯度下

降开始成功

训练非常大

的模型之前

，相比这些投

影所显

示的

神经网络代

价函数的表

面通常被认

为有更多的

非凸结构。该

投影所显示

的主要障碍

是初始参

数

附近的高代

价鞍点，但如

由蓝色路径

所示，SGD 训练轨

迹能轻易地

逃脱该鞍点

。大多数训练

时

间花费在

横穿代价函

数中相对平

坦的峡谷，可

能由于梯度

中的高噪声

、或该区域中

Hessian 矩阵

的病态

条件，或者需

要经过间接

的弧路径绕

过图中可见

的高 ‘‘山” 。图经

Goodfellow et

al. (2015)

许可改编。

也

可能存在恒

值的、宽且平

坦的区域。在

这些区域，梯

度和

Hessian 矩阵都

是

零。这种退

化的情形是

所有数值优

化算法的主

要问题。在凸

问题中，一个

宽而平坦

的

区间肯定包

含全局极小

值，但是对于

一般的优化

问题而言，这

样的区域可

能会对

应着

目标函数中

一个较高的

值。

8.2.4 悬崖和梯

度爆炸

多层

神经网络通

常存在像悬

崖一样的斜

率较大区域

，如图

8.3 所示。这

是由于几

个

较大的权重

相乘导致的

。遇到斜率极

大的悬崖结

构时，梯度更

新会很大程

度地改

变参

数值，通常会

完全跳过这

类悬崖结构

。

不管我们是

从上还是从

下接近悬崖

，情况都很糟

糕，但幸运的

是我们可以

用使

用第 10.11.1 节

介绍的启发

式

梯度截断

（gradient clipping）来避免其严

重的后果。其

基本想法源

自梯度并没

有指明最佳

步长，只说明

了在无限小

区域内的最

佳方向。当

传

统的梯度下

降算法提议

更新很大一

步时，启发式

梯度截断会

干涉来减小

步长，从

Projection

2 of θ

J(θ)

Projection 1 of θ

8.2 神经

网络优化中

的挑战 247

w

b

图 8.3: 高

度非线性的

深度神经网

络或循环神

经网络的目

标函数通常

包含由几个

参数连乘而

导致的

参数

空间中尖锐

非线性。这些

非线性在某

些区域会产

生非常大的

导数。当参数

接近这样的

悬崖区

域时

，梯度下降更

新可以使参

数弹射得非

常远，可能会

使大量已完

成的优化工

作成为无用

功。图

经 Pascanu

et al. (2013a) 许可

改编。

而使其

不太可能走

出梯度近似

为最陡下降

方向的悬崖

区域。悬崖结

构在循环神

经网

络的代

价函数中很

常见，因为这

类模型会涉

及到多个因

子的相乘，其

中每个因子

对

应一个时

间步。因此，长

期时间序列

会产生大量

相乘。

8.2.5

长期依

赖

当计算图

变得极深时

，神经网络优

化算法会面

临的另外一

个难题就是

长期依

赖问

题——由于变深

的结构使模

型丧失了学

习到先前信

息的能力，让

优化变得极

其困难。深层

的计算图不

仅存在于前

馈网络，还存

在于之后介

绍的循环网

络中（在

第十

章中描述）。因

为循环网络

要在很长时

间序列的各

个时刻重复

应用相同操

作来构

建非

常深的计算

图，并且模型

参数共享，这

使问题更加

凸显。

例如，假

设某个计算

图中包含一

条反复与矩

阵 W 相乘的路

径。那么

t 步后

，相

当于乘以

Wt。假设 W

有特征

值分解 W = Vdiag(λ)V

−1。在这

种简单的情

况下，

很容易

看出

Wt =

(Vdiag(λ)V

−1

)

t

= Vdiag(λ)

tV

−1

. (8.11)

当特征

值 λi

不在 1 附近

时，若在量级

上大于 1

则会

爆炸；若小于

1 时则会消失

。梯

度消失与

爆炸问题（vanishing and

exploding gradient problem）是

指该计算图

上的 J(w;b)

248 第八章

深度模型中

的优化

梯度

也会因为 diag(λ)

t 大

幅度变化。梯

度消失使得

我们难以知

道参数朝哪

个方向移

动

能够改进代

价函数，而梯

度爆炸会使

得学习不稳

定。之前描述

的促使我们

使用梯

度截

断的悬崖结

构便是梯度

爆炸现象的

一个例子。

此

处描述的在

各时间步重

复与 W 相乘非

常类似于寻

求矩阵 W

的最

大特征值及

对应特征向

量的 幂方法

（power method）。从这个观点

来看，x

⊤Wt

最终会

丢弃 x

中所有

与 W

的主特征

向量正交的

成分。

循环网

络在各时间

步上使用相

同的矩阵 W，而

前馈网络并

没有。所以即

使使

用非常

深层的前馈

网络，也能很

大程度上有

效地避免梯

度消失与爆

炸问题

(Sussillo,

2014)。

在更

详细地描述

循环网络之

后，我们将会

在第 10.7

节进一

步讨论循环

网络训练

中

的挑战。

8.2.6 非精

确梯度

大多

数优化算法

的先决条件

都是我们知

道精确的梯

度或是 Hessian 矩阵

。在实践

中，通

常这些量会

有噪声，甚至

是有偏的估

计。几乎每一

个深度学习

算法都需要

基

于采样的

估计，至少使

用训练样本

的小批量来

计算梯度。

在

其他情况，我

们希望最小

化的目标函

数实际上是

难以处理的

。当目标函数

不

可解时，通

常其梯度也

是难以处理

的。在这种情

况下，我们只

能近似梯度

。这些问题

主

要出现在第

三部分中更

高级的模型

中。例如，对比

散度是用来

近似玻尔兹

曼机中

难以

处理的对数

似然梯度的

一种技术。

各

种神经网络

优化算法的

设计都考虑

到了梯度估

计的缺陷。我

们可以选择

比真

实损失

函数更容易

估计的代理

损失函数来

避免这个问

题。

8.2.7

局部和全

局结构间的

弱对应

迄今

为止，我们讨

论的许多问

题都是关于

损失函数在

单个点的性

质——若 J(θ)

是当前

点

θ 的病态条

件，或者 θ 在悬

崖中，或者

θ 是

一个下降方

向不明显的

鞍点，

那么会

很难更新当

前步。

如果该

方向在局部

改进很大，但

并没有指向

代价低得多

的遥远区域

，那么我们

有

可能在单点

处克服以上

所有困难，但

仍然表现不

佳。

8.2 神经网络

优化中的挑

战 249

Goodfellow et al. (2015)

认为大部

分训练的运

行时间取决

于到达解决

方案的轨

迹

长度。如图 8.2 所

示，学习轨迹

将花费大量

的时间探寻

一个围绕山

形结构的宽

弧。

大多数优

化研究的难

点集中于训

练是否找到

了全局最小

点、局部极小

点或是鞍

点

，但在实践中

神经网络不

会到达任何

一种临界点

。图 8.1 表明神经

网络通常不

会到

达梯度

很小的区域

。甚至，这些临

界点不一定

存在。例如，损

失函数 − log p(y

| x; θ)

可以

没有全局最

小点，而是当

随着训练模

型逐渐稳定

后，渐近地收

敛于某个值

。对

于具有离

散的 y 和 softmax

分布

p(y | x) 的分类器而

言，若模型能

够正确分类

训

练集上的

每个样本，则

负对数似然

可以无限趋

近但不会等

于零。同样地

，实值模型

p(y | x)

= N (y; f(θ),

β−1

) 的

负对数似然

会趋向于负

无穷——如果 f(θ)

能

够正确预

测

所有训练集

中的目标 y，学

习算法会无

限制地增加

β。图8.4 给出了一

个失败的例

子，即使没有

局部极小值

和鞍点，该例

还是不能从

局部优化中

找到一个良

好的代价

函

数值。

θ

图 8.4:

如果

局部表面没

有指向全局

解，基于局部

下坡移动的

优化可能就

会失败。这里

我们提供一

个例子，说明

即使在没有

鞍点或局部

极小值的情

况下，优化过

程会如何失

败。此例中的

代价函数仅

包含朝向低

值而不是极

小值的渐近

线。在这种情

况下，造成这

种困难的主

要原因是初

始化在 ‘‘山’’

的

错误一侧，并

且无法遍历

。在高维空间

中，学习算法

通常可以环

绕过这样的

高山，但是相

关的轨

迹可

能会很长，并

且导致过长

的训练时间

，如图

8.2 所示。

未

来的研究需

要进一步探

索影响学习

轨迹长度和

更好地表征

训练过程的

结果。

许多现

有研究方法

在求解具有

困难全局结

构的问题时

，旨在寻求良

好的初始点

，

而不是开发

非局部范围

更新的算法

。

梯度下降和

基本上所有

的可以有效

训练神经网

络的学习算

法，都是基于

局部较

J(θ)

250

第八

章 深度模型

中的优化

小

更新。之前的

小节主要集

中于为何这

些局部范围

更新的正确

方向难以计

算。我们

也许

能计算目标

函数的一些

性质，如近似

的有偏梯度

或正确方向

估计的方差

。在这

些情况

下，难以确定

局部下降能

否定义通向

有效解的足

够短的路径

，但我们并不

能

真的遵循

局部下降的

路径。目标函

数可能有诸

如病态条件

或不连续梯

度的问题，使

得梯度为目

标函数提供

较好近似的

区间非常小

。在这些情况

下，步长为 ϵ 的

局部下

降可

能定义了到

达解的合理

的短路经，但

是我们只能

计算步长为

δ ≪ ϵ 的局部下降

方向。在这些

情况下，局部

下降或许能

定义通向解

的路径，但是

该路径包含

很多次

更新

，因此遵循该

路径会带来

很高的计算

代价。有时，比

如说当目标

函数有一个

宽

而平的区

域，或是我们

试图寻求精

确的临界点

（通常来说后

一种情况只

发生于显式

求解临界点

的方法，如牛

顿法）时，局部

信息不能为

我们提供任

何指导。在这

些情况

下，局

部下降完全

无法定义通

向解的路径

。在其他情况

下，局部移动

可能太过贪

心，

朝着下坡

方向移动，却

和所有可行

解南辕北辙

，如图

8.4 所示，或

者是用舍近

求远的

方法

来求解问题

，如图 8.2

所示。目

前，我们还不

了解这些问

题中的哪一

个与神经网

络优化中的

难点最相关

，这是研究领

域的热点方

向。

不管哪个

问题最重要

，如果存在一

个区域，我们

遵循局部下

降便能合理

地直接

到达

某个解，并且

我们能够在

该良好区域

上初始化学

习，那么这些

问题都可以

避免。

最终的

观点还是建

议在传统优

化算法上研

究怎样选择

更佳的初始

化点，以此来

实现

目标更

切实可行。

8.2.8 优

化的理论限

制

一些理论

结果表明，我

们为神经网

络设计的任

何优化算法

都有性能限

制

(Blum

and Rivest, 1992;

Judd, 1989; Wolpert and

MacReady, 1997)。通常这些

结果不影

响

神经网络在

实践中的应

用。

一些理论

结果仅适用

于神经网络

的单元输出

离散值的情

况。然而，大多

数神经

网络

单元输出光

滑的连续值

，使得局部搜

索求解优化

可行。一些理

论结果表明

，存在

某类问

题是不可解

的，但很难判

断一个特定

问题是否属

于该类。其他

结果表明，寻

找给定规模

的网络的一

个可行解是

很困难的，但

在实际情况

中，我们通过

设置更多

参

数，使用更大

的网络，能轻

松找到可接

受的解。此外

，在神经网络

训练中，我们

通常不关注

某个函数的

精确极小点

，而只关注将

其值下降到

足够小以获

得一个良好

的泛化误差

。对优化算法

是否能完成

此目标进行

理论分析是

非常困难的

。因此，研

究优

化算法更现

实的性能上

界仍然是学

术界的一个

重要目标。

8.3 基

本算法 251

8.3

基本

算法

之前我

们已经介绍

了梯度下降

（第4.3 节），即沿着

整个训练集

的梯度方向

下降。

这可以

使用随机梯

度下降很大

程度地加速

，沿着随机挑

选的小批量

数据的梯度

下降

方向，就

像第 5.9 节和第

8.1.3 节中讨论的

一样。

8.3.1 随机梯

度下降

随机

梯度下降（SGD）及

其变种很可

能是一般机

器学习中应

用最多的优

化算法，

特别

是在深度学

习中。如第

8.1.3 节

中所讨论的

，按照数据生

成分布抽取

m 个小批

量（独

立同分布的

）样本，通过计

算它们梯度

均值，我们可

以得到梯度

的无偏估计

。

算法 8.1 展示了

如何沿着这

个梯度的估

计下降。

算法

8.1

随机梯度下

降（SGD）在第 k 个训

练迭代的更

新

Require:

学习率 ϵk

Require: 初

始参数

θ

while 停止

准则未满足

do

从训练集中

采包含

m 个样

本 {x

(1)

, . . .

, x

(m)} 的小批量

，其中

x

(i) 对应目

标为

y

(i)。

计算梯

度估计：gˆ ← +

m

1 ∇θ

∑

i L(f(x

(i)

;

θ), y

(i)

)

应用

更新：θ ← θ −

ϵgˆ

end while

SGD

算法中

的一个关键

参数是学习

率。之前，我们

介绍的 SGD 使用

固定的学

习

率。在实践中

，有必要随着

时间的推移

逐渐降低学

习率，因此我

们将第

k 步迭

代

的学习率

记作 ϵk。

这是因

为 SGD 中梯度估

计引入的噪

声源（m 个训练

样本的随机

采样）并不会

在极小点处

消失。相比之

下，当我们使

用批量梯度

下降到达极

小点时，整个

代价函

数的

真实梯度会

变得很小，之

后为 0，因此批

量梯度下降

可以使用固

定的学习率

。保

证 SGD

收敛的

一个充分条

件是

∞∑

k=1

ϵk

= ∞, (8.12)

252

第八章

深度模型中

的优化

且 ∞∑

k=1

ϵ

2

k <

∞. (8.13)

实

践中，一般会

线性衰减学

习率直到第

τ 次迭代：

ϵk = (1 −

α)ϵ0 + αϵτ (8.14)

其中

α = τ

k。在

τ 步迭代之

后，一般使 ϵ 保

持常数。

学习

率可通过试

验和误差来

选取，通常最

好的选择方

法是监测目

标函数值随

时

间变化的

学习曲线。与

其说是科学

，这更像是一

门艺术，我们

应该谨慎地

参考关于

这

个问题的大

部分指导。使

用线性策略

时，需要选择

的参数为 ϵ0，ϵτ，τ。通

常

τ 被

设为需

要反复遍历

训练集几百

次的迭代次

数。通常 ϵτ

应设

为大约 ϵ0 的 1%。主

要问

题是如

何设置 ϵ0。若 ϵ0 太

大，学习曲线

将会剧烈振

荡，代价函数

值通常会明

显增

加。温和

的振荡是良

好的，容易在

训练随机代

价函数（例如

使用 Dropout 的代价

函

数）时出现

。如果学习率

太小，那么学

习过程会很

缓慢。如果初

始学习率太

低，那么

学习

可能会卡在

一个相当高

的代价值。通

常，就总训练

时间和最终

代价值而言

，最优

初始学

习率会高于

大约迭代 100 次

左右后达到

最佳效果的

学习率。因此

，通常最好

是

检测最早的

几轮迭代，选

择一个比在

效果上表现

最佳的学习

率更大的学

习率，但

又不

能太大导致

严重的震荡

。

SGD 及相关的小

批量亦或更

广义的基于

梯度优化的

在线学习算

法，一个重要

的

性质是每

一步更新的

计算时间不

依赖训练样

本数目的多

寡。即使训练

样本数目非

常

大时，它们

也能收敛。对

于足够大的

数据集，SGD 可能

会在处理整

个训练集之

前就

收敛到

最终测试集

误差的某个

固定容差范

围内。

研究优

化算法的收

敛率，一般会

衡量 额外误

差（excess error）J(θ)−minθ J(θ)，

即当前代

价函数超出

最低可能代

价的量。SGD 应用

于凸问题时

，k 步迭代后的

额外

误差量

级是

O( √

1

k

)，在强凸

情况下是 O(

k

1

)。除

非假定额外

的条件，否则

这些界限

不

能进一步改

进。批量梯度

下降在理论

上比随机梯

度下降有更

好的收敛率

。然而，

Cramér-Rao 界限

(Cramér, 1946; Rao, 1945)

指

出，泛化误差

的下降速度

不会快于

O(

k

1

)。Bottou and Bousquet (2008b)

因

此认为对于

机器学习任

务，不值得探

寻收敛

快于

O(

k

1

) 的优化算法

——更快的收敛

可能对应着

过拟合。此外

，渐近分析掩

盖了随

机梯

度下降在少

量更新步之

后的很多优

点。对于大数

据集，SGD 只需非

常少量样本

计算梯度从

而实现初始

快速更新，远

远超过了其

缓慢的渐近

收敛。本章剩

余部分介

绍

的大多数算

法在实践中

都受益于这

种性质，但是

损失了常数

倍 O(

k

1

) 的渐近分

析。

8.3 基本算法

253

我们也可以

在学习过程

中逐渐增大

小批量的大

小，以此权衡

批量梯度下

降和随机梯

度下降两者

的优点。

了解

SGD 更多的信息

，请查看 Bottou

(1998)。

8.3.2 动量

虽然随机梯

度下降仍然

是非常受欢

迎的优化方

法，但其学习

过程有时会

很慢。

动量方

法

(Polyak, 1964) 旨在加速

学习，特别是

处理高曲率

、小但一致的

梯度，或是

带

噪声的梯度

。动量算法积

累了之前梯

度指数级衰

减的移动平

均，并且继续

沿该方

向移

动。动量的效

果如图8.5 所示

。

−30 −20

−10 0 10 20

−30

−20

−10

0

10

20

图 8.5:

动量的主

要目的是解

决两个问题

：Hessian 矩阵的病态

条件和随机

梯度的方差

。我们通

过此

图说明动量

如何克服这

两个问题的

第一个。等高

线描绘了一

个二次损失

函数（具有病

态条

件的

Hessian 矩

阵）。横跨轮廓

的红色路径

表示动量学

习规则所遵

循的路径，它

使该函数最

小化。

我们在

该路径的每

个步骤画一

个箭头，表示

梯度下降将

在该点采取

的步骤。我们

可以看到，一

个病

态条件

的二次目标

函数看起来

像一个长而

窄的山谷或

具有陡峭边

的峡谷。动量

正确地纵向

穿过峡

谷，而

普通的梯度

步骤则会浪

费时间在峡

谷的窄轴上

来回移动。比

较图 4.6 ，它也显

示了没有动

量的梯度下

降的行为。

从

形式上看，动

量算法引入

了变量

v 充当

速度角色——它

代表参数在

参数空间

移

动的方向和

速率。速度被

设为负梯度

的指数衰减

平均。名称 动

量（momentum）

来自物理

类比，根据牛

顿运动定律

，负梯度是移

动参数空间

中粒子的力

。动量在物

理

学上定义为

质量乘以速

度。在动量学

习算法中，我

们假设是单

位质量，因此

速度

向量 v

也

可以看作是

粒子的动量

。超参数α ∈ [0, 1)

决定

了之前梯度

的贡献衰减

得有

254 第八章

深度模型中

的优化

多快

。更新规则如

下：

v ← αv −

ϵ∇θ

(

m

1

m∑

i=1

L(f(x

(i)

; θ), y

(i)

)

)

, (8.15)

θ ← θ +

v. (8.16)

速度 v

累积

了梯度元素

∇θ( m

1 ∑m

i=1 L(f(x

(i)

;

θ), y

(i)

))。相对于

ϵ，α 越大

，之前梯度

对

现在方向的

影响也越大

。带动量的 SGD

算

法如算法8.2 所

示。

算法 8.2

使用

动量的随机

梯度下降（SGD）

Require: 学

习率 ϵ，动量参

数

α

Require: 初始参数

θ，初始速度 v

while 没

有达到停止

准则 do

从训练

集中采包含

m

个样本 {x

(1)

,

. . . ,

x

(m)} 的小

批量，对应目

标为 y

(i)。

计算梯

度估计：g ← 1

m ∇θ

∑

i

L(f(x

(i)

; θ),

y

(i)

)

计算

速度更新：v

← αv − ϵg

应

用更新：θ ← θ +

v

end while

之前

，步长只是梯

度范数乘以

学习率。现在

，步长取决于

梯度序列的

大小和排

列

。当许多连续

的梯度指向

相同的方向

时，步长最大

。如果动量算

法总是观测

到梯

度 g，那么

它会在方向

−g 上不停加速

，直到达到最

终速度，其中

步长大小为

ϵ

∥g∥

1 − α

. (8.17)

因此将动量

的超参数视

为 1

1

−α 有助于理

解。例如，α =

0.9 对应

着最大速度

10 倍

于梯度下

降算法。

在实

践中，α 的一般

取值为 0.5，0.9 和

0.99。和

学习率一样

，α 也会随着时

间

不断调整

。一般初始值

是一个较小

的值，随后会

慢慢变大。随

着时间推移

调整 α

没

有收

缩 ϵ 重要。

我们

可以将动量

算法视为模

拟连续时间

下牛顿动力

学下的粒子

。这种物理类

比

有助于直

觉上理解动

量和梯度下

降算法是如

何表现的。

粒

子在任意时

间点的位置

由 θ(t)

给定。粒子

会受到净力

f(t)。该力会导致

粒子

加速：

f(t) =

∂

2

∂t2

θ(t).

(8.18)

8.3 基

本算法 255

与其

将其视为位

置的二阶微

分方程，我们

不如引入表

示粒子在时

间 t 处速度的

变量

v(t)，将牛顿

动力学重写

为一阶微分

方程：

v(t) = ∂

∂tθ(t),

(8.19)

f(t) = ∂

∂tv(t). (8.20)

由此，动

量算法包括

通过数值模

拟求解微分

方程。求解微

分方程的一

个简单数值

方

法是欧拉

方法，通过在

每个梯度方

向上小且有

限的步来简

单模拟该等

式定义的动

力

学。

这解释

了动量更新

的基本形式

，但具体什么

是力呢？力正

比于代价函

数的负梯

度

−∇θJ(θ)。该力推动粒

子沿着代价

函数表面下

坡的方向移

动。梯度下降

算法基于

每

个梯度简单

地更新一步

，而使用动量

算法的牛顿

方案则使用

该力改变粒

子的速度。

我

们可以将粒

子视作在冰

面上滑行的

冰球。每当它

沿着表面最

陡的部分下

降时，它

会累

积继续在该

方向上滑行

的速度，直到

其开始向上

滑动为止。

另

一个力也是

必要的。如果

代价函数的

梯度是唯一

的力，那么粒

子可能永远

不

会停下来

。想象一下，假

设理想情况

下冰面没有

摩擦，一个冰

球从山谷的

一端下滑，

上

升到另一端

，永远来回振

荡。要解决这

个问题，我们

添加另一个

正比于 −v(t) 的

力

。在物理术语

中，此力对应

于粘性阻力

，就像粒子必

须通过一个

抵抗介质，如

糖

浆。这会导

致粒子随着

时间推移逐

渐失去能量

，最终收敛到

局部极小点

。

为什么要特

别使用 −v(t) 和粘

性阻力呢？部

分原因是因

为

−v(t) 在数学上

的便

利——速度

的整数幂很

容易处理。然

而，其他物理

系统具有基

于速度的其

他整数幂

的

其他类型的

阻力。例如，颗

粒通过空气

时会受到正

比于速度平

方的湍流阻

力，而颗

粒沿

着地面移动

时会受到恒

定大小的摩

擦力。这些选

择都不合适

。湍流阻力，正

比于

速度的

平方，在速度

很小时会很

弱。不够强到

使粒子停下

来。非零值初

始速度的粒

子仅受到湍

流阻力，会从

初始位置永

远地移动下

去，和初始位

置的距离大

概正比于

O(log t)。因

此我们必须

使用速度较

低幂次的力

。如果幂次为

零，相当于干

摩擦，那

么力

太强了。当代

价函数的梯

度表示的力

很小但非零

时，由于摩擦

导致的恒力

会使

得粒子

在达到局部

极小点之前

就停下来。粘

性阻力避免

了这两个问

题——它足够弱

，

可以使梯度

引起的运动

直到达到最

小，但又足够

强，使得坡度

不够时可以

阻止运动。

256

第

八章 深度模

型中的优化

8.3.3 Nesterov 动量

受 Nesterov 加速

梯度算法 (Nesterov,

1983, 2004) 启

发，Sutskever et

al. (2013)

提出了动

量算法的一

个变种。这种

情况的更新

规则如下：

v

← αv − ϵ∇θ

[

m

1

m∑

i=1

L

(

f(x

(i)

; θ +

αv), y

(i)

)

]

, (8.21)

θ

← θ + v,

(8.22)

其

中参数 α 和

ϵ 发

挥了和标准

动量方法中

类似的作用

。Nesterov 动量和标准

动量之

间的

区别体现在

梯度计算上

。Nesterov

动量中，梯度

计算在施加

当前速度之

后。因此，

Nesterov 动量

可以解释为

往标准动量

方法中添加

了一个校正

因子。完整的

Nesterov

动量算法如

算法

8.3 所示。

算

法 8.3

使用Nesterov 动量

的随机梯度

下降（SGD）

Require: 学习率

ϵ，动量参数

α

Require: 初

始参数 θ，初始

速度

v

while 没有达

到停止准则

do

从训练集中

采包含

m 个样

本 {x

(1)

, . . .

, x

(m)} 的小批量

，对应目标为

y

(i)。

应用临时更

新：˜θ ← θ

+ αv

计算梯度

（在临时点）：g ←

1

m ∇θ˜

∑

i L(f(x

(i)

;

˜θ), y

(i)

)

计

算速度更新

：v ← αv −

ϵg

应用更新：θ ← θ

+ v

end while

在

凸批量梯度

的情况下，Nesterov 动

量将额外误

差收敛率从

O(1/k)（k 步后）

改进到

O(1/k

2

)，如 Nesterov (1983)

所示。可惜

，在随机梯度

的情况下，Nesterov

动

量没有改进

收敛率。

8.4 参数

初始化策略

有些优化算

法本质上是

非迭代的，只

是求解一个

解点。有些其

它优化算法

本质

上是迭

代的，但是应

用于这一类

的优化问题

时，能在可接

受的时间内

收敛到可接

受

的解，并且

与初始值无

关。深度学习

训练算法通

常没有这两

种奢侈的性

质。深度学

8.4 参

数初始化策

略

257

习模型的

训练算法通

常是迭代的

，因此要求使

用者指定一

些开始迭代

的初始点。此

外，训练深度

模型是一个

足够困难的

问题，以致于

大多数算法

都很大程度

地受到初

始

化选择的影

响。初始点能

够决定算法

是否收敛，有

些初始点十

分不稳定，使

得该

算法会

遭遇数值困

难，并完全失

败。当学习收

敛时，初始点

可以决定学

习收敛得多

快，以及是否

收敛到一个

代价高或低

的点。此外，差

不多代价的

点可以具有

区别极

大的

泛化误差，初

始点也可以

影响泛化。

现

代的初始化

策略是简单

的、启发式的

。设定改进的

初始化策略

是一项困难

的

任务，因为

神经网络优

化至今还未

被很好地理

解。大多数初

始化策略基

于在神经网

络初始化时

实现一些很

好的性质。然

而，我们并没

有很好地理

解这些性质

中的哪些会

在学习开始

进行后的哪

些情况下得

以保持。进一

步的难点是

，有些初始点

从优化的

观

点看或许是

有利的，但是

从泛化的观

点看是不利

的。我们对于

初始点如何

影响泛

化的

理解是相当

原始的，几乎

没有提供如

何选择初始

点的任何指

导。

也许完全

确知的唯一

特性是初始

参数需要在

不同单元间

‘‘破坏对称性

’’。如果具

有相

同激活函数

的两个隐藏

单元连接到

相同的输入

，那么这些单

元必须具有

不同的

初始

参数。如果它

们具有相同

的初始参数

，然后应用到

确定性损失

和模型的确

定性

学习算

法将一直以

相同的方式

更新这两个

单元。即使模

型或训练算

法能够使用

随机

性为不

同的单元计

算不同的更

新（例如使用

Dropout的训练），通常

来说，最好还

是

初始化每

个单元使其

和其他单元

计算不同的

函数。这或许

有助于确保

没有输入模

式

丢失在前

向传播的零

空间中，没有

梯度模式丢

失在反向传

播的零空间

中。每个单元

计算不同函

数的目标促

使了参数的

随机初始化

。我们可以明

确地搜索一

大组彼此互

不相同的基

函数，但这经

常会导致明

显的计算代

价。例如，如果

我们有和输

出一样

多的

输入，我们可

以使用 Gram-Schmidt 正交

化于初始的

权重矩阵，保

证每个单元

计算彼此非

常不同的函

数。在高维空

间上使用高

熵分布来随

机初始化，计

算代价小

并

且不太可能

分配单元计

算彼此相同

的函数。

通常

情况下，我们

可以为每个

单元的偏置

设置启发式

挑选的常数

，仅随机初始

化权重。额外

的参数（例如

用于编码预

测条件方差

的参数）通常

和偏置一样

设置为

启发

式选择的常

数。

我们几乎

总是初始化

模型的权重

为高斯或均

匀分布中随

机抽取的值

。高斯或均

匀

分布的选择

似乎不会有

很大的差别

，但也没有被

详尽地研究

。然而，初始分

布的

大小确

实对优化过

程的结果和

网络泛化能

力都有很大

的影响。

更大

的初始权重

具有更强的

破坏对称性

的作用，有助

于避免冗余

的单元。它们

258 第八章 深度

模型中的优

化

也有助于

避免在每层

线性成分的

前向或反向

传播中丢失

信号——矩阵中

更大的值在

矩阵乘法中

有更大的输

出。如果初始

权重太大，那

么会在前向

传播或反向

传播中产

生

爆炸的值。在

循环网络中

，很大的权重

也可能导致

混沌（chaos）（对于输

入中很

小的

扰动非常敏

感，导致确定

性前向传播

过程表现随

机）。在一定程

度上，梯度爆

炸

问题可以

通过梯度截

断来缓解（执

行梯度下降

步骤之前设

置梯度的阈

值）。较大的权

重也会产生

使得激活函

数饱和的值

，导致饱和单

元的梯度完

全丢失。这些

竞争因素

决

定了权重的

理想初始大

小。

关于如何

初始化网络

，正则化和优

化有着非常

不同的观点

。优化观点建

议权重

应该

足够大以成

功传播信息

，但是正则化

希望其小一

点。诸如随机

梯度下降这

类对

权重较

小的增量更

新，趋于停止

在更靠近初

始参数的区

域（不管是由

于卡在低梯

度

的区域，还

是由于触发

了基于过拟

合 的提前终

止准则）的优

化算法倾向

于最终参数

应接近于初

始参数。回顾

第 7.8 节，在某些

模型上，提前

终止的梯度

下降等价于

权重

衰减。在

一般情况下

，提前终止的

梯度下降和

权重衰减不

同，但是提供

了一个宽松

的类比去考

虑初始化的

影响。我们可

以将初始化

参数 θ 为 θ0

类比

于强置均值

为 θ0

的高斯先

验 p(θ)。从这个角

度来看，选择

θ0

接近 0 是有道

理的。这个先

验表明，单

元

间彼此互不

交互比交互

更有可能。只

有在目标函

数的似然项

表达出对交

互很强的

偏

好时，单元才

会交互。另一

方面，如果我

们初始化 θ0 为

很大的值，那

么我们的先

验指定了哪

些单元应互

相交互，以及

它们应如何

交互。

有些启

发式方法可

用于选择权

重的初始大

小。一种初始

化

m 个输入和

n 输出

的全连

接层的权重

的启发式方

法是从分布

U(−

1

√m

, √

1

m

) 中采样权重

，而

Glorot and

Bengio (2010)

建议使用

标准初始化

（normalized initialization）

Wi,j ∼

U

(

−

√

m +

6

n

,

√

m

6

+ n

)

.

(8.23)

后一种启发

式方法初始

化所有的层

，折衷于使其

具有相同激

活方差和使

其具有相同

梯度方差之

间。这假设网

络是不含非

线性的链式

矩阵乘法，据

此推导得出

。现实的神

经

网络显然会

违反这个假

设，但很多设

计于线性模

型的策略在

其非线性对

应中的效

果

也不错。

Saxe et al. (2013)

推荐

初始化为随

机正交矩阵

，仔细挑选负

责每一层非

线性缩

放或

增益 (gain) 因子

g。他

们得到了用

于不同类型

的非线性激

活函数的特

定缩放因

子

。这种初始化

方案也是启

发于不含非

线性的矩阵

相乘序列的

深度网络。在

该模型

下，这

个初始化方

案保证了达

到收敛所需

的训练迭代

总数独立于

深度。

8.4

参数初

始化策略 259

增

加缩放因子

g 将网络推向

网络前向传

播时激活范

数增加，反向

传播时梯度

范

数增加的

区域。Sussillo (2014) 表明，正

确设置缩放

因子足以训

练深达 1000

层的

网

络，而不需

要使用正交

初始化。这种

方法的一个

重要观点是

，在前馈网络

中，激活

和梯

度会在每一

步前向传播

或反向传播

中增加或缩

小，遵循随机

游走行为。这

是因

为前馈

网络在每一

层使用了不

同的权重矩

阵。如果该随

机游走调整

到保持范数

，那

么前馈网

络能够很大

程度地避免

相同权重矩

阵用于每层

的梯度消失

与爆炸问题

，如

第 8.2.5 节所述

。

可惜，这些初

始权重的最

佳准则往往

不会带来最

佳效果。这可

能有三种不

同的

原因。首

先，我们可能

使用了错误

的标准——它实

际上并不利

于保持整个

网络信号

的

范数。其次，初

始化时强加

的性质可能

在学习开始

进行后不能

保持。最后，该

标

准可能成

功提高了优

化速度，但意

外地增大了

泛化误差。在

实践中，我们

通常需要

将

权重范围视

为超参数，其

最优值大致

接近，但并不

完全等于理

论预测。

数值

范围准则的

一个缺点是

，设置所有的

初始权重具

有相同的标

准差，例如

1

√m

，会

使得层很大

时每个单一

权重会变得

极其小。Martens (2010) 提出

了一种被称

为 稀疏初始

化（sparse

initialization）的替代方

案，每个单元

初始化为恰

好有 k 个

非零

权重。这个想

法保持该单

元输入的总

数量独立于

输入数目

m，而

不使单一权

重

元素的大

小随 m 缩小。稀

疏初始化有

助于实现单

元之间在初

始化时更具

多样性。但

是

，获得较大取

值的权重也

同时被加了

很强的先验

。因为梯度下

降需要很长

时间缩

小 ‘‘不

正确’’ 的大值

，这个初始化

方案可能会

导致某些单

元出问题，例

如

maxout 单

元有几

个过滤器，互

相之间必须

仔细调整。

计

算资源允许

的话，将每层

权重的初始

数值范围设

为超参数通

常是个好主

意，使

用第 11.4.2 节

介绍的超参

数搜索算法

，如随机搜索

，挑选这些数

值范围。是否

选择使

用密

集或稀疏初

始化也可以

设为一个超

参数。作为替

代，我们可以

手动搜索最

优初

始范围

。一个好的挑

选初始数值

范围的经验

法则是观测

单个小批量

数据上的激

活或

梯度的

幅度或标准

差。如果权重

太小，那么当

激活值在小

批量上前向

传播于网络

时，

激活值的

幅度会缩小

。通过重复识

别具有小得

不可接受的

激活值的第

一层，并提高

其权重，最终

有可能得到

一个初始激

活全部合理

的网络。如果

学习在这点

上仍然很

慢

，观测梯度的

幅度或标准

差可能也会

有所帮助。这

个过程原则

上是自动的

，且通

常计算

量低于基于

验证集误差

的超参数优

化，因为它是

基于初始模

型在单批数

据上

的行为

反馈，而不是

在验证集上

训练模型的

反馈。由于这

个协议很长

时间都被启

发

式使用，最

近 Mishkin

and Matas (2015) 更正式地

研究了该协

议。

目前为止

，我们关注在

权重的初始

化上。幸运的

是，其他参数

的初始化通

常更

260 第八章

深度模型中

的优化

容易

。

设置偏置的

方法必须和

设置权重的

方法协调。设

置偏置为零

通常在大多

数权重

初始

化方案中是

可行的。存在

一些我们可

能设置偏置

为非零值的

情况：

• 如果偏

置是作为输

出单元，那么

初始化偏置

以获取正确

的输出边缘

统计通常是

有利的。要做

到这一点，我

们假设初始

权重足够小

，该单元的输

出仅由偏置

决

定。这说明

设置偏置为

应用于训练

集上输出边

缘统计的激

活函数的逆

。例如，

如果输

出是类上的

分布，且该分

布是高度偏

态分布，第 i 类

的边缘概率

由某个

向量

c 的第 i 个元素

给定，那么我

们可以通过

求解方程

softmax(b) = c 来

设

置偏置向

量 b。这不仅适

用于分类器

，也适用于我

们将在第三

部分遇到的

模型，

例如自

编码器和玻

尔兹曼机。这

些模型拥有

输出类似于

输入数据 x

的

网络层，

非常

有助于初始

化这些层的

偏置以匹配

x 上的边缘分

布。

•

有时，我们

可能想要选

择偏置以避

免初始化引

起太大饱和

。例如，我们可

能会

将 ReLU 的隐

藏单元设为

0.1

而非 0，以避免

ReLU 在初始化时

饱和。尽管这

种方法违背

不希望偏置

具有很强输

入的权重初

始化准则。例

如，不建议使

用随

机游走

初始化

(Sussillo, 2014)。

• 有时

，一个单元会

控制其他单

元能否参与

到等式中。在

这种情况下

，我们有

一个

单元输出 u，另

一个单元 h ∈

[0, 1]，那

么我们可以

将 h 视作门，以

决定

uh ≈ 1 还是

uh ≈ 0。在

这种情形下

，我们希望设

置偏置 h，使得

在初始化的

大

多数情况

下 h ≈ 1。否则，u

没有

机会学习。例

如，Jozefowicz et al. (2015)

提

议设置

LSTM 模型遗忘门

的偏置为 1，如

第

10.10 节所述。

另

一种常见类

型的参数是

方差或精确

度参数。例如

，我们用以下

模型进行带

条

件方差估

计的线性回

归

p(y | x) =

N (y | w

⊤x + b, 1/β),

(8.24)

其中 β 是精

确度参数。通

常我们能安

全地初始化

方差或精确

度参数为

1。另

一种方

法假

设初始权重

足够接近零

，设置偏置可

以忽略权重

的影响，然后

设定偏置以

产生

输出的

正确边缘均

值，并将方差

参数设置为

训练集输出

的边缘方差

。

除了这些初

始化模型参

数的简单常

数或随机方

法，还有可能

使用机器学

习初始

化模

型参数。在本

书第三部分

讨论的一个

常用策略是

使用相同的

输入数据集

，用无

监督模

型训练出来

的参数来初

始化监督模

型。我们也可

以在相关问

题上使用监

督训

8.5 自适应

学习率算法

261

练。即使是在

一个不相关

的任务上运

行监督训练

，有时也能得

到一个比随

机初始化

具

有更快收敛

率的初始值

。这些初始化

策略有些能

够得到更快

的收敛率和

更好的泛

化

误差，因为它

们编码了模

型初始参数

的分布信息

。其他策略显

然效果不错

的原因

主要

在于它们设

置参数为正

确的数值范

围，或是设置

不同单元计

算互相不同

的函数。

8.5 自适

应学习率算

法

神经网络

研究员早就

意识到学习

率肯定是难

以设置的超

参数之一，因

为它对模

型

的性能有显

著的影响。正

如我们在第

4.3

节和第 8.2 节中

所探讨的，损

失通常高度

敏感于参数

空间中的某

些方向，而不

敏感于其他

。动量算法可

以在一定程

度缓解这

些

问题，但这样

做的代价是

引入了另一

个超参数。在

这种情况下

，自然会问有

没有

其他方

法。如果我们

相信方向敏

感度在某种

程度是轴对

齐的，那么每

个参数设置

不

同的学习

率，在整个学

习过程中自

动适应这些

学习率是有

道理的。

Delta-bar-delta 算法

(Jacobs,

1988) 是一个早期

的在训练时

适应模型参

数各

自学习

率的启发式

方法。该方法

基于一个很

简单的想法

，如果损失对

于某个给定

模

型参数的

偏导保持相

同的符号，那

么学习率应

该增加。如果

对于该参数

的偏导变化

了符号，那么

学习率应减

小。当然，这种

方法只能应

用于全批量

优化中。

最近

，提出了一些

增量（或者基

于小批量）的

算法来自适

应模型参数

的学习率。

这

节将简要回

顾其中一些

算法。

8.5.1 AdaGrad

AdaGrad 算法，如

算法 8.4 所示，独

立地适应所

有模型参数

的学习率，缩

放每

个参数

反比于其所

有梯度历史

平方值总和

的平方根 (Duchi et al.,

2011)。具

有损失

最大

偏导的参数

相应地有一

个快速下降

的学习率，而

具有小偏导

的参数在学

习率上

有相

对较小的下

降。净效果是

在参数空间

中更为平缓

的倾斜方向

会取得更大

的进步。

在凸

优化背景中

，AdaGrad

算法具有一

些令人满意

的理论性质

。然而，经验上

已经发现，对

于训练深度

神经网络模

型而言，从训

练开始时积

累梯度平方

会导致有

效

学习率过早

和过量的减

小。AdaGrad 在某些深

度学习模型

上效果不错

，但不是全

部

。

262 第八章 深度

模型中的优

化

算法

8.4 AdaGrad 算法

Require: 全局学习率

ϵ

Require: 初始参数 θ

Require:

小

常数 δ，为了数

值稳定大约

设为 10−7

初始化

梯度累积变

量

r = 0

while

没有达到

停止准则 do

从

训练集中采

包含 m

个样本

{x

(1)

, .

. . , x

(m)} 的小批量，对

应目标为 y

(i)。

计

算梯度：g ← 1

m

∇θ

∑

i L(f(x

(i)

; θ), y

(i)

)

累积

平方梯度：r ←

r + g ⊙

g

计

算更新：∆θ ← −

ϵ

δ+

√

r

⊙ g （逐元

素地应用除

和求平方根

）

应用更新：θ

← θ + ∆θ

end while

8.5.2 RMSProp

RMSProp 算

法 (Hinton, 2012)

修改 AdaGrad 以在

非凸设定下

效果更好，改

变梯度积累

为指数加权

的移动平均

。AdaGrad 旨在应用于

凸问题时快

速收敛。当应

用于非凸函

数训练神经

网络时，学习

轨迹可能穿

过了很多不

同的结构，最

终到达一

个

局部是凸碗

的区域。AdaGrad 根据

平方梯度的

整个历史收

缩学习率，可

能使得学

习

率在达到这

样的凸结构

前就变得太

小了。RMSProp 使用指

数衰减平均

以丢弃遥远

过去的历史

，使其能够在

找到凸碗状

结构后快速

收敛，它就像

一个初始化

于该碗状

结

构的 AdaGrad 算法实

例。

RMSProp

的标准形

式如算法 8.5 所

示，结合 Nesterov

动量

的形式如算

法 8.6 所

示。相比

于

AdaGrad，使用移动

平均引入了

一个新的超

参数ρ，用来控

制移动平均

的

长度范围

。

经验上，RMSProp 已被

证明是一种

有效且实用

的深度神经

网络优化算

法。目前

它是

深度学习从

业者经常采

用的优化方

法之一。

8.5.3 Adam

Adam

(Kingma and Ba, 2014)

是另

一种学习率

自适应的优

化算法，如算

法8.7 所

示。“Adam’’ 这个

名字派生自

短语

“adaptive moments’’。早期算

法背景下，它

也许

8.5 自适应

学习率算法

263

算法 8.5 RMSProp 算法

Require: 全

局学习率 ϵ，衰

减速率 ρ

Require: 初始

参数 θ

Require:

小常数

δ，通常设为 10−6（用

于被小数除

时的数值稳

定）

初始化累

积变量 r

= 0

while 没有

达到停止准

则

do

从训练集

中采包含 m 个

样本

{x

(1)

, .

. . , x

(m)} 的小批

量，对应目标

为 y

(i)。

计算梯度

：g ← 1

m

∇θ

∑

i L(f(x

(i)

; θ), y

(i)

)

累积平方梯

度：r ←

ρr + (1 −

ρ)g ⊙ g

计算参数

更新：∆θ

= −

ϵ √

δ+r

⊙ g (

√

δ

1

+r

逐元素

应用)

应用更

新：θ ← θ

+ ∆θ

end while

最好被看

作结合 RMSProp 和具

有一些重要

区别的动量

的变种。首先

，在 Adam

中，

动量直

接并入了梯

度一阶矩（指

数加权）的估

计。将动量加

入 RMSProp 最直观的

方法是将动

量应用于缩

放后的梯度

。结合缩放的

动量使用没

有明确的理

论动机。其

次

，Adam 包括偏置修

正，修正从原

点初始化的

一阶矩（动量

项）和（非中心

的）二

阶矩的

估计（算法8.7 ）。RMSProp

也

采用了（非中

心的）二阶矩

估计，然而缺

失了

修正因

子。因此，不像

Adam，RMSProp 二阶矩估计

可能在训练

初期有很高

的偏置。

Adam

通常

被认为对超

参数的选择

相当鲁棒，尽

管学习率有

时需要从建

议的默认修

改。

8.5.4 选择正确

的优化算法

在本节中，我

们讨论了一

系列算法，通

过自适应每

个模型参数

的学习率以

解决

优化深

度模型中的

难题。此时，一

个自然的问

题是：该选择

哪种算法呢

？

遗憾的是，目

前在这一点

上没有达成

共识。Schaul et al. (2014)

展示了

许多优

化算

法在大量学

习任务上极

具价值的比

较。虽然结果

表明，具有自

适应学习率

（以

RMSProp 和

AdaDelta 为代表

）的算法族表

现得相当鲁

棒，不分伯仲

，但没有哪个

算法能脱颖

而出。

目前，最

流行并且使

用很高的优

化算法包括

SGD、具动量的 SGD、RMSProp、

具

动量的 RMSProp、AdaDelta 和 Adam。此

时，选择哪一

个算法似乎

主要取决于

264

第八章 深度

模型中的优

化

算法 8.6

使用

Nesterov 动量的 RMSProp 算法

Require:

全局学习率

ϵ，衰减速率 ρ，动

量系数 α

Require:

初始

参数 θ，初始参

数 v

初始化累

积变量

r = 0

while

没有

达到停止准

则 do

从训练集

中采包含 m

个

样本 {x

(1)

,

. . . ,

x

(m)} 的小批

量，对应目标

为 y

(i)。

计算临时

更新：˜θ ← θ

+ αv

计算梯

度：g ←

1

m ∇θ˜

∑

i L(f(x

(i)

;

˜θ), y

(i)

)

累积梯度

：r ← ρr +

(1 − ρ)g ⊙

g

计算速度更

新：v ← αv

−

ϵ√

r ⊙

g ( √

1

r 逐元素应

用)

应用更新

：θ ←

θ + v

end

while

使用者对算

法的熟悉程

度（以便调节

超参数）。

8.6 二阶

近似方法

265

算

法 8.7 Adam

算法

Require: 步长

ϵ （建议默认为

：0.001）

Require: 矩估计的指

数衰减速率

，ρ1 和 ρ2

在区间 [0, 1) 内

。（建议默认为

：分别

为 0.9 和 0.999）

Require: 用

于数值稳定

的小常数 δ （建

议默认为：10−8）

Require: 初

始参数 θ

初始

化一阶和二

阶矩变量

s = 0, r

= 0

初

始化时间步

t =

0

while 没有达到停

止准则 do

从训

练集中采包

含 m 个样本 {x

(1)

, . .

. , x

(m)}

的

小批量，对应

目标为 y

(i)。

计算

梯度：g

← 1

m ∇θ

∑

i L(f(x

(i)

; θ), y

(i)

)

t ← t

+ 1

更新有

偏一阶矩估

计：s ←

ρ1s + (1 −

ρ1)g

更新有偏

二阶矩估计

：r ← ρ2r

+ (1 − ρ2)g

⊙ g

修正一阶矩

的偏差：ˆs ←

s

1−ρ

t

1

修正

二阶矩的偏

差：rˆ ← r

1−ρ

t

2

计算更新

：∆θ =

−ϵ √

ˆr

ˆs

+δ （逐元素应用

操作）

应用更

新：θ ←

θ + ∆θ

end

while

8.6 二阶近似

方法

在本节

中，我们会讨

论训练深度

神经网络的

二阶方法。参

考LeCun

et al. (1998a)

了解该问

题的早期处

理方法。为表

述简单起见

，我们只考察

目标函数为

经验风险：

J(θ) = Ex,y∼pˆdata(x,y)

[L(f(x;

θ), y)] =

m

1

m∑

i=1

L(f(x

(i)

; θ), y(i)

). (8.25)

然

而，我们在这

里讨论的方

法很容易扩

展到更一般

的目标函数

，例如，第七章

讨论

的包括

参数正则项

的函数。

266 第八

章 深度模型

中的优化

8.6.1

牛

顿法

在第 4.3 节

，我们介绍了

二阶梯度方

法。与一阶方

法相比，二阶

方法使用二

阶导

数改进

了优化。最广

泛使用的二

阶方法是牛

顿法。我们现

在更详细地

描述牛顿法

，重

点在其应

用于神经网

络的训练。

牛

顿法是基于

二阶泰勒级

数展开在某

点 θ0

附近来近

似 J(θ) 的优化方

法，其忽

略了

高阶导数：

J(θ) ≈ J(θ0) +

(θ − θ0)

⊤∇θJ(θ0)

+ 1

2

(θ

− θ0)

⊤H(θ −

θ0), (8.26)

其

中 H

是 J 相对于

θ 的

Hessian 矩阵在 θ0 处

的估计。如果

我们再求解

这个函数

的

临界点，我们

将得到牛顿

参数更新规

则：

θ

∗ =

θ0 − H

−1∇θJ(θ0).

(8.27)

因此，对于

局部的二次

函数（具有正

定的 H ），用

H

−1 重新

调整梯度，牛

顿法会直

接

跳到极小值

。如果目标函

数是凸的但

非二次的（有

高阶项），该更

新将是迭代

的，

得到和牛

顿法相关的

算法，如算法

8.8 所示。

对于非

二次的表面

，只要Hessian 矩阵保

持正定，牛顿

法能够迭代

地应用。这意

味着一个两

步迭代过程

。首先，更新或

计算

Hessian 逆（通过

更新二阶近

似）。其次，

根据

式 (8.27)

更新参数

。

在第 8.2.3 节，我们

讨论了牛顿

法只适用于

Hessian

矩阵是正定

的情况。在深

度

学习中，目

标函数的表

面通常非凸

（有很多特征

），如鞍点。因此

使用牛顿法

是有问

题的

。如果Hessian 矩阵的

特征值并不

都是正的，例

如，靠近鞍点

处，牛顿法实

际上

会导致

更新朝错误

的方向移动

。这种情况可

以通过正则

化 Hessian 矩阵来避

免。常用

的正

则化策略包

括在

Hessian 矩阵对

角线上增加

常数 α。正则化

更新变为

θ

∗ = θ0 −

[H(f(θ0)) + αI]

−1∇θf(θ0).

(8.28)

这

个正则化策

略用于牛顿

法的近似，例

如 Levenberg-Marquardt 算法

(Levenberg,

1944; Marquardt, 1963)，只要

Hessian

矩阵的负特

征值仍然相

对接近零，效

果就会

很好

。在曲率方向

更极端的情

况下，α 的值必

须足够大，以

抵消负特征

值。然而，如

果

α

持续增加，Hessian 矩

阵会变得由

对角矩阵 αI 主

导，通过牛顿

法所选择的

方向

会收敛

到普通梯度

除以 α。当很强

的负曲率存

在时，α 可能需

要特别大，以

致于牛顿

法

比选择合适

学习率的梯

度下降的步

长更小。

8.6 二阶

近似方法 267

算

法

8.8 目标为 J(θ) =

m

1 ∑m

i=1

L(f(x

(i)

; θ),

y(i)

) 的

牛顿法

Require:

初始

参数 θ0

Require: 包含

m 个

样本的训练

集

while 没有达到

停止准则

do

计

算梯度：g ← 1

m ∇θ

∑

i

L(f(x

(i)

; θ),

y

(i)

)

计算

Hessian

矩阵：H ← 1

m

∇2

θ

∑

i

L(f(x

(i)

; θ),

y

(i)

)

计算

Hessian 逆

：H

−1

计算更新：∆θ

= −H

−1

g

应

用更新：θ = θ +

∆θ

end while

除了

目标函数的

某些特征带

来的挑战，如

鞍点，牛顿法

用于训练大

型神经网络

还

受限于其

显著的计算

负担。Hessian 矩阵中

元素数目是

参数数量的

平方，因此，如

果

参数数目

为 k（甚至是在

非常小的神

经网络中

k 也

可能是百万

级别），牛顿法

需要计

算 k

× k 矩

阵的逆，计算

复杂度为 O(k

3

)。另

外，由于参数

将每次更新

都会改变，每

次训练迭代

都需要计算

Hessian 矩阵的逆。其

结果是，只有

参数很少的

网络才能在

实

际中用牛

顿法训练。在

本节的剩余

部分，我们将

讨论一些试

图保持牛顿

法优点，同

时

避免计算障

碍的替代算

法。

8.6.2 共轭梯度

共轭梯度是

一种通过迭

代下降的 共

轭方向（conjugate

directions）以有

效避

免 Hessian 矩阵

求逆计算的

方法。这种方

法的灵感来

自于对最速

下降方法弱

点的仔

细研

究（详细信息

请查看第 4.3 节

），其中线搜索

迭代地用于

与梯度相关

的方向上。

图

8.6

说明了该方

法在二次碗

型目标中如

何表现的，是

一个相当低

效的来回往

复，锯

齿形模

式。这是因为

每一个由梯

度给定的线

搜索方向，都

保证正交于

上一个线搜

索

方向。

假设

上一个搜索

方向是

dt−1。在极

小值处，线搜

索终止，方向

dt−1 处的方向导

数为零：∇θJ(θ) · dt−1

= 0。因为

该点的梯度

定义了当前

的搜索方向

，dt = ∇θJ(θ)

将不会贡献

于方向 dt−1。因此

方向 dt 正交于

dt−1。最速下降多

次迭代中，方

向

dt−1

和 dt 之间的

关系如图

8.6 所

示。如图展示

的，下降正交

方向的选择

不会保持前

一搜

索方向

上的最小值

。这产生了锯

齿形的过程

。在当前梯度

方向下降到

极小值，我们

268 第八章

深度

模型中的优

化

−30 −20 −10

0 10 20

−30

−20

−10

0

10

20

图 8.6: 将最速

下降法应用

于二次代价

表面。在每个

步骤，最速下

降法沿着由

初始点处的

梯度定义

的

线跳到最低

代价的点。这

解决了图 4.6 中

使用固定学

习率所遇到

的一些问题

，但即使使用

最佳步

长，算

法仍然朝最

优方向曲折

前进。根据定

义，在沿着给

定方向的目

标最小值处

，最终点处的

梯度

与该方

向正交。

必须

重新最小化

之前梯度方

向上的目标

。因此，通过遵

循每次线搜

索结束时的

梯度，

我们在

某种程度上

撤销了在之

前线搜索的

方向上取得

的进展。共轭

梯度试图解

决这

个问题

。

在共轭梯度

法中，我们寻

求一个和先

前线搜索方

向 共轭（conjugate）的搜

索方

向，即它

不会撤销该

方向上的进

展。在训练迭

代 t

时，下一步

的搜索方向

dt 的形式

如下

：

dt

= ∇θJ(θ) + βtdt−1,

(8.29)

其中，系数 βt 的

大小控制我

们应沿方向

dt−1

加回多少到

当前搜索方

向上。

如果 d

⊤

t Hdt−1 = 0，其

中

H 是 Hessian 矩阵，则

两个方向

dt 和

dt−1 被称为共

轭

的。

适应共轭

的直接方法

会涉及到 H 特

征向量的计

算以选择 βt。这

将无法满足

我们

的开发

目标：寻找在

大问题比牛

顿法计算更

加可行的方

法。我们能否

不进行这些

计

算而得到

共轭方向？幸

运的是这个

问题的答案

是肯定的。

两

种用于计算

βt 的流行方法

是：

1. Fletcher-Reeves:

βt =

∇θJ(θt)

⊤∇θJ(θt)

∇θJ(θt−1)⊤∇θJ(θt−1)

(8.30)

8.6 二阶近似

方法 269

2.

Polak-Ribière:

βt =

(∇θJ(θt)

− ∇θJ(θt−1))⊤∇θJ(θt)

∇θJ(θt−1)⊤∇θJ(θt−1)

(8.31)

对于二

次曲面而言

，共轭方向确

保梯度沿着

前一方向大

小不变。因此

，我们在前一

方向上仍然

是极小值。其

结果是，在 k-维

参数空间中

，共轭梯度只

需要至多 k 次

线

搜索就能

达到极小值

。共轭梯度算

法如算法 8.9 所

示。

算法

8.9 共轭

梯度方法

Require: 初

始参数

θ0

Require: 包含

m 个样本的训

练集

初始化

ρ0 = 0

初始化

g0 = 0

初始

化

t = 1

while

没有达到

停止准则 do

初

始化梯度 gt

= 0

计

算梯度：gt ←

1

m ∇θ

∑

i L(f(x

(i)

;

θ), y

(i)

)

计算

βt =

(gt−gt−1

)

⊤gt

g⊤

t−1

gt−1

(Polak-Ribière)

(非线性共轭

梯度：视情况

可重置 βt 为零

，例如

t 是常数

k 的倍数时，如

k =

5)

计算搜索方

向：ρt = −gt

+ βtρt−1

执行线搜

索寻找：ϵ

∗

= argminϵ m

1

∑m

i=1 L(f(x

(i)

; θt + ϵρt),

y

(i)

)

（对于

真正二次的

代价函数，存

在

ϵ

∗ 的解析解

，而无需显式

地搜索）

应用

更新：θt+1

= θt + ϵ

∗ρt

t ← t

+ 1

end while

非线性

共轭梯度： 目

前，我们已经

讨论了用于

二次目标函

数的共轭梯

度法。当然，

本

章我们主要

关注于探索

训练神经网

络和其他相

关深度学习

模型的优化

方法，其对

应

的目标函数

比二次函数

复杂得多。或

许令人惊讶

，共轭梯度法

在这种情况

下仍然

是适

用的，尽管需

要作一些修

改。没有目标

是二次的保

证，共轭方向

也不再保证

在

以前方向

上的目标仍

是极小值。其

结果是，非线

性共轭梯度

算法会包括

一些偶尔的

重设，共轭梯

度法沿未修

改的梯度重

启线搜索。

270 第

八章

深度模

型中的优化

实践者报告

在实践中使

用非线性共

轭梯度算法

训练神经网

络是合理的

，尽管在

开始

非线性共轭

梯度前使用

随机梯度下

降迭代若干

步来初始化

效果更好。另

外，尽

管（非线

性）共轭梯度

算法传统上

作为批方法

，小批量版本

已经成功用

于训练神经

网络 (Le

et al., 2011)。针对神

经网路的共

轭梯度应用

早已被提出

，例如缩放的

共轭

梯度算

法

(Moller, 1993)。

8.6.3 BFGS

Broyden-Fletcher-Goldfarb-Shanno（BFGS）算法具有

牛顿法的一

些优

点，但没

有牛顿法的

计算负担。在

这方面，BFGS 和 CG

很

像。然而，BFGS 使用

了

一个更直

接的方法近

似牛顿更新

。回顾牛顿更

新由下式给

出

θ

∗ = θ0 −

H

−1∇θJ(θ0), (8.32)

其中，H

是 J 相

对于 θ

的 Hessian 矩阵

在 θ0

处的估计

。运用牛顿法

的主要计算

难

点在于计

算Hessian 逆 H

−1。拟牛顿

法所采用的

方法（BFGS 是其中

最突出的）是

使

用矩阵 Mt

近

似逆，迭代地

低秩更新精

度以更好地

近似 H

−1。

BFGS

近似的

说明和推导

出现在很多

关于优化的

教科书中，包

括Luenberger

(1984)。

当 Hessian

逆近似

Mt 更新时，下降

方向 ρt 为

ρt = Mtgt。该方

向上的线搜

索

用于决定

该方向上的

步长

ϵ

∗。参数的

最后更新为

：

θt+1 =

θt + ϵ

∗ρt

. (8.33)

和共轭梯度

法相似，BFGS 算法

迭代一系列

线搜索，其方

向含二阶信

息。然而

和共

轭梯度不同

的是，该方法

的成功并不

严重依赖于

线搜索寻找

该方向上和

真正极

小值

很近的一点

。因此，相比于

共轭梯度，BFGS 的

优点是其花

费较少的时

间改进每

个

线搜索。在另

一方面，BFGS

算法

必须存储 Hessian 逆

矩阵 M，需要

O(n

2

) 的

存

储空间，使

BFGS 不适用于大

多数具有百

万级参数的

现代深度学

习模型。

存 储

受

限 的 BFGS（或 L-BFGS）

通

过 避 免 存

储

完 整 的 Hessian

逆 近

似 M，

BFGS

算法的存

储代价可以

显著降低。L-BFGS 算

法使用和 BFGS 算

法相同的方

法计

算 M 的近

似，但起始假

设是 M(t−1)

是单位

矩阵，而不是

一步一步都

要存储近似

。

如果使用精

确的线搜索

，L-BFGS 定义的方向

会是相互共

轭的。然而，不

同于共轭梯

8.7 优化策略和

元算法

271

度法

，即使只是近

似线搜索的

极小值，该过

程的效果仍

然不错。这里

描述的无存

储

的 L-BFGS

方法可

以拓展为包

含 Hessian 矩阵更多

的信息，每步

存储一些用

于更新

M

的向

量，且每步的

存储代价是

O(n)。

8.7 优化策略和

元算法

许多

优化技术并

非真正的算

法，而是一般

化的模板，可

以特定地产

生算法，或

是

并入到很多

不同的算法

中。

8.7.1 批标准化

批标准化 (Ioffe

and Szegedy, 2015) 是

优化深度神

经网络中最

激动人心的

最新创

新之

一。实际上它

并不是一个

优化算法，而

是一个自适

应的重参数

化的方法，试

图

解决训练

非常深的模

型的困难。

非

常深的模型

会涉及多个

函数或层组

合。在其他层

不改变的假

设下，梯度用

于

如何更新

每一个参数

。在实践中，我

们同时更新

所有层。当我

们进行更新

时，可能会

发

生一些意想

不到的结果

，这是因为许

多组合在一

起的函数同

时改变时，计

算更新

的假

设是其他函

数保持不变

。举一个简单

的例子，假设

我们有一个

深度神经网

络，每

一层只

有一个单元

，并且在每个

隐藏层不使

用激活函数

：yˆ =

xw1w2w3 . . .

wl。此处，

wi 表示用

于层 i

的权重

。层 i 的输出是

hi =

hi−1wi。输出 yˆ 是输入

x 的线性函数

，

但是权重 wi 的

非线性函数

。假设我们的

代价函数 yˆ

上

的梯度为 1，所

以我们希望

稍

稍降低 yˆ。然

后反向传播

算法可以计

算梯度

g = ∇wyˆ。想想

我们在更新

w ←

w − ϵg

时会发生什

么。近似

yˆ 的一

阶泰勒级数

会预测 yˆ 的值

下降

ϵg

⊤g。如果我

们希望 yˆ 下

降

0.1，那么梯度中

的一阶信息

表明我们应

设置学习率

ϵ 为 0.1

g⊤g。然而，实际

的更新

将包

括二阶，三阶

，直到 l 阶的影

响。yˆ 的更新值

为

x(w1 − ϵg1)(w2 −

ϵg2). . .(wl −

ϵgl), (8.34)

这个更新

中所产生的

一个二阶项

示例是 ϵ

2

g1g2

∏l

i=3

wi 。如果

∏l

i=3 wi

很小，那么该

项可以忽略

不计。而如果

层 3 到层 l

的权

重都比 1 大时

，该项可能会

指数级大。这

使得我们很

难选择一个

合适的学习

率，因为某一

层中参数更

新的效果很

大程度上取

决于其他所

有层。二阶优

化算法通过

考虑二阶相

互影响来解

决这个问题

，但我们可

以

看到，在非常

深的网络中

，更高阶的相

互影响会很

显著。即使是

二阶优化算

法，计

272 第八章

深度模型中

的优化

算代

价也很高，并

且通常需要

大量近似，以

免真正计算

所有的重要

二阶相互作

用。因

此对于

n

> 2 的情况，建立

n 阶优化算法

似乎是无望

的。那么我们

可以做些什

么呢？

批标准

化提出了一

种几乎可以

重参数化所

有深度网络

的优雅方法

。重参数化显

著减少了多

层之间协调

更新的问题

。批标准化可

应用于网络

的任何输入

层或隐藏层

。

设 H 是需要标

准化的某层

的小批量激

活函数，排布

为设计矩阵

，每个样本的

激活出

现在

矩阵的每一

行中。为了标

准化 H，我们将

其替换为

H

′

=

H − µ

σ

, (8.35)

其

中

µ 是包含每

个单元均值

的向量，σ 是包

含每个单元

标准差的向

量。此处的算

术

是基于广

播向量

µ 和向

量 σ 应用于矩

阵

H 的每一行

。在每一行内

，运算是逐元

素

的，因此 Hi,j

标

准化为减去

µj 再除以 σj。网络

的其余部分

操作 H

′ 的方式

和原网

络操

作 H

的方式一

样。

在训练阶

段，

µ =

m

1 ∑

i

Hi,: (8.36)

和

σ

=

√

δ +

m

1 ∑

i

(H − µ)

2

i

, (8.37)

其中

δ 是

个很小的正

值，比如 10−8，以强

制避免遇到

√

z

的梯度在 z = 0

处

未定义

的问

题。至关重要

的是，我们反

向传播这些

操作，来计算

均值和标准

差，并应用它

们

于标准化

H。这意味着，梯

度不会再简

单地增加 hi

的

标准差或均

值；标准化操

作会

除掉这

一操作的影

响，归零其在

梯度中的元

素。这是批标

准化方法的

一个重大创

新。

以前的方

法添加代价

函数的惩罚

，以鼓励单元

标准化激活

统计量，或是

在每个梯度

下降步骤之

后重新标准

化单元统计

量。前者通常

会导致不完

全的标准化

，而后者通

常

会显著地消

耗时间，因为

学习算法会

反复改变均

值和方差而

标准化步骤

会反复抵

消

这种变化。批

标准化重参

数化模型，以

使一些单元

总是被定义

标准化，巧妙

地回

避了这

两个问题。

在

测试阶段，µ 和

σ

可以被替换

为训练阶段

收集的运行

均值。这使得

模型可以

对

单一样本评

估，而无需使

用定义于整

个小批量的

µ 和 σ。

回顾例子

yˆ = xw1w2 .

. . wl，我们看到，我

们可以通过

标准化 hl−1

很大

程度地

解决

了学习这个

模型的问题

。假设 x 采样自

一个单位高

斯。那么

hl−1 也是

来自高

斯，因

为从 x

到 hl 的变

换是线性的

。然而，hl−1 不再有

零均值和单

位方差。使用

批

8.7 优化策略

和元算法 273

标

准化后，我们

得到的归一

化

hˆ

l−1 恢复了零

均值和单位

方差的特性

。对于底层的

几

乎任意更

新而言，hˆ

l−1 仍然

保持着单位

高斯。然后输

出 yˆ 可以学习

为一个简单

的线

性函数

yˆ = wlhˆ

l−1。现在学习这

个模型非常

简单，因为低

层的参数在

大多数情况

下

没有什么

影响；它们的

输出总是重

新标准化为

单位高斯。只

在少数个例

中，低层会

有

影响。改变某

个低层权重

为 0，可能使输

出退化；改变

低层权重的

符号可能反

转

hˆ

l−1 和 y 之间的

关系。这些情

况都是非常

罕见的。没有

标准化，几乎

每一个更新

都

会对 hl−1 的统

计量有着极

端的影响。因

此，批标准化

显著地使得

模型更易学

习。在

这个示

例中，容易学

习的代价是

使得底层网

络没有用。在

我们的线性

示例中，较低

层不再有任

何有害的影

响，但它们也

不再有任何

有益的影响

。这是因为我

们已经标

准

化了一阶和

二阶统计量

，这是线性网

络可以影响

的所有因素

。在具有非线

性激活

函数

的深度神经

网络中，较低

层可以进行

数据的非线

性变换，所以

它们仍然是

有用

的。批标

准化仅标准

化每个单元

的均值和方

差，以稳定化

学习，但允许

单元和单个

单元的非线

性统计量之

间的关系发

生变化。

由于

网络的最后

一层能够学

习线性变换

，实际上我们

可能希望移

除一层内单

元

之间的所

有线性关系

。事实上，这是

Guillaume Desjardins (2015) 中采用的方

法，

为批标准

化提供了灵

感。令人遗憾

的是，消除所

有的线性关

联比标准化

各个独立单

元的均值和

标准差代价

更高，因此批

标准化仍是

迄今最实用

的方法。

标准

化一个单元

的均值和标

准差会降低

包含该单元

的神经网络

的表达能力

。为

了保持网

络的表现力

，通常会将批

量隐藏单元

激活 H

替换为

γH

′ + β，而不是简单

地使用标准

化的

H

′。变量 γ 和

β

是允许新变

量有任意均

值和标准差

的学习参数

。

乍一看，这似

乎是无用的

——为什么我们

将均值设为

0，然后又引入

参数允许它

被重

设为任

意值 β？答案是

新的参数可

以表示旧参

数作为输入

的同一族函

数，但是新参

数有不同的

学习动态。在

旧参数中，H

的

均值取决于

H 下层中参数

的复杂关联

。在

新参数中

，γH

′

+ β 的均值仅由

β 确定。新参数

很容易通过

梯度下降来

学习。

大多数

神经网络层

会采取 ϕ(XW + b)

的形

式，其中 ϕ 是某

个固定的非

线性激

活函

数，如整流线

性变换。自然

想到我们应

该将批标准

化应用于输

入

X 还是变换

后

的值 XW

+ b。Ioffe and Szegedy

(2015) 推荐

后者。更具体

地，XW + b

应替换为

XW 的标准化形

式。偏置项应

被忽略，因为

参数 β 会加入

批标准化重

参数化，它是

冗余的。一层

的输入通常

是前一层的

非线性激活

函数（如整流

线性函数）的

输出。因

此，输

入的统计量

更符合非高

斯，而更不服

从线性操作

的标准化。

第

九章所述的

卷积网络，在

特征映射中

每个空间位

置同样地标

准化 µ 和

σ 是很

重要的，能使

特征映射的

统计量在不

同的空间位

置，仍然保持

相同。

274 第八章

深度模型中

的优化

8.7.2 坐标

下降

在某些

情况下，将一

个优化问题

分解成几个

部分，可以更

快地解决原

问题。如

果我

们相对于某

个单一变量

xi

最小化 f(x)，然后

相对于另一

个变量 xj 等等

，反

复循环所

有的变量，我

们会保证到

达（局部）极小

值。这种做法

被称为 坐标

下降

（coordinate descent），因为我

们一次优化

一个坐标。更

一般地，

块坐

标下降（block

coordinate descent）是指

对于某个子

集的变量同

时最小化。术

语 “坐标下降

’’

通常既

指块

坐标下降，也

指严格的单

个坐标下降

。

当优化问题

中的不同变

量能够清楚

地分成相对

独立的组，或

是当优化一

组变量

明显

比优化所有

变量效率更

高时，坐标下

降最有意义

。例如，考虑代

价函数

J(H,W) = ∑

i,j

|Hi,j | +

∑

i,j

(

X −

W⊤H

)2

i,j .

(8.38)

该函

数描述了一

种被称为稀

疏编码的学

习问题，其目

标是寻求一

个权重矩阵

W，可

以线性解

码激活值矩

阵 H

以重构训

练集X。稀疏编

码的大多数

应用还涉及

到权重衰

减

或 W 列范数的

约束，以避免

极小

H 和极大

W 的病态解。

函

数

J 不是凸的

。然而，我们可

以将训练算

法的输入分

成两个集合

：字典参数

W 和

编码表示

H。最

小化关于这

两者之一的

任意一组变

量的目标函

数都是凸问

题。

因此，块坐

标下降允许

我们使用高

效的凸优化

算法，交替固

定 H 优化

W 和固

定 W

优化

H。

当一

个变量的值

很大程度地

影响另一个

变量的最优

值时，坐标下

降不是一个

很

好的方法

，如函数 f(x)

= (x1 − x2)

2 + α(x

2

1 + x

2

2

)，其中

α 是正值常数

。第一项鼓

励

两个变量具

有相似的值

，而第二项鼓

励它们接近

零。解是两者

都为零。牛顿

法可

以一步

解决这个问

题，因为它是

一个正定二

次问题。但是

，对于小值 α 而

言，坐标

下降

会使进展非

常缓慢，因为

第一项不允

许单个变量

变为和其他

变量当前值

显著不

同的

值。

8.7.3 Polyak 平均

Polyak 平均

(Polyak and Juditsky,

1992) 会平均优化

算法在参数

空间访问轨

迹

中的几个

点。如果 t

次迭

代梯度下降

访问了点 θ

(1)

,

. . . ,

θ

(t)，那

么 Polyak 平均算法

的输出是

θˆ(t) =

1

t

∑

i

θ

(i)。在

某些问题中

，如梯度下降

应用于凸问

题时，这种方

法具

有较强

的收敛保证

。当应用于神

经网络时，其

验证更多是

启发式的，但

在实践中表

8.7 优化策略和

元算法 275

现良

好。基本想法

是，优化算法

可能会来回

穿过山谷好

几次而没经

过山谷底部

附近

的点。尽

管两边所有

位置的均值

应比较接近

谷底。

在非凸

问题中，优化

轨迹的路径

可以非常复

杂，并且经过

了许多不同

的区域。包

括

参数空间中

遥远过去的

点，可能与当

前点在代价

函数上相隔

很大的障碍

，看上去

不像

一个有用的

行为。其结果

是，当应用

Polyak 平

均于非凸问

题时，通常会

使用指

数衰

减计算平均

值：

θˆ(t)

= αθˆ(t−1) + (1

− α)θ

(t)

.

(8.39)

这个计算

平均值的方

法被用于大

量数值应用

中。最近的例

子请查看Szegedy et al.

(2015)。

8.7.4 监

督预训练

有

时，如果模型

太复杂难以

优化，或是如

果任务非常

困难，直接训

练模型来解

决特定任务

的挑战可能

太大。有时训

练一个较简

单的模型来

求解问题，然

后使模型

更

复杂会更有

效。训练模型

来求解一个

简化的问题

，然后转移到

最后的问题

，有时

也会更

有效些。这些

在直接训练

目标模型求

解目标问题

之前，训练简

单模型求解

简

化问题的

方法统称为

预训练（pretraining）。

贪心

算法（greedy

algorithm）将问题

分解成许多

部分，然后独

立地在每个

部分

求解最

优值。令人遗

憾的是，结合

各个最佳的

部分不能保

证得到一个

最佳的完整

解。

然而，贪心

算法计算上

比求解最优

联合解的算

法高效得多

，并且贪心算

法的解在不

是

最优的情

况下，往往也

是可以接受

的。贪心算法

也可以紧接

一个

精调（fine-tuning）

阶

段，联合优化

算法搜索全

问题的最优

解。使用贪心

解初始化联

合优化算法

，可以

极大地

加速算法，并

提高寻找到

的解的质量

。

预训练算法

，特别是贪心

预训练，在深

度学习中是

普遍存在的

。在本节中，我

们

会具体描

述这些将监

督学习问题

分解成其他

简化的监督

学习问题的

预训练算法

。这

种方法被

称为 贪心监

督预训练（greedy supervised

pretraining）。

在

贪心监督预

训练的原始

版本 (Bengio et

al., 2007c) 中，每个

阶段包括一

个仅

涉及最

终神经网络

的子集层的

监督学习训

练任务。贪心

监督预训练

的一个例子

如

图 8.7 所示，其

中每个附加

的隐藏层作

为浅层监督

多层感知机

的一部分预

训练，以先

前

训练的隐藏

层输出作为

输入。Simonyan

and Zisserman (2015) 预训练

深度卷积网

络（11

层权重），然

后使用该网

络前四层和

最后三层初

始化更深的

网络（多达 19 层

276 第八章

深度

模型中的优

化

权重），并非

一次预训练

一层。非常深

的新网络的

中间层是随

机初始化的

。然后联合

训

练新网络。还

有一种选择

，由Yu et

al. (2010) 提出，将先

前训练多层

感知机的输

出，以及原始

输入，作为每

个附加阶段

的输入。

y

hh(1) (1)

x

(a)

UU(1) (1)

WW(1) (1)

y

hh(1) (1)

x

(b)

UU(1) (1) WW(1)

(1)

y

hh(1) (1)

x

(c)

UU(1) (1)

WW(1) (1)

hh(2) (2)

y UU(2) (2) WW(2)

(2)

y

hh(1) (1)

x

(d)

UU(1) (1)

WW(1) (1)

hh(2) (2)

y

UU(2) (2)

WW(2)

(2)

图 8.7: 一

种形式的贪

心监督预训

练的示意图

(Bengio

et al., 2007a)。(a) 我们从训练

一个足够浅

的架构开始

。(b)

同一个架构

的另一描绘

。(c) 我们只保留

原始网络的

输入到隐藏

层，并丢弃隐

藏

到输出层

。我们将第一

层隐藏层的

输出作为输

入发送到另

一监督单隐

层 MLP（使用与第

一个网络

相

同的目标训

练），从而可以

添加第二层

隐藏层。这可

以根据需要

重复多层。(d) 所

得架构的另

一

种描绘，可

视为前馈网

络。为了进一

步改进优化

，我们可以联

合地精调所

有层（仅在该

过程的结束

或者该过程

的每个阶段

）。

为什么贪心

监督预训练

会有帮助呢

？最初由

Bengio et al. (2007d)

提出

的假说

8.7 优化

策略和元算

法 277

是，其有助

于更好地指

导深层结构

的中间层的

学习。一般情

况下，预训练

对于优化

和

泛化都是有

帮助的。

另一

个与监督预

训练有关的

方法扩展了

迁移学习的

想法：Yosinski et

al. (2014)

在一组

任务上预训

练了 8

层权重

的深度卷积

网络（1000 个 ImageNet 对象

类的子

集），然

而用该网络

的前 k 层初始

化同样规模

的网络。然后

第二个网络

的所有层（上

层随机初始

化）联合训练

以执行不同

的任务（1000 个

ImageNet 对

象类的另一

个子

集），但训

练样本少于

第一个任务

。神经网络中

另一个和迁

移学习相关

的方法将在

第 15.2

节讨论。

另

一条相关的

工作线是 FitNets (Romero

et al., 2015) 方

法。这种方法

始于训

练深

度足够低和

宽度足够大

（每层单元数

），容易训练的

网络。然后，这

个网络成为

第二个网络

（被指定为 学

生）的 老师。学

生网络更深

更窄（11 至

19 层），且

在正

常情况

下很难用 SGD

训

练。训练学生

网络不仅需

要预测原任

务的输出，还

需要预

测教

师网络中间

层的值，这样

使得训练学

生网络变得

更容易。这个

额外的任务

说明

了隐藏

层应如何使

用，并且能够

简化优化问

题。附加参数

被引入来从

更深的学生

网

络中间层

去回归

5 层教

师网络的中

间层。然而，该

目标是预测

教师网络的

中间隐藏

层

，并非预测最

终分类目标

。学生网络的

低层因而具

有两个目标

：帮助学生网

络的

输出完

成其目标和

预测教师网

络的中间层

。尽管一个窄

而深的网络

似乎比宽而

浅的

网络更

难训练，但窄

而深网络的

泛化能力可

能更好，并且

如果其足够

窄，参数足够

少，那么其计

算代价更小

。没有隐藏层

的提示，学生

网络在训练

集和测试集

上的实

验表

现都很差。因

而中间层的

提示是有助

于训练很难

训练的网络

的方法之一

，但是

其他优

化技术或是

架构上的变

化也可能解

决这个问题

。

8.7.5

设计有助于

优化的模型

改进优化的

最好方法并

不总是改进

优化算法。相

反，深度模型

中优化的许

多改

进来自

于设计易于

优化的模型

。

原则上，我们

可以使用呈

锯齿非单调

模式上上下

下的激活函

数，但是，这将

使

优化极为

困难。在实践

中，选择一族

容易优化的

模型比使用

一个强大的

优化算法更

重要。神经网

络学习在过

去

30 年的大多

数进步主要

来自于改变

模型族，而非

改变优

化过

程。1980 年代用于

训练神经网

络的带动量

的随机梯度

下降，仍然是

现代神经网

络应用中的

前沿算法。

具

体来说，现代

神经网络的

设计选择体

现在层之间

的线性变换

，几乎处处可

导

278 第八章 深

度模型中的

优化

的激活

函数，和大部

分定义域都

有明显的梯

度。特别地，创

新的模型，如

LSTM，整

流线性单

元和 maxout 单元都

比先前的模

型（如基于

sigmoid 单

元的深度网

络）使用

更多

的线性函数

。这些模型都

具有简化优

化的性质。如

果线性变换

的 Jacobian

具有

相对

合理的奇异

值，那么梯度

能够流经很

多层。此外，线

性函数在一

个方向上一

致

增加，所以

即使模型的

输出远离正

确值，也可以

简单清晰地

计算梯度，使

其输出方

向

朝降低损失

函数的方向

移动。换言之

，现代神经网

络的设计方

案旨在使其

局部梯

度信

息合理地对

应着移向一

个遥远的解

。

其他的模型

设计策略有

助于使优化

更简单。例如

，层之间的线

性路径或是

跳

跃连接减

少了从较低

层参数到输

出最短路径

的长度，因而

缓解了梯度

消失的问题

(Srivastava et

al., 2015)。一个和跳跃

连接相关的

想法是添加

和网络中间

隐藏层相

连

的输出的额

外副本，如 GoogLeNet

(Szegedy et al., 2014a)

和

深度监督网

络 (Lee

et al.,

2014)。这些 ‘‘辅助

头’’ 被训练来

执行和网络

顶层主要输

出相同的任

务，以确

保底

层网络能够

接受较大的

梯度。当训练

完成时，辅助

头可能被丢

弃。这是之前

小

节介绍到

的预训练策

略的替代方

法。以这种方

式，我们可以

在一个阶段

联合训练所

有层，而不改

变架构，使得

中间层（特别

是低层）能够

通过更短的

路径得到一

些如

何更新

的有用信息

。这些信息为

底层提供了

误差信号。

8.7.6 延

拓法和课程

学习

正如第

8.2.7 节探讨的，许

多优化挑战

都来自于代

价函数的全

局结构，不能

仅通

过局部

更新方向上

更好的估计

来解决。解决

这个问题的

主要方法是

尝试初始化

参数

到某种

区域内，该区

域可以通过

局部下降很

快连接到参

数空间中的

解。

延拓法（continuation method）是

一族通过挑

选初始点使

优化更容易

的方法，

以确

保局部优化

花费大部分

时间在表现

良好的空间

。延拓法的背

后想法是构

造一系

列具

有相同参数

的目标函数

。为了最小化

代价函数

J(θ)，我

们构建新的

代价函数

{J

(0), .

. . , J(n)}。这

些代价函数

的难度逐步

提高，其中

J

(0) 是

最容易最小

化的，J

(n)

是最难

的，真正的代

价函数驱动

整个过程。当

我们说 J

(i) 比

J

(i+1) 更

容易时，是指

其在更多的

θ 空间上表现

良好。随机初

始化更有可

能落入局部

下降可以成

功最小

化代

价函数的区

域，因为其良

好区域更大

。这系列代价

函数设计为

前一个解是

下一

个的良

好初始点。因

此，我们首先

解决一个简

单的问题，然

后改进解以

解决逐步变

难的问题，直

到我们求解

真正问题的

解。

传统的延

拓法（用于神

经网络训练

之前的延拓

法）通常基于

平滑目标函

数。读

8.7

优化策

略和元算法

279

者可以查看

Wu (1997) 了解这类方

法的示例，以

及一些相关

方法的综述

。延拓法也

和

参数中加入

噪声的模拟

退火紧密相

关 (Kirkpatrick et al.,

1983)。延拓法在

最近几

年非

常成功。参考

Mobahi and Fisher

(2015) 了解近期文

献的概述，特

别是在 AI 方

面

的应用。

传统

上，延拓法主

要用来克服

局部极小值

的问题。具体

地，它被设计

来在有很

多

局部极小值

的情况下，求

解一个全局

最小点。这些

连续方法会

通过 ‘‘模糊’’

原

来

的代价函

数来构建更

容易的代价

函数。这些模

糊操作可以

是用采样来

近似

J

(i)

(θ) = Eθ

′∼N(θ′

;θ,σ(i)2)J(θ

′

) (8.40)

这个方

法的直觉是

有些非凸函

数在模糊后

会近似凸的

。在许多情况

下，这种模糊

保

留了关于

全局极小值

的足够信息

，我们可以通

过逐步求解

模糊更少的

问题来求解

全

局极小值

。这种方法有

三种可能失

败的方式。首

先，它可能成

功地定义了

一连串代

价

函数，并从开

始的一个凸

函数起（逐一

地）沿着函数

链最佳轨迹

逼近全局最

小值，

但可能

需要非常多

的逐步代价

函数，整个过

程的成本仍

然很高。另外

，即使延拓法

可

以适用，NP-hard 的

优化问题仍

然是 NP-hard。其他两

种延拓法失

败的原因是

不实

用。其一

，不管如何模

糊，函数都没

法变成凸的

，比如函数 J(θ) = −θ

⊤θ。其

二，函

数可能

在模糊后是

凸的，但模糊

函数的最小

值可能会追

踪到一个局

部最小值，而

非

原始代价

函数的全局

最小值。

尽管

延拓法最初

用来解决局

部最小值的

问题，而局部

最小值已不

再认为是神

经

网络优化

中的主要问

题了。幸运的

是，延拓法仍

然有所帮助

。延拓法引入

的简化目

标

函数能够消

除平坦区域

，减少梯度估

计的方差，提

高Hessian 矩阵的条

件数，使局

部

更新更容易

计算，或是改

进局部更新

方向与朝向

全局解方向

之间的对应

关系。

Bengio et al. (2009)

指出被

称为 课程学

习（curriculum learning）或者 塑造

（shaping）的方法可以

被解释为延

拓法。课程学

习基于规划

学习过程的

想法，首先

学

习简单的概

念，然后逐步

学习依赖于

这些简化概

念的复杂概

念。之前这一

基本

策略被

用来加速动

物训练过程

(Skinner, 1958; Peterson,

2004; Krueger and Dayan,

2009) 和机器学习

过程 (Solomonoff, 1989;

Elman, 1993; Sanger, 1994)。Bengio

et al.

(2009) 验证这

一策略为延

拓法，通过增

加简单样本

的影响（通过

分配它们较

大的系

数到

代价函数，或

者更频繁地

采样），先前的

J

(i) 会变得更容

易。实验证明

，在大

规模的

神经语言模

型任务上使

用课程学习

，可以获得更

好的结果。课

程学习已经

成

功应用于

大量的自然

语言 (Spitkovsky et al.,

2010; Collobert et al.,

2011a; Mikolov

et al.,

2011b; Tu and Honavar,

2011) 和计算

机视觉 (Kumar et

al., 2010; Lee and

280 第八

章 深度模型

中的优化

Grauman,

2011; Supancic and Ramanan,

2013) 任

务上。课程学

习被证实为

与人类

教学

方式一致 (Khan

et al., 2011)：教

师刚开始会

展示更容易

、更典型的示

例，然

后帮助

学习者在不

太显然的情

况下提炼决

策面。在人类

教学上，基于

课程学习的

策略比基于

样本均匀采

样的策略更

有效，也能提

高其他学习

策略的效率

(Basu

and

Christensen, 2013)。

课程学习研

究的另一个

重要贡献体

现在训练循

环神经网络

捕获长期依

赖：

Zaremba and Sutskever (2014)

发现使用

随机课程获

得了更好的

结果，其中容

易和困

难的

示例混合在

一起，随机提

供给学习者

，更难示例（这

些具有长期

依赖）的平均

比例在逐渐

上升。而使用

确定性课程

，并没有发现

超过基线（完

整训练集的

普通训

练）的

改进。

现在我

们已经介绍

了一些基本

的神经网络

模型，以及如

何进行正则

化和优化。

在

接下来的章

节中，我们转

向特化的神

经网络家族

，允许其扩展

到能够处理

很大规

模的

数据和具有

特殊结构的

数据。在本章

中讨论的优

化算法在较

少改动后或

者无需

改动

，通常就可以

直接用于这

些特化的架

构。

第九章

卷

积网络

卷积

网络（convolutional network）(LeCun, 1989)，也叫做

卷积神经网

络（con￾volutional

neural network, CNN），是一种专

门用来处理

具有类似网

格结构的数

据的

神经网

络。例如时间

序列数据（可

以认为是在

时间轴上有

规律地采样

形成的一维

网

格）和图像

数据（可以看

作是二维的

像素网格）。卷

积网络在诸

多应用领域

都表现优

异

。“卷积神经网

络’’ 一词表明

该网络使用

了 卷积（convolution）这种

数学运算。卷

积是一种特

殊的线性运

算。卷积网络

是指那些至

少在网络的

一层中使用

卷积运算来

替代一般的

矩阵乘法运

算的神经网

络。

本章，我们

首先说明什

么是卷积运

算。接着，我们

会解释在神

经网络中使

用卷

积运算

的动机。然后

我们会介绍

池化（pooling），这是一

种几乎所有

的卷积网络

都会

用到的

操作。通常来

说，卷积神经

网络中用到

的卷积运算

和其他领域

（例如工程领

域以及纯数

学领域）中的

定义并不完

全一致。我们

会对神经网

络实践中广

泛应用的

几

种卷积函数

的变体进行

说明。我们也

会说明如何

在多种不同

维数的数据

上使用卷

积

运算。之后我

们讨论使得

卷积运算更

加高效的一

些方法。卷积

网络是神经

科学原

理影

响深度学习

的典型代表

。我们之后也

会讨论这些

神经科学的

原理，并对卷

积网

络在深

度学习发展

史中的作用

作出评价。本

章没有涉及

如何为你的

卷积网络选

择合

适的结

构，因为本章

的目标是说

明卷积网络

提供的各种

工具。第十一

章将会对如

何

在具体环

境中选择使

用相应的工

具给出通用

的准则。对于

卷积网络结

构的研究进

展

得如此迅

速，以至于针

对特定基准

(benchmark)，数月甚至几

周就会公开

一个新的

最

优的网络结

构，甚至在写

这本书时也

不好描述究

竟哪种结构

是最好的。然

而，最

好的结

构也是由本

章所描述的

基本部件逐

步搭建起来

的。

281

282 第九章 卷

积网络

9.1 卷积

运算

在通常

形式中，卷积

是对两个实

变函数的一

种数学运算

1。为了给出卷

积的定义，

我

们从两个可

能会用到的

函数的例子

出发。

假设我

们正在用激

光传感器追

踪一艘宇宙

飞船的位置

。我们的激光

传感器给出

一个单独的

输出 x(t)，表示宇

宙飞船在时

刻 t 的位置。x

和

t 都是实值的

，这意味

着我

们可以在任

意时刻从传

感器中读出

飞船的位置

。

现在假设我

们的传感器

受到一定程

度的噪声干

扰。为了得到

飞船位置的

低噪声

估计

，我们对得到

的测量结果

进行平均。显

然，时间上越

近的测量结

果越相关，所

以我们采用

一种加权平

均的方法，对

于最近的测

量结果赋予

更高的权重

。我们可以

采

用一个加权

函数 w(a) 来实现

，其中

a 表示测

量结果距当

前时刻的时

间间隔。如果

我们对任意

时刻都采用

这种加权平

均的操作，就

得到了一个

新的对于飞

船位置的平

滑估计函数

s：

s(t) =

∫

x(a)w(t − a)da.

(9.1)

这种运算就

叫做 卷积（convolution）。卷

积运算通常

用星号表示

：

s(t)

= (x ∗ w)(t).

(9.2)

在我们的例

子中，w 必须是

一个有效的

概率密度函

数，否则输出

就不再是一

个

加权平均

。另外，在参数

为负值时，w

的

取值必须为

0，否则它会预

测到未来，这

不

是我们能

够推测得了

的。但这些限

制仅仅是对

我们这个例

子来说。通常

，卷积被定

义

在满足上述

积分式的任

意函数上，并

且也可能被

用于加权平

均以外的目

的。

在卷积网

络的术语中

，卷积的第一

个参数（在这

个例子中，函

数

x）通常叫做

输

入（input），第二个

参数（函数 w）叫

做 核函数（kernel

function）。输

出有时被称

作 特征映射

（feature map）。

在本例中，激

光传感器在

每个瞬间反

馈测量结果

的想法是不

切实际的。一

般地，

当我们

用计算机处

理数据时，时

间会被离散

化，传感器会

定期地反馈

数据。所以在

我

们的例子

中，假设传感

器每秒反馈

一次测量结

果是比较现

实的。这样，时

刻 t 只能取

整

数值。如果我

们假设 x 和 w

都

定义在整数

时刻 t 上，就可

以定义离散

形式的卷积

：

s(t)

= (x ∗ w)(t)

=

∞∑

a=−∞

x(a)w(t

− a). (9.3)

1译者注：本书

中

operation 视语境有

时翻译成 ‘‘运

算’’，有时翻译

成 ‘‘操作’’。

9.1 卷积

运算 283

在机器

学习的应用

中，输入通常

是多维数组

的数据，而核

通常是由学

习算法优

化

得到的多维

数组的参数

。我们把这些

多维数组叫

做张量。因为

在输入与核

中的每

一个

元素都必须

明确地分开

存储，我们通

常假设在存

储了数值的

有限点集以

外，这

些函数

的值都为零

。这意味着在

实际操作中

，我们可以通

过对有限个

数组元素的

求

和来实现

无限求和。

最

后，我们经常

一次在多个

维度上进行

卷积运算。例

如，如果把一

张二维的图

像 I 作为输入

，我们也许也

想要使用一

个二维的核

K：

S(i,

j) = (I ∗

K)(i, j) = ∑

m

∑

n

I(m,

n)K(i − m, j

− n). (9.4)

卷积是可交

换的

(commutative)，我们可

以等价地写

作：

S(i, j) =

(K ∗ I)(i, j)

= ∑

m

∑

n

I(i − m,

j − n)K(m, n).

(9.5)

通常，下面

的公式在机

器学习库中

实现更为简

单，因为 m 和

n 的

有效取值范

围

相对较小

。

卷积运算可

交换性的出

现是因为我

们将核相对

输入进行了

翻转（flip），从

m 增

大

的角度来看

，输入的索引

在增大，但是

核的索引在

减小。我们将

核翻转的唯

一目

的是实

现可交换性

。尽管可交换

性在证明时

很有用，但在

神经网络的

应用中却不

是

一个重要

的性质。与之

不同的是，许

多神经网络

库会实现一

个相关的函

数，称为 互

相

关函数（cross-correlation），和卷

积运算几乎

一样但是并

没有对核进

行翻转：

S(i,

j) = (I ∗

K)(i, j) = ∑

m

∑

n

I(i

+ m, j +

n)K(m, n). (9.6)

许多

机器学习的

库实现的是

互相关函数

但是称之为

卷积。在这本

书中我们遵

循把两

种运

算都叫做卷

积的这个传

统，在与核翻

转有关的上

下文中，我们

会特别指明

是否

对核进

行了翻转。在

机器学习中

，学习算法会

在核合适的

位置学得恰

当的值，所以

一

个基于核

翻转的卷积

运算的学习

算法所学得

的核，是对未

进行翻转的

算法学得的

核

的翻转。单

独使用卷积

运算在机器

学习中是很

少见的，卷积

经常与其他

的函数一起

使用，无论卷

积运算是否

对它的核进

行了翻转，这

些函数的组

合通常是不

可交换的。

图

9.1 演示了一个

在 2 维张量上

的卷积运算

（没有对核进

行翻转）的例

子。

离散卷积

可以看作矩

阵的乘法，然

而，这个矩阵

的一些元素

被限制为必

须和另外

一

些元素相等

。例如对于单

变量的离散

卷积，矩阵每

一行中的元

素都与上一

行对应

284 第九

章

卷积网络

a b c d

e f g h

i j k l

w x

y z

aw + bx +

ey + fz

aw

+ bx +

ey

+ fz

bw +

cx +

fy +

gz

bw + cx

+

fy + gz

cw + dx +

gy + hz

cw

+ dx +

gy

+ hz

ew +

fx +

iy +

jz

ew + fx

+

iy + jz

fw + gx +

jy + kz

fw

+ gx +

jy

+ kz

gw +

hx +

ky +

lz

gw + hx

+

ky + lz

Input

Kernel

Output

图

9.1: 一个 2 维卷

积的例子（没

有对核进行

翻转）。我们限

制只对核完

全处在图像

中的位置进

行

输出，在一

些上下文中

称为 “有效’’ 卷

积。我们用画

有箭头的盒

子来说明输

出张量的左

上角元素是

如何通过对

输入张量相

应的左上角

区域应用核

进行卷积得

到的。

位置平

移一个单位

的元素相同

。这种矩阵叫

做

Toeplitz 矩阵（Toeplitz matrix）。对

于

二维情况，卷

积对应着一

个

双重分块

循环矩阵（doubly block circulant matrix）。

除

了这些元素

相等的限制

以外，卷积通

常对应着一

个非常稀疏

的矩阵（一个

几乎所

有元

素都为零的

矩阵）。这是因

为核的大小

通常要远小

于输入图像

的大小。任何

一个

使用矩

阵乘法但是

并不依赖矩

阵结构的特

殊性质的神

经网络算法

，都适用于卷

积运

算，并且

不需要对神

经网络做出

大的修改。典

型的卷积神

经网络为了

更有效地处

理

大规模输

入，确实使用

了一些专门

化的技巧，但

这些在理论

分析方面并

不是严格必

要的。

9.2 动机 285

9.2 动

机

卷积运算

通过三个重

要的思想来

帮助改进机

器学习系统

： 稀疏交互（sparse

interactions）、 参

数共享（parameter sharing）、 等变

表示（equivariant

representa￾tions）。另外，卷

积提供了一

种处理大小

可变的输入

的方法。我们

下面依次介

绍这些

思想

。

传统的神经

网络使用矩

阵乘法来建

立输入与输

出的连接关

系。其中，参数

矩

阵中每一

个单独的参

数都描述了

一个输入单

元与一个输

出单元间的

交互。这意

味

着每一个输

出单元与每

一个输入单

元都产生交

互。然而，卷积

网络具有 稀

疏交

互（sparse interactions）（也叫

做

稀疏连接

（sparse connectivity）或者 稀疏权

重

（sparse

weights））的特征。这

是使核的大

小远小于输

入的大小来

达到的。举个

例子，

当处理

一张图像时

，输入的图像

可能包含成

千上万个像

素点，但是我

们可以通过

只

占用几十

到上百个像

素点的核来

检测一些小

的有意义的

特征，例如图

像的边缘。这

意味着我们

需要存储的

参数更少，不

仅减少了模

型的存储需

求，而且提高

了它的统

计

效率。这也意

味着为了得

到输出我们

只需要更少

的计算量。这

些效率上的

提高往

往是

很显著的。如

果有 m 个输入

和 n

个输出，那

么矩阵乘法

需要 m × n

个参数

并

且相应算

法的时间复

杂度为 O(m ×

n)（对于

每一个例子

）。如果我们限

制每一个输

出拥有的连

接数为 k，那么

稀疏的连接

方法只需要

k × n

个参数以及

O(k × n) 的运

行时间

。在很多实际

应用中，只需

保持 k 比 m

小几

个数量级，就

能在机器学

习的

任务中

取得好的表

现。稀疏连接

的图形化解

释如图 9.2 和图

9.3

所示。在深度

卷积网

络中

，处在网络深

层的单元可

能与绝大部

分输入是间

接交互的，如

图 9.4 所示。这允

许网络可以

通过只描述

稀疏交互的

基石来高效

地描述多个

变量的复杂

交互。

参数共

享（parameter sharing）是指在一

个模型的多

个函数中使

用相同的参

数。

在传统的

神经网络中

，当计算一层

的输出时，权

重矩阵的每

一个元素只

使用一次，当

它乘以输入

的一个元素

后就再也不

会用到了。作

为参数共享

的同义词，我

们可以说

一

个网络含有

绑定的权重

（tied

weights），因为用于一

个输入的权

重也会被绑

定在

其他的

权重上。在卷

积神经网络

中，核的每一

个元素都作

用在输入的

每一位置上

（是

否考虑边

界像素取决

于对边界决

策的设计）。卷

积运算中的

参数共享保

证了我们只

需

要学习一

个参数集合

，而不是对于

每一位置都

需要学习一

个单独的参

数集合。这虽

然没有改变

前向传播的

运行时间（仍

然是

O(k × n)），但它显

著地把模型

的存储需求

降低至 k

个参

数，并且 k 通常

要比 m

小很多

个数量级。因

为 m 和 n

通常有

着大致

相同

的大小，k 在实

际中相对于

m ×

n 是很小的。因

此，卷积在存

储需求和统

计效

286 第九章

卷积网络

xx11 xx22 xx33

ss22

ss11 ss33

xx44

ss44

xx55

ss55

xx11 xx22

xx33

ss22 ss11 ss33

xx44

ss44

xx55

ss55

图

9.2: 稀疏连接，对

每幅图从下

往上看。我们

强调了一个

输入单元 x3 以

及在

s 中受该

单元影响

的

输出单元。(上

) 当

s 是由核宽

度为 3 的卷积

产生时，只有

三个输出受

到

x 的影响2。(下

) 当 s

是由矩阵

乘法产生时

，连接不再是

稀疏的，所以

所有的输出

都会受到 x3 的

影响。

率方面

极大地优于

稠密矩阵的

乘法运算。图

9.5

演示了参数

共享是如何

实现的。

作为

前两条原则

的一个实际

例子，图 9.6 说明

了稀疏连接

和参数共享

是如何显著

提高线性函

数在一张图

像上进行边

缘检测的效

率的。

对于卷

积，参数共享

的特殊形式

使得神经网

络层具有对

平移 等变（equivariance）

的

性质。如果一

个函数满足

输入改变，输

出也以同样

的方式改变

这一性质，我

们就说

它是

等变

(equivariant) 的。特别

地，如果函数

f(x) 与 g(x)

满足 f(g(x)) = g(f(x))，

我们

就说 f(x) 对于变

换 g

具有等变

性。对于卷积

来说，如果令

g 是输入的任

意平

移函数

，那么卷积函

数对于 g

具有

等变性。举个

例子，令 I 表示

图像在整数

坐标上

的亮

度函数，g

表示

图像函数的

变换函数（把

一个图像函

数映射到另

一个图像函

数

的函数）使

得 I

′

= g(I)，其中图像

函数 I

′

满足 I

′

(x,

y) = I(x −

1, y)。这

个函数把 I

中

的每个像素

向右移动一

个单位。如果

我们先对

I 进

行这种变换

然后进行卷

积操作

所得

到的结果，与

先对 I

进行卷

积然后再对

输出使用平

移函数 g 得到

的结果是一

样

的4

。当处理

时间序列数

据时，这意味

着通过卷积

可以得到一

个由输入中

出现不同特

4译者注：原文

将此处误写

成了 I

′。

9.2

动机 287

xx11 xx22

xx33

ss22 ss11 ss33

xx44

ss44

xx55

ss55

xx11 xx22 xx33

ss22

ss11 ss33

xx44

ss44

xx55

ss55

图

9.3: 稀疏连接，对

每幅图从上

往下看。我们

强调了一个

输出单元

s3 以

及 x 中影响该

单元的输

入

单元。这些单

元被称为 s3 的

接受域（receptive field）3。(上)

当

s 是由核宽度

为 3 的卷积产

生

时，只有三

个输入影响

s3。(下) 当 s 是由矩

阵乘法产生

时，连接不再

是稀疏的，所

以所有的输

入

都会影响

s3。

xx11 xx22 xx33

hh22 hh11 hh33

xx44

hh44

xx55

hh55

gg22

gg11 gg33 gg44 gg55

图 9.4: 处于卷积

网络更深的

层中的单元

，它们的接受

域要比处在

浅层的单元

的接受域更

大。如果

网络

还包含类似

步幅卷积（图

9.12

）或者池化（第

9.3 节）之类的结

构特征，这种

效应会加强

。这

意味着在

卷积网络中

尽管直接连

接都是很稀

疏的，但处在

更深的层中

的单元可以

间接地连接

到全

部或者

大部分输入

图像。

288 第九章

卷积网络

xx11 xx22

xx33

ss22 ss11 ss33

xx44

ss44

xx55

ss55

xx11 xx22 xx33 xx44

xx55

ss22 ss11 ss33

ss44 ss55

图

9.5: 参数共享。黑

色箭头表示

在两个不同

的模型中使

用了特殊参

数的连接。(上

)

黑色箭头表

示

在卷积模

型中对 3 元素

核的中间元

素的使用。因

为参数共享

，这个单独的

参数被用于

所有的输入

位置。(下)

这个

单独的黑色

箭头表示在

全连接模型

中对权重矩

阵的中间元

素的使用。这

个模型没

有

使用参数共

享，所以参数

只使用了一

次。

征的时刻

所组成的时

间轴。如果我

们把输入中

的一个事件

向后延时，在

输出中仍然

会有完全相

同的表示，只

是时间延后

了。图像与之

类似，卷积产

生了一个 2

维

映射

来表明

某些特征在

输入中出现

的位置。如果

我们移动输

入中的对象

，它的表示也

会

在输出中

移动同样的

量。当处理多

个输入位置

时，一些作用

在邻居像素

的函数是很

有用的。例如

在处理图像

时，在卷积网

络的第一层

进行图像的

边缘检测是

很有用的。

相

同的边缘或

多或少地散

落在图像的

各处，所以应

当对整个图

像进行参数

共享。但

在某

些情况下，我

们并不希望

对整幅图进

行参数共享

。例如，在处理

已经通过剪

裁

而使其居

中的人脸图

像时，我们可

能想要提取

不同位置上

的不同特征

（处理人脸上

部的部分网

络需要去搜

寻眉毛，处理

人脸下部的

部分网络就

需要去搜寻

下巴了）。

卷积

对其他的一

些变换并不

是天然等变

的，例如对于

图像的放缩

或者旋转变

换，

需要其他

的一些机制

来处理这些

变换。

最后，一

些不能被传

统的由（固定

大小的）矩阵

乘法定义的

神经网络处

理的特

殊数

据，可能通过

卷积神经网

络来处理，我

们将在第 9.7 节

中进行讨论

。

9.2 动机 289

图

9.6: 边缘

检测的效率

。右边的图像

是通过先获

得原始图像

中的每个像

素，然后减去

左边相邻像

素的值而形

成的。这个操

作给出了输

入图像中所

有垂直方向

上的边缘的

强度，对目标

检测来说是

有

用的。两个

图像的高度

均为 280

个像素

。输入图像的

宽度为 320 个像

素，而输出图

像的宽度为

319

个像素。这个

变换可以通

过包含两个

元素的卷积

核来描述，使

用卷积需要

319

×280 ×3 = 267,

960

次浮点运算

（每个输出像

素需要两次

乘法和一次

加法）。为了用

矩阵乘法描

述相同的变

换，需要一

个

包含 320

× 280 × 319

× 280 个或者

说超过 80

亿个

元素的矩阵

，这使得卷积

对于表示这

种变换

更有

效 40 亿倍。直接

运行矩阵乘

法的算法将

执行超过

160 亿

次浮点运算

，这使得卷积

在计算上大

约有 60,000 倍的效

率。当然，矩阵

的大多数元

素将为零。如

果我们只存

储矩阵的非

零元，则矩阵

乘法和卷积

都需要相同

数量的浮点

运算来计算

。矩阵仍然需

要包含

2 × 319 ×

280 = 178, 640

个元

素。将小的局

部区域上的

相同线性变

换应用到整

个输入上，卷

积是描述这

种变换的极

其有效的方

法。照片来源

：Paula Goodfellow。

290 第九章

卷积

网络

9.3 池化

卷

积网络中一

个典型层包

含三级（如图

9.7

所示）。在第一

级中，这一层

并行地计

算

多个卷积产

生一组线性

激活响应。在

第二级中，每

一个线性激

活响应将会

通过一个

非

线性的激活

函数，例如整

流线性激活

函数。这一级

有时也被称

为 探测级（detector

stage）。在

第三级中，我

们使用 池化

函数（pooling function）来进一

步调整这一

层

的输出。

Convolutional Layer

Input to

layer

Convolution stage:

Affine

transform

Detector stage:

Nonlinearity

e.g., rectified linear

Pooling

stage

Next layer

Input

to layers

Convolution layer:

Affine transform 

Detector

layer: Nonlinearity

e.g., rectified

linear

Pooling layer

Next

layer

Complex layer terminology

Simple layer terminology

图

9.7:

一个典型卷

积神经网络

层的组件。有

两组常用的

术语用于描

述这些层。(左

) 在这组术语

中，

卷积网络

被视为少量

相对复杂的

层，每层具有

许多 ‘‘级’’。在这

组术语中，核

张量与网络

层之间存

在

一一对应关

系。在本书中

，我们通常使

用这组术语

。(右) 在这组术

语中，卷积网

络被视为更

多

数量的简

单层；每一个

处理步骤都

被认为是一

个独立的层

。这意味着不

是每一 ‘‘层’’

都

有参数。

池化

函数使用某

一位置的相

邻输出的总

体统计特征

来代替网络

在该位置的

输出。

例如， 最

大池化（max

pooling）函数

(Zhou and Chellappa, 1988)

给出相邻矩

形区

域内的

最大值。其他

常用的池化

函数包括相

邻矩形区域

内的平均值

、L

2 范数以及基

于据中心像

素距离的加

权平均函数

。

9.3 池化 291

不管采

用什么样的

池化函数，当

输入作出少

量平移时，池

化能够帮助

输入的表

示

近似 不变（invariant）。对

于平移的不

变性是指当

我们对输入

进行少量平

移时，经

过池

化函数后的

大多数输出

并不会发生

改变。图 9.8

用了

一个例子来

说明这是如

何实

现的。局

部平移不变

性是一个很

有用的性质

，尤其是当我

们关心某个

特征是否出

现

而不关心

它出现的具

体位置时。例

如，当判定一

张图像中是

否包含人脸

时，我们并

不

需要知道眼

睛的精确像

素位置，我们

只需要知道

有一只眼睛

在脸的左边

，有一只

在右

边就行了。但

在一些其他

领域，保存特

征的具体位

置却很重要

。例如当我们

想

要寻找一

个由两条边

相交而成的

拐角时，我们

就需要很好

地保存边的

位置来判定

它

们是否相

交。

0.1

1. 0.2

1. 1.

1.

0.1

0.2

...

...

... ...

0.3

0.1 1.

1. 0.3

1.

0.2

1.

...

...

... ...

DETECTOR

STAGE

POOLING STAGE

POOLING

STAGE

DETECTOR STAGE

图

9.8: 最大池

化引入了不

变性。(上) 卷积

层中间输出

的视图。下面

一行显示非

线性的输出

。上面

一行显

示最大池化

的输出，每个

池的宽度为

三个像素并

且池化区域

的步幅为一

个像素。(下)

相

同

网络的视

图，不过对输

入右移了一

个像素。下面

一行的所有

值都发生了

改变，但上面

一行只有一

半的值发生

了改变，这是

因为最大池

化单元只对

周围的最大

值比较敏感

，而不是对精

确的位置。

使

用池化可以

看作是增加

了一个无限

强的先验：这

一层学得的

函数必须具

有对

少量平

移的不变性

。当这个假设

成立时，池化

可以极大地

提高网络的

统计效率。

对

空间区域进

行池化产生

了平移不变

性，但当我们

对分离参数

的卷积的输

出进

行池化

时，特征能够

学得应该对

于哪种变换

具有不变性

（如图 9.9 所示）。

292 第

九章 卷积网

络

Large

response

in pooling unit

Large response

in pooling

unit

Large

response

in

detector

unit 1

Large

response

in detector

unit

3

图 9.9: 学习不

变性的示例

。使用分离的

参数学得多

个特征，再使

用池化单元

进行池化，可

以学得

对输

入的某些变

换的不变性

。这里我们展

示了用三个

学得的过滤

器和一个最

大池化单元

可以学得

对

旋转变换的

不变性。这三

个过滤器都

旨在检测手

写的数字 5。每

个过滤器尝

试匹配稍微

不同方向

的

5。当输入中出

现

5 时，相应的

过滤器会匹

配它并且在

探测单元中

引起大的激

活。然后，无论

哪

个探测单

元被激活，最

大池化单元

都具有大的

激活。我们在

这里演示了

网络如何处

理两个不同

的输

入，这导

致两个不同

的探测单元

被激活，然而

对池化单元

的影响大致

相同。这个原

则在

maxout 网

络 (Goodfellow

et al., 2013b) 和

其他卷积网

络中更有影

响。空间位置

上的最大池

化对于平移

是天

然不变

的；这种多通

道方法只在

学习其他变

换时是必要

的。

因为池化

综合了全部

邻居的反馈

，这使得池化

单元少于探

测单元成为

可能，我

们可

以通过综合

池化区域的

k 个像素的统

计特征而不

是单个像素

来实现。图

9.10 给

出了一个例

子。这种方法

提高了网络

的计算效率

，因为下一层

少了约 k 倍的

输入。

当下一

层的参数数

目是关于那

一层输入大

小的函数时

（例如当下一

层是全连接

的基

于矩阵

乘法的网络

层时），这种对

于输入规模

的减小也可

以提高统计

效率并且减

少对

于参数

的存储需求

。

在很多任务

中，池化对于

处理不同大

小的输入具

有重要作用

。例如我们想

对不

同大小

的图像进行

分类时，分类

层的输入必

须是固定的

大小，而这通

常通过调整

池

化区域的

偏置大小来

实现，这样分

类层总是能

接收到相同

数量的统计

特征而不管

最

初的输入

大小了。例如

，最终的池化

层可能会输

出四组综合

统计特征，每

组对应着

图

像的一个象

限，而与图像

的大小无关

。

一些理论工

作对于在不

同情况下应

当使用哪种

池化函数给

出了一些指

导

(Boureau et al.,

2010)。将特征一

起动态地池

化也是可行

的，例如，对于

感兴趣

9.3 池化

293

0.1

1. 0.2

1. 0.2

0.1

0.1

0.0 0.1

图 9.10: 带有降采

样的池化。这

里我们使用

最大池化，池

的宽度为三

并且池之间

的步幅为二

。这使

得表示

的大小减少

了一半，减轻

了下一层的

计算和统计

负担。注意到

最右边的池

化区域尺寸

较小，

但如果

我们不想忽

略一些探测

单元的话就

必须包含这

个区域。

特征

的位置运行

聚类算法 (Boureau et

al., 2011)。这

种方法对于

每幅图像产

生一个

不同

的池化区域

集合。另一种

方法是先学

习一个单独

的池化结构

，再应用到全

部的

图像中

(Jia

et al., 2012)。

池化可能会

使得一些利

用自顶向下

信息的神经

网络结构变

得复杂，例如

玻尔兹

曼机

和自编码器

。这些问题将

在第三章中

当我们遇到

这些类型的

网络时进一

步讨论。

卷积

玻尔兹曼机

中的池化出

现在第 20.6 节。一

些可微网络

中需要的在

池化单元上

进

行的类逆

运算将在第

20.10.6 节中讨论。

图

9.11 给出了一些

使用卷积和

池化操作的

用于分类的

完整卷积网

络结构的例

子。

294 第九章 卷

积网络

Input

image: 

256x256x3

Output

of 

convolution +

ReLU: 256x256x64

Output of

pooling 

with stride

4: 

64x64x64

Output

of 

convolution +

ReLU: 64x64x64

Output of

pooling 

with stride

4: 

16x16x64

Output

of reshape to

vector:

16,384 units

Output

of matrix 

multiply:

1,000 units

Output of

softmax: 

1,000 class

probabilities

Input image:

256x256x3

Output of

convolution + 

ReLU:

256x256x64

Output of pooling

with stride 4:

64x64x64

Output of

convolution + 

ReLU:

64x64x64

Output of pooling

to 

3x3 grid:

3x3x64

Output of reshape

to 

vector:

576

units

Output of matrix

multiply: 1,000 units

Output

of softmax: 

1,000

class 

probabilities

Input

image: 

256x256x3

Output

of 

convolution +

ReLU: 256x256x64

Output of

pooling 

with stride

4: 

64x64x64

Output

of 

convolution +

ReLU: 64x64x64

Output of

convolution:

16x16x1,000

Output of

average 

pooling: 1x1x1,000

Output of softmax:

1,000 class 

probabilities

Output of pooling

with stride 4:

16x16x64

图 9.11: 卷

积网络用于

分类的结构

示例。本图中

使用的具体

步幅和深度

并不建议实

际使用；它们

被设计得非

常浅以适合

页面。实际的

卷积网络还

常常涉及大

量的分支，不

同于这里为

简单起见所

使用的链式

结构。(左)

处理

固定大小的

图像的卷积

网络。在卷积

层和池化层

几层交替之

后，卷积

特征

映射的张量

被重新变形

以展平空间

维度。网络的

其余部分是

一个普通的

前馈网络分

类器，如

第六

章所述。(中) 处

理大小可变

的图像的卷

积网络，但仍

保持全连接

的部分。该网

络使用具有

可

变大小但

是数量固定

的池的池化

操作，以便向

网络的全连

接部分提供

固定 576 个单位

大小的向量

。

(右)

没有任何

全连接权重

层的卷积网

络。相对的，最

后的卷积层

为每个类输

出一个特征

映射。该

模型

可能会用来

学习每个类

出现在每个

空间位置的

可能性的映

射。将特征映

射进行平均

得到的单

个

值，提供了顶

部 softmax

分类器的

变量。

9.4 卷积与

池化作为一

种无限强的

先验 295

9.4 卷积与

池化作为一

种无限强的

先验

回忆一

下第 5.2

节中 先

验概率分布

（prior probability distribution）的概念。这

是

一个模型参

数的概率分

布，它刻画了

在我们看到

数据之前我

们认为什么

样的模型

是

合理的信念

。

先验被认为

是强或者弱

取决于先验

中概率密度

的集中程度

。弱先验具有

较高的

熵值

，例如方差很

大的高斯分

布。这样的先

验允许数据

对于参数的

改变具有或

多或

少的自

由性。强先验

具有较低的

熵值，例如方

差很小的高

斯分布。这样

的先验在决

定参数最终

取值时起着

更加积极的

作用。

一个无

限强的先验

需要对一些

参数的概率

置零并且完

全禁止对这

些参数赋值

，

无论数据对

于这些参数

的值给出了

多大的支持

。

我们可以把

卷积网络类

比成全连接

网络，但对于

这个全连接

网络的权重

有一个

无限

强的先验。这

个无限强的

先验是说一

个隐藏单元

的权重必须

和它邻居的

权重相

同，但

可以在空间

上移动。这个

先验也要求

除了那些处

在隐藏单元

的小的空间

连续

的接受

域内的权重

以外，其余的

权重都为零

。总之，我们可

以把卷积的

使用当作是

对网络中一

层的参数引

入了一个无

限强的先验

概率分布。这

个先验说明

了该层应该

学得的函数

只包含局部

连接关系并

且对平移具

有等变性。类

似的，使用池

化也是一

个

无限强的先

验：每一个单

元都具有对

少量平移的

不变性。

当然

，把卷积神经

网络当作一

个具有无限

强先验的全

连接网络来

实现会导致

极

大的计算

浪费。但把卷

积神经网络

想成具有无

限强先验的

全连接网络

可以帮助我

们

更好地洞

察卷积神经

网络是如何

工作的。

其中

一个关键的

洞察是卷积

和池化可能

导致欠拟合

。与任何其他

先验类似，卷

积和池化只

有当先验的

假设合理且

正确时才有

用。如果一项

任务依赖于

保存精确

的

空间信息，那

么在所有的

特征上使用

池化将会增

大训练误差

。一些卷积网

络结

构 (Szegedy et

al., 2014a) 为了

既获得具有

较高不变性

的特征又获

得当平移不

变性不

合理

时不会导致

欠拟合的特

征，被设计成

在一些通道

上使用池化

而在另一些

通道上

不使

用。当一项任

务涉及到要

对输入中相

隔较远的信

息进行合并

时，那么卷积

所利

用的先

验可能就不

正确了。

另一

个关键洞察

是当我们比

较卷积模型

的统计学习

表现时，只能

以基准中的

其

他卷积模

型作为比较

的对象。其他

不使用卷积

的模型即使

我们把图像

中的所有像

素

点都置换

后依然有可

能进行学习

。对于许多图

像数据集，还

有一些分别

的基准，有

296 第

九章 卷积网

络

些是针对

那些具有 置

换不变性（permutation invariant）并

且必须通过

学习发现拓

扑结构的模

型，还有一些

是针对模型

设计者将空

间关系的知

识植入了它

们的模型。

9.5

基

本卷积函数

的变体

当在

神经网络的

上下文中讨

论卷积时，我

们通常不是

特指数学文

献中使用的

那

种标准的

离散卷积运

算。实际应用

中的函数略

有不同。这里

我们详细讨

论一下这些

差异，并且对

神经网络中

用到的函数

的一些重要

性质进行重

点说明。

首先

，当我们提到

神经网络中

的卷积时，我

们通常是指

由多个并行

卷积组成的

运算。这是因

为具有单个

核的卷积只

能提取一种

类型的特征

，尽管它作用

在多个空

间

位置上。我们

通常希望网

络的每一层

能够在多个

位置提取多

种类型的特

征。

另外，输入

通常也不仅

仅是实值的

网格，而是由

一系列观测

数据的向量

构成的

网格

。例如，一幅彩

色图像在每

一个像素点

都会有红绿

蓝三种颜色

的亮度。在多

层

的卷积网

络中，第二层

的输入是第

一层的输出

，通常在每个

位置包含多

个不同卷积

的输出。当处

理图像时，我

们通常把卷

积的输入输

出都看作是

3

维的张量，其

中一

个索引

用于标明不

同的通道（例

如红绿蓝），另

外两个索引

标明在每个

通道上的空

间

坐标。软件

实现通常使

用批处理模

式，所以实际

上会使用 4

维

的张量，第四

维索引

用于

标明批处理

中不同的实

例，但我们为

简明起见这

里忽略批处

理索引。

因为

卷积网络通

常使用多通

道的卷积，所

以即使使用

了核翻转，也

不一定保证

网络的线性

运算是可交

换的。只有当

其中的每个

运算的输出

和输入具有

相同的通道

数时，这些多

通道的运算

才是可交换

的。。

假定我们

有一个

4 维的

核张量 K，它的

每一个元素

是 Ki,j,k,l，表示输出

中处于

通道

i 的一个单元

和输入中处

于通道 j 中的

一个单元的

连接强度，并

且在输出单

元

和输入单

元之间有 k 行

l 列的偏置。假

定我们的输

入由观测数

据

V 组成，它的

每一

个元素

是 Vi,j,k，表示处在

通道

i 中第 j 行

第

k 列的值。假

定我们的输

出 Z 和输入

V 具

有相同的形

式。如果输出

Z 是通过对 K

和

V 进行卷积而

不涉及翻转

K 得到

的，那么

Zi,j,k

=

∑

l,m,n

Vl,j+m−1,k+n−1Ki,l,m,n,

(9.7)

这里对所有

的 l，m 和

n 进行求

和是对所有

（在求和式中

）有效的张量

索引的值进

行求和。在线

性代数中，向

量的索引通

常从 1 开始，这

就是上述公

式中

−1 的由来

。

9.5 基本卷积函

数的变体

297

但

是像 C 或

Python 这类

编程语言索

引通常从 0 开

始，这使得上

述公式可以

更加简

洁。

我

们有时会希

望跳过核中

的一些位置

来降低计算

的开销（相应

的代价是提

取

特征没有

先前那么好

了）。我们可以

把这一过程

看作是对全

卷积函数输

出的下采样

(downsampling)。如果我们只

想在输出的

每个方向上

每间隔 s

个像

素进行采样

，那

么我们可

以定义一个

下采样卷积

函数 c 使得

Zi,j,k = c(K, V,

s)i,j,k =

∑

l,m,n

[Vl,(j−1)×s+m,(k−1)×s+n,Ki,l,m,n]. (9.8)

我

们把 s

称为下

采样卷积的

步幅（stride）。当然也

可以对每个

移动方向定

义不同的

步

幅。图 9.12 演示了

一个实例。

在

任何卷积网

络的实现中

都有一个重

要性质，那就

是能够隐含

地对输入 V 用

零

进行填充

(pad)

使得它加宽

。如果没有这

个性质，表示

的宽度在每

一层就会缩

减，缩

减的幅

度是比核少

一个像素这

么多。对输入

进行零填充

允许我们对

核的宽度和

输出

的大小

进行独立的

控制。如果没

有零填充，我

们就被迫面

临二选一的

局面，要么选

择网络空间

宽度的快速

缩减，要么选

择一个小型

的核——这两种

情境都会极

大得限

制网

络的表示能

力。图9.13

给出了

一个例子。

有

三种零填充

设定的情况

值得注意。第

一种是无论

怎样都不使

用零填充的

极端

情况，并

且卷积核只

允许访问那

些图像中能

够完全包含

整个核的位

置。在 MATLAB

的术语

中，这称为 有

效（valid）卷积。在这

种情况下，输

出的所有像

素都是输入

中

相同数量

像素的函数

，这使得输出

像素的表示

更加规范。然

而，输出的大

小在每一

层

都会缩减。如

果输入的图

像宽度是

m，核

的宽度是 k，那

么输出的宽

度就会变成

m − k

+ 1。如果卷积核

非常大的话

缩减率会非

常显著。因为

缩减数大于

0，这限制

了网

络中能够包

含的卷积层

的层数。当层

数增加时，网

络的空间维

度最终会缩

减到

1

× 1，这种情

况下增加的

层就不可能

进行有意义

的卷积了。第

二种特殊的

情况是只

进

行足够的零

填充来保持

输出和输入

具有相同的

大小。在 MATLAB

的术

语中，这

称为

相同（same）卷积。在

这种情况下

，只要硬件支

持，网络就能

包含任意多

的卷

积层，这

是因为卷积

运算不改变

下一层的结

构。。然而，输入

像素中靠近

边界的部分

相比于中间

部分对于输

出像素的影

响更小。这可

能会导致边

界像素存在

一定程度的

欠表示。这使

得第三种极

端情况产生

了，在 MATLAB

中称为

全（full）卷积。它进

行了足够多

的零填充使

得每个像素

在每个方向

上恰好被访

问了 k 次，最终

输出图像

的

宽度为

m + k −

1。在这

种情况下，输

出像素中靠

近边界的部

分相比于中

间部分是

更

少像素的函

数。这将导致

学得一个在

卷积特征映

射的所有位

置都表现不

错的单核

298 第

九章

卷积网

络

xx11 xx22 xx33

ss11 ss22

xx44 xx55

ss33

xx11 xx22 xx33

zz22 zz11 zz33

xx44

zz44

xx55

zz55

ss11

ss22 ss33

Strided

convolution

Downsampling

Convolution

图 9.12:

带有步

幅的卷积。在

这个例子中

，我们的步幅

为二。(上) 在单

个操作中实

现的步幅为

二的

卷积。(下

) 步幅大于一

个像素的卷

积在数学上

等价于单位

步幅的卷积

随后降采样

。显然，涉及降

采

样的两步

法在计算上

是浪费的，因

为它计算了

许多将被丢

弃的值。

更为

困难。通常零

填充的最优

数量（对于测

试集的分类

正确率）处于

“有效卷积’’ 和

“相同卷积’’ 之

间的某个位

置。

在一些情

况下，我们并

不是真的想

使用卷积，而

是想用一些

局部连接的

网络层

(LeCun, 1986, 1989)。在这

种情况下，我

们的多层感

知机对应的

邻接矩阵是

相同的，

但每

一个连接都

有它自己的

权重，用一个

6 维的张量 W 来

表示。W

的索引

分别是：

输出

的通道 i，输出

的行 j

和列 k，输

入的通道 l，输

入的行偏置

m 和列偏置

n。局

部连接层的

线性部分可

以表示为

Zi,j,k =

∑

l,m,n

[Vl,j+m−1,k+n−1wi,j,k,l,m,n]. (9.9)

9.5

基

本卷积函数

的变体 299

... ...

...

... ...

...

...

... ...

图

9.13: 零

填充对网络

大小的影响

。考虑一个卷

积网络，每层

有一个宽度

为六的核。在

这个例子

中

，我们不使用

任何池化，所

以只有卷积

操作本身缩

小网络的大

小。(上) 在这个

卷积网络中

，我

们不使用

任何隐含的

零填充。这使

得表示在每

层缩小五个

像素。从十六

个像素的输

入开始，我们

只能有三个

卷积层，并且

最后一层不

能移动核，所

以可以说只

有两层是真

正的卷积层

。可以通过

使

用较小的核

来减缓收缩

速率，但是较

小的核表示

能力不足，并

且在这种结

构中一些收

缩是不可

避

免的。(下) 通过

向每层添加

五个隐含的

零，我们防止

了表示随深

度收缩。这允

许我们设计

一个

任意深

的卷积网络

。

这有时也被

称为 非共享

卷积（unshared convolution），因为它

和具有一个

小核的离

散

卷积运算很

像，但并不横

跨位置来共

享参数。图9.14比

较了局部连

接、卷积和全

连

接的区别

。

当我们知道

每一个特征

都是一小块

空间的函数

并且相同的

特征不会出

现在所有

的

空间上时，局

部连接层是

很有用的。例

如，如果我们

想要辨别一

张图片是否

是人

脸图像

时，我们只需

要去寻找嘴

是否在图像

下半部分即

可。

使用那些

连接被更进

一步限制的

卷积或者局

部连接层也

是有用的，例

如，限制

300 第九

章

卷积网络

xx11 xx22 xx33

ss22

ss11 ss33

xx44

ss44

xx55

ss55

xx11 xx22

ss11 ss33

xx55

ss55

xx11 xx22 xx33

ss22

ss11 ss33

xx44

ss44

xx55

ss55

a b

a b a b

a b a

a b c d

e f g h

i 

xx44 xx33

ss44 ss22

图 9.14:

局部连接

，卷积和全连

接的比较。(上

) 每一小片（接

受域）有两个

像素的局部

连接层。每

条

边用唯一的

字母标记，来

显示每条边

都有自身的

权重参数。(中

) 核宽度为两

个像素的卷

积层。

该模型

与局部连接

层具有完全

相同的连接

。区别不在于

哪些单元相

互交互，而在

于如何共享

参数。

局部连

接层没有参

数共享。正如

用于标记每

条边的字母

重复出现所

指示的，卷积

层在整个输

入上

重复使

用相同的两

个权重。(下) 全

连接层类似

于局部连接

层，它的每条

边都有其自

身的参数（在

该图中用字

母明确标记

的话就太多

了）。然而，它不

具有局部连

接层的连接

受限的特征

。

每一个输出

的通道 i 仅仅

是输入通道

l 的一部分的

函数时。实现

这种情况的

一种通

用方

法是使输出

的前 m 个通道

仅仅连接到

输入的前 n

个

通道，输出的

接下来的 m

个

通道仅仅连

接到输入的

接下来的 n

个

通道，以此类

推。图 9.15 给出了

一个例子。

对

少量通道间

的连接进行

建模允许网

络使用更少

的参数，这降

低了存储的

消耗以及

提

高了统计效

率，并且减少

了前向和反

向传播所需

要的计算量

。这些目标的

实现并

没有

减少隐藏单

元的数目。

平

铺卷积（tiled convolution）(Gregor

and LeCun, 2010a; Le

et al., 2010) 对卷

积层和局部

连接层进行

了折衷。这里

并不是对每

一个空间位

置的权重集

合进行学习

，

我们学习一

组核使得当

我们在空间

移动时它们

可以循环利

用。这意味着

在近邻的位

9.5 基本卷积函

数的变体 301

置

上拥有不同

的过滤器，就

像局部连接

层一样，但是

对于这些参

数的存储需

求仅仅

会增

长常数倍，这

个常数就是

核的集合的

大小，而不是

整个输出的

特征映射的

大小。

图 9.16 对局

部连接层、平

铺卷积和标

准卷积进行

了比较。

为了

用代数的方

法定义平铺

卷积，令 K 是一

个 6

维的张量

5，其中的两维

对应

着输出

映射中的不

同位置。K 在这

里并没有对

输出映射中

的每一个位

置使用单独

的

索引，输出

的位置在每

个方向上在

t

个不同的核

组成的集合

中进行循环

。如果 t 等

于输

出的宽度，这

就是局部连

接层了。

Zi,j,k =

∑

l,m,n

Vl,j+m−1,k+n−1Ki,l,m,n,j%t+1,k%t+1, (9.10)

这里

百分号是取

模运算，它的

性质包括 t%t

= 0,(t + 1)%t

= 1 等

等。在每一维

上使

用不同

的

t 可以很容

易对这个方

程进行扩展

。

局部连接层

与平铺卷积

层都和最大

池化有一些

有趣的关联

：这些层的探

测单元

都是

由不同的过

滤器驱动的

。如果这些过

滤器能够学

会探测相同

隐含特征的

不同变

换形

式，那么最大

池化的单元

对于学得的

变换就具有

不变性（如图

9.9 所示）。卷积

层

对于平移具

有内置的不

变性。

实现卷

积网络时，通

常也需要除

卷积以外的

其他运算。为

了实现学习

，必须在

给定

输出的梯度

时能够计算

核的梯度。在

一些简单情

况下，这种运

算可以通过

卷积

来实现

，但在很多我

们感兴趣的

情况下，包括

步幅大于 1 的

情况，并不具

有这样的

性

质。

回忆一下

卷积是一种

线性运算，所

以可以表示

成矩阵乘法

的形式（如果

我们首

先把

输入张量变

形为一个扁

平的向量）。其

中包含的矩

阵是关于卷

积核的函数

。这个

矩阵是

稀疏的并且

核的每个元

素都复制给

矩阵的多个

元素。这种观

点能够帮助

我们

导出实

现一个卷积

网络所需的

很多其他运

算。

通过卷积

定义的矩阵

转置的乘法

就是这样一

种运算。这种

运算用于在

卷积层反

向

传播误差的

导数，所以它

在训练多于

一个隐藏层

的卷积网络

时是必要的

。如果我们

想

要从隐藏层

单元重构可

视化单元时

，同样的运算

也是需要的

(Simard

et al., 1992)。

重构可视化

单元是本书

第三部分的

模型广泛用

到的一种运

算，这些模型

包括自编码

器、RBM和稀疏编

码等等。构建

这些模型的

卷积化的版

本都要用到

转置化卷积

。类

似核梯度

运算，这种输

入梯度运算

在某些情况

下可以用卷

积来实现，但

在一般情况

下需要用到

第三种运算

来实现。必须

非常小心地

来使这种转

置运算和前

向传播过程

5译者注：原文

将 K 误写成了

k。

302

第九章 卷积

网络

相协调

。转置运算返

回的输出的

大小取决于

三个方面：零

填充的策略

、前向传播运

算的步幅以

及前向传播

的输出映射

的大小。在一

些情况下，不

同大小的输

入通过前

向

传播过程能

够得到相同

大小的输出

映射，所以必

须明确地告

知转置运算

原始输入

的

大小。

这三种

运算——卷积、从

输出到权重

的反向传播

和从输出到

输入的反向

传播

——对于训

练任意深度

的前馈卷积

网络，以及训

练带有（基于

卷积的转置

的）重构

函数

的卷积网络

，这三种运算

都足以计算

它们所需的

所有梯度。对

于完全一般

的多

维、多样

例情况下的

公式，完整的

推导可以参

考 Goodfellow (2010)。为了直观

说明

这些公

式是如何起

作用的，我们

这里给出一

个二维单个

样例的版本

。

假设我们想

要训练这样

一个卷积网

络，它包含步

幅为 s 的步幅

卷积，该卷积

的

核为

K，作用

于多通道的

图像 V，定义为

c(K, V, s)，就像式(9.8)

中一

样。假设我们

想要最小化

某个损失函

数 J(V, K)。在前向传

播过程中，我

们需要用 c

本

身来输出

Z，然

后 Z 传递到网

络的其余部

分并且被用

来计算损失

函数

J。在反向

传播过程中

，

我们会得到

一个张量 G 满

足

Gi,j,k = ∂Z

∂

i,j,k

J(V, K)。

为了训练

网络，我们需

要对核中的

权重求导。为

了实现这个

目的，我们可

以使

用一个

函数

g(G, V, s)i,j,k,l

=

∂

∂Ki,j,k,l

J(V,

K) = ∑

m,n

Gi,m,nVj,(m−1)×s+k,(n−1)×s+l

. (9.11)

如果这

一层不是网

络的底层，我

们需要对

V 求

梯度来使得

误差进一步

反向传播。

我

们可以使用

如下的函数

h(K, G,

s)i,j,k =

∂

∂Vi,j,k

J(V, K) (9.12)

=

∑

l,m

s.t.

(l−1)×s+m=j

∑

n,p

s.t.

(n−1)×s+p=k

∑

q

Kq,i,m,pGq,l,n. (9.13)

第十四章描

述的自编码

器网络，是一

些被训练成

把输入拷贝

到输出的前

馈网

络。一个

简单的例子

是 PCA 算法，将输

入

x 拷贝到一

个近似的重

构值 r，通过函

数

W⊤Wx

来实现。使

用权重矩阵

转置的乘法

，就像 PCA 算法这

种，在一般的

自编码

器中

是很常见的

。为了使这些

模型卷积化

，我们可以用

函数

h 来实现

卷积运算的

转

置。假定我

们有和 Z

相同

形式的隐藏

单元 H，并且我

们定义一种

重构运算

R =

h(K, H, s). (9.14)

9.5 基

本卷积函数

的变体 303

为了

训练自编码

器，我们会得

到关于

R 的梯

度，表示为一

个张量 E。为了

训练

解码器

，我们需要获

得对于

K 的梯

度，这通过 g(H, E,

s) 来

得到。为了训

练编码器，

我

们需要获得

对于 H

的梯度

，这通过 c(K, E, s)

来得

到。通过用 c 和

h 对

g 求微分

也

是可行的，但

这些运算对

于任何标准

神经网络上

的反向传播

算法来说都

是不需要

的

。

一般来说，在

卷积层从输

入到输出的

变换中我们

不仅仅只用

线性运算。我

们一

般也会

在进行非线

性运算前，对

每个输出加

入一些偏置

项。这样就产

生了如何在

偏

置项中共

享参数的问

题。对于局部

连接层，很自

然地对每个

单元都给定

它特有的偏

置，对于平铺

卷积，也很自

然地用与核

一样的平铺

模式来共享

参数。对于卷

积层来

说，通

常的做法是

在输出的每

一个通道上

都设置一个

偏置，这个偏

置在每个卷

积映

射的所

有位置上共

享。然而，如果

输入是已知

的固定大小

，也可以在输

出映射的每

个

位置学习

一个单独的

偏置。分离这

些偏置可能

会稍稍降低

模型的统计

效率，但同时

也允许模型

来校正图像

中不同位置

的统计差异

。例如，当使用

隐含的零填

充时，图

像边

缘的探测单

元接收到较

少的输入，因

此需要较大

的偏置。

304

第九

章 卷积网络

Input Tensor

Output

Tensor

Spatial coordinates

图

9.15: 卷积网络

的前两个输

出通道只和

前两个输入

通道相连，随

后的两个输

出通道只和

随后的

两个

输入通道相

连。

Channel

coordinates

9.5 基本卷积

函数的变体

305

xx11

xx22 xx33

ss22 ss11

ss33

xx44

ss44

xx55

ss55

xx11 xx22 xx33

ss22 ss11 ss33

xx44

ss44

xx55

ss55

a

b a b a

b a b a

a b c d

e f g h

i 

xx11 xx22

xx33

ss22 ss11 ss33

xx44

ss44

xx55

ss55

a b c d

a b c d

a 

图 9.16:

局部连接

层、平铺卷积

和标准卷积

的比较。当使

用相同大小

的核时，这三

种方法在单

元之

间具有

相同的连接

。此图是对使

用两个像素

宽的核的说

明。这三种方

法之间的区

别在于它们

如何

共享参

数。(上) 局部连

接层根本没

有共享参数

。我们对每个

连接使用唯

一的字母标

记，来表明每

个连接都有

它自身的权

重。(中)平铺卷

积有

t 个不同

的核。这里我

们说明 t =

2 的情

况。其中一个

核具有标记

为 “a’’ 和

“b’’ 的边，而

另一个具有

标记为 “c’’ 和

“d’’ 的

边。每当我们

在输出中右

移一

个像素

后，我们使用

一个不同的

核。这意味着

，与局部连接

层类似，输出

中的相邻单

元具有不同

的

参数。与局

部连接层不

同的是，在我

们遍历所有

可用的

t 个核

之后，我们循

环回到了第

一个核。如

果

两个输出单

元间隔 t

个步

长的倍数，则

它们共享参

数。(下) 传统卷

积等效于 t =

1 的

平铺卷积。

它

只有一个核

，并且被应用

到各个地方

，我们在图中

表示为在各

处使用具有

标记为 “a’’

和 “b’’ 的

边的核。

306

第九

章 卷积网络

9.6 结构化输出

卷积神经网

络可以用于

输出高维的

结构化对象

，而不仅仅是

预测分类任

务的类

标签

或回归任务

的实数值。通

常这个对象

只是一个张

量，由标准卷

积层产生。例

如，

模型可以

产生张量 S，其

中 Si,j,k 是网络的

输入像素

(j, k) 属

于类 i

的概率

。这允许

模型

标记图像中

的每个像素

，并绘制沿着

单个对象轮

廓的精确掩

模。

经常出现

的一个问题

是输出平面

可能比输入

平面要小，如

图 9.13

所示。用于

对图像中单

个对象分类

的常用结构

中，网络空间

维数的最大

减少来源于

使用大步

幅

的池化层。为

了产生与输

入大小相似

的输出映射

，我们可以避

免把池化放

在一起

(Jain et

al., 2007)。另一

种策略是单

纯地产生一

张低分辨率

的标签网格

(Pinheiro

and Collobert,

2014, 2015)。最后，原则上

可以使用具

有单位步幅

的池化操作

。

对图像逐个

像素标记的

一种策略是

先产生图像

标签的原始

猜测，然后使

用相邻

像素

之间的交互

来修正该原

始猜测。重复

这个修正步

骤数次对应

于在每一步

使用相

同的

卷积，该卷积

在深层网络

的最后几层

之间共享权

重 (Jain et al.,

2007)。这使得在

层之间共享

参数的连续

的卷积层所

执行的一系

列运算，形成

了一种特殊

的循环神经

网络 (Pinheiro and Collobert,

2014, 2015)。图 9.17 给出

了这样一个

循环卷积网

络的

结构。

一

旦对每个像

素都进行了

预测，我们就

可以使用各

种方法来进

一步处理这

些

预测，以便

获得图像在

区域上的分

割 (Briggman

et al., 2009; Turaga

et al., 2010;

Farabet

et al., 2013)。一般的想

法是假设大

片相连的像

素倾向于对

应着相同的

标签。

图模型

可以描述相

邻像素间的

概率关系。或

者，卷积网络

可以被训练

来最大化地

近

似图模型

的训练目标

(Ning et al., 2005;

Thompson et al., 2014)。

9.7 数据类型 307

YYˆˆ

(1) (1)

YYˆˆ (2)

(2)

YYˆˆ (3) (3)

HH(1) (1) HH(2) (2)

HH(3) (3)

X

U

U U

V V

V W W

图

9.17:

用于像素标

记的循环卷

积网络的示

例。输入是图

像张量 X，它的

轴对应图像

的行、列和通

道（红，绿，蓝）。目

标是输出标

签张量 Yˆ，它遵

循每个像素

的标签的概

率分布。该张

量的轴对应

图像的行、列

和不同类别

。循环网络通

过使用 Yˆ

的先

前估计作为

创建新估计

的输入，来迭

代地改

善其

估计，而不是

单次输出 Yˆ，。每

个更新的估

计使用相同

的参数，并且

估计可以如

我们所愿地

被

改善任意

多次。每一步

使用的卷积

核张量

U，是用

来计算给定

输入图像的

隐藏表示的

。核张量 V

用于

产生给定隐

藏值时标签

的估计。除了

第一步之外

，核 W

都对 Yˆ 进行

卷积来提供

隐藏层的输

入。在第一步

中，此项由零

代替。因为每

一步使用相

同的参数，所

以这是一个

循环网络的

例子，如

第十

章所述。

9.7 数据

类型

卷积网

络使用的数

据通常包含

多个通道，每

个通道是时

间上或空间

中某一点的

不同观测量

。参考表 9.1

来了

解具有不同

维数和通道

数的数据类

型的例子。

卷

积网络用于

视频的例子

，可以参考 Chen et

al. (2010)。

到

目前为止，我

们仅讨论了

训练和测试

数据中的每

个样例都有

相同的空间

维度

的情况

。卷积网络的

一个优点是

它们还可以

处理具有可

变的空间尺

度的输入。这

些

类型的输

入不能用传

统的基于矩

阵乘法的神

经网络来表

示。这为卷积

网络的使用

提

供了令人

信服的理由

，即使当计算

开销和过拟

合都不是主

要问题时。

例

如，考虑一组

图像的集合

，其中每个图

像具有不同

的高度和宽

度。目前还不

清楚如何用

固定大小的

权重矩阵对

这样的输入

进行建模。卷

积就可以很

直接地应用

；

核依据输入

的大小简单

地被使用不

同次，并且卷

积运算的输

出也相应地

放缩。卷积

可

以被视为矩

阵乘法；相同

的卷积核为

每种大小的

输入引入了

一个不同大

小的双重

分

块循环矩阵

。有时，网络的

输出允许和

输入一样具

有可变的大

小，例如如果

我们

想要为

输入的每个

像素分配一

个类标签。在

这种情况下

，不需要进一

步的设计工

作。

在其他情

况下，网络必

须产生一些

固定大小的

输出，例如，如

果我们想要

为整个图

308 第

九章 卷积网

络

单通道

多

通道

1 维 音频

波形：卷积的

轴对应于时

间。

我们将时

间离散化并

且在每个时

间点测量一

次波形的振

幅。

骨架动画

(skeleton animation) 数

据：计算机

渲染的 3D 角色

动画是

通过

随时间调整

‘‘骨架’’

的姿势

而生成的。在

每个时间点

，角色的

姿势

通过骨架中

的每个关节

的角

度来描

述。我们输入

到卷积模型

的数据的每

个通道，表示

一个关

节关

于一个轴的

角度。

2 维 已经

使用傅立叶

变换预处理

过的

音频数

据：我们可以

将音频波形

变换成

2 维张

量，不同的行

对应

不同的

频率，不同的

列对应不同

的时间点。在

时间轴上使

用卷积

使模

型等效于在

时间上移动

。在

频率轴上

使用卷积使

得模型等效

于在频率上

移动，这使得

在不同

八度

音阶中播放

的相同旋律

产生

相同的

表示，但处于

网络输出中

的不同高度

。

彩色图像数

据：其中一个

通道包

含红

色像素，另一

个包含绿色

像

素，最后一

个包含蓝色

像素。在图

像

的水平轴和

竖直轴上移

动卷积

核，赋

予了两个方

向上平移等

变

性。

3 维 体积

数据：这种数

据一般来源

于

医学成像

技术，例如 CT 扫

描等。

彩色视

频数据：其中

一个轴对应

着时间，另一

个轴对应着

视频帧

的高

度，最后一个

对应着视频

帧

的宽度。

表

9.1: 用于卷积网

络的不同数

据格式的示

例。

9.8 高效的卷

积算法 309

像指

定单个类标

签。在这种情

况下，我们必

须进行一些

额外的设计

步骤，例如插

入

一个池化

层，池化区域

的大小要与

输入的大小

成比例，以便

保持固定数

量的池化输

出。这种策略

的一些例子

可以参考图

9.11 。

注意，使用卷

积处理可变

尺寸的输入

，仅对输入是

因为包含对

同种事物的

不同

量的观

察

(时间上不

同长度的记

录，空间上不

同宽度的观

察等) 而导致

的尺寸变化

这

种情况才

有意义。如果

输入是因为

它可以选择

性地包括不

同种类的观

察而具有可

变

尺寸，使用

卷积是不合

理的。例如，如

果我们正在

处理大学申

请，并且我们

的特征

包括

成绩等级和

标准化测试

分数，但不是

每个申请人

都进行了标

准化测试，则

使用

相同的

权重来对成

绩特征和测

试分数特征

进行卷积是

没有意义的

。

9.8 高效的卷积

算法

现代卷

积网络的应

用通常需要

包含超过百

万个单元的

网络。利用并

行计算资源

的强大实现

是很关键的

，如第 12.1 节中所

描述的。然而

，在很多情况

下，也可以通

过选择适当

的卷积算法

来加速卷积

。

卷积等效于

使用傅立叶

变换将输入

与核都转换

到频域、执行

两个信号的

逐点相

乘，再

使用傅立叶

逆变换转换

回时域。对于

某些问题的

规模，这种算

法可能比离

散

卷积的朴

素实现更快

。

当一个 d

维的

核可以表示

成 d 个向量（每

一维一个向

量）的外积时

，该核被称

为

可分离的（separable）。当

核可分离时

，朴素的卷积

是低效的。它

等价于组合

d

个

一维卷积

，每个卷积使

用这些向量

中的一个。组

合方法显著

快于使用它

们的外积来

执行一个 d 维

的卷积。并且

核也只要更

少的参数来

表示成向量

。如果核在每

一维都

是 w 个

元素宽，那么

朴素的多维

卷积需要 O(w

d

) 的

运行时间和

参数存储空

间，而可

分离

卷积只需要

O(w

× d) 的运行时间

和参数存储

空间。当然，并

不是每个卷

积都可

以表

示成这种形

式。

设计更快

的执行卷积

或近似卷积

，而不损害模

型准确性的

方法，是一个

活跃的

研究

领域。甚至仅

提高前向传

播效率的技

术也是有用

的，因为在商

业环境中，通

常

部署网络

比训练网络

还要耗资源

。

310

第九章 卷积

网络

9.9 随机或

无监督的特

征

通常，卷积

网络训练中

最昂贵的部

分是学习特

征。输出层的

计算代价通

常相对

不高

，因为在通过

若干层池化

之后作为该

层输入的特

征的数量较

少。当使用梯

度下

降执行

监督训练时

，每步梯度计

算需要完整

地运行整个

网络的前向

传播和反向

传播。

减少卷

积网络训练

成本的一种

方式是使用

那些不是由

监督方式训

练得到的特

征。

有三种基

本策略可以

不通过监督

训练而得到

卷积核。其中

一种是简单

地随机初

始

化它们。另一

种是手动设

计它们，例如

设置每个核

在一个特定

的方向或尺

度来检

测边

缘。最后，可以

使用无监督

的标准来学

习核。例如，Coates et

al. (2011) 将

k 均

值聚类算

法应用于小

图像块，然后

使用每个学

得的中心作

为卷积核。第

三部分描述

了更多的无

监督学习方

法。使用无监

督的标准来

学习特征，允

许这些特征

的确定与

位

于网络结构

顶层的分类

层相分离。然

后只需提取

一次全部训

练集的特征

，构造用

于最

后一层的新

训练集。假设

最后一层类

似逻辑回归

或者 SVM，那么学

习最后一层

通常是凸优

化问题。

随机

过滤器经常

在卷积网络

中表现得出

乎意料得好

Jarrett et al. (2009b);

Saxe

et al. (2011);

Pinto et al. (2011);

Cox and Pinto (2011)。Saxe

et al. (2011) 说明，由

卷积

和随后的池

化组成的层

，当赋予随机

权重时，自然

地变得具有

频率选择性

和平

移不变

性。他们认为

这提供了一

种廉价的方

法来选择卷

积网络的结

构：首先通过

仅

训练最后

一层来评估

几个卷积网

络结构的性

能，然后选择

最好的结构

并使用更昂

贵

的方法来

训练整个网

络。

一个中间

方法是学习

特征，但是使

用那种不需

要在每个梯

度计算步骤

中都进行

完

整的前向和

反向传播的

方法。与多层

感知机一样

，我们使用贪

心逐层预训

练，单

独训练

第一层，然后

一次性地从

第一层提取

所有特征，之

后用那些特

征单独训练

第二层，以此

类推。第八章

描述了如何

实现监督的

贪心逐层预

训练，第三部

分将此

扩展

到了无监督

的范畴。卷积

模型的贪心

逐层预训练

的经典模型

是卷积深度

信念网

络(Lee et al., 2009)。卷

积网络为我

们提供了相

对于多层感

知机更进一

步采用预训

练策略的机

会。并非一次

训练整个卷

积层，我们可

以训练一小

块模型，就像

Coates

et al. (2011) 使用

k 均值做

的那样。然后

，我们可以用

来自这个小

块模型的参

数来定

义卷

积层的核。这

意味着使用

无监督学习

来训练卷积

网络并且在

训练的过程

中完全

不使

用卷积是可

能的。使用这

种方法，我们

可以训练非

常大的模型

，并且只在推

断期

间产生

高计算成本

(Ranzato et al., 2007c;

Jarrett et al., 2009b;

Kavukcuoglu et al.,

2010;

Coates et al., 2013)。这种方法大

约在

2007 到 2013 年间

流行，当时标

记的数

9.10 卷积

网络的神经

科学基础 311

据

集很小，并且

计算能力有

限。如今，大多

数卷积网络

以纯粹监督

的方式训练

，在每

次训练

迭代中使用

通过整个网

络的完整的

前向和反向

传播。

与其他

无监督预训

练的方法一

样，使用这种

方法的一些

好处仍然难

以说清。无

监

督预训练可

以提供一些

相对于监督

训练的正则

化，或者它可

以简单地允

许我们训

练

更大的结构

，因为它的学

习规则降低

了计算成本

。

9.10 卷积网络的

神经科学基

础

卷积网络

也许是生物

学启发人工

智能的最为

成功的案例

。虽然卷积网

络也经过

许

多其他领域

的指导，但是

神经网络的

一些关键设

计原则来自

于神经科学

。

卷积网络的

历史始于神

经科学实验

，远早于相关

计算模型的

发展。为了确

定关

于哺乳

动物视觉系

统如何工作

的许多最基

本的事实，神

经生理学家

David Hubel 和

Torsten Wiesel 合作多年

(Hubel and

Wiesel, 1959, 1962, 1968)。他们的成就

最终获

得了

诺贝尔奖。他

们的发现对

当代深度学

习模型有最

大影响的是

基于记录猫

的单个

神经

元的活动。他

们观察了猫

的脑内神经

元如何响应

投影在猫前

面屏幕上精

确位置

的图

像。他们的伟

大发现是，处

于视觉系统

较为前面的

神经元对非

常特定的光

模式

（例如精

确定向的条

纹）反应最强

烈，但对其他

模式几乎完

全没有反应

。

他们的工作

有助于表征

大脑功能的

许多方面，这

些方面超出

了本书的范

围。从

深度学

习的角度来

看，我们可以

专注于简化

的、草图形式

的大脑功能

视图。

在这个

简化的视图

中，我们关注

被称为 V1

的大

脑的一部分

，也称为 初级

视觉

皮层（primary visual

cortex）。V1 是

大脑对视觉

输入开始执

行显著高级

处理的第一

个区域。在该

草图视图中

，图像是由光

到达眼睛并

刺激视网膜

（眼睛后部的

光敏组

织）形

成的。视网膜

中的神经元

对图像执行

一些简单的

预处理，但是

基本不改变

它

被表示的

方式。然后图

像通过视神

经和称为外

侧膝状核的

脑部区域。这

些解剖区域

的主要作用

是仅仅将信

号从眼睛传

递到位于头

后部的

V1。

卷积

网络层被设

计为描述 V1 的

三个性质：

1. V1 可

以进行空间

映射。它实际

上具有二维

结构来反映

视网膜中的

图像结构。例

如，到达视网

膜下半部的

光仅影响 V1

相

应的一半。卷

积网络通过

用二维映射

定义特征的

方式来描述

该特性。

2. V1 包含

许多

简单细

胞（simple cell）。简单细胞

的活动在某

种程度上可

以概括

312 第九

章

卷积网络

为在一个小

的空间位置

感受野内的

图像的线性

函数。卷积网

络的检测器

单元被

设计

为模拟简单

细胞的这些

性质。

3. V1

还包括

许多 复杂细

胞（complex cell）。这些细胞

响应类似于

由简单细胞

检

测的那些

特征，但是复

杂细胞对于

特征的位置

微小偏移具

有不变性。这

启发

了卷积

网络的池化

单元。复杂细

胞对于照明

中的一些变

化也是不变

的，不能简

单

地通过在空

间位置上池

化来刻画。这

些不变性激

发了卷积网

络中的一些

跨通

道池化

策略，例如 maxout

单

元 (Goodfellow et al.,

2013b)。

虽然我们

最了解 V1，但是

一般认为相

同的基本原

理也适用于

视觉系统的

其他区

域。在

我们视觉系

统的草图视

图中，当我们

逐渐深入大

脑时，遵循池

化的基本探

测

策略被反

复执行。当我

们穿过大脑

的多个解剖

层时，我们最

终找到了响

应一些特定

概念的细胞

，并且这些细

胞对输入的

很多种变换

都具有不变

性。这些细胞

被昵称为

‘‘祖

母细胞’’——这个

想法是一个

人可能有一

个神经元，当

看到他祖母

的照片时该

神

经元被激

活，无论祖母

是出现在照

片的左边或

右边，无论照

片是她的脸

部的特写镜

头还是她的

全身照，也无

论她处在光

亮还是黑暗

中，等等。

这些

祖母细胞已

经被证明确

实存在于人

脑中，在一个

被称为内侧

颞叶的区域

(Quiroga

et al., 2005)。研究人员测

试了单个神

经元是否会

响应名人的

照片。他们发

现了后来被

称为 “Halle

Berry 神经元

’’ 的神经元：由

Halle Berry

的概念激活

的单

个神经

元。当一个人

看到 Halle Berry

的照片

，Halle Berry 的图画，甚至

包含单词

“Halle

Berry’’ 的

文本时，这个

神经元会触

发。当然，这与

Halle Berry 本人无关；其

他神经元会

对

Bill Clinton，Jennifer Aniston 等的出现

做出响应。

这

些内侧颞叶

神经元比现

代卷积网络

更通用一些

，这些网络在

读取名称时

不会

自动联

想到识别人

或对象。与卷

积网络的最

后一层在特

征上最接近

的类比是称

为颞

下皮质

（IT）的脑区。当查

看一个对象

时，信息从视

网膜经 LGN

流到

V1，然后到

V2，V4，之后

是 IT。这发生在

瞥见对象的

前 100ms

内。如果允

许一个人继

续观察对

象

更多的时间

，那么信息将

开始回流，因

为大脑使用

自上而下的

反馈来更新

较低级

脑区

中的激活。然

而，如果我们

打断人的注

视，并且只观

察前 100ms

内的大

多数前

向激

活导致的放

电率，那么 IT 被

证明与卷积

网络非常相

似。卷积网络

可以预测

IT

放

电率，并且在

执行对象识

别任务时与

人类（时间有

限的情况）非

常类似 (DiCarlo,

2013)。

话虽

如此，卷积网

络和哺乳动

物的视觉系

统之间还是

有许多区别

。这些区别有

一些是计算

神经科学家

所熟知的，但

超出了本书

的范围。还有

一些区别尚

未知晓，因

9.10 卷

积网络的神

经科学基础

313

为关于哺乳

动物视觉系

统如何工作

的许多基本

问题仍未得

到回答。简要

列表如下：

• 人

眼大部分是

非常低的分

辨率，除了一

个被称为 中

央凹（fovea）的小块

。中

央凹仅观

察在手臂长

度距离内一

块拇指大小

的区域。虽然

我们觉得我

们可以看

到

高分辨率的

整个场景，但

这是由我们

的大脑的潜

意识部分创

建的错觉，因

为

它缝合了

我们瞥见的

若干个小区

域。大多数卷

积网络实际

上接收大的

全分辨率

的

照片作为输

入。人类大脑

控制几次眼

动，称为 扫视

（saccade），以瞥见场景

中最显眼的

或任务相关

的部分。将类

似的注意力

机制融入深

度学习模型

是一

个活跃

的研究方向

。在深度学习

的背景下，注

意力机制对

于自然语言

处理是最

成

功的，参考第

12.4.5.1 节。研究者已

经研发了几

种具有视觉

机制的视觉

模型，

但到目

前为止还没

有成为主导

方法

(Larochelle and Hinton, 2010;

Denil et al.,

2012)。

• 人类视

觉系统集成

了许多其他

感觉，例如听

觉，以及像我

们的心情和

想法一样

的

因素。卷积网

络迄今为止

纯粹是视觉

的。

•

人类视觉

系统不仅仅

用于识别对

象。它能够理

解整个场景

，包括许多对

象和对

象之

间的关系，以

及处理我们

的身体与世

界交互所需

的丰富的三

维几何信息

。

卷积网络已

经应用于这

些问题中的

一些，但是这

些应用还处

于起步阶段

。

•

即使像 V1 这样

简单的大脑

区域也受到

来自较高级

别的反馈的

严重影响。反

馈

已经在神

经网络模型

中被广泛地

探索，但还没

有被证明提

供了引人注

目的改进。

• 虽

然前馈 IT 放电

频率刻画了

与卷积网络

特征很多相

同的信息，但

是仍不清楚

中间计算的

相似程度。大

脑可能使用

非常不同的

激活和池化

函数。单个神

经元

的激活

可能不能用

单个线性过

滤器的响应

来很好地表

征。最近的 V1 模

型涉及

对每

个神经元的

多个二次过

滤器

(Rust et al., 2005)。事实上

，我们的

‘‘简单

细

胞’’ 和 ‘‘复杂

细胞’’

的草图

图片可能并

没有区别；简

单细胞和复

杂细胞可能

是

相同种类

的细胞，但是

它们的 ‘‘参数

’’ 使得它们能

够实现从我

们所说的

‘‘简

单’’

到 ‘‘复杂’’ 的

连续的行为

。

还值得一提

的是，神经科

学很少告诉

我们该如何

训练卷积网

络。具有跨多

个空

间位置

的参数共享

的模型结构

，可以追溯到

早期关于视

觉的联结主

义模型 (Marr

and

Poggio, 1976)，但是

这些模型没

有使用现代

的反向传播

算法和梯度

下降。例如，

(Fukushima, 1980)

结

合了现代卷

积网络的大

多数模型结

构设计元素

，但依赖于层

次

化的无监

督聚类算法

。

314 第九章

卷积

网络

Lang and Hinton

(1988) 引入反

向传播来训

练 时延神经

网络（time delay

neural

network, TDNN）。使用当

代术语来说

，TDNN 是用于时间

序列的一维

卷积网络。用

于这些模型

的反向传播

不受任何神

经科学观察

的启发，并且

被一些人认

为是生物不

可信的。在基

于使用反向

传播训练的

TDNN

成功之后，LeCun et al. (1989)

通

过将

相同的

训练算法应

用于图像的

2 维卷积来发

展现代卷积

网络。

到目前

为止，我们已

经描述了简

单细胞对于

某些特征是

如何呈现粗

略的线性和

选择性，复杂

细胞是如何

更加的非线

性，并且对于

这些简单细

胞特征的某

些变换具

有

不变性，以及

在选择性和

不变性之间

交替放置的

层可以产生

对非常特定

现象的祖

母

细胞。我们还

没有精确描

述这些单个

细胞检测到

了什么。在深

度非线性网

络中，

可能难

以理解单个

细胞的功能

。第一层中的

简单细胞相

对更容易分

析，因为它们

的

响应由线

性函数驱动

。在人工神经

网络中，我们

可以直接显

示卷积核的

图像，来查

看

卷积层的相

应通道是如

何响应的。在

生物神经网

络中，我们不

能访问权重

本身。

相反，我

们在神经元

自身中放置

一个电极，在

动物视网膜

前显示几个

白噪声图像

样

本，并记录

这些样本中

的每一个是

如何导致神

经元激活的

。然后，我们可

以对这些

响

应拟合线性

模型，以获得

近似的神经

元权重。这种

方法被称为

反向相关（reverse

correlation）(Ringach and Shapley, 2004)。

反

向相关向我

们表明，大多

数的 V1 细胞具

有由 Gabor

函数（Gabor function）

所

描述的权重

。Gabor 函数描述在

图像中的

2 维

点处的权重

。我们可以认

为图像是

2 维

坐标

I(x, y) 的函数

。类似地，我们

可以认为简

单细胞是在

图像中的一

组位置采

样

，这组位置由

一组

x 坐标 X 和

一组

y 坐标 Y 来

定义，并且使

用的权重

w(x, y) 也

是位置的函

数。从这个观

点来看，简单

细胞对于图

像的响应由

下式给出

s(I)

= ∑

x∈X

∑

y∈Y

w(x, y)I(x, y).

(9.15)

特

别地，w(x, y) 采用Gabor

函

数的形式：

w(x, y; α,

βx, βy, f, ϕ,

x0, y0, τ )

= α exp(−βxx

′2

− βyy

′2

)

cos(fx′ + ϕ), (9.16)

其

中

x

′ =

(x − x0) cos(τ

) + (y −

y0)sin(τ ) (9.17)

以及

y

′ = −(x

− x0)sin(τ ) +

(y − y0) cos(τ

). (9.18)

这里

α, βx,

βy, f, ϕ, x0,

y0, τ 都是控制 Gabor

函

数性质的参

数。图 9.18 给出

了

Gabor

函数在不同

参数集上的

一些例子。

9.10 卷

积网络的神

经科学基础

315

图

9.18: 具有各种

参数设置的

Gabor 函数。白色表

示绝对值大

的正权重，黑

色表示绝对

值大的负

权

重，背景灰色

对应于零权

重。(左)

控制坐

标系的参数

具有不同值

的Gabor 函数，这些

参数包括：

x0、y0 和

γ。在该网格中

的每个Gabor

函数

被赋予和它

在网格中的

位置成比例

的 x0 和 y0

的值，

并

且 τ 被选择为

使得每个

Gabor 过

滤器对从网

格中心辐射

出的方向非

常敏感。对于

其他两幅图

，

x0、y0 和

γ 固定为零

。(中) 具有不同

高斯比例参

数 βx

和 βy 的Gabor 函数

。当我们从左

到右通

过网

格时，Gabor 函数被

设置为增加

宽度（减少 βx）；当

我们从上到

下通过网格

时，Gabor 函数被

设

置为为增加

高度（减少 βy）。对

于其他两幅

图，β 值固定为

图像宽度的

1.5 倍。(右)

具有不

同的

正弦参

数 f 和

ϕ 的Gabor 函数

。当我们从上

到下移动时

，f 增加；当我们

从左到右移

动时，ϕ

增

加。对

于其他两幅

图，ϕ 固定为 0，f

固

定为图像宽

度的 5 倍。

参数

x0,

y0 和 τ 定义坐标

系。我们平移

和旋转

x 和 y 来

得到

x

′ 和 y

′。具体

地，

简单细胞

会响应以点

(x0, y0) 为中心的图

像特征，并且

当我们沿着

从水平方向

旋转

τ

弧度的

线移动时，简

单细胞将响

应亮度的变

化。

作为 x

′ 和 y

′

的

函数，函数 w 会

响应当我们

沿着 x

′ 移动时

的亮度变化

。它有两

个重

要的因子：一

个是高斯函

数，另一个是

余弦函数。

高

斯因子

α exp(−βxx

′2 −

βyy

′2

) 可以

被视为阈值

项，用于保证

简单细胞仅

对接

近 x

′ 和

y

′ 都

为零点处的

值响应，换句

话说，接近细

胞接受域的

中心。尺度因

子 α

调整简单

细胞响应的

总的量级，而

βx 和 βy 控制接受

域消退的速

度。

余弦因子

cos(fx′ + ϕ) 控制简单细

胞如何响应

延

x‘ 轴的亮度

改变。参数 f 控

制

余弦的频

率，ϕ 控制它的

相位偏移。

合

在一起，简单

细胞的这个

草图视图意

味着，简单细

胞对在特定

位置处、特定

方向上、特定

空间频率的

亮度进行响

应。当图像中

的光波与细

胞的权重具

有相同的

相

位时，简单细

胞是最兴奋

的。这种情况

发生在当图

像亮时，它的

权重为正，而

图

像暗时，它

的权重为负

。当光波与权

重完全异相

时，简单细胞

被抑制——当图

像较

316 第九章

卷积网络

暗

时，它的权重

为正；较亮时

，它的权重为

负。

复杂细胞

的草图视图

是它计算包

含两个简单

细胞响应的

2 维向量的 L

2

范

数：

c(I) = √

s0(I)

2 + s1(I)

2。一个重要

的特殊情况

是当 s1 和 s0

具有

除 ϕ 以外都相

同的

参数，并

且

ϕ 被设置为

使得 s1 与

s0 相位

相差四分之

一周期时。在

这种情况下

，s0 和

s1

形成 象限

对（quadrature pair）。当高斯重

新加权的图

像 I(x,

y) exp(−βxx

′2−βyy

2

)

包含具有

频率 f、在方向

τ 上、接近

(x0, y0) 的高

振幅正弦波

时，用先前方

法定义的

复

杂细胞会响

应，并且不管

该波的相位

偏移。换句话

说，复杂细胞

对于图像在

方向

τ

上的微

小变换或者

翻转图像（用

白色代替黑

色，反之亦然

）具有不变性

。

神经科学和

机器学习之

间最显著的

对应关系，是

从视觉上比

较机器学习

模型学

得的

特征与使用

V1

得到的特征

。Olshausen and Field (1996)

说明，一个简

单的无

监督

学习算法，稀

疏编码，学习

的特征具有

与简单细胞

类似的感受

野。从那时起

，我

们发现，当

应用于自然

图像时，极其

多样的统计

学习算法学

习类Gabor 函数的

特征。

这包括

大多数深度

学习算法，它

们在其第一

层中学习这

些特征。图 9.19 给

出了一些

例

子。因为如此

众多不同的

学习算法学

习边缘检测

器，所以很难

仅基于学习

算法学

得的

特征，来断定

哪一个特定

的学习算法

是 ‘‘正确’’ 的大

脑模型（虽然

，当应用于自

然图像时，如

果一个算法

不能学得某

种检测器时

，它能够作为

一种否定标

志）。这些

特征

是自然图像

的统计结构

的重要部分

，并且可以通

过许多不同

的统计建模

方法来

重新

获得。读者可

以参考 (Hyvärinen et al.,

2009) 来获

得自然图像

统计领域的

综述。

9.11 卷积网

络与深度学

习的历史

317

图

9.19: 许多机器学

习算法在应

用于自然图

像时，会学习

那些用来检

测边缘或边

缘的特定颜

色的特

征。这

些特征检测

器使人联想

到已知存在

于初级视觉

皮层中的

Gabor 函

数。(左) 通过应

用于小图

像

块的无监督

学习算法（尖

峰和平板稀

疏编码）学得

的权重。(右)

由

完全监督的

卷积 maxout 网

络的

第一层学得

的卷积核。相

邻的一对过

滤器驱动相

同的

maxout 单元。

9.11 卷

积网络与深

度学习的历

史

卷积网络

在深度学习

的历史中发

挥了重要作

用。它们是将

研究大脑获

得的深刻

理

解成功用于

机器学习应

用的关键例

子。它们也是

首批表现良

好的深度模

型之一，

远远

早于任意深

度模型被认

为是可行之

前。卷积网络

也是第一个

解决重要商

业应用

的神

经网络，并且

仍然处于当

今深度学习

商业应用的

前沿。例如，在

20

世纪 90 年

代，AT&T

的

神经网络研

究小组开发

了一个用于

读取支票的

卷积网络(LeCun et al.,

1998c)。到

90

年代末，NEC 部署

的这个系统

已经被用于

读取美国 10％以

上的支

票。后

来，微软部署

了若干个基

于卷积网络

的

OCR 和手写识

别系统 (Simard et

al.,

2003)。关于

卷积网络的

这种应用和

更现代应用

的更多细节

，参考第十二

章。读者可

以

参考 (LeCun

et al., 2010) 了解

2010 年

之前的更为

深入的卷积

网络历史。

卷

积网络也被

用作在许多

比赛中的取

胜手段。当前

对深度学习

的商业兴趣

的热

度始于

Krizhevsky

et al. (2012a) 赢得了

ImageNet 对象

识别挑战，但

是在那之前

，

卷积网络也

已经被用于

赢得前些年

影响较小的

其他机器学

习和计算机

视觉竞赛了

。

卷积网络是

第一批能使

用反向传播

有效训练的

深度网络之

一。现在仍不

完全清

楚为

什么卷积网

络在一般的

反向传播网

络被认为已

经失败时反

而成功了。这

可能可

以简

单地归结为

卷积网络比

全连接网络

计算效率更

高，因此使用

它们运行多

个实验

318 第九

章

卷积网络

并调整它们

的实现和超

参数更容易

。更大的网络

也似乎更容

易训练。利用

现代硬件，

大

型全连接的

网络在许多

任务上也表

现得很合理

，即使使用过

去那些全连

接网络被

认

为不能工作

得很好的数

据集和当时

流行的激活

函数时，现在

也能执行得

很好。心

理可

能是神经网

络成功的主

要阻碍（实践

者没有期望

神经网络有

效，所以他们

没有

认真努

力地使用神

经网络）。无论

如何，幸运的

是卷积网络

在几十年前

就表现良好

。

在许多方面

，它们为余下

的深度学习

传递火炬，并

为一般的神

经网络被接

受铺平了

道

路。

卷积网络

提供了一种

方法来特化

神经网络，使

其能够处理

具有清楚的

网格结构

拓

扑的数据，以

及将这样的

模型扩展到

非常大的规

模。这种方法

在二维图像

拓扑上

是最

成功的。为了

处理一维序

列数据，我们

接下来转向

神经网络框

架的另一种

强大

的特化

：循环神经网

络。

第十章

序

列建模：循环

和递归网络

循环神经网

络（recurrent neural network）或 RNN

(Rumelhart et al., 1986c)

是一类

用于处理序

列数据的神

经网络。就像

卷积网络是

专门用于处

理网格化数

据 X

（如一个图

像）的神经网

络，循环神经

网络是专门

用于处理序

列 x

(1)

, . .

. , x

(τ)

的神

经网

络。正如卷积

网络可以很

容易地扩展

到具有很大

宽度和高度

的图像，以及

处理

大小可

变的图像，循

环网络可以

扩展到更长

的序列（比不

基于序列的

特化网络长

得

多）。大多数

循环网络也

能处理可变

长度的序列

。

从多层网络

出发到循环

网络，我们需

要利用上世

纪 80 年代机器

学习和统计

模

型早期思

想的优点：在

模型的不同

部分共享参

数。参数共享

使得模型能

够扩展到不

同形式的样

本（这里指不

同长度的样

本）并进行泛

化。如果我们

在每个时间

点都有

一个

单独的参数

，我们不但不

能泛化到训

练时没有见

过序列长度

，也不能在时

间上

共享不

同序列长度

和不同位置

的统计强度

。当信息的特

定部分会在

序列内多个

位置

出现时

，这样的共享

尤为重要。例

如，考虑这两

句话：“I went

to Nepal in 2009’’

和

“In 2009, I

went to Nepal.” 如果

我们让一个

机器学习模

型读取这两

个句子，并提

取

叙述者去

Nepal的年份，无论

“2009 年’’ 是作为句

子的第六个

单词还是第

二个单词出

现，我们都希

望模型能认

出 “2009

年’’ 作为相

关资料片段

。假设我们要

训练一个处

理固定长度

句子的前馈

网络。传统的

全连接前馈

网络会给每

个输入特征

分配一个单

独的参数，所

以需要分别

学习句子每

个位置的所

有语言规则

。相比之下，循

环神经网

络

在几个时间

步内共享相

同的权重，不

需要分别学

习句子每个

位置的所有

语言规则。

一

个相关的想

法是在

1 维时

间序列上使

用卷积。这种

卷积方法是

时延神经网

络的基础 (Lang and

Hinton, 1988; Waibel et

al., 1989; Lang et

al., 1990)。卷

积操作

允许

网络跨时间

共享参数，但

是浅层的。卷

积的输出是

一个序列，其

中输出中的

每

一项是相

邻几项输入

的函数。参数

共享的概念

体现在每个

时间步中使

用的相同卷

积

核。循环神

经网络以不

同的方式共

享参数。输出

的每一项是

前一项的函

数。输出的

319

320 第

十章

序列建

模：循环和递

归网络

每一

项对先前的

输出应用相

同的更新规

则而产生。这

种循环方式

导致参数通

过很深

的计

算图共享。

为

简单起见，我

们说的

RNN 是指

在序列上的

操作，并且该

序列在时刻

t（从

1 到

τ）包含向

量 x

(t)。在实际情

况中，循环网

络通常在序

列的小批量

上操作，并

且

小批量的每

项具有不同

序列长度

τ。我

们省略了小

批量索引来

简化记号。此

外，

时间步索

引不必是字

面上现实世

界中流逝的

时间。有时，它

仅表示序列

中的位置。

RNN 也

可以应用于

跨越两个维

度的空间数

据（如图像）。当

应用于涉及

时间的数据

，

并且将整个

序列提供给

网络之前就

能观察到整

个序列时，该

网络可具有

关于时间向

后的连接。

本

章将计算图

的思想扩展

到包括循环

。这些周期代

表变量自身

的值在未来

某

一时间步

对自身值的

影响。这样的

计算图允许

我们定义循

环神经网络

。然后，我们

描

述许多构建

、训练和使用

循环神经网

络的不同方

式。

本章将简

要介绍循环

神经网络，为

获取更多详

细信息，我们

建议读者参

考 Graves

(2012) 的著作。

10.1 展

开计算图

计

算图是形式

化一组计算

结构的方式

，如那些涉及

将输入和参

数映射到输

出和

损失的

计算。综合的

介绍请参考

第6.5.1

节。本节，我

们对 展开（unfolding）递

归或

循环计

算得到的重

复结构进行

解释，这些重

复结构通常

对应于一个

事件链。 展开

（unfolding）这个计算图

将导致深度

网络结构中

的参数共享

。

例如，考虑动

态系统的经

典形式：

s

(t) =

f(s

(t−1); θ), (10.1)

其中

s

(t) 称为系统的

状态。

s

在时刻

t 的定义需要

参考时刻 t −

1 时

同样的定义

，因此式(10.1) 是循

环的。

对有限

时间步

τ，τ − 1 次应

用这个定义

可以展开这

个图。例如

τ = 3，我

们对

式

(10.1) 展开

，可以得到：

s

(3)

= f(s

(2); θ)

(10.2)

= f(f(s

(1);

θ); θ). (10.3)

10.1

展

开计算图 321

以

这种方式重

复应用定义

，展开等式，就

能得到不涉

及循环的表

达。现在我们

可以使用传

统的有向无

环计算图呈

现这样的表

达。

式

(10.1) 和式(10.3) 的

展开计算图

如图10.1 所示。

ss((tt−−1)1) ss((tt)) ss((tt+1) +1)

f ss((... ... ))

ss((... ... ))

f

f f

图

10.1: 将式

(10.1) 描述的

经典动态系

统表示为展

开的计算图

。每个节点表

示在某个时

刻 t 的状

态，并

且函数 f 将 t

处

的状态映射

到 t + 1

处的状态

。所有时间步

都使用相同

的参数（用于

参数

化 f 的相

同

θ 值）。

作为另

一个例子，让

我们考虑由

外部信号 x

(t) 驱

动的动态系

统，

s

(t)

= f(s

(t−1)

,

x

(t)

; θ),

(10.4)

我们可以

看到，当前状

态包含了整

个过去序列

的信息。

循环

神经网络可

以通过许多

不同的方式

建立。就像几

乎所有函数

都可以被认

为

是前馈网

络，本质上任

何涉及循环

的函数都可

以被认为是

一个循环神

经网络。

很多

循环神经网

络使用式 (10.5) 或

类似的公式

定义隐藏单

元的值。为了

表明状

态是

网络的隐藏

单元，我们使

用变量

h 代表

状态重写式

(10.4) ：

h

(t) = f(h

(t−1)

, x

(t)

;

θ), (10.5)

如图 10.2

所示，典

型 RNN 会增加额

外的架构特

性，如读取状

态信息 h

进行

预测的

输出

层。

f

h

x

hh((tt−−1)1) hh((tt)) hh((tt+1)

+1)

xx((tt−−1)1) xx((tt)) xx((tt+1)

+1)

hh((... ... ))

hh((... ... ))

f

Unfold

f f f

图 10.2: 没有输

出的循环网

络。此循环网

络只处理来

自输入 x

的信

息，将其合并

到经过时间

向前

传播的

状态 h。(左) 回路

原理图。黑色

方块表示单

个时间步的

延迟。(右)

同一

网络被视为

展开的

计算

图，其中每个

节点现在与

一个特定的

时间实例相

关联。

322 第十章

序列建模：循

环和递归网

络

当训练循

环网络根据

过去预测未

来时，网络通

常要学会使

用 h

(t) 作为过去

序列

（直到 t）与

任务相关方

面的有损摘

要。此摘要一

般而言一定

是有损的，因

为其映射

任

意长度的序

列 (x

(t)

, x

(t−1)

, x

(t−2)

,

. . . ,

x

(2)

, x

(1)) 到一固定

长度的向量

h

(t)。根据不

同的

训练准则，摘

要可能选择

性地精确保

留过去序列

的某些方面

。例如，如果在

统

计语言建

模中使用的

RNN，通常给定前

一个词预测

下一个词，可

能没有必要

存储时

刻 t 前

输入序列中

的所有信息

；而仅仅存储

足够预测句

子其余部分

的信息。最苛

刻

的情况是

我们要求 h

(t) 足

够丰富，并能

大致恢复输

入序列，如自

编码器框架

（第十

四章）。

式

(10.5) 可以用两种

不同的方式

绘制。一种方

法是为可能

在模型的物

理实现中

存

在的部分赋

予一个节点

，如生物神经

网络。在这个

观点下，网络

定义了实时

操作

的回路

，如图10.2 的左侧

，其当前状态

可以影响其

未来的状态

。在本章中，我

们使用

回路

图的黑色方

块表明在时

刻 t

的状态到

时刻 t + 1

的状态

单个时刻延

迟中的相互

作

用。另一个

绘制 RNN 的方法

是展开的计

算图，其中每

一个组件由

许多不同的

变量表

示，每

个时间步一

个变量，表示

在该时间点

组件的状态

。每个时间步

的每个变量

绘

制为计算

图的一个独

立节点，如图

10.2 的右侧。我们

所说的展开

是将左图中

的回路

映射

为右图中包

含重复组件

的计算图的

操作。目前，展

开图的大小

取决于序列

长度。

我们可

以用一个函

数 g

(t) 代表经

t 步

展开后的循

环：

h

(t)

= g

(t)

(x

(t)

, x

(t−1)

, x

(t−2)

,

. . . ,

x

(2)

, x

(1)) (10.6)

= f(h

(t−1)

, x

(t)

; θ). (10.7)

函数

g

(t) 将全

部的过去序

列 (x

(t)

, x

(t−1)

, x

(t−2)

,

. . . ,

x

(2)

, x

(1)) 作为输入

来生成当前

状

态，但是展

开的循环架

构允许我们

将 g

(t) 分解为函

数 f 的重复应

用。因此，展开

过

程引入两

个主要优点

：

1. 无论序列的

长度，学成的

模型始终具

有相同的输

入大小，因为

它指定的是

从一

种状态

到另一种状

态的转移，而

不是在可变

长度的历史

状态上操作

。

2. 我们可以在

每个时间步

使用相同参

数的相同转

移函数 f。

这两

个因素使得

学习在所有

时间步和所

有序列长度

上操作单一

的模型

f 是可

能的，

而不需

要在所有可

能时间步学

习独立的模

型 g

(t)。学习单一

的共享模型

允许泛化到

没有见过的

序列长度（没

有出现在训

练集中），并且

估计模型所

需的训练样

本远远少

于

不带参数共

享的模型。

10.2 循

环神经网络

323

无论是循环

图和展开图

都有其用途

。循环图简洁

。展开图能够

明确描述其

中的

计算流

程。展开图还

通过显式的

信息流动路

径帮助说明

信息在时间

上向前（计算

输

出和损失

）和向后（计算

梯度）的思想

。

10.2

循环神经网

络

基于第 10.1 节

中的图展开

和参数共享

的思想，我们

可以设计各

种循环神经

网络。

U

V

W

oo((tt−−1)1)

h

o

y

L

x

oo((tt)) oo((tt+1) +1)

LL((tt−−1)1) LL((tt)) LL((tt+1) +1)

yy((tt−−1)1) yy((tt)) yy((tt+1) +1)

hh((tt−−1)1) hh((tt)) hh((tt+1) +1)

xx((tt−−1)1) xx((tt)) xx((tt+1) +1)

W W W W

hh((... ... )) hh((...

... ))

V V

V

U U U

Unfold

图 10.3: 计算

循环网络(将

x

值的输入序

列映射到输

出值 o 的对应

序列) 训练损

失的计算图

。损失

L 衡量每

个 o 与相应的

训练目标

y 的

距离。当使用

softmax 输出时，我们

假设 o

是未归

一化的

对数

概率。损失 L 内

部计算

yˆ = softmax(o)，并将

其与目标 y

比

较。RNN输入到隐

藏的连接由

权重矩阵 U 参

数化，隐藏到

隐藏的循环

连接由权重

矩阵 W

参数化

以及隐藏到

输出的连接

由权重

矩阵

V 参数化。式 (10.8)

定

义了该模型

中的前向传

播。(左) 使用循

环连接绘制

的 RNN 和它的损

失。(右)

同一网

络被视为展

开的计算图

，其中每个节

点现在与一

个特定的时

间实例相关

联。

循环神经

网络中一些

重要的设计

模式包括以

下几种：

1. 每个

时间步都有

输出，并且隐

藏单元之间

有循环连接

的循环网络

，如图

10.3 所

示。

324

第

十章 序列建

模：循环和递

归网络

2. 每个

时间步都产

生一个输出

，只有当前时

刻的输出到

下个时刻的

隐藏单元之

间

有循环连

接的循环网

络，如图 10.4 所示

。

3.

隐藏单元之

间存在循环

连接，但读取

整个序列后

产生单个输

出的循环网

络，如

图 10.5 所示

。

图 10.3 是非常具

有代表性的

例子，我们将

会在本章大

部分涉及这

个例子。

U

V

W

oo((tt−−1)1)

h

o

y

L

x

oo((tt)) oo((tt+1) +1)

LL((tt−−1)1)

LL((tt)) LL((tt+1) +1)

yy((tt−−1)1)

yy((tt)) yy((tt+1) +1)

hh((tt−−1)1)

hh((tt)) hh((tt+1) +1)

xx((tt−−1)1)

xx((tt)) xx((tt+1) +1)

W

W W W

oo((...

... ))

hh((... ...

))

V V V

U U U

Unfold

图 10.4: 此

类 RNN

的唯一循

环是从输出

到隐藏层的

反馈连接。在

每个时间步

t，输入为 xt，隐藏

层激活为 h

(t)，输

出为

o

(t)，目标为

y

(t)，损失为 L

(t)。(左) 回

路原理图。(右

) 展开的计算

图。这样

的

RNN 没

有图 10.3 表示的

RNN

那样强大（只

能表示更小

的函数集合

）。图 10.3 中的 RNN

可以

选择将其想

要的关于过

去的任何信

息放入隐藏

表示 h 中并且

将 h

传播到未

来。该图中的

RNN 被

训练为将

特定输出值

放入 o

中，并且

o 是允许传播

到未来的唯

一信息。此处

没有从 h 前向

传播的

直接

连接。之前的

h 仅通过产生

的预测间接

地连接到当

前。o 通常缺乏

过去的重要

信息，除非它

非常高维且

内容丰富。这

使得该图中

的 RNN

不那么强

大，但是它更

容易训练，因

为每个时间

步可

以与其

他时间步分

离训练，允许

训练期间更

多的并行化

，如第 10.2.1 节所述

。

任何图灵可

计算的函数

都可以通过

这样一个有

限维的循环

网络计算，在

这

个意义上

图 10.3 和式

(10.8) 的循

环神经网络

是万能的。RNN 经

过若干时间

步后读

取输

出，这与由图

灵机所用的

时间步是渐

近线性的，与

输入长度也

是渐近线性

的

(Siegelmann and Sontag, 1991;

Siegelmann, 1995; Siegelmann and

Sontag, 1995;

10.2 循环神经

网络

325

hh((tt−−1)1)

W

hh((tt))

...

xx((tt−−1)1) xx((tt)) xx((...

...))

W W

U

U U

hh((⌧⌧))

xx((⌧⌧))

W

U

oo((⌧⌧)) yy((⌧⌧))

LL((⌧⌧))

V

...

图

10.5: 关于

时间展开的

循环神经网

络，在序列结

束时具有单

个输出。这样

的网络可以

用于概括序

列并产生用

于进一步处

理的固定大

小的表示。在

结束处可能

存在目标（如

此处所示），或

者通过更

下

游模块的反

向传播来获

得输出 o

(t) 上的

梯度。

Hyotyniemi, 1996)。由图灵

机计算的函

数是离散的

，所以这些结

果都是函数

的具体

实现

，而不是近似

。RNN 作为图灵机

使用时，需要

一个二进制

序列作为输

入，其输

出必

须离散化以

提供二进制

输出。利用单

个有限大小

的特定 RNN

计算

在此设置下

的所有函数

是可能的（ Siegelmann and Sontag

(1995) 用

了 886 个单元）。图

灵机的

‘‘输入

’’ 是要计算函

数的详细说

明 (specification)，所以模拟

此图灵机的

相同网络足

以应付所有

问题。用于证

明的理论 RNN

可

以通过激活

和权重（由无

限精度的有

理

数表示）来

模拟无限堆

栈。

现在我们

研究图 10.3

中 RNN 的

前向传播公

式。这个图没

有指定隐藏

单元的激

活

函数。我们假

设使用双曲

正切激活函

数。此外，图中

没有明确指

定何种形式

的输

出和损

失函数。我们

假定输出是

离散的，如用

于预测词或

字符的 RNN。表示

离散变

量的

常规方式是

把输出 o

作为

每个离散变

量可能值的

非标准化对

数概率。然后

，我

们可以应

用 softmax 函数

后续

处理后，获得

标准化后概

率的输出向

量 yˆ。RNN 从特

定的

初始状态

h

(0) 开

始前向传播

。从 t

= 1 到 t

= τ 的每个

时间步，我们

应用以下

326

第

十章 序列建

模：循环和递

归网络

更新

方程：

a

(t) = b +

Wh(t−1) + Ux(t)

,

(10.8)

h

(t) =

tanh(a

(t)

), (10.9)

o

(t) = c

+ Vh(t)

, (10.10)

yˆ

(t) = softmax(o

(t)

), (10.11)

其中的

参数的偏置

向量

b 和 c 连同

权重矩阵

U、V 和

W，分别对应于

输入到隐藏

、

隐藏到输出

和隐藏到隐

藏的连接。这

个循环网络

将一个输入

序列映射到

相同长度的

输出序列。与

x 序列配对的

y

的总损失就

是所有时间

步的损失之

和。例如，L

(t) 为

给

定的

x

(1)

, .

. . , x

(t) 后 y

(t)

的负

对数似然，则

L

(

{x

(1)

, . . .

, x

(τ)

},

{y

(1)

, .

. . , y

(τ)

}

)

(10.12)

=

∑

t

L

(t)

(10.13)

= −

∑

t

log pmodel(

y

(t)

| {x

(1)

, . .

. , x

(t)

}

)

, (10.14)

其中 pmodel(

y

(t)

| {x

(1)

,

. . . ,

x

(t)}

)

需要读

取模型输出

向量

yˆ

(t) 中对应

于 y

(t) 的项。

关于

各个参数计

算这个损失

函数的梯度

是计算成本

很高的操作

。梯度计算涉

及执行

一次

前向传播（如

在图

10.3 展开图

中从左到右

的传播），接着

是由右到左

的反向传

播

。运行时间是

O(τ )，并且不能通

过并行化来

降低，因为前

向传播图是

固有循序的

;

每个时间步

只能一前一

后地计算。前

向传播中的

各个状态必

须保存，直到

它们反向

传

播中被再次

使用，因此内

存代价也是

O(τ )。应用于展开

图且代价为

O(τ )

的反向

传播

算法称为 通

过时间反向

传播（back-propagation through

time, BPTT），将在

第

10.2.2 节进一步讨

论。因此隐藏

单元之间存

在循环的网

络非常强大

但训练代价

也

很大。我们

是否有其他

选择呢？

10.2.1 导师

驱动过程和

输出循环网

络

仅在一个

时间步的输

出和下一个

时间步的隐

藏单元间存

在循环连接

的网络（示

于

图 10.4 ）确实没有

那么强大（因

为缺乏隐藏

到隐藏的循

环连接）。例如

，它不能模

拟

通用图灵机

。因为这个网

络缺少隐藏

到隐藏的循

环，它要求输

出单元捕捉

用于预

测未

来的关于过

去的所有信

息。因为输出

单元明确地

训练成匹配

训练集的目

标，它

们不太

能捕获关于

过去输入历

史的必要信

息，除非用户

知道如何描

述系统的全

部状

10.2 循环神

经网络

327

态，并

将它作为训

练目标的一

部分。消除隐

藏到隐藏循

环的优点在

于，任何基于

比

较时刻 t

的

预测和时刻

t 的训练目标

的损失函数

中的所有时

间步都解耦

了。因此训

练

可以并行化

，即在各时刻

t 分别计算梯

度。因为训练

集提供输出

的理想值，所

以

没有必要

先计算前一

时刻的输出

。

由输出反馈

到模型而产

生循环连接

的模型可用

导师驱动过

程（teacher forcing）

进行训练

。训练模型时

，导师驱动过

程不再使用

最大似然准

则，而在时刻

t

+ 1 接收

真实值

y

(t) 作为输入。我

们可以通过

检查两个时

间步的序列

得知这一点

。条件最大

似

然准则是

log

p(y

(1)

, y

(2) | x

(1)

, x

(2)) (10.15)

= log p(y

(2)

| y

(1)

,

x

(1)

, x

(2)) + log p(y

(1) | x

(1)

, x

(2)). (10.16)

在

这个例子中

，同时给定迄

今为止的 x 序

列和来自训

练集的前一

y 值，我们可

以

看到在时刻

t = 2 时，模型被训

练为最大化

y

(2) 的条件概率

。因此最大似

然在训

练时

指定正确反

馈，而不是将

自己的输出

反馈到模型

。如图 10.6

所示。

我

们使用导师

驱动过程的

最初动机是

为了在缺乏

隐藏到隐藏

连接的模型

中避

免通过

时间反向传

播。只要模型

一个时间步

的输出与下

一时间步计

算的值存在

连接，

导师驱

动过程仍然

可以应用到

这些存在隐

藏到隐藏连

接的模型。然

而，只要隐藏

单

元成为较

早时间步的

函数，BPTT 算法是

必要的。因此

训练某些模

型时要同时

使

用导师驱

动过程和 BPTT。

如

果之后网络

在开环 (open-loop) 模式

下使用，即网

络输出（或输

出分布的样

本）反馈作为

输入，那么完

全使用导师

驱动过程进

行训练的缺

点就会出现

。在这种

情况

下，训练期间

该网络看到

的输入与测

试时看到的

会有很大的

不同。减轻此

问题

的一种

方法是同时

使用导师驱

动过程和自

由运行的输

入进行训练

，例如在展开

循环

的输出

到输入路径

上预测几个

步骤的正确

目标值。通过

这种方式，网

络可以学会

考

虑在训练

时没有接触

到的输入条

件（如自由运

行模式下，自

身生成自身

），以及将状

态

映射回使网

络几步之后

生成正确输

出的状态。另

外一种方式

(Bengio

et al., 2015b)

是通过随意

选择生成值

或真实的数

据值作为输

入以减小训

练时和测试

时看到的输

入

之间的差

别。这种方法

利用了课程

学习策略，逐

步使用更多

生成值作为

输入。

328 第十章

序列建模：循

环和递归网

络

oo((tt−−1)1)

oo((tt))

hh((tt−−1)1) hh((tt))

xx((tt−−1)1)

xx((tt))

W

V V

U U

oo((tt−−1)1) oo((tt))

LL((tt−−1)1) LL((tt))

yy((tt−−1)1) yy((tt))

hh((tt−−1)1) hh((tt))

xx((tt−−1)1) xx((tt))

W

V V

U

U

Train time Test

time

图 10.6: 导师驱

动过程的示

意图。导师驱

动过程是一

种训练技术

，适用于输出

与下一时间

步的隐藏

状

态存在连接

的 RNN。(左) 训练时

，我们将训练

集中正确的

输出 y

(t) 反馈到

h

(t+1)。(右) 当模型

部

署后，真正的

输出通常是

未知的。在这

种情况下，我

们用模型的

输出 o

(t) 近似正

确的输出

y

(t)，

并

反馈回模型

。

10.2.2

计算循环神

经网络的梯

度

计算循环

神经网络的

梯度是容易

的。我们可以

简单地将第

6.5.6 节中的推广

反向

传播算

法应用于展

开的计算图

，而不需要特

殊化的算法

。由反向传播

计算得到的

梯

度，并结合

任何通用的

基于梯度的

技术就可以

训练 RNN。

为了获

得 BPTT

算法行为

的一些直观

理解，我们举

例说明如何

通过 BPTT 计算

上

述RNN公式（式(10.8)

和

式 (10.12) ）的梯度。计

算图的节点

包括参数 U,

V,W, b

和

c，以及以 t

为索

引的节点序

列 x

(t)

,

h

(t)

, o

(t) 和 L

(t)。对于每

一个节点

N，我

们

需要基于

N 后面的节点

的梯度，递归

地计算梯度

∇NL。我们从紧接

着最终损失

的节

点开始

递归：

∂L

∂L(t)

= 1.

(10.17)

在这个

导数中，我们

假设输出 o

(t)

作

为 softmax 函数 的参

数，我们可以

从

softmax

10.2 循环神经

网络 329

函数可

以获得关于

输出概率的

向量 yˆ。我们也

假设损失是

迄今为止给

定了输入后

的

真实目标

y

(t)

的负对数似

然。对于所有

i, t，关于时间步

t 输出的梯度

∇o(t)L 如下：

(∇o(t)L)i =

∂L

∂o(

i

t) =

∂L

∂L(t)

∂L(t)

∂o(

i

t)

= ˆyi

(t)

− 1i,y(t) . (10.18)

我们从

序列的末尾

开始，反向进

行计算。在最

后的时间步

τ , h

(τ)

只有 o

(τ) 作为后

续

节点，因此

这个梯度很

简单：

∇h

(τ)L =

V

⊤∇o(τ)L. (10.19)

然后，我

们可以从时

刻

t = τ −

1 到 t =

1 反向迭

代，通过时间

反向传播梯

度，注意

h

(t)

(t < τ )

同时

具有 o

(t) 和

h

(t+1) 两个

后续节点。因

此，它的梯度

由下式计算

∇h

(t)L

=

(∂h

(t+1)

∂h

(t)

)⊤

(∇h

(t+1)L)

+ (∂o

(t)

∂h

(t)

)⊤

(∇o(t)L) (10.20)

= W⊤

(∇h

(t+1)L)diag(

1 − (h

(t+1))

2

)

+ V

⊤

(∇o(t)L), (10.21)

其中

diag(

1−(h

(t+1))

2

)

表示包

含元素 1−(h

(

i

t+1))

2 的对

角矩阵。这是

关于时刻

t+ 1

与

隐藏单元 i

关

联的双曲正

切的Jacobian。

一旦获

得了计算图

内部节点的

梯度，我们就

可以得到关

于参数节点

的梯度。因

为

参数在许多

时间步共享

，我们必须在

表示这些变

量的微积分

操作时谨慎

对待。我

们希

望实现的等

式使用第

6.5.6 节

中的 bprop 方法计

算计算图中

单一边对梯

度的贡

献。然

而微积分中

的 ∇Wf 算子，计算

W 对于

f 的贡献

时将计算图

中的所有边

都考

虑进去

了。为了消除

这种歧义，我

们定义只在

t 时刻使用的

虚拟变量

W(t) 作

为 W

的副本。然

后，我们可以

使用

∇W(t) 表示权

重在时间步

t 对梯度的贡

献。

330

第十章 序

列建模：循环

和递归网络

使用这个表

示，关于剩下

参数的梯度

可以由下式

给出：

∇cL =

∑

t

(∂o

(t)

∂c

)⊤

∇o(t)L =

∑

t

∇o(t)L, (10.22)

∇bL =

∑

t

(∂

∂

h

b

(

(

t

t

)

) )⊤

∇h

(t)L =

∑

t

diag(

1 −

(

h

(t)

)2

)

∇h

(t)L, (10.23)

∇VL

=

∑

t

∑

i

(

∂o

∂L

(t)

i

)

∇Vo

(

i

t) =

∑

t

(∇o(t)L)h

(t)

⊤

, (10.24)

∇WL

=

∑

t

∑

i

(

∂h

∂L

(t)

i

)

∇W(t)h

(

i

t)

(10.25)

=

∑

t

diag(

1 −

(

h

(t)

)2

)

(∇h

(t)L)h

(t−1)⊤

, (10.26)

∇UL =

∑

t

∑

i

(

∂h

∂L

(t)

i

)

∇U(t)h

(

i

t)

(10.27)

=

∑

t

diag(

1 −

(

h

(t)

)2

)

(∇h

(t)L)x

(t)

⊤

, (10.28)

因为计

算图中定义

的损失的任

何参数都不

是训练数据

x

(t)

的父节点，所

以我们不需

要计算关于

它的梯度。

10.2.3 作

为有向图模

型的循环网

络

目前为止

，我们接触的

循环网络例

子中损失

L

(t) 是

训练目标 y

(t) 和

输出 o

(t)

之

间的

交叉熵。与前

馈网络类似

，原则上循环

网络几乎可

以使用任何

损失。但必须

根

据任务来

选择损失。如

前馈网络，我

们通常希望

将 RNN

的输出解

释为一个概

率分

布，并且

我们通常使

用与分布相

关联的交叉

熵来定义损

失。均方误差

是与单位高

斯

分布的输

出相关联的

交叉熵损失

，例如前馈网

络中所使用

的。

当我们使

用一个预测

性对数似然

的训练目标

，如式

(10.12) ，我们将

RNN 训练

为能够

根据之前的

输入估计下

一个序列元

素

y

(t) 的条件分

布。这可能意

味着，我们

最

大化对数似

然

log p(y

(t)

|

x

(1)

, .

. . , x

(t)

), (10.29)

或者，如果

模型包括来

自一个时间

步的输出到

下一个时间

步的连接，

log p(y

(t)

|

x

(1)

, .

. . , x

(t)

, y

(1)

, . . .

, y

(t−1)). (10.30)

10.2 循

环神经网络

331

将整个序列

y 的联合分布

分解为一系

列单步的概

率预测是捕

获关于整个

序列完整

联

合分布的一

种方法。当我

们不把过去

的 y 值反馈给

下一步作为

预测的条件

时，那

么有向

图模型不包

含任何从过

去

y

(i) 到当前 y

(t) 的

边。在这种情

况下，输出 y 与

给

定的 x 序列

是条件独立

的。当我们反

馈真实的 y

值

（不是它们的

预测值，而是

真正

观测到

或生成的值

）给网络时，那

么有向图模

型包含所有

从过去 y

(i)

到当

前 y

(t) 的

边。

yy(1) (1) yy(2)

(2) yy(3) (3) yy(4)

(4) yy(5) (5) yy((...

...))

图 10.7: 序

列

y

(1), y(2), .

. . , y(t)

, . . .

的全连接

图模型。给定

先前的值，每

个过去的观

察值 y

(i) 可

以影

响一些 y

(t)

(t

> i) 的条

件分布。当序

列中每个元

素的输入和

参数的数目

越来越多，根

据此图

直接

参数化图模

型（如式

(10.6) 中）可

能是非常低

效的。RNN 可以通

过高效的参

数化获得相

同的

全连接

，如图

10.8 所示。

举

一个简单的

例子，让我们

考虑对标量

随机变量序

列 Y

= {y

(1)

,

. . . ,

y

(τ)} 建

模的

RNN，也

没有额外的

输入 x。在时间

步 t 的输入仅

仅是时间步

t

− 1 的输出。

该

RNN 定

义了关于 y 变

量的有向图

模型。我们使

用链式法则

（用于条件概

率的

式 (3.6) ）参数

化这些观察

值的联合分

布：

P(Y)

= P(y

(1)

,

. . . ,

y

(τ)

) =

τ∏

t=1

P(y

(t)

| y

(t−1)

,

y

(t−2)

, .

. . , y

(1)), (10.31)

其中当 t

= 1 时

竖杠右侧显

然为空。因此

，根据这样一

个模型，一组

值 {y

(1), . . .

, y(τ)}

的负对数

似然为

L

=

∑

t

L

(t)

, (10.32)

332

第十

章 序列建模

：循环和递归

网络

其中

L

(t) = − log

P(y

(t) = y

(t)

| y

(t−1),

y(t−2), . . .

, y(1)). (10.33)

yy(1)

(1) yy(2) (2) yy(3)

(3) yy(4) (4) yy(5)

(5) yy((... ...))

hh(1)

(1) hh(2) (2) hh(3)

(3) hh(4) (4) hh(5)

(5) hh((... ... ))

图

10.8: 在 RNN 图模型中

引入状态变

量，尽管它是

输入的确定

性函数，但它

有助于我们

根据

式 (10.5) 获得

非常高效的

参数化。序列

中的每个阶

段（对于 h

(t) 和 y

(t)）使

用相同的结

构（每个

节点

具有相同数

量的输入），并

且可以与其

他阶段共享

相同的参数

。

图模型中的

边表示哪些

变量直接依

赖于其他变

量。许多图模

型的目标是

省略不

存在

强相互作用

的边以实现

统计和计算

的效率。例如

，我们通常可

以作Markov假设，

即

图模型应该

只包含从

{y

(t−k)

, .

. . , y

(t−1)} 到

y

(t) 的边，而不是

包含整个过

去历史

的边

。然而，在一些

情况下，我们

认为整个过

去的输入会

对序列的下

一个元素有

一

定影响。当

我们认为 y

(t)

的

分布可能取

决于遥远过

去 (在某种程

度) 的 y

(i) 的值，且

无法通过 y

(t−1)

捕

获 y

(i) 的影响时

，RNN

将会很有用

。

解释 RNN 作为图

模型的一种

方法是将RNN视

为定义一个

结构为完全

图的图模

型

，且能够表示

任何一对 y 值

之间的直接

联系。图 10.7

是关

于 y 值且具有

完全图结

构

的图模型。该

RNN

完全图的解

释基于排除

并忽略模型

中的隐藏单

元 h

(t)。

更有趣的

是，将隐藏单

元

h

(t) 视为随机

变量，从而产

生 RNN

的图模型

结构1。

在图模

型中包括隐

藏单元预示

RNN 能对观测的

联合分布提

供非常有效

的参数化。

假

设我们用表

格表示法来

表示离散值

上任意的联

合分布，即对

每个值可能

的赋值分

配

一个单独条

目的数组，该

条目表示发

生该赋值的

概率。如果 y 可

以取 k

个不同

的

值，表格表

示法将有 O(k

τ

) 个

参数。对比 RNN，由

于参数共享

，RNN 的参数数目

为

O(1) 且是序列

长度的函数

。我们可以调

节 RNN 的参数数

量来控制模

型容量，但

不

用被迫与序

列长度成比

例。式(10.5) 展示了

所述 RNN 通过循

环应用相同

的函数

f

以及

在每个时间

步的相同参

数 θ，有效地参

数化的变量

之间的长期

联系。图 10.8

说

1给

定这些变量

的父变量，其

条件分布是

确定性的。尽

管设计具有

这样确定性

的隐藏单元

的图模型是

很少见的，但

这是完全合

理的。

10.2 循环神

经网络

333

明了

这个图模型

的解释。在图

模型中结合

h

(t) 节点可以用

作过去和未

来之间的中

间

量，从而将

它们解耦。遥

远过去的变

量 y

(i) 可以通过

其对

h 的影响

来影响变量

y

(t)。

该图的结构

表明可以在

时间步使用

相同的条件

概率分布有

效地参数化

模型，并且当

观察到全部

变量时，可以

高效地评估

联合分配给

所有变量的

概率。

即便使

用高效参数

化的图模型

，某些操作在

计算上仍然

具有挑战性

。例如，难

以预

测序列中缺

少的值。

循环

网络为减少

的参数数目

付出的代价

是优化参数

可能变得困

难。

在循环网

络中使用的

参数共享的

前提是相同

参数可用于

不同时间步

的假设。也

就

是说，假设给

定时刻 t 的变

量后，时刻 t

+ 1 变

量的条件概

率分布是 平

稳的

（stationary），这意味

着之前的时

间步与下个

时间步之间

的关系并不

依赖于 t。原则

上，可以使用

t 作为每个时

间步的额外

输入，并让学

习器在发现

任何时间依

赖性的

同时

，在不同时间

步之间尽可

能多地共享

。相比在每个

t

使用不同的

条件概率分

布

已经好很

多了，但网络

将必须在面

对新 t 时进行

推断。

为了完

整描述将 RNN 作

为图模型的

观点，我们必

须描述如何

从模型采样

。我们

需要执

行的主要操

作是简单地

从每一时间

步的条件分

布采样。然而

，这会导致额

外

的复杂性

。RNN 必须有某种

机制来确定

序列的长度

。这可以通过

多种方式实

现。

在当输出

是从词汇表

获取的符号

的情况下，我

们可以添加

一个对应于

序列末端

的

特殊符号

(Schmidhuber, 2012)。当

产生该符号

时，采样过程

停止。在训练

集中，

我们将

该符号作为

序列的一个

额外成员，即

紧跟每个训

练样本 x

(τ) 之后

。

另一种选择

是在模型中

引入一个额

外的 Bernoulli

输出，表

示在每个时

间步决定

继

续生成或停

止生成。相比

向词汇表增

加一个额外

符号，这种方

法更普遍，因

为它

适用于

任何 RNN，而不仅

仅是输出符

号序列的

RNN。例

如，它可以应

用于一个产

生实数序列

的 RNN。新的输出

单元通常使

用 sigmoid 单元，并通

过交叉熵训

练。在

这种方

法中，sigmoid 被训练

为最大化正

确预测的对

数似然，即在

每个时间步

序列决

定结

束或继续。

确

定序列长度

τ

的另一种方

法是将一个

额外的输出

添加到模型

并预测整数

τ 本

身。模型可

以采出 τ

的值

，然后采 τ 步有

价值的数据

。这种方法需

要在每个时

间

步的循环

更新中增加

一个额外输

入，使得循环

更新知道它

是否是靠近

所产生序列

的

末尾。这种

额外的输入

可以是 τ 的值

，也可以是 τ

− t 即

剩下时间步

的数量。如果

没有这个额

外的输入，RNN 可

能会产生突

然结束序列

，如一个句子

在最终完整

前结

334 第十章

序列建模：循

环和递归网

络

束。此方法

基于分解

P(x

(1)

, . .

. , x

(τ)

) = P(τ )P(x

(1)

, . .

. , x

(τ)

| τ ). (10.34)

直

接预测 τ 的例

子见Goodfellow et

al. (2014d)。

10.2.4 基于上

下文的

RNN 序列

建模

上一节

描述了没有

输入 x

时，关于

随机变量序

列 y

(t) 的RNN如何对

应于有向图

模型。当然，如

式(10.8)

所示的RNN包

含一个输入

序列 x

(1)

,

x

(2)

, .

. . , x

(τ)。一般情

况

下，RNN 允许将

图模型的观

点扩展到不

仅代表 y

变量

的联合分布

也能表示给

定 x

后 y

条件分

布。如在第6.2.1.1 节

的前馈网络

情形中所讨

论的，任何代

表变量 P(y; θ)

的模

型都能被解

释为代表条

件分布 P(y | ω)

的模

型，其中 ω = θ。我们

能像之前一

样使用

P(y | ω) 代表

分布

P(y | x) 来扩展

这样的模型

，但要令

ω 是关

于 x 的函数。

在

RNN 的情况，这可

以通过不同

的方式来实

现。此处，我们

回顾最常见

和最明显的

选择。

之前，我

们已经讨论

了将 t

= 1, . .

. , τ 的向量

x

(t) 序列作为输

入的 RNN。另一

种

选择是只使

用单个向量

x

作为输入。当

x 是一个固定

大小的向量

时，我们可以

简

单地将其

看作产生 y

序

列 RNN 的额外输

入。将额外输

入提供到 RNN

的

一些常见

方

法是：

1. 在每个

时刻作为一

个额外输入

，或

2. 作为初始

状态 h

(0)，或

3. 结合

两种方式。

第

一个也是最

常用的方法

如图 10.9

所示。输

入 x 和每个隐

藏单元向量

h

(t)

之间

的相互

作用是通过

新引入的权

重矩阵 R 参数

化的，这是只

包含

y 序列的

模型所没有

的。同样的乘

积 x

⊤R

在每个时

间步作为隐

藏单元的一

个额外输入

。我们可以认

为 x

的选择（确

定 x

⊤R 值），是有效

地用于每个

隐藏单元的

一个新偏置

参数。权重与

输

入保持独

立。我们可以

认为这种模

型采用了非

条件模型的

θ，并将 ω

代入 θ，其

中

ω 内的偏置

参数现在是

输入的函数

。

RNN 可以接收向

量序列 x

(t)

作为

输入，而不是

仅接收单个

向量 x 作为输

入。

式

(10.8) 描述的

RNN 对应条件分

布 P(y

(1)

, . .

. , y

(τ)

| x

(1)

,

. . . ,

x

(τ)

)，并在条件

独立

10.2

循环神

经网络 335

oo((tt−−1)1) oo((tt))

oo((tt+1) +1)

LL((tt−−1)1) LL((tt))

LL((tt+1) +1)

yy((tt−−1)1) yy((tt))

yy((tt+1) +1)

hh((tt−−1)1) hh((tt))

hh((tt+1) +1)

W W

W W ss((... ...

)) hh((... ... ))

V V V

U

U U

x

yy((...

...))

R R R

R R

图 10.9:

将

固定长度的

向量 x 映射到

序列 Y

上分布

的 RNN。这类 RNN 适用

于很多任务

如图注，

其中

单个图像作

为模型的输

入，然后产生

描述图像的

词序列。观察

到的输出序

列的每个元

素 y

(t)

同时用作

输入（对于当

前时间步）和

训练期间的

目标（对于前

一时间步）。

的

假设下这个

分布分解为

∏

t

P(y

(t)

| x

(1)

,

. . . ,

x

(t)

). (10.35)

为去掉条件

独立的假设

，我们可以在

时刻 t 的输出

到时刻 t

+ 1 的隐

藏单元添加

连

接，如图10.10

所

示。该模型就

可以代表关

于 y 序列的任

意概率分布

。这种给定一

个

序列表示

另一个序列

分布的模型

的还是有一

个限制，就是

这两个序列

的长度必须

是

相同的。我

们将在第 10.4 节

描述如何消

除这种限制

。

336

第十章 序列

建模：循环和

递归网络

oo((tt−−1)1) oo((tt))

oo((tt+1) +1)

LL((tt−−1)1) LL((tt))

LL((tt+1) +1)

yy((tt−−1)1) yy((tt))

yy((tt+1) +1)

hh((tt−−1)1) hh((tt))

hh((tt+1) +1)

W W

W W

hh((... ...

)) hh((... ... ))

V V V

U

U U

xx((tt−−1)1)

R

xx((tt)) xx((tt+1) +1)

R

R

图

10.10: 将可变长度

的 x

值序列映

射到相同长

度的 y 值序列

上分布的条

件循环神经

网络。对比

图

10.3

，此 RNN 包含从前

一个输出到

当前状态的

连接。这些连

接允许此RNN对

给定 x

的序列

后

相同长度

的 y 序列上的

任意分布建

模。图

10.3 的 RNN 仅能

表示在给定

x

值的情况下

，y 值彼此

条件

独立的分布

。

10.3

双向 RNN

目前为

止我们考虑

的所有循环

神经网络有

一个 ‘‘因果’’

结

构，意味着在

时刻 t 的

状态

只能从过去

的序列

x

(1)

, .

. . , x

(t−1) 以及

当前的输入

x

(t) 捕获信息。我

们还讨论

了

某些在 y 可用

时，允许过去

的 y

值信息影

响当前状态

的模型。

然而

，在许多应用

中，我们要输

出的 y

(t)

的预测

可能依赖于

整个输入序

列。例

如，在语

音识别中，由

于协同发音

，当前声音作

为音素的正

确解释可能

取决于未来

几个音素，甚

至潜在的可

能取决于未

来的几个词

，因为词与附

近的词之间

的存在语

义

依赖：如果当

前的词有两

种声学上合

理的解释，我

们可能要在

更远的未来

（和过

去）寻找

信息区分它

们。这在手写

识别和许多

其他序列到

序列学习的

任务中也是

如

此，将会在

下一节中描

述。

双向循环

神经网络（或

双向 RNN）为满足

这种需要而

被发明 (Schuster

and

Paliwal, 1997)。他们

在需要双向

信息的应用

中非常成功

(Graves, 2012)，如手写

10.3 双向

RNN 337

识别

(Graves et al., 2008;

Graves and Schmidhuber, 2009)，语音识

别

(Graves and

Schmidhuber, 2005;

Graves et al., 2013)

以及生物

信息学 (Baldi et al.,

1999)。

顾名

思义，双向 RNN 结

合时间上从

序列起点开

始移动的

RNN 和

另一个时间

上

从序列末

尾开始移动

的 RNN。图10.11

展示了

典型的双向

RNN，其中 h

(t) 代表通

过

时间向前

移动的子 RNN 的

状态，g

(t)

代表通

过时间向后

移动的子 RNN 的

状态。这

允许

输出单元

o

(t) 能

够计算同时

依赖于过去

和未来且对

时刻 t

的输入

值最敏感的

表

示，而不必

指定 t 周围固

定大小的窗

口（这是前馈

网络、卷积网

络或具有固

定大小

的先

行缓存器的

常规 RNN 所必须

要做的）。

oo((tt−−1)1)

oo((tt)) oo((tt+1) +1)

LL((tt−−1)1)

LL((tt)) LL((tt+1) +1)

yy((tt−−1)1)

yy((tt)) yy((tt+1) +1)

hh((tt−−1)1)

hh((tt)) hh((tt+1) +1)

xx((tt−−1)1)

xx((tt)) xx((tt+1) +1)

gg((tt−−1)1)

gg((tt)) gg((tt+1) +1)

图

10.11: 典

型的双向循

环神经网络

中的计算，意

图学习将输

入序列 x 映射

到目标序列

y（在每个

步骤

t 具有损失 L

(t)）。循

环性

h 在时间

上向前传播

信息（向右），而

循环性 g 在时

间上向后传

播

信息（向左

）。因此在每个

点 t，输出单元

o

(t) 可以受益于

输入

h

(t) 中关于

过去的相关

概要以及输

入 g

(t) 中关于未

来的相关概

要。

这个想法

可以自然地

扩展到 2

维输

入，如图像，由

四个 RNN 组成，每

一个沿

着四

个方向中的

一个计算：上

、下、左、右。如果

RNN

能够学习到

承载长期信

息，

338 第十章 序

列建模：循环

和递归网络

那在

2 维网格

每个点 (i, j)

的输

出 Oi,j 就能计算

一个能捕捉

到大多局部

信息但仍依

赖于长期输

入的表示。相

比卷积网络

，应用于图像

的 RNN

计算成本

通常更高，但

允

许同一特

征图的特征

之间存在长

期横向的相

互作用 (Visin et

al., 2015; Kalchbrenner

et

al., 2015)。实际

上，对于这样

的 RNN，前向传播

公式可以写

成表示使用

卷积的

形式

，计算自底向

上到每一层

的输入（在整

合横向相互

作用的特征

图的循环传

播之

前）。

10.4 基于

编码-解码的

序列到序列

架构

我们已

经在图

10.5 看到

RNN如何将输入

序列映射成

固定大小的

向量，在

图 10.9

中

看到RNN如何将

固定大小的

向量映射成

一个序列，在

图 10.3 、图 10.4

、

图 10.10 和图

10.11

中看到RNN如何

将一个输入

序列映射到

等长的输出

序列。

本节我

们讨论如何

训练RNN，使其将

输入序列映

射到不一定

等长的输出

序列。

这在许

多场景中都

有应用，如语

音识别、机器

翻译或问答

，其中训练集

的输入和输

出序列的长

度通常不相

同（虽然它们

的长度可能

相关）。

我们经

常将RNN的输入

称为

‘‘上下文

’’。我们希望产

生此上下文

的表示，C。这

个

上下文 C 可能

是一个概括

输入序列

X = (x

(1)

, . . .

, x

(nx)

)

的

向量或者向

量序列。

用于

映射可变长

度序列到另

一可变长度

序列最简单

的RNN架构最初

由Cho

et al.

(2014a) 提出，之后

不久由Sutskever et al.

(2014) 独立

开发，并且第

一个使

用这

种方法获得

翻译的最好

结果。前一系

统是对另一

个机器翻译

系统产生的

建

议进行评

分，而后者使

用独立的循

环网络生成

翻译。这些作

者分别将该

架构称

为编

码-解码或序

列到序列架

构，如图 10.12 所示

。这个想法非

常简单：（1） 编码

器（encoder）或

读取器

(reader) 或 输入 (input)

RNN 处理

输入序列。编

码器输出

上

下文 C（通常是

最终隐藏状

态的简单函

数）。(2)

解码器（decoder）或

写入器

(writer) 或 输

出

(output) RNN 则以固定

长度的向量

（如图 10.9

）为条件

产生输出

序

列 Y =

(y

(1)

, .

. . , y

(ny)

)。这种架构

对比本章前

几节提出的

架构的创新

之处在于长

度 nx 和

ny 可以彼

此不同，而之

前的架构约

束 nx =

ny = τ。在序列到

序列的架构

中，两个 RNN

共同

训练以最大

化 log P(y

(1)

, . . .

, y

(ny)

|

x

(1)

, .

. . , x

(nx)

)(关于训练

集

中所有 x

和

y 对的平均)。编

码器 RNN 的最后

一个状态

hnx 通

常被当作输

入的表

示 C

并

作为解码器

RNN 的输入。

如果

上下文 C

是一

个向量，则解

码器 RNN 只是在

第 10.2.4

节描述的

向量到序

10.4 基

于编码-解码

的序列到序

列架构 339

Encoder

…

xx(1) (1)

xx(2) (2) xx((... ...))

xx((nnxx))

Decoder

…

yy(1)

(1) yy(2) (2) yy((...

...)) yy((nnyy))

C

图

10.12: 在

给定输入序

列 (x

(1)

, x

(2)

,

. . . ,

x

(nx)

) 的情况下

学习生成输

出序列

(y

(1)

, y

(2)

, . .

. , y

(ny)

)

的编

码器-解码器

或序列到序

列的 RNN 架构的

示例。它由读

取输入序列

的编码器

RNN 以

及生成

输出

序列（或计算

给定输出序

列的概率）的

解码器 RNN

组成

。编码器 RNN 的最

终隐藏状态

用于

计算一

般为固定大

小的上下文

变量

C，C 表示输

入序列的语

义概要并且

作为解码器

RNN 的输入。

列

RNN。正

如我们所见

，向量到序列

RNN 至少有两种

接受输入的

方法。输入可

以

被提供为

RNN 的初始状态

，或连接到每

个时间步中

的隐藏单元

。这两种方式

也可以

结合

。

这里并不强

制要求编码

器与解码器

的隐藏层具

有相同的大

小。

此架构的

一个明显不

足是，编码器

RNN 输出的上下

文

C 的维度太

小而难以适

当地概括一

个长序列。这

种现象由Bahdanau et al.

(2015) 在

机器翻译中

观察到。他

们

提出让 C

成为

可变长度的

序列，而不是

一个固定大

小的向量。此

外，他们还引

入

了将序列

C 的元素和输

出序列的元

素相关联的

注意力机制

（attention mechanism）。

读者可在第

12.4.5.1 节了解更多

细节。

340 第十章

序列建模：循

环和递归网

络

10.5 深度循环

网络

大多数

RNN 中的计算可

以分解成三

块参数及其

相关的变换

：

1. 从输入到隐

藏状态，

2. 从前

一隐藏状态

到下一隐藏

状态，以及

3. 从

隐藏状态到

输出。

根据图

10.3 中的

RNN 架构，这

三个块都与

单个权重矩

阵相关联。换

句话说，当网

络

被展开时

，每个块对应

一个浅的变

换。能通过深

度 MLP

内单个层

来表示的变

换称为

浅变

换。通常，这是

由学成的仿

射变换和一

个固定非线

性表示组成

的变换。

在这

些操作中引

入深度会有

利的吗？实验

证据 (Graves

et al., 2013; Pascanu

et al., 2014a) 强烈暗

示理应如此

。实验证据与

我们需要足

够的深度以

执行所需

映

射的想法一

致。读者可以

参考 Schmidhuber (1992); El

Hihi and Bengio (1996)

或 Jaeger (2007a) 了解

更早的关于

深度

RNN 的研究

。

Graves et

al. (2013) 第一个展示

了将 RNN

的状态

分为多层的

显著好处，如

图 10.13 (左)。我们可

以认为，在图

10.13 (a)

所示层次结

构中较低的

层起到了将

原始

输入转

化为对更高

层的隐藏状

态更合适表

示的作用。Pascanu et al.

(2014a) 更

进一步

提出

在上述三个

块中各使用

一个单独的

MLP（可能是深度

的），如图10.13 (b)

所示

。

考虑表示容

量，我们建议

在这三个步

中都分配足

够的容量，但

增加深度可

能会因为

优

化困难而损

害学习效果

。在一般情况

下，更容易优

化较浅的架

构，加入图10.13 (b)

的

额外深度导

致从时间步

t 的变量到时

间步 t +

1 的最短

路径变得更

长。例如，如果

具有单个隐

藏层的 MLP 被用

于状态到状

态的转换，那

么与图

10.3 相比

，我们就会

加

倍任何两个

不同时间步

变量之间最

短路径的长

度。然而Pascanu et

al. (2014a) 认

为

，在隐藏到隐

藏的路径中

引入跳跃连

接可以缓和

这个问题，如

图

10.13 (c) 所示。

10.6

递归

神经网络 341

h

y

x

z

(a) (b)

(c)

x

h

y

x

h

y

图

10.13:

循环神经网

络可以通过

许多方式变

得更深 (Pascanu et al.,

2014a)。(a) 隐藏

循环状态可

以被分解为

具有层次的

组。(b) 可以向输

入到隐藏，隐

藏到隐藏以

及隐藏到输

出的部分引

入更深的

计

算

(如 MLP)。这可以

延长链接不

同时间步的

最短路径。(c) 可

以引入跳跃

连接来缓解

路径延长

的

效应。

10.6 递归神

经网络

递归

神经网络2代

表循环网络

的另一个扩

展，它被构造

为深的树状

结构而不

是

RNN

的链状结构

，因此是不同

类型的计算

图。递归网络

的典型计算

图如图 10.14 所

示

。递归神经网

络由

Pollack (1990) 引入，而

Bottou (2011)

描述了这类

网络的潜在

用途——学习推

论。递归网络

已成功地应

用于输入是

数据结构的

神经网络 (Frasconi

et al.,

1997, 1998)，如

自然语言处

理 (Socher et

al., 2011a,c, 2013a) 和计算机

视觉

(Socher et al., 2011b)。

递归网

络的一个明

显优势是，对

于具有相同

长度 τ 的序列

，深度（通过非

线性

操作的

组合数量来

衡量）可以急

剧地从

τ 减小

为 O(log τ

)，这可能有

助于解决长

期

2我们建议

不要将 ‘‘递归

神经网络’’ 缩

写为

“RNN’’，以免与

“循环神经网

络’’ 混淆。

342 第十

章

序列建模

：循环和递归

网络

依赖。一

个悬而未决

的问题是如

何以最佳的

方式构造树

。一种选择是

使用不依赖

于

数据的树

结构，如平衡

二叉树。在某

些应用领域

，外部方法可

以为选择适

当的树结构

提供借鉴。例

如，处理自然

语言的句子

时，用于递归

网络的树结

构可以被固

定为句

子语

法分析树的

结构（可以由

自然语言语

法分析程序

提供）(Socher

et al., 2011a,c)。

理想的

情况下，人们

希望学习器

自行发现和

推断适合于

任意给定输

入的树结构

，如

(Bottou, 2011) 所建议。

xx(1)

(1) xx(2) (2) xx(3)

(3)

V V V

y

L

xx(4) (4)

V

o

U W

U W

U

W

图

10.14: 递归网络将

循环网络的

链状计算图

推广到树状

计算图。可变

大小的序列

x

(1)

,

x

(2)

, .

. . , x

(t)

可以通过固

定的参数集

合（权重矩阵

U, V,W）映射到固定

大小的表示

（输出 o）。该图展

示了监

督学

习的情况，其

中提供了一

些与整个序

列相关的目

标 y。

递归网络

想法的变种

存在很多。例

如，Frasconi et

al. (1997) 和 Frasconi

et al.

(1998) 将数据

与树结构相

关联，并将输

入和目标与

树的单独节

点相关联。由

每个节

点执

行的计算无

须是传统的

人工神经计

算（所有输入

的仿射变换

后跟一个单

调非线

性）。例

如，Socher et al.

(2013a) 提出用张

量运算和双

线性形式，在

这之前人们

已

经发现当

概念是由连

续向量（嵌入

）表示时，这种

方式有利于

建模概念之

间的联系

10.7

长

期依赖的挑

战 343

(Weston et

al., 2010; Bordes et

al., 2012)。

10.7 长期依赖

的挑战

学习

循环网络长

期依赖的数

学挑战在第

8.2.5 节中引入。根

本问题是，经

过许多

阶段

传播后的梯

度倾向于消

失（大部分情

况）或爆炸（很

少，但对优化

过程影响很

大）。即使我们

假设循环网

络是参数稳

定的（可存储

记忆，且梯度

不爆炸），但长

期依

赖的困

难来自比短

期相互作用

指数小的权

重（涉及许多

Jacobian

相乘）。许多资

料提

供了更

深层次的讨

论 (Hochreiter, 1991a;

Doya, 1993; Bengio et

al., 1994b; Pascanu

et

al., 2013a)。在这一节

中，我们会更

详细地描述

该问题。其余

几节介绍克

服这个问

题

的方法。

循环

网络涉及相

同函数的多

次组合，每个

时间步一次

。这些组合可

以导致极端

非线性行为

，如图

10.15 所示。

−60 −40

−20 0 20 40

60

Input coordinate

−4

−3

−2

−1

0

1

2

3

4

0

1

2

3

4

5

图

10.15: 重复组合函

数。当组合许

多非线性函

数（如这里所

示的线性

tanh 层

）时，结果是高

度

非线性的

，通常大多数

值与微小的

导数相关联

，也有一些具

有大导数的

值，以及在增

加和减小之

间的多次交

替。此处，我们

绘制从 100

维隐

藏状态降到

单个维度的

线性投影，绘

制于 y 轴上。x

轴

是

100 维空间中

沿着随机方

向的初始状

态的坐标。因

此，我们可以

将该图视为

高维函数的

线性

截面。曲

线显示每个

时间步之后

的函数，或者

等价地，转换

函数被组合

一定次数之

后。

特别地，循

环神经网络

所使用的函

数组合有点

像矩阵乘法

。我们可以认

为，循

Projection of output

344

第十章

序列建模：循

环和递归网

络

环联系

h

(t)

= W⊤

h

(t−1)

(10.36)

是

一个非常简

单的、缺少非

线性激活函

数和输入 x 的

循环神经网

络。如第8.2.5

节描

述，这种递推

关系本质上

描述了幂法

。它可以被简

化为

h

(t) =

(Wt

)

⊤h

(0)

, (10.37)

而当 W

符

合下列形式

的特征分解

W = QΛQ

⊤

, (10.38)

其中 Q

正交，循

环性可进一

步简化为

h

(t) =

Q

⊤Λ

tQh(0)

.

(10.39)

特

征值提升到

t 次后，导致幅

值不到一的

特征值衰减

到零，而幅值

大于一的就

会激

增。任何

不与最大特

征向量对齐

的

h

(0) 的部分将

最终被丢弃

。

这个问题是

针对循环网

络的。在标量

情况下，想象

多次乘一个

权重

w。该乘积

w

t 消失还是爆

炸取决于 w

的

幅值。然而，如

果每个时刻

使用不同权

重 w

(t) 的非循

环

网络，情况就

不同了。如果

初始状态给

定为 1，那么时

刻 t 的状态可

以由

∏

t w

(t)

给出。假

设 w

(t) 的值是随

机生成的，各

自独立，且有

0

均值 v 方差。乘

积的方差

就

为

O(v

n

)。为了获得

某些期望的

方差 v

∗，我们可

以选择单个

方差为 v =

n√

v

∗ 权

重

。因此，非常深

的前馈网络

通过精心设

计的比例可

以避免梯度

消失和爆炸

问题，

如 Sussillo (2014) 所主

张的。

RNN 梯度消

失和爆炸问

题是由不同

研究人员独

立发现 (Hochreiter, 1991a;

Bengio et al., 1993,

1994b)。有人

可能会希望

通过简单地

停留在梯度

不消失或爆

炸的

参数空

间来避免这

个问题。不幸

的是，为了储

存记忆并对

小扰动具有

鲁棒性，RNN 必

须

进入参数空

间中的梯度

消失区域

(Bengio et al., 1993,

1994b)。具

体来说，每当

模

型能够表

示长期依赖

时，长期相互

作用的梯度

幅值就会变

得指数小（相

比短期相互

作用的梯度

幅值）。这并不

意味着这是

不可能学习

的，由于长期

依赖关系的

信号很容

易

被短期相关

性产生的最

小波动隐藏

，因而学习长

期依赖可能

需要很长的

时间。实

践中

，Bengio

et al. (1994b) 的实验表明

，当我们增加

了需要捕获

的依赖关系

的跨度，

基于

梯度的优化

变得越来越

困难，SGD 在长度

仅为 10 或

20 的序

列上成功训

练传

统 RNN

的概

率迅速变为

0。

10.8 回声状态网

络 345

将循环网

络作为动力

系统更深入

探讨的资料

见 Doya (1993); Bengio

et al.

(1994b); Siegelmann

and Sontag (1995) 及

Pascanu et al. (2013b)

的回顾

。本章的其

余

部分将讨论

目前已经提

出的降低学

习长期依赖

（在某些情况

下，允许一个

RNN 学

习横跨数

百步的依赖

）难度的不同

方法，但学习

长期依赖的

问题仍是深

度学习中的

一个主要挑

战。

10.8 回声状态

网络

从 h

(t−1) 到 h

(t)

的

循环权重映

射以及从 x

(t) 到

h

(t) 的输入权重

映射是循环

网

络中最难

学习的参数

。研究者 (Jaeger,

2003; Maass et al.,

2002; Jaeger and Haas,

2004; Jaeger, 2007b) 提出

避免这种困

难的方法是

设定循环隐

藏单元，使其

能很好

地捕

捉过去输入

历史，并且只

学习输出权

重。 回声状态

网络（echo state network）

或 ESN (Jaeger and

Haas, 2004; Jaeger, 2007b)，以及

流体状态机

（liquid

state

machine）(Maass et al.,

2002) 分别独立地

提出了这种

想法。后者是

类似的，只不

过它使用脉

冲神经元（二

值输出）而不

是 ESN 中的连续

隐藏单元。ESN

和

流体状

态机

都被称为 储

层计算（reservoir computing）(Lukoševičius

and Jaeger, 2009)，因

为

隐藏单元形

成了可能捕

获输入历史

不同方面的

临时特征池

。

储层计算循

环网络类似

于核机器，这

是思考它们

的一种方式

：它们将任意

长度

的序列

（到时刻 t 的输

入历史）映射

为一个长度

固定的向量

（循环状态

h

(t)），之

后

可以施加

一个线性预

测算子（通常

是一个线性

回归）以解决

感兴趣的问

题。训练准

则

就可以很容

易地设计为

输出权重的

凸函数。例如

，如果输出是

从隐藏单元

到输出

目标

的线性回归

，训练准则就

是均方误差

，由于是凸的

就可以用简

单的学习算

法可

靠地解

决 (Jaeger, 2003)。

因此，重要

的问题是：我

们如何设置

输入和循环

权重才能让

一组丰富的

历史可

以在

循环神经网

络的状态中

表示？储层计

算研究给出

的答案是将

循环网络视

为动态

系统

，并设定让动

态系统接近

稳定边缘的

输入和循环

权重。

最初的

想法是使状

态到状态转

换函数的

Jacobian 矩

阵的特征值

接近 1。如

第

8.2.5 节

解释，循环网

络的一个重

要特征就是

Jacobian 矩阵的特征

值谱 J

(t) =

∂s(t)

∂s(t−1)。特别重

要的是

J

(t) 的 谱

半径（spectral

radius），定义为

特征值的最

大绝对

值。

为

了解谱半径

的影响，可以

考虑反向传

播中 Jacobian

矩阵 J 不

随 t

改变的简

单

346 第十章 序

列建模：循环

和递归网络

情况。例如当

网络是纯线

性时，会发生

这种情况。假

设

J 特征值 λ 对

应的特征向

量

为 v。考虑当

我们通过时

间向后传播

梯度向量时

会发生什么

。如果刚开始

的梯度向量

为 g，然后经过

反向传播的

一个步骤后

，我们将得到

Jg，n 步之后我们

会得到

J

n

g。

现在

考虑如果我

们向后传播

扰动版本的

g

会发生什么

。如果我们刚

开始是 g + δv，

一步

之后，我们会

得到 J(g + δv)。n

步之后

，我们将得到

J

n

(g +

δv)。由此我们可

以看出，由 g 开

始的反向传

播和由 g

+ δv 开始

的反向传播

，n 步之后偏离

δJ

n

v。如

果 v

选择为

J 特征值 λ 对应

的一个单位

特征向量，那

么在每一步

乘

Jacobian 矩阵

只是

简单地缩放

。反向传播的

两次执行分

离的距离为

δ|λ|

n。当

v 对应于最

大特征值

|λ|，初

始扰动为 δ

时

这个扰动达

到可能的最

宽分离。

当 |λ| >

1，偏

差 δ|λ|

n 就会指数

增长。当

|λ| < 1，偏差

就会变得指

数小。

当然，这

个例子假定

Jacobian

矩阵在每个

时间步是相

同的，即对应

于没有非线

性循环网络

。当非线性存

在时，非线性

的导数将在

许多时间步

后接近零，并

有助于

防止

因过大的谱

半径而导致

的爆炸。事实

上，关于回声

状态网络的

最近工作提

倡使

用远大

于 1

的谱半径

(Yildiz et al., 2012;

Jaeger, 2012)。

我们已经说

过多次，通过

反复矩阵乘

法的反向传

播同样适用

于没有非线

性的正

向传

播的网络，其

状态为

h

(t+1) = h

(t)⊤W。

如果

线性映射 W⊤ 在

L

2 范数的测度

下总是缩小

h，那么我们说

这个映射是

收

缩（contractive）的。当谱

半径小于一

，则从 h

(t) 到 h

(t+1)

的映

射是收缩的

，因此小

变化

在每个时间

步后变得更

小。当我们使

用有限精度

（如 32 位整数）来

存储状态向

量时，必然会

使得网络忘

掉过去的信

息。

Jacobian 矩阵告诉

我们 h

(t)

一个微

小的变化如

何向前一步

传播，或等价

的，

h

(t+1) 的梯度如

何向后一步

传播。需要注

意的是，W

和 J 都

不需要是对

称的（尽管

它

们是实方阵

），因此它们可

能有复的特

征值和特征

向量，其中虚

数分量对应

于潜

在的振

荡行为（如果

迭代地应用

同一 Jacobian）。即使 h

(t)

或

h

(t) 中有趣的小

变化

在反向

传播中是实

值的，它们仍

可以用这样

的复数基表

示。重要的是

，当向量乘以

矩

阵时，这些

复数基的系

数幅值（复数

的绝对值）会

发生什么变

化。幅值大于

1 的特

征值对

应于放大（如

果反复应用

则指数增长

）或收缩（如果

反复应用则

指数减小）。

非

线性映射情

况时，Jacobian

会在每

一步任意变

化。因此，动态

量变得更加

复

杂。然而，一

个小的初始

变化多步之

后仍然会变

成一个大的

变化。纯线性

和非线性

情

况的一个不

同之处在于

使用压缩非

线性（如 tanh）可以

使循环动态

量有界。注意

，

即使前向传

播动态量有

界，反向传播

的动态量仍

然可能无界

，例如，当 tanh 序列

10.9 渗漏单元和

其他多时间

尺度的策略

347

都在它们状

态中间的线

性部分，并且

由谱半径大

于 1 的权重矩

阵连接。然而

，所有

tanh

单元同

时位于它们

的线性激活

点是非常罕

见的。

回声状

态网络的策

略是简单地

固定权重使

其具有一定

的谱半径如

3，其中信息

通

过时间前向

传播，但会由

于饱和非线

性单元（如 tanh）的

稳定作用而

不会爆炸。

最

近，已经有研

究表明，用于

设置 ESN 权重的

技术可以用

来初始化完

全可训练

的

循环网络的

权重（通过时

间反向传播

来训练隐藏

到隐藏的循

环权重），帮助

学习长

期依

赖 (Sutskever, 2012; Sutskever

et al., 2013)。在这种设

定下，结合第

8.4 节中稀

疏初

始化的方案

，设置 1.2 的初始

谱半径表现

不错。

10.9

渗漏单

元和其他多

时间尺度的

策略

处理长

期依赖的一

种方法是设

计工作在多

个时间尺度

的模型，使模

型的某些部

分在细粒度

时间尺度上

操作并能处

理小细节，而

其他部分在

粗时间尺度

上操作并能

把遥远过去

的信息更有

效地传递过

来。存在多种

同时构建粗

细时间尺度

的策略。这

些

策略包括在

时间轴增加

跳跃连接，“渗

漏单元’’ 使用

不同时间常

数整合信号

，并去

除一些

用于建模细

粒度时间尺

度的连接。

10.9.1 时

间维度的跳

跃连接

增加

从遥远过去

的变量到目

前变量的直

接连接是得

到粗时间尺

度的一种方

法。

使用这样

跳跃连接的

想法可以追

溯到Lin et al. (1996)，紧接是

向前馈网络

引入延迟

的

想法 (Lang and Hinton,

1988)。在普通

的循环网络

中，循环从时

刻 t 的单元连

接

到时刻

t + 1 单

元。构造较长

的延迟循环

网络是可能

的

(Bengio, 1991)。

正如我们

在第 8.2.5

节看到

，梯度可能关

于时间步数

呈指数消失

或爆炸。(Lin

et al., 1996)

引入

了 d 延时的循

环连接以减

轻这个问题

。现在导数指

数减小的速

度与

τ

d 相关而

不是 τ。既然同

时存在延迟

和单步连接

，梯度仍可能

成 t

指数爆炸

。这允许

学习

算法捕获更

长的依赖性

，但不是所有

的长期依赖

都能在这种

方式下良好

地表示。

348 第十

章

序列建模

：循环和递归

网络

10.9.2 渗漏单

元和一系列

不同时间尺

度

获得导数

乘积接近

1 的

另一方式是

设置线性自

连接单元，并

且这些连接

的权重

接近

1。

我们对某些

v

值应用更新

µ

(t) ← αµ(t−1)

+ (1−α)v

(t) 累积一个滑

动平均值

µ

(t)，

其

中 α

是一个从

µ

(t−1) 到 µ

(t) 线性自连

接的例子。当

α 接近 1

时，滑动

平均值能记

住过去很长

一段时间的

信息，而当 α 接

近 0，关于过去

的信息被迅

速丢弃。线性

自连

接的隐

藏单元可以

模拟滑动平

均的行为。这

种隐藏单元

称为 渗漏单

元（leaky unit）。

d

时间步的

跳跃连接可

以确保单元

总能被 d 个时

间步前的那

个值影响。使

用权

重接近

1

的线性自连

接是确保该

单元可以访

问过去值的

不同方式。线

性自连接通

过

调节实值

α 更平滑灵活

地调整这种

效果，而不是

调整整数值

的跳跃长度

。

这个想法由

Mozer

(1992) 和 El Hihi

and Bengio (1996) 提出。在回

声状态网

络

中，渗漏单元

也被发现很

有用 (Jaeger et al.,

2007)。

我们可

以通过两种

基本策略设

置渗漏单元

使用的时间

常数。一种策

略是手动将

其固定为常

数，例如在初

始化时从某

些分布采样

它们的值。另

一种策略是

使时间常

数

成为自由变

量，并学习出

来。在不同时

间尺度使用

这样的渗漏

单元似乎能

帮助学

习长

期依赖

(Mozer, 1992; Pascanu et

al., 2013a)。

10.9.3 删除

连接

处理长

期依赖另一

种方法是在

多个时间尺

度组织 RNN 状态

的想法 (El

Hihi and

Bengio, 1996)，信息

在较慢的时

间尺度上更

容易长距离

流动。

这个想

法与之前讨

论的时间维

度上的跳跃

连接不同，因

为它涉及主

动删除长度

为一的连接

并用更长的

连接替换它

们。以这种方

式修改的单

元被迫在长

时间尺度上

运作。而通过

时间跳跃连

接是添加边

。收到这种新

连接的单元

，可以学习在

长时间

尺度

上运作，但也

可以选择专

注于自己其

他的短期连

接。

强制一组

循环单元在

不同时间尺

度上运作有

不同的方式

。一种选择是

使循环

单元

变成渗漏单

元，但不同的

单元组关联

不同的固定

时间尺度。这

由

Mozer (1992)

提出，并被

成功应用于

Pascanu et

al. (2013a)。另一种选择

是使显式且

离散的更新

发生在不同

的时间，不同

的单元组有

不同的频率

。这是 El Hihi

and Bengio (1996)

和

Koutnik et al. (2014)

的方

法。它在一些

基准数据集

上表现不错

。

10.10 长短期记忆

和其他门控

RNN 349

10.10 长短期记忆

和其他门控

RNN

本文撰写之

时，实际应用

中最有效的

序列模型称

为 门控

RNN（gated RNN）。

包括

基于 长短期

记忆（long

short-term memory）和基于

门控循环单

元（gated

recurrent unit）的网络。

像

渗漏单元一

样，门控 RNN 想法

也是基于生

成通过时间

的路径，其中

导数既不

消

失也不发生

爆炸。渗漏单

元通过手动

选择常量的

连接权重或

参数化的连

接权重来

达

到这一目的

。门控 RNN 将其推

广为在每个

时间步都可

能改变的连

接权重。

渗漏

单元允许网

络在较长持

续时间内积

累信息（诸如

用于特定特

征或类的线

索）。然而，一旦

该信息被使

用，让神经网

络遗忘旧的

状态可能是

有用的。例如

，如

果一个序

列是由子序

列组成，我们

希望渗漏单

元能在各子

序列内积累

线索，我们需

要将状态设

置为 0 以忘记

旧状态的机

制。我们希望

神经网络学

会决定何时

清除状态，

而

不是手动决

定。这就是门

控

RNN 要做的事

。

10.10.1 LSTM

引入自循环

的巧妙构思

，以产生梯度

长时间持续

流动的路径

是初始 长短

期记忆

（long short-term

memory, LSTM）模型

的核心贡献

(Hochreiter and Schmidhuber,

1997)。其中一个关

键扩展是使

自循环的权

重视上下文

而定，而不是

固定的 (Gers

et al.,

2000)。门控

此自循环（由

另一个隐藏

单元控制）的

权重，累积的

时间尺度可

以动态地改

变。在这种情

况下，即使是

具有固定参

数的 LSTM，累积的

时间尺度也

可以因输入

序列而改变

，因为时间常

数是模型本

身的输出。LSTM 已

经在许多应

用

中取得重

大成功，如无

约束手写识

别

(Graves et al., 2009)、语音识别

(Graves

et al.,

2013; Graves

and Jaitly, 2014)、手写生成 (Graves,

2013)、机

器翻译 (Sutskever et al.,

2014)、为图

像生成标题

(Kiros et al., 2014b;

Vinyals et al., 2014b;

Xu et al., 2015)

和解析 (Vinyals et al.,

2014a)。

LSTM 块如

图 10.16

所示。在浅

循环网络的

架构下，相应

的前向传播

公式如下。

更

深的架构也

被成功应用

(Graves et al.,

2013; Pascanu et al.,

2014a)。LSTM 循

环网络除

了外部的 RNN

循

环外，还具有

内部的 “LSTM 细胞

’’ 循环（自环），因

此

LSTM 不是简单

地向输入和

循环单元的

仿射变换之

后施加一个

逐元素的非

线性。

与普通

的循环网络

类似，每个单

元有相同的

输入和输出

，但也有更多

的参数和控

制

信息流动

的门控单元

系统。最重要

的组成部分

是状态单元

s

(

i

t)，与前一节讨

论的渗漏

350

第

十章 序列建

模：循环和递

归网络

×

input

input gate forget gate

output gate

output

state

self-loop

×

+ ×

图 10.16: LSTM 循

环网络‘‘细胞

’’

的框图。细胞

彼此循环连

接，代替一般

循环网络中

普通的隐藏

单元。这里使

用常规的人

工神经元计

算输入特征

。如果 sigmoid 输入门

允许，它的值

可以累加到

状

态。状态单

元具有线性

自循环，其权

重由遗忘门

控制。细胞的

输出可以被

输出门关闭

。所有门控单

元都具有

sigmoid 非

线性，而输入

单元可具有

任意的压缩

非线性。状态

单元也可以

用作门控单

元

的额外输

入。黑色方块

表示单个时

间步的延迟

。

单元有类似

的线性自环

。然而，此处自

环的权重（或

相关联的时

间常数）由

遗

忘门

（forget gate） fi

(t) 控制（时

刻 t 和细胞

i），由

sigmoid 单元将权重

设置为 0 和

1 之

间的值：

fi

(t)

= σ

(

b

f

i +

∑

j

Ui,j

f

x

(

j

t) +

∑

j

Wi,j

f

h

(

j

t−1))

, (10.40)

其中

x

(t)

是当前输入

向量，h

t 是当前

隐藏层向量

，h

t

包含所有 LSTM 细

胞的输出。

b

f

, U

f

,Wf 分

别是偏置、输

入权重和遗

忘门的循环

权重。因此 LSTM 细

胞内部状态

10.10

长短期记忆

和其他门控

RNN 351

以如下方式

更新，其中有

一个条件的

自环权重 fi

(t)：

s

(t

i

) = fi

(t)

s

(

i

t−1)

+ gi

(t)

σ

(

bi +

∑

j

Ui,jx

(

j

t) +

∑

j

Wi,jh

(

j

t−1))

, (10.41)

其

中 b,

U,W 分别是 LSTM 细

胞中的偏置

、输入权重和

遗忘门的循

环权重。外部

输

入门 (external input gate)

单元

gi

(t) 以类似遗忘

门（使用sigmoid获得

一个 0

和 1 之

间

的值）的方式

更新，但有自

身的参数：

g

(t

i

)

= σ

(

b

g

i +

∑

j

Ui,j

g

x

(

j

t) +

∑

j

Wi,j

g

h

(

j

t−1))

. (10.42)

LSTM 细

胞的输出

h

(

i

t)

也

可以由输出

门 (output gate) qi

(t) 关闭（使用

sigmoid单元

作为门

控）：

h

(

i

t) =

tanh(

s

(

i

t)

)

qi

(t)

, (10.43)

q

(t

i

) = σ

(

b

o

i

+

∑

j

Ui,j

o x

(

j

t) +

∑

j

Wi,j

o h

(

j

t−1))

, (10.44)

其中 b

o

,

U

o

,Wo 分别

是偏置、输入

权重和遗忘

门的循环权

重。在这些变

体中，可以

选

择使用细胞

状态 s

(

i

t) 作为额

外的输入（及

其权重），输入

到第 i 个单元

的三个门，

如

图 10.16 所示。这将

需要三个额

外的参数。

LSTM

网

络比简单的

循环架构更

易于学习长

期依赖，先是

用于测试长

期依

赖学习

能力的人工

数据集 (Bengio et

al., 1994c; Hochreiter and

Schmidhuber, 1997;

Hochreiter et

al., 2001)，然后

是在具有挑

战性的序列

处理任务上

获得最先进

的表现

(Graves, 2012,

2013; Sutskever et al.,

2014)。LSTM 的变

体和替代也

已经被研究

和

使用，这将

在下文进行

讨论。

10.10.2

其他门

控 RNN

LSTM 架构中哪

些部分是真

正必须的？还

可以设计哪

些其他成功

架构允许网

络

动态地控

制时间尺度

和不同单元

的遗忘行为

？

最近关于门

控 RNN 的工作给

出了这些问

题的某些答

案，其单元也

被称为门控

循

环单元或

GRU (Cho et al.,

2014c; Chung et al.,

2014, 2015a; Jozefowicz et

al., 2015;

Chrupala et

al., 2015)。与 LSTM 的主要区

别是，单个门

控单元同时

控制遗忘因

子

352 第十章 序

列建模：循环

和递归网络

和更新状态

单元的决定

。更新公式如

下：

h

(

i

t) =

u

(

i

t−1)h

(

i

t−1) +

(1 − u

(

i

t−1))σ

(

bi

+

∑

j

Ui,jx

(

j

t) +

∑

j

Wi,j rj

(t−1)h

(

j

t−1))

, (10.45)

其中 u

代表

‘‘更新’’ 门，r 表示

‘‘复位’’ 门。它们

的值就如通

常所定义的

：

u

(t

i

)

= σ

(

b

u

i +

∑

j

Ui,j

u x

(

j

t) +

∑

j

Wi,j

u

h

(

j

t)

)

, (10.46)

和

r

(t

i

)

= σ

(

b

r

i +

∑

j

Ui,j

r x

(

j

t) +

∑

j

Wi,j

r

h

(

j

t)

)

. (10.47)

复位和更

新门能独立

地

‘‘忽略’’ 状态

向量的一部

分。更新门像

条件渗漏累

积器一样可

以线性门控

任意维度，从

而选择将它

复制（在 sigmoid 的一

个极端）或完

全由新的

‘‘目

标状态’’ 值（朝

向渗漏累积

器的收敛方

向）替换并完

全忽略它（在

另一个极端

）。

复位门控制

当前状态中

哪些部分用

于计算下一

个目标状态

，在过去状态

和未来状态

之间引入了

附加的非线

性效应。

围绕

这一主题可

以设计更多

的变种。例如

复位门（或遗

忘门）的输出

可以在

多个

隐藏单元间

共享。或者，全

局门的乘积

（覆盖一整组

的单元，例如

整一层）和

一

个局部门（每

单元）可用于

结合全局控

制和局部控

制。然而，一些

调查发现这

些 LSTM 和

GRU 架构的

变种，在广泛

的任务中难

以明显地同

时击败这两

个原始架

构

(Greff et

al., 2015; Jozefowicz et

al., 2015)。Greff et al.

(2015) 发现其中的

关键因

素是

遗忘门，而 Jozefowicz

et al. (2015) 发

现向

LSTM 遗忘门

加入 1 的偏置

(由

Gers

et al. (2000)

提倡) 能让

LSTM 变得与已探

索的最佳变

种一样健壮

。

10.11

优化长期依

赖

我们已经

在第 8.2.5 节和第

10.7

节中描述过

在许多时间

步上优化 RNN 时

发生

的梯度

消失和爆炸

的问题。

由 Martens and Sutskever

(2011) 提

出了一个有

趣的想法是

，二阶导数可

能在一

阶导

数消失的同

时消失。二阶

优化算法可

以大致被理

解为将一阶

导数除以二

阶导数

（在更

高维数，由梯

度乘以

Hessian 的逆

）。如果二阶导

数与一阶导

数以类似的

速率

收缩，那

么一阶和二

阶导数的比

率可保持相

对恒定。不幸

的是，二阶方

法有许多缺

10.11 优化长期依

赖

353

点，包括高

的计算成本

、需要一个大

的小批量、并

且倾向于被

吸引到鞍点

。Martens

and Sutskever

(2011) 发现采用二

阶方法的不

错结果。之后

，Sutskever et al.

(2013)

发现使用较

简单的方法

可以达到类

似的结果，例

如经过谨慎

初始化的 Nesterov 动

量

法。更详细

的内容参考

Sutskever (2012)。应用于 LSTM 时，这

两种方法在

很大程

度上

会被单纯的

SGD（甚至没有动

量）取代。这是

机器学习中

一个延续的

主题，设

计一

个易于优化

模型通常比

设计出更加

强大的优化

算法更容易

。

10.11.1 截断梯度

如

第 8.2.4 节讨论，强

非线性函数

（如由许多时

间步计算的

循环网络）往

往倾向

于非

常大或非常

小幅度的梯

度。如图

8.3 和图

10.17 所示，我们可

以看到，目标

函数

（作为参

数的函数）存

在一个伴随

‘‘悬崖’’

的 ‘‘地形

’’：宽且相当平

坦区域被目

标函

数变化

快的小区域

隔开，形成了

一种悬崖。

这

导致的困难

是，当参数梯

度非常大时

，梯度下降的

参数更新可

以将参数抛

出

很远，进入

目标函数较

大的区域，到

达当前解所

作的努力变

成了无用功

。梯度告诉

我

们，围绕当前

参数的无穷

小区域内最

速下降的方

向。这个无穷

小区域之外

，代价

函数可

能开始沿曲

线背面而上

。更新必须被

选择为足够

小，以避免过

分穿越向上

的

曲面。我们

通常使用衰

减速度足够

慢的学习率

，使连续的步

骤具有大致

相同的学习

率。适合于一

个相对线性

的地形部分

的步长经常

在下一步进

入地形中更

加弯曲的部

分时变得不

适合，会导致

上坡运动。

一

个简单的解

决方案已被

从业者使用

多年： 截断梯

度（clipping the gradient）。

此想法有

不同实例 (Mikolov, 2012; Pascanu

et al., 2013a)。一

种选择是在

参数更新

之

前，逐元素地

截断小批量

产生的参数

梯度

(Mikolov, 2012)。另一种

是在参数更

新

之前截断

梯度 g

的范数

∥g∥ (Pascanu et al.,

2013a)：

if ∥g∥ >

v (10.48)

g ←

gv

∥g∥

, (10.49)

其中 v 是范数

上界，g 用来更

新参数。因为

所有参数（包

括不同的参

数组，如权重

和偏置）的梯

度被单个缩

放因子联合

重整化，所以

后一方法具

有的优点是

保证了每

个

步骤仍然是

在梯度方向

上的，但实验

表明两种形

式类似。虽然

参数更新与

真实梯

度具

有相同的方

向梯度，经过

梯度范数截

断，参数更新

的向量范数

现在变得有

界。这

种有界

梯度能避免

执行梯度爆

炸时的有害

一步。事实上

，当梯度大小

高于阈值时

，即

354

第十章 序

列建模：循环

和递归网络

w

b

Without

clipping

w

b

With

clipping

图 10.17: 梯度截断

在有两个参

数

w 和 b 的循环

网络中的效

果示例。梯度

截断可以使

梯度下降在

极陡峭的悬

崖附近更合

理地执行。这

些陡峭的悬

崖通常发生

在循环网络

中，位于循环

网络近似线

性

的附近。悬

崖在时间步

的数量上呈

指数地陡峭

，因为对于每

个时间步，权

重矩阵都自

乘一次。(左)

没

有梯度截断

的梯度下降

越过这个小

峡谷的底部

，然后从悬崖

面接收非常

大的梯度。大

梯度灾难

性

地将参数推

到图的轴外

。(右) 使用梯度

截断的梯度

下降对悬崖

的反应更温

和。当它上升

到悬崖

面时

，步长受到限

制，使得它不

会被推出靠

近解的陡峭

区域。经 Pascanu et al.

(2013a) 许可

改编

此图。

使

是采取简单

的随机步骤

往往工作得

几乎一样好

。如果爆炸非

常严重，梯度

数值上

为 Inf 或

Nan（无穷大或不

是一个数字

），则可以采取

大小为 v

的随

机一步，通常

会离开数值

不稳定的状

态。截断每小

批量梯度范

数不会改变

单个小批量

的梯度方向

。

然而，许多小

批量使用范

数截断梯度

后的平均值

不等同于截

断真实梯度

（使用所有

的

实例所形成

的梯度）的范

数。大导数范

数的样本，和

像这样的出

现在同一小

批量的

样本

，其对最终方

向的贡献将

消失。不像传

统小批量梯

度下降，其中

真实梯度的

方

向是等于

所有小批量

梯度的平均

。换句话说，传

统的随机梯

度下降使用

梯度的无偏

估计，而与使

用范数截断

的梯度下降

引入了经验

上是有用的

启发式偏置

。通过逐元

素

截断，更新的

方向与真实

梯度或小批

量的梯度不

再对齐，但是

它仍然是一

个下降

方向

。还有学者提

出 (Graves,

2013)（相对于隐

藏单元）截断

反向传播梯

度，但没有

公

布与这些变

种之间的比

较; 我们推测

，所有这些方

法表现类似

。 J(w;b)

J(w;b)

10.12 外显记忆 355

10.11.2 引

导信息流的

正则化

梯度

截断有助于

处理爆炸的

梯度，但它无

助于消失的

梯度。为了解

决消失的梯

度问题并更

好地捕获长

期依赖，我们

讨论了如下

想法：在展开

循环架构的

计算图中，

沿

着与弧边相

关联的梯度

乘积接近

1 的

部分创建路

径。在第 10.10 节中

已经讨论过

，

实现这一点

的一种方法

是使用 LSTM 以及

其他自循环

和门控机制

。另一个想法

是正

则化或

约束参数，以

引导

‘‘信息流

’’。特别是即使

损失函数只

对序列尾部

的输出作惩

罚，我们也希

望梯度向量

∇h

(t)L 在反向传播

时能维持其

幅度。形式上

，我们要使

(∇h

(t)L)

∂h

(t)

∂h

(t−1) (10.50)

与

∇h

(t)L

(10.51)

一样大。在这

个目标下，Pascanu et al.

(2013a) 提

出以下正则

项：

Ω =

∑

t

(

(∇h

(t)L)

∂h

(t)

∂h

(t−1)

∥∇h

(t)L∥

− 1

)2

.

(10.52)

计算这一

梯度的正则

项可能会出

现困难，但 Pascanu et

al. (2013a) 提

出可以将后

向

传播向量

∇h

(t)L 考虑为恒值

作为近似（为

了计算正则

化的目的，没

有必要通过

它们

向后传

播）。使用该正

则项的实验

表明，如果与

标准的启发

式截断（处理

梯度爆炸）

相

结合，该正则

项可以显著

地增加

RNN 可以

学习的依赖

跨度。梯度截

断特别重要

，

因为它保持

了爆炸梯度

边缘的 RNN

动态

。如果没有梯

度截断，梯度

爆炸将阻碍

学习

的成功

。

这种方法的

一个主要弱

点是，在处理

数据冗余的

任务时如语

言模型，它并

不

像

LSTM 一样有

效。

10.12 外显记忆

智能需要知

识并且可以

通过学习获

取知识，这已

促使大型深

度架构的发

展。然

而，知识

是不同的并

且种类繁多

。有些知识是

隐含的、潜意

识的并且难

以用语言表

达——比如怎么

行走或狗与

猫的样子有

什么不同。其

他知识可以

是明确的、可

陈述

的以及

可以相对简

单地使用词

语表达——每天

常识性的知

识，如 ‘‘猫是一

种动物’’，

356

第十

章 序列建模

：循环和递归

网络

或者为

实现自己当

前目标所需

知道的非常

具体的事实

，如 ‘‘与销售团

队会议在

141

室

于下午 3:00 开始

’’。

神经网络擅

长存储隐性

知识，但是他

们很难记住

事实。被存储

在神经网络

参数

中之前

，随机梯度下

降需要多次

提供相同的

输入，即使如

此，该输入也

不会被特

别

精确地存储

。Graves et

al. (2014) 推测这是因

为神经网络

缺乏工作存

储 (working

memory) 系统，即类

似人类为实

现一些目标

而明确保存

和操作相关

信息片段的

系统。

这种外

显记忆组件

将使我们的

系统不仅能

够快速 ‘‘故意

’’

地存储和检

索具体的事

实，

也能利用

他们循序推

论。神经网络

处理序列信

息的需要，改

变了每个步

骤向网络注

入输入的方

式，长期以来

推理能力被

认为是重要

的，而不是对

输入做出自

动的、直

观的

反应 (Hinton,

1990) 。

为了解

决这一难题

，Weston et

al. (2014) 引入了 记忆

网络（memory

network），

其中包

括一组可以

通过寻址机

制来访问的

记忆单元。记

忆网络原本

需要监督信

号

指示他们

如何使用自

己的记忆单

元。Graves et

al. (2014) 引入的 神

经网络图灵

机

（neural Turing machine），不需要明

确的监督指

示采取哪些

行动而能学

习从记忆单

元读写任意

内容，并通过

使用基于内

容的软注意

机制（ 见Bahdanau

et al. (2015)

和第

12.4.5.1

节），允许端到

端的训练。这

种软寻址机

制已成为其

他允许基于

梯度优

化的

模拟算法机

制的相关架

构的标准 (Sukhbaatar et

al., 2015; Joulin and

Mikolov,

2015; Kumar et

al., 2015a; Vinyals et

al., 2015a; Grefenstette et

al., 2015)。

每

个记忆单元

可以被认为

是 LSTM

和 GRU 中记忆

单元的扩展

。不同的是，网

络输出一个

内部状态来

选择从哪个

单元读取或

写入，正如数

字计算机读

取或写入到

特定地址的

内存访问。

产

生确切整数

地址的函数

很难优化。为

了缓解这一

问题，NTM

实际同

时从多个

记

忆单元写入

或读取。读取

时，它们采取

许多单元的

加权平均值

。写入时，他们

对

多个单元

修改不同的

数值。用于这

些操作的系

数被选择为

集中在一个

小数目的单

元，

如通过

softmax 函

数产生它们

。使用这些具

有非零导数

的权重允许

函数控制访

问存

储器，从

而能使用梯

度下降法优

化。关于这些

系数的梯度

指示着其中

每个参数是

应

该增加还

是减少，但梯

度通常只在

接收大系数

的存储器地

址上变大。

这

些记忆单元

通常扩充为

包含向量，而

不是由 LSTM 或 GRU

存

储单元所存

储的单个标

量。增加记忆

单元大小的

原因有两个

。原因之一是

，我们已经增

加了访

问记

忆单元的成

本。我们为产

生用于许多

单元的系数

付出计算成

本，但我们预

期这

些系数

聚集在周围

小数目的单

元。通过读取

向量值，而不

是一个标量

，我们可以抵

10.12 外显记忆

357

消

部分成本。使

用向量值的

记忆单元的

另一个原因

是，它们允许

基于内容的

寻址

(content-based addressing)，其中从

一个单元读

或写的权重

是该单元的

函数。如果我

们能够生产

符合某些但

并非所有元

素的模式，向

量值单元允

许我们检索

一个完整向

量值的记忆

。这类似于人

们能够通过

几个歌词回

忆起一首歌

曲的方式。我

们可以认

为

基于内容的

读取指令是

说，‘‘检索一首

副歌歌词中

带有’ 我们都

住在黄色潜

水艇’ 的

歌’’。当

我们要检索

的对象很大

时，基于内容

的寻址更为

有用——如果歌

曲的每一个

字母被存储

在单独的记

忆单元中，我

们将无法通

过这种方式

找到他们。通

过比较，基

于

位置的寻址

(location-based addressing) 不允许引用

存储器的内

容。我们可以

认为

基于位

置的读取指

令是说

‘‘检索

347 档的歌的歌

词’’。即使当存

储单元很小

时，基于

位置

的寻址通常

也是完全合

理的机制。

如

果一个存储

单元的内容

在大多数时

间步上会被

复制（不被忘

记），则它包含

的

信息可以

在时间上向

前传播，随时

间向后传播

的梯度也不

会消失或爆

炸。

Task network,

controlling

the memory

Memory cells

Writing

mechanism

Reading

mechanism

图 10.18: 具有外

显记忆网络

的示意图，具

备神经网络

图灵机的一

些关键设计

元素。在此图

中，我

们将模

型的

“表示’’ 部

分（‘‘任务网络

’’，这里是底部

的循环网络

）与存储事实

的模型（记忆

单元的

集合

）的 ‘‘存储器’’

部

分区分开。任

务网络学习

‘‘控制’’ 存储器

，决定从哪读

取以及在哪

写入（通

过读

取和写入机

制，由指向读

取和写入地

址的粗箭头

指示）。

外显记

忆的方法在

图

10.18 说明，其中

我们可以看

到与存储器

耦接的 ‘‘任务

神

经网络’’。虽

然这一任务

神经网络可

以是前馈或

循环的，但整

个系统是一

个循环网

络

。任务网络可

以选择读取

或写入的特

定内存地址

。外显记忆似

乎允许模型

学习普

358 第十

章 序列建模

：循环和递归

网络

通 RNN 或 LSTM

RNN 不

能学习的任

务。这种优点

的一个原因

可能是因为

信息和梯

度

可以在非常

长的持续时

间内传播（分

别在时间上

向前或向后

）。

作为存储器

单元的加权

平均值反向

传播的替代

，我们可以将

存储器寻址

系数解

释为

概率，并随机

从一个单元

读取 (Zaremba and Sutskever,

2015)。优化离

散决策

的模

型需要专门

的优化算法

，这将在第20.9.1 节

中描述。目前

为止，训练这

些做离散

决

策的随机架

构，仍比训练

进行软判决

的确定性算

法更难。

无论

是软（允许反

向传播）或随

机硬性的，用

于选择一个

地址的机制

与先前

在机

器翻译的背

景下引入的

注意力机制

形式相同 (Bahdanau et

al., 2015)，这

在

第 12.4.5.1

节中也

有讨论。甚至

更早之前，注

意力机制的

想法就被引

入了神经网

络，

在手写生

成的情况下

(Graves, 2013)，有一个被约

束为通过序

列只向前移

动的注意力

机制。在机器

翻译和记忆

网络的情况

下，每个步骤

中关注的焦

点可以移动

到一个完

全

不同的地方

(相比之前的

步骤)。

循环神

经网络提供

了将深度学

习扩展到序

列数据的一

种方法。它们

是我们的深

度学习工具

箱中最后一

个主要的工

具。现在我们

的讨论将转

移到如何选

择和使用这

些工具，以及

如何在真实

世界的任务

中应用这些

工具。

第十一

章 实践方法

论

要成功地

使用深度学

习技术，仅仅

知道存在哪

些算法和解

释他们为何

有效的原

理

是不够的。一

个优秀的机

器学习实践

者还需要知

道如何针对

具体应用挑

选一个合

适

的算法以及

如何监控，并

根据实验反

馈改进机器

学习系统。在

机器学习系

统的日

常开

发中，实践者

需要决定是

否收集更多

的数据、增加

或减少模型

容量、添加或

删

除正则化

项、改进模型

的优化、改进

模型的近似

推断或调试

模型的软件

实现。尝试

这

些操作都需

要大量时间

，因此确定正

确做法，而不

盲目猜测尤

为重要的。

本

书的大部分

内容都是关

于不同的机

器学习模型

、训练算法和

目标函数。这

可

能给人一

种印象——成为

机器学习专

家的最重要

因素是了解

各种各样的

机器学习技

术，并熟悉各

种不同的数

学。在实践中

，正确使用一

个普通算法

通常比草率

地使用一

个

不清楚的算

法效果更好

。正确应用一

个算法需要

掌握一些相

当简单的方

法论。本

章的

许多建议都

来自 Ng (2015)。

我们建

议参考以下

几个实践设

计流程：

• 确定

目标——使用什

么样的误差

度量，并为此

误差度量指

定目标值。这

些目标

和误

差度量取决

于该应用旨

在解决的问

题。

•

尽快建立

一个端到端

的工作流程

，包括估计合

适的性能度

量。

• 搭建系统

，并确定性能

瓶颈。检查哪

个部分的性

能差于预期

，以及是否是

因

为过拟合

、欠拟合，或者

数据或软件

缺陷造成的

。

• 根据具体观

察反复地进

行增量式的

改动，如收集

新数据、调整

超参数或改

进算

法。

我们

将使用街景

地址号码转

录系统

(Goodfellow et al., 2014d)

作为

一个运行示

例。该应用的

目标是将建

筑物添加到

谷歌地图。街

景车拍摄建

筑物，并记录

与每张

359

360 第十

一章

实践方

法论

建筑照

片相关的 GPS 坐

标。卷积网络

识别每张照

片上的地址

号码，由谷歌

地图数据

库

在正确的位

置添加该地

址。这个商业

应用是一个

很好的示例

，它的开发流

程遵循

我们

倡导的设计

方法。

我们现

在描述这个

过程中的每

一个步骤。

11.1

性

能度量

确定

目标，即使用

什么误差度

量，是必要的

第一步，因为

误差度量将

指导接下

来

的所有工作

。同时我们也

应该了解大

概能得到什

么级别的目

标性能。

值得

注意的是对

于大多数应

用而言，不可

能实现绝对

零误差。即使

你有无限的

训练数据，并

且恢复了真

正的概率分

布，贝叶斯误

差仍定义了

能达到的最

小错误率。

这

是因为输入

特征可能无

法包含输出

变量的完整

信息，或是因

为系统可能

本质上是

随

机的。当然我

们还会受限

于有限的训

练数据。

训练

数据的数量

会因为各种

原因受到限

制。当目标是

打造现实世

界中最好的

产

品或服务

时，我们通常

需要收集更

多的数据，但

必须确定进

一步减少误

差的价值，并

与收集更多

数据的成本

做权衡。数据

收集会耗费

时间、金钱，或

带来人体痛

苦（例

如，收集

人体医疗测

试数据）。科研

中，目标通常

是在某个确

定基准下探

讨哪个算法

更好，一般会

固定训练集

，不允许收集

更多的数据

。

如何确定合

理的性能期

望？在学术界

，通常我们可

以根据先前

公布的基准

结果

来估计

预期错误率

。在现实世界

中，一个应用

的错误率有

必要是安全

的、具有成本

效益的或吸

引消费者的

。一旦你确定

了想要达到

的错误率，那

么你的设计

将由如何

达

到这个错误

率来指导。

除

了需要考虑

性能度量之

外，另一个需

要考虑的是

度量的选择

。我们有几种

不

同的性能

度量，可以用

来度量一个

含有机器学

习组件的完

整应用的有

效性。这些性

能度量通常

不同于训练

模型的代价

函数。如第 5.1.2 节

所述，我们通

常会度量一

个系

统的准

确率，或等价

地，错误率。

然

而，许多应用

需要更高级

的度量。

有时

，一种错误可

能会比另一

种错误更严

重。例如，垃圾

邮件检测系

统会有两

种

错误：将正常

邮件错误地

归为垃圾邮

件，将垃圾邮

件错误地归

为正常邮件

。阻止

正常消

息比允许可

疑消息通过

糟糕得多。我

们希望度量

某种形式的

总代价，其中

拦

11.1 性能度量

361

截正常邮件

比允许垃圾

邮件通过的

代价更高，而

不是度量垃

圾邮件分类

的错误率。

有

时，我们需要

训练检测某

些罕见事件

的二元分类

器。例如，我们

可能会为一

种罕见疾病

设计医疗测

试。假设每一

百万人中只

有一人患病

。我们只需要

让分类器

一

直报告没有

患者，就能轻

易地在检测

任务上实现

99.9999% 的正确率。显

然，正确

率很

难描述这种

系统的性能

。解决这个问

题的方法是

度量

精度（precision）和

召回

率（recall）。精度

是模型报告

的检测是正

确的比率，而

召回率则是

真实事件被

检测

到的比

率。检测器永

远报告没有

患者，会得到

一个完美的

精度，但召回

率为零。而

报

告每个人都

是患者的检

测器会得到

一个完美的

召回率，但是

精度会等于

人群中患

有

该病的比例

（在我们的例

子是 0.0001%，每一百

万人只有一

人患病）。当使

用精

度和召

回率时，我们

通常会画 PR

曲

线（PR curve），y 轴表示精

度，x 轴表示召

回率。如果检

测到的事件

发生了，那么

分类器会返

回一个较高

的得分。例如

，我们

将前馈

网络设计为

检测一种疾

病，估计一个

医疗结果由

特征 x 表示的

人患病的概

率

为

yˆ = P(y =

1 | x)。每当这

个得分超过

某个阈值时

，我们报告检

测结果。通过

调

整阈值，我

们能权衡精

度和召回率

。在很多情况

下，我们希望

用一个数而

不是曲线

来

概括分类器

的性能。要做

到这一点，我

们可以将精

度 p 和召回率

r 转换为

F 分数

（F-score）

F =

2pr

p + r

. (11.1)

另一种方法

是报告 PR

曲线

下方的总面

积。

在一些应

用中，机器学

习系统可能

会拒绝做出

判断。如果机

器学习算法

能够估

计所

作判断的置

信度，这将会

非常有用，特

别是在错误

判断会导致

严重危害，而

人工

操作员

能够偶尔接

管的情况下

。街景转录系

统可以作为

这种情况的

一个示例。这

个

任务是识

别照片上的

地址号码，将

照片拍摄地

点对应到地

图上的地址

。如果地图是

不精确的，那

么地图的价

值会严重下

降。因此只在

转录正确的

情况下添加

地址十分

重

要。如果机器

学习系统认

为它不太能

像人一样正

确地转录，那

么最好办法

当然是

让人

来转录照片

。当然，只有当

机器学习系

统能够大量

降低需要人

工操作处理

的图

片时，它

才是有用的

。在这种情况

下，一种自然

的性能度量

是

覆盖（coverage）。覆

盖

是机器学习

系统能够产

生响应的样

本所占的比

率。我们权衡

覆盖和精度

。一个系

统可

以通过拒绝

处理任意样

本的方式来

达到 100%

的精度

，但是覆盖降

到了 0%。对

于街

景任务，该项

目的目标是

达到人类级

别的转录精

度，同时保持

95% 的覆盖。在

这

项任务中，人

类级别的性

能是 98% 的精度

。

还有许多其

他的性能度

量。例如，我们

可以度量点

击率、收集用

户满意度调

查

362 第十一章

实践方法论

等等。许多专

业的应用领

域也有特定

的标准。

最重

要的是首先

要确定改进

哪个性能度

量，然后专心

提高性能度

量。如果没有

明确的目标

，那么我们很

难判断机器

学习系统上

的改动是否

有所改进。

11.2

默

认的基准模

型

确定性能

度量和目标

后，任何实际

应用的下一

步是尽快建

立一个合理

的端到端

的

系统。本节给

出了一些关

于在不同情

况下使用哪

种算法作为

第一个基准

方法推荐。

在

本节中，我们

提供了关于

不同情况下

使用哪种算

法作为第一

基准方法的

推荐。值

得注

意的是，深度

学习研究进

展迅速，所以

本书出版后

很快可能会

有更好的默

认算

法。

根据

问题的复杂

性，项目开始

时可能无需

使用深度学

习。如果只需

正确地选择

几个线性权

重就可能解

决问题，那么

项目可以开

始于一个简

单的统计模

型，如逻辑

回

归。

如果问题

属于 “AI-完全’’ 类

的，如对象识

别、语音识别

、机器翻译等

等，那么

项目

开始于一个

合适的深度

学习模型，效

果会比较好

。

首先，根据数

据的结构选

择一类合适

的模型。如果

项目是以固

定大小的向

量作

为输入

的监督学习

，那么可以使

用全连接的

前馈网络。如

果输入有已

知的拓扑结

构

（例如，输入

是图像），那么

可以使用卷

积网络。在这

些情况下，刚

开始可以使

用某

些分段

线性单元（ReLU

或

者其扩展，如

Leaky ReLU、PReLU 和 maxout）。如果输

入

或输出是一

个序列，可以

使用门控循

环网络（LSTM 或 GRU）。

具

有衰减学习

率以及动量

的

SGD 是优化算

法一个合理

的选择（流行

的衰减方

法

有，衰减到固

定最低学习

率的线性衰

减、指数衰减

，或每次发生

验证错误停

滞时

将学习

率降低

2 − 10 倍，这

些衰减方法

在不同问题

上好坏不一

）。另一个非常

合理

的选择

是 Adam 算法。批标

准化对优化

性能有着显

著的影响，特

别是对卷积

网络和

具有

sigmoid

非线性函数

的网络而言

。虽然在最初

的基准中忽

略批标准化

是合理的，

然

而当优化似

乎出现问题

时，应该立刻

使用批标准

化。

除非训练

集包含数千

万以及更多

的样本，否则

项目应该在

一开始就包

含一些

温和

的正则化。提

前终止也被

普遍采用。Dropout

也

是一个很容

易实现，且兼

容很

多模型

和训练算法

的出色正则

化项。批标准

化有时也能

降低泛化误

差，此时可以

省

略 Dropout

步骤，因

为用于标准

化变量的统

计量估计本

身就存在噪

声。

11.3 决定是否

收集更多数

据 363

如果我们

的任务和另

一个被广泛

研究的任务

相似，那么通

过复制先前

研究中已

知

性能良好的

模型和算法

，可能会得到

很好的效果

。甚至可以从

该任务中复

制一个

训练

好的模型。例

如，通常会使

用在 ImageNet

上训练

好的卷积网

络的特征来

解决其

他计

算机视觉任

务 (Girshick et

al., 2015)。

一个常见

问题是项目

开始时是否

使用无监督

学习，我们将

在第三部分

进一步探

讨

这个问题。这

个问题和特

定领域有关

。在某些领域

，比如自然语

言处理，能够

大大

受益于

无监督学习

技术，如学习

无监督词嵌

入。在其他领

域，如计算机

视觉，除非是

在半监督的

设定下（标注

样本数量很

少）(Kingma et al., 2014;

Rasmus et al., 2015)，

目前无监

督学习并没

有带来益处

。如果应用所

在环境中，无

监督学习被

认为是很重

要的，那么将

其包含在第

一个端到端

的基准中。否

则，只有在解

决无监督问

题时，才

会第

一次尝试时

使用无监督

学习。在发现

初始基准过

拟合的时候

，我们可以尝

试加

入无监

督学习。

11.3

决定

是否收集更

多数据

在建

立第一个端

到端的系统

后，就可以度

量算法性能

并决定如何

改进算法。许

多机器学习

新手都忍不

住尝试很多

不同的算法

来进行改进

。然而，收集更

多的数据

往

往比改进学

习算法要有

用得多。

怎样

判断是否要

收集更多的

数据？首先，确

定训练集上

的性能是否

可接受。如

果

模型在训练

集上的性能

就很差，学习

算法都不能

在训练集上

学习出良好

的模型，

那么

就没必要收

集更多的数

据。反之，可以

尝试增加更

多的网络层

或每层增加

更多

的隐藏

单元，以增加

模型的规模

。此外，也可以

尝试调整学

习率等超参

数的措施来

改进学习算

法。如果更大

的模型和仔

细调试的优

化算法效果

不佳，那么问

题可能源

自

训练数据的

质量。数据可

能含太多噪

声，或是可能

不包含预测

输出所需的

正确输

入。这

意味着我们

需要重新开

始，收集更干

净的数据或

是收集特征

更丰富的数

据集。

如果训

练集上的性

能是可接受

的，那么我们

开始度量测

试集上的性

能。如果测试

集上的性能

也是可以接

受的，那么就

顺利完成了

。如果测试集

上的性能比

训练集的要

差得多，那么

收集更多的

数据是最有

效的解决方

案之一。这时

主要的考虑

是收集更

多

数据的代价

和可行性，其

他方法降低

测试误差的

代价和可行

性，和增加数

据数量

能否

显著提升测

试集性能。在

拥有百万甚

至上亿用户

的大型网络

公司，收集大

型数

据集是

可行的，并且

这样做的成

本可能比其

他方法要少

很多，所以答

案几乎总是

收

364 第十一章

实践方法论

集更多的训

练数据。例如

，收集大型标

注数据集是

解决对象识

别问题的主

要因素之

一

。在其他情况

下，如医疗应

用，收集更多

的数据可能

代价很高或

者不可行。一

个可

以替代

的简单方法

是降低模型

大小或是改

进正则化（调

整超参数，如

权重衰减系

数，

或是加入

正则化策略

，如 Dropout）。如果调整

正则化超参

数后，训练集

性能和测试

集性能之间

的差距还是

不可接受，那

么收集更多

的数据是可

取的。

在决定

是否收集更

多的数据时

，也需要确定

收集多少数

据。如图

5.4 所示

，绘制

曲线显

示训练集规

模和泛化误

差之间的关

系是很有帮

助的。根据走

势延伸曲线

，可

以预测还

需要多少训

练数据来达

到一定的性

能。通常，加入

总数目一小

部分的样本

不会对泛化

误差产生显

著的影响。因

此，建议在对

数尺度上考

虑训练集的

大小，例

如在

后续的实验

中倍增样本

数目。

如果收

集更多的数

据是不可行

的，那么改进

泛化误差的

唯一方法是

改进学习算

法本身。这属

于研究领域

，并非对应用

实践者的建

议。

11.4 选择超参

数

大部分深

度学习算法

都有许多超

参数来控制

不同方面的

算法表现。有

些超参

数会

影响算法运

行的时间和

存储成本。有

些超参数会

影响学习到

的模型质量

，以及

在新输

入上推断正

确结果的能

力。

有两种选

择超参数的

基本方法：手

动选择和自

动选择。手动

选择超参数

需要了

解超

参数做了些

什么，以及机

器学习模型

如何才能取

得良好的泛

化。自动选择

超参

数算法

大大减少了

解这些想法

的需要，但它

们往往需要

更高的计算

成本。

11.4.1 手动调

整超参数

手

动设置超参

数，我们必须

了解超参数

、训练误差、泛

化误差和计

算资源（内存

和运行时间

）之间的关系

。这需要切实

了解一个学

习算法有效

容量的基础

概念，如

第五

章所描述的

。

手动搜索超

参数的目标

通常是最小

化受限于运

行时间和内

存预算的泛

化误差。

我们

不去探讨如

何确定各种

超参数对运

行时间和内

存的影响，因

为这高度依

赖于平

台。

手

动搜索超参

数的主要目

标是调整模

型的有效容

量以匹配任

务的复杂性

。有

11.4 选择超参

数

365

效容量受

限于三个因

素：模型的表

示容量、学习

算法成功最

小化训练模

型代价函数

的

能力以及

代价函数和

训练过程正

则化模型的

程度。具有更

多网络层，每

层有更多隐

藏单元的模

型具有较高

的表示能力

——能够表示更

复杂的函数

。然而，如果训

练算

法不能

找到某个合

适的函数来

最小化训练

代价，或是正

则化项（如权

重衰减）排除

了这些合适

的函数，那么

即使模型的

表达能力较

高，也不能学

习出合适的

函数。

当泛化

误差以某个

超参数为变

量，作为函数

绘制出来时

，通常会表现

为 U 形曲

线，如

图

5.3 所示。在某

个极端情况

下，超参数对

应着低容量

，并且泛化误

差由于训

练

误差较大而

很高。这便是

欠拟合的情

况。另一种极

端情况，超参

数对应着高

容量，

并且泛

化误差由于

训练误差和

测试误差之

间的差距较

大而很高。最

优的模型容

量位

于曲线

中间的某个

位置，能够达

到最低可能

的泛化误差

，由某个中等

的泛化误差

和

某个中等

的训练误差

相加构成。

对

于某些超参

数，当超参数

数值太大时

，会发生过拟

合。例如中间

层隐藏单元

的

数量，增加

数量能提高

模型的容量

，容易发生过

拟合。对于某

些超参数，当

超参数数

值

太小时，也会

发生过拟合

。例如，最小的

权重衰减系

数允许为零

，此时学习算

法具

有最大

的有效容量

，反而容易过

拟合。

并非每

个超参数都

能对应着完

整的 U

形曲线

。很多超参数

是离散的，如

中间层

单元

数目或是 maxout 单

元中线性元

件的数目，这

种情况只能

沿曲线探索

一些点。有

些

超参数是二

值的。通常这

些超参数用

来指定是否

使用学习算

法中的一些

可选部分，

如

预处理步骤

减去均值并

除以标准差

来标准化输

入特征。这些

超参数只能

探索曲线

上

的两点。其他

一些超参数

可能会有最

小值或最大

值，限制其探

索曲线的某

些部分。

例如

，权重衰减系

数最小是零

。这意味着，如

果权重衰减

系数为零时

模型欠拟合

，那

么我们将

无法通过修

改权重衰减

系数探索过

拟合区域。换

言之，有些超

参数只能减

少模型容量

。

学习率可能

是最重要的

超参数。如果

你只有时间

调整一个超

参数，那就调

整学

习率。相

比其他超参

数，它以一种

更复杂的方

式控制模型

的有效容量

——当学习率适

合优化问题

时，模型的有

效容量最高

，此时学习率

是正确的，既

不是特别大

也不是

特别

小。学习率关

于训练误差

具有

U 形曲线

，如图 11.1 所示。当

学习率过大

时，梯

度下降

可能会不经

意地增加而

非减少训练

误差。在理想

化的二次情

况下，如果学

习

率是最佳

值的两倍大

时，会发生这

种情况 (LeCun et

al., 1998b)。当学

习率太小，训

练不仅慢，还

有可能永久

停留在一个

很高的训练

误差。关于这

种效应，我们

知之甚

少（不

会发生于一

个凸损失函

数中）。

366

第十一

章 实践方法

论

10−2 10−1

100

Learning rate (logarithmic

scale)

0

1

2

3

4

5

6

7

8

图 11.1:

训练误

差和学习率

之间的典型

关系。注意当

学习率大于

最优值时误

差会有显著

的提升。此

图

针对固定的

训练时间，越

小的学习率

有时候可以

以一个正比

于学习率减

小量的因素

来减慢训练

过程。泛化误

差也会得到

类似的曲线

，由于正则项

作用在学习

率过大或过

小处比较复

杂。由于一个

糟糕的优化

从某种程度

上说可以避

免过拟合，即

使是训练误

差相同的点

也会拥有完

全不同的泛

化

误差。

调整

学习率外的

其他参数时

，需要同时监

测训练误差

和测试误差

，以判断模型

是否过拟合

或欠拟合，然

后适当调整

其容量。

如果

训练集错误

率大于目标

错误率，那么

只能增加模

型容量以改

进模型。如果

没有使用正

则化，并且确

信优化算法

正确运行，那

么有必要添

加更多的网

络层或隐

藏

单元。然而，令

人遗憾的是

，这增加了模

型的计算代

价。

如果测试

集错误率大

于目标错误

率，那么可以

采取两个方

法。测试误差

是训练

误差

和测试误差

之间差距与

训练误差的

总和。寻找最

佳的测试误

差需要权衡

这些数

值。当

训练误差较

小（因此容量

较大），测试误

差主要取决

于训练误差

和测试误差

之

间的差距

时，通常神经

网络效果最

好。此时目标

是缩小这一

差距，使训练

误差的增

长

速率不快于

差距减小的

速率。要减少

这个差距，我

们可以改变

正则化超参

数，以

减少有

效的模型容

量，如添加

Dropout 或

权重衰减策

略。通常，最佳

性能来自正

则

化得很好

的大规模模

型，比如使用

Dropout 的神经网络

。

大部分超参

数可以通过

推理其是否

增加或减少

模型容量来

设置。部分示

例如

表11.1所示

。

手动调整超

参数时，不要

忘记最终目

标：提升测试

集性能。加入

正则化只是

实

现这个目

标的一种方

法。只要训练

误差低，随时

都可以通过

收集更多的

训练数据来

Training

error

11.4 选择超参数

367

超参数

容 量

何 时

增加

原

因 注意事项

隐藏单元数

量 增加 增加

隐藏单元数

量会增加模

型的表示能

力。

几乎模型

每个操作所

需的时

间和

内存代价都

会随隐藏单

元数量的增

加而增加。

学

习率 调至最

优

不正确的

学习速率，不

管是

太高还

是太低都会

由于优化

失

败而导致低

有效容量的

模

型。

卷积核

宽度 增加 增

加卷积核宽

度会增加模

型

的参数数

量。

较宽的卷

积核导致较

窄的输

出尺

寸，除非使用

隐式零填

充

减少此影响

，否则会降低

模型容量。较

宽的卷积核

需

要更多的

内存存储参

数，并

会增加

运行时间，但

较窄的

输出

会降低内存

代价。

隐式零

填充 增加

在

卷积之前隐

式添加零能

保

持较大尺

寸的表示。

大

多数操作的

时间和内存

代

价会增加

。

权重衰减系

数 降低 降低

权重衰减系

数使得模型

参数可以自

由地变大。

Dropout

比

率 降低 较少

地丢弃单元

可以更多地

让单元彼此

‘‘协力’’ 来适应

训

练集。

表 11.1: 各

种超参数对

模型容量的

影响。

减少泛

化误差。实践

中能够确保

学习有效的

暴力方法就

是不断提高

模型容量和

训练

集的大

小，直到解决

问题。这种做

法增加了训

练和推断的

计算代价，所

以只有在拥

有足够资源

时才是可行

的。原则上，这

种做法可能

会因为优化

难度提高而

失败，但

对于

许多问题而

言，优化似乎

并没有成为

一个显著的

障碍，当然，前

提是选择了

合

适的模型

。

11.4.2 自动超参数

优化算法

理

想的学习算

法应该是只

需要输入一

个数据集，就

可以输出学

习的函数，而

不

需要手动

调整超参数

。一些流行的

学习算法，如

逻辑回归和

支持向量机

，流行的部

368 第

十一章 实践

方法论

分原

因是这类算

法只有一到

两个超参数

需要调整，它

们也能表现

出不错的性

能。有

些情况

下，所需调整

的超参数数

量较少时，神

经网络可以

表现出不错

的性能；但超

参数数量有

几十甚至更

多时，效果会

提升得更加

明显。当使用

者有一个很

好的初始

值

，例如由在相

同类型的应

用和架构上

具有经验的

人确定初始

值，或者使用

者在相

似问

题上具有几

个月甚至几

年的神经网

络超参数调

整经验，那么

手动调整超

参数能

有很

好的效果。然

而，对于很多

应用而言，这

些起点都不

可用。在这些

情况下，自动

算法可以找

到合适的超

参数。

如果我

们仔细想想

使用者搜索

学习算法合

适超参数的

方式，我们会

意识到这其

实是一种优

化：我们在试

图寻找超参

数来优化目

标函数，例如

验证误差，有

时还会

有一

些约束（如训

练时间，内存

或识别时间

的预算）。因此

，原则上有可

能开发出封

装学习算法

的 超参数优

化（hyperparameter optimization）算法，并选

择其超参数

，

从而使用者

不需要指定

学习算法的

超参数。令人

遗憾的是，超

参数优化算

法往往有

自

己的超参数

，如学习算法

的每个超参

数应该被探

索的值的范

围。然而，这些

次级超

参数

通常很容易

选择，这是说

，相同的次级

超参数能够

很多不同的

问题上具有

良好

的性能

。

11.4.3 网格搜索

当

有三个或更

少的超参数

时，常见的超

参数搜索方

法是 网格搜

索（grid

search）。

对于每个

超参数，使用

者选择一个

较小的有限

值集去探索

。然后，这些超

参数笛卡

尔

乘积得到一

组组超参数

，网格搜索使

用每组超参

数训练模型

。挑选验证集

误差最

小的

超参数作为

最好的超参

数。如图

11.2 所示

超参数值的

网络。

应该如

何选择搜索

集合的范围

呢？在超参数

是数值（有序

）的情况下，每

个列

表的最

小和最大的

元素可以基

于先前相似

实验的经验

保守地挑选

出来，以确保

最优

解非常

可能在所选

范围内。通常

，网格搜索大

约会在 对数

尺度（logarithmic scale）

下挑选

合适的值，例

如，一个学习

率的取值集

合是

{0.1, 0.01, 10−3

,

10−4

, 10−5}，或

者隐

藏单元数目

的取值集合

{50,

100, 200, 500, 1000,

2000}。

通常重复进

行网格搜索

时，效果会最

好。例如，假设

我们在集合

{−1, 0, 1}

上网

格搜索

超参数 α。如果

找到的最佳

值是 1，那么说

明我们低估

了最优值

α 所

在的范

围，应

该改变搜索

格点，例如在

集合 {1,

2, 3} 中搜索

。如果最佳值

是 0，那么我们

不

妨通过细

化搜索范围

以改进估计

，在集合 {−0.1, 0, 0.1}

上进

行网格搜索

。

网格搜索带

来的一个明

显问题是，计

算代价会随

着超参数数

量呈指数级

增长。如

11.4 选择

超参数

369

Grid Layout Random

Layout

Important parameter Important

parameter

Grid Layout Random

Layout

Important parameter Important

parameter

图 11.2: 网

格搜索和随

机搜索的比

较。为了方便

地说明，我们

只展示两个

超参数的例

子，但是我们

关注的问题

中超参数个

数通常会更

多。(左)

为了实

现网格搜索

，我们为每个

超参数提供

了一个值

的

集合。搜索算

法对每一种

在这些集合

的交叉积中

的超参数组

合进行训练

。(右) 为了实现

随机搜

索，我

们给联合超

参数赋予了

一个概率分

布。通常超参

数之间是相

互独立的。常

见的这种分

布的选

择是

均匀分布或

者是对数均

匀（从对数均

匀分布中抽

样，就是对从

均匀分布中

抽取的样本

进行指

数运

算）的。然后这

些搜索算法

从联合的超

参数空间中

采样，然后运

行每一个样

本。网格搜索

和随

机搜索

都运行了验

证集上的误

差并返回了

最优的解。这

个图说明了

通常只有一

个超参数对

结果有

着重

要的影响。在

这个例子中

，只有水平轴

上的超参数

对结果有重

要的作用。网

格搜索将大

量的计

算浪

费在了指数

量级的对结

果无影响的

超参数中，相

比之下随机

搜索几乎每

次测试都测

试了对结

果

有影响的每

个超参数的

独一无二的

值。此图经 Bergstra and

Bengio (2011) 允

许转载。

果有

m

个超参数，每

个最多取 n 个

值，那么训练

和估计所需

的试验数将

是 O(n

m)。

我们可以

并行地进行

实验，并且并

行要求十分

宽松（进行不

同搜索的机

器之间几乎

没有必要进

行通信）。令人

遗憾的是，由

于网格搜索

指数级增长

计算代价，即

使是并

行，我

们也无法提

供令人满意

的搜索规模

。

11.4.4

随机搜索

幸

运的是，有一

个替代网格

搜索的方法

，并且编程简

单，使用更方

便，能更快地

收敛到超参

数的良好取

值：随机搜索

(Bergstra and Bengio,

2012)。

随机搜索过

程如下。首先

，我们为每个

超参数定义

一个边缘分

布，例如，Bernoulli

分布

或范畴分布

（分别对应着

二元超参数

或离散超参

数），或者对数

尺度上的均

匀分 Unimportant

parameter

Unimportant parameter

Unimportant

parameter

Unimportant parameter

370

第十一

章 实践方法

论

布（对应着

正实值超参

数）。例如，

log_learning_rate

∼ u(−1, −5), (11.2)

learning_rate = 10log_learning_rate

,

(11.3)

其中

，u(a, b) 表示区间

(a, b) 上

均匀采样的

样本。类似地

，log_number_of_hidden_units

可以从

u(log(50), log(2000)) 上采

样。

与网格搜

索不同，我们

不需要离散

化超参数的

值。这允许我

们在一个更

大的集

合上

进行搜索，而

不产生额外

的计算代价

。实际上，如图

11.2 所示，当有几

个超参

数对

性能度量没

有显著影响

时，随机搜索

相比于网格

搜索指数级

地高效。Bergstra

and

Bengio (2012) 进行

了详细的研

究并发现相

比于网格搜

索，随机搜索

能够更快地

减小验证集

误差（就每个

模型运行的

试验数而言

）。

与网格搜索

一样，我们通

常会重复运

行不同版本

的随机搜索

，以基于前一

次运

行的结

果改进下一

次搜索。

随机

搜索能比网

格搜索更快

地找到良好

超参数的原

因是，没有浪

费的实验，不

像网格搜索

有时会对一

个超参数的

两个不同值

（给定其他超

参数值不变

）给出相同

结

果。在网格搜

索中，其他超

参数将在这

两次实验中

拥有相同的

值，而在随机

搜索中，

它们

通常会具有

不同的值。因

此，如果这两

个值的变化

所对应的验

证集误差没

有明

显区别

的话，网格搜

索没有必要

重复两个等

价的实验，而

随机搜索仍

然会对其他

超

参数进行

两次独立地

探索。

11.4.5 基于模

型的超参数

优化

超参数

搜索问题可

以转化为一

个优化问题

。决策变量是

超参数。优化

的代价是超

参数训练出

来的模型在

验证集上的

误差。在简化

的设定下，可

以计算验证

集上可导误

差函数关于

超参数的梯

度，然后我们

遵循这个梯

度更新 (Bengio et al.,

1999; Bengio,

2000; Maclaurin

et al., 2015)。令人

遗憾的是，在

大多数实际

设定中，这个

梯度是

不可

用的。这可能

是因为其高

额的计算代

价和存储成

本，也可能是

因为验证集

误差

在超参

数上本质上

不可导，例如

超参数是离

散值的情况

。

为了弥补梯

度的缺失，我

们可以对验

证集误差建

模，然后通过

优化该模型

来

提出新的

超参数猜想

。大部分基于

模型的超参

数搜索算法

，都是使用贝

叶斯回归模

型来估计每

个超参数的

验证集误差

期望和该期

望的不确定

性。因此，优化

涉及到探

索

（探索高度不

确定的超参

数，可能带来

显著的效果

提升，也可能

效果很差）和

11.5

调试策略 371

使

用（使用已经

确信效果不

错的超参数

——通常是先前

见过的非常

熟悉的超参

数）

之间的权

衡。关于超参

数优化的最

前沿方法还

包括

Spearmint (Snoek et al.,

2012)，

TPE (Bergstra et

al., 2011) 和 SMAC

(Hutter et al., 2011)。

目前

，我们无法明

确确定，贝叶

斯超参数优

化是否是一

个能够实现

更好深度学

习结果或是

能够事半功

倍的成熟工

具。贝叶斯超

参数优化有

时表现得像

人类专家，

能

够在有些问

题上取得很

好的效果，但

有时又会在

某些问题上

发生灾难性

的失误。

看看

它是否适用

于一个特定

的问题是值

得尝试的，但

目前该方法

还不够成熟

或可靠。

就像

所说的那样

，超参数优化

是一个重要

的研究领域

，通常主要受

深度学习所

需驱

动，但是

它不仅能贡

献于整个机

器学习领域

，还能贡献于

一般的工程

学。

大部分超

参数优化算

法比随机搜

索更复杂，并

且具有一个

共同的缺点

，在它们

能够

从实验中提

取任何信息

之前，它们需

要运行完整

的训练实验

。相比于人类

实践

者手动

搜索，考虑实

验早期可以

收集的信息

量，这种方法

是相当低效

的，因为手动

搜索通常可

以很早判断

出某组超参

数是否是完

全病态的。Swersky

et al. (2014) 提

出

了一个可

以维护多个

实验的早期

版本算法。在

不同的时间

点，超参数优

化算法可以

选择开启一

个新实验，‘‘冻

结’’ 正在运行

但希望不大

的实验，或是

‘‘解冻’’ 并恢复

早

期被冻结

的，但现在根

据更多信息

后又有希望

的实验。

11.5 调试

策略

当一个

机器学习系

统效果不好

时，通常很难

判断效果不

好的原因是

算法本身，

还

是算法实现

错误。由于各

种原因，机器

学习系统很

难调试。

在大

多数情况下

，我们不能提

前知道算法

的行为。事实

上，使用机器

学习的整

个

出发点是，它

会发现一些

我们自己无

法发现的有

用行为。如果

我们在一个

新的分

类任

务上训练一

个神经网络

，它达到 5%

的测

试误差，我们

没法直接知

道这是期望

的结果，还是

次优的结果

。

另一个难点

是，大部分机

器学习模型

有多个自适

应的部分。如

果一个部分

失效

了，其他

部分仍然可

以自适应，并

获得大致可

接受的性能

。例如，假设我

们正在训

练

多层神经网

络，其中参数

为权重

W 和偏

置 b。进一步假

设，我们单独

手动实现了

每个参数的

梯度下降规

则。而我们在

偏置更新时

犯了一个错

误：

b

← b − α,

(11.4)

372 第十一章

实践方法论

其中 α

是学习

率。这个错误

更新没有使

用梯度。它会

导致偏置在

整个学习中

不断变

为负

值，对于一个

学习算法来

说这显然是

错误的。然而

只是检查模

型输出的话

，该错

误可能

并不是显而

易见的。根据

输入的分布

，权重可能可

以自适应地

补偿负的偏

置。

大部分神

经网络的调

试策略都是

解决这两个

难题的一个

或两个。我们

可以设计

一

种足够简单

的情况，能够

提前得到正

确结果，判断

模型预测是

否与之相符

；我们

也可以

设计一个测

试，独立检查

神经网络实

现的各个部

分。

一些重要

的调试检测

如下所列。

可

视化计算中

模型的行为

：当训练模型

检测图像中

的对象时，查

看一些模型

检

测到部分

重叠的图像

。在训练语音

生成模型时

，试听一些生

成的语音样

本。这似乎

是

显而易见的

，但在实际中

很容易只注

意量化性能

度量，如准确

率或对数似

然。直

接观察

机器学习模

型运行其任

务，有助于确

定其达到的

量化性能数

据是否看上

去合

理。错误

评估模型性

能可能是最

具破坏性的

错误之一，因

为它们会使

你在系统出

问

题时误以

为系统运行

良好。

可视化

最严重的错

误：大多数模

型能够输出

运行任务时

的某种置信

度量。例如，

基

于 softmax

函数 输出

层的分类器

给每个类分

配一个概率

。因此，分配给

最有可能

的

类的概率给

出了模型在

其分类决定

上的置信估

计值。通常，相

比于正确预

测的概

率最

大似然训练

会略有高估

。但是由于实

际上模型的

较小概率不

太可能对应

着正确

的标

签，因此它们

在一定意义

上还是有些

用的。通过查

看训练集中

很难正确建

模的

样本，通

常可以发现

该数据预处

理或者标记

方式的问题

。例如，街景转

录系统原本

有

个问题是

，地址号码检

测系统会将

图像裁剪得

过于紧密，而

省略掉了一

些数字。然

后

转录网络会

给这些图像

的正确答案

分配非常低

的概率。将图

像排序，确定

置信度

最高

的错误，显示

系统的裁剪

有问题。修改

检测系统裁

剪更宽的图

像，从而使整

个

系统获得

更好的性能

，但是转录网

络需要能够

处理地址号

码中位置和

范围更大变

化

的情况。

根

据训练和测

试误差检测

软件：我们往

往很难确定

底层软件是

否是正确实

现。

训练和测

试误差能够

提供一些线

索。如果训练

误差较低，但

是测试误差

较高，那么很

有可能训练

过程是在正

常运行，但模

型由于算法

原因过拟合

了。另一种可

能是，测

试误

差没有被正

确地度量，可

能是由于训

练后保存模

型再重载去

度量测试集

时出现

问题

，或者是因为

测试数据和

训练数据预

处理的方式

不同。如果训

练和测试误

差都

很高，那

么很难确定

是软件错误

，还是由于算

法原因模型

欠拟合。这种

情况需要进

一步的测试

，如下面所述

。

11.5 调试策略 373

拟

合极小的数

据集：当训练

集上有很大

的误差时，我

们需要确定

问题是真正

的欠

拟合，还

是软件错误

。通常，即使是

小模型也可

以保证很好

地拟合一个

足够小的数

据集。例如，只

有一个样本

的分类数据

可以通过正

确设置输出

层的偏置来

拟合。通

常，如

果不能训练

一个分类器

来正确标注

一个单独的

样本，或不能

训练一个自

编码

器来成

功地精准再

现一个单独

的样本，或不

能训练一个

生成模型来

一致地生成

一个

单独的

样本，那么很

有可能是由

于软件错误

阻止训练集

上的成功优

化。此测试可

以

扩展到只

有少量样本

的小数据集

上。

比较反向

传播导数和

数值导数：如

果读者正在

使用一个需

要实现梯度

计算的软

件

框架，或者在

添加一个新

操作到求导

库中，必须定

义它的 bprop

方法

，那么常见

的

错误原因是

没能正确地

实现梯度表

达。验证这些

求导正确性

的一种方法

是比较实

现

的自动求导

和通过 有限

差分（finite

difference）计算的

导数。因为

f

′

(x)

= limϵ→0

f(x +

ϵ) − f(x)

ϵ

, (11.5)

我

们可以使用

小的、有限的

ϵ 近似导数：

f

′

(x) ≈

f(x + ϵ) −

f(x)

ϵ

. (11.6)

我

们可以使用

中心差分（centered difference）提

高近似的准

确率：

f

′

(x) ≈

f(x +

1

2

ϵ) −

f(x −

1

2

ϵ)

ϵ

. (11.7)

扰动大

小 ϵ 必须足够

大，以确保该

扰动不会由

于数值计算

的有限精度

问题产生舍

入

误差。

通常

，我们会测试

向量值函数

g : R

m

→ R

n 的梯度或

Jacobian 矩

阵。令人遗憾

的是，有限差

分只允许我

们每次计算

一个导数。我

们可以使用

有限差分 mn 次

评估

g 的所有

偏导数，也可

以将该测试

应用于一个

新函数（在函

数 g 的输入输

出都加上

随

机投影）。例如

，我们可以将

导数实现的

测试用于函

数 f(x) = u

T

g(vx)，其中 u 和

v 是

随机向量。正

确计算 f

′

(x) 要求

能够正确地

通过 g 反向传

播，但是使用

有限差

分能

够高效地计

算，因为 f 只有

一个输入和

一个输出。通

常，一个好的

方法是在多

个 u

值和 v 值上

重复这个测

试，可以减少

测试忽略了

垂直于随机

投影的错误

的几率。

如果

我们可以在

复数上进行

数值计算，那

么使用复数

作为函数的

输入会有非

常

高效的数

值方法估算

梯度 (Squire and Trapp,

1998)。该方法

基于如下观

察

f(x + iϵ)

= f(x) + iϵf′

(x) + O(ϵ

2

), (11.8)

real(f(x +

iϵ)) = f(x) +

O(ϵ

2

), image(

f(x + iϵ)

ϵ

) = f

′

(x) + O(ϵ

2

), (11.9)

374 第十一章

实践方法论

其中

i =

√

−1。和上面

的实值情况

不同，这里不

存在消除影

响，因为我们

对

f 在不

同点

上计算差分

。因此我们可

以使用很小

的 ϵ，比如

ϵ = 10−150，其中

误差 O(ϵ

2

) 对

所有

实用目标都

是微不足道

的。

监控激活

函数值和梯

度的直方图

：可视化神经

网络在大量

训练迭代后

（也许是

一个

轮）收集到的

激活函数值

和梯度的统

计量往往是

有用的。隐藏

单元的预激

活值

可以告

诉我们该单

元是否饱和

，或者它们饱

和的频率如

何。例如，对于

整流器，它

们

多久关一次

？是否有单元

一直关闭？对

于双曲正切

单元而言，预

激活绝对值

的平

均值可

以告诉我们

该单元的饱

和程度。在深

度网络中，传

播梯度的快

速增长或快

速

消失，可能

会阻碍优化

过程。最后，比

较参数梯度

和参数的量

级也是有帮

助的。正

如 (Bottou,

2015) 所

建议的，我们

希望参数在

一个小批量

更新中变化

的幅度是参

数

量值 1%

这样

的级别，而不

是 50% 或者 0.001%（这会

导致参数移

动得太慢）。也

有

可能是某

些参数以良

好的步长移

动，而另一些

停滞。如果数

据是稀疏的

（比如自然

语

言），有些参数

可能很少更

新，检测它们

变化时应该

记住这一点

。

最后，许多深

度学习算法

为每一步产

生的结果提

供了某种保

证。例如，在第

三

部分，我们

将看到一些

使用代数解

决优化问题

的近似推断

算法。通常，这

些可以通

过

测试它们的

每个保证来

调试。某些优

化算法提供

的保证包括

，目标函数值

在算法

的迭

代步中不会

增加，某些变

量的导数在

算法的每一

步中都是零

，所有变量的

梯度

在收敛

时会变为零

。通常，由于舍

入误差，这些

条件不会在

数字计算机

上完全成立

，

因此调试测

试应该包含

一些容差参

数。

11.6 示例：多位

数字识别

为

了端到端的

说明如何在

实践中应用

我们的设计

方法论，我们

从设计深度

学

习组件出

发，简单地介

绍下街景转

录系统。显然

，整个系统的

许多其他组

件，如街景

车

、数据库设施

等等，也是极

其重要的。

从

机器学习任

务的视角出

发，首先这个

过程要采集

数据。街景车

收集原始数

据，

然后操作

员手动提供

标签。转录任

务开始前有

大量的数据

处理工作，包

括在转录前

使用其他机

器学习技术

探测房屋号

码。

转录项目

开始于性能

度量的选择

和对这些度

量的期望值

。一个重要的

总原则是

度

量的选择要

符合项目的

业务目标。因

为地图只有

是高准确率

时才有用，所

以为这

个项

目设置高准

确率的要求

非常重要。具

体地，目标是

达到人类水

平，98% 的准确

11.6

示

例：多位数字

识别 375

率。这种

程度的准确

率并不是总

能达到。为了

达到这个级

别的准确率

，街景转录系

统牺牲了覆

盖。因此在保

持准确率 98%

的

情况下，覆盖

成了这个项

目优化的主

要性

能度量

。随着卷积网

络的改进，我

们能够降低

网络拒绝转

录输入的置

信度阈值，最

终超出了覆

盖 95% 的目标。

在

选择量化目

标后，我们推

荐方法的下

一步是要快

速建立一个

合理的基准

系统。

对于视

觉任务而言

，基准系统是

带有整流线

性单元的卷

积网络。转录

项目开始于

一个

这样的

模型。当时，使

用卷积网络

输出预测序

列并不常见

。开始时，我们

使用一个尽

可能简单的

基准模型，该

模型输出层

的第一个实

现包含 n

个不

同的 softmax 单元来

预测 n

个字符

的序列。我们

使用与训练

分类任务相

同的方式来

训练这些 softmax 单

元，独立地训

练每个 softmax

单元

。

我们建议反

复细化这些

基准，并测试

每个变化是

否都有改进

。街景转录系

统的

第一个

变化受激励

于覆盖指标

的理论理解

和数据结构

。具体地，当输

出序列的概

率

低于某个

值

t 即 p(y |

x) < t 时，网络

拒绝为输入

x

分类。最初，p(y | x) 的

定义是

临时

的，简单地将

所有 softmax 函数输

出乘在一起

。这促使我们

发展能够真

正计算

出合

理对数似然

的特定输出

层和代价函

数。这种方法

使得样本拒

绝机制更有

效。

此时，覆盖

仍低于 90%，但该

方法没有明

显的理论问

题了。因此，我

们的方法论

建议综合训

练集和测试

集性能，以确

定问题是否

是欠拟合或

过拟合。在这

种情况下，

训

练和测试集

误差几乎是

一样的。事实

上，这个项目

进行得如此

顺利的主要

原因是

有数

以千万计的

标注样本数

据集可用。因

为训练和测

试集的误差

是如此相似

，这表

明要么

是这个问题

欠拟合，要么

是训练数据

的问题。我们

推荐的调试

策略之一是

可

视化模型

最糟糕的错

误。在这种情

况下，这意味

着可视化不

正确而模型

给了最高置

信度的训练

集转录结果

。结果显示，主

要是输入图

像裁剪得太

紧，有些和地

址相关的

数

字被裁剪操

作除去了。例

如，地址 “1849’’

的图

片可能裁切

得太紧，只剩

下 “849’’

是可见的

。如果我们花

费几周时间

改进确定裁

剪区域的地

址号码检测

系统的准确

率，

或许也可

以解决这个

问题。与之不

同，项目团队

采取了更实

际的办法，简

单地系统

性

扩大裁剪区

域的宽度，使

其大于地址

号码检测系

统预测的区

域宽度。这种

单一改

变将

转录系统的

覆盖提高了

10 个百分点。

最

后，性能提升

的最后几个

百分点来自

调整超参数

。这主要包括

在保持一些

计

算代价限

制的同时加

大模型的规

模。因为训练

误差和测试

误差保持几

乎相等，所以

明确表明性

能不足是由

欠拟合造成

的，数据集本

身也存在一

些问题。

总体

来说，转录项

目是非常成

功的，可以比

人工速度更

快、代价更低

地转录数

376 第

十一章

实践

方法论

以亿

计的地址。

我

们希望本章

中介绍的设

计原则能带

来其他更多

类似的成功

。

第十二章

应

用

在本章中

，我们将介绍

如何使用深

度学习来解

决计算机视

觉、语音识别

、自然

语言处

理以及其他

商业领域中

的应用。首先

我们将讨论

在许多最重

要的 AI

应用中

所

需的大规

模神经网络

的实现。接着

，我们将回顾

深度学习已

经成功应用

的几个特定

领域。尽管深

度学习的一

个目标是设

计能够处理

各种任务的

算法，然而截

止目前深

度

学习的应用

仍然需要一

定程度的特

化。例如，计算

机视觉中的

任务对每一

个样本

都需

要处理大量

的输入特征

（像素）。自然语

言处理任务

的每一个输

入特征都需

要对

大量的

可能值（词汇

表中的词）建

模。

12.1 大规模深

度学习

深度

学习的基本

思想基于联

结主义：尽管

机器学习模

型中单个生

物性的神经

元

或者说是

单个特征不

是智能的，但

是大量的神

经元或者特

征作用在一

起往往能够

表

现出智能

。我们必须着

重强调神经

元数量必须

很大这个事

实。相比 20 世纪

80

年代，

如今神

经网络的精

度以及处理

任务的复杂

度都有一定

提升，其中一

个关键的因

素就

是网络

规模的巨大

提升。正如我

们在第 1.2.3

节中

看到的一样

，在过去的三

十年内，

网络

规模是以指

数级的速度

递增的。然而

如今的人工

神经网络的

规模也仅仅

和昆虫

的神

经系统差不

多。

由于规模

的大小对于

神经网络来

说至关重要

，因此深度学

习需要高性

能的硬件

设

施和软件实

现。

377

378 第十二章

应用

12.1.1 快速的

CPU 实现

传统的

神经网络是

用单台机器

的

CPU 来训练的

。如今，这种做

法通常被视

为是

不可取

的。现在，我们

通常使用 GPU

或

者许多台机

器的 CPU 连接在

一起进行计

算。在使用这

种昂贵配置

之前，为论证

CPU 无法承担神

经网络所需

的巨大计算

量，

研究者们

付出了巨大

的努力。

描述

如何实现高

效的数值 CPU 代

码已经超出

了本书的讨

论范围，但是

我们在

这里

还是要强调

通过设计一

些特定的 CPU 上

的操作可以

大大提升效

率。例如，在

2011

年

，最好的 CPU 在训

练神经网络

时使用定点

运算能够比

浮点运算跑

得更快。

通过

调整定点运

算的实现方

式，Vanhoucke

et al. (2011) 获得了

3 倍

于一个强浮

点

运算系统

的速度。因为

各个新型 CPU

都

有各自不同

的特性，所以

有时候采用

浮点

运算实

现会更快。一

条重要的准

则就是，通过

特殊设计的

数值运算，我

们可以获得

巨大的回报

。除了选择定

点运算或者

浮点运算以

外，其他的策

略还包括了

如通过优

化

数据结构避

免高速缓存

缺失、使用向

量指令等。如

果模型规模

不会限制模

型表现

（不会

影响模型精

度）时，机器学

习的研究者

们一般忽略

这些实现的

细节。

12.1.2 GPU 实现

许

多现代神经

网络的实现

基于

图形处

理器（Graphics Processing Unit, GPU）。

图形处

理器（GPU）最初是

为图形应用

而开发的专

用硬件组件

。视频游戏系

统的

消费市

场刺激了图

形处理硬件

的发展。它为

视频游戏所

设计的特性

也可以使神

经网

络的计

算受益。

视频

游戏的渲染

要求许多操

作能够快速

并行地执行

。环境和角色

模型通过一

系

列顶点的

3D 坐标确定。为

了将大量的

3D 坐标转化为

2D 显示器上的

坐标，显卡必

须并行地对

许多顶点执

行矩阵乘法

与除法。之后

，显卡必须并

行地在每个

像素上执

行

诸多计算，来

确定每个像

素点的颜色

。在这两种情

况下，计算都

是非常简单

的，并

且不涉

及 CPU 通常遇到

的复杂的分

支运算。例如

，同一个刚体

内的每个顶

点都会乘

上

相同的矩阵

；也就是说，不

需要通过 if 语

句来判断确

定每个顶点

需要乘哪个

矩

阵。各个计

算过程之间

也是完全相

互独立的，因

此能够实现

并行操作。计

算过程还

涉

及处理大量

内存缓冲以

及描述每一

个需要被渲

染的对象的

纹理（颜色模

式）的位

图信

息。总的来说

，这使显卡设

计为拥有高

度并行特性

以及很高的

内存带宽，同

时

也付出了

一些代价，如

相比传统的

CPU 更慢的时钟

速度以及更

弱的处理分

支运算

12.1 大规

模深度学习

379

的能力。

与上

述的实时图

形算法相比

，神经网络算

法所需要的

性能特性是

相同的。神经

网络算法通

常涉及大量

参数、激活值

、梯度值的缓

冲区，其中每

个值在每一

次训练迭

代

中都要被完

全更新。这些

缓冲太大，会

超出传统的

桌面计算机

的高速缓存

(cache)，

所以内存带

宽通常会成

为主要瓶颈

。相比 CPU，GPU 一个显

著的优势是

其极高的内

存带宽。神经

网络的训练

算法通常并

不涉及大量

的分支运算

与复杂的控

制指令，所

以

更适合在 GPU 硬

件上训练。由

于神经网络

能够被分为

多个单独的

‘‘神经元’’，并

且

独立于同一

层内其他神

经元进行处

理，所以神经

网络可以从

GPU

的并行特性

中

受益匪浅

。

GPU 硬件最初专

为图形任务

而设计。随着

时间的推移

，GPU

也变得更灵

活，

允许定制

的子程序处

理转化顶点

坐标或者计

算像素颜色

的任务。原则

上，GPU 不

要求这

些像素值实

际基于渲染

任务。只要将

计算的输出

值作为像素

值写入缓冲

区，

GPU 就可以用

于科学计算

。Steinkrau et al.

(2005) 在 GPU 上实现了

一个两层

全

连接的神经

网络，并获得

了相对基于

CPU 的基准方法

三倍的加速

。不久以后，

Chellapilla et

al. (2006) 也

论证了相同

的技术可以

用来加速监

督卷积网络

的训练。

在通

用

GPU 发布以后

，使用显卡训

练神经网络

的热度开始

爆炸性地增

长。这

种通用

GPU 可以执行任

意的代码，而

并非仅仅渲

染子程序。NVIDIA

的

CUDA

编程语言使

得我们可以

用一种像 C 一

样的语言实

现任意代码

。由于相对简

便的编

程模

型，强大的并

行能力以及

巨大的内存

带宽，通用 GPU 为

我们提供了

训练神经

网

络的理想平

台。在它发布

以后不久，这

个平台就迅

速被深度学

习的研究者

们所采

纳 (Raina et al.,

2009b; Ciresan et al.,

2010)。

如

何在通用 GPU 上

写高效的代

码依然是一

个难题。在

GPU 上

获得良好表

现

所需的技

术与 CPU

上的技

术非常不同

。比如说，基于

CPU 的良好代码

通常被设

计

为尽可能从

高速缓存中

读取更多的

信息。然而在

GPU 中，大多数可

写内存位置

并不会被高

速缓存，所以

计算某个值

两次往往会

比计算一次

然后从内存

中读取更

快

。GPU 代码是天生

多线程的，不

同线程之间

必须仔细协

调好。例如，如

果能够把

数

据 级联（coalesced）起来

，那么涉及内

存的操作一

般会更快。当

几个线程同

时需

要读/写

一个值时，像

这样的级联

会作为一次

内存操作出

现。不同的 GPU 可

能采用

不同

的级联读/写

数据的方式

。通常来说，如

果在

n 个线程

中，线程 i 访问

的是第

i + j 处的

内存，其中

j 是

2 的某个幂的

倍数，那么内

存操作就易

于级联。具体

的设

定在不

同的

GPU 型号中

有所区别。GPU 另

一个常见的

设定是使一

个组中的所

有线

程都同

时执行同一

指令。这意味

着

GPU 难以执行

分支操作。线

程被分为一

个个称

380 第十

二章

应用

作

warp 的小组。在一

个 warp

中的每一

个线程在每

一个循环中

执行同一指

令，所以

当同

一个 warp 中的不

同线程需要

执行不同的

指令时，需要

使用串行而

非并行的方

式。

由于实现

高效 GPU 代码的

困难性，研究

人员应该组

织好他们的

工作流程，避

免

对每一个

新的模型或

算法都编写

新的

GPU 代码。通

常来讲，人们

会选择建立

一个包

含高

效操作（如卷

积和矩阵乘

法）的软件库

解决这个问

题，然后再从

库中调用所

需

要的操作

确定模型。例

如，机器学习

库

Pylearn2 (Goodfellow et al.,

2013e) 将其所

有

的机器学习

算法都通过

调用 Theano

(Bergstra et al., 2010c;

Bastien et al., 2012a)

和 cuda-convnet (Krizhevsky, 2010)

所提

供的高性能

操作来指定

。这种分解方

法还

可以简

化对多种硬

件的支持。例

如，同一个 Theano 程

序可以在

CPU 或

者 GPU 上

运行，而

不需要改变

调用 Theano 的方式

。其他库如 Tensorflow

(Abadi et al., 2015)

和

Torch (Collobert et al.,

2011b) 也提供了类

似的功能。

12.1.3 大

规模的分布

式实现

在许

多情况下，单

个机器的计

算资源是有

限的。因此，我

们希望把训

练或者推

断

的任务分摊

到多个机器

上进行。

分布

式的推断是

容易实现的

，因为每一个

输入的样本

都可以在单

独的机器上

运

行。这也被

称为

数据并

行（data parallelism）。

同样地，模

型并行（model parallelism）也是

可行的，其中

多个机器共

同运行一

个

数据点，每一

个机器负责

模型的一个

部分。对于推

断和训练，这

都是可行的

。

在训练过程

中，数据并行

某种程度上

来说更加困

难。对于随机

梯度下降的

单步

来说，我

们可以增加

小批量的大

小，但是从优

化性能的角

度来说，我们

得到的回报

通

常并不会

线性增长。使

用多个机器

并行地计算

多个梯度下

降步骤是一

个更好的选

择。

不幸的是

，梯度下降的

标准定义完

全是一个串

行的过程：第

t 步的梯度是

第 t −

1 步

所得参

数的函数。

这

个问题可以

使用

异步随

机梯度下降

（Asynchoronous Stochastic Gradient

Descent）(Bengio

et al., 2001b; Recht

et al., 2011) 解决。在这个

方法中，几个

处理

器的核

共用存有参

数的内存。每

一个核在无

锁情况下读

取这些参数

并计算对应

的梯

度，然后

在无锁状态

下更新这些

参数。由于一

些核把其他

的核所更新

的参数覆盖

了，

因此这种

方法减少了

每一步梯度

下降所获得

的平均提升

。但因为更新

步数的速率

增

12.1

大规模深

度学习 381

加，总

体上还是加

快了学习过

程。Dean et

al. (2012) 率先提出

了多机器无

锁的梯度

下

降方法，其中

参数是由

参

数服务器（parameter server）管

理而非存储

在共用的内

存中。分布式

的异步梯度

下降方法保

留了训练深

度神经网络

的基本策略

，并被工业

界

很多机器学

习组所使用

(Chilimbi et

al., 2014; Wu et

al., 2015)。学术界的深

度学

习研究

者们通常无

法负担那么

大规模的分

布式学习系

统，但是一些

研究仍关注

于如

何在校

园环境中使

用相对廉价

的硬件系统

构造分布式

网络

(Coates et al., 2013)。

12.1.4 模型压

缩

在许多商

业应用的机

器学习模型

中，一个时间

和内存开销

较小的推断

算法比一

个

时间和内存

开销较小的

训练算法要

更为重要。对

于那些不需

要个性化设

计的应用

来

说，我们只需

要一次性的

训练模型，然

后它就可以

被成千上万

的用户使用

。在许

多情况

下，相比开发

者，终端用户

的可用资源

往往更有限

。例如，开发者

们可以使

用

巨大的计算

机集群训练

一个语音识

别的网络，然

后将其部署

到移动手机

上。

减少推断

所需开销的

一个关键策

略是

模型压

缩（model compression） (Buciluˇa

et

al., 2006)。模型压缩

的基本思想

是用一个更

小的模型取

代原始耗时

的模型，从而

使得用来存

储与评估所

需的内存与

运行时间更

少。

当原始模

型的规模很

大，且我们需

要防止过拟

合时，模型压

缩就可以起

到作用。

在许

多情况下，拥

有最小泛化

误差的模型

往往是多个

独立训练而

成的模型的

集成。

评估所

有 n 个集成成

员的成本很

高。有时候，当

单个模型很

大（例如，如果

它使

用

Dropout 正则

化）时，其泛化

能力也会很

好。

这些巨大

的模型能够

学习到某个

函数 f(x)，但选用

的参数数量

超过了任务

所需

的参数

数量。只是因

为训练样本

数是有限的

，所以模型的

规模才变得

必要。只要我

们拟合了这

个函数 f(x)，我们

就可以通过

将 f 作用于随

机采样点

x 来

生成有无穷

多

训练样本

的训练集。然

后，我们使用

这些样本训

练一个新的

更小的模型

，使其能够

在

这些点上拟

合

f(x)。为了更加

充分地利用

了这个新的

小模型的容

量，最好从类

似

于真实测

试数据（之后

将提供给模

型）的分布中

采样 x。这个过

程可以通过

损坏训

练样

本或者从原

始训练数据

训练的生成

模型中采样

完成。

此外，我

们还可以仅

在原始训练

数据上训练

一个更小的

模型，但只是

为了复制

模

型的其他特

征，比如在不

正确的类上

的后验分布

(Hinton et al.,

2014, 2015)。

382 第十二章

应

用

12.1.5 动态结构

一般来说，加

速数据处理

系统的一种

策略是构造

一个系统，这

个系统用 动

态

结构（dynamic structure）描述

图中处理输

入的所需计

算过程。在给

定一个输入

的

情况中，数

据处理系统

可以动态地

决定运行神

经网络系统

的哪一部分

。单个神经网

络内部同样

也存在动态

结构，给定输

入信息，决定

特征（隐藏单

元）哪一部分

用于

计算。这

种神经网络

中的动态结

构有时被称

为

条件计算

（conditional computation）

(Bengio, 2013;

Bengio et al., 2013b)。由于模型结

构许多部分

可能只跟输

入的一小部

分有关，只计

算那些需要

的特征可以

起到加速的

目的。

动态结

构计算是一

种基础的计

算机科学方

法，广泛应用

于软件工程

项目。应用

于

神经网络的

最简单的动

态结构基于

决定神经网

络（或者其他

机器学习模

型）中的

哪些

子集需要应

用于特定的

输入。

在分类

器中加速推

断的可行策

略是使用

级

联（cascade）的分类器

。当目标是检

测罕见对象

（或事件）是否

存在时，可以

应用级联策

略。要确定对

象是否存在

，我们

必须使

用具有高容

量、运行成本

高的复杂分

类器。然而，因

为对象是罕

见的，我们通

常可以使用

更少的计算

拒绝不包含

对象的输入

。在这些情况

下，我们可以

训练一序

列

分类器。序列

中的第一个

分类器具有

低容量，训练

为具有高召

回率。换句话

说，他

们被训

练为确保对

象存在时，我

们不会错误

地拒绝输入

。最后一个分

类器被训练

为

具有高精

度。在测试时

，我们按照顺

序运行分类

器进行推断

，一旦级联中

的任何一

个

拒绝它，就选

择抛弃。总的

来说，这允许

我们使用高

容量模型以

较高的置信

度验

证对象

的存在，而不

是强制我们

为每个样本

付出完全推

断的成本。有

两种不同的

方

式可以使

得级联实现

高容量。一种

方法是使级

联中靠后的

成员单独具

有高容量。在

这种情况下

，由于系统中

的一些个体

成员具有高

容量，因此系

统作为一个

整体显然

也

具有高容量

。还可以使用

另一种级联

，其中每个单

独的模型具

有低容量，但

是由

于许多

小型模型的

组合，整个系

统具有高容

量。Viola and Jones

(2001) 使用级联

的

增强决策

树实现了适

合在手持数

字相机中使

用的快速并

且鲁棒的面

部检测器。本

质

上，它们的

分类器使用

滑动窗口方

法来定位面

部。分类器会

检查许多的

窗口，如果

这

些窗口内不

包含面部则

被拒绝。级联

的另一个版

本使用早期

模型来实现

一种硬注

意

力机制：级联

的先遣成员

定位对象，并

且级联的后

续成员在给

定对象位置

的情况

下执

行进一步处

理。例如，Google 使用

两步级联从

街景视图图

像中转换地

址编号：

首先

使用一个机

器学习模型

查找地址编

号，然后使用

另一个机器

学习模型将

其转录

(Goodfellow et al.,

2014d)。

12.1 大规

模深度学习

383

决策树本身

是动态结构

的一个例子

，因为树中的

每个节点决

定应该使用

哪个子

树来

评估输入。一

个结合深度

学习和动态

结构的简单

方法是训练

一个决策树

，其中

每个节

点使用神经

网络做出决

策 (Guo and

Gelfand, 1992)，虽然这种

方法没有实

现

加速推断

计算的目标

。

类似的，我们

可以使用称

为

选通器（gater）的

神经网络来

选择在给定

当前输入

的

情况下将使

用几个 专家

网络（expert network）中的哪

一个来计算

输出。这个想

法

的第一个

版本被称为

专家混合体

（mixture of experts）(Nowlan, 1990;

Jacobs et al.,

1991)，其中选通器

为每个专家

输出一个概

率或权重（通

过非线性的

softmax

函数获

得），并

且最终输出

由各个专家

输出的加权

组合获得。在

这种情况下

，使用选通器

不

会降低计

算成本，但如

果每个样本

的选通器选

择单个专家

，我们就会获

得一个特殊

的 硬专家混

合体（hard

mixture of experts） (Collobert

et al., 2001, 2002)，这可以

加速推断和

训练。当选通

器决策的数

量很小时，这

个策略效果

会很好，因为

它不是

组合

的。但是当我

们想要选择

不同的单元

或参数子集

时，不可能使

用 ‘‘软开关’’，因

为它需要枚

举（和计算输

出）所有的选

通器配置。为

了解决这个

问题，许多工

作探

索了几

种方法来训

练组合的选

通器。Bengio et

al. (2013b) 提出使

用选通器概

率梯度

的若

干估计器，而

Bacon

et al. (2015); Bengio

et al. (2015a) 使用强化学

习技术（

策

略

梯度（policy gradient））来学习

一种条件的

Dropout 形式（作用于

隐藏单元块

），

减少了实际

的计算成本

，而不会对近

似的质量产

生负面影响

。

另一种动态

结构是开关

，其中隐藏单

元可以根据

具体情况从

不同单元接

收输

入。这种

动态路由方

法可以理解

为 注意力机

制（attention

mechanism）(Olshausen

et al., 1993)。目前为止

，硬性开关的

使用在大规

模应用中还

没有被证明

是有效的。

较

为先进的方

法一般采用

对许多可能

的输入使用

加权平均，因

此不能完全

得到动态

结

构所带来的

计算益处。先

进的注意力

机制将在第

12.4.5.1 节中描述。

使

用动态结构

化系统的主

要障碍是由

于系统针对

不同输入的

不同代码分

支导致

的并

行度降低。这

意味着网络

中只有很少

的操作可以

被描述为对

样本小批量

的矩阵

乘法

或批量卷积

。我们可以写

更多的专用

子程序，用不

同的核对样

本做卷积，或

者

通过不同

的权重列来

乘以设计矩

阵的每一行

。不幸的是，这

些专用的子

程序难以高

效地实现。由

于缺乏高速

缓存的一致

性，CPU 实现会十

分缓慢。此外

，由于缺乏级

联的内存操

作以及

warp 成员

使用不同分

支时需要串

行化操作，GPU 的

实现也会很

慢。在一些情

况下，我们可

以通过将样

本分成组，并

且都采用相

同的分支并

且同时

处理

这些样本组

的方式来缓

解这些问题

。在离线环境

中，这是最小

化处理固定

量样

本所需

时间的一项

可接受的策

略。然而在实

时系统中，样

本必须连续

处理，对工作

384 第十二章 应

用

负载进行

分区可能会

导致负载均

衡问题。例如

，如果我们分

配一台机器

处理级联中

的第一步，另

一台机器处

理级联中的

最后一步，那

么第一台机

器将倾向于

过载，最

后一

个机器倾向

于欠载。如果

每个机器被

分配以实现

神经决策树

的不同节点

，也会

出现类

似的问题。

12.1.6 深

度网络的专

用硬件实现

自从早期的

神经网络研

究以来，硬件

设计者已经

致力于可以

加速神经网

络算法

的训

练和/或推断

的专用硬件

实现。读者可

以查看早期

和更近的专

用硬件深度

网络的

评论

(Lindsey and Lindblad,

1994; Beiu et al.,

2003; Misra and Saha,

2010)。

不同形式的

专用硬件 (Graf and

Jackel, 1989; Mead and

Ismail, 2012; Kim et

al.,

2009; Pham et

al., 2012; Chen et

al., 2014b,a) 的

研究已经持

续了好几十

年，比如 专

用

集成电路（application-specific integrated circuit, ASIC）的

数字（基于数

字的二

进制

表示），模拟 (Graf and Jackel,

1989; Mead and Ismail,

2012)（基

于以电压或

电

流表示连

续值的物理

实现）和混合

实现（组合数

字和模拟组

件）。近年来更

灵活的 现

场

可编程门阵

列（field

programmable gated array, FPGA）实现（其中

电路的具体

细节可以在

制造完成后

写入芯片）也

得到了长足

发展。

虽然 CPU 和

GPU 上的软件实

现通常使用

32

或 64 位的精度

来表示浮点

数，但

是长期

以来使用较

低的精度在

更短的时间

内完成推断

也是可行的

(Holt

and Baker,

1991; Holi

and Hwang, 1993; Presley

and Haggard, 1994; Simard

and Graf, 1994;

Wawrzynek

et al., 1996; Savich

et al., 2007)。这已成为近

年来更迫切

的问题，因为

深

度学习在

工业产品中

越来越受欢

迎，并且由于

更快的硬件

产生的巨大

影响已经通

过

GPU 的使用得

到了证明。激

励当前对深

度网络专用

硬件研究的

另一个因素

是单

个 CPU

或 GPU 核

心的进展速

度已经减慢

，并且最近计

算速度的改

进来自于核

心的

并行化

（无论

CPU 还是 GPU）。这

与 20

世纪 90 年代

的情况（上一

个神经网络

时

代）的不同

之处在于，神

经网络的硬

件实现（从开

始到芯片可

用可能需要

两年）跟

不上

快速进展和

价格低廉的

通用 CPU 的脚步

。因此，在针对

诸如手机等

低功率设备

开发新的硬

件设计，并且

想要用于深

度学习的一

般公众应用

（例如，具有语

音、计算

机视

觉或自然语

言功能的设

施）等时，研究

专用硬件能

够进一步推

动其发展。

最

近对基于反

向传播神经

网络的低精

度实现的工

作 (Vanhoucke et al.,

2011;

Courbariaux et al.,

2015; Gupta et al.,

2015) 表明，8 和 16

位

之间的精度

足以满足

使

用或训练基

于反向传播

的深度神经

网络的要求

。显而易见的

是，在训练期

间需要

12.2 计算

机视觉

385

比在

推断时更高

的精度，并且

数字某些形

式的动态定

点表示能够

减少每个数

需要的

存储

空间。传统的

定点数被限

制在了一个

固定范围之

内（其对应于

浮点表示中

的给

定指数

）。而动态定点

表示在一组

数字（例如一

个层中的所

有权重）之间

共享该范

围

。使用定点代

替浮点表示

并且每个数

使用较少的

比特能够减

少执行乘法

所需的硬

件

表面积、功率

需求和计算

时间。而乘法

已经是使用

或训练反向

传播的现代

深度网

络中

要求最高的

操作。

12.2

计算机

视觉

一直以

来，计算机视

觉就是深度

学习应用中

几个最活跃

的研究方向

之一。因为

视

觉是一个对

人类以及许

多动物毫不

费力，但对计

算机却充满

挑战的任务

(Ballard

et

al., 1983)。深度学习中

许多流行的

标准基准任

务包括对象

识别以及光

学字符识别

。

计算机视觉

是一个非常

广阔的发展

领域，其中包

括多种多样

的处理图片

的方式

以及

应用方向。计

算机视觉的

应用广泛：从

复现人类视

觉能力（比如

识别人脸）到

创

造全新的

视觉能力。举

个后者的例

子，近期一个

新的计算机

视觉应用是

从视频中可

视物体的振

动中识别相

应的声波 (Davis et al.,

2014)。大

多数计算机

视觉领域的

深度

学习研

究未曾关注

过这样一个

奇异的应用

，它扩展了图

像的范围，而

不是仅仅关

注

于人工智

能中较小的

核心目标——复

制人类的能

力。无论是报

告图像中存

在哪个物

体

，还是给图像

中每个对象

周围添加注

释性的边框

，或从图像中

转录符号序

列，或

给图像

中的每个像

素标记它所

属对象的标

识，大多数计

算机视觉中

的深度学习

往往

用于对

象识别或者

某种形式的

检测。由于生

成模型已经

是深度学习

研究的指导

原则，

因此还

有大量图像

合成工作使

用了深度模

型。尽管图像

合成（“无中生

有’’）通常不

包

括在计算机

视觉内，但是

能够进行图

像合成的模

型通常用于

图像恢复，即

修复图

像中

的缺陷或从

图像中移除

对象这样的

计算机视觉

任务。

12.2.1 预处理

由于原始输

入往往以深

度学习架构

难以表示的

形式出现，许

多应用领域

需要复

杂精

细的预处理

。计算机视觉

通常只需要

相对少的这

种预处理。图

像应该被标

准化，

从而使

得它们的像

素都在相同

并且合理的

范围内，比如

[0, 1] 或者 [−1,

1]。将 [0, 1]

中的

图像与

[0, 255] 中的

图像混合通

常会导致失

败。将图像格

式化为具有

相同的比

例

严格上说是

唯一一种必

要的预处理

。许多计算机

视觉架构需

要标准尺寸

的图像，

386 第十

二章 应用

因

此必须裁剪

或缩放图像

以适应该尺

寸。然而，严格

地说即使是

这种重新调

整比例

的操

作并不总是

必要的。一些

卷积模型接

受可变大小

的输入并动

态地调整它

们的池

化区

域大小以保

持输出大小

恒定 (Waibel et

al., 1989)。其他卷

积模型具有

可变大小

的

输出，其尺寸

随输入自动

缩放，例如对

图像中的每

个像素进行

去噪或标注

的模型

(Hadsell

et al., 2007)。

数据

集增强可以

被看作是一

种只对训练

集做预处理

的方式。数据

集增强是减

少

大多数计

算机视觉模

型泛化误差

的一种极好

方法。在测试

时可用的一

个相关想法

是

将同一输

入的许多不

同版本传给

模型（例如，在

稍微不同的

位置处裁剪

的相同图像

），

并且在模型

的不同实例

上决定模型

的输出。后一

个想法可以

被理解为集

成方法，并

且

有助于减少

泛化误差。

其

他种类的预

处理需要同

时应用于训

练集和测试

集，其目的是

将每个样本

置于

更规范

的形式，以便

减少模型需

要考虑的变

化量。减少数

据中的变化

量既能够减

少泛

化误差

，也能够减小

拟合训练集

所需模型的

大小。更简单

的任务可以

通过更小的

模

型来解决

，而更简单的

解决方案泛

化能力一般

更好。这种类

型的预处理

通常被设计

为去除输入

数据中的某

种可变性，这

对于人工设

计者来说是

容易描述的

，并且人工

设

计者能够保

证不受到任

务影响。当使

用大型数据

集和大型模

型训练时，这

种预处

理通

常是不必要

的，并且最好

只是让模型

学习哪些变

化性应该保

留。例如，用于

分

类 ImageNet

的 AlexNet 系统

仅具有一个

预处理步骤

：对每个像素

减去训练样

本的

平均值

(Krizhevsky

et al., 2012b)。

12.2.1.1

对比度归一

化

在许多任

务中，对比度

是能够安全

移除的最为

明显的变化

源之一。简单

地说，

对比度

指的是图像

中亮像素和

暗像素之间

差异的大小

。量化图像对

比度有许多

方式。

在深度

学习中，对比

度通常指的

是图像或图

像区域中像

素的标准差

。假设我们有

一

个张量表

示的图像 X ∈ R

r×c×3，其

中 Xi,j,1 表示第 i

行

第 j 列红色的

强度，Xi,j,2 对

应的

是绿色的强

度，Xi,j,3 对应的是

蓝色的强度

。然后整个图

像的对比度

可以表示如

下：

v

u

u

t

3

1

rc

∑

i=1

r

∑

j=1

c ∑

k=1

3

(Xi,j,k −

X¯)

2

, (12.1)

12.2 计算机视

觉 387

其中

X¯ 是整

个图片的平

均强度，满足

X¯ =

3

1

rc

r∑

i=1

c∑

j=1

3

∑

k=1

Xi,j,k. (12.2)

全局对比度

归一化（Global

contrast normalization, GCN）旨在

通过从每个

图

像中减去

其平均值，然

后重新缩放

其使得其像

素上的标准

差等于某个

常数

s 来防止

图像具有变

化的对比度

。这种方法非

常复杂，因为

没有缩放因

子可以改变

零对比度

图

像（所有像素

都具有相等

强度的图像

）的对比度。具

有非常低但

非零对比度

的图

像通常

几乎没有信

息内容。在这

种情况下除

以真实标准

差通常仅能

放大传感器

噪声

或压缩

伪像。这种现

象启发我们

引入一个小

的正的正则

化参数 λ 来平

衡估计的标

准

差。或者，我

们至少可以

约束分母使

其大于等于

ϵ。给定一个输

入图像

X，全局

对比

度归一

化产生输出

图像 X

′，定义为

X

′

i,j,k = s

Xi,j,k − X¯

max{ϵ,

√

λ + 3

1

rc

∑r

i=1

∑c

j=1

∑3

k=1(Xi,j,k

− X¯)

2}

.

(12.3)

从大图像中

剪切感兴趣

的对象所组

成的数据集

不可能包含

任何强度几

乎恒定的

图

像。在这些情

况下，通过设

置 λ

= 0 来忽略小

分母问题是

安全的，并且

在非常罕

见

的情况下为

了避免除以

0，通过将

ϵ 设置

为一个非常

小的值比如

说 10−8。这也

是

Goodfellow et al. (2013c)

在

CIFAR-10 数据集上所

使用的方法

。随机剪裁的

小图

像更可

能具有几乎

恒定的强度

，使得激进的

正则化更有

用。在处理从

CIFAR-10 数

据中随机

选择的小区

域时，Coates et al. (2011)

使用 ϵ = 0,

λ = 10。

尺

度参数

s 通常

可以设置为

1（如 Coates et

al. (2011) 所采用的

），或选择使所

有样本上每

个像素的标

准差接近 1（如

Goodfellow

et al. (2013c) 所采用的）。

式

(12.3) 中的标准差

仅仅是对图

片 L

2

范数的重

新缩放（假设

图像的平均

值已经

被移

除）。我们更偏

向于根据标

准差而不是

L

2 范数来定义

GCN，因为标准差

包括除

以像

素数量这一

步，从而基于

标准差的 GCN 能

够使用与图

像大小无关

的固定的 s。

然

而，观察到 L

2 范

数与标准差

成比例，这符

合我们的直

觉。我们可以

把

GCN 理解

成到

球壳的一种

映射。图 12.1

对此

有所说明。这

可能是一个

有用的属性

，因为神经

网

络往往更好

地响应空间

方向，而不是

精确的位置

。响应相同方

向上的多个

距离需

要具

有共线权重

向量但具有

不同偏置的

隐藏单元。这

样的情况对

于学习算法

来说可

能是

困难的。此外

，许多浅层的

图模型把多

个分离的模

式表示在一

条线上会出

现问

题。GCN 采用

一个样本一

个方向1而不

是不同的方

向和距离来

避免这些问

题。

1译者：所有

样本相似的

距离

388

第十二

章 应用

−1.5 0.0

1.5

x0

−1.5

0.0

1.5

Raw input

−1.5

0.0 1.5

x0

GCN,

λ = 10−2

−1.5

0.0 1.5

x0

GCN,

λ = 0

图

12.1: GCN 将

样本投影到

一个球上。(左

) 原始的输入

数据可能拥

有任意的范

数。(中)λ

= 0 时

候的

GCN

可以完美地

将所有的非

零样本投影

到球上。这里

我们令 s = 1，ϵ

= 10−8。由于

我们

使用的

GCN 是基于归一

化标准差而

不是

L

2 范数，所

得到的球并

不是单位球

。(右)λ >

0 的正则

化

GCN 将样本投影

到球上，但是

并没有完全

地丢弃其范

数中变化。s

和

ϵ 的取值与之

前一样。

与直

觉相反的是

，存在被称为

sphering 的预处理操

作，并且它不

同于

GCN。

sphering 并不会

使数据位于

球形壳上，而

是将主成分

重新缩放以

具有相等方

差，

使得

PCA 使用

的多变量正

态分布具有

球形等高线

。sphering 通常被称为

白化

（whitening）。

全局对

比度归一化

常常不能突

出我们想要

突出的图像

特征，例如边

缘和角。如

果

我们有一个

场景，包含了

一个大的黑

暗区域和一

个大的明亮

的区域（例如

一个城

市广

场有一半的

区域处于建

筑物的阴影

之中），则全局

对比度归一

化将确保暗

区域的

亮度

与亮区域的

亮度之间存

在大的差异

。然而，它不能

确保暗区内

的边缘突出

。

这催生了 局

部对比度归

一化（local contrast normalization,

LCN）。局部对

比

度归一化

确保对比度

在每个小窗

口上被归一

化，而不是作

为整体在图

像上被归一

化。

关于局部

对比度归一

化和全局对

比度归一化

的比较可以

参考图 12.2

。

局部

对比度归一

化的各种定

义都是可行

的。在所有情

况下，我们可

以通过减去

邻

近像素的

平均值并除

以邻近像素

的标准差来

修改每个像

素。在一些情

况下，要计算

以当前要修

改的像素为

中心的矩形

窗口中所有

像素的平均

值和标准差

(Pinto et

al.,

2008)。在其他情况

下，使用的则

是以要修改

的像素为中

心的高斯权

重的加权平

均和

加权标

准差。在彩色

图像的情况

下，一些策略

单独处理不

同的颜色通

道，而其他策

略组合来自

不同通道的

信息以使每

个像素归一

化 (Sermanet

et al., 2012)。

x1

12.2 计算机视

觉 389

Input

image GCN LCN

图

12.2: 全局对

比度归一化

和局部对比

度归一化的

比较。直观上

说，全局对比

度归一化的

效果很巧

妙

。它使得所有

的图片的尺

度都差不多

，这减轻了学

习算法处理

多个尺度的

负担。局部对

比度归

一化

更多地改变

了图像，丢弃

了所有相同

强度的区域

。这使得模型

能够只关注

于边缘。较好

的纹

理区域

，如第二行的

屋子，可能会

由于归一化

核的过高带

宽而丢失一

些细节。

局部

对比度归一

化通常可以

通过使用可

分离卷积（参

考第 9.8 节）来计

算特征映

射

的局部平均

值和局部标

准差，然后在

不同的特征

映射上使用

逐元素的减

法和除法。

局

部对比度归

一化是可微

分的操作，并

且还可以作

为一种非线

性作用应用

于网

络隐藏

层，以及应用

于输入的预

处理操作。

与

全局对比度

归一化一样

，我们通常需

要正则化局

部对比度归

一化来避免

出现

除以零

的情况。事实

上，因为局部

对比度归一

化通常作用

于较小的窗

口，所以正则

化更加重要

。较小的窗口

更可能包含

彼此几乎相

同的值，因此

更可能具有

零标准差。

12.2.2 数

据集增强

如

第

7.4 节中讲到

的一样，我们

很容易通过

增加训练集

的额外副本

来增加训练

集的大小，进

而改进分类

器的泛化能

力。这些额外

副本可以通

过对原始图

像进行一

些

变化来生成

，但是并不改

变其类别。对

象识别这个

分类任务特

别适合于这

种形式

的数

据集增强，因

为类别信息

对于许多变

换是不变的

，而我们可以

简单地对输

入应

用诸多

几何变换。如

前所述，分类

器可以受益

于随机转换

或者旋转，某

些情况下输

入的翻转可

以增强数据

集。在专门的

计算机视觉

应用中，存在

很多更高级

的用以数

据

集增强的变

换。这些方案

包括图像中

颜色的随机

扰动 (Krizhevsky et

al., 2012b)，

390 第十二

章

应用

以及

对输入的非

线性几何变

形 (LeCun et

al., 1998c)。

12.3 语音识别

语音识别任

务在于将一

段包括了自

然语言发音

的声学信号

投影到对应

说话人的

词

序列上。令 X = (x

(1)

, x

(2)

, . . .

, x

(T)

)

表

示语音的输

入向量（传统

做法以 20ms 为

一

帧分割信号

）。许多语音识

别的系统通

过特殊的手

工设计方法

预处理输入

信号，从

而提

取特征，但是

某些深度学

习系统 (Jaitly and Hinton,

2011) 直接

从原始输入

中学

习特征

。令 y

= (y1, y2, .

. . , yN

) 表示目标

的输出序列

（通常是一个

词或者字符

的序

列）。自动

语音识别（Automatic Speech

Recognition, ASR）任

务指的是构

造一个函

数

fASR

∗

，使得它能够

在给定声学

序列 X 的情况

下计算最有

可能的语言

序列 y：

fASR

∗

(X) =

arg max

y

P

∗

(y | X

= X), (12.4)

其中

P

∗ 是

给定输入值

X 时对应目标

y

的真实条件

分布。

从 20 世纪

80

年代直到约

2009-2012 年，最先进的

语音识别系

统是 隐马尔

可夫

模型（Hidden

Markov Model, HMM）和

高斯混合模

型（Gaussian Mixture

Model,

GMM）的结合。GMM 对

声学特征和

音素（phoneme）之间的

关系建模 (Bahl

et al.,

1987)，HMM 对

音素序列建

模。GMM-HMM

模型将语

音信号视作

由如下过程

生成：

首先，一

个 HMM 生成了一

个音素的序

列以及离散

的子音素状

态（比如每一

个音

素的开

始，中间，结尾

），然后 GMM 把每一

个离散的状

态转化为一

个简短的声

音信号。尽管

直到最近 GMM-HMM

一

直在 ASR 中占据

主导地位，语

音识别仍然

是神经网络

所成功应用

的第一个领

域。从 20

世纪 80 年

代末期到 90

年

代初期，大

量

语音识别系

统使用了神

经网络 (Bourlard and

Wellekens, 1989; Waibel et

al., 1989;

Robinson and

Fallside, 1991; Bengio et

al., 1991, 1992; Konig

et al., 1996)。当时

，基

于神经网

络的

ASR 的表现

和 GMM-HMM 系统的表

现差不多。比

如说，Robinson

and Fallside (1991) 在

TIMIT 数据

集 (Garofolo et

al., 1993)（有 39 个区分

的音素）

上达

到了 26% 的音素

错误率，这个

结果优于或

者说是可以

与基于 HMM

的结

果相

比。从那

时起，TIMIT 成为了

音素识别的

一个基准数

据集，在语音

识别中的作

用就

和

MNIST 在对

象识别中的

作用差不多

。然而，由于语

音识别软件

系统中复杂

的工

程因素

以及在基于

GMM-HMM 的系统中已

经付出的巨

大努力，工业

界并没有迫

切

转向神经

网络的需求

。结果，直到 21 世

纪 00

年代末期

，学术界和工

业界的研究

者

们更多的

是用神经网

络为 GMM-HMM 系统学

习一些额外

的特征。

12.3 语音

识别 391

之后，随

着更大更深

的模型以及

更大的数据

集的出现，通

过使用神经

网络代

替 GMM 来

实现将声学

特征转化为

音素（或者子

音素状态）的

过程可以大

大地提高

识

别的精度。从

2009

年开始，语音

识别的研究

者们将一种

无监督学习

的深度学习

方

法应用于

语音识别。这

种深度学习

方法基于训

练一个被称

作是受限玻

尔兹曼机的

无

向概率模

型，从而对输

入数据建模

。受限玻尔兹

曼机将会在

第三部分中

描述。为了完

成语音识别

任务，无监督

的预训练被

用来构造一

个深度前馈

网络，这个神

经网络每

一

层都是通过

训练受限玻

尔兹曼机来

初始化的。这

些网络的输

入是从一个

固定规格

的

输入窗（以当

前帧为中心

）的谱声学表

示抽取，预测

了当前帧所

对应的 HMM 状

态

的条件概率

。训练一个这

样的神经网

络能够可以

显著提高在

TIMIT

数据集上的

识别率 (Mohamed et al.,

2009, 2012a)，并将

音素级别的

错误率从大

约 26% 降到了

20.7%。关

于这个模型

成功原因的

详细分析可

以参考Mohamed et al. (2012b)。对于

基本的电话

识别工作流

程的一个扩

展工作是添

加说话人自

适应相关特

征

(Mohamed

et al., 2011)

的方法，这

可以进一步

地降低错误

率。紧接着的

工作则将结

构从音素识

别（TIMIT 所主要关

注的）转向了

大规模词汇

语音识别 (Dahl et

al., 2012)，这

不仅

包含了

识别音素，还

包括了识别

大规模词汇

的序列。语音

识别上的深

度网络从最

初

的使用受

限玻尔兹曼

机进行预训

练发展到了

使用诸如整

流线性单元

和

Dropout 这样

的技

术 (Zeiler

et al., 2013; Dahl

et al., 2013)。从那时开

始，工业界的

几个语音研

究

组开始寻

求与学术圈

的研究者之

间的合作。Hinton

et al. (2012a) 描

述了这些合

作所

带来的

突破性进展

，这些技术现

在被广泛应

用在产品中

，比如移动手

机端。

随后，当

研究组使用

了越来越大

的带标签的

数据集，加入

了各种初始

化，训练

方法

以及调试深

度神经网络

的结构之后

，他们发现这

种无监督的

预训练方式

是没有

必要

的，或者说不

能带来任何

显著的改进

。

用语音识别

中词错误率

来衡量，在语

音识别性能

上的这些突

破是史无前

例的

（大约 30% 的

提高）。在这之

前的长达十

年左右的时

间内，尽管数

据集的规模

是随时

间增

长的（见 Deng and Yu

(2014) 的图

2.4），但基于 GMM-HMM 的系

统的传统技

术已经停滞

不前了。这也

导致了语音

识别领域快

速地转向深

度学习的研

究。在大约

的

两年时间内

，工业界的大

多数的语音

识别产品都

包含了深度

神经网络，这

种成功

也激

发了 ASR领 域对

深度学习算

法和结构的

一波新的研

究浪潮，并且

影响至今。

其

中的一个创

新点是卷积

网络的应用

(Sainath et al., 2013)。卷积网络在

时域与

频域

上复用了权

重，改进了之

前的仅在时

域上使用重

复权值的时

延神经网络

。这种

新的二

维的卷积模

型并不是将

输入的频谱

当作一个长

的向量，而是

当成是一个

图像，

其中一

个轴对应着

时间，另一个

轴对应的是

谱分量的频

率。

392

第十二章

应用

完全抛

弃 HMM 并转向研

究端到端的

深度学习语

音识别系统

是至今仍然

活跃的

另一

个重要推动

。这个领域第

一个主要的

突破是 Graves et al.

(2013)，其中

训练了一

个

深度的长短

期记忆循环

神经网络（见

第 10.10 节），使用了

帧－音素排列

的

MAP 推

断，就像

LeCun et

al. (1998c) 以及 CTC

框架 (Graves et al.,

2006; Graves, 2012)

中

一样。一个深

度循环神经

网络

(Graves et al., 2013)

每个时

间步的各层

都有状态

变

量，两种展开

图的方式导

致两种不同

深度：一种是

普通的根据

层的堆叠衡

量的深

度，另

一种根据时

间展开衡量

的深度。这个

工作把 TIMIT

数据

集上音素的

错误率

记录

降到了的新

低 17.7%。关于应用

于其他领域

的深度循环

神经网络的

变种可以参

考 Pascanu

et al. (2014a); Chung

et al. (2014)。

另一个端

到端的深度

学习语音识

别方向的最

新方法是让

系统学习如

何利用

语音

（phonetic）层级的信息

‘‘排列” 声学（acoustic）层

级的信息 (Chorowski et

al., 2014;

Lu et

al., 2015)。

12.4 自

然语言处理

自然语言处

理（Natural

Language Processing）让计算机

能够使用人

类语言，例

如

英语或法语

。为了让简单

的程序能够

高效明确地

解析，计算机

程序通常读

取和发

出特

殊化的语言

。而自然的语

言通常是模

糊的，并且可

能不遵循形

式的描述。自

然

语言处理

中的应用如

机器翻译，学

习者需要读

取一种人类

语言的句子

，并用另一种

人类语言发

出等同的句

子。许多 NLP 应用

程序基于语

言模型，语言

模型定义了

关于

自然语

言中的字、字

符或字节序

列的概率分

布。

与本章讨

论的其他应

用一样，非常

通用的神经

网络技术可

以成功地应

用于自然

语

言处理。然而

，为了实现卓

越的性能并

扩展到大型

应用程序，一

些领域特定

的策略

也很

重要。为了构

建自然语言

的有效模型

，通常必须使

用专门处理

序列数据的

技术。

在很多

情况下，我们

将自然语言

视为一系列

词，而不是单

个字符或字

节序列。因为

可能的词总

数非常大，基

于词的语言

模型必须在

极高维度和

稀疏的离散

空间上操作

。

为使这种空

间上的模型

在计算和统

计意义上都

高效，研究者

已经开发了

几种策略。

12.4.1 n-gram

语

言模型（language

model）定义

了自然语言

中标记序列

的概率分布

。根据模型

的

设计，标记可

以是词、字符

、甚至是字节

。标记总是离

散的实体。最

早成功的语

言

12.4 自然语言

处理

393

模型基

于固定长度

序列的标记

模型，称为 n-gram。一

个 n-gram

是一个包

含 n 个标

记的

序列。

基于 n-gram 的

模型定义一

个条件概率

——给定前 n

− 1 个标

记后的第 n

个

标

记的条件

概率。该模型

使用这些条

件分布的乘

积定义较长

序列的概率

分布：

P(x1, .

. . , xτ

) = P(x1, .

. . , xn−1)

τ∏

t=n

P(xt

|

xt−n+1, . . .

, xt−1). (12.5)

这个分

解可以由概

率的链式法

则证明。初始

序列

P(x1, . . .

, xn−1) 的概率

分布可以通

过带有较小

n 值的不同模

型建模。

训练

n-gram 模型是简单

的，因为最大

似然估计可

以通过简单

地统计每个

可能

的 n-gram

在训

练集中出现

的次数来获

得。几十年来

，基于 n-gram 的模型

都是统

计语

言模型的核

心模块

(Jelinek and Mercer, 1980;

Katz, 1987; Chen and

Goodman,

1999)。

对于

小的 n

值，模型

有特定的名

称：n = 1 称为

一元

语法（unigram），n = 2 称

为 二

元语法（bigram）及 n =

3 称

为 三元语法

（trigram）。这些名称源

于相应数字

的拉丁前缀

和希腊后缀

“-gram’’，分别表示所

写之物。

通常

我们同时训

练

n-gram 模型和 n −

1 gram 模

型。这使得下

式可以简单

地通

过查找

两个存储的

概率来计算

。

P(xt

| xt−n+1, .

. . , xt−1)

= Pn(xt−n+1, . .

. , xt)

Pn−1(xt−n+1,

. . . ,

xt−1)

(12.6)

为了在 Pn

中精

确地再现推

断，我们训练

Pn−1 时必须省略

每个序列最

后一个字符

。

举个例子，我

们演示三元

模型如何计

算句子 “THE

DOG RAN AWAY.’’ 的概

率。句

子的第

一个词不能

通过上述条

件概率的公

式计算，因为

句子的开头

没有上下文

。取

而代之，在

句子的开头

我们必须使

用词的边缘

概率。因此我

们计算 P3(THE DOG

RAN)。

最后

，可以使用条

件分布 P(AWAY |

DOG RAN)（典型

情况）来预测

最后一个词

。将这

与式 (12.6)

放

在一起，我们

得到：

P(THE DOG RAN

AWAY) = P3(THE DOG

RAN)P3(DOG RAN AWAY)/P2(DOG RAN).

(12.7)

n-gram 模型最

大似然的基

本限制是，在

许多情况下

从训练集计

数估计得到

的

Pn

很可能为

零（即使元组

(xt−n+1, . . .

, xt) 可能出现在

测试集中）。这

可能会导致

两种不同的

灾难性后果

。当 Pn−1

为零时，该

比率是未定

义的，因此模

型甚至不能

394 第十二章 应

用

产生有意

义的输出。当

Pn−1

非零而 Pn 为零

时，测试样本

的对数似然

为 −∞。为

避免这

种灾难性的

后果，大多数

n-gram 模型采用某

种形式的 平

滑（smoothing）。

平滑技术

将概率质量

从观察到的

元组转移到

类似的未观

察到的元组

。见

Chen and

Goodman (1999)

的综述和

实验对比。其

中一种基本

技术基于向

所有可能的

下一个符

号

值添加非零

概率质量。这

个方法可以

被证明是，计

数参数具有

均匀或 Dirichlet 先

验

的贝叶斯推

断。另一个非

常流行的想

法是包含高

阶和低阶 n-gram 模

型的混合模

型，其中高阶

模型提供更

多的容量，而

低阶模型尽

可能地避免

零计数。如果

上下文

xt−n+k,

. . . ,

xt−1 的频

率太小而不

能使用高阶

模型，回退方

法 (back-off methods)

就

查找低

阶 n-gram 。更正式地

说，它们通过

上下文

xt−n+k, . . .

, xt−1 估计

xt 上的分

布，并

增加 k 直到找

到足够可靠

的估计。

经典

的

n-gram 模型特别

容易引起维

数灾难。因为

存在 |V|

n

可能的

n-gram，而

且 |V| 通常很

大。即使有大

量训练数据

和适当的

n，大

多数 n-gram 也不会

出现在训

练

集中。经典

n-gram 模

型的一种观

点是执行最

近邻查询。换

句话说，它可

以被视为

局

部非参数预

测器，类似于

k-最近邻。这些

极端局部预

测器面临的

统计问题已

经在

第

5.11.2 节中

描述过。语言

模型的问题

甚至比普通

模型更严重

，因为任何两

个不同的

词

在one-hot向量空间

中的距离彼

此相同。因此

，难以大量利

用来自任意

‘‘邻居’’ 的

信息

——只有重复相

同上下文的

训练样本对

局部泛化有

用。为了克服

这些问题，语

言模型必须

能够在一个

词和其他语

义相似的词

之间共享知

识。

为了提高

n-gram 模型的统计

效率，基于类

的语言模型

(class-based language

model) (Brown et al.,

1992; Ney and Kneser,

1993; Niesler et al.,

1998) 引入词类别

的概念，然后

属于同一类

别的词共享

词之间的统

计强度。这个

想法使用了

聚类算法，

基

于它们与其

他词同时出

现的频率，将

该组词分成

集群或类。随

后，模型可以

在条

件竖杠

的右侧使用

词类

ID 而不是

单个词 ID。混合

（或回退）词模

型和类模型

的复

合模型

也是可能的

。尽管词类提

供了在序列

之间泛化的

方式，但其中

一些词被相

同

类的另一

个替换，导致

该表示丢失

了很多信息

。

12.4.2 神经语言模

型

神经语言

模型（Neural

Language Model, NLM）是一类

用来克服维

数灾难的语

言模型，它使

用词的分布

式表示对自

然语言序列

建模 (Bengio

et al., 2001b)。不同于

基于类的 n-gram

模

型，神经语言

模型在能够

识别两个相

似的词，并且

不丧失将每

个

词编码为

彼此不同的

能力。神经语

言模型共享

一个词（及其

上下文）和其

他类似词

12.4 自

然语言处理

395

（和上下文之

间）的统计强

度。模型为每

个词学习的

分布式表示

，允许模型处

理具有

类似

共同特征的

词来实现这

种共享。例如

，如果词 dog 和词

cat

映射到具有

许多属

性的

表示，则包含

词 cat 的句子可

以告知模型

对包含词

dog 的

句子做出预

测，反之

亦然

。因为这样的

属性很多，所

以存在许多

泛化的方式

，可以将信息

从每个训练

语

句传递到

指数数量的

语义相关语

句。维数灾难

需要模型泛

化到指数多

的句子（指数

相对句子长

度而言）。该模

型通过将每

个训练句子

与指数数量

的类似句子

相关联克服

这个问题。

我

们有时将这

些词表示称

为 词嵌入（word embedding）。在

这个解释下

，我们将

原始

符号视为维

度等于词表

大小的空间

中的点。词表

示将这些点

嵌入到较低

维的特

征空

间中。在原始

空间中，每个

词由一个one-hot向

量表示，因此

每对词彼此

之间的

欧氏

距离都是 √

2。在

嵌入空间中

，经常出现在

类似上下文

（或共享由模

型学习的一

些

‘‘特征’’ 的任

何词对）中的

词彼此接近

。这通常导致

具有相似含

义的词变得

邻近。

图 12.3

放大

了学到的词

嵌入空间的

特定区域，我

们可以看到

语义上相似

的词如何映

射到彼此接

近的表示。

−34 −32 −30

−28 −26

−14

−13

−12

−11

−10

−9

−8

−7

−6

Canada

Europe

Ontario

North

English

Canadian

UnionAfrican Africa

British

France

Russian China

Germany

French

Assembly EU Japan

Iraq

South

European

35.0

35.5 36.0 36.5 37.0

37.5 38.0

17

18

19

20

21

22

1995

1997 19981996

1999

2000

2001

2002

2003

2004

2005

2006

2007

2009 2008

图

12.3: 从神经机器

翻译模型获

得的词嵌入

的二维可视

化

(Bahdanau et al., 2015)。此图在语

义相

关词的

特定区域放

大，它们具有

彼此接近的

嵌入向量。国

家在左图，数

字在右图。注

意，这些嵌入

是为了可视

化才表示为

2 维。在实际应

用中，嵌入通

常具有更高

的维度并且

可以同时捕

获词之间

多

种相似性。

其

他领域的神

经网络也可

以定义嵌入

。例如，卷积网

络的隐藏层

提供

‘‘图像嵌

入’’。因为自然

语言最初不

在实值向量

空间上，所以

NLP 从业者通常

对嵌入的这

个

想法更感

兴趣。隐藏层

在表示数据

的方式上提

供了更质变

的戏剧性变

化。

396

第十二章

应用

使用分

布式表示来

改进自然语

言处理模型

的基本思想

不必局限于

神经网络。它

还可以用于

图模型，其中

分布式表示

是多个潜变

量的形式 (Mnih and

Hinton, 2007)。

12.4.3 高

维输出

在许

多自然语言

应用中，我们

通常希望我

们的模型产

生词（而不是

字符）作为

输

出的基本单

位。对于大词

汇表，由于词

汇量很大，在

词的选择上

表示输出分

布的计

算成

本可能非常

高。在许多应

用中，V 包含数

十万词。表示

这种分布的

朴素方法是

应用一个仿

射变换，将隐

藏表示转换

到输出空间

，然后应用

softmax 函

数。假设我

们

的词汇表 V

大

小为 |V|。因为其

输出维数为

|V|，描述该仿射

变换线性分

量的权重

矩

阵非常大。这

造成了表示

该矩阵的高

存储成本，以

及与之相乘

的高计算成

本。因

为

softmax 要在

所有 |V| 输出之

间归一化，所

以在训练时

以及测试时

执行全矩阵

乘

法是必要

的——我们不能

仅计算与正

确输出的权

重向量的点

积。因此，输出

层的高

计算

成本在训练

期间（计算似

然性及其梯

度）和测试期

间（计算所有

或所选词的

概

率）都有出

现。对于专门

的损失函数

，可以有效地

计算梯度 (Vincent

et al., 2015)，

但

是应用于传

统

softmax 输出层的

标准交叉熵

损失时会出

现许多困难

。

假设 h

是用于

预测输出概

率 yˆ 的顶部隐

藏层。如果我

们使用学到

的权重 W

和

学

到的偏置 b 参

数化从

h 到 yˆ 的

变换，则仿射

softmax

输出层执行

以下计算：

ai = bi

+

∑

j

Wijhj

∀i ∈ {1, .

. . , |V|},

(12.8)

yˆi =

e

ai

∑|V|

i

′=1

e

ai

′

.

(12.9)

如

果 h 包含

nh 个元

素，则上述操

作复杂度是

O(|V|nh)。在 nh 为数千和

|V|

数十

万的情

况下，这个操

作占据了神

经语言模型

的大多数计

算。

12.4.3.1 使用短列

表

第一个神

经语言模型

(Bengio et al., 2001b,

2003) 通过将词汇

量限制为 10,000

或

20,000

来减轻大词

汇表上 softmax 的高

成本。Schwenk and

Gauvain (2002) 和

Schwenk

(2007) 在这

种方法的基

础上建立新

的方式，将词

汇表 V 分为最

常见词汇

（由

神经网络处

理）的 短列表

（shortlist） L 和较稀有词

汇的尾列表

T

= V\L（由n￾gram模型处理

）。为了组合这

两个预测，神

经网络还必

须预测在上

下文 C 之后出

现

12.4 自然语言

处理 397

的词位

于尾列表的

概率。我们可

以添加额外

的

sigmoid 输出单元

估计 P(i ∈

T | C)

实现这

个预测。额外

输出则可以

用来估计

V 中

所有词的概

率分布，如下

：

P(y =

i | C) =1i∈LP(y

= i | C,

i ∈ L)(1 −

P(i ∈ T |

C))

+ 1i∈TP(y =

i | C, i

∈ T)P(i ∈ T

| C), (12.10)

其中

P(y = i |

C, i ∈ L)

由神经

语言模型提

供 P(y = i

| C, i ∈

T) 由 n-gram 模型提

供。稍作修改

，这种方法也

可以在神经

语言模型的

softmax

层中使用额

外的输出值

，

而不是单独

的 sigmoid 单元。

短列

表方法的一

个明显缺点

是，神经语言

模型的潜在

泛化优势仅

限于最常用

的

词，这大概

是最没用的

。这个缺点引

发了处理高

维输出替代

方法的探索

，如下所述。

12.4.3.2 分

层

Softmax

减少大词

汇表 V 上高维

输出层计算

负担的经典

方法

(Goodman, 2001) 是分层

地

分解概率

。|V|

因子可以降

低到 log |V| 一样低

，而无需执行

与

|V| 成比例数

量（并且

也与

隐藏单元数

量 nh

成比例）的

计算。Bengio (2002) 和 Morin

and Bengio (2005)

将这

种因子分解

方法引入神

经语言模型

中。

我们可以

认为这种层

次结构是先

建立词的类

别，然后是词

类别的类别

，然后是

词类

别的类别的

类别等等。这

些嵌套类别

构成一棵树

，其叶子为词

。在平衡树中

，

树的深度为

log |V|。选择一个词

的概率是由

路径（从树根

到包含该词

叶子的路径

）

上的每个节

点通向该词

分支概率的

乘积给出。图

12.4 是一个简单

的例子。Mnih and

Hinton

(2009) 也描

述了使用多

个路径来识

别单个词的

方法，以便更

好地建模具

有多

个含义

的词。计算词

的概率则涉

及在导向该

词所有路径

上的求和。

为

了预测树的

每个节点所

需的条件概

率，我们通常

在树的每个

节点处使用

逻辑

回归模

型，并且为所

有这些模型

提供与输入

相同的上下

文 C。因为正确

的输出编码

在训练集中

，我们可以使

用监督学习

训练逻辑回

归模型。我们

通常使用标

准交叉熵损

失，对应于最

大化正确判

断序列的对

数似然。

因为

可以高效地

计算输出对

数似然（低至

log |V|

而不是 |V|），所以

也可以高效

地计算梯度

。这不仅包括

关于输出参

数的梯度，而

且还包括关

于隐藏层激

活的梯度。

优

化树结构最

小化期望的

计算数量是

可能的，但通

常不切实际

。给定词的相

对

频率，信息

理论的工具

可以指定如

何选择最佳

的二进制编

码。为此，我们

可以构造

树

，使得与词相

关联的位数

量近似等于

该词频率的

对数。然而在

实践中，节省

计算通

398 第十

二章 应用

(1) (0)

(0,0,0) (0,0,1)

(0,1,0) (0,1,1) (1,0,0) (1,0,1)

(1,1,0) (1,1,1)

(1,1) (1,0)

(0,1) (0,0)

ww00 ww11

ww22 ww33 ww44 ww55

ww66 ww77

图

12.4: 词类别简单

层次结构的

示意图，其中

8

个词 w0, . .

. , w7 组织成

三级层次结

构。树的叶

子

表示实际特

定的词。内部

节点表示词

的组别。任何

节点都可以

通过二值决

策序列（0= 左，1=

右

）索引，从根到

达节点。超类

(0) 包含类

(0, 0) 和 (0,

1)，其

中分别包含

词 {w0, w1} 和

{w2, w3}

的集合

，类似地超类

(1) 包含类

(1, 0) 和 (1,

1)，分

别包含词 {w4, w5} 和

{w6,

w7}。如果树充分

平衡，则最大

深度（二值决

策的数量）与

词数 |V| 的对数

同阶：从 |V|

个词

中选一个词

只需执行

O(log |V|) 次

操作（从根开

始的路径上

的每个节点

一次操作）。在

该示例中，我

们乘三次概

率就能

计算

词 y 的概率，这

三次概率与

从根到节点

y 的路径上每

个节点向左

或向右的二

值决策相关

联。

令 bi(y) 为遍历

树移向 y

时的

第 i 个二值决

策。对输出 y

进

行采样的概

率可以通过

条件概率的

链

式法则分

解为条件概

率的乘积，其

中每个节点

由这些位的

前缀索引。例

如，节点 (1, 0)

对应

于前缀

(b0(w4) = 1,

b1(w4) = 0)，并且

w4 的概率可以

如下分解：

P(y = w4) =

P(b0 = 1, b1

= 0, b2 =

0) (12.11)

= P(b0

= 1)P(b1 = 0

| b0 = 1)P(b2

= 0 | b0

= 1, b1 =

0). (12.12)

12.4 自

然语言处理

399

常事倍功半

，因为输出概

率的计算仅

是神经语言

模型中总计

算的一部分

。例如，假

设有

l 个全连接的

宽度为 nh

的隐

藏层。令 nb 是识

别一个词所

需比特数的

加权平均

值

，其加权由这

些词的频率

给出。在这个

例子中，计算

隐藏激活所

需的操作数

增长

为 O(ln2

h

)，而输

出计算增长

为

O(nhnb)。只要 nb ≤ lnh，我们

可以通过收

缩

nh 比

收缩 nb

减

少更多的计

算量。事实上

，nb 通常很小。因

为词汇表的

大小很少超

过一

百万而

log2

(106

) ≈ 20，所以可以将

nb 减小到大约

20，但

nh 通常大得

多，大约为

103 或

更大。我们可

以定义深度

为

2 和分支因

子为 √

|T|

的树，而

不用仔细优

化分支

因子

为 2 的树。这样

的树对应于

简单定义一

组互斥的词

类。基于深度

为

2 的树的简

单方法可以

获得层级策

略大部分的

计算益处。

一

个仍然有点

开放的问题

是如何最好

地定义这些

词类，或者如

何定义一般

的词

层次结

构。早期工作

使用现有的

层次结构

(Morin and Bengio, 2005)

，但

也可以理想

地与神经语

言模型联合

学习层次结

构。学习层次

结构很困难

。对数似然的

精确优化

似

乎难以解决

，因为词层次

的选择是离

散的，不适于

基于梯度的

优化。然而，我

们

可以使用

离散优化来

近似地最优

化词类的分

割。

分层

softmax 的一

个重要优点

是，它在训练

期间和测试

期间（如果在

测试时我

们

想计算特定

词的概率）都

带来了计算

上的好处。

当

然即使使用

分层

softmax，计算所

有 |V| 个词概率

的成本仍是

很高的。另一

个

重要的操

作是在给定

上下文中选

择最可能的

词。不幸的是

，树结构不能

为这个问题

提供高效精

确的解决方

案。

缺点是在

实践中，分层

softmax 倾向于更差

的测试结果

（相对基于采

样的方法），

我

们将在下文

描述。这可能

是因为词类

选择得不好

。

12.4.3.3

重要采样

加

速神经语言

模型训练的

一种方式是

，避免明确地

计算所有未

出现在下一

位置

的词对

梯度的贡献

。每个不正确

的词在此模

型下具有低

概率。枚举所

有这些词的

计

算成本可

能会很高。相

反，我们可以

仅采样词的

子集。使用式

(12.8)

中引入的符

号，

400 第十二章

应用

梯度可

以写成如下

形式：

∂ log P(y |

C)

∂θ =

∂

log softmaxy(a)

∂θ (12.13)

=

∂

∂θ log

e

ay

∑

i

e

ai

(12.14)

=

∂

∂θ (ay −

log∑

i

e

ai

) (12.15)

=

∂ay

∂θ −

∑

i

P(y = i |

C)

∂ai

∂θ ,

(12.16)

其中 a 是

presoftmax

激活（或得分

）向量，每个词

对应一个元

素。第一项是

正相

(positive phase) 项，推动

ay

向上；而第二

项是负相 (negative phase) 项

，对于所有

i 以

权重 P(i |

C) 推动 ai 向

下。由于负相

项是期望值

，我们可以通

过蒙特卡罗

采样

估计。然

而，这将需要

从模型本身

采样。从模型

中采样需要

对词汇表中

所有的 i 计

算

P(i

| C)，这正是我们

试图避免的

。

我们可以从

另一个分布

中采样，而不

是从模型中

采样，这个分

布称为 提议

分布

（proposal distribution）（记为 q），并

通过适当的

权重校正从

错误分布采

样引入的偏

差 (Bengio

and Sénécal, 2003; Bengio

and Sénécal, 2008)。这是一种

称为 重要采

样

（Importance Sampling）的更通用

技术的应用

，我们将在第

12.4.3.3 节中更详细

地描

述。不幸

的是，即使精

确重要采样

也不一定有

效，因为我们

需要计算权

重

pi/qi，其

中的 pi =

P(i | C) 只

能在计算所

有得分

ai 后才

能计算。这个

应用采取的

解决方案

称

为有偏重要

采样，其中重

要性权重被

归一化加和

为 1。当对负词

ni

进行采样时

，

相关联的梯

度被加权为

：

wi =

pni /qni ∑N

j=1

pnj /qnj

. (12.17)

这些权重用

于对来自 q 的

m 个负样本给

出适当的重

要性，以形成

负相估计对

梯度的

贡献

：

|V|

∑

i=1

P(i | C)

∂ai

∂θ ≈

1

m

∑m

i=1

wi

∂ani

∂θ . (12.18)

一元语法或

二元语法分

布与提议分

布

q 工作得一

样好。从数据

估计这种分

布的参数

是

很容易。在估

计参数之后

，也可以非常

高效地从这

样的分布采

样。

重要采样

（Importance

Sampling）不仅可以加

速具有较大

softmax 输出的模

型

。更一般地，它

可以加速具

有大稀疏输

出层的训练

，其中输出是

稀疏向量而

不是

12.4

自然语

言处理 401

n 选

1。其

中一个例子

是 词袋（bag of words）。词袋

具有稀疏向

量

v，其中 vi 表示

词汇表中的

词 i

存不存在

文档中。或者

，vi 可以指示词

i 出现的次数

。由于各种原

因，训练产生

这种稀疏向

量的机器学

习模型的成

本可能很高

。在学习的早

期，模型

可能

不会真的使

输出真正稀

疏。此外，将输

出的每个元

素与目标的

每个元素进

行比

较，可能

是描述训练

的损失函数

最自然的方

式。这意味着

稀疏输出并

不一定能带

来

计算上的

好处，因为模

型可以选择

使大多数输

出非零，并且

所有这些非

零值需要与

相应的训练

目标进行比

较（即使训练

目标是零）。Dauphin et al.

(2011) 证

明可以使

用

重要采样加

速这种模型

。高效算法最

小化 ‘‘正词’’（在

目标中非零

的那些词）和

相

等数量的

‘‘负词’’ 的重构

损失。负词是

被随机选取

的，如使用启

发式采样更

可能被误

解

的词。该启发

式过采样引

入的偏差则

可以使用重

要性权重校

正。

在所有这

些情况下，输

出层梯度估

计的计算复

杂度被减少

为与负样本

数量成比

例

，而不是与输

出向量的大

小成比例。

12.4.3.4 噪

声对比估计

和排名损失

为减少训练

大词汇表的

神经语言模

型的计算成

本，研究者也

提出了其他

基于采

样的

方法。早期的

例子是

Collobert and Weston (2008a)

提出

的排名损失

，将神经语

言

模型每个词

的输出视为

一个得分，并

试图使正确

词的得分 ay 比

其他词

ai 排名

更

高。提出的

排名损失则

是

L

=

∑

i

max(0,

1 − ay +

ai). (12.19)

如果观察

到词的得分

ay 远超过负词

的得分

ai（相差

大于 1），则第 i 项

梯度为零。

这

个准则的一

个问题是它

不提供估计

的条件概率

，条件概率在

很多应用中

是有用的，

包

括语音识别

和文本生成

（包括诸如翻

译的条件文

本生成任务

）。

最近用于神

经语言模型

的训练目标

是噪声对比

估计，将在第

18.6 节中介绍。这

种方法已成

功应用于神

经语言模型

(Mnih

and Teh, 2012; Mnih

and Kavukcuoglu,

2013)。

12.4.4

结合 n-gram 和神经

语言模型

n-gram

模

型相对神经

网络的主要

优点是 n-gram 模型

具有更高的

模型容量（通

过存储非常

多的元组的

频率），并且处

理样本只需

非常少的计

算量（通过查

找只匹配

402

第

十二章 应用

当前上下文

的几个元组

）。如果我们使

用哈希表或

树来访问计

数，那么用于

n-gram 的

计算量几

乎与容量无

关。相比之下

，将神经网络

的参数数目

加倍通常也

大致加倍计

算时间。当然

，避免每次计

算时使用所

有参数的模

型是一个例

外。嵌入层每

次只索

引单

个嵌入，所以

我们可以增

加词汇量，而

不会增加每

个样本的计

算时间。一些

其

他模型，例

如平铺卷积

网络，可以在

减少参数共

享程度的同

时添加参数

以保持相同

的计算量。然

而，基于矩阵

乘法的典型

神经网络层

需要与参数

数量成比例

的计算量。

因

此，增加容量

的一种简单

方法是将两

种方法结合

，由神经语言

模型和 n￾gram

语言

模型组成集

成 (Bengio et al.,

2001b, 2003)。

对于任何

集成，如果集

成成员产生

独立的错误

，这种技术可

以减少测试

误差。集

成学

习领域提供

了许多方法

来组合集成

成员的预测

，包括统一加

权和在验证

集上选

择权

重。Mikolov et al. (2011a)

扩展了集

成，不是仅包

括两个模型

，而是包括大

量

模型。我们

也可以将神

经网络与最

大熵模型配

对并联合训

练 (Mikolov et

al., 2011b)。

该方法可

以被视为训

练具有一组

额外输入的

神经网络，额

外输入直接

连接到输出

并

且不连接

到模型的任

何其他部分

。额外输入是

输入上下文

中特定

n-gram 是否

存在

的指示

器，因此这些

变量是非常

高维且非常

稀疏的。

模型

容量的增加

是巨大的（架

构的新部分

包含高达

|sV |

n 个

参数），但是处

理输

入所需

的额外计算

量是很小的

（因为额外输

入非常稀疏

）。

12.4.5 神经机器翻

译

机器翻译

以一种自然

语言读取句

子并产生等

同含义的另

一种语言的

句子。机器

翻

译系统通常

涉及许多组

件。在高层次

，一个组件通

常会提出许

多候选翻译

。由于语

言之

间的差异，这

些翻译中的

许多翻译是

不符合语法

的。例如，许多

语言在名词

后

放置形容

词，因此直接

翻译成英语

时，它们会产

生诸如 “apple

red’’ 的短

语。提议机

制

提出建议翻

译的许多变

体，理想情况

下应包括 “red

apple’’。翻

译系统的第

二个组

成部

分（语言模型

）评估提议的

翻译，并可以

评估 “red apple’’

比 “apple red’’ 更好

。

最早的机器

翻译神经网

络探索中已

经纳入了编

码器和解码

器的想法 (Allen 1987;

Chrisman

1991; Forcada and Ñeco

1997)，而

翻译中神经

网络的第一

个大规模有

竞

争力的用

途是通过神

经语言模型

升级翻译系

统的语言模

型 (Schwenk et

al., 2006;

Schwenk, 2010)。之前，大多

数机器翻译

系统在该组

件使用

n-gram 模型

。机器翻

译中

基于 n-gram

的模型

不仅包括传

统的回退 n-gram 模

型 (Jelinek

and Mercer,

1980; Katz,

1987; Chen and Goodman,

1999)，而且包括

最大熵语言

模型 (maximum

12.4 自然语

言处理

403

entropy language models)

(Berger et al., 1996)，其中

给定上下文

中常见的词

，affine￾softmax

层预测下一

个词。

传统语

言模型仅仅

报告自然语

言句子的概

率。因为机器

翻译涉及给

定输入句子

产生输出句

子，所以将自

然语言模型

扩展为条件

的是有意义

的。如第 6.2.1.1 节所

述

可以直接

地扩展一个

模型，该模型

定义某些变

量的边缘分

布，以便在给

定上下文

C（C 可

以是单个变

量或变量列

表）的情况下

定义该变量

的条件分布

。Devlin et

al.

(2014) 在一些统计

机器翻译的

基准中击败

了最先进的

技术，他给定

源语言中的

短语

s1,s2,

. . . ,sk

后使用

MLP 对目标语言

的短语 t1,t2, .

. . ,tk 进行

评分。这个

MLP 估

计 P(t1,t2, .

. . ,tk |

s1,s2, . . .

,sk)。这个 MLP 的估

计替代了条

件 n-gram

模型提供

的

估计。

基于

MLP 方法的缺点

是需要将序

列预处理为

固定长度。为

了使翻译更

加灵活，

我们

希望模型允

许可变的输

入长度和输

出长度。RNN 具备

这种能力。第

10.2.4 节描

述了给

定某些输入

后，关于序列

条件分布

RNN 的

几种构造方

法，并且第 10.4 节

描

述了当输

入是序列时

如何实现这

种条件分布

。在所有情况

下，一个模型

首先读取输

入序列并产

生概括输入

序列的数据

结构。我们称

这个概括为

‘‘上下文” C。上下

文 C

可以是向

量列表，或者

向量或张量

。读取输入以

产生

C 的模型

可以是 RNN (Cho

et al., 2014b; Sutskever

et al., 2014; Jean

et al., 2014) 或卷

积网络

(Kalchbrenner and

Blunsom, 2013)。另一

个模型（通常

是

RNN），则读取上

下文 C 并且生

成目标语言

的句子。在图

12.5 中展示了这

种用于机器

翻译的编码

器-解码器框

架的总体思

想。

为生成以

源句为条件

的整句，模型

必须具有表

示整个源句

的方式。早期

模型只能

表

示单个词或

短语。从表示

学习的观点

来看，具有相

同含义的句

子具有类似

表示是有

用

的，无论它们

是以源语言

还是以目标

语言书写。研

究者首先使

用卷积和 RNN

的

组

合探索该

策略 (Kalchbrenner and

Blunsom, 2013)。后来的

工作介绍了

使用 RNN 对

所提

议的翻译进

行打分 (Cho et al.,

2014b) 或生

成翻译句子

(Sutskever et al.,

2014)。

Jean et al.

(2014) 将这些模型

扩展到更大

的词汇表。

12.4.5.1 使

用注意力机

制并对齐数

据片段

使用

固定大小的

表示概括非

常长的句子

（例如 60 个词）的

所有语义细

节是非

常困

难的。这需要

使用足够大

的

RNN，并且用足

够长时间训

练得很好才

能实现，如

Cho et al.

(2014b) 和

Sutskever et al.

(2014) 所表明的。然

而，更高效的

方法是先

读

取整个句子

或段落（以获

得正在表达

的上下文和

焦点），然后一

次翻译一个

词，

404

第十二章

应用

Decoder

Output object

(English 

sentence)

Intermediate,

semantic representation

Source object

(French sentence or image)

Encoder

图 12.5: 编码

器-解码器架

构在直观表

示（例如词序

列或图像）和

语义表示之

间来回映射

。使用来

自一

种模态数据

的编码器输

出（例如从法

语句子到捕

获句子含义

的隐藏表示

的编码器映

射）作为

用于

另一模态的

解码器输入

（如解码器将

捕获句子含

义的隐藏表

示映射到英

语），我们可以

训练将

一种

模态转换到

另一种模态

的系统。这个

想法已经成

功应用于很

多领域，不仅

仅是机器翻

译，还

包括为

图像生成标

题。

每次聚焦

于输入句子

的不同部分

来收集产生

下一个输出

词所需的语

义细节。这正

是 Bahdanau et al.

(2015) 第一次引

入的想法。图

12.6 中展示了注

意力机制，其

中每

个时间

步关注输入

序列的特定

部分。

我们可

以认为基于

注意力机制

的系统有三

个组件：

• 读取

器读取原始

数据（例如源

语句中的源

词）并将其转

换为分布式

表示，其中

一

个特征向量

与每个词的

位置相关联

。

• 存储器存储

读取器输出

的特征向量

列表。这可以

被理解为包

含事实序列

的存储

器，而

之后不必以

相同的顺序

从中检索，也

不必访问全

部。

•

最后一个

程序利用存

储器的内容

顺序地执行

任务，每个时

间步聚焦于

某个存储

器

元素的内容

（或几个，具有

不同权重）。

第

三组件可以

生成翻译语

句。

当用一种

语言书写的

句子中的词

与另一种语

言的翻译语

句中的相应

词对齐时，

可

以使对应的

词嵌入相关

联。早期的工

作表明，我们

可以学习将

一种语言中

的词

嵌入与

另一种语言

中的词嵌入

相关联的翻

译矩阵 (Kočiský et

al., 2014)，与传

统

的基于短

语表中频率

计数的方法

相比，可以产

生较低的对

齐错误率。更

早的工作

12.4

自

然语言处理

405

↵↵((tt−−1)1) ↵↵((tt)) ↵↵((tt+1)

+1)

hh((tt−−1)1) hh((tt)) hh((tt+1)

+1)

c

⇥ ⇥

⇥

+

图 12.6:

由 Bahdanau et al.

(2015) 引入的

现代注意力

机制，本质上

是加权平均

。注意力机制

对具

有权重

α

(t)

的特征向量

h

(t) 进行加权平

均形成上下

文向量 c。在一

些应用中，特

征向量

h 是神

经

网络的隐

藏单元，但它

们也可以是

模型的原始

输入。权重 α

(t) 由

模型本身产

生。它们通常

是区间

[0, 1]

中的

值，并且旨在

仅仅集中在

单个 h

(t) 周围，使

得加权平均

精确地读取

接近一个特

定时间

步的

特征向量。权

重 α

(t) 通常由模

型另一部分

发出的相关

性得分应用

softmax

函数后产生

。注意

力机制

在计算上需

要比直接索

引期望的 h

(t)

付

出更高的代

价，但直接索

引不能使用

梯度下降训

练。

基于加权

平均的注意

力机制是平

滑、可微的近

似，可以使用

现有优化算

法训练。

406 第十

二章

应用

(Klementiev et al.,

2012) 也

对跨语言词

向量进行了

研究。这种方

法存在很多

的扩展。

例如

，允许在更大

数据集上训

练的更高效

的跨语言对

齐 (Gouws

et al., 2014) 。

12.4.6 历史展望

在对反向传

播的第一次

探索中，Rumelhart et al.

(1986a) 等人

提出了分布

式表

示符号

的思想，其中

符号对应于

族成员的身

份，而神经网

络捕获族成

员之间的关

系，

训练样本

形成三元组

如（Colin，Mother，Victoria）。神经网络

的第一层学

习每个族

成

员的表示。例

如，Colin 的特征可

能代表 Colin 所在

的族树，他所

在树的分支

，他

来自哪一

代等等。我们

可以将神经

网络认为是

将这些属性

关联在一起

的计算学习

规

则，可以获

得期望预测

。模型则可以

进行预测，例

如推断谁是

Colin 的母亲。

Deerwester

et al. (1990) 将符

号嵌入的想

法扩展到对

词的嵌入。这

些嵌入使用

SVD

学习。之后，嵌

入将通过神

经网络学习

。

自然语言处

理的历史是

由流行表示

（对模型输入

不同方式的

表示）的变化

为

标志的。在

早期对符号

和词建模的

工作之后，神

经网络在NLP上

一些最早的

应用

(Miikkulainen

and Dyer, 1991; Schmidhuber,

1996) 将输入

表示为字符

序列。

Bengio et

al. (2001b) 将焦点

重新引到对

词建模并引

入神经语言

模型，能产生

可

解释的词

嵌入。这些神

经模型已经

从在一小组

符号上的定

义表示（20

世纪

80 年代）

扩展到

现代应用中

的数百万字

（包括专有名

词和拼写错

误）。这种计算

扩展的努力

导

致了第

12.4.3 节

中描述的技

术发明。

最初

，使用词作为

语言模型的

基本单元可

以改进语言

建模的性能

(Bengio et

al.,

2001b)。而今，新技术

不断推动基

于字符 (Sutskever et

al., 2011)）和基

于词的模型

向前发展，最

近的工作 (Gillick et

al., 2015) 甚

至建模 Unicode

字符

的单个字节

。

神经语言模

型背后的思

想已经扩展

到多个自然

语言处理应

用，如解析 (Hender￾son, 2003,

2004; Collobert, 2011)、词

性标注、语义

角色标注、分

块等，有时使

用

共享词嵌

入的单一多

任务学习架

构

(Collobert and Weston, 2008a;

Collobert et al.,

2011a)。

随着 t-SNE 降维

算法的发展

(van der

Maaten and Hinton, 2008)

以及 Joseph

Turian 在

2009 年引

入的专用于

可视化词嵌

入的应用，用

于分析语言

模型嵌入的

二

维可视化

成为一种流

行的工具。

12.5

其

他应用 407

12.5 其他

应用

在本节

中，我们介绍

深度学习一

些其他类型

的应用，它们

与上面讨论

的标准对

象

识别、语音识

别和自然语

言处理任务

不同。本书的

第三部分将

扩大这个范

围，甚

至进一

步扩展到仍

是目前主要

研究领域的

任务。

12.5.1

推荐系

统

信息技术

部门中机器

学习的主要

应用之一是

向潜在用户

或客户推荐

项目。这可

以

分为两种主

要的应用：在

线广告和项

目建议（通常

这些建议的

目的仍然是

为了销

售产

品）。两者都依

赖于预测用

户和项目之

间的关联，一

旦向该用户

展示了广告

或推

荐了该

产品，推荐系

统要么预测

一些行为的

概率（用户购

买产品或该

行为的一些

代

替）或预期

增益（其可取

决于产品的

价值）。目前，互

联网的资金

主要来自于

各种形

式的

在线广告。经

济的主要部

分依靠网上

购物。包括 Amazon

和

eBay 在内的公司

都使用了机

器学习（包括

深度学习）推

荐他们的产

品。有时，项目

不是实际出

售的

产品。如

选择在社交

网络新闻信

息流上显示

的帖子、推荐

观看的电影

、推荐笑话、推

荐专家建议

、匹配视频游

戏的玩家或

匹配约会的

人。

通常，这种

关联问题可

以作为监督

学习问题来

处理：给出一

些关于项目

和关于

用户

的信息，预测

感兴趣的行

为（用户点击

广告、输入评

级、点击 ‘‘喜欢

’’ 按钮、购

买产

品，在产品上

花钱、花时间

访问产品页

面等）。通常这

最终会归结

到回归问题

（预测一些条

件期望值）或

概率分类问

题（预测一些

离散事件的

条件概率）。

早

期推荐系统

的工作依赖

于这些预测

输入的最小

信息：用户 ID 和

项目 ID。在

这种

情况下，唯一

的泛化方式

依赖于不同

用户或不同

项目的目标

变量值之间

的模式

相似

性。假设用户

1 和用户 2

都喜

欢项目 A，B 和 C.

由

此，我们可以

推断出用户

1 和用户 2 具有

类似的口味

。如果用户

1 喜

欢项目 D，那么

这可以强烈

提示用户 2

也

喜欢 D。基于此

原理的算法

称为 协同过

滤（collaborative filtering）。非参数方

法

（例如基于

估计偏好模

式之间相似

性的最近邻

方法）和参数

方法都可能

用来解决这

个

问题。参数

方法通常依

赖于为每个

用户和每个

项目学习分

布式表示（也

称为嵌入）。

目

标变量的双

线性预测（例

如评级）是一

种简单的参

数方法，这种

方法非常成

功，通

常被认

为是最先进

系统的组成

部分。通过用

户嵌入和项

目嵌入之间

的点积（可能

需

要使用仅

依赖于用户

ID 或项目 ID 的常

数来校正）获

得预测。令

Rˆ 是

包含我们预

测的矩阵，A 矩

阵行中是用

户嵌入，B 矩阵

列中具有项

目嵌入。令

b 和

c 是分别包

408

第

十二章 应用

含针对每个

用户（表示用

户平常坏脾

气或积极的

程度）以及每

个项目（表示

其大体

受欢

迎程度）的偏

置向量。因此

，双线性预测

如下获得：

Rˆ

u,i = bu +

ci +

∑

j

Au,jBj,i. (12.20)

通

常，人们希望

最小化预测

评级 Rˆ

u,i 和实际

评级 Ru,i 之间的

平方误差。当

用户嵌入

和

项目嵌入首

次缩小到低

维度（两个或

三个）时，它们

就可以方便

地可视化，或

者

可以将用

户或项目彼

此进行比较

（就像词嵌入

）。获得这些嵌

入的一种方

式是对实际

目标（例如评

级）的矩阵 R 进

行奇异值分

解。这对应于

将

R = UDV′（或归一化

的变体）分解

为两个因子

的乘积，低秩

矩阵 A

= UD 和 B

= V

′。SVD的一

个问题

是它

以任意方式

处理缺失条

目，如同它们

对应于目标

值

0。相反，我们

希望避免为

缺

失条目做

出的预测付

出任何代价

。幸运的是，观

察到的评级

的平方误差

总和也可以

使用基于梯

度的优化最

小化。SVD 和式 (12.20)

中

的双线性预

测在 Netflix 奖竞赛

中

（目的是仅

基于大量匿

名用户的之

前评级预测

电影的评级

）表现得非常

好

(Bennett

and Lanning, 2007)。许多机器

学习专家参

加了

2006 年和 2009 年

之间的这场

比赛。

它提高

了使用先进

机器学习的

推荐系统的

研究水平，并

改进了推荐

系统。即使简

单

的双线性

预测或 SVD 本身

并没有赢得

比赛，但它是

大多数竞争

对手提出的

整体模型

中

一个组成部

分，包括胜者

(Töscher et al., 2009;

Koren, 2009)。

除了这些具

有分布式表

示的双线性

模型之外，第

一次用于协

同过滤的神

经网络之

一

是基于

RBM 的无

向概率模型

(Salakhutdinov et al.,

2007)。RBM 是 Netflix 比

赛获胜

方法的一个

重要组成部

分 (Töscher et al.,

2009; Koren, 2009)。神经网络

社群

中也已

经探索了对

评级矩阵进

行因子分解

的更高级变

体

(Salakhutdinov and Mnih,

2008)。

然而，协同

过滤系统有

一个基本限

制：当引入新

项目或新用

户时，缺乏评

级历

史意味

着无法评估

其与其他项

目或用户的

相似性，或者

说无法评估

新的用户和

现有

项目的

联系。这被称

为冷启动推

荐问题。解决

冷启动推荐

问题的一般

方式是引入

单

个用户和

项目的额外

信息。例如，该

额外信息可

以是用户简

要信息或每

个项目的特

征。使用这种

信息的系统

被称为

基于

内容的推荐

系统 (content-based recommender

system)。从丰富

的用户特征

或项目特征

集到嵌入的

映射可以通

过深度学习

架构学习

(Huang et al., 2013;

Elkahky et al., 2015)。

专

用的深度学

习架构，如卷

积网络已经

应用于从丰

富内容中提

取特征，如提

取

用于音乐

推荐的音乐

音轨 (van den

Oörd et al., 2013)。在该工

作中，卷积网

络将声

学特

征作为输入

并计算相关

歌曲的嵌入

。该歌曲嵌入

和用户嵌入

之间的点积

则可以

12.5 其他

应用 409

预测用

户是否将收

听该歌曲。

12.5.1.1 探

索与利用

当

向用户推荐

时，会产生超

出普通监督

学习范围的

问题，并进入

强化学习的

领

域。理论上

，许多推荐问

题最准确的

描述是contextual bandit(Langford and Zhang,

2008; Lu et al.,

2010)。问题

是，当我们使

用推荐系统

收集数据时

，我们得到是

一个

有偏且

不完整的用

户偏好观：我

们只能看到

用户对推荐

给他们项目

的反应，而不

是

其他项目

。此外，在某些

情况下，我们

可能无法获

得未向其进

行推荐的用

户的任何

信

息（例如，在广

告竞价中，可

能是广告的

建议价格低

于最低价格

阈值，或者没

有

赢得竞价

，因此广告不

会显示）。更重

要的是，我们

不知道推荐

任何其他项

目会产生

什

么结果。这就

像训练一个

分类器，为每

个训练样本

x 挑选一个类

别 yˆ（通常是基

于模型最高

概率的类别

），然后只能获

得该类别正

确与否的反

馈。显然，每个

样本传

达的

信息少于监

督的情况（其

中真实标签

y 是可直接访

问的），因此需

要更多的样

本。更糟糕的

是，如果我们

不够小心，即

使收集越来

越多的数据

，我们得到的

系统

可能会

继续选择错

误的决定，因

为正确的决

定最初只有

很低的概率

：直到学习者

选

择正确的

决定之前，该

系统都无法

学习正确的

决定。这类似

于强化学习

的情况，其

中

仅观察到所

选动作的奖

励。一般来说

，强化学习会

涉及许多动

作和许多奖

励的序

列。bandit 情

景是强化学

习的特殊情

况，其中学习

者仅采取单

一动作并接

收单个奖

励

。bandit

问题在学习

者知道哪个

奖励与哪个

动作相关联

的时候，是更

容易的。在

一

般的强化学

习场景中，高

奖励或低奖

励可能是由

最近的动作

或很久以前

的动作引

起

的。术语 contextual

bandit（contextual bandit）指的

是在一些输

入变量可以

通

知决定的

上下文中采

取动作的情

况。例如，我们

至少知道用

户身份，并且

我们要选

择

一个项目。从

上下文到动

作的映射也

称为

策略（policy）。学

习者和数据

分布（现

在取

决于学习者

的动作）之间

的反馈循环

是强化学习

和bandit研究的中

心问题。

强化

学习需要权

衡 探索（exploration）与

利

用（exploitation）。利用指的

是从

目前学

到的最好策

略采取动作

，也就是我们

所知的将获

得高奖励的

动作。 探索

（exploration）是

指采取行动

以获得更多

的训练数据

。如果我们知

道给定上下

文

x，

动作 a 给予

我们

1 的奖励

，但我们不知

道这是否是

最好的奖励

。我们可能想

利用我

们目

前的策略，并

继续采取行

动 a

相对肯定

地获得 1 的奖

励。然而，我们

也可能想

通

过尝试动作

a

′ 来探索。我们

不知道尝试

动作 a

′

会发生

什么。我们希

望得到 2 的

奖

励，但有获得

0

奖励的风险

。无论如何，我

们至少获得

了一些知识

。

410 第十二章 应

用

探索（exploration）可以

以许多方式

实现，从覆盖

可能动作的

整个空间的

随机

动作到

基于模型的

方法（基于预

期回报和模

型对该回报

不确定性的

量来计算动

作的

选择）。

许

多因素决定

了我们喜欢

探索或利用

的程度。最突

出的因素之

一是我们感

兴趣

的时间

尺度。如果代

理只有短暂

的时间积累

奖励，那么我

们喜欢更多

的利用。如果

代理有很长

时间积累奖

励，那么我们

开始更多的

探索，以便使

用更多的知

识更有效

地

规划未来的

动作。

监督学

习在探索或

利用之间没

有权衡，因为

监督信号总

是指定哪个

输出对于每

个输入是正

确的。我们总

是知道标签

是最好的输

出，没有必要

尝试不同的

输出来确

定

是否优于模

型当前的输

出。

除了权衡

探索和利用

之外，强化学

习背景下出

现的另一个

困难是难以

评估和比

较

不同的策略

。强化学习包

括学习者和

环境之间的

相互作用。这

个反馈回路

意味着

使用

固定的测试

集输入评估

学习者的表

现不是直接

的。策略本身

确定将看到

哪些输

入。Dudik

et al. (2011) 提

出了评估contextual

bandit的

技术。

12.5.2 知识表

示、推理和回

答

因为使用

符号

(Rumelhart et al., 1986a)

和词嵌

入 (Deerwester et al.,

1990;

Bengio et al.,

2001b)，深度学习

方法在语言

模型、机器翻

译和自然语

言处理方面

非

常成功。这

些嵌入表示

关于单个词

或概念的语

义知识。研究

前沿是为短

语或词和事

实之间的关

系开发嵌入

。搜索引擎已

经使用机器

学习来实现

这一目的，但

是要改进

这

些更高级的

表示还有许

多工作要做

。

12.5.2.1

知识、联系和

回答

一个有

趣的研究方

向是确定如

何训练分布

式表示才能

捕获两个实

体之间的 关

系

（relation）。

数学中，二

元关系是一

组有序的对

象对。集合中

的对具有这

种关系，而那

些不

在集合

中的对则没

有。例如，我们

可以在实体

集 {1, 2,

3} 上定义关

系 ‘‘小于’’ 来定

义

有序对的

集合 S = {(1,

2),(1, 3),(2, 3)}。一旦这

个关系被定

义，我们可以

像动词一样

使用它。因为

(1, 2)

∈ S，我们说 1 小于

2。因为

(2, 1) ̸∈ S，我们不

能说

2 小于 1。

当

然，彼此相关

的实体不必

是数字。我们

可以定义关

系

is_a_type_of 包含如（狗

，

12.5 其他应用

411

哺

乳动物）的元

组。

在 AI

的背景

下，我们将关

系看作句法

上简单且高

度结构化的

语言。关系起

到动

词的作

用，而关系的

两个参数发

挥着主体和

客体的作用

。这些句子是

一个三元组

标

记的形式

：

(subject,

verb, object) (12.21)

其值是

(entityi

,relationj , entityk

). (12.22)

我们

还可以定义

属性（attribute），类似于

关系的概念

，但只需要一

个参数：

(entityi

, attributej ). (12.23)

例如

，我们可以定

义 has_fur 属性，并将

其应用于像

狗这样的实

体。

许多应用

中需要表示

关系和推理

。我们如何在

神经网络中

做到这一点

？

机器学习模

型当然需要

训练数据。我

们可以推断

非结构化自

然语言组成

的训练

数据

集中实体之

间的关系，也

可以使用明

确定义关系

的结构化数

据库。这些数

据库

的共同

结构是关系

型数据库，它

存储这种相

同类型的信

息，虽然没有

格式化为三

元标记的句

子。当数据库

旨在将日常

生活中常识

或关于应用

领域的专业

知识传达

给

人工智能系

统时，我们将

这种数据库

称为知识库

。知识库包括

一般的像

Freebase、

OpenCyc、WordNet、Wikibase2 等

等，和专业的

知识库，如 GeneOntology3。实

体

和关系的

表示可以将

知识库中的

每个三元组

作为训练样

本来学习，并

且以最大化

捕

获它们的

联合分布为

训练目标 (Bordes et

al., 2013a)。

除

了训练数据

，我们还需定

义训练的模

型族。一种常

见的方法是

将神经语言

模

型扩展到

模型实体和

关系。神经语

言模型学习

提供每个词

分布式表示

的向量。他们

还

通过学习

这些向量的

函数来学习

词之间的相

互作用，例如

哪些词可能

出现在词序

列

之后。我们

可以学习每

个关系的嵌

入向量将这

种方法扩展

到实体和关

系。事实上，建

模语言和通

过关系编码

建模知识的

联系非常接

近，研究人员

可以同时使

用知识库和

自然语言句

子训练这样

的实体表示

(Bordes et al.,

2011, 2012; Wang et

al., 2014a)，

或组合来自

多个关系型

数据库的数

据 (Bordes

et al., 2013b)。可能与这

种模型相关

联的特定参

数化有许多

种。早期关于

学习实体间

关系的工作

(Paccanaro and

Hinton,

2分别可以在

如下网址获

取: freebase.com, cyc.com/opencyc,

wordnet.princeton.edu, wikiba.se

3

geneontology.org

412 第十二章

应用

2000) 假定高

度受限的参

数形式（‘‘线性

关系嵌入’’），通

常对关系使

用与实体形

式不

同的表

示。例如，Paccanaro and Hinton (2000)

和 Bordes et al.

(2011) 用

向量表示

实

体而矩阵表

示关系，其思

想是关系在

实体上相当

于运算符。或

者，关系可以

被认

为是任

何其他实体

(Bordes

et al., 2012)，允许我们关

于关系作声

明，但是更灵

活的

是将它

们结合在一

起并建模联

合分布的机

制。

这种模型

的实际短期

应用是 链接

预测（link prediction）：预测知

识图谱中缺

失

的弧。这是

基于旧事实

推广新事实

的一种形式

。目前存在的

大多数知识

库都是通过

人力劳动构

建的，这往往

使知识库缺

失许多并且

可能是大多

数真正的关

系。请查

看 Wang et al.

(2014b)、Lin et al. (2015)

和

Garcia-Duran et al. (2015)

中这样应用

的例子。

我们

很难评估链

接预测任务

上模型的性

能，因为我们

的数据集只

有正样本（已

知是真实的

事实）。如果模

型提出了不

在数据集中

的事实，我们

不确定模型

是犯了错

误

还是发现了

一个新的以

前未知的事

实。度量基于

测试模型如

何将已知真

实事实的

留

存集合与不

太可能为真

的其他事实

相比较，因此

有些不精确

。构造感兴趣

的负样

本（可

能为假的事

实）的常见方

式是从真实

事实开始，并

创建该事实

的损坏版本

，例

如用随机

选择的不同

实体替换关

系中的一个

实体。通用的

测试精度（10% 度

量）计

算模型

在该事实的

所有损坏版

本的前

10% 中选

择 ‘‘正确’’ 事实

的次数。

知识

库和分布式

表示的另一

个应用是 词

义消歧（word-sense disambiguation）

(Navigli

and Velardi, 2005; Bordes

et al., 2012)，这个

任务决定在

某些语境中

哪个词

的意

义是恰当。

最

后，知识的关

系结合一个

推理过程和

对自然语言

的理解可以

让我们建立

一个

一般的

问答系统。一

般的问答系

统必须能处

理输入信息

并记住重要

的事实，并以

之

后能检索

和推理的方

式组织。这仍

然是一个困

难的开放性

问题，只能在

受限的 ‘‘玩

具

’’ 环境下解决

。目前，记住和

检索特定声

明性事实的

最佳方法是

使用显式记

忆机

制，如第

10.12 节所述。记忆

网络最开始

是被用来解

决一个玩具

问答任务

(Weston

et al., 2014)。Kumar

et al. (2015b) 提

出了一种扩

展，使用

GRU 循环

网络将输入

读

入存储器

并且在给定

存储器的内

容后产生回

答。

深度学习

已经应用于

其他许多应

用（除了这里

描述的应用

以外），并且肯

定会在

此之

后应用于更

多的场景。我

们不可能全

面描述与此

主题相关的

所有应用。本

项调

查尽可

能地提供了

在本文写作

之时的代表

性样本

第二

部分介绍了

涉及深度学

习的现代实

践，包括了所

有非常成功

的方法。一般

12.5 其他应用

413

而

言，这些方法

使用代价函

数的梯度寻

找模型（近似

于某些所期

望的函数）的

参数。

当具有

足够的训练

数据时，这种

方法是非常

强大的。我们

现在转到第

三部分，开始

进入研究领

域，旨在使用

较少的训练

数据或执行

更多样的任

务。而且相比

目前为止

所

描述的情况

，其中的挑战

更困难并且

远远没有解

决。

第三部分

深度学习研

究

414

415

本书这一

部分描述目

前研究社群

所追求的、更

有远见和更

先进的深度

学习方法。

在

本书的前两

部分，我们已

经展示了如

何解决监督

学习问题，即

在给定足够

的

映射样本

的情况下，学

习将一个向

量映射到另

一个。

我们想

要解决的问

题并不全都

属于这个类

别。我们可能

希望生成新

的样本、或

确

定一个点的

似然性、或处

理缺失值以

及利用一组

大量的未标

记样本或相

关任务的

样

本。当前应用

于工业的最

先进技术的

缺点是我们

的学习算法

需要大量的

监督数据

才

能实现良好

的精度。在本

书这一部分

，我们讨论一

些推测性的

方法，来减少

现有

模型工

作所需的标

注数据量，并

适用于更广

泛的任务。实

现这些目标

通常需要某

种

形式的无

监督或半监

督学习。

许多

深度学习算

法被设计为

处理无监督

学习问题，但

不像深度学

习已经在很

大

程度上解

决了各种任

务的监督学

习问题，没有

一个算法能

以同样的方

式真正解决

无

监督学习

问题。在本书

这一部分，我

们描述无监

督学习的现

有方法和一

些如何在这

一领域取得

进展的流行

思想。

无监督

学习困难的

核心原因是

被建模的随

机变量的高

维度。这带来

了两个不同

的挑战：统计

挑战和计算

挑战。统计挑

战与泛化相

关：我们可能

想要区分的

配置数

会随

着感兴趣的

维度数指数

增长，并且这

快速变得比

可能具有的

（或者在有限

计算

资源下

使用的）样本

数大得多。与

高维分布相

关联的计算

挑战之所以

会出现，是因

为用于学习

或使用训练

模型的许多

算法（特别是

基于估计显

式概率函数

的算法）涉

及

难处理的计

算量，并且随

维数呈指数

增长。

使用概

率模型，这种

计算挑战来

自执行难解

的推断或归

一化分布。

• 难

解的推断：推

断主要在第

十九章讨论

。推断关于捕

获 a，b 和

c 上联合

分布的

模型

，给定其他变

量 b

的情况下

，猜测一些变

量 a 的可能值

。为了计算这

样的

条件概

率，我们需要

对变量

c 的值

求和，以及计

算对 a 和

c 的值

求和的归一

化

常数。

•

难解

的归一化常

数（配分函数

）：配分函数主

要在第十八

章讨论。归一

化概

率函数

的常数在推

断（上文）以及

学习中出现

。许多概率模

型涉及这样

的归

一化常

数。不幸的是

，学习这样的

模型通常需

要相对于模

型参数计算

配分函

数对

数的梯度。该

计算通常与

计算配分函

数本身一样

难解。马尔可

夫链蒙特

卡

罗（MCMC）（第十七章

）通常用于处

理配分函数

。不幸的是，当

模型分

布的

模式众多且

分离良好时

，MCMC方法会出现

问题，特别是

在高维空间

中

416

（第

17.5 节）。

面对

这些难以处

理的计算的

一种方法是

近似它们，如

在本书的第

三部分中讨

论

的，研究者

已经提出了

许多方法。这

里还讨论另

一种有趣的

方式是通过

设计模型，完

全避免这些

难以处理的

计算，因此不

需要这些计

算的方法是

非常有吸引

力的。近年

来

，研究者已经

提出了数种

具有该动机

的生成模型

。其中第二十

章讨论了各

种各样

的现

代生成式建

模方法。

第三

部分对于研

究者来说是

最重要的，研

究者想要了

解深度学习

领域的广度

，

并将领域推

向真正的人

工智能。

第十

三章 线性因

子模型

许多

深度学习的

研究前沿均

涉及构建输

入的概率模

型 pmodel(x)。原则上说

，给

定任何其

他变量的情

况下，这样的

模型可以使

用概率推断

来预测其环

境中的任何

变

量。许多这

样的模型还

具有潜变量

h，其中 pmodel(x) =

Eh pmodel(x | h)。这些潜

变

量提供了

表示数据的

另一种方式

。我们在深度

前馈网络和

循环网络中

已经发现，基

于潜变量的

分布式表示

继承了表示

学习的所有

优点。

在本章

中，我们描述

了一些基于

潜变量的最

简单的概率

模型： 线性因

子模型

（linear

factor model）。这些

模型有时被

用来作为混

合模型的组

成模块 (Hinton et

al.,

1995a; Ghahramani and

Hinton, 1996; Roweis et

al., 2002) 或者

更大的深度

概率模

型

(Tang et al., 2012)。同

时，也介绍了

构建生成模

型所需的许

多基本方法

，在此基

础上

更先进的深

度模型也将

得到进一步

扩展。

线性因

子模型通过

随机线性解

码器函数来

定义，该函数

通过对 h 的线

性变换以

及

添加噪声来

生成 x。

有趣的

是，通过这些

模型我们能

够发现一些

符合简单联

合分布的解

释性因子。

线

性解码器的

简单性使得

它们成为了

最早被广泛

研究的潜变

量模型。

线性

因子模型描

述如下的数

据生成过程

。首先，我们从

一个分布中

抽取解释性

因子 h

h ∼

p(h), (13.1)

其中 p(h)

是

一个因子分

布，满足 p(h) = ∏

i

p(hi)，所以

易于从中采

样。接下来，在

给定因子的

情况下，我们

对实值的可

观察变量进

行采样

x =

Wh + b +

noise, (13.2)

其中

噪声通常是

对角化的（在

维度上是独

立的）且服从

高斯分布。这

在图 13.1

有具

417

418 第

十三章

线性

因子模型

体

说明。

hh11 hh22

hh33

xx11 xx22 xx33

xx == WWhh ++

bb ++ noise noise

图 13.1: 描述

线性因子模

型族的有向

图模型，其中

我们假设观

察到的数据

向量 x

是通过

独立的潜

在

因子 h 的线性

组合再加上

一定噪声获

得的。不同的

模型，比如概

率

PCA，因子分析

或者是 ICA，

都是

选择了不同

形式的噪声

以及先验 p(h)。

13.1 概

率 PCA 和因子分

析

概率 PCA（probabilistic PCA）、因子

分析和其他

线性因子模

型是上述等

式

（式(13.1)

和式 (13.2) ）的

特殊情况，并

且仅在对观

测到 x

之前的

噪声分布和

潜变量

h 先验

的选择上有

所不同。

在

因

子分析（factor analysis） (Bartholomew, 1987;

Basilevsky, 1994) 中，潜

变量的先验

是一个方差

为单位矩阵

的高斯分布

h ∼

N (h; 0, I),

(13.3)

同时，假定在

给定 h 的条件

下观察值

xi 是

条件独立（conditionally independent）

的

。具体来说，我

们可以假设

噪声是从对

角协方差矩

阵的高斯分

布中抽出的

，协方

差矩阵

为 ψ = diag(σ

2

)，其中 σ

2

= [σ1

2

,

σ2

2

, .

. . , σn

2

]

⊤ 表示

一个向量，每

个元素表示

一个变量的

方差。

因此，潜

变量的作用

是捕获不同

观测变量 xi 之

间的依赖关

系。实际上，可

以容

易地看

出

x 服从多维

正态分布，并

满足

x ∼

N (x; b,WW⊤ +

ψ). (13.4)

为了将

PCA 引入到概率

框架中，我们

可以对因子

分析模型作

轻微修改，使

条件

方差 σi

2 等

于同一个值

。在这种情况

下，x

的协方差

简化为 WW⊤ + σ

2

I，这里

的 σ

2

13.2 独立成分

分析 419

是一个

标量。由此可

以得到条件

分布，如下：

x ∼ N (x;

b,WW⊤ + σ

2

I), (13.5)

或

者等价地

x

= Wh + b

+ σz, (13.6)

其

中

z ∼ N (z;

0, I) 是高斯噪

声。之后 Tipping

and Bishop (1999) 提出

了一种迭代

的

EM 算法来估

计参数 W 和

σ

2。

这

个 概率

PCA（probabilistic PCA）模型

利用了这样

一种观察现

象：除了一

些

微小残余的

重构误差（reconstruction error）（至

多为

σ

2），数据中

的大多数变

化可以由潜

变量 h 描述。通

过Tipping

and Bishop (1999) 的研究我

们可以发现

，当

σ −→ 0 时，概率

PCA 退

化为 PCA。在这种

情况下，给定

x 情况下

h 的条

件期望等

于

将 x

− b 投影到 W

的

d 列所生成的

空间上，与 PCA 一

样。

当 σ −→ 0

时，概率

PCA 所定义的密

度函数在 d 维

的

W 的列生成

空间周围非

常尖锐。这导

致模型会为

没有在一个

超平面附近

聚集的数据

分配非常低

的概率。

13.2 独立

成分分析

独

立成分分析

（independent component analysis, ICA）是最古老的

表示学习算

法之一

(Herault and Ans, 1984;

Jutten and Herault, 1991;

Comon, 1994; Hyvärinen,

1999;

Hyvärinen et al., 2001a;

Hinton et al., 2001;

Teh et al., 2003)。它是

一种建模

线

性因子的方

法，旨在将观

察到的信号

分离成许多

潜在信号，这

些潜在信号

通过缩

放和

叠加可以恢

复成观察数

据。这些信号

是完全独立

的，而不是仅

仅彼此不相

关1。

许多不同

的具体方法

被称为 ICA。与我

们本书中描

述的其他生

成模型最相

似

的 ICA 变种 (Pham

et al., 1992) 训

练了完全参

数化的生成

模型。潜在因

子

h 的先验

p(h)，必

须由用户提

前给出并固

定。接着模型

确定性地生

成 x

= Wh。我们可以

通过

非线性

变化（使用式

(3.47) ）来确定

p(x)。然后

通过一般的

方法比如最

大化似然进

行学习。

这种

方法的动机

是，通过选择

一个独立的

p(h)，我们可以尽

可能恢复接

近独立

的潜

在因子。这是

一种常用的

方法，它并不

是用来捕捉

高级别的抽

象因果因子

，而是

1第

3.8 节讨

论了不相关

变量和独立

变量之间的

差异。

420 第十三

章

线性因子

模型

恢复已

经混合在一

起的低级别

信号。在该设

置中，每个训

练样本对应

一个时刻，每

个 xi 是一个传

感器对混合

信号的观察

值，并且每个

hi

是单个原始

信号的一个

估计。

例如，我

们可能有 n 个

人同时说话

。如果我们在

不同位置放

置

n 个不同的

麦克风，

则 ICA

可

以检测每个

麦克风的音

量变化，并且

分离信号，使

得每个 hi 仅包

含一个

人清

楚地说话。这

通常用于脑

电图的神经

科学，这种技

术可用于记

录源自大脑

的电

信号。放

置在受试者

头部上的许

多电极传感

器用于测量

来自身体的

多种电信号

。实

验者通常

仅对来自大

脑的信号感

兴趣，但是来

自受试者心

脏和眼睛的

信号强到足

以

混淆在受

试者头皮处

的测量结果

。信号到达电

极，并且混合

在一起，因此

为了分离

源

于心脏与源

于大脑的信

号，并且将不

同脑区域中

的信号彼此

分离，ICA

是必要

的。

如前所述

，ICA 存在许多变

种。一些版本

在 x

的生成中

添加一些噪

声，而不是

使

用确定性的

解码器。大多

数方法不使

用最大似然

准则，而是旨

在使 h =

W−1

x 的

元素

彼此独立。许

多准则能够

达成这个目

标。式(3.47)

需要用

到 W 的行列式

，这可

能是代

价很高且数

值不稳定的

操作。ICA

的一些

变种通过将

W 约束为正交

来避免

这个

有问题的操

作。

ICA

的所有变

种均要求 p(h) 是

非高斯的。这

是因为如果

p(h) 是具有高斯

分量

的独立

先验，则 W 是不

可识别的。对

于许多 W

值，我

们可以在 p(x) 上

获得相同

的

分布。这与其

他线性因子

模型有很大

的区别，例如

概率

PCA 和因子

分析通常要

求

p(h) 是高斯的

，以便使模型

上的许多操

作具有闭式

解。在用户明

确指定分布

的最大

似然

方法中，一个

典型的选择

是使用 p(hi) = dh

d

i

σ(hi)。这些

非高斯分布

的典型选择

在 0

附近具有

比高斯分布

更高的峰值

，因此我们也

可以看到独

立成分分析

经常用于

学

习稀疏特征

。

按照我们对

生成模型这

个术语的定

义，ICA 的许多变

种不是生成

模型。在本书

中，生成模型

可以直接表

示

p(x)，也可以认

为是从 p(x) 中抽

取样本。ICA 的许

多

变种仅知

道如何在 x 和

h 之间变换，而

没有任何表

示

p(h) 的方式，因

此也无法在

p(x) 上施加分布

。例如，许多 ICA

变

量旨在增加

h = W−1

x

的样本峰度

，因为高

峰度

说明了 p(h) 是非

高斯的，但这

是在没有显

式表示

p(h) 的情

况下完成的

。这就

是为什

么 ICA

多被用作

分离信号的

分析工具，而

不是用于生

成数据或估

计其密度。

正

如 PCA 可以推广

到第十四章

中描述的非

线性自编码

器，ICA

也可以推

广到

非线性

生成模型，其

中我们使用

非线性函数

f 来生成观测

数据。关于非

线性 ICA

最

初的

工作可以参

考 Hyvärinen and

Pajunen (1999)，它和集成

学习的成功

结合可以参

见 Roberts and

Everson (2001); Lappalainen et

al. (2000)。ICA 的另一个

非线性扩

展

是

非线性独

立成分估计

（nonlinear independent components estimation,

NICE）

13.3 慢特征分析

421

方法

(Dinh et al., 2014)，这个方

法堆叠了一

系列可逆变

换（在编码器

阶段），其特

性

是能高效地

计算每个变

换的 Jacobian 行列式

。这使得我们

能够精确地

计算似然，

并

且像

ICA 一样，NICE 尝

试将数据变

换到具有因

子的边缘分

布的空间。由

于非线

性编

码器的使用

，这种方法更

可能成功。因

为编码器和

一个能进行

完美逆变换

的解

码器相

关联，所以可

以直接从模

型生成样本

（首先从 p(h) 采样

，然后使用解

码器）。

ICA

的另一

个推广是通

过鼓励组内

统计依赖关

系、抑制组间

依赖关系来

学习

特征组

(Hyvärinen and Hoyer,

1999; Hyvärinen et al.,

2001b)。当相关单元

的组被

选为

不重叠时，这

被称为 独立

子空间分析

（independent subspace

analysis）。我们

还可以

向每个隐藏

单元分配空

间坐标，并且

空间上相邻

的单元组形

成一定程度

的重

叠。这能

够鼓励相邻

的单元学习

类似的特征

。当应用于自

然图像时，这

种 地质

ICA

（topographic ICA）方法

可以学习 Gabor

滤

波器，从而使

得相邻特征

具有相似的

方

向、位置或

频率。在每个

区域内出现

类似 Gabor 函数的

许多不同相

位存在抵消

作用，

使得在

小区域上的

池化产生了

平移不变性

。

13.3 慢特征分析

慢特征分析

（slow feature

analysis, SFA）是使用来自

时间信号的

信息学习不

变

特征的线

性因子模型

(Wiskott and

Sejnowski, 2002)。

慢特征分析

的想法源于

所谓的 慢性

原则（slowness

principle）。其基本

思想是，

与场

景中起描述

作用的单个

量度相比，场

景的重要特

性通常变化

得非常缓慢

。例如，

在计算

机视觉中，单

个像素值可

以非常快速

地改变。如果

斑马从左到

右移动穿过

图

像并且它

的条纹穿过

对应的像素

时，该像素将

迅速从黑色

变为白色，并

再次恢复成

黑色。通过比

较，指示斑马

是否在图像

中的特征将

不发生改变

，并且描述斑

马位置

的特

征将缓慢地

改变。因此，我

们可能希望

将模型正则

化，从而能够

学习到那些

随

时间变化

较为缓慢的

特征。

慢性原

则早于慢特

征分析，并已

被应用于各

种模型 (Hinton,

1989; Földiák, 1989;

Mobahi

et al., 2009; Bergstra

and Bengio, 2009)。一般

来说，我们可

以将慢性原

则应

用于可

以使用梯度

下降训练的

任何可微分

模型。为了引

入慢性原则

，我们可以向

代

价函数添

加以下项

λ

∑

t

L(f(x

(t+1)), f(x

(t)

)), (13.7)

422 第

十三章

线性

因子模型

其

中 λ 是确定慢

度正则化强

度的超参数

项，t

是样本时

间序列的索

引，f 是需要正

则

化的特征

提取器，L 是测

量

f(x

(t)

) 和

f(x

(t+1)) 之间的

距离的损失

函数。L 的一个

常见选择是

均方误差。

慢

特征分析是

慢性原则中

一个特别高

效的应用。由

于它被应用

于线性特征

提取

器，并且

可以通过闭

式解训练，所

以它是高效

的。像 ICA 的一些

变种一样，SFA

本

身并不是生

成模型，只是

在输入空间

和特征空间

之间定义了

一个线性映

射，但是没

有

定义特征空

间的先验，因

此没有在输

入空间上施

加分布 p(x)。

SFA

算法

(Wiskott and Sejnowski, 2002)

先将 f(x; θ) 定义为

线性变换，然

后求

解如下

优化问题

min

θ

Et(f(x

(t+1))i − f(x

(t)

)i)

2

(13.8)

并

且满足下面

的约束：

Etf(x

(t)

)i =

0 (13.9)

以及

Et

[f(x

(t)

)

2

i

] = 1. (13.10)

学习特征具

有零均值的

约束对于使

问题具有唯

一解是必要

的; 否则我们

可以向所有

特

征值添加

一个常数，并

获得具有相

等慢度目标

值的不同解

。特征具有单

位方差的约

束对于防止

所有特征趋

近于 0

的病态

解是必要的

。与 PCA 类似，SFA 特征

是有序

的，其

中学习第一

特征是最慢

的。要学习多

个特征，我们

还必须添加

约束

∀i < j,

Et

[f(x

(t)

)if(x

(t)

)j ] =

0. (13.11)

这要求

学习的特征

必须彼此线

性去相关。没

有这个约束

，所有学习到

的特征将简

单

地捕获一

个最慢的信

号。可以想象

使用其他机

制，如最小化

重构误差，也

可以迫使

特

征多样化。但

是由于 SFA 特征

的线性，这种

去相关机制

只能得到一

种简单的解

。

SFA

问题可以通

过线性代数

软件获得闭

式解。

在运行

SFA 之前，SFA 通常通

过对

x 使用非

线性的基扩

充来学习非

线性特征。

例

如，通常用 x

的

二次基扩充

来代替原来

的 x，得到一个

包含所有 xixj 的

向量。由

此，我

们可以通过

反复地学习

一个线性 SFA 特

征提取器，对

其输出应用

非线性基扩

展，然后在该

扩展之上学

习另一个线

性 SFA

特征提取

器的方式来

组合线性 SFA 模

块从而学习

深度非线性

慢特征提取

器。

13.4

稀疏编码

423

当在自然场

景视频的小

块空间部分

上训练时，使

用二次基扩

展的 SFA 所学习

到的特征与

V1

皮层中那些

复杂细胞的

特征有许多

共同特性 (Berkes and Wiskott,

2005)。当

在计算机渲

染的 3D 环境内

随机运动的

视频上训练

时，深度 SFA

模型

能

够学习的

特征与大鼠

脑中用于导

航的神经元

学到的特征

有许多共同

特性 (Franzius

et

al., 2007)。因此从

生物学角度

上来说 SFA 是一

个合理的有

依据的模型

。

SFA 的一个主要

优点是，即使

在深度非线

性条件下，它

依然能够在

理论上预

测

SFA 能够学习哪

些特征。为了

做出这样的

理论预测，必

须知道关于

配置空间的

环

境动力（例

如，在 3D 渲染环

境中随机运

动的例子中

，理论分析是

从相机位置

、速度

的概率

分布中入手

的）。已知潜在

因子如何改

变的情况下

，我们能够通

过理论分析

解

出表达这

些因子的最

佳函数。在实

践中，基于模

拟数据的实

验上，使用深

度 SFA 似

乎能够

恢复理论预

测的函数。相

比之下，在其

他学习算法

中，代价函数

高度依赖于

特定像素值

，使得难以确

定模型将学

习到什么特

征。

深度 SFA 也已

经被用于学

习用在对象

识别和姿态

估计的特征

(Franzius et

al.,

2008)。到目前为止

，慢性原则尚

未成为任何

最先进应用

的基础。究竟

是什么因素

限

制了其性

能仍有待研

究。我们推测

，或许慢度先

验太过强势

，并且，最好添

加这样

一个

先验使得当

前时间步到

下一个时间

步的预测更

加容易，而不

是加一个先

验使得

特征

近似为一个

常数。对象的

位置是一个

有用的特征

，无论对象的

速度是高还

是低。

但慢性

原则鼓励模

型忽略具有

高速度的对

象的位置。

13.4 稀

疏编码

稀疏

编码（sparse coding） (Olshausen and

Field, 1996) 是一个

线性因子模

型，

已作为一

种无监督特

征学习和特

征提取机制

得到了广泛

研究。严格来

说，术语

“稀疏

编码’’ 是指在

该模型中推

断 h 值的过程

，而

‘‘稀疏建模

’’ 是指设计和

学习模型的

过

程，但是通

常这两个概

念都可以用

术语 “稀疏编

码’’

描述。

像大

多数其他线

性因子模型

一样，它使用

了线性的解

码器加上噪

声的方式获

得

一个 x

的重

构，就像式 (13.2) 描

述的一样。更

具体地说，稀

疏编码模型

通常假设线

性因子有一

个各向同性

精度为 β

的高

斯噪声：

p(x | h)

= N (x;Wh +

b,

1

β

I).

(13.12)

分布

p(h) 通常选取为

一个峰值很

尖锐且接近

0 的分布

(Olshausen and Field,

424

第十

三章 线性因

子模型

1996)。常见

的选择包括

可分解的 Laplace、Cauchy

或

者可分解的

Student-t 分布。

例如，以

稀疏惩罚系

数 λ

为参数的

Laplace 先验可以表

示为

p(hi) =

Laplace(hi

; 0,

2

λ

) = λ

4

e

− 1

2

λ|hi|

, (13.13)

相应的

，Student-t 先验分布可

以表示为

p(hi) ∝

1

(1 + h

2

ν

i

)

ν+1

2

. (13.14)

使

用最大似然

的方法来训

练稀疏编码

模型是不可

行的。相反，为

了在给定编

码

的情况下

更好地重构

数据，训练过

程在编码数

据和训练解

码器之间交

替进行。稍后

在第 19.3 节中，这

种方法将被

进一步证明

为是解决最

大似然问题

的一种通用

的近似

方法

。

对于诸如 PCA 的

模型，我们已

经看到使用

了预测

h 的参

数化的编码

器函数，

并且

该函数仅包

括乘以权重

矩阵。稀疏编

码中的编码

器不是参数

化的编码器

。相反，

编码器

是一个优化

算法，在这个

优化问题中

，我们寻找单

个最可能的

编码值：

h

∗ = f(x)

= arg max

h

p(h | x). (13.15)

结合

式 (13.13) 和式 (13.12)

，我们

得到如下的

优化问题：

arg max

h

p(h | x) (13.16)

= arg max

h

log p(h | x)

(13.17)

= arg min

h

λ∥h∥1 + β∥x

− Wh∥

2

2

, (13.18)

其

中，我们扔掉

了与 h

无关的

项，并除以一

个正的缩放

因子来简化

表达。

由于在

h 上施加 L

1 范数

，这个过程将

产生稀疏的

h

∗（详见第 7.1.2

节）。

为

了训练模型

而不仅仅是

进行推断，我

们交替迭代

关于 h 和

W 的最

小化过程。

在

本文中，我们

将 β

视为超参

数。我们通常

将其设置为

1，因为它在此

优化问题的

作用与 λ 类似

，没有必要使

用两个超参

数。原则上，我

们还可以将

β 作为模型的

参

数，并学习

它。我们在这

里已经放弃

了一些不依

赖于 h 但依赖

于 β

的项。要学

习 β，

必须包含

这些项，否则

β 将退化为

0。

不

是所有的稀

疏编码方法

都显式地构

建了一个 p(h) 和

一个

p(x | h)。通常我

们

只是对学

习一个带有

激活值的特

征的字典感

兴趣，当特征

是由这个推

断过程提取

时，

这个激活

值通常为 0。

13.4 稀

疏编码

425

如果

我们从 Laplace 先验

中采样

h，h 的元

素实际上为

0 是一个零概

率事件。生

成

模型本身并

不稀疏，只有

特征提取器

是稀疏的。Goodfellow

et al. (2013f) 描

述了

不同模

型族中的近

似推断，如尖

峰和平板稀

疏编码模型

，其中先验的

样本通常包

含

许多真正

的 0。

与非参数

编码器结合

的稀疏编码

方法原则上

可以比任何

特定的参数

化编码器更

好地最小化

重构误差和

对数先验的

组合。另一个

优点是编码

器没有泛化

误差。参数

化

的编码器必

须泛化地学

习如何将 x 映

射到 h。对于与

训练数据差

异很大的异

常

x，所学习的

参数化编码

器可能无法

找到对应精

确重构或稀

疏的编码 h。对

于稀疏编

码

模型的绝大

多数形式，推

断问题是凸

的，优化过程

总能找到最

优编码（除非

出现

退化的

情况，例如重

复的权重向

量）。显然，稀疏

和重构成本

仍然可以在

不熟悉的点

上升，但这归

因于解码器

权重中的泛

化误差，而不

是编码器中

的泛化误差

。当稀疏

编码

用作分类器

的特征提取

器，而不是使

用参数化的

函数来预测

编码值时，基

于优

化的稀

疏编码模型

的编码过程

中较小的泛

化误差可以

得到更好的

泛化能力。Coates

and Ng

(2011) 证

明了在对象

识别任务中

稀疏编码特

征比基于参

数化的编码

器（线

性-sigmoid 自编

码器）的特征

拥有更好的

泛化能力。受

他们的工作

启发，Goodfellow

et al. (2013f) 表明一

种稀疏编码

的变体在标

签极少（每类

20

个或更少标

签）的情况

中

比相同情况

下的其他特

征提取器拥

有更好的泛

化能力。

非参

数编码器的

主要缺点是

在给定 x

的情

况下需要大

量的时间来

计算 h，因为

非

参数方法需

要运行迭代

算法。在第十

四章中讲到

的参数化自

编码器方法

仅使用固

定

数量的层，通

常只有一层

。另一个缺点

是它不直接

通过非参数

编码器进行

反向传

播，这

使得我们很

难采用先使

用无监督方

式预训练稀

疏编码模型

然后使用监

督方式

对其

进行精调的

方法。允许近

似导数的稀

疏编码模型

的修改版本

确实存在但

未被广

泛使

用 (Bagnell

and Bradley, 2009)。

像其他线

性因子模型

一样，稀疏编

码经常产生

糟糕的样本

，如图

13.2 所示。即

使当模型能

够很好地重

构数据并为

分类器提供

有用的特征

时，也会发生

这种情况。

这

种现象发生

的原因是每

个单独的特

征可以很好

地被学习到

，但是隐藏编

码值的因

子

先验会导致

模型包括每

个生成样本

中所有特征

的随机子集

。这促使人们

开发更深

的

模型，可以在

其中最深的

编码层施加

一个非因子

分布，与此同

时也在开发

一些复

杂的

浅度模型。

426 第

十三章

线性

因子模型

图

13.2: 尖峰和平板

稀疏编码模

型上在 MNIST

数据

集训练的样

例和权重。(左

) 这个模型中

的样

本和训

练样本相差

很大。第一眼

看来，我们可

能认为模型

拟合得很差

。(右) 这个模型

的权重向量

已经学习到

了如何表示

笔迹，有时候

还能写完整

的数字。因此

这个模型也

学习到了有

用的特征。问

题在于特征

的因子先验

会导致特征

子集合随机

的组合。一些

这样的子集

能够合成可

识别的

MNIST

集上

的数字。这也

促进了拥有

更强大潜在

编码分布的

生成模型的

发展。此图经

Goodfellow et al.

(2013f) 允许转载。

13.5 PCA的

流形解释

线

性因子模型

，包括 PCA 和因子

分析，可以理

解为学习一

个流形 (Hinton

et al.,

1997)。我们

可以将概率

PCA 定义为高概

率的薄饼状

区域，即一个

高斯分布，沿

着

某些轴非

常窄，就像薄

饼沿着其垂

直轴非常平

坦，但沿着其

他轴是细长

的，正如薄

饼

在其水平轴

方向是很宽

的一样。图 13.3 解

释了这种现

象。PCA

可以理解

为将该薄

饼

与更高维空

间中的线性

流形对准。这

种解释不仅

适用于传统

PCA，而且适用于

学

习矩阵 W

和

V 的任何线性

自编码器，其

目的是使重

构的 x 尽可能

接近于原始

的

x。

编码器表

示为

h =

f(x) = W⊤

(x

− µ). (13.19)

编码器

计算

h 的低维

表示。从自编

码器的角度

来看，解码器

负责计算重

构：

xˆ =

g(h) = b +

Vh. (13.20)

能够最小

化重构误差

E[∥x −

xˆ∥

2

] (13.21)

13.5 PCA的流形解释

427

图 13.3:

平坦的高

斯能够描述

一个低维流

形附近的概

率密度。此图

表示了 “流形

平面’’ 上 ‘‘馅饼

’’

的上半部分

，并且这个平

面穿过了馅

饼的中心。正

交于流形方

向（指向平面

外的箭头方

向）的方差

非

常小，可以被

视作是 ‘‘噪声

’’，其他方向（平

面内的箭头

）的方差则很

大，对应了 ‘‘信

号’’

以及

降维

数据的坐标

系统。

的线性

编码器和解

码器的选择

对应着 V

= W，µ = b

= E[x]，W 的列

形成一组标

准

正交基，这

组基生成的

子空间与协

方差矩阵

C

C = E[(x

− µ)(x − µ)

⊤] (13.22)

的

主特征向量

所生成的子

空间相同。在

PCA 中，W

的列是按

照对应特征

值（其全

部是

实数和非负

数）幅度大小

排序所对应

的特征向量

。

我们还可以

发现 C

的特征

值 λi 对应了 x

在

特征向量 v

(i) 方

向上的方差

。如果

x ∈ R

D，h

∈ R

d 并且满

足

d < D，则（给定上

述的 µ,

b, V,W 的情况

下）最佳的重

构误差是

min

E[∥x − xˆ∥

2

] =

D

∑

i=d+1

λi

. (13.23)

因

此，如果协方

差矩阵的秩

为 d，则特征值

λd+1 到 λD

都为 0，并且

重构误差为

0。

此外，我们还

可以证明上

述解可以通

过在给定正

交矩阵 W

的情

况下最大化

h

元素的方差

而不是最小

化重构误差

来获得。

428 第十

三章

线性因

子模型

某种

程度上说，线

性因子模型

是最简单的

生成模型和

学习数据表

示的最简单

模

型。许多模

型如线性分

类器和线性

回归模型可

以扩展到深

度前馈网络

，而这些线性

因子模型可

以扩展到自

编码器网络

和深度概率

模型，它们可

以执行相同

任务但具有

更强大和更

灵活的模型

族。

第十四章

自编码器

自

编码器（autoencoder）是神

经网络的一

种，经过训练

后能尝试将

输入复制到

输出。 自编码

器（autoencoder）内部有一

个隐藏层 h，可

以产生 编码

（code）表示

输入。该

网络可以看

作由两部分

组成：一个由

函数 h = f(x)

表示的

编码器和一

个生

成重构

的解码器 r =

g(h)。图

14.1 展示了这种

架构。如果一

个自编码器

只是简单地

学会将处处

设置为 g(f(x)) =

x，那么

这个自编码

器就没什么

特别的用处

。相反，我

们不

应该将自编

码器设计成

输入到输出

完全相等。这

通常需要向

自编码器强

加一些

约束

，使它只能近

似地复制，并

只能复制与

训练数据相

似的输入。这

些约束强制

模

型考虑输

入数据的哪

些部分需要

被优先复制

，因此它往往

能学习到数

据的有用特

性。

现代自编

码器将编码

器和解码器

的概念推而

广之，将其中

的确定函数

推广为随

机

映射 pencoder(h |

x) 和 pdecoder(x |

h)。

数十

年间，自编码

器的想法一

直是神经网

络历史景象

的一部分 (LeCun, 1987;

Bourlard and Kamp, 1988;

Hinton and Zemel, 1994)。传

统自编码器

被用于降维

或

特征学习

。近年来，自编

码器与潜变

量模型理论

的联系将自

编码器带到

了生成式建

模的前沿，我

们将在第二

十章揭示更

多细节。自编

码器可以被

看作是前馈

网络的一

个

特例，并且可

以使用完全

相同的技术

进行训练，通

常使用小批

量梯度下降

法（其

中梯度

基于反向传

播计算）。不同

于一般的前

馈网络，自编

码器也可以

使用 再循环

（recirculation）训练

(Hinton and McClelland, 1988)，这种学

习算法基于

比较原始

输

入的激活和

重构输入的

激活。相比反

向传播算法

，再循环算法

更具生物学

意义，但

很少

用于机器学

习应用。

429

430

第十

四章 自编码

器

x r

h

f g

图

14.1: 自编码

器的一般结

构，通过内部

表示或编码

h 将输入 x

映射

到输出（称为

重构）r。自编

码

器具有两个

组件：编码器

f（将 x 映射到

h）和

解码器 g（将 h 映

射到

r）。

14.1 欠完备

自编码器

将

输入复制到

输出听起来

没什么用，但

我们通常不

关心解码器

的输出。相反

，我

们希望通

过训练自编

码器对输入

进行复制而

使 h 获得有用

的特性。

从自

编码器获得

有用特征的

一种方法是

限制

h 的维度

比 x 小，这种编

码维度

小于

输入维度的

自编码器称

为 欠完备（undercomplete）自

编码器。学习

欠完备的表

示将强制自

编码器捕捉

训练数据中

最显著的特

征。

学习过程

可以简单地

描述为最小

化一个损失

函数

L(x,

g(f(x))), (14.1)

其中 L

是

一个损失函

数，惩罚 g(f(x)) 与 x

的

差异，如均方

误差。

当解码

器是线性的

且 L 是均方误

差，欠完备的

自编码器会

学习出与

PCA 相

同

的生成子

空间。这种情

况下，自编码

器在训练来

执行复制任

务的同时学

到了训练数

据的主元子

空间。

因此，拥

有非线性编

码器函数

f 和

非线性解码

器函数 g 的自

编码器能够

学习出

更强

大的 PCA 非线性

推广。不幸的

是，如果编码

器和解码器

被赋予过大

的容量，自

编

码器会执行

复制任务而

捕捉不到任

何有关数据

分布的有用

信息。从理论

上说，我们

可

以设想这样

一个自编码

器，它只有一

维编码，但它

具有一个非

常强大的非

线性编

码器

，能够将每个

训练数据 x

(i)

表

示为编码 i。而

解码器可以

学习将这些

整数索引

映

射回特定训

练样本的值

。这种特定情

形不会在实

际情况中发

生，但它清楚

地说明，

如果

自编码器的

容量太大，那

训练来执行

复制任务的

自编码器可

能无法学习

到数据

集的

任何有用信

息。

14.2 正则自编

码器 431

14.2 正则自

编码器

编码

维数小于输

入维数的欠

完备自编码

器可以学习

数据分布最

显著的特征

。我

们已经知

道，如果赋予

这类自编码

器过大的容

量，它就不能

学到任何有

用的信息。

如

果隐藏编码

的维数允许

与输入相等

，或隐藏编码

维数大于输

入的 过完备

（overcomplete）情况下，会发

生类似的问

题。在这些情

况下，即使是

线性编码器

和

线性解码

器也可以学

会将输入复

制到输出，而

学不到任何

有关数据分

布的有用信

息。

理想情况

下，根据要建

模的数据分

布的复杂性

，选择合适的

编码维数和

编码器、

解码

器容量，就可

以成功训练

任意架构的

自编码器。正

则自编码器

提供这样的

能力。

正则自

编码器使用

的损失函数

可以鼓励模

型学习其他

特性（除了将

输入复制到

输

出），而不必

限制使用浅

层的编码器

和解码器以

及小的编码

维数来限制

模型的容量

。

这些特性包

括稀疏表示

、表示的小导

数、以及对噪

声或输入缺

失的鲁棒性

。即使模

型容

量大到足以

学习一个无

意义的恒等

函数，非线性

且过完备的

正则自编码

器仍然

能够

从数据中学

到一些关于

数据分布的

有用信息。

除

了这里所描

述的方法（正

则化自编码

器最自然的

解释），几乎任

何带有潜变

量并配有一

个推断过程

（计算给定输

入的潜在表

示）的生成模

型，都可以看

作是自

编码

器的一种特

殊形式。强调

与自编码器

联系的两个

生成式建模

方法是

Helmholtz

机 (Hinton et

al., 1995b) 的

衍生模型，如

变分自编码

器（第 20.10.3

节）和生

成随机

网络

（第20.12 节）。这些变

种（或衍生）自

编码器能够

学习出高容

量且过完备

的模

型，进而

发现输入数

据中有用的

结构信息，并

且也无需对

模型进行正

则化。这些编

码显然是有

用的，因为这

些模型被训

练为近似训

练数据的概

率分布而不

是将输入复

制到输出。

14.2.1 稀

疏自编码器

稀疏自编码

器简单地在

训练时结合

编码层的稀

疏惩罚 Ω(h) 和重

构误差：

L(x, g(f(x))) + Ω(h),

(14.2)

其中

g(h) 是解码器的

输出，通常 h

是

编码器的输

出，即 h = f(x)。

稀疏自

编码器一般

用来学习特

征，以便用于

像分类这样

的任务。稀疏

正则化的自

编码器必须

反映训练数

据集的独特

统计特征，而

不是简单地

充当恒等函

数。以这种

方

式训练，执行

附带稀疏惩

罚的复制任

务可以得到

能学习有用

特征的模型

。

432 第十四章

自

编码器

我们

可以简单地

将惩罚项 Ω(h) 视

为加到前馈

网络的正则

项，这个前馈

网络的

主要

任务是将输

入复制到输

出（无监督学

习的目标），并

尽可能地根

据这些稀疏

特征

执行一

些监督学习

任务（根据监

督学习的目

标）。不像其它

正则项如权

重衰减——没

有

直观的贝叶

斯解释。如第

5.6.1 节描述，权重

衰减和其他

正则惩罚可

以被解释为

一

个 MAP 近似贝

叶斯推断，正

则化的惩罚

对应于模型

参数的先验

概率分布。这

种观点

认为

，正则化的最

大似然对应

最大化

p(θ | x)，相当

于最大化 log

p(x | θ) +

log p(θ)。

log p(x

| θ) 即

通常的数据

似然项，参数

的对数先验

项 log

p(θ) 则包含了

对 θ 特定值

的

偏好。这种观

点在第 5.6 节有

所描述。正则

自编码器不

适用这样的

解释是因为

正则

项取决

于数据，因此

根据定义上

（从文字的正

式意义）来说

，它不是一个

先验。虽

然如

此，我们仍可

以认为这些

正则项隐式

地表达了对

函数的偏好

。

我们可以认

为整个稀疏

自编码器框

架是对带有

潜变量的生

成模型的近

似最大似

然

训练，而不将

稀疏惩罚视

为复制任务

的正则化。假

如我们有一

个带有可见

变量 x

和潜变

量 h 的模型，且

具有明确的

联合分布 pmodel(x,

h) = pmodel(h)pmodel(x |

h)。我

们将 pmodel(h) 视为模

型关于潜变

量的先验分

布，表示模型

看到 x

的信念

先验。这与

我

们之前使用

‘‘先验’’ 的方式

不同，之前指

分布 p(θ)

在我们

看到数据前

就对模型参

数的先验进

行编码。对数

似然函数可

分解为

log pmodel(x) =

log∑

h

pmodel(h, x).

(14.3)

我们

可以认为自

编码器使用

一个高似然

值 h 的点估计

近似这个总

和。这类似于

稀疏

编码生

成模型（第 13.4 节

），但 h

是参数编

码器的输出

，而不是从优

化结果推断

出的

最可能

的 h。从这个角

度看，我们根

据这个选择

的 h，最大化如

下

log pmodel(h, x) =

log pmodel(h) + log

pmodel(x | h). (14.4)

log pmodel(h) 项能被稀

疏诱导。如Laplace先

验，

pmodel(hi)

= λ

2

e

−λ|hi|

, (14.5)

对应于绝

对值稀疏惩

罚。将对数先

验表示为绝

对值惩罚，我

们得到

Ω(h) = λ

∑

i

|hi

|, (14.6)

− log pmodel(h) =

∑

i

(λ|hi

|

− log λ

2

) = Ω(h) +

const, (14.7)

14.2 正则

自编码器

433

这

里的常数项

只跟 λ 有关。通

常我们将

λ 视

为超参数，因

此可以丢弃

不影响参数

学

习的常数

项。其他如 Student-t

先

验也能诱导

稀疏性。从稀

疏性导致 pmodel(h) 学

习

成近似最

大似然的结

果看，稀疏惩

罚完全不是

一个正则项

。这仅仅影响

模型关于潜

变量的分布

。这个观点提

供了训练自

编码器的另

一个动机：这

是近似训练

生成模型的

一种途径。这

也给出了为

什么自编码

器学到的特

征是有用的

另一个解释

：它们描述

的

潜变量可以

解释输入。

稀

疏自编码器

的早期工作

(Ranzato et al.,

2007a, 2008) 探讨了各种

形式的稀

疏

性，并提出了

稀疏惩罚和

logZ

项（将最大似

然应用到无

向概率模型

p(x) = Z

1

p˜(x)

时产生）之间

的联系。这个

想法是最小

化 logZ 防止概率

模型处处具

有高概率，同

理

强制稀疏

可以防止自

编码器处处

具有低的重

构误差 。这种

情况下，这种

联系是对通

用机制的直

观理解而不

是数学上的

对应。在数学

上更容易解

释稀疏惩罚

对应于有向

模型 pmodel(h)pmodel(x |

h) 中的 log pmodel(h)。

Glorot et al. (2011b)

提

出了一种在

稀疏（和去噪

）自编码器的

h 中实现真正

为

零的方式

。该想法是使

用整流线性

单元产生编

码层。基于将

表示真正推

向零（如绝

对

值惩罚）的先

验，可以间接

控制表示中

零的平均数

量。

14.2.2 去噪自编

码器

除了向

代价函数增

加一个惩罚

项，我们也可

以通过改变

重构误差项

来获得一个

能学到有用

信息的自编

码器。

传统的

自编码器最

小化以下目

标

L(x, g(f(x))), (14.8)

其中

L 是一

个损失函数

，惩罚 g(f(x)) 与

x 的差

异，如它们彼

此差异的 L

2

范

数。如

果模型

被赋予过大

的容量，L 仅仅

使得 g

◦ f 学成一

个恒等函数

。

相反，

去噪自

编码器（denoising autoencoder, DAE）最小

化

L(x,

g(f(x˜))), (14.9)

其中 x˜

是被

某种噪声损

坏的 x 的副本

。因此去噪自

编码器必须

撤消这些损

坏，而不

是简

单地复制输

入。

Alain and Bengio (2013)

和 Bengio et al.

(2013c) 指出去

噪训练过程

强制 f 和

g 隐式

地学习 pdata(x) 的结

构。因此去噪

自编码器也

是一个通过

最小化重构

误差获

434 第十

四章 自编码

器

取有用特

性的例子。这

也是将过完

备、高容量的

模型用作自

编码器的一

个例子——

只要

小心防止这

些模型仅仅

学习一个恒

等函数。去噪

自编码器将

在第 14.5 节给出

更

多细节。

14.2.3 惩

罚导数作为

正则

另一正

则化自编码

器的策略是

使用一个类

似稀疏自编

码器中的惩

罚项 Ω，

L(x, g(f(x))) + Ω(h,

x), (14.10)

但 Ω

的形

式不同：

Ω(h, x) =

λ

∑

i

∥∇xhi∥

2

. (14.11)

这迫

使模型学习

一个在

x 变化

小时目标也

没有太大变

化的函数。因

为这个惩罚

只对训练数

据适用，它迫

使自编码器

学习可以反

映训练数据

分布信息的

特征。

这样正

则化的自编

码器被称为

收缩自编码

器（contractive autoencoder,

CAE）。

这种方法

与去噪自编

码器、流形学

习和概率模

型存在一定

理论联系。收

缩自编码器

将

在第 14.7

节更

详细地描述

。

14.3 表示能力、层

的大小和深

度

自编码器

通常只有单

层的编码器

和解码器，但

这不是必然

的。实际上深

度编码

器和

解码器能提

供更多优势

。

回忆第 6.4.1 节，其

中提到加深

前馈网络有

很多优势。这

些优势也同

样适用于自

编码器，因为

它也属于前

馈网络。此外

，编码器和解

码器各自都

是一个前馈

网络，因

此这

两个部分也

能各自从深

度结构中获

得好处。

万能

近似定理保

证至少有一

层隐藏层且

隐藏单元足

够多的前馈

神经网络能

以任

意精度

近似任意函

数（在很大范

围里），这是非

平凡深度（至

少有一层隐

藏层）的一

个

主要优点。这

意味着具有

单隐藏层的

自编码器在

数据域内能

表示任意近

似数据的

恒

等函数。但是

，从输入到编

码的映射是

浅层的。这意

味这我们不

能任意添加

约束，

比如约

束编码稀疏

。深度自编码

器（编码器至

少包含一层

额外隐藏层

）在给定足够

多的隐藏单

元的情况下

，能以任意精

度近似任何

从输入到编

码的映射。

14.4 随

机编码器和

解码器

435

深度

可以指数地

降低表示某

些函数的计

算成本。深度

也能指数地

减少学习一

些

函数所需

的训练数据

量。读者可以

参考第 6.4.1

节巩

固深度在前

馈网络中的

优势。

实验中

，深度自编码

器能比相应

的浅层或线

性自编码器

产生更好的

压缩效率

(Hinton and

Salakhutdinov, 2006)。

训

练深度自编

码器的普遍

策略是训练

一堆浅层的

自编码器来

贪心地预训

练相应

的深

度架构。所以

即使最终目

标是训练深

度自编码器

，我们也经常

会遇到浅层

自编

码器。

14.4 随

机编码器和

解码器

自编

码器本质上

是一个前馈

网络，可以使

用与传统前

馈网络相同

的损失函数

和

输出单元

。

如第 6.2.2.4 节中描

述，设计前馈

网络的输出

单元和损失

函数普遍策

略是定义一

个输出分布

p(y

| x) 并最小化负

对数似然 −

log p(y | x)。在

这种情况下

，y

是关于目

标

的向量（如类

标）。

在自编码

器中，x 既是输

入也是目标

。然而，我们仍

然可以使用

与之前相同

的架

构。给定

一个隐藏编

码 h，我们可以

认为解码器

提供了一个

条件分布 pmodel(x |

h)。

接

着我们根据

最小化 − log

pdecoder(x | h) 来训

练自编码器

。损失函数的

具体形式视

pdecoder

的形式而定

。就传统的前

馈网络来说

，如果 x 是实值

的，那么我们

通常使用

线

性输出单元

参数化高斯

分布的均值

。在这种情况

下，负对数似

然对应均方

误差准

则。类

似地，二值 x 对

应于一个 Bernoulli

分

布，其参数由

sigmoid 输出单元确

定

的。而离散

的 x

对应 softmax 分布

，以此类推。在

给定 h

的情况

下，为了便于

计算

概率分

布，输出变量

通常被视为

是条件独立

的，但一些技

术（如混合密

度输出）可

以

解决输出相

关的建模。

为

了更彻底地

与我们之前

了解到的前

馈网络相区

别，我们也可

以将编码函

数

(encoding function) f(x) 的概念推

广为编码分

布

(encoding distribution) pencoder(h |

x)，如图 14.2 中所

示。

任何潜变

量模型

pmodel(h, x) 定义

一个随机编

码器

pencoder(h

| x) = pmodel(h

| x) (14.12)

436

第十四

章 自编码器

x r

h

pencoder(h | x) pdecoder(x

| h)

图 14.2:

随机自编

码器的结构

，其中编码器

和解码器包

括一些噪声

注入，而不是

简单的函数

。这

意味着可

以将它们的

输出视为来

自分布的采

样（对于编码

器是 pencoder(h |

x)，对于解

码器是

pdecoder(x | h)）。

以及

一个随机解

码器

pdecoder(x | h)

= pmodel(x | h).

(14.13)

通常情

况下，编码器

和解码器的

分布没有必

要是与唯一

一个联合分

布 pmodel(x, h)

相

容的条

件分布。Alain et al.

(2015) 指出

，在保证足够

的容量和样

本的情况下

，将编

码器和

解码器作为

去噪自编码

器训练，能使

它们渐近地

相容。

14.5

去噪自

编码器

去噪

自编码器（denoising autoencoder, DAE）是

一类接受损

坏数据作为

输入，

并训练

来预测原始

未被损坏数

据作为输出

的自编码器

。

DAE 的训练过程

如图 14.3

中所示

。我们引入一

个损坏过程

C(x˜ | x)，这个条件

分

布代表给定

数据样本

x 产

生损坏样本

x˜ 的概率。自编

码器则根据

以下过程，从

训

练数据对

(x,

x˜) 中学习重构

分布 (reconstruction distribution)

preconstruct(x | x˜)：

1.

从训练

数据中采一

个训练样本

x。

2. 从 C(x˜

| x = x)

采一个损

坏样本 x˜。

3. 将

(x, x˜) 作

为训练样本

来估计自编

码器的重构

分布 preconstruct(x

| x˜) =

pdecoder(x

| h)，其中 h 是

编码器

f(x˜) 的输

出，pdecoder 根据解码

函数 g(h)

定

义。

通

常我们可以

简单地对负

对数似然 −

log pdecoder(x | h)

进

行基于梯度

法（如小批

14.5 去

噪自编码器

437

量梯度下降

）的近似最小

化。只要编码

器是确定性

的，去噪自编

码器就是一

个前馈

网络

，并且可以使

用与其他前

馈网络完全

相同的方式

进行训练。

xx˜˜ L

h

f g

x

C(x˜

| x)

图

14.3: 去噪自编码

器代价函数

的计算图。去

噪自编码器

被训练为从

损坏的版本

x˜

重构干净数

据

点 x。这可以

通过最小化

损失 L

= − log pdecoder(x

| h = f(x˜))

实现，其

中 x˜ 是样本 x

经

过损坏过

程

C(x˜ | x)

后得到的损

坏版本。通常

，分布 pdecoder 是因子

的分布（平均

参数由前馈

网络 g

给出）。

因

此我们可以

认为 DAE 是在以

下期望下进

行随机梯度

下降：

−Ex∼pˆdata(x)Ex˜∼C(x˜|x)

log pdecoder(x |

h = f(x˜)), (14.14)

其中 pˆdata(x) 是

训练数据的

分布。

14.5.1

得分估

计

得分匹配

(Hyvärinen, 2005a) 是最大似然

的代替。它提

供了概率分

布的一致估

计，促使模型

在各个数据

点

x 上获得与

数据分布相

同的 得分（score）。在

这种情况

下

，得分是一个

特定的梯度

场：

∇x log p(x). (14.15)

我们将在

第 18.4 节中更详

细地讨论得

分匹配。对于

现在讨论的

自编码器，理

解

学习

log pdata 的梯

度场是学习

pdata 结构的一种

方式就足够

了。

DAE 的训练准

则（条件高斯

p(x | h)）能让自编码

器学到能估

计数据分布

得分

的向量

场 (g(f(x)) − x)

，这是 DAE 的一

个重要特性

。具体如图 14.4

所

示。

对一类采

用高斯噪声

和均方误差

作为重构误

差的特定去

噪自编码器

（具有 sig￾moid 隐藏单

元和线性重

构单元）的去

噪训练过程

，与训练一类

特定的被称

为

RBM 的

438 第十四

章

自编码器

x

x˜

g ◦

f

x˜

C(x˜ |

x)

x

图 14.4:

去噪自编

码器被训练

为将损坏的

数据点 x˜ 映射

回原始数据

点 x。我们将训

练样本

x 表示

为位于低维

流形（粗黑线

）附近的红叉

。我们用灰色

圆圈表示等

概率的损坏

过程 C(x˜ |

x)。灰色箭

头演示了如

何将一个训

练样本转换

为经过此损

坏过程的样

本。当训练去

噪自编码器

最小化平方

误

差 ∥g(f(x˜)) −

x∥

2 的平均

值时，重构 g(f(x˜))

估

计 Ex,x˜∼pdata(x)C(x˜|x)[x | x˜]。g(f(x˜))

对可能产

生

x˜ 的原始点

x 的质心进行

估计，所以向

量

g(f(x˜)) − x˜ 近似指向

流形上最近

的点。因此自

编码器可

以

学习由绿色

箭头表示的

向量场 g(f(x)) − x。该向

量场将得分

∇x

log pdata(x) 估计为一个

乘性因

子，即

重构误差均

方根的平均

。

无向概率模

型是等价的

(Vincent, 2011)。这类模型将

在第 20.5.1 节给出

更详细的介

绍；对于现在

的讨论，我们

只需知道这

个模型能显

式的给出

pmodel(x; θ)。当

RBM 使

用

去噪得

分匹配（denoising score matching）算法

(Kingma and

LeCun, 2010a) 训

练时，它的

学习算法与

训练对应的

去噪自编码

器是等价的

。在一个确定

的噪声水平

下，正则化的

得分匹配不

是一致估计

量；相反它会

恢复分布的

一个模糊版

本。然而，

当噪

声水平趋向

于 0 且训练样

本数趋向于

无穷时，一致

性就会恢复

。我们将会在

第 18.5

节更详细

地讨论去噪

得分匹配。

自

编码器和 RBM 还

存在其他联

系。在

RBM 上应用

得分匹配后

，其代价函数

将

等价于重

构误差结合

类似 CAE

惩罚的

正则项 (Swersky et al.,

2011)。Bengio and

Delalleau (2009)

指出

自编码器的

梯度是对 RBM 对

比散度训练

的近似。

对于

连续的

x，高斯

损坏和重构

分布的去噪

准则得到的

得分估计适

用于一般编

14.5 去噪自编码

器 439

码器和解

码器的参数

化

(Alain and Bengio, 2013)。这意味着

一个使用平

方误差准则

∥g(f(x˜))

− x∥

2

(14.16)

和噪声方差

为 σ

2 的损坏

C(˜x = x˜ |

x) = N(x˜; µ

= x, Σ =

σ

2

I) (14.17)

的

通用编码器

-解码器架构

可以用来训

练估计得分

。图 14.5 展示其中

的工作原理

。

图

14.5: 由去噪自

编码器围绕

1 维弯曲流形

学习的向量

场，其中数据

集中在 2

维空

间中。每个箭

头与重构向

量减去自编

码器的输入

向量后的向

量成比例，并

且根据隐式

估计的概率

分布指向较

高

的概率。向

量场在估计

的密度函数

的最大值处

（在数据流形

上）和密度函

数的最小值

处都为零。例

如，螺旋臂形

成局部最大

值彼此连接

的 1 维流形。局

部最小值出

现在两个臂

间隙的中间

附近。当重

构

误差的范数

（由箭头的长

度示出）很大

时，在箭头的

方向上移动

可以显著增

加概率，并且

在低

概率的

地方大多也

是如此。自编

码器将这些

低概率点映

射到较高的

概率重构。在

概率最大的

情况

下，重构

变得更准确

，因此箭头会

收缩。经 Alain

and Bengio (2013) 许可

转载此图。

一

般情况下，不

能保证重构

函数 g(f(x)) 减去输

入 x

后对应于

某个函数的

梯

度，更不用

说得分 。这是

早期工作 (Vincent,

2011) 专

用于特定参

数化的原因

（其中

g(f(x)) −

x 能通过

另一个函数

的导数获得

）。Kamyshanska and Memisevic

(2015)

440 第十四章 自

编码器

通过

标识一类特

殊的浅层自

编码器家族

，使 g(f(x)) − x

对应于这

个家族所有

成员的

一个

得分，以此推

广 Vincent (2011)

的结果。

目

前为止我们

所讨论的仅

限于去噪自

编码器如何

学习表示一

个概率分布

。更一

般的，我

们可能希望

使用自编码

器作为生成

模型，并从其

分布中进行

采样。这将在

第 20.11

节中讨论

。

14.5.2 历史展望

采

用

MLP 去噪的想

法可以追溯

到 LeCun (1987)

和 Gallinari et al.

(1987) 的

工作

。Behnke (2001)

也曾使用循

环网络对图

像去噪。在某

种意义上，去

噪自编码

器

仅仅是被训

练去噪的 MLP。然

而，“去噪自编

码器’’ 的命名

指的不仅仅

是学习去

噪

，而且可以学

到一个好的

内部表示（作

为学习去噪

的副效用）。这

个想法提出

较

晚 (Vincent et

al., 2008b, 2010)。学习到

的表示可以

被用来预训

练更深的无

监督网络

或

监督网络。与

稀疏自编码

器、稀疏编码

、收缩自编码

器等正则化

的自编码器

类似，

DAE 的动机

是允许学习

容量很高的

编码器，同时

防止在编码

器和解码器

学习一个无

用的恒等函

数。

在引入现

代 DAE

之前，Inayoshi and Kurita (2005)

探索

了其中一些

相同的方

法

和目标。他们

除了在监督

目标的情况

下最小化重

构误差之外

，还在监督 MLP 的

隐

藏层注入

噪声，通过引

入重构误差

和注入噪声

提升泛化能

力。然而，他们

的方法基

于

线性编码器

，因此无法学

习到现代 DAE 能

学习的强大

函数族。

14.6 使用

自编码器学

习流形

如第

5.11.3 节描述，自编

码器跟其他

很多机器学

习算法一样

，也利用了数

据集中

在一

个低维流形

或者一小组

这样的流形

的思想。其中

一些机器学

习算法仅能

学习到

在流

形上表现良

好但给定不

在流形上的

输入会导致

异常的函数

。自编码器进

一步借

此想

法，旨在学习

流形的结构

。

要了解自编

码器如何做

到这一点，我

们必须介绍

流形的一些

重要特性。

流

形的一个重

要特征是 切

平面（tangent plane）的集合

。d 维流形上的

一点

x，

切平面

由能张成流

形上允许变

动的局部方

向的 d 维基向

量给出。如图

14.6

所示，这

些局

部方向决定

了我们能如

何微小地变

动 x 而保持于

流形上。

14.6 使用

自编码器学

习流形 441

图

14.6: 正

切超平面概

念的图示。我

们在 784 维空间

中创建了

1 维

流形。我们使

用一张 784 像素

的

MNIST 图像，并通

过垂直平移

来转换它。垂

直平移的量

定义沿着 1 维

流形的坐标

，轨迹为通过

图像空间的

弯曲路径。该

图显示了沿

着该流形的

几个点。为了

可视化，我们

使用

PCA 将流形

投影

到 2

维空

间中。n 维流形

在每个点处

都具有 n 维切

平面。该切平

面恰好在该

点接触流形

，并且在

该点

处平行于流

形表面。它定

义了为保持

在流形上可

以移动的方

向空间。该 1 维

流形具有单

个切

线。我们

在图中示出

了一个点处

的示例切线

，其中图像表

示该切线方

向在图像空

间中是怎样

的。灰

色像素

表示沿着切

线移动时不

改变的像素

，白色像素表

示变亮的像

素，黑色像素

表示变暗的

像素。

所有自

编码器的训

练过程涉及

两种推动力

的折衷：

1. 学习

训练样本

x 的

表示 h 使得

x 能

通过解码器

近似地从 h 中

恢复。x

是从训

练数据挑出

的这一事实

很关键，因为

这意味着自

编码器不需

要成功重构

不属于

数据

生成分布下

的输入。

2. 满足

约束或正则

惩罚。这可以

是限制自编

码器容量的

架构约束，也

可以是加入

442

第十四章 自

编码器

到重

构代价的一

个正则项。这

些技术一般

倾向那些对

输入较不敏

感的解。

显然

，单一的推动

力是无用的

——从它本身将

输入复制到

输出是无用

的，同样

忽略

输入也是没

用的。相反，两

种推动力结

合是有用的

，因为它们驱

使隐藏的表

示

能捕获有

关数据分布

结构的信息

。重要的原则

是，自编码器

必须有能力

表示重构训

练实例所需

的变化。如果

该数据生成

分布集中靠

近一个低维

流形，自编码

器能隐式

产

生捕捉这个

流形局部坐

标系的表示

：仅在 x

周围关

于流形的相

切变化需要

对应于

h = f(x)

中的

变化。因此，编

码器学习从

输入空间 x 到

表示空间的

映射，映射仅

对

沿着流形

方向的变化

敏感，并且对

流形正交方

向的变化不

敏感。

图 14.7 中一

维的例子说

明，我们可以

通过构建对

数据点周围

的输入扰动

不敏感

的重

构函数，使得

自编码器恢

复流形结构

。

x0 x1 x2

x

0.0

0.2

0.4

0.6

0.8

1.0

Identity

Optimal

reconstruction

图 14.7: 如果自编

码器学习到

对数据点附

近的小扰动

不变的重构

函数，它就能

捕获数据的

流形结

构。这

里，流形结构

是 0 维流形的

集合。虚线对

角线表示重

构的恒等函

数目标。最佳

重构函数会

在存在数据

点的任意处

穿过恒等函

数。图底部的

水平箭头表

示在输入空

间中基于箭

头的 r(x)

− x

重建方

向向量，总是

指向最近的

“流形’’（1 维情况

下的单个数

据点）。在数据

点周围，去噪

自编

码器明

确地尝试将

重构函数 r(x) 的

导数限制为

很小。收缩自

编码器的编

码器执行相

同操作。虽然

在数据点周

围，r(x) 的导数被

要求很小，但

在数据点之

间它可能会

很大。数据点

之间的空间

对应

于流形

之间的区域

，为将损坏点

映射回流形

，重构函数必

须具有大的

导数。

为了理

解自编码器

可用于流形

学习的原因

，我们可以将

自编码器和

其他方法进

行对比。学习

表征流形最

常见的是流

形上（或附近

）数据点的 表

示（representation）。

对于特定

的实例，这样

的表示也被

称为嵌入。它

通常由一个

低维向量给

出，具有比这

个流形的

‘‘外

围’’ 空间更少

的维数。有些

算法（下面讨

论的非参数

流形学习算

法）直

r(x)

14.6

使用自

编码器学习

流形 443

接学习

每个训练样

例的嵌入，而

其他算法学

习更一般的

映射（有时被

称为编码器

或

表示函数

），将周围空间

（输入空间）的

任意点映射

到它的嵌入

。

流形学习大

多专注于试

图捕捉到这

些流形的无

监督学习过

程。最初始的

学习非

线性

流形的机器

学习研究专

注基于 最近

邻图（nearest neighbor

graph）的 非参

数

（non-parametric）方法。该图

中每个训练

样例对应一

个节点，它的

边连接近邻

点对。如

图

14.8 所

示，这些方法

(Schölkopf et al.,

1998b; Roweis and Saul,

2000; Tenenbaum

et al.,

2000; Brand, 2003b; Belkin

and Niyogi, 2003a; Donoho

and Grimes, 2003;

Weinberger

and Saul, 2004b; Hinton

and Roweis, 2003; van

der Maaten and Hinton,

2008) 将每个节点

与张成实例

和近邻之间

的差向量变

化方向的切

平面相关联

。

图 14.8:

非参数流

形学习过程

构建的最近

邻图，其中节

点表示训练

样本，有向边

指示最近邻

关系。

因此，各

种过程可以

获得与图的

邻域相关联

的切平面以

及将每个训

练样本与实

值向量位置

或 嵌入

（embedding）相关

联的坐标系

。我们可以通

过插值将这

种表示概括

为新的样本

。只要样本的

数量

大到足

以覆盖流形

的弯曲和扭

转，这些方法

工作良好。图

片来自 QMUL 多角

度人脸数据

集 (Gong

et al., 2000)。

全局坐标

系则可以通

过优化或求

解线性系统

获得。图

14.9 展示

了如何通过

大量

局部线

性的类高斯

样平铺（或 ‘‘薄

煎饼’’，因为高

斯块在切平

面方向是扁

平的）得到

一

个流形。

444 第十

四章 自编码

器

图 14.9: 如果每

个位置处的

切平面（见图

14.6 ）是已知的，则

它们可以平

铺后形成全

局坐标系或

密度函数。每

个局部块可

以被认为是

局部欧几里

德坐标系或

者是局部平

面高斯或

‘‘薄

饼’’，在与薄

饼

正交的方向

上具有非常

小的方差而

在定义坐标

系的方向上

具有非常大

的方差。这些

高斯的混合

提供了估计

的密度函数

，如流形中的

Parzen 窗口算法 (Vincent

and Bengio, 2003) 或

其非局部的

基于神经网

络的变体

(Bengio et al., 2006b)。

然

而，Bengio and Monperrus (2005)

指出了这

些局部非参

数方法应用

于流形学

习

的根本困难

：如果流形不

是很光滑（它

们有许多波

峰、波谷和曲

折），为覆盖其

中的每一个

变化，我们可

能需要非常

多的训练样

本，导致没有

能力泛化到

没见过的

变

化。实际上，这

些方法只能

通过内插，概

括相邻实例

之间流形的

形状。不幸的

是，

AI

问题中涉

及的流形可

能具有非常

复杂的结构

，难以仅从局

部插值捕获

特征。考虑

图

14.6 转换所得的

流形样例。如

果我们只观

察输入向量

内的一个坐

标 xi，当平移图

像，我们可以

观察到当这

个坐标遇到

波峰或波谷

时，图像的亮

度也会经历

一个波峰

或

波谷。换句话

说，底层图像

模板亮度的

模式复杂性

决定执行简

单的图像变

换所产

生的

流形的复杂

性。这是采用

分布式表示

和深度学习

捕获流形结

构的动机。

14.7 收

缩自编码器

445

14.7 收缩自编码

器

收缩自编

码器 (Rifai

et al., 2011a,b) 在编码

h

= f(x) 的基础上添

加了显式的

正

则项，鼓励

f

的导数尽可

能小：

Ω(h) = λ





∂f

∂

(

x

x)



2

F

. (14.18)

惩罚项

Ω(h) 为平方 Frobenius 范数

（元素平方之

和），作用于与

编码器的函

数相

关偏导

数的 Jacobian 矩阵。

去

噪自编码器

和收缩自编

码器之间存

在一定联系

：Alain

and Bengio (2013) 指出

在小高

斯噪声的限

制下，当重构

函数将 x 映射

到 r

= g(f(x)) 时，去噪重

构误差与收

缩惩罚项是

等价的。换句

话说，去噪自

编码器能抵

抗小且有限

的输入扰动

，而收缩

自编

码器使特征

提取函数能

抵抗极小的

输入扰动。

分

类任务中，基

于 Jacobian 的收缩惩

罚预训练特

征函数 f(x)，将收

缩惩罚应

用

在 f(x) 而不是 g(f(x))

可

以产生最好

的分类精度

。如第 14.5.1 节所讨

论，应用于

f(x)

的

收缩惩罚与

得分匹配也

有紧密的联

系。

收缩（contractive）源于

CAE 弯曲空间的

方式。具体来

说，由于 CAE

训练

为

抵抗输入

扰动，鼓励将

输入点邻域

映射到输出

点处更小的

邻域。我们能

认为这是将

输入的邻域

收缩到更小

的输出邻域

。

说得更清楚

一点，CAE 只在局

部收缩——一个

训练样本

x 的

所有扰动都

映射到

f(x) 的附

近。全局来看

，两个不同的

点

x 和 x

′

会分别

被映射到远

离原点的两

个点

f(x) 和 f(x

′

)。f 扩展

到数据流形

的中间或远

处是合理的

（见图 14.7

中小例

子的情

况）。当

Ω(h) 惩罚应用于

sigmoid 单元时，收缩

Jacobian

的简单方式

是令 sigmoid 趋

向饱

和的

0 或 1。这鼓

励 CAE

使用 sigmoid 的极

值编码输入

点，或许可以

解释为二

进

制编码。它也

保证了

CAE 可以

穿过大部分

sigmoid 隐藏单元能

张成的超立

方体，

进而扩

散其编码值

。

我们可以认

为点 x 处的 Jacobian

矩

阵 J 能将非线

性编码器近

似为线性算

子。这

允许我

们更形式地

使用

“收缩’’ 这

个词。在线性

理论中，当 Jx 的

范数对于所

有单位

x 都小

于等于 1 时，J

被

称为收缩的

。换句话说，如

果 J 收缩了单

位球，他就是

收

缩的。我们

可以认为

CAE 为

鼓励每个局

部线性算子

具有收缩性

，而在每个训

练数据

点处

将 Frobenius

范数作为

f(x) 的局部线性

近似的惩罚

。

如第 14.6

节中描

述，正则自编

码器基于两

种相反的推

动力学习流

形。在 CAE 的

446

第十

四章 自编码

器

情况下，这

两种推动力

是重构误差

和收缩惩罚

Ω(h)。单独的重构

误差鼓励 CAE

学

习一个恒等

函数。单独的

收缩惩罚将

鼓励 CAE 学习关

于 x

是恒定的

特征。这两种

推动力的折

衷产生导数

∂f

∂

(

x

x) 大多是微小

的自编码器

。只有少数隐

藏单元，对应

于一

小部分

输入数据的

方向，可能有

显著的导数

。

CAE

的目标是学

习数据的流

形结构。使 Jx 很

大的方向 x，会

快速改变

h，因

此很可能是

近似流形切

平面的方向

。Rifai et al. (2011a,b)

的实验显示

训练 CAE 会

导致

J

中大部分奇

异值（幅值）比

1 小，因此是收

缩的。然而，有

些奇异值仍

然比

1 大，因为

重构误差的

惩罚鼓励

CAE 对

最大局部变

化的方向进

行编码。对应

于最大

奇异

值的方向被

解释为收缩

自编码器学

到的切方向

。理想情况下

，这些切方向

应对

应于数

据的真实变

化。比如，一个

应用于图像

的

CAE 应该能学

到显示图像

改变的切

向

量，如图14.6 图中

物体渐渐改

变状态。如图

14.10

所示，实验获

得的奇异向

量的可

视化

似乎真的对

应于输入图

象有意义的

变换。

Input

point

Tangent vectors

Local PCA

(no sharing across regions)

Contractive autoencoder

图 14.10:

通过

局部 PCA 和收缩

自编码器估

计的流形切

向量的图示

。流形的位置

由来自 CIFAR-10

数据

集中狗的输

入图像定义

。切向量通过

输入到代码

映射的 Jacobian 矩阵

∂

∂

h

x 的前导奇异

向量估

计。虽

然局部

PCA 和 CAE 都

可以捕获局

部切方向，但

CAE

能够从有限

训练数据形

成更准确的

估计，因为它

利用了不同

位置的参数

共享（共享激

活的隐藏单

元子集）。CAE切方

向通常对应

于物

体的移

动或改变部

分（例如头或

腿）。经 Rifai et

al. (2011c) 许可转

载此图。

收缩

自编码器正

则化准则的

一个实际问

题是，尽管它

在单一隐藏

层的自编码

器情况下是

容易计算的

，但在更深的

自编码器情

况下会变的

难以计算。根

据

Rifai

et al. (2011a)

的策略，分

别训练一系

列单层的自

编码器，并且

每个被训练

为重构前

一

个自编码器

的隐藏层。这

些自编码器

的组合就组

成了一个深

度自编码器

。因为每

个层

分别训练成

局部收缩，深

度自编码器

自然也是收

缩的。这个结

果与联合训

练深

度模型

完整架构（带

有关于Jacobian的惩

罚项）获得的

结果是不同

的，但它抓住

了

14.8 预测稀疏

分解 447

许多理

想的定性特

征。

另一个实

际问题是，如

果我们不对

解码器强加

一些约束，收

缩惩罚可能

导致无

用的

结果。例如，编

码器将输入

乘一个小常

数 ϵ，解码器将

编码除以一

个小常数 ϵ。

随

着 ϵ 趋向于 0，编

码器会使收

缩惩罚项

Ω(h) 趋

向于 0 而学不

到任何关于

分布的信

息

。同时，解码器

保持完美的

重构。Rifai et al. (2011a)

通过绑

定 f 和 g

的权重

来

防止这种

情况。f 和 g

都是

由线性仿射

变换后进行

逐元素非线

性变换的标

准神经网

络

层组成，因此

将 g 的权重矩

阵设成

f 权重

矩阵的转置

是很直观的

。

14.8 预测稀疏分

解

预测稀疏

分解（predictive sparse decomposition, PSD）是稀疏

编码和参数

化自

编码器

(Kavukcuoglu et al., 2008)

的混合模型

。参数化编码

器被训练为

能预测迭代

推断的输出

。PSD 被应用于图

片和视频中

对象识别的

无监督特征

学习 (Kavukcuoglu

et

al., 2009, 2010; Jarrett

et al., 2009b; Farabet

et al., 2011)，在音频

中也有所应

用

(Henaff

et al., 2011)。这个模型

由一个编码

器 f(x)

和一个解

码器 g(h) 组成，并

且都

是参数

化的。在训练

过程中，h

由优

化算法控制

。优化过程是

最小化

∥x − g(h)∥

2 + λ|h|1 +

γ∥h − f(x)∥

2

. (14.19)

就像

稀疏编码，训

练算法交替

地相对 h

和模

型的参数最

小化上述目

标。相对 h 最小

化较快，因为

f(x) 提供

h 的良好

初始值以及

损失函数将

h 约束在 f(x)

附近

。简单

的梯度

下降算法只

需 10 步左右就

能获得理想

的

h。

PSD 所使用的

训练程序不

是先训练稀

疏编码模型

，然后训练 f(x)

来

预测稀疏

编

码的特征。PSD 训

练过程正则

化解码器，使

用 f(x)

可以推断

出良好编码

的参数。

预测

稀疏分解是

学习近似推

断（learned approximate inference）的一个例

子。

在第 19.5 节中

，这个话题将

会进一步展

开。第十九章

中展示的工

具能让我们

了解到，

PSD

能够

被解释为通

过最大化模

型的对数似

然下界训练

有向稀疏编

码的概率模

型。

在 PSD 的实际

应用中，迭代

优化仅在训

练过程中使

用。模型被部

署后，参数编

码器

f 用于计

算已经习得

的特征。相比

通过梯度下

降推断 h，计算

f 是很容易的

。

因为 f 是一个

可微带参函

数，PSD 模型可堆

叠，并用于初

始化其他训

练准则的深

度

网络。

448 第十

四章 自编码

器

14.9 自编码器

的应用

自编

码器已成功

应用于降维

和信息检索

任务。降维是

表示学习和

深度学习的

第

一批应用

之一。它是研

究自编码器

早期驱动力

之一。例如，Hinton

and Salakhutdinov

(2006) 训

练了一个栈

式

RBM，然后利用

它们的权重

初始化一个

隐藏层逐渐

减小的深

度

自编码器，终

结于 30 个单元

的瓶颈。生成

的编码比

30 维

的 PCA 产生更少

的重

构误差

，所学到的表

示更容易定

性解释，并能

联系基础类

别，这些类别

表现为分离

良好的集群

。

低维表示可

以提高许多

任务的性能

，例如分类。小

空间的模型

消耗更少的

内存

和运行

时间。据 Salakhutdinov

and Hinton (2007b) 和

Torralba et al. (2008)

观

察，

许多降维

的形式会将

语义上相关

的样本置于

彼此邻近的

位置。映射到

低维空间所

提

供的线索

有助于泛化

。

相比普通任

务，

信息检索

（information retrieval）从降维中获

益更多，此任

务

需要找到

数据库中类

似查询的条

目。此任务不

仅和其他任

务一样从降

维中获得一

般

益处，还使

某些低维空

间中的搜索

变得极为高

效。特别的，如

果我们训练

降维算法生

成一个低维

且二值的编

码，那么我们

就可以将所

有数据库条

目在哈希表

映射为二值

编码向量。这

个哈希表允

许我们返回

具有相同二

值编码的数

据库条目作

为查询结果

进行信息检

索。我们也可

以非常高效

地搜索稍有

不同条目，只

需反转查询

编码的各

个

位。这种通过

降维和二值

化的信息检

索方法被称

为 语义哈希

（semantic hashing）

(Salakhutdinov

and Hinton, 2007b, 2009b)，已经被用于

文本输入

(Salakhutdinov and

Hinton, 2007b,

2009b) 和

图像 (Torralba et

al., 2008; Weiss et

al., 2008; Krizhevsky

and

Hinton, 2011)。

通常在

最终层上使

用 sigmoid

编码函数

产生语义哈

希的二值编

码。sigmoid 单元

必须

被训练为到

达饱和，对所

有输入值都

接近 0

或接近

1。能做到这一

点的窍门就

是训练时在

sigmoid 非线性单元

前简单地注

入加性噪声

。噪声的大小

应该随时间

增

加。要对抗

这种噪音并

且保存尽可

能多的信息

，网络必须加

大输入到 sigmoid

函

数

的幅度，直

到饱和。

学习

哈希函数的

思想已在其

他多个方向

进一步探讨

，包括改变损

失训练表

示

的想法，其中

所需优化的

损失与哈希

表中查找附

近样本的任

务有更直接

的联系

(Norouzi and Fleet, 2011)。

第十

五章 表示学

习

在本章中

，首先我们会

讨论学习表

示是什么意

思，以及表示

的概念如何

有助于

深度

框架的设计

。我们探讨学

习算法如何

在不同任务

中共享统计

信息，包括使

用无

监督任

务中的信息

来完成监督

任务。共享表

示有助于处

理多模式或

多领域，或是

将

已学到的

知识迁移到

样本很少或

没有、但任务

表示依然存

在的任务上

。最后，我们

回

过头探讨表

示学习成功

的原因，从分

布式表示 (Hinton

et al., 1986) 和

深度表示的

理论优势，最

后会讲到数

据生成过程

潜在假设的

更一般概念

，特别是观测

数据的基

本

成因。

很多信

息处理任务

可能非常容

易，也可能非

常困难，这取

决于信息是

如何表示

的

。这是一个广

泛适用于日

常生活、计算

机科学及机

器学习的基

本原则。例如

，对于

人而言

，可以直接使

用长除法计

算

210 除以 6。但如

果使用罗马

数字表示，这

个问

题就没

那么直接了

。大部分现代

人在使用罗

马数字计算

CCX

除以 VI 时，都会

将其

转化成

阿拉伯数字

，从而使用位

值系统的长

除法。更具体

地，我们可以

使用合适或

不合适的表

示来量化不

同操作的渐

近运行时间

。例如，插入一

个数字到有

序表中的

正

确位置，如果

该数列表示

为链表，那么

所需时间是

O(n)；如果该列表

表示为红黑

树，那么只需

要 O(log n) 的时间。

在

机器学习中

，到底是什么

因素决定了

一种表示比

另一种表示

更好呢？一般

而

言，一个好

的表示可以

使后续的学

习任务更容

易。选择什么

表示通常取

决于后续的

学习任务。

我

们可以将监

督学习训练

的前馈网络

视为表示学

习的一种形

式。具体地，网

络

的最后一

层通常是线

性分类器，如

softmax

回归分类器

。网络的其余

部分学习出

该

分类器的

表示。监督学

习训练模型

，一般会使得

模型的各个

隐藏层（特别

是接近顶

层

的隐藏层）的

表示能够更

加容易地完

成训练任务

。例如，输入特

征线性不可

分的

类别可

能在最后一

个隐藏层变

成线性可分

离的。原则上

，最后一层可

以是另一种

模

449

450 第十五章

表示学习

型

，如最近邻分

类器

(Salakhutdinov and Hinton, 2007a)。倒数第

二层的特征

应该根

据最

后一层的类

型学习不同

的性质。

前馈

网络的监督

训练并没有

给学成的中

间特征明确

强加任何条

件。其他的表

示

学习算法

往往会以某

种特定的方

式明确设计

表示。例如，我

们想要学习

一种使得密

度估计更容

易的表示。具

有更多独立

性的分布会

更容易建模

，因此，我们可

以设计

鼓励

表示向量

h 中

元素之间相

互独立的目

标函数。就像

监督网络，无

监督深度学

习

算法有一

个主要的训

练目标，但也

额外地学习

出了表示。不

论该表示是

如何得到的

，

它都可以用

于其他任务

。或者，多个任

务（有些是监

督的，有些是

无监督的）可

以通

过共享

的内部表示

一起学习。

大

多数表示学

习算法都会

在尽可能多

地保留与输

入相关的信

息和追求良

好的性

质（如

独立性）之间

作出权衡。

表

示学习特别

有趣，因为它

提供了进行

无监督学习

和半监督学

习的一种方

法。

我们通常

会有巨量的

未标注训练

数据和相对

较少的标注

训练数据。在

非常有限的

标

注数据集

上监督学习

通常会导致

严重的过拟

合。半监督学

习通过进一

步学习未标

注数据，来解

决过拟合的

问题。具体地

，我们可以从

未标注数据

上学习出很

好的表

示，然

后用这些表

示来解决监

督学习问题

。

人类和动物

能够从非常

少的标注样

本中学习。我

们至今仍不

知道这是如

何做到

的。有

许多假说解

释人类的卓

越学习能力

——例如，大脑可

能使用了大

量的分类器

或者贝叶斯

推断技术的

集成。一种流

行的假说是

，大脑能够利

用无监督学

习和半监

督

学习。利用未

标注数据有

多种方式。在

本章中，我们

主要使用的

假说是未标

注数

据可以

学习出良好

的表示。

15.1

贪心

逐层无监督

预训练

无监

督学习在深

度神经网络

的复兴上起

到了关键的

、历史性的作

用，它使研究

者首次可以

训练不含诸

如卷积或者

循环这类特

殊结构的深

度监督网络

。我们将这一

过程称为 无

监督预训练

（unsupervised pretraining），或者更精确

地，贪心逐层

无监

督预训

练（greedy layer-wise unsupervised pretraining）。此过程是

一个任务（无

监

督学习，尝

试获取输入

分布的形状

）的表示如何

有助于另一

个任务（具有

相同输入

域

的监督学习

）的典型示例

。

贪心逐层无

监督预训练

依赖于单层

表示学习算

法，例如 RBM、单层

自编码器、

15.1 贪

心逐层无监

督预训练 451

稀

疏编码模型

或其他学习

潜在表示的

模型。每一层

使用无监督

学习预训练

，将前一

层的

输出作为输

入，输出数据

的新的表示

。这个新的表

示的分布（或

者是和其他

变

量比如要

预测类别的

关系）有可能

是更简单的

。如算法 15.1 所示

的正式表述

。

算法 15.1 贪心逐

层无监督预

训练的协定

给定如下：无

监督特征学

习算法 L，L

使用

训练集样本

并返回编码

器或特征函

数 f。

原始输入

数据是 X，每行

一个样本，并

且

f

(1)(X) 是第一阶

段编码器关

于 X

的输出。

在

执行精调的

情况下，我们

使用学习者

T ，并使用初始

函数 f，输入样

本

X（以及

在监

督精调情况

下关联的目

标 Y），并返回细

调好函数。阶

段数为 m。

f ← 恒等

函数

X˜

= X

for k

= 1, . .

. , m do

f

(k) = L(X˜

)

f ← f

(k) ◦ f

X˜

← f

(k)

(X˜

)

end for

if

fine-tuning then

f ←

T (f, X, Y)

end if

Return f

基于无

监督标准的

贪心逐层训

练过程，早已

被用来规避

监督问题中

深度神经网

络难以联合

训练多层的

问题。这种方

法至少可以

追溯神经认

知机 (Fukushima, 1975)。

深度学

习的复兴始

于

2006 年，源于发

现这种贪心

学习过程能

够为多层联

合训练过程

找到一个好

的初始值，甚

至可以成功

训练全连接

的结构 (Hinton et

al., 2006b; Hinton

and

Salakhutdinov, 2006; Hinton, 2006;

Bengio et al., 2007d;

Ranzato et al., 2007a)。

在此

发现之前，只

有深度卷积

网络或深度

循环网络这

类特殊结构

的深度网络

被认为

是有

可能训练的

。现在我们知

道训练具有

全连接的深

度结构时，不

再需要使用

贪心

逐层无

监督预训练

，但无监督预

训练是第一

个成功的方

法。

贪心逐层

无监督预训

练被称为

贪

心（greedy）的，是因为

它是一个 贪

心算法

（greedy algorithm），这意

味着它独立

地优化解决

方案的每一

个部分，每一

步解决一

个

部分，而不是

联合优化所

有部分。它被

称为 逐层的

（layer-wise），是因为这些

独立

的解决

方案是网络

层。具体地，贪

心逐层无监

督预训练每

次处理一层

网络，训练第

k

452

第十五章 表

示学习

层时

保持前面的

网络层不变

。特别地，低层

网络（最先训

练的）不会在

引入高层网

络后进行调

整。它被称为

无监督（unsupervised）的，是

因为每一层

用无监督表

示学

习算法

训练。然而，它

也被称为

预

训练（pretraining），是因为

它只是在联

合训练算

法

精调（fine-tune）所有层

之前的第一

步。在监督学

习任务中，它

可以被看作

是正

则化项

（在一些实验

中，预训练不

能降低训练

误差，但能降

低测试误差

）和参数初

始

化的一种形

式。

通常而言

，“预训练’’ 不仅

单指预训练

阶段，也指结

合预训练和

监督学习的

两阶

段学习

过程。监督学

习阶段可能

会使用预训

练阶段得到

的顶层特征

训练一个简

单分

类器，或

者可能会对

预训练阶段

得到的整个

网络进行监

督精调。不管

采用什么类

型

的监督学

习算法和模

型，在大多数

情况下，整个

训练过程几

乎是相同的

。虽然无监

督

学习算法的

选择将明显

影响到细节

，但是大多数

无监督预训

练应用都遵

循这一基

本

方法。

贪心逐

层无监督预

训练也能用

作其他无监

督学习算法

的初始化，比

如深度自编

码器

(Hinton and Salakhutdinov, 2006)

和具有

很多潜变量

层的概率模

型。这些模

型

包括深度信

念网络 (Hinton et

al., 2006b) 和深

度玻尔兹曼

机 (Salakhutdinov

and

Hinton, 2009a)。这些深度

生成模型会

在第二十章

中讨论。

正如

第

8.7.4 节所探讨

的，我们也可

以进行贪心

逐层监督预

训练。这是建

立在

训练浅

层模型比深

度模型更容

易的前提下

，而该前提似

乎在一些情

况下已被证

实 (Erhan

et al., 2010)。

15.1.1

何时以及

为何无监督

预训练有效

？

在很多分类

任务中，贪心

逐层无监督

预训练能够

在测试误差

上获得重大

提升。

这一观

察结果始于

2006 年对深度神

经网络的重

新关注

(Hinton et al., 2006b;

Bengio

et al., 2007d;

Ranzato et al., 2007a)。然而

，在很多其他

问题上，无监

督预训练不

能

带来改善

，甚至还会带

来明显的负

面影响。Ma et al. (2015)

研究

了预训练对

机器学

习模

型在化学活

性预测上的

影响。结果发

现，平均而言

预训练是有

轻微负面影

响的，

但在有

些问题上会

有显著帮助

。由于无监督

预训练有时

有效，但经常

也会带来负

面

效果，因此

很有必要了

解它何时有

效以及有效

的原因，以确

定它是否适

合用于特定

的任务。

首先

，要注意的是

这个讨论大

部分都是针

对贪心无监

督预训练而

言。还有很多

其

他完全不

同的方法使

用半监督学

习来训练神

经网络，比如

第 7.13 节介绍的

虚拟对抗

15.1 贪

心逐层无监

督预训练 453

训

练。我们还可

以在训练监

督模型的同

时训练自编

码器或生成

模型。这种单

阶段方

法的

例子包括判

别 RBM (Larochelle and

Bengio, 2008b) 和梯形网

络 (Rasmus

et al.,

2015)，其中整体

目标是两项

之和（一个使

用标签，另一

个仅仅使用

输入）。

无监督

预训练结合

了两种不同

的想法。第一

，它利用了深

度神经网络

对初始参

数

的选择，可以

对模型有着

显著的正则

化效果（在较

小程度上，可

以改进优化

）的

想法。第二

，它利用了更

一般的想法

——学习输入分

布有助于学

习从输入到

输出的

映射

。

这两个想法

都涉及到机

器学习算法

中多个未能

完全理解的

部分之间复

杂的相互

作

用。

第一个想

法，即深度神

经网络初始

参数的选择

对其性能具

有很强的正

则化效果，

很

少有关于这

个想法的理

解。在预训练

变得流行时

，在一个位置

初始化模型

被认为

会使

其接近某一

个局部极小

点，而不是另

一个局部极

小点。如今，局

部极小值不

再被

认为是

神经网络优

化中的严重

问题。现在我

们知道标准

的神经网络

训练过程通

常不

会到达

任何形式的

临界点。仍然

可能的是，预

训练会初始

化模型到一

个可能不会

到

达的位置

——例如，某种区

域，其中代价

函数从一个

样本点到另

一个样本点

变化很

大，而

小批量只能

提供噪声严

重的梯度估

计，或是某种

区域中的

Hessian 矩

阵条件

数是

病态的，梯度

下降必须使

用非常小的

步长。然而，我

们很难准确

判断监督学

习期

间预训

练参数的哪

些部分应该

保留。这是现

代方法通常

同时使用无

监督学习和

监督

学习，而

不是依序使

用两个学习

阶段的原因

之一。除了这

些复杂的方

法可以让监

督

学习阶段

保持无监督

学习阶段提

取的信息之

外，还有一种

简单的方法

，固定特征提

取器的参数

，仅仅将监督

学习作为顶

层学成特征

的分类器。

另

一个想法有

更好的理解

，即学习算法

可以使用无

监督阶段学

习的信息，在

监

督学习的

阶段表现得

更好。其基本

想法是对于

无监督任务

有用的一些

特征对于监

督

学习任务

也可能是有

用的。例如，如

果我们训练

汽车和摩托

车图像的生

成模型，它

需

要知道轮子

的概念，以及

一张图中应

该有多少个

轮子。如果我

们幸运的话

，无监

督阶段

学习的轮子

表示会适合

于监督学习

。然而我们还

未能从数学

、理论层面上

证

明，因此并

不总是能够

预测哪种任

务能以这种

形式从无监

督学习中受

益。这种方法

的许多方面

高度依赖于

具体使用的

模型。例如，如

果我们希望

在预训练特

征的顶层

添

加线性分类

器，那么（学习

到的）特征必

须使潜在的

类别是线性

可分离的。这

些性

质通常

会在无监督

学习阶段自

然发生，但也

并非总是如

此。这是另一

个监督和无

监

督学习同

时训练更可

取的原因——输

出层施加的

约束很自然

地从一开始

就包括在内

。

454

第十五章 表

示学习

从无

监督预训练

作为学习一

个表示的角

度来看，我们

可以期望无

监督预训练

在

初始表示

较差的情况

下更有效。一

个重要的例

子是词嵌入

。使用

one-hot 向量表

示

的词并不

具有很多信

息，因为任意

两个不同的

one-hot 向量之间的

距离（平方

L

2 距

离都是 2

) 都是

相同的。学成

的词嵌入自

然会用它们

彼此之间的

距离来编码

词之间

的相

似性。因此，无

监督预训练

在处理单词

时特别有用

。然而在处理

图像时是不

太

有用的，可

能是因为图

像已经在一

个很丰富的

向量空间中

，其中的距离

只能提供低

质量的相似

性度量。

从无

监督预训练

作为正则化

项的角度来

看，我们可以

期望无监督

预训练在标

注样本数量

非常小时很

有帮助。因为

无监督预训

练添加的信

息来源于未

标注数据，

所

以当未标注

样本的数量

非常大时，我

们也可以期

望无监督预

训练的效果

最好。

无监督

预训练的大

量未标注样

本和少量标

注样本构成

的半监督学

习的优势特

别明

显。在

2011 年

，无监督预训

练赢得了两

个国际迁移

学习比赛 (Mesnil et

al., 2011;

Goodfellow et

al., 2011)。在

该情景中，目

标任务中标

注样本的数

目很少（每类

几个

到几十

个）。这些效果

也出现在被

Paine et

al. (2014) 严格控制的

实验中。

还可

能涉及到一

些其他的因

素。例如，当我

们要学习的

函数非常复

杂时，无监

督

预训练可能

会非常有用

。无监督学习

不同于权重

衰减这样的

正则化项，它

不偏向

于学

习一个简单

的函数，而是

学习对无监

督学习任务

有用的特征

函数。如果真

实的

潜在函

数是复杂的

，并且由输入

分布的规律

塑造，那么无

监督学习更

适合作为正

则

化项。

除了

这些注意事

项外，我们现

在分析一些

无监督预训

练改善性能

的成功示例

，并

解释这种

改进发生的

已知原因。无

监督预训练

通常用来改

进分类器，并

且从减少测

试集误差的

观点来看是

很有意思的

。然而，无监督

预训练还有

助于分类以

外的任务，

并

且可以用于

改进优化，而

不仅仅只是

作为正则化

项。例如，它可

以提高去噪

自编

码器的

训练和测试

重构误差

(Hinton and Salakhutdinov, 2006)。

Erhan et al. (2010)

进

行了许多实

验来解释无

监督预训练

的几个成功

原因。对训

练

误差和测试

误差的改进

都可以解释

为，无监督预

训练将参数

引入到了其

他方法可

能

探索不到的

区域。神经网

络训练是非

确定性的，并

且每次运行

都会收敛到

不同的

函数

。训练可以停

止在梯度很

小的点；也可

以提前终止

结束训练，以

防过拟合；还

可

以停止在

梯度很大，但

由于诸如随

机性或 Hessian 矩阵

病态条件等

问题难以找

到合

适下降

方向的点。经

过无监督预

训练的神经

网络会一致

地停止在一

片相同的函

数空

间区域

，但未经过预

训练的神经

网络会一致

地停在另一

个区域。图 15.1 可

视化了这

种

现象。经过预

训练的网络

到达的区域

是较小的，这

表明预训练

减少了估计

过程的

15.1 贪心

逐层无监督

预训练 455

方差

，这进而又可

以降低严重

过拟合的风

险。换言之，无

监督预训练

将神经网络

参

数初始化

到它们不易

逃逸的区域

，并且遵循这

种初始化的

结果更加一

致，和没有这

种初始化相

比，结果很差

的可能性更

低。

Erhan et al.

(2010) 也回答了

何时预训练

效果最好——预

训练的网络

越深，测试

误

差的均值和

方差下降得

越多。值得注

意的是，这些

实验是在训

练非常深层

网络的

现代

方法发明和

流行（整流线

性单元，Dropout

和批

标准化）之前

进行的，因此

对

于无监督

预训练与当

前方法的结

合，我们所知

甚少。

一个重

要的问题是

无监督预训

练是如何起

到正则化项

作用的。一个

假设是，预训

练鼓励学习

算法发现那

些与生成观

察数据的潜

在原因相关

的特征。这也

是启发除无

监督预训练

之外许多其

他算法的重

要思想，将会

在第 15.3

节中进

一步讨论。

与

无监督学习

的其他形式

相比，无监督

预训练的缺

点是其使用

了两个单独

的训

练阶段

。很多正则化

技术都具有

一个优点，允

许用户通过

调整单一超

参数的值来

控

制正则化

的强度。无监

督预训练没

有一种明确

的方法来调

整无监督阶

段正则化的

强

度。相反，无

监督预训练

有许多超参

数，但其效果

只能之后度

量，通常难以

提前预

测。当

我们同时执

行无监督和

监督学习而

不使用预训

练策略时，会

有单个超参

数（通

常是附

加到无监督

代价的系数

）控制无监督

目标正则化

监督模型的

强度。减少该

系

数，总是能

够可预测地

获得较少正

则化强度。在

无监督预训

练的情况下

，没有一种

灵

活调整正则

化强度的方

式——要么监督

模型初始化

为预训练的

参数，要么不

是。

具有两个

单独的训练

阶段的另一

个缺点是每

个阶段都具

有各自的超

参数。第二

阶

段的性能通

常不能在第

一阶段期间

预测，因此在

第一阶段提

出超参数和

第二阶段

根

据反馈来更

新之间存在

较长的延迟

。最通用的方

法是在监督

阶段使用验

证集上的

误

差来挑选预

训练阶段的

超参数，如 Larochelle et al.

(2009) 中

讨论的。在实

际中，

有些超

参数，如预训

练迭代的次

数，很方便在

预训练阶段

设定，通过无

监督目标上

使用提前终

止策略完成

。这个策略并

不理想，但是

在计算上比

使用监督目

标代价小

得

多。

如今，大部

分算法已经

不使用无监

督预训练了

，除了在自然

语言处理领

域中单词

作

为 one-hot 向量的自

然表示不能

传达相似性

信息，并且有

非常多的未

标注数据集

可用。在这种

情况下，预训

练的优点是

可以对一个

巨大的未标

注集合（例如

用包含数

十

亿单词的语

料库）进行预

训练，学习良

好的表示（通

常是单词，但

也可以是句

子），

然后使用

该表示或精

调它，使其适

合于训练集

样本大幅减

少的监督任

务。这种方法

由 Collobert and

Weston (2008b)、Turian et al.

(2010) 和 Collobert et

al. (2011a)

456 第十五

章

表示学习

−4000 −3000 −2000 −1000

0 1000 2000 3000

4000

−1500

−1000

−500

0

500

1000

1500

With pretraining

Without pretraining

图 15.1: 在函数空

间（并非参数

空间，避免从

参数向量到

函数的多对

一映射）不同

神经网络的

学

习轨迹的

非线性映射

的可视化。不

同网络采用

不同的随机

初始化，并且

有的使用了

无监督预训

练，

有的没有

。每个点对应

着训练过程

中一个特定

时间的神经

网络。经Erhan et al. (2010)

许可

改编此

图。函

数空间中的

坐标是关于

每组输入 x 和

它的一个输

出

y 的无限维

向量。Erhan et al.

(2010)

将很多

特定 x 的

y 连接

起来，线性投

影到高维空

间中。然后他

们使用 Isomap (Tenenbaum

et al.,

2000) 进行

进一步的非

线性投影并

投到二维空

间。颜色表示

时间。所有的

网络初始化

在上图的中

心

点附近（对

应的函数区

域在不多数

输入上具有

近似均匀分

布的类别 y）。随

着时间推移

，学习将函

数

向外移动到

预测得更好

的点。当使用

预训练时，训

练会一致地

收敛到同一

个区域；而不

使用预

训练

时，训练会收

敛到另一个

不重叠的区

域。Isomap

试图维持

全局相对距

离（体积因此

也保持不

变

），因此使用预

训练的模型

对应的较小

区域意味着

，基于预训练

的估计具有

较小的方差

。

开创，至今仍

在使用。

基于

监督学习的

深度学习技

术，通过

Dropout 或批

标准化来正

则化，能够在

很

多任务上

达到人类级

别的性能，但

仅仅是在极

大的标注数

据集上。在中

等大小的数

据集（例如 CIFAR-10

和

MNIST，每个类大约

有 5,000 个标注样

本）上，这些技

术

的效果比

无监督预训

练更好。在极

小的数据集

，例如选择性

剪接数据集

，贝叶斯方

法

要优于基于

无监督预训

练的方法 (Srivastava, 2013)。由

于这些原因

，无监督预训

练已经不如

以前流行。然

而，无监督预

训练仍然是

深度学习研

究历史上的

一个重要

里

程碑，并将继

续影响当代

方法。预训练

的想法已经

推广到

监督

预训练（supervised

pretraining），这将

在第8.7.4 节中讨

论，在迁移学

习中这是非

常常用的方

法。迁移学

习

中的监督预

训练流行

(Oquab et al., 2014;

Yosinski et al., 2014)

于

在 ImageNet 数

据集上

使用卷积网

络预训练。由

于这个原因

，实践者们公

布了这些网

络训练出的

参

数，就像自

然语言任务

公布预训练

的单词向量

一样 (Collobert et al.,

2011a; Mikolov

15.2 迁移学

习和领域自

适应

457

et al., 2013a)。

15.2 迁移学

习和领域自

适应

迁移学

习和领域自

适应指的是

利用一个情

景（例如，分布

P1）中已经学到

的内

容去改

善另一个情

景（比如分布

P2）中的泛化情

况。这点概括

了上一节提

出的想法，

即

在无监督学

习任务和监

督学习任务

之间转移表

示。

在 迁移学

习（transfer learning）中，学习器

必须执行两

个或更多个

不同的任务

，

但是我们假

设能够解释

P1 变化的许多

因素和学习

P2 需要抓住的

变化相关。这

通常

能够在

监督学习中

解释，输入是

相同的，但是

输出不同的

性质。例如，我

们可能在

第

一种情景中

学习了一组

视觉类别，比

如猫和狗，然

后在第二种

情景中学习

一组不

同的

视觉类别，比

如蚂蚁和黄

蜂。如果第一

种情景（从 P1 采

样）中具有非

常多的数

据

，那么这有助

于学习到能

够使得从 P2 抽

取的非常少

样本中快速

泛化的表示

。许多

视觉类

别共享一些

低级概念，比

如边缘、视觉

形状、几何变

化、光照变化

的影响等

等

。一般而言，当

存在对不同

情景或任务

有用特征时

，并且这些特

征对应多个

情景

出现的

潜在因素，迁

移学习、多任

务学习（第7.7 节

）和领域自适

应可以使用

表示学

习来

实现。如图

7.2 所

示，这是具有

共享底层和

任务相关上

层的学习框

架。

然而，有时

不同任务之

间共享的不

是输入的语

义，而是输出

的语义。例如

，语

音识别系

统需要在输

出层产生有

效的句子，但

是输入附近

的较低层可

能需要识别

相

同音素或

子音素发音

的非常不同

的版本（这取

决于说话人

）。在这样的情

况下，共享

神

经网络的上

层（输出附近

）和进行任务

特定的预处

理是有意义

的，如图 15.2 所示

。

在 领域自适

应（domain adaption）的相关情

况下，在每个

情景之间任

务（和最

优的

输入到输出

的映射）都是

相同的，但是

输入分布稍

有不同。例如

，考虑情感分

析

的任务，如

判断一条评

论是表达积

极的还是消

极的情绪。网

上的评论有

许多类别。在

书、视频和音

乐等媒体内

容上训练的

顾客评论情

感预测器，被

用于分析诸

如电视机

或

智能电话的

消费电子产

品的评论时

，领域自适应

情景可能会

出现。可以想

象，存

在一个

潜在的函数

可以判断任

何语句是正

面的、中性的

还是负面的

，但是词汇和

风

格可能会

因领域而有

差异，使得跨

域的泛化训

练变得更加

困难。简单的

无监督预训

练（去噪自编

码器）已经能

够非常成功

地用于领域

自适应的情

感分析

(Glorot et al.,

2011c)。

一个

相关的问题

是 概念漂移

（concept drift），我们可以将

其视为一种

迁移学习，

458

第

十五章 表示

学习

Selection switch

hh(1) (1) hh(2) (2)

hh(3) (3)

y

hh(shared)

(shared)

xx(1) (1) xx(2)

(2) xx(3) (3)

图

15.2: 多任

务学习或者

迁移学习的

架构示例。输

出变量 y 在所

有的任务上

具有相同的

语义；输

入变

量 x 在每个任

务（或者，比如

每个用户）上

具有不同的

意义（甚至可

能具有不同

的维度），图

上

三个任务为

x

(1)，x

(2)，x

(3)。底层结构（决

定了选择方

向）是面向任

务的，上层结

构是共享的

。

底层结构学

习将面向特

定任务的输

入转化为通

用特征。

因为

数据分布随

时间而逐渐

变化。概念漂

移和迁移学

习都可以被

视为多任务

学习的

特定

形式。“多任务

学习’’ 这个术

语通常指监

督学习任务

，而更广义的

迁移学习的

概

念也适用

于无监督学

习和强化学

习。

在所有这

些情况下，我

们的目标是

利用第一个

情景下的数

据，提取那些

在第二

种情

景中学习时

或直接进行

预测时可能

有用的信息

。表示学习的

核心思想是

相同的

表示

可能在两种

情景中都是

有用的。两个

情景使用相

同的表示，使

得表示可以

受益

于两个

任务的训练

数据。

如前所

述，迁移学习

中无监督深

度学习已经

在一些机器

学习比赛中

取得了成

功

(Mesnil et al.,

2011; Goodfellow et al.,

2011)。这些比赛中

的某一个实

验配置如

下

。首先每个参

与者获得一

个第一种情

景（来自分布

P1）的数据集，其

中含有一些

类别的样本

。参与者必须

使用这个来

学习一个良

好的特征空

间（将原始输

入映射到

某

种表示），使得

当我们将这

个学成变换

用于来自迁

移情景（分布

P2）的输入时，线

性分类器可

以在很少标

注样本上训

练、并泛化得

很好。这个比

赛中最引人

注目的结

果

之一是，学习

表示的网络

架构越深（在

第一个情景

P1

中的数据使

用纯无监督

方式

学习），在

第二个情景

（迁移）P2 的新类

别上学习到

的曲线就越

好。对于深度

表示而

言，迁

移任务只需

要少量标注

样本就能显

著地提升泛

化性能。

15.2 迁移

学习和领域

自适应 459

迁移

学习的两种

极端形式是

一次学习（one-shot

learning）和

零次学习（zero￾shot learning），有

时也被称为

零数据学习

（zero-data learning）。只有一个标

注样本

的迁

移任务被称

为一次学习

；没有标注样

本的迁移任

务被称为零

次学习。

因为

第一阶段学

习出的表示

就可以清楚

地分离出潜

在的类别，所

以一次学

习

(Fei-Fei et al.,

2006) 是可能的。在

迁移学习阶

段，仅需要一

个标注样本

来推断表

示

空间中聚集

在相同点周

围许多可能

测试样本的

标签。这使得

在学成的表

示空间中，

对

应于不变性

的变化因子

已经与其他

因子完全分

离，在区分某

些类别的对

象时，我

们可

以学习到哪

些因素具有

决定意义。

考

虑一个零次

学习情景的

例子，学习器

已经读取了

大量文本，然

后要解决对

象

识别的问

题。如果文本

足够好地描

述了对象，那

么即使没有

看到某对象

的图像，也

能

识别出该对

象的类别。例

如，已知猫有

四条腿和尖

尖的耳朵，那

么学习器可

以在

没有见

过猫的情况

下猜测该图

像中是猫。

只

有在训练时

使用了额外

信息，零数据

学习 (Larochelle et

al., 2008) 和零次

学

习

(Palatucci et al., 2009;

Socher et al., 2013b)

才是有

可能的。我们

可以认为零

数据

学习场

景包含三个

随机变量：传

统输入 x，传统

输出或目标

y，以及描述任

务的附

加随

机变量

T。该模

型被训练来

估计条件分

布 p(y | x,

T)，其中 T 是我

们希望执行

的任务的描

述。在我们的

例子中，读取

猫的文本信

息然后识别

猫，输出是二

元变量

y，y

= 1 表示

‘‘是’’，y =

0 表示 ‘‘不是

’’。任务变量 T

表

示要回答的

问题，例如 ‘‘这

个图像中是

否有猫？” 如果

训练集包含

和 T

在相同空

间的无监督

对象样本，我

们也

许能够

推断未知的

T 实例的含义

。在我们的例

子中，没有提

前看到猫的

图像而去识

别猫，所以拥

有一些未标

注文本数据

包含句子诸

如 ‘‘猫有四条

腿’’

或 ‘‘猫有尖

耳朵’’，

对于学

习非常有帮

助。

零次学习

要求

T 被表示

为某种形式

的泛化。例如

，T 不能仅是指

示对象类别

的one-hot编码。通过

使用每个类

别词的词嵌

入表示，Socher et

al. (2013b) 提出

了对

象类别

的分布式表

示。

我们还可

以在机器翻

译中发现一

种类似的现

象 (Klementiev et al.,

2012; Mikolov

et al.,

2013b; Gouws et al.,

2014)：我们已经

知道一种语

言中的单词

，还可以学到

单

一语言语

料库中词与

词之间的关

系；另一方面

，我们已经翻

译了一种语

言中的单词

与另一种语

言中的单词

相关的句子

。即使我们可

能没有将语

言 X 中的单词

A

翻译

成语言

Y 中的单词 B

的

标注样本，我

们也可以泛

化并猜出单

词 A 的翻译，这

是由

于我们

已经学习了

语言

X 和 Y 单词

的分布式表

示，并且通过

两种语言句

子的匹配

460 第

十五章 表示

学习

对组成

的训练样本

，产生了关联

于两个空间

的链接（可能

是双向的）。如

果联合学习

三种成分（两

种表示形式

和它们之间

的关系），那么

这种迁移将

会非常成功

。

零次学习是

迁移学习的

一种特殊形

式。同样的原

理可以解释

如何能执行

多模

态学习

（multimodal learning），学习两种模

态的表示，和

一种模态中

的观察结果

x

与另一种模

态中的观察

结果

y 组成的

对 (x, y)

之间的关

系（通常是一

个联合分布

）

(Srivastava and Salakhutdinov,

2012)。通过学习所

有的三组参

数（从 x 到它的

表示、

从

y 到它

的表示，以及

两个表示之

间的关系），一

个表示中的

概念被锚定

在另一个表

示中，反之亦

然，从而可以

有效地推广

到新的对组

。这个过程如

图 15.3 所示。

15.3 半监

督解释因果

关系 461

hx

= fx(x)

xtest

ytest

hy = fy(y)

y−space

Relationship between embedded points

within one of the

domains

Maps between representation

spaces 

fx

fy

x−space

(x, y) pairs

in the training set

fx : encoder function

for x

fy :

encoder function for y

图 15.3: 两个

域 x

和 y 之间的

迁移学习能

够进行零次

学习。标注或

未标注样本

x 可以学习表

示函

数 fx。同样

地，样本 y 也可

以学习表示

函数

fy。上图中

fx 和 fy 旁都有一

个向上的箭

头，不同

的箭

头表示不同

的作用函数

。并且箭头的

类型表示使

用了哪一种

函数。hx 空间中

的相似性度

量表

示 x

空间

中任意点对

之间的距离

，这种度量方

式比直接度

量 x 空间的距

离更好。同样

地，hy 空间

中的

相似性度量

表示 y 空间中

任意点对之

间的距离。这

两种相似函

数都使用带

点的双向箭

头表示。

标注

样本（水平虚

线）(x,

y) 能够学习

表示 fx(x) 和表示

fy(y)

之间的单向

或双向映射

（实双向箭

头

），以及这些表

示之间如何

锚定。零数据

学习可以通

过以下方法

实现。像 xtest 可以

和单词

ytest

关联

起来，即使该

单词没有像

，仅仅是因为

单词表示 fy(ytest) 和

像表示

fx(xtest) 可以

通过表示空

间的映射彼

此关联。这种

方法有效的

原因是，尽管

像和单词没

有匹配成队

，但是它们各

自的特征

向

量 fx(xtest)

和 fy(ytest) 互相关

联。上图受 Hrant

Khachatrian 的

建议启发。

15.3 半

监督解释因

果关系

表示

学习的一个

重要问题是

‘‘什么原因能

够使一个表

示比另一个

表示更好？” 一

种假设是，理

想表示中的

特征对应到

观测数据的

潜在成因，特

征空间中不

同的特征

462 第

十五章

表示

学习

或方向

对应着不同

的原因，从而

表示能够区

分这些原因

。这个假设促

使我们去寻

找

表示 p(x)

的更

好方法。如果

y 是 x 的重要成

因之一，那么

这种表示也

可能是计算

p(y

| x) 的一种良好

表示。从 20

世纪

90 年代以来，这

个想法已经

指导了大量

的深

度学习

研究工作 (Becker

and Hinton, 1992; Hinton

and Sejnowski, 1999)。关

于半监

督学

习可以超过

纯监督学习

的其他论点

，请读者参考

Chapelle

et al. (2006) 的第

1.2

节。

在表

示学习的其

他方法中，我

们大多关注

易于建模的

表示——例如，数

据稀疏

或是

各项之间相

互独立的情

况。能够清楚

地分离出潜

在因素的表

示可能并不

一定易

于建

模。然而，该假

设促使半监

督学习使用

无监督表示

学习的一个

更深层原因

是，对

于很多

人工智能任

务而言，有两

个相随的特

点：一旦我们

能够获得观

察结果基本

成

因的解释

，那么将会很

容易分离出

个体属性。具

体来说，如果

表示向量 h

表

示观察

值 x 的

很多潜在因

素，并且输出

向量

y 是最为

重要的原因

之一，那么从

h 预测 y

会

很容

易。

首先，让我

们看看 p(x)

的无

监督学习无

助于学习 p(y | x)

时

，半监督学习

为何

失败。例

如，考虑一种

情况，p(x) 是均匀

分布的，我们

希望学习 f(x)

= E[y | x]。显

然，仅仅观察

训练集的值

x

不能给我们

关于 p(y | x)

的任何

信息。

接下来

，让我们看看

半监督学习

成功的一个

简单例子。考

虑这样的情

况，x 来

自一个

混合分布，每

个

y 值具有一

个混合分量

，如图 15.4 所示。如

果混合分量

很好

地分出

来了，那么建

模 p(x) 可以精确

地指出每个

分量的位置

，每个类一个

标注样本

的

训练集足以

精确学习

p(y | x)。但

是更一般地

，什么能将 p(y

| x) 和

p(x) 关联在

一起

呢？

如果 y 与

x 的

成因之一非

常相关，那么

p(x) 和 p(y

| x) 也会紧密

关联，试图

找

到变化潜在

因素的无监

督表示学习

可能像半监

督学习一样

有用。

假设 y 是

x 的成因之一

，让

h 代表所有

这些成因。真

实的生成过

程可以被认

为

是根据这

个有向图模

型结构化出

来的，其中 h

是

x 的父节点：

p(h, x)

= p(x | h)p(h).

(15.1)

因

此，数据的边

缘概率是

p(x) =

Ehp(x | h). (15.2)

从

这个直观的

观察中，我们

得出结论，x 最

好可能的模

型（从广义的

观点）是会表

示

上述 ‘‘真实

’’

结构的，其中

h 作为潜变量

解释 x 中可观

察的变化。上

文讨论的

‘‘理

15.3 半监督解释

因果关系 463

x

y=1 y=2 y=3

图

15.4:

混合模型。具

有三个混合

分量的 x 上混

合密度示例

。混合分量的

内在本质是

潜在解释因

子y。因为混合

分量（例如，图

像数据中的

自然对象类

别）在统计学

上是显著的

，所以仅仅使

用未

标注样

本无监督建

模

p(x) 也能揭示

解释因子y。

想

’’ 的表示学习

应该能够反

映出这些潜

在因子。如果

y

是其中之一

（或是紧密关

联

于其中之

一），那么将很

容易从这种

表示中预测

y。我们会看到

给定 x 下

y 的条

件

分布通过

贝叶斯规则

关联到上式

中的分量：

p(y

| x) = p(x

| y)p(y)

p(x)

.

(15.3)

因

此边缘概率

p(x) 和条件概率

p(y |

x) 密切相关，前

者的结构信

息应该有助

于学习

后者

。因此，在这些

假设情况下

，半监督学习

应该能提高

性能。

关于这

个事实的一

个重要的研

究问题是，大

多数观察是

由极其大量

的潜在成

因

形成的。假设

y = hi，但是无监督

学习器并不

知道是哪一

个 hi。对于一个

无监

督学习

器暴力求解

就是学习一

种表示，这种

表示能够捕

获所有合理

的重要生成

因子

hj，并将它

们彼此区分

开来，因此不

管 hi 是否关联

于

y，从 h 预测 y

都

是容易的。

在

实践中，暴力

求解是不可

行的，因为不

可能捕获影

响观察的所

有或大多数

变

化因素。例

如，在视觉场

景中，表示是

否应该对背

景中的所有

最小对象进

行编码？根

据

一个有据可

查的心理学

现象，人们不

会察觉到环

境中和他们

所在进行的

任务并不

立

刻相关的变

化，具体例子

可以参考 Simons and Levin

(1998)。半

监督学习的

一个

重要研

究前沿是确

定每种情况

下要编码什

么。目前，处理

大量潜在原

因的两个主

要

策略是，同

时使用无监

督学习和监

督学习信号

，从而使得模

型捕获最相

关的变动因

素，或是使用

纯无监督学

习学习更大

规模的表示

。

p(x)

464 第十五章 表

示学习

无监

督学习的另

一个思路是

选择一个更

好的确定哪

些潜在因素

最为关键的

定义。

之前，自

编码器和生

成模型被训

练来优化一

个类似于均

方误差的固

定标准。这些

固

定标准确

定了哪些因

素是重要的

。例如，图像像

素的均方误

差隐式地指

定，一个潜

在

因素只有在

其显著地改

变大量像素

的亮度时，才

是重要影响

因素。如果我

们希望

解决

的问题涉及

到小对象之

间的相互作

用，那么这将

有可能遇到

问题。如图

15.5 所

示，在机器人

任务中，自编

码器未能学

习到编码小

乒乓球。同样

是这个机器

人，它可

以成

功地与更大

的对象进行

交互（例如棒

球，均方误差

在这种情况

下很显著）。

输

入

重构

图 15.5: 机

器人任务上

，基于均方误

差训练的自

编码器不能

重构乒乓球

。乒乓球的存

在及其所有

空

间坐标，是

生成图像且

与机器人任

务相关的重

要潜在因素

。不幸的是，自

编码器具有

有限的容量

，

基于均方误

差的训练没

能将乒乓球

作为显著物

体识别出来

编码。以上图

像由 Chelsea Finn

提供。

还

有一些其他

的显著性的

定义。例如，如

果一组像素

具有高度可

识别的模式

，那

么即使该

模式不涉及

到极端的亮

度或暗度，该

模式还是会

被认为非常

显著。实现这

样一种定义

显著的方法

是使用最近

提出的 生成

式对抗网络

（generative

adversarial

network）(Goodfellow et al.,

2014c)。在这种方法

中，生成模型

被训练来愚

弄前馈分

类

器。前馈分类

器尝试将来

自生成模型

的所有样本

识别为假的

，并将来自训

练集的

所有

样本识别为

真的。在这个

框架中，前馈

网络能够识

别出的任何

结构化模式

都是

非常显

著的。生成式

对抗网络会

在第

20.10.4 节中更

详细地介绍

。为了叙述方

便，知

道它能

学习出如何

决定什么是

显著的就可

以了。Lotter et

al. (2015) 表明，生

成人类

头部

头像的模型

在使用均方

误差训练时

往往会忽视

耳朵，但是对

抗式框架学

习能够

成功

地生成耳朵

。因为耳朵与

周围的皮肤

相比不是非

常明亮或黑

暗，所以根据

均方

15.3 半监督

解释因果关

系 465

误差损失

它们不是特

别突出，但是

它们高度可

识别的形状

和一致的位

置意味着前

馈

网络能够

轻易地学习

出如何检测

它们，从而使

得它们在生

成式对抗框

架下是高度

突

出的。图 15.6

给

了一些样例

图片。生成式

对抗网络只

是确定应该

表示哪些因

素的一

小步

。我们期望未

来的研究能

够发现更好

的方式来确

定表示哪些

因素，并且根

据任

务来开

发表示不同

因素的机制

。

真实图

MSE 对抗

学习

图 15.6:

预测

生成网络是

一个学习哪

些特征显著

的例子。在这

个例子中，预

测生成网络

已被训练成

在特定视角

预测人头的

3D 模型。(左) 真实

情况。这是一

张网络应该

生成的正确

图片。(中) 由具

有均方误差

的预测生成

网络生成的

图片。因为与

相邻皮肤相

比，耳朵不会

引起亮度的

极大差异，所

以它们的显

著性不足以

让模型学习

表示它们。(右

)

由具有均方

误差和对抗

损失的模型

生成的图片

。

使用这个学

成的代价函

数，由于耳朵

遵循可预测

的模式，因此

耳朵是显著

重要的。学习

哪些原因

对

于模型而言

是足够重要

和相关的，是

一个重要的

活跃研究领

域。以上图片

由 Lotter

et al. (2015)

提供。

正如

Schölkopf et al. (2012)

指出，学习潜

在因素的好

处是，如果真

实的生成过

程中 x 是结果

，y 是原因，那么

建模

p(x | y) 对于

p(y) 的

变化是鲁棒

的。如果因果

关系被逆转

，这是不对的

，因为根据贝

叶斯规则，p(x | y)

将

会对 p(y) 的变化

十分

敏感。很

多时候，我们

考虑分布的

变化（由于不

同领域、时间

不稳定性或

任务性质

的

变化）时，因果

机制是保持

不变的（‘‘宇宙

定律不变’’），而

潜在因素的

边缘分布是

会变化的。因

此，通过学习

试图恢复成

因向量 h 和 p(x

| h) 的

生成模型，我

们可以

期望

最后的模型

对所有种类

的变化有更

好的泛化和

鲁棒性。

466 第十

五章 表示学

习

15.4

分布式表

示

分布式表

示的概念（由

很多元素组

合的表示，这

些元素之间

可以设置成

可分离

的）是

表示学习最

重要的工具

之一。分布式

表示非常强

大，因为他们

能用具有 k

个

值的 n 个特征

去描述 k

n 个不

同的概念。正

如我们在本

书中看到的

，具有多个隐

藏单

元的神

经网络和具

有多个潜变

量的概率模

型都利用了

分布式表示

的策略。我们

现在

再介绍

一个观察结

果。许多深度

学习算法基

于的假设是

，隐藏单元能

够学习表示

出

解释数据

的潜在因果

因子，就像第

15.3 节中讨论的

一样。这种方

法在分布式

表示上

是自

然的，因为表

示空间中的

每个方向都

对应着一个

不同的潜在

配置变量的

值。

n

维二元向

量是一个分

布式表示的

示例，有 2

n 种配

置，每一种都

对应输入空

间

中的一个

不同区域，如

图 15.7 所示。这可

以与符号表

示相比较，其

中输入关联

到单

一符号

或类别。如果

字典中有

n 个

符号，那么可

以想象有 n 个

特征监测器

，每个

特征探

测器监测相

关类别的存

在。在这种情

况下，只有表

示空间中 n 个

不同配置才

有可能在输

入空间中刻

画 n

个不同的

区域，如图 15.8 所

示。这样的符

号表示也被

称

为

one-hot 表示，因

为它可以表

示成相互排

斥的 n 维二元

向量（其中只

有一位是激

活的）。符号表

示是更广泛

的非分布式

表示类中的

一个具体示

例，它可以包

含很多条

目

，但是每个条

目没有显著

意义的单独

控制作用。

以

下是基于非

分布式表示

的学习算法

的示例：

• 聚类

算法，包含

k-means 算

法：每个输入

点恰好分配

到一个类别

。

• k-最近邻算法

：给定一个输

入，一个或几

个模板或原

型样本与之

关联。在

k > 1

的情

况下，每个输

入都使用多

个值来描述

，但是它们不

能彼此分开

控制，因此

这

不能算真正

的分布式表

示。

• 决策树：给

定输入时，只

有一个叶节

点（和从根到

该叶节点路

径上的点）是

被

激活的。

• 高

斯混合体和

专家混合体

：模板（聚类中

心）或专家关

联一个激活

的程度。和

k-最

近邻算法一

样，每个输入

用多个值表

示，但是这些

值不能轻易

地彼此分开

控制。

•

具有高

斯核 （或其他

类似的局部

核）的核机器

：尽管每个 “支

持向量’’ 或模

板

样本的激

活程度是连

续值，但仍然

会出现和高

斯混合体相

同的问题。

15.4 分

布式表示 467

h1

h2 h3

h

= [1, 1, 1]>

h = [0, 1,

1]>

h = [1,

0, 1]> h =

[1, 1, 0]>

h

= [0, 1, 0]>

h = [0, 0,

1]>

h = [1,

0, 0]>

图

15.7: 基于分布式

表示的学习

算法如何将

输入空间分

割成多个区

域的图示。这

个例子具有

二元

变量 h1，h2，h3。每

个特征通过

为学成的线

性变换设定

输出阀值而

定义。每个特

征将 R

2

分成两

个半平面。令

h

+

i 表示输入点

hi

= 1 的集合；h

−

i 表示

输入点 hi =

0 的集

合。在这个图

示中，每

条线

代表着一个

hi 的决策边界

，对应的箭头

指向边界的

h

+

i 区域。整个表

示在这些半

平面的每个

相交区域都

指定一个唯

一值。例如，表

示值为 [1,

1, 1]⊤ 对应

着区域 h

+

1 ∩ h

+

2 ∩ h

+

3 。可以

将以上表

示

和图

15.8 中的非

分布式表示

进行比较。在

输入维度是

d 的一般情况

下，分布式表

示通过半空

间

（而不是半

平面）的交叉

分割

R

d。具有 n 个

特征的分布

式表示给

O(n

d

) 个

不同区域分

配唯一的编

码，而具有

n 个

样本的最近

邻算法只能

给 n 个不同区

域分配唯一

的编码。因此

，分布式表示

能够

比非分

布式表示多

分配指数级

的区域。注意

并非所有的

h 值都是可取

的（这个例子

中没有 h =

0），

在分

布式表示上

的线性分类

器不能向每

个相邻区域

分配不同的

类别标识；甚

至深度线性

阀值网络

的

VC 维只有

O(w log w)（其中

w 是权重数目

）(Sontag,

1998)。强表示层和

弱分类器层

的组合

是一

个强正则化

项。试图学习

‘‘人’’ 和 ‘‘非人’’

概

念的分类器

不需要给表

示为 ‘‘戴眼镜

的女人’’ 和

‘‘没

有戴眼镜的

男人’’

的输入

分配不同的

类别。容量限

制鼓励每个

分类器关注

少数几个 hi，鼓

励 h

以线性可

分的方式学

习表示这些

类别。

• 基于 n-gram 的

语言或翻译

模型：根据后

缀的树结构

划分上下文

集合（符号序

列）。例如，一个

叶节点可能

对应于最后

两个单词

w1 和

w2。树上的每个

叶节

点分别

估计单独的

参数（有些共

享也是可能

的）。

对于部分

非分布式算

法而言，有些

输出并非是

恒定的，而是

在相邻区域

之间内

468 第十

五章 表示学

习

图

15.8: 最近邻

算法如何将

输入空间分

成不同区域

的图示。最近

邻算法是一

个基于非分

布式表示的

学习算法的

示例。不同的

非分布式算

法可以具有

不同的几何

形状，但是它

们通常将输

入空间分成

区域，每个区

域具有不同

的参数。非分

布式方法的

优点是，给定

足够的参数

，它能够拟合

一个训练

集

，而不需要复

杂的优化算

法。因为它直

接为每个区

域独立地设

置不同的参

数。缺点是，非

分布式

表示

的模型只能

通过平滑先

验来局部地

泛化，因此学

习波峰波谷

多于样本的

复杂函数时

，该方法

是不

可行的。和分

布式表示的

对比，可以参

照图 15.7 。

插。参数

（或样本）的数

量和它们能

够定义区域

的数量之间

仍保持线性

关系。

将分布

式表示和符

号表示区分

开来的一个

重要概念是

，由不同概念

之间的共享

属性而产生

的泛化。作为

纯符号，‘‘猫’’ 和

‘‘狗’’ 之间的距

离和任意其

他两种符号

的

距离一样

。然而，如果将

它们与有意

义的分布式

表示相关联

，那么关于猫

的很多特

点

可以推广到

狗，反之亦然

。例如，我们的

分布式表示

可能会包含

诸如 ‘‘具有皮

毛’’

或 ‘‘腿的数

目’’

这类在 ‘‘猫

’’ 和 ‘‘狗’’

的嵌入

上具有相同

值的项。正如

第 12.4.2 节所

讨论

的，作用于单

词分布式表

示的神经语

言模型比其

他直接对单

词

one-hot 表示进

行

操作的模型

泛化得更好

。分布式表示

具有丰富的

相似性空间

，语义上相近

的概念

（或输

入）在距离上

接近，这是纯

粹的符号表

示所缺少的

特点。

在学习

算法中使用

分布式表示

何时以及为

什么具有统

计优势？当一

个明显复杂

的结构可以

用较少参数

紧致地表示

时，分布式表

示具有统计

上的优点。一

些传统的非

分布式学习

算法仅仅在

平滑假设的

情况下能够

泛化，也就是

说如果 u ≈ v，那么

学习

到的目

标函数 f 通常

具有 f(u)

≈ f(v) 的性质

。有许多方法

来形式化这

样一个假设

，

但其结果是

如果我们有

一个样本

(x, y)，并

且我们知道

f(x) ≈ y，那么我们可

以选取

一个

估计f

ˆ 近似地

满足这些限

制，并且当我

们移动到附

近的输入 x

+ ϵ 时

，f

ˆ

尽可能

少地

发生改变。显

然这个假设

是非常有用

的，但是它会

遭受维数灾

难：学习出一

个

15.4 分布式表

示

469

能够在很

多不同区域

上增加或减

少很多次的

目标函数 1，我

们可能需要

至少和可区

分

区域数量

一样多的样

本。我们可以

将每一个区

域视为一个

类别或符号

：通过让每个

符号（或区域

）具有单独的

自由度，我们

可以学习出

从符号映射

到值的任意

解码器。

然而

，这不能推广

到新区域的

新符号上。

如

果我们幸运

的话，除了平

滑之外，目标

函数可能还

有一些其他

规律。例如，具

有最大池化

的卷积网络

可以在不考

虑对象在图

像中位置（即

使对象的空

间变换不对

应输入空间

的平滑变换

）的情况下识

别出对象。

让

我们检查分

布式表示学

习算法的一

个特殊情况

，它通过对输

入的线性函

数进

行阀值

处理来提取

二元特征。该

表示中的每

个二元特征

将

R

d 分成一对

半空间，如

图

15.7

所示。n 个相应

半空间的指

数级数量的

交集确定了

该分布式表

示学习器能

够

区分多少

区域。空间 R

d 中

的 n 个超平面

的排列组合

能够生成多

少区间？通过

应用

关于超

平面交集的

一般结果 (Zaslavsky, 1975)，我

们发现 (Pascanu

et al., 2014b) 这

个

二元特征表

示能够区分

的空间数量

是

d

∑

j=0

(

n

j

)

= O(n

d

).

(15.4)

因此，我们

会发现关于

输入大小呈

指数级增长

，关于隐藏单

元的数量呈

多项式级增

长。

这提供了

分布式表示

泛化能力的

一种几何解

释：O(nd) 个参数（空

间

R

d 中的 n

个线

性阀值特征

）能够明确表

示输入空间

中 O(n

d

)

个不同区

域。如果我们

没有对数

据

做任何假设

，并且每个区

域使用唯一

的符号来表

示，每个符号

使用单独的

参数去

识别

R

d

中的对应区

域，那么指定

O(n

d

) 个区域需要

O(n

d

) 个样本。更一

般地，分

布式

表示的优势

还可以体现

在我们对分

布式表示中

的每个特征

使用非线性

的、可能

连续

的特征提取

器，而不是线

性阀值单元

的情况。在这

种情况下，如

果具有 k 个参

数的参数变

换可以学习

输入空间中

的 r

个区域（k ≪ r），并

且如果学习

这样的表示

有助于关注

的任务，那么

这种方式会

比非分布式

情景（我们需

要 O(r)

个样本来

获得

相同的

特征，将输入

空间相关联

地划分成 r 个

区域。）泛化得

更好。使用较

少的参数

来

表示模型意

味着我们只

需拟合较少

的参数，因此

只需要更少

的训练样本

去获得良

好

的泛化。

另一

个解释基于

分布式表示

的模型泛化

能力更好的

说法是，尽管

能够明确地

编

1一般来说

，我们可能会

想要学习一

个函数，这个

函数在指数

级数量区域

的表现都是

不同的：在

d-维

空间中，为了

区分每一维

，至少有两个

不同的值。我

们想要函数

f 区分这 2

d

个不

同的区域，需

要 O(2d

) 量级的训

练样本

470 第十

五章 表示学

习

码这么多

不同的区域

，但它们的容

量仍然是很

有限的。例如

，线性阀值单

元神经网

络

的 VC 维仅为 O(w

log w)，其

中 w 是权重的

数目

(Sontag, 1998)。这种限

制出现

的原

因是，虽然我

们可以为表

示空间分配

非常多的唯

一码，但是我

们不能完全

使用

所有的

码空间，也不

能使用线性

分类器学习

出从表示空

间

h 到输出 y 的

任意函数映

射。因此使用

与线性分类

器相结合的

分布式表示

传达了一种

先验信念，待

识别的类

在

h 代表的潜在

因果因子的

函数下是线

性可分的。我

们通常想要

学习类别，例

如所

有绿色

对象的图像

集合，或是所

有汽车图像

集合，但不会

是需要非线

性 XOR

逻辑

的类

别。例如，我们

通常不会将

数据划分成

所有红色汽

车和绿色卡

车作为一个

集合，

所有绿

色汽车和红

色卡车作为

另一个集合

。

到目前为止

讨论的想法

都是抽象的

，但是它们可

以通过实验

验证。Zhou

et al.

(2015) 发现，在

ImageNet

和 Places 基准数据

集上训练的

深度卷积网

络中的隐藏

单

元学成的

特征通常是

可以解释的

，对应人类自

然分配的标

签。在实践中

，隐藏单元并

不能总是学

习出具有简

单语言学名

称的事物，但

有趣的是，这

些事物会在

那些最好

的

计算机视觉

深度网络的

顶层附近出

现。这些特征

的共同之处

在于，我们可

以设想

学习

其中的每个

特征不需要

知道所有其

他特征的所

有配置。Radford et al.

(2015) 发

现

生成模型可

以学习人脸

图像的表示

，在表示空间

中的不同方

向捕获不同

的潜在变

差

因素。图

15.9 展示

表示空间中

的一个方向

对应着该人

是男性还是

女性，而另一

个

方向对应

着该人是否

戴着眼镜。这

些特征都是

自动发现的

，而非先验固

定的。我们

没

有必要为隐

藏单元分类

器提供标签

：只要该任务

需要这样的

特征，梯度下

降就能

在感

兴趣的目标

函数上自然

地学习出语

义上有趣的

特征。我们可

以学习出男

性和女

性之

间的区别，或

者是眼镜的

存在与否，而

不必通过涵

盖所有这些

值组合的样

本来

表征其

他 n

− 1 个特征的

所有配置。这

种形式的统

计可分离性

质能够泛化

到训练期

间

从未见过的

新特征上。

15.5 得

益于深度的

指数增益 471

-

+ =

图

15.9: 生成模型学

到了分布式

表示，能够从

戴眼镜的概

念中区分性

别的概念。如

果我们从一

个

戴眼镜的

男人的概念

表示向量开

始，然后减去

一个没戴眼

镜的男人的

概念表示向

量，最后加上

一

个没戴眼

镜的女人的

概念表示向

量，那么我们

会得到一个

戴眼镜的女

人的概念表

示向量。生成

模

型将所有

这些表示向

量正确地解

码为可被识

别为正确类

别的图像。图

片转载许可

自 Radford

et al.

(2015)。

15.5

得益于深

度的指数增

益

我们已经

在第 6.4.1 节中看

到，多层感知

机是万能近

似器，相比于

浅层网络，一

些函数能够

用指数级小

的深度网络

表示。缩小模

型规模能够

提高统计效

率。在本节

中

，我们描述如

何将类似结

果更一般地

应用于其他

具有分布式

隐藏表示的

模型。

在第 15.4 节

中，我们看到

了一个生成

模型的示例

，能够学习人

脸图像的潜

在解

释因子

，包括性别以

及是否佩戴

眼镜。完成这

个任务的生

成模型是基

于一个深度

神

经网络的

。浅层网络例

如线性网络

不能学习出

这些抽象解

释因子和图

像像素之间

的

复杂关系

。在这个任务

和其他 AI

任务

中，这些因子

几乎彼此独

立地被抽取

，但仍

然对应

到有意义输

入的因素，很

有可能是高

度抽象的，并

且和输入呈

高度非线性

的

关系。我们

认为这需要

深度分布式

表示，需要许

多非线性组

合来获得较

高级的特征

（被视为输入

的函数）或因

子（被视为生

成原因）。

在许

多不同情景

中已经证明

，非线性和重

用特征层次

结构的组合

来组织计算

，可

以使分布

式表示获得

指数级加速

之外，还可以

获得统计效

率的指数级

提升。许多种

类的只有一

个隐藏层的

网络（例如，具

有饱和非线

性，布尔门，和

/积，或 RBF 单

元的

网络）都可以

被视为万能

近似器。在给

定足够多隐

藏单元的情

况下，这个模

型

族是一个

万能近似器

，可以在任意

非零允错级

别近似一大

类函数（包括

所有连续函

数）。然而，隐藏

单元所需的

数量可能会

非常大。关于

深层架构表

达能力的理

论结果

表明

，有些函数族

可以高效地

通过深度 k 层

的网络架构

表示，但是深

度不够（深度

472

第十五章 表

示学习

为 2

或

k − 1）时会需要指

数级（相对于

输入大小而

言）的隐藏单

元。

在第

6.4.1 节中

，我们看到确

定性前馈网

络是函数的

万能近似器

。许多具有单

个隐藏层（潜

变量）的结构

化概率模型

（包括受限玻

尔兹曼机，深

度信念网络

）是

概率分布

的万能近似

器 (Le

Roux and Bengio, 2008,

2010; Montúfar and Ay,

2011;

Montúfar, 2014; Krause

et al., 2013)。

在第

6.4.1 节中

，我们看到足

够深的前馈

网络会比深

度不够的网

络具有指数

级优

势。这样

的结果也能

从诸如概率

模型的其他

模型中获得

。 和-积网络（sum-product

network, SPN） (Poon and

Domingos, 2011) 是

这样的一种

概率模型。这

些模型使

用

多项式回路

来计算一组

随机变量的

概率分布。Delalleau

and Bengio (2011) 表

明存

在一种

概率分布，对

SPN 的最小深度

有要求，以避

免模型规模

呈指数级增

长。后来，

Martens and

Medabalimi (2014) 表明

，任意两个有

限深度的 SPN

之

间都会存在

显

著差异，并

且一些使 SPN 易

于处理的约

束可能会限

制其表示能

力。

另一个有

趣的进展是

，一系列和卷

积网络相关

的深度回路

族表达能力

的理论结

果

，即使让浅度

回路只去近

似深度回路

计算的函数

，也能突出反

映深度回路

的指数

级优

势 (Cohen

et al., 2015)。相比之下

，以前的理论

工作只研究

了浅度回路

必须精

确复

制特定函数

的情况。

15.6 提供

发现潜在原

因的线索

我

们回到最初

的问题之一

来结束本章

：什么原因能

够使一个表

示比另一个

表示

更好？首

先在第

15.3 节中

介绍的一个

答案是，一个

理想的表示

能够区分生

成数据变

化

的潜在因果

因子，特别是

那些与我们

的应用相关

的因素。表示

学习的大多

数策略

都会

引入一些有

助于学习潜

在变差因素

的线索。这些

线索可以帮

助学习器将

这些观

察到

的因素与其

他因素分开

。监督学习提

供了非常强

的线索：每个

观察向量 x 的

标

签y，它通常

直接指定了

至少一个变

差因素。更一

般地，为了利

用丰富的未

标注数

据，表

示学习会使

用关于潜在

因素的其他

不太直接的

提示。这些提

示包含一些

我们

（学习算

法的设计者

）为了引导学

习器而强加

的隐式先验

信息。诸如没

有免费午餐

定

理的这些

结果表明，正

则化策略对

于获得良好

泛化是很有

必要的。当不

可能找到一

个普遍良好

的正则化策

略时，深度学

习的一个目

标是找到一

套相当通用

的正则化策

略，使其能够

适用于各种

各样的 AI

任务

（类似于人和

动物能够解

决的任务）。

在

此，我们提供

了一些通用

正则化策略

的列表。该列

表显然是不

详尽的，但是

15.6 提供发现潜

在原因的线

索 473

给出了一

些学习算法

是如何发现

对应潜在因

素的特征的

具体示例。该

列表在 Bengio

et al.

(2013d) 的第

3.1 节中提出，这

里进行了部

分拓展。

•

平滑

：假设对于单

位 d 和小量 ϵ

有

f(x + ϵd) ≈

f(x)。这个假设允

许学习器从

训练样本泛

化到输入空

间中附近的

点。许多机器

学习算法都

利用了这个

想法，

但它不

能克服维数

灾难难题。

• 线

性：很多学习

算法假定一

些变量之间

的关系是线

性的。这使得

算法能够预

测

远离观测

数据的点，但

有时可能会

导致一些极

端的预测。大

多数简单的

学习

算法不

会做平滑假

设，而会做线

性假设。这些

假设实际上

是不同的，具

有很

大权重

的线性函数

在高维空间

中可能不是

非常平滑的

。参看 Goodfellow

et al.

(2014b) 了解关

于线性假设

局限性的进

一步讨论。

• 多

个解释因子

：许多表示学

习算法受以

下假设的启

发，数据是由

多个潜在解

释

因子生成

的，并且给定

每一个因子

的状态，大多

数任务都能

轻易解决。第

15.3 节

描述了这

种观点如何

通过表示学

习来启发半

监督学习的

。学习 p(x) 的结构

要

求学习出

一些对建模

p(y

| x) 同样有用的

特征，因为它

们都涉及到

相同的潜

在

解释因子。第

15.4

节介绍了这

种观点如何

启发分布式

表示的使用

，表示空间

中

分离的方向

对应着分离

的变差因素

。

• 因果因子：该

模型认为学

成表示所描

述的变差因

素是观察数

据

x 的成因，而

并非反过来

。正如第 15.3 节中

讨论的，这对

于半监督学

习是有利的

，当潜在成

因

上的分布发

生改变，或者

我们应用模

型到一个新

的任务上时

，学成的模型

都

会更加鲁

棒。

• 深度，或者

解释因子的

层次组织：高

级抽象概念

能够通过将

简单概念层

次化来

定义

。从另一个角

度来看，深度

架构表达了

我们认为任

务应该由多

个程序步骤

完成的观念

，其中每一个

步骤回溯到

先前步骤处

理之后的输

出。

• 任务间共

享因素：当多

个对应到不

同变量 yi

的任

务共享相同

的输入 x 时，或

者当每个任

务关联到全

局输入 x

的子

集或者函数

f

(i)

(x) 时，我们会假

设每个

变量

yi 关联到来自

相关因素 h 公

共池的不同

子集。因为这

些子集有重

叠，所

以通过

共享的中间

表示 P(h | x)

来学习

所有的 P(yi

| x)

能够

使任务间共

享统

计强度

。

• 流形：概率质

量集中，并且

集中区域是

局部连通的

，且占据很小

的体积。在连

续情况下，这

些区域可以

用比数据所

在原始空间

低很多维的

低维流形来

近似。

474 第十五

章 表示学习

很多机器学

习算法只在

这些流形上

有效 (Goodfellow

et al., 2014b)。一些机

器

学习算法

，特别是自编

码器，会试图

显式地学习

流形的结构

。

• 自然聚类：很

多机器学习

算法假设输

入空间中每

个连通流形

可以被分配

一个单

独的

类。数据分布

在许多个不

连通的流形

上，但相同流

形上数据的

类别是相同

的。这个假设

激励了各种

学习算法，包

括正切传播

、双反向传播

、流形正切分

类器和对抗

训练。

•

时间和

空间相干性

：慢特征分析

和相关的算

法假设，最重

要的解释因

子随时间

变

化很缓慢，或

者至少假设

预测真实的

潜在解释因

子比预测诸

如像素值这

类原

始观察

会更容易些

。读者可以参

考第 13.3

节，进一

步了解这个

方法。

• 稀疏性

：假设大部分

特征和大部

分输入不相

关，如在表示

猫的图像时

，没有必

要使

用象鼻的特

征。因此，我们

可以强加一

个先验，任何

可以解释为

‘‘存在’’

或 ‘‘不存

在’’ 的特征在

大多数时间

都是不存在

的。

•

简化因子

依赖：在良好

的高级表示

中，因子会通

过简单的依

赖相互关联

。最简

单的可

能是边缘独

立，即 P(h) =

∏

i P(hi)。但是线

性依赖或浅

层自编码器

所

能表示的

依赖关系也

是合理的假

设。这可以从

许多物理定

律中看出来

，并且假

设在

学成表示的

顶层插入线

性预测器或

分解的先验

。

表示学习的

概念将许多

深度学习形

式联系在了

一起。前馈网

络和循环网

络，自

编码器

和深度概率

模型都在学

习和使用表

示。学习最佳

表示仍然是

一个令人兴

奋的

研究方

向。

第十六章

深度学习中

的结构化概

率模

型

深度

学习为研究

者们提供了

许多建模方

式，用以设计

以及描述算

法。其中一

种

形式是

结构

化概率模型

（structured probabilistic model）的思想。我们

曾经在

第

3.14 节

中简要讨论

过结构化概

率模型。此前

简要的介绍

已经足够使

我们充分了

解

如何使用

结构化概率

模型作为描

述第二部分

中某些算法

的语言。现在

在第三部分

，

我们可以看

到结构化概

率模型是许

多深度学习

重要研究方

向的关键组

成部分。作为

讨论这些研

究方向的预

备知识，本章

将更加详细

地描述结构

化概率模型

。本章内容

是

自洽的，所以

在阅读本章

之前读者不

需要回顾之

前的介绍。

结

构化概率模

型使用图来

描述概率分

布中随机变

量之间的直

接相互作用

，从

而描述一

个概率分布

。在这里我们

使用了图论

（一系列结点

通过一系列

边来连接）

中

‘‘图’’

的概念，由

于模型结构

是由图定义

的，所以这些

模型也通常

被称为 图模

型

（graphical model）。

图模型的

研究社群是

巨大的，并提

出过大量的

模型、训练算

法和推断算

法。在本

章中

，我们将介绍

图模型中几

个核心方法

的基本背景

，并且重点描

述已被证明

对深

度学习

社群最有用

的观点。如果

你已经熟知

图模型，那么

你可以跳过

本章的绝大

部

分。然而，我

们相信即使

是资深的图

模型方向的

研究者也会

从本章的最

后一节中获

益匪浅，详见

第

16.7 节，其中我

们强调了在

深度学习算

法中使用图

模型的独特

方式。

相比于

其他图模型

研究领域的

是，深度学习

的研究者们

通常会使用

完全不同的

模型

结构、学

习算法和推

断过程。在本

章中，我们将

指明这种区

别并解释其

中的原因。

我

们首先介绍

了构建大规

模概率模型

时面临的挑

战。之后，我们

介绍如何使

用一

个图来

描述概率分

布的结构。尽

管这个方法

能够帮助我

们解决许多

挑战和问题

，它

本身仍有

很多缺陷。图

模型中的一

个主要难点

就是判断哪

些变量之间

存在直接的

相

475

476 第十六章

深度学习中

的结构化概

率模型

互作

用关系，也就

是对于给定

的问题哪一

种图结构是

最适合的。在

第16.5 节中，我们

通过了解

依

赖（dependency），简要概括

了解决这个

难点的两种

方法。最后，作

为本

章的收

尾，我们在第

16.7 节中讨论深

度学习研究

者使用图模

型特定方式

的独特之处

。

16.1

非结构化建

模的挑战

深

度学习的目

标是使得机

器学习能够

解决许多人

工智能中亟

需解决的挑

战。这

也意味

着它们能够

理解具有丰

富结构的高

维数据。举个

例子，我们希

望AI的算法能

够理解自然

图片1，表示语

音的声音信

号和包含许

多词和标点

的文档。

分类

问题可以把

这样一个来

自高维分布

的数据作为

输入，然后使

用一个类别

的

标签来概

括它——这个标

签可以是照

片中是什么

物品，一段语

音中说的是

哪个单词，

也

可以是一段

文档描述的

是哪个话题

。这个分类过

程丢弃了输

入数据中的

大部分信

息

，然后产生单

个值的输出

（或者是关于

单个输出值

的概率分布

）。这个分类器

通常

可以忽

略输入数据

的很多部分

。例如，当我们

识别一张照

片中的一个

物体时，我们

通常可以忽

略图片的背

景。

我们也可

以使用概率

模型完成许

多其他的任

务。这些任务

通常相比于

分类成本

更

高。其中的一

些任务需要

产生多个输

出。大部分任

务需要对输

入数据整个

结构的

完整

理解，所以并

不能舍弃数

据的一部分

。这些任务包

括以下几个

：

•

估计密度函

数：给定一个

输入 x，机器学

习系统返回

一个对数据

生成分布的

真

实密度函

数 p(x)

的估计。这

只需要一个

输出，但它需

要完全理解

整个输入。即

使向量中只

有一个元素

不太正常，系

统也会给它

赋予很低的

概率。

• 去噪：给

定一个受损

的或者观察

有误的输入

数据 x˜，机器学

习系统返回

一个对

原始

的真实 x 的估

计。举个例子

，有时候机器

学习系统需

要从一张老

相片中去

除

灰尘或者抓

痕。这个系统

会产生多个

输出值（对应

着估计的干

净样本

x 的每

一个元素），并

且需要我们

有一个对输

入的整体理

解（因为即使

只有一个损

坏

的区域，仍

然会显示最

终估计被损

坏）。

•

缺失值的

填补：给定 x 的

某些元素作

为观察值，模

型被要求返

回一个 x

一些

或

者全部未

观察值的估

计或者概率

分布。这个模

型返回的也

是多个输出

。由于这

个模

型需要恢复

x 的每一个元

素，所以它必

须理解整个

输入。

1自然图

片指的是能

够在正常的

环境下被照

相机拍摄的

图片，不同于

合成的图片

，或者一个网

页的截图等

等。

16.1 非结构化

建模的挑战

477

•

采样：模型从

分布 p(x) 中抽取

新的样本。其

应用包括语

音合成，即产

生一个

听起

来很像人说

话的声音。这

个模型也需

要多个输出

以及对输入

整体的良好

建

模。即使样

本只有一个

从错误分布

中产生的元

素，那么采样

的过程也是

错误的。

图 16.1 中

描述了一个

使用较小的

自然图片的

采样任务。

图

16.1: 自然图片的

概率建模。(上

) CIFAR-10 数据集

(Krizhevsky and Hinton, 2009)

中的

32 × 32 像素的样例

图片。(下)

从这

个数据集上

训练的结构

化概率模型

中抽出的样

本。每一个样

本

都出现在

与其欧氏距

离最近的训

练样本的格

点中。这种比

较使得我们

发现这个模

型确实能够

生成

新的图

片，而不是记

住训练样本

。为了方便展

示，两个集合

的图片都经

过了微调。图

片经 Courville

et al. (2011a) 许可转

载。

478 第十六章

深度学习中

的结构化概

率模型

对上

千甚至是上

百万随机变

量的分布建

模，无论从计

算上还是从

统计意义上

说，

都是一个

极具挑战性

的任务。假设

我们只想对

二值的随机

变量建模。这

是一个最简

单的例子，但

是我们仍然

无能为力。对

一个只有

32 × 32 像

素的彩色（RGB）图

片

来说，存在

2

3072 种可能的二

值图片。这个

数量已经超

过了 10800，比宇宙

中的原子

总

数还要多。

通

常意义上讲

，如果我们希

望对一个包

含 n 个离散变

量并且每个

变量都能取

k

个值的 x 的分

布建模，那么

最简单的表

示 P(x)

的方法需

要存储一个

可以查询的

表

格。这个表

格记录了每

一种可能值

的概率，则需

要 k

n

个参数。

基

于下述几个

原因，这种方

式是不可行

的：

• 内存：存储

参数的开销

。

除了极小的

n 和 k 的值，用表

格的形式来

表示这样

一

个分布需要

太多的存储

空间。

• 统计的

高效性：当模

型中的参数

个数增加时

，使用统计估

计器估计这

些参数所

需

要的训练数

据数量也需

要相应地增

加。因为基于

查表的模型

拥有天文数

字级

别的参

数，为了准确

地拟合，相应

的训练集的

大小也是相

同级别的。任

何这样

的模

型都会导致

严重的过拟

合，除非我们

添加一些额

外的假设来

联系表格中

的

不同元素

（正如第 12.4.1

节中

所举的回退

或者平滑 n-gram 模

型）。

•

运行时间

：推断的开销

。 假设我们需

要完成这样

一个推断的

任务，其中我

们需

要使用

联合分布 P(x)

来

计算某些其

他的分布，比

如说边缘分

布 P(x1) 或者是

条

件分布

P(x2 | x1)。计算

这样的分布

需要对整个

表格的某些

项进行求和

操作，

因此这

样的操作的

运行时间和

上述高昂的

内存开销是

一个级别的

。

• 运行时间：采

样的开销。 类

似的，假设我

们想要从这

样的模型中

采样。最简单

的方法就是

从均匀分布

中采样，u ∼

U(0, 1)，然后

把表格中的

元素累加起

来，

直到和大

于 u，然后返回

最后一个加

上的元素。最

差情况下，这

个操作需要

读

取整个表

格，所以和其

他操作一样

，它也需要指

数级别的时

间。

基于表格

操作的方法

的主要问题

是我们显式

地对每一种

可能的变量

子集所产生

的每一种可

能类型的相

互作用建模

。在实际问题

中我们遇到

的概率分布

远比这个简

单。通常，许多

变量只是间

接地相互作

用。

例如，我们

想要对接力

跑步比赛中

一个队伍完

成比赛的时

间进行建模

。假设这

个队

伍有三名成

员：Alice，Bob

和 Carol。在比赛

开始时，Alice 拿着

接力棒，开始

16.2 使用图描述

模型结构

479

跑

第一段距离

。在跑完她的

路程以后，她

把棒递给了

Bob。然后 Bob 开始跑

，再把

棒给 Carol，Carol 跑

最后一棒。我

们可以用连

续变量来建

模他们每个

人完成的时

间。

因为

Alice 第一

个跑，所以她

的完成时间

并不依赖于

其他的人。Bob 的

完成时间依

赖

于

Alice 的完成

时间，因为 Bob 只

能在

Alice 跑完以

后才能开始

跑。如果 Alice 跑得

更快，那么

Bob 也

会完成得更

快。所有其他

关系都可以

被类似地推

出。最后，Carol

的完

成时间依赖

于她的两个

队友。如果 Alice

跑

得很慢，那么

Bob 也会完成得

更慢。

结果，Carol 将

会更晚开始

跑步，因此她

的完成时间

也更有可能

要晚。然而，在

给定

Bob 完成时

间的情况下

，Carol 的完成时间

只是间接地

依赖于 Alice

的完

成时间。如

果

我们已经知

道了 Bob 的完成

时间，知道

Alice 的

完成时间对

估计 Carol 的完成

时

间并无任

何帮助。这意

味着我们可

以通过仅仅

两个相互作

用来建模这

个接力赛。这

两个相互作

用分别是 Alice 的

完成时间对

Bob 的完成时间

的影响和

Bob 的

完成时间

对

Carol 的完成时间

的影响。在这

个模型中，我

们可以忽略

第三种间接

的相互作用

，

即 Alice 的完成时

间对 Carol

的完成

时间的影响

。

结构化概率

模型为随机

变量之间的

直接作用提

供了一个正

式的建模框

架。这种

方式

大大减少了

模型的参数

个数以致于

模型只需要

更少的数据

来进行有效

的估计。

这些

更小的模型

大大减小了

在模型存储

、模型推断以

及从模型中

采样时的计

算开销。

16.2 使用

图描述模型

结构

结构化

概率模型使

用图（在图论

中 ‘‘结点’’

是通

过 ‘‘边’’ 来连接

的）来表示随

机

变量之间

的相互作用

。每一个结点

代表一个随

机变量。每一

条边代表一

个直接相互

作用。这些直

接相互作用

隐含着其他

的间接相互

作用，但是只

有直接的相

互作用会

被

显式地建模

。

使用图来描

述概率分布

中相互作用

的方法不止

一种。在下文

中我们会介

绍几种

最为

流行和有用

的方法。图模

型可以被大

致分为两类

：基于有向无

环图的模型

和基

于无向

图的模型。

480 第

十六章 深度

学习中的结

构化概率模

型

16.2.1

有向模型

有向图模型

（directed graphical model）是一种结构

化概率模型

，也被称为 信

念网络（belief

network）或者

贝叶斯网络

（Bayesian network）2

(Pearl, 1985)。

之所以命名

为有向图模

型是因为所

有的边都是

有方向的，即

从一个结点

指向另

一个

结点。这个方

向可以通过

画一个箭头

来表示。箭头

所指的方向

表示了这个

随机

变量的

概率分布是

由其他变量

的概率分布

所定义的。画

一个从结点

a 到结点

b 的箭

头表示了我

们用一个条

件分布来定

义 b，而 a

是作为

这个条件分

布符号右边

的一个

变量

。换句话说，b 的

概率分布依

赖于 a

的取值

。

我们继续第

16.1 节所讲的接

力赛的例子

，我们假设 Alice

的

完成时间为

t0，Bob

的完成时间

为 t1，Carol 的完成时

间为

t2。就像我

们之前看到

的一样，t1 的估

计是

依赖于

t0 的，t2

的估计是

直接依赖于

t1 的，但是仅仅

间接地依赖

于 t0。我们用一

个有向图模

型来建模这

种关系，如图

16.2 所示。

tt00 tt11 tt22

Alice

Bob Carol

图 16.2:

描述

接力赛例子

的有向图模

型。Alice 的完成时

间 t0 影响了

Bob 的

完成时间 t1，因

为

Bob

只能在 Alice 完

成比赛后才

开始。类似的

，Carol 也只会在

Bob 完

成之后才开

始，所以 Bob

的完

成时间

t1 直接

影响了 Carol 的完

成时间

t2。

正式

地说，变量 x 的

有向概率模

型是通过有

向无环图

G（每

个结点都是

模型中的

随

机变量）和一

系列 局部条

件概率分布

（local conditional

probability distribution）

p(xi

|

P aG(xi)) 来定义的，其

中 P

aG(xi) 表示结点

xi 的所有父结

点。x 的概率分

布

可以表示

为

p(x) = ∏

i

p(xi

| P

aG(xi)). (16.1)

在之前所

述的接力赛

的例子中，参

考图 16.2

，这意味

着概率分布

可以被表示

为

p(t0,t1,t2) = p(t0)p(t1

| t0)p(t2 | t1).

(16.2)

2当我们希

望 ‘‘强调’’ 从网

络中计算出

的值的

‘‘推断

’’ 本质，即强调

这些值代表

的是置信程

度大小而不

是事件的频

率时，Judea Pearl 建议使

用

“贝叶斯网

络’’ 这个术语

。

16.2 使用图描述

模型结构

481

这

是我们看到

的第一个结

构化概率模

型的实际例

子。我们能够

检查这样建

模的

计算开

销，为了验证

相比于非结

构化建模，结

构化建模为

什么有那么

多的优势。

假

设我们采用

从第

0 分钟到

第 10 分钟每

6 秒

一块的方式

离散化地表

示时间。这

使

得 t0，t1

和 t2 都是一

个有 100

个取值

可能的离散

变量。如果我

们尝试着用

一个表

来表

示 p(t0,t1,t2)，那么我们

需要存储 999,

999 个

值（100 个 t0

的可能

取值 × 100

个

t1 的可

能取值 × 100

个 t2 的

可能取值减

去 1，由于存在

所有的概率

之和为

1 的

限

制，所以其中

有 1

个值的存

储是多余的

）。反之，如果我

们用一个表

来记录每一

种

条件概率

分布，那么表

中记录 t0 的分

布需要存储

99

个值，给定 t0 情

况下 t1

的分

布

需要存储 9900 个

值，给定

t1 情况

下 t2 的分布也

需要存储

9900 个

值。加起来总

共需要存储

19, 899 个值。这意味

着使用有向

图模型将参

数的个数减

少了超过

50 倍

！

通常意义上

说，对每个变

量都能取 k

个

值的 n 个变量

建模，基于建

表的方法需

要的复杂度

是 O(k

n

)，就像我们

之前观察到

的一样。现在

假设我们用

一个有向图

模

型来对这

些变量建模

。如果 m

代表图

模型的单个

条件概率分

布中最大的

变量数目

（在

条件符号的

左右皆可），那

么对这个有

向模型建表

的复杂度大

致为 O(k

m)。只要

我

们在设计模

型时使其满

足 m ≪ n，那么复杂

度就会被大

大地减小。

换

一句话说，只

要图中的每

个变量都只

有少量的父

结点，那么这

个分布就可

以

用较少的

参数来表示

。图结构上的

一些限制条

件，比如说要

求这个图为

一棵树，也

可

以保证一些

操作（例如求

一小部分变

量的边缘或

者条件分布

）更加地高效

。

决定哪些信

息需要被包

含在图中而

哪些不需要

是很重要的

。如果变量之

间可以

被假

设为是条件

独立的，那么

这个图可以

包含这种简

化假设。当然

也存在其他

类型

的简化

图模型的假

设。例如，我们

可以假设无

论 Alice 的表现如

何，Bob

总是跑得

一样快（实际

上，Alice 的表现很

大概率会影

响 Bob 的表现，这

取决于

Bob 的性

格，

如果在之

前的比赛中

Alice 跑得特别快

，这有可能鼓

励

Bob 更加努力

并取得更好

的

成绩，当然

这也有可能

使得 Bob

过分自

信或者变得

懒惰）。那么 Alice 对

Bob 的唯

一影响

就是在计算

Bob 的完成时间

时需要加上

Alice 的时间。这个

假设使得我

们所

需要的

参数量从

O(k

2

) 降

到了

O(k)。然而，值

得注意的是

在这个假设

下 t0 和 t1

仍

然是

直接相关的

，因为 t1 表示的

是

Bob 完成时的

时间，并不是

他跑的总时

间。这也

意味

着图中会有

一个从 t0

指向

t1 的箭头。“Bob 的个

人跑步时间

相对于其他

因素是

独立

的’’

这个假设

无法在 t0，t1，t2 的图

中被表示出

来。反之，我们

只能将这个

关系

表示在

条件分布的

定义中。这个

条件分布不

再是一个大

小为

k × k −

1 的分别

对应着

t0，t1 的表

格，而是一个

包含了

k − 1 个参

数的略微复

杂的公式。有

向图模型的

语法

并不能

对我们如何

定义条件分

布作出任何

限制。它只定

义了哪些变

量可以作为

其中

482 第十六

章 深度学习

中的结构化

概率模型

的

参数。

16.2.2 无向模

型

有向图模

型为我们提

供了一种描

述结构化概

率模型的语

言。而另一种

常见的语

言

则是 无向模

型（undirected Model），也被称为

马尔可夫随

机场（Markov random

field, MRF）或者是

马尔可夫网

络（Markov network）(Kindermann, 1980)。就像它

们

的名字所说

的那样，无向

模型中所有

的边都是没

有方向的。

当

存在很明显

的理由画出

每一个指向

特定方向的

箭头时，有向

模型显然最

适用。

有向模

型中，经常存

在我们理解

的具有因果

关系以及因

果关系有明

确方向的情

况。

接力赛的

例子就是一

个这样的情

况。之前运动

员的表现会

影响后面运

动员的完成

时

间，而后面

运动员却不

会影响前面

运动员的完

成时间。

然而

并不是所有

情况的相互

作用都有一

个明确的方

向关系。当相

互的作用并

没

有本质性

的指向，或者

是明确的双

向相互作用

时，使用无向

模型更加合

适。

作为一个

这种情况的

例子，假设我

们希望对三

个二值随机

变量建模：你

是否生

病，你

的同事是否

生病以及你

的室友是否

生病。就像在

接力赛的例

子中所作的

简化

假设一

样，我们可以

在这里做一

些关于相互

作用的简化

假设。假设你

的室友和同

事

并不认识

，所以他们不

太可能直接

相互传染一

些疾病，比如

说感冒。这个

事件太过

罕

见，所以我们

不对此事件

建模。然而，很

有可能其中

之一将感冒

传染给你，然

后

通过你再

传染给了另

一个人。我们

通过对你的

同事传染给

你以及你传

染给你的室

友

建模来对

这种间接的

从你的同事

到你的室友

的感冒传染

建模。

在这种

情况下，你传

染给你的室

友和你的室

友传染给你

都是非常容

易的，所以

模

型不存在一

个明确的单

向箭头。这启

发我们使用

无向模型。其

中随机变量

对应着

图中

的相互作用

的结点。与有

向模型相同

的是，如果在

无向模型中

的两个结点

通过

一条边

相连接，那么

对应这些结

点的随机变

量相互之间

是直接作用

的。不同于有

向

模型，在无

向模型中的

边是没有方

向的，并不与

一个条件分

布相关联。

我

们把对应你

健康状况的

随机变量记

作

hy，对应你的

室友健康状

况的随机变

量

记作 hr，你的

同事健康的

变量记作 hc。图

16.3

表示这种关

系。

正式地说

，一个无向模

型是一个定

义在无向模

型 G 上的结构

化概率模型

。对于

图中的

每一个团3 C，一

个 因子（factor）ϕ(C)(也称

为 团势能（clique

potential）)，

3图

的一个团是

图中结点的

一个子集，并

且其中的点

是全连接的

16.2 使用图描述

模型结构 483

hhrr hhyy hhcc

图

16.3:

表示你室友

健康状况的

hr、你健康状况

的 hy 和你同事

健康状况的

hc 之间如何相

互影响

的一

个无向图。你

和你的室友

可能会相互

传染感冒，你

和你的同事

之间也是如

此，但是假设

你室

友和同

事之间相互

不认识，他们

只能通过你

来间接传染

。

hy =

0 hy = 1

hc = 0 2

1

hc = 1

1 10

衡量了团中

变量每一种

可能的联合

状态所对应

的密切程度

。这些因子都

被限制为是

非负的。它们

一起定义了

未归一化概

率函数（unnormalized probability

function）：

p˜(x) = ∏

C∈G

ϕ(C). (16.3)

只要

所有团中的

结点数都不

大，那么我们

就能够高效

地处理这些

未归一化概

率

函数。它包

含了这样的

思想，密切度

越高的状态

有越大的概

率。然而，不像

贝叶斯网

络

，几乎不存在

团定义的结

构，所以不能

保证把它们

乘在一起能

够得到一个

有效的

概率

分布。图 16.4

展示

了一个从无

向模型中读

取分解信息

的例子。

a b c

d e f

图

16.4: 这

个 图 说

明 通

过 选 择

适 当

的 ϕ， 函

数 p(a, b, c,

d, e, f) 可

以

写 作

1

Z

ϕa,b(a, b)ϕb,c(b, c)ϕa,d(a, d)ϕb,e(b,

e)ϕe,f(e, f)。

在你、你

的室友和同

事之间感冒

传染的例子

中包含了两

个团。一个团

包含了 hy

和 hc。这

个团的因子

可以通过一

个表来定义

，可能取到下

面的值：

状态

为 1

代表了健

康的状态，相

对的状态为

0 则表示不好

的健康状态

（即感染

了感

冒）。你们两个

通常都是健

康的，所以对

应的状态拥

有最高的密

切程度。两个

人

中只有一

个人是生病

的密切程度

是最低的，因

为这是一个

很罕见的状

态。两个人都

484

第十六章 深

度学习中的

结构化概率

模型

生病的

状态（通过一

个人来传染

给了另一个

人）有一个稍

高的密切程

度，尽管仍然

不及两个人

都健康的密

切程度。

为了

完整地定义

这个模型，我

们需要对包

含

hy 和 hr 的团定

义类似的因

子。

16.2.3 配分函数

尽管这个未

归一化概率

函数处处不

为零，我们仍

然无法保证

它的概率之

和或者

积分

为 1。为了得到

一个有效的

概率分布，我

们需要使用

对应的归一

化的概率分

布

4：

p(x) = 1

Z

p˜(x), (16.4)

其中，Z

是使

得所有的概

率之和或者

积分为 1 的常

数，并且满足

：

Z

=

∫

p˜(x)dx. (16.5)

当函数 ϕ 固定

时，我们可以

把 Z

当成是一

个常数。值得

注意的是如

果函数 ϕ 带有

参数时，那么

Z 是这些参数

的一个函数

。在相关文献

中为了节省

空间忽略控

制

Z 的

变量而

直接写 Z

是一

个常用的方

式。归一化常

数 Z 被称作是

配分函数，这

是一个从

统

计物理学中

借鉴的术语

。

由于 Z 通常是

由对所有可

能的 x

状态的

联合分布空

间求和或者

求积分得到

的，

它通常是

很难计算的

。为了获得一

个无向模型

的归一化概

率分布，模型

的结构和函

数 ϕ 的定义通

常需要设计

为有助于高

效地计算

Z。在

深度学习中

，Z 通常是难以

处

理的。由于

Z 难以精确地

计算出，我们

只能使用一

些近似的方

法。这样的近

似方法

是第

十八章的主

要内容。

在设

计无向模型

时，我们必须

牢记在心的

一个要点是

设定一些使

得 Z 不存在

的

因子也是有

可能的。当模

型中的一些

变量是连续

的，且 p˜ 在其定

义域上的积

分发

散时这

种情况就会

发生。例如，当

我们需要对

一个单独的

标量变量

x ∈ R 建

模，并

且单个

团势能定义

为 ϕ(x) = x

2 时。在这种

情况下，

Z =

∫

x

2

dx.

(16.6)

由于

这个积分是

发散的，所以

不存在一个

对应着这个

势能函数 ϕ(x) 的

概率分布。有

时候

ϕ 函数某

些参数的选

择可以决定

相应的概率

分布是否能

够被定义。例

如，对 ϕ

4一个通

过归一化团

势能乘积定

义的分布也

被称作是

吉

布斯分布（Gibbs distribution）

16.2 使

用图描述模

型结构

485

函数

ϕ(x; β) =

exp(−βx2

) 来说，参数 β

决

定了归一化

常数 Z 是否存

在。正的 β

使

得

ϕ 函数是一个

关于 x

的高斯

分布，但是非

正的参数 β 则

使得 ϕ

不可能

被归一化。

有

向建模和无

向建模之间

一个重要的

区别就是有

向模型是通

过从起始点

的概率

分布

直接定义的

，反之无向模

型的定义显

得更加宽松

，通过 ϕ

函数转

化为概率分

布

而定义。这

改变了我们

处理这些建

模问题的直

觉。当我们处

理无向模型

时需要牢记

一点，每一个

变量的定义

域对于一系

列给定的 ϕ 函

数所对应的

概率分布有

着重要的

影

响。举个例子

，我们考虑一

个 n 维向量的

随机变量 x

以

及一个由偏

置向量 b 参数

化的无向模

型。假设 x

的每

一个元素对

应着一个团

，并且满足 ϕ

(i)

(xi)

= exp(bixi)。

在

这种情况下

概率分布是

怎样的呢？答

案是我们无

法确定，因为

我们并没有

指定 x

的定义

域。如果 x 满足

x ∈

R

n，那么有关归

一化常数 Z 的

积分是发散

的，这导

致了

对应的概率

分布是不存

在的。如果 x ∈ {0,

1}

n，那

么 p(x) 可以被分

解成

n 个

独立

的分布，并且

满足 p(xi

= 1) = sigmoid(bi)。如果

x 的

定义域是基

本单位向量

({[1, 0, .

. . , 0],

[0, 1, . .

. , 0], .

. . , [0,

0, . . .

, 1]}) 的集合，那么

p(x) =

softmax(b)，因此

对于 j =

i，一

个较大的 bi 的

值会降低所

有 p(xj

= 1) 的概率。通

常情况下，通

过仔

细选择

变量的定义

域，能够从一

个相对简单

的

ϕ 函数的集

合可以获得

一个相对复

杂

的表达。我

们会在第 20.6

节

中讨论这个

想法的实际

应用。

16.2.4 基于能

量的模型

无

向模型中许

多有趣的理

论结果都依

赖于

∀x, p˜(x) > 0

这个假

设。使这个条

件

满足的一

种简单方式

是使用 基于

能量的模型

（Energy-based model,

EBM），其中

p˜(x) = exp(−E(x)),

(16.7)

E(x) 被称作

是 能量函数

（energy

function）。对所有的 z，exp(z) 都

是正的，这保

证

了没有一

个能量函数

会使得某一

个状态

x 的概

率为 0。我们可

以完全自由

地选择那

些

能够简化学

习过程的能

量函数。如果

我们直接学

习各个团势

能，我们需要

利用约

束优

化方法来任

意地指定一

些特定的最

小概率值。学

习能量函数

的过程中，我

们可

以采用

无约束的优

化方法5。基于

能量的模型

中的概率可

以无限趋近

于 0 但是永远

达

不到 0。

服从

式 (16.7)

形式的任

意分布都是

玻尔兹曼分

布（Boltzmann distribution）

的一个实

例。正是基于

这个原因，我

们把许多基

于能量的模

型称为 玻尔

兹曼机

5对于

某些模型，我

们可以仍然

使用约束优

化方法来确

保 Z 存在。

486

第十

六章 深度学

习中的结构

化概率模型

（Boltzmann Machine） (Fahlman

et al., 1983; Ackley

et al., 1985; Hinton

et al.,

1984a; Hinton

and Sejnowski, 1986)。关于什么时

候称之为基

于能量的模

型，什么时

候

称之为玻尔

兹曼机不存

在一个公认

的判别标准

。一开始玻尔

兹曼机这个

术语是用

来

描述一个只

有二值变量

的模型，但是

如今许多模

型，比如均值

-协方差 RBM，也

涉

及到了实值

变量。虽然玻

尔兹曼机最

初的定义既

可以包含潜

变量也可以

不包含潜

变

量，但是时至

今日玻尔兹

曼机这个术

语通常用于

指拥有潜变

量的模型，而

没有潜

变量

的玻尔兹曼

机则经常被

称为马尔可

夫随机场或

对数线性模

型。

无 向 模

型

中 的团对 应

于未 归

一 化

概 率 函

数中

的因 子。通 过

exp(a +

b) =

exp(a) exp(b)，我们发现无

向模型中的

不同团对应

于能量函数

的不同项。换

句话说，

基于

能量的模型

只是一种特

殊的马尔可

夫网络：求幂

使能量函数

中的每个项

对应

于不同

团的一个因

子。关于如何

从无向模型

结构中获得

能量函数形

式的示例可

以参

考图 16.5

。人

们可以将能

量函数中带

有多个项的

基于能量的

模型视作是

专家之积

（product of expert）

(Hinton, 1999)。能

量函数中的

每一项对应

的是概率分

布中的

一个

因子。能量函

数中的每一

项都可以看

作决定一个

特定的软约

束是否能够

满足的

‘‘专家

’’。每个专家只

执行一个约

束，而这个约

束仅仅涉及

随机变量的

一个低维投

影，

但是当其

结合概率的

乘法时，专家

们一同构造

了复杂的高

维约束。

a b c

d e f

图

16.5: 这

个图说明通

过为每个团

选择适当的

能量函数 E(a, b,

c, d, e, f)

可

以写作 Ea,b(a, b) +

Eb,c(b, c) + Ea,d(a,

d) + Eb,e(b, e)

+ Ee,f(e, f)。值得

注意的是，我

们令 ϕ

等于对

应负能量的

指数，

可以获

得图16.4中的 ϕ 函

数，比如，ϕa,b(a,

b) = exp(−E(a, b))。

基于

能量的模型

定义的一部

分无法用机

器学习观点

来解释：即式

(16.7) 中的 “-’’

符号。这

个

“-’’ 符号可以

被包含在 E 的

定义之中。对

于很多

E 函数

的选择来说

，学

习算法可

以自由地决

定能量的符

号。这个负号

的存在主要

是为了保持

机器学习文

献

和物理学

文献之间的

兼容性。概率

建模的许多

研究最初都

是由统计物

理学家做出

的，

其中 E 是指

实际的、物理

概念的能量

，没有任何符

号。诸如 ‘‘能量

’’

和 “配分函数

’’

这类术语仍

然与这些技

术相关联，尽

管它们的数

学适用性比

在物理中更

宽。一些机

器

学习研究者

（例如，Smolensky

(1986) 将负能

量称为 harmony）发出

了不同的声

16.2 使用图描述

模型结构

487

音

，但这些都不

是标准惯例

。

许 多

对 概 率

模 型

进 行 操

作 的

算 法 不

需 要

计 算 pmodel(x)， 而

只

需 要 计 算

log

p˜model(x)。对于具有潜

变量 h 的基于

能量的模型

，这些算法有

时会将该量

的负数

称为

自由能（free

energy）：

F(x) = −

log∑

h

exp(−E(x, h)).

(16.8)

在本

书中，我们更

倾向于更为

通用的基于

log p˜model(x) 的定义。

16.2.5 分离

和 d-分离

图模

型中的边告

诉我们哪些

变量直接相

互作用。我们

经常需要知

道哪些变量

间

接相互作

用。某些间接

相互作用可

以通过观察

其他变量来

启用或禁用

。更正式地，我

们想知道在

给定其他变

量子集的值

时，哪些变量

子集彼此条

件独立。

在无

向模型中，识

别图中的条

件独立性是

非常简单的

。在这种情况

下，图中隐

含

的条件独立

性称为 分离

（separation）。如果图结构

显示给定变

量集

S 的情况

下变

量集 A

与

变量集 B 无关

，那么我们声

称给定变量

集 S

时，变量集

A 与另一组变

量

集 B

是分离

的。如果连接

两个变量 a 和

b 的连接路径

仅涉及未观

察变量，那么

这些

变量不

是分离的。如

果它们之间

没有路径，或

者所有路径

都包含可观

测的变量，那

么它们是分

离的。我们认

为仅涉及未

观察到的变

量的路径是

‘‘活跃’’ 的，而包

括可观

察变

量的路径称

为 ‘‘非活跃’’

的

。

当我们画图

时，我们可以

通过加阴影

来表示观察

到的变量。图

16.6 用于描述当

以这种方式

绘图时无向

模型中的活

跃和非活跃

路径的样子

。图 16.7

描述了一

个从无

向模

型中读取分

离信息的例

子。

a s

b a s b

(a) (b)

图 16.6:

(a) 随机变

量 a 和随机变

量

b 之间穿过

s 的路径是活

跃的，因为 s

是

观察不到的

。这意

味着 a，b 之

间不是分离

的。(b)

图中 s 用阴

影填充，表示

它是可观察

的。因为 a

和 b 之

间的唯一

路

径通过

s，并且

这条路径是

不活跃的，我

们可以得出

结论，在给定

s 的条件下 a 和

b

是分离的。

488 第

十六章 深度

学习中的结

构化概率模

型

a

b c

d

图 16.7: 从一个

无向图中读

取分离性质

的一个例子

。这里 b

用阴影

填充，表示它

是可观察的

。由于

b 挡住了

从 a

到 c 的唯一

路径，我们说

在给定 b

的情

况下 a 和 c

是相

互分离的。观

察值 b 同样

挡

住了从

a 到 d 的

一条路径，但

是它们之间

有另一条活

跃路径。因此

给定

b 的情况

下 a 和

d 不

是分

离的。

类似的

概念适用于

有向模型，只

是在有向模

型中，这些概

念被称为

d-分

离（d￾separation）。“d’’ 代表 “依赖

’’ 的意思。有向

图中d-分离的

定义与无向

模型中分离

的

定义相同

：如果图结构

显示给定变

量集 S 时，变量

集 A

与变量集

B 无关，那么我

们

认为给定

变量集 S

时，变

量集 A d-分离于

变量集 B。

与无

向模型一样

，我们可以通

过查看图中

存在的活跃

路径来检查

图中隐含的

独

立性。如前

所述，如果两

个变量之间

存在活跃路

径，则两个变

量是依赖的

，如果没

有活

跃路径，则为

d-分离。在有向

网络中，确定

路径是否活

跃有点复杂

。关于在有向

模型中识别

活跃路径的

方法可以参

考图 16.8

。图 16.9 是从

一个图中读

取一些属性

的

例子。

尤其

重要的是要

记住分离和

d-分离只能告

诉我们图中

隐含的条件

独立性。图并

不需要表示

所有存在的

独立性。进一

步的，使用完

全图（具有所

有可能的边

的图）来

表示

任何分布总

是合法的。事

实上，一些分

布包含不可

能用现有图

形符号表示

的独

立性。 特

定环境下的

独立（context-specific

independences）指的是

取决于网络

中一

些变量

值的独立性

。例如，考虑三

个二值变量

的模型：a，b 和 c。假

设当

a 是 0 时，

b 和

c 是独立的，但

是当 a

是 1 时，b 确

定地等于

c。当

a = 1 时图模型需

要连接

b

和 c 的

边。但是图不

能说明当

a = 0 时

b

和 c 不是独立

的。

一般来说

，当独立性不

存在时，图不

会显示独立

性。然而，图可

能无法编码

独立

性。

16.2 使用

图描述模型

结构 489

a s b

a

s b

a

s

b a s b

a s b

c

(a) (b)

(c) (d)

图 16.8: 两个

随机变量 a，b

之

间存在的长

度为 2 的所有

种类的活跃

路径。(a) 箭头方

向从

a 指向

b 的

任何路径，反

过来也一样

。如果

s 可以被

观察到，这种

路径就是阻

塞的。在接力

赛的例子中

，

我们已经看

到过这种类

型的路径。(b) 变

量

a 和 b 通过共

因

s 相连。举个

例子，假设 s 是

一个表

示是

否存在飓风

的变量，a 和 b 表

示两个相邻

气象监控区

域的风速。如

果我们在

a 处

观察到很高

的风速，我们

可以期望在

b 处也观察到

高速的风。如

果观察到 s，那

么这条路径

就被阻塞了

。如果

我们已

经知道存在

飓风，那么无

论 a 处观察到

什么，我们都

能期望 b

处有

较高的风速

。在 a 处观

察到

一个低于预

期的风速（对

飓风而言）并

不会改变我

们对

b 处风速

的期望（已知

有飓风的情

况

下）。然而，如

果 s

不被观测

到，那么 a 和 b

是

依赖的，即路

径是活跃的

。(c) 变量 a 和

b 都是

s 的父节点。这

称为 V-结构（V-structure）或

者

碰撞情况

（the collider case）。根据 相消解

释作

用（explaining away effect），V-结构

导致 a

和 b 是相

关的。在这种

情况下，当 s

被

观测到时路

径

是活跃的

。举个例子，假

设 s 是一个表

示你的同事

不在工作的

变量。变量

a 表

示她生病了

，而变

量 b

表示

她在休假。如

果你观察到

了她不在工

作，你可以假

设她很有可

能是生病了

或者是在度

假，

但是这两

件事同时发

生是不太可

能的。如果你

发现她在休

假，那么这个

事实足够解

释她的缺席

了。

你可以推

断她很可能

没有生病。(d) 即

使

s 的任意后

代都被观察

到，相消解释

作用也会起

作用。举

个例

子，假设 c

是一

个表示你是

否收到你同

事的报告的

一个变量。如

果你注意到

你还没有收

到这

个报告

，这会增加你

估计的她今

天不在工作

的概率，这反

过来又会增

加她今天生

病或者度假

的概

率。阻塞

V-结构中路径

的唯一方法

就是共享子

节点的后代

一个都观察

不到。

490

第十六

章 深度学习

中的结构化

概率模型

a b

c

d e

图

16.9:

从这张图中

，我们可以发

现一些 d-分离

的性质。这包

括了：

• 给定空

集的情况下

，a

和 b 是 d-分离的

。

• 给定 c 的情况

下，a

和 e 是 d-分离

的。

• 给定 c 的情

况下，d

和 e 是 d-分

离的。

我们还

可以发现当

我们观察到

一些变量时

，一些变量不

再是 d-分离的

：

• 给定

c 的情况

下，a 和 b

不是 d-分

离的。

• 给定

d 的

情况下，a 和 b

不

是 d-分离的。

16.2.6 在

有向模型和

无向模型中

转换

我们经

常将特定的

机器学习模

型称为无向

模型或有向

模型。例如，我

们通常将受

限玻尔兹曼

机称为无向

模型，而稀疏

编码则被称

为有向模型

。这种措辞的

选择可能

有

点误导，因为

没有概率模

型本质上是

有向或无向

的。但是，一些

模型很适合

使用

有向图

描述，而另一

些模型很适

合使用无向

模型描述。

有

向模型和无

向模型都有

其优点和缺

点。这两种方

法都不是明

显优越和普

遍优

选的。相

反，我们根据

具体的每个

任务来决定

使用哪一种

模型。这个选

择部分取决

于我们希望

描述的概率

分布。根据哪

种方法可以

最大程度地

捕捉到概率

分布中的独

立性，或者哪

种方法使用

最少的边来

描述分布，我

们可以决定

使用有向建

模还是无

向

建模。还有其

他因素可以

影响我们决

定使用哪种

建模方式。即

使在使用单

个概率

分布

时，我们有时

也可以在不

同的建模方

式之间切换

。有时，如果我

们观察到变

量

的某个子

集，或者如果

我们希望执

行不同的计

算任务，换一

种建模方式

可能更合适

。

例如，有向模

型通常提供

了一种高效

地从模型中

抽取样本（在

第 16.3 节中描述

）的

直接方法

。而无向模型

形式通常对

于推导近似

推断过程（我

们将在第十

九章中看到

，

式 (19.56) 强调了无

向模型的作

用）是很有用

的。

16.2

使用图描

述模型结构

491

每个概率分

布可以由有

向模型或由

无向模型表

示。在最坏的

情况下，我们

可以

使用 “完

全图’’

来表示

任何分布。在

有向模型的

情况下，完全

图是任意有

向无环图，

其

中我们对随

机变量排序

，并且每个变

量在排序中

位于其之前

的所有其他

变量作为

其

图中的祖先

。对于无向模

型，完全图只

是包含所有

变量的单个

团。图 16.10

给出了

一个实例。

图

16.10: 完全图的例

子，完全图能

够描述任何

的概率分布

。这里我们展

示了一个带

有四个随机

变

量的例子

。(左)

完全无向

图。在无向图

中，完全图是

唯一的。(右) 一

个完全有向

图。在有向图

中，

并不存在

唯一的完全

图。我们选择

一种变量的

排序，然后对

每一个变量

，从它本身开

始，向每一个

指向顺序在

其后面的变

量画一条弧

。因此存在着

关于变量数

阶乘数量级

的不同种完

全图。在这个

例子中，我们

从左到右从

上到下地排

序变量。

当然

，图模型的优

势在于图能

够包含一些

变量不直接

相互作用的

信息。完全图

并

不是很有

用，因为它并

不隐含任何

独立性。

当我

们用图表示

概率分布时

，我们想要选

择一个包含

尽可能多独

立性的图，但

是并不会假

设任何实际

上不存在的

独立性。

从这

个角度来看

，一些分布可

以使用有向

模型更高效

地表示，而其

他分布可以

使用无向模

型更高效地

表示。换句话

说，有向模型

可以编码一

些无向模型

所不能编

码

的独立性，反

之亦然。

有向

模型能够使

用一种无向

模型无法完

美表示的特

定类型的子

结构。这个子

结

构被称为

不道德（immorality）。这种

结构出现在

当两个随机

变量 a 和

b 都是

第三个

随机

变量 c

的父结

点，并且不存

在任一方向

上直接连接

a 和 b 的边时。（“不

道德’’

的名字

可能看起来

很奇怪; 它在

图模型文献

中使用源于

一个关于未

婚父母的笑

话。）

为了将有

向模型图 D

转

换为无向模

型，我们需要

创建一个新

图 U。对于每对

变量 x

和

y，如果

存在连接 D 中

的 x

和 y 的有向

边（在任一方

向上），或者如

果 x

和 y 都

是图

D

中另一个变

量 z 的父节点

，则在 U

中添加

连接 x 和 y

的无

向边。得到的

图

U 被称为是

道德图（moralized graph）。关于

一个通过道

德化将有向

图模型转化

为无

向模型

的例子可以

参考图 16.11 。

492

第十

六章 深度学

习中的结构

化概率模型

hh11 hh22 hh33

vv11 vv22 vv33

a

b

c

a

c

b

hh11 hh22 hh33

vv11 vv22 vv33

a

b

c

a

c

b

图 16.11: 通过构造

道德图将有

向模型（上一

行）转化为无

向模型（下一

行）的例子。(左

)

只需要

把有

向边替换成

无向边就可

以把这个简

单的链转化

为一个道德

图。得到的无

向模型包含

了完全相

同

的独立关系

和条件独立

关系。(中) 这个

图是在不丢

失独立性的

情况下是无

法转化为无

向模型的

最

简单的有向

模型。这个图

包含了单个

完整的不道

德结构。因为

a 和 b 都是

c 的父

节点，当 c 被

观

察到时，它们

之间通过活

跃路径相连

。为了捕捉这

个依赖，无向

模型必须包

含一个含有

所有三

个变

量的团。这个

团无法编码

a ⊥ b

这个信息。(右

) 一般来说，道

德化的过程

会给图添加

许多边，

因此

丢失了一些

隐含的独立

性。举个例子

，这个稀疏编

码图需要在

每一对隐藏

单元之间添

加道德

化的

边，因此也引

入了二次数

量级的新的

直接依赖。

同

样的，无向模

型可以包括

有向模型不

能完美表示

的子结构。具

体来说，如果

U

包含长度大

于 3 的

环（loop），则有

向图 D 不能捕

获无向模型

U 所包含的所

有条件

独立

性，除非该环

还包含 弦（chord）。环

指的是由无

向边连接的

变量序列，并

且满

足序列

中的最后一

个变量连接

回序列中的

第一个变量

。弦是定义环

序列中任意

两个

非连续

变量之间的

连接。如果

U 具

有长度为 4 或

更大的环，并

且这些环没

有弦，我

们必

须在将它们

转换为有向

模型之前添

加弦。添加这

些弦会丢弃

在 U 中编码的

一些

16.2

使用图

描述模型结

构 493

独立信息

。通过将弦添

加到 U

形成的

图被称为 弦

图（chordal graph）或者 三角

形化

图（triangulated graph），因为

我们现在可

以用更小的

、三角的环来

描述所有的

环。

要从弦图

构建有向图

D，我们还需要

为边指定方

向。当这样做

时，我们不能

在 D

中

创建有

向循环，否则

将无法定义

有效的有向

概率模型。为

D 中的边分配

方向的一种

方法是对随

机变量排序

，然后将每个

边从排序较

早的节点指

向排序稍后

的节点。一

个

简单的实例

可以参考图

16.12

。

a b

d

c

a b

d

c

a b

d

c

图 16.12: 将一个无

向模型转化

为一个有向

模型。(左)

这个

无向模型无

法转化为有

向模型，因为

它

有一个长

度为 4 且不带

有弦的环。具

体说来，这个

无向模型包

含了两种不

同的独立性

，并且不存

在

一个有向模

型可以同时

描述这两种

性质：a ⊥ c |

{b, d} 和 b

⊥ d | {a,

c}。(中) 为

了将无向图

转化为有向

图，我们必须

通过保证所

有长度大于

3 的环都有弦

来三角形化

图。为了实现

这个目标，

我

们可以加一

条连接

a 和 c 或

者连接

b 和 d 的

边。在这个例

子中，我们选

择添加一条

连接

a 和 c

的边

。(右)

为了完成

转化的过程

，我们必须给

每条边分配

一个方向。执

行这个任务

时，我们必须

保证不产生

任何有向环

。避免出现有

向环的一种

方法是赋予

节点一定的

顺序，然后将

每个边从排

序较早的节

点指向排序

稍后的节点

。在这个例子

中，我们根据

变量名的字

母进行排序

。

16.2.7 因子图

因子

图（factor

graph）是从无向

模型中抽样

的另一种方

法，它可以解

决标准无

向

模型语法中

图表达的模

糊性。在无向

模型中，每个

ϕ 函数的范围

必须是图中

某

个团的子

集。我们无法

确定每一个

团是否含有

一个作用域

包含整个团

的因子——比

如

说一个包含

三个结点的

团可能对应

的是一个有

三个结点的

因子，也可能

对应的是

三

个因子并且

每个因子包

含了一对结

点，这通常会

导致模糊性

。通过显式地

表示每

一个

ϕ 函数的作用

域，因子图解

决了这种模

糊性。具体来

说，因子图是

一个包含无

向

二分图的

无向模型的

图形化表示

。一些节点被

绘制为圆形

。就像在标准

无向模型中

一样，这些节

点对应于随

机变量。其余

节点绘制为

方块。这些节

点对应于未

归一化

概率

函数的因子

ϕ。变量和因子

可以通过无

向边连接。当

且仅当变量

包含在未归

一

化概率函

数的因子中

时，变量和因

子在图中存

在连接。没有

因子可以连

接到图中的

494 第十六章

深

度学习中的

结构化概率

模型

另一个

因子，也不能

将变量连接

到变量。图 16.2.7 给

出了一个例

子来说明因

子图如

何解

决无向网络

中的模糊性

。

a b

c

a b

c

ff11

a b

c

ff11

ff22

ff33

图 16.13:

因子图如

何解决无向

网络中的模

糊性的一个

例子。(左) 一个

包含三个变

量（a、b 和 c）

的团组

成的无向网

络。(中) 对应这

个无向模型

的因子图。这

个因子图有

一个包含三

个变量的因

子。

(右) 对应这

个无向模型

的另一种有

效的因子图

。这个因子图

包含了三个

因子，每个因

子只对应两

个变量。即使

它们表示的

是同一个无

向模型，这个

因子图上进

行的表示、推

断和学习相

比于中图

描

述的因子图

都要渐近地

廉价。

16.3 从图模

型中采样

图

模型同样简

化了从模型

中采样的过

程。

有向图模

型的一个优

点是，可以通

过一个简单

高效的过程

从模型所表

示的联合

分

布中产生样

本，这个过程

被称为 原始

采样（Ancestral Sampling）。

原始采

样的基本思

想是将图中

的变量 xi 使用

拓扑排序，使

得对于所有

i 和

j，如

果 xi 是

xj 的

一个父亲结

点，则 j 大于

i。然

后可以按此

顺序对变量

进行采样。换

句

话说，我们

可以首先采

x1 ∼ P(x1)，然后采

x2 ∼ P(x2 |

P aG(x2))，以此

类推，直到

最

后我们从 P(xn

| P aG(xn)) 中

采样。只要不

难从每个条

件分布

xi ∼ P(xi

|

P aG(xi))

中采

样，那么从整

个模型中采

样也是容易

的。拓扑排序

操作保证我

们可以按照

式 (16.1)

中条件分

布的顺序依

次采样。如果

没有拓扑排

序，我们可能

会在其父节

点

可用之前

试图对该变

量进行抽样

。

有些图可能

存在多个拓

扑排序。原始

采样可以使

用这些拓扑

排序中的任

何一个。

原始

采样通常非

常快（假设从

每个条件分

布中采样都

是很容易的

）并且非常简

便。

原始采样

的一个缺点

是其仅适用

于有向图模

型。另一个缺

点是它并不

是每次采

16.4 结

构化建模的

优势 495

样都是

条件采样操

作。当我们希

望从有向图

模型中变量

的子集中采

样时，给定一

些

其他变量

，我们经常要

求所有给定

的条件变量

在顺序图中

比要采样的

变量的顺序

要

早。在这种

情况下，我们

可以从模型

分布指定的

局部条件概

率分布中采

样。否则，我

们

需要采样的

条件分布是

给定观测变

量的后验分

布。这些后验

分布在模型

中通常没

有

明确指定和

参数化。推断

这些后验分

布的代价可

能是很高的

。在这种情况

下的模

型中

，原始采样不

再有效。

不幸

的是，原始采

样仅适用于

有向模型。我

们可以通过

将无向模型

转换为有向

模型来实现

从无向模型

中抽样，但是

这通常需要

解决棘手的

推断问题（要

确定新有

向

图的根节点

上的边缘分

布），或者需要

引入许多边

从而会使得

到的有向模

型变得难

以

处理。从无向

模型采样，而

不首先将其

转换为有向

模型的做法

似乎需要解

决循环

依赖

的问题。每个

变量与每个

其他变量相

互作用，因此

对于采样过

程没有明确

的起

点。不幸

的是，从无向

模型中抽取

样本是一个

成本很高的

多次迭代的

过程。理论上

最简单的方

法是 Gibbs

采样（Gibbs Sampling）。假

设我们在一

个 n 维向量的

随机

变量 x 上

有一个图模

型。我们迭代

地访问每个

变量 xi，在给定

其他变量的

条件下从

p(xi

| x−i) 中

抽样。由于图

模型的分离

性质，抽取

xi 时

我们可以等

价地仅对 xi 的

邻

居条件化

。不幸的是，在

我们遍历图

模型一次并

采样所有 n 个

变量之后，我

们仍然

无法

得到一个来

自

p(x) 的客观样

本。相反，我们

必须重复该

过程并使用

它们邻居的

更新值对所

有 n 个变量重

新取样。在多

次重复之后

，该过程渐近

地收敛到正

确的目

标分

布。我们很难

确定样本何

时达到所期

望分布的足

够精确的近

似。无向模型

的采

样技术

是一个高级

的研究方向

，第十七章将

对此进行更

详细的讨论

。

16.4 结构化建模

的优势

使用

结构化概率

模型的主要

优点是它们

能够显著降

低表示概率

分布、学习和

推

断的成本

。有向模型中

采样还可以

被加速，但是

对于无向模

型情况则较

为复杂。选

择

不对某些变

量的相互作

用进行建模

是允许所有

这些操作使

用较少的运

行时间和内

存的主要机

制。图模型通

过省略某些

边来传达信

息。在没有边

的情况下，模

型假设

不对

变量间直接

的相互作用

建模。

结构化

概率模型允

许我们明确

地将给定的

现有知识与

知识的学习

或者推断分

开，

这是一个

不容易量化

的益处。这使

我们的模型

更容易开发

和调试。我们

可以设计、

分

析和评估适

用于更广范

围的图的学

习算法和推

断算法。同时

，我们可以设

计能够

捕捉

到我们认为

数据中存在

的重要关系

的模型。然后

，我们可以组

合这些不同

的算

496 第十六

章 深度学习

中的结构化

概率模型

法

和结构，并获

得不同可能

性的笛卡尔

乘积。然而，为

每种可能的

情况设计端

到端

的算法

会更加困难

。

16.5 学习依赖关

系

良好的生

成模型需要

准确地捕获

所观察到的

或

‘‘可见’’ 变量

v 上的分布。通

常

v

的不同元

素彼此高度

依赖。在深度

学习中，最常

用于建模这

些依赖关系

的方法是

引

入几个潜在

或 ‘‘隐藏’’ 变量

h。然后，该模型

可以捕获任

何对（变量

vi 和

vj 间

接依赖可

以通过

vi 和 h 之

间直接依赖

和

h 和 vj 直接依

赖捕获)

之间

的依赖关系

。

如果一个良

好的关于 v 的

模型不包含

任何潜变量

，那么它在贝

叶斯网络中

的每

个节点

需要具有大

量父节点或

在马尔可夫

网络中具有

非常大的团

。仅仅表示这

些高

阶相互

作用的成本

就很高了，首

先从计算角

度上考虑，存

储在存储器

中的参数数

量

是团中成

员数量的指

数级别，接着

在统计学意

义上，因为这

些指数数量

的参数需要

大量的数据

来准确估计

。

当模型旨在

描述直接连

接的可见变

量之间的依

赖关系时，通

常不可能连

接所有

变量

，因此设计图

模型时需要

连接那些紧

密相关的变

量，并忽略其

他变量之间

的

作用。机器

学习中有一

个称为 结构

学习（structure learning）的领域

专门讨论这

个

问题。Koller and Friedman (2009)

是一

个不错的结

构学习参考

资料。大多数

结构学

习技

术基于一种

贪婪搜索的

形式。它们提

出了一种结

构，对具有该

结构的模型

进行

训练，然

后给出分数

。该分数奖励

训练集上的

高精度并对

模型的复杂

度进行惩罚

。然

后提出添

加或移除少

量边的候选

结构作为搜

索的下一步

。搜索向一个

预计会增加

分

数的新结

构发展。

使用

潜变量而不

是自适应结

构避免了离

散搜索和多

轮训练的需

要。可见变量

和潜变量之

间的固定结

构可以使用

可见单元和

隐藏单元之

间的直接作

用，从而建模

可见单元之

间的间接作

用。使用简单

的参数学习

技术，我们可

以学习到一

个具有固

定

结构的模型

，这个模型在

边缘分布 p(v)

上

拥有正确的

结构。

潜变量

除了发挥本

来的作用，即

能够高效地

描述 p(v) 以外，还

具有另外的

优

势。新变量

h 还提供了 v 的

替代表示。例

如，如第

3.9.6 节所

示，高斯混合

模型学习

了

一个潜变量

，这个潜变量

对应于输入

样本是从哪

一个混合体

中抽出。这意

味着高

斯混

合模型中的

潜变量可以

用于做分类

。我们可以看

到第十四章

中简单的概

率模型

如稀

疏编码，是如

何学习可以

用作分类器

输入特征或

者作为流形

上坐标的潜

变量的。

16.6 推断

和近似推断

497

其他模型也

可以使用相

同的方式，但

是更深的模

型和具有多

种相互作用

方式的模型

可以获得更

丰富的输入

描述。许多方

法通过学习

潜变量来完

成特征学习

。通常，给

定 v 和

h，实验观察显

示 E[h

| v] 或 arg

maxh

p(h, v) 都是

v 的

良好特征映

射。

16.6 推断和近

似推断

解决

变量之间如

何相互关联

的问题是我

们使用概率

模型的一个

主要方式。给

定

一组医学

测试，我们可

以询问患者

可能患有什

么疾病。在一

个潜变量模

型中，我们

可

能需要提取

能够描述可

观察变量 v

的

特征 E[h | v]。有时我

们需要解决

这些问题

来

执行其他任

务。我们经常

使用最大似

然的准则来

训练我们的

模型。由于

log p(v) =

Eh∼p(h|v)

[log p(h, v)

− log p(h |

v)], (16.9)

学

习过程中，我

们经常需要

计算 p(h

| v)。所有这

些都是 推断

（inference）问题的例

子

，其中我们必

须预测给定

其他变量的

情况下一些

变量的值，或

者在给定其

他变量

值的

情况下预测

一些变量的

概率分布。

不

幸的是，对于

大多数有趣

的深度模型

来说，即使我

们使用结构

化图模型来

简

化这些推

断问题，它们

仍然是难以

处理的。图结

构允许我们

用合理数量

的参数来表

示复杂的高

维分布，但是

用于深度学

习的图并不

满足这样的

条件，从而难

以实现高

效

地推断。

我们

可以直接看

出，计算一般

图模型的边

缘概率是 #P-hard 的

。复杂性类别

#P 是复杂性类

别

NP 的泛化。NP 中

的问题只需

确定其中一

个问题是否

有解决方

案

，并找到一个

解决方案（如

果存在）就可

以解决。#P

中的

问题需要计

算解决方案

的数量。为了

构建最坏情

况的图模型

，我们可以设

想一下我们

在 3-SAT 问题中定

义

二值变量

的图模型。我

们可以对这

些变量施加

均匀分布。然

后我们可以

为每个子句

添加一个二

值潜变量，来

表示每个子

句是否成立

。然后，我们可

以添加另一

个潜变

量，来

表示所有子

句是否成立

。这可以通过

构造一个潜

变量的缩减

树来完成，树

中

的每个结

点表示其他

两个变量是

否成立，从而

不需要构造

一个大的团

。该树的叶是

每个子句的

变量。树的根

表示整个问

题是否成立

。由于子句的

均匀分布，缩

减树根

结点

的边缘分布

表示子句有

多少比例是

成立的。虽然

这是一个设

计的最坏情

况的例

子，NP-hard

图

确实会频繁

地出现在现

实世界的场

景中。

这促使

我们使用近

似推断。在深

度学习中，这

通常涉及变

分推断，其中

通过寻

求尽

可能接近真

实分布的近

似分布 q(h

| v) 来逼

近真实分布

p(h |

v)。这个技术将

在

498 第十六章

深度学习中

的结构化概

率模型

第十

九章中深入

讨论。

16.7 结构化

概率模型的

深度学习方

法

深度学习

从业者通常

与其他从事

结构化概率

模型研究的

机器学习研

究者使用相

同的基本计

算工具。然而

，在深度学习

中，我们通常

对如何组合

这些工具作

出不同

的设

计决定，导致

总体算法、模

型与更传统

的图模型具

有非常不同

的风格。

深度

学习并不总

是涉及特别

深的图模型

。在图模型中

，我们可以根

据图模型的

图而不是计

算图来定义

模型的深度

。如果从潜变

量 hi 到可观察

变量的最短

路径是 j

步，我

们可以认为

潜变量 hj 处于

深度 j。我们通

常将模型的

深度描述为

任何这样的

hj

的最大深度

。这种深度不

同于由计算

图定义的深

度。用于深度

学习的许多

生成模

型没

有潜变量或

只有一层潜

变量，但使用

深度计算图

来定义模型

中的条件分

布。

深度学习

基本上总是

利用分布式

表示的思想

。即使是用于

深度学习目

的的浅层

模

型（例如预训

练浅层模型

，稍后将形成

深层模型），也

几乎总是具

有单个大的

潜变

量层。深

度学习模型

通常具有比

可观察变量

更多的潜变

量。变量之间

复杂的非线

性

相互作用

通过多个潜

变量的间接

连接来实现

。

相比之下，传

统的图模型

通常包含至

少是偶尔观

察到的变量

，即使一些训

练样

本中的

许多变量随

机地丢失。传

统模型大多

使用高阶项

和结构学习

来捕获变量

之间

复杂的

非线性相互

作用。如果有

潜变量，它们

的数量通常

很少。

潜变量

的设计方式

在深度学习

中也有所不

同。深度学习

从业者通常

不希望潜变

量提前包含

了任何特定

的含义——训练

算法可以自

由地开发对

特定数据集

建模所需

要

的概念。在事

后解释潜变

量通常是很

困难的，但是

可视化技术

可以得到它

们表示

的一

些粗略表征

。当潜变量在

传统图模型

中使用时，它

们通常被赋

予一些特定

含义

——比如文

档的主题、学

生的智力、导

致患者症状

的疾病等。这

些模型通常

由研究

者解

释，并且通常

具有更多的

理论保证，但

是不能扩展

到复杂的问

题，并且不能

像

深度模型

一样在许多

不同背景中

重复使用。

另

一个明显的

区别是深度

学习方法中

经常使用的

连接类型。深

度图模型通

常具

有大的

与其他单元

组全连接的

单元组，使得

两个组之间

的相互作用

可以由单个

矩阵

描述。传

统的图模型

具有非常少

的连接，并且

每个变量的

连接选择可

以单独设计

。

模型结构的

设计与推断

算法的选择

紧密相关。图

模型的传统

方法通常旨

在保持精确

推断的可解

性。当这个约

束太强时，我

们可以采用

一种流行的

被称为 环状

信念传播

16.7 结

构化概率模

型的深度学

习方法 499

（loopy

belief propagation）的近

似推断算法

。这两种方法

通常在稀疏

连接图上都

有

很好的效

果。相比之下

，在深度学习

中使用的模

型倾向于将

每个可见单

元 vi

连接到

非

常多的隐藏

单元 hj 上，从而

使得

h 可以获

得一个 vi 的分

布式表示（也

可能是其

他

几个可观察

变量）。分布式

表示具有许

多优点，但是

从图模型和

计算复杂性

的观点

来看

，分布式表示

有一个缺点

就是很难产

生对于精确

推断和环状

信念传播等

传统技

术来

说足够稀疏

的图。结果，大

规模图模型

和深度图模

型最大的区

别之一就是

深度

学习中

几乎从来不

会使用环状

信念传播。相

反的，许多深

度学习模型

可以设计来

加

速 Gibbs 采样或

者变分推断

。此外，深度学

习模型包含

了大量的潜

变量，使得高

效

的数值计

算代码显得

格外重要。除

了选择高级

推断算法之

外，这提供了

另外的动机

，

用于将结点

分组成层，相

邻两层之间

用一个矩阵

来描述相互

作用。这要求

实现算法

的

单个步骤可

以实现高效

的矩阵乘积

运算，或者专

门适用于稀

疏连接的操

作，例如

块对

角矩阵乘积

或卷积。

最后

，图模型的深

度学习方法

的一个主要

特征在于对

未知量的较

高容忍度。与

简化模型直

到它的每一

个量都可以

被精确计算

不同的是，我

们仅仅直接

使用数据运

行或者是训

练，以增强模

型的能力。我

们一般使用

边缘分布不

能计算的模

型，但可

以从

中简单地采

近似样本。我

们经常训练

具有难以处

理的目标函

数的模型，我

们甚

至不能

在合理的时

间内近似，但

是如果我们

能够高效地

获得这样一

个函数的梯

度估

计，我们

仍然能够近

似训练模型

。深度学习方

法通常是找

出我们绝对

需要的最小

量

信息，然后

找出如何尽

快得到该信

息的合理近

似。

16.7.1 实例：受限

玻尔兹曼机

受限玻尔兹

曼机（Restricted Boltzmann Machine,

RBM）(Smolensky, 1986) 或

者

簧

风琴（harmonium）是图模

型如何用于

深度学习的

典型例子。RBM 本

身不是一

个

深层模型。相

反，它有一层

潜变量，可用

于学习输入

的表示。在第

二十章中，我

们

将看到

RBM 如

何被用来构

建许多的深

层模型。在这

里，我们举例

展示了 RBM 在

许

多深度图模

型中使用的

实践：它的单

元被分成很

大的组，这种

组称作层，层

之间

的连接

由矩阵描述

，连通性相对

密集。该模型

被设计为能

够进行高效

的 Gibbs 采样，

并且

模型设计的

重点在于以

很高的自由

度来学习潜

变量，而潜变

量的含义并

不是设

计者

指定的。之后

在第20.2 节，我们

将更详细地

再次讨论 RBM。

标

准的 RBM 是具有

二值的可见

和隐藏单元

的基于能量

的模型。其能

量函数为

E(v,

h) = −b

⊤

v − c

⊤h

− v

⊤Wh, (16.10)

500 第

十六章 深度

学习中的结

构化概率模

型

其中

b, c 和 W

都

是无约束、实

值的可学习

参数。我们可

以看到，模型

被分成两组

单元：v 和 h，它们

之间的相互

作用由矩阵

W 来描述。该模

型在图

16.14 中以

图的

形式描

绘。该图能够

使我们更清

楚地发现，该

模型的一个

重要方面是

在任何两个

可

见单元之

间或任何两

个隐藏单元

之间没有直

接的相互作

用（因此称为

‘‘受限’’，一般

的

玻尔兹曼机

可以具有任

意连接）。

hh11 hh22 hh33

vv11 vv22 vv33

hh44

图 16.14: 一

个画成马尔

可夫网络形

式的RBM。

对

RBM 结构

的限制产生

了良好的属

性

p(h |

v) = ∏

i

p(hi

| v) (16.11)

以及

p(v | h)

= ∏

i

p(vi

| h). (16.12)

独立

的条件分布

很容易计算

。对于二元的

受限玻尔兹

曼机，我们可

以得到：

p(hi = 1 |

v) = σ

(

v

⊤W:,i + bi

)

, (16.13)

p(hi

= 0 | v)

= 1 − σ

(

v

⊤W:,i +

bi

)

. (16.14)

结合

这些属性可

以得到高效

的 块吉布斯

采样（block Gibbs Sampling），它在同

时采

样所有

h 和同时采样

所有 v 之间交

替。RBM

模型通过

Gibbs 采样产生的

样本展示

在

图 16.15

中。

由于能

量函数本身

只是参数的

线性函数，很

容易获取能

量函数的导

数。例如，

∂

∂Wi,j

E(v, h) = −vihj

. (16.15)

这两

个属性，高效

的 Gibbs

采样和导

数计算，使训

练过程变得

非常方便。在

第十

八章中

，我们将看到

，可以通过计

算应用于这

种来自模型

样本的导数

来训练无向

模

型。

16.7

结构化

概率模型的

深度学习方

法 501

图 16.15:

训练好

的 RBM 的样本及

其权重。(左) 用

MNIST

训练模型，然

后用 Gibbs 采样进

行

采样。每一

列是一个单

独的

Gibbs 采样过

程。每一行表

示另一个 1000 步

后

Gibbs 采样的输

出。

连续的样

本之间彼此

高度相关。(右

) 对应的权重

向量。将本图

结果与图13.2中

描述的线性

因子模

型的

样本和权重

相比。由于 RBM 的

先验 p(h)

没有限

制为因子，这

里的样本表

现得好很多

。采样

时 RBM 能够

学习到哪些

特征需要一

起出现。另一

方面说，RBM

后验

p(h | v) 是因子的，而

稀疏

编码的

后验并不是

，所以在特征

提取上稀疏

编码模型表

现得更好。其

他的模型可

以使用非因

子的

p(h) 和非因

子的 p(h

| h)。图片经

LISA (2008) 允许转载。

训

练模型可以

得到数据 v 的

表示 h。我们经

常使用

Eh∼p(h|v)

[h] 作为

一组描述 v

的

特征。

总的来

说，RBM 展示了典

型的图模型

深度学习方

法：使用多层

潜变量，并由

矩

阵参数化

层之间的高

效相互作用

来完成表示

学习。

图模型

为描述概率

模型提供了

一种优雅、灵

活、清晰的语

言。在未来的

章节中，

我们

将使用这种

语言，以其他

视角来描述

各种各样的

深度概率模

型。

第十七章

蒙特卡罗方

法

随机算法

可以粗略地

分为两类：Las

Vegas 算

法和蒙特卡

罗算法。Las Vegas 算

法

总是精确地

返回一个正

确答案（或者

返回算法失

败了）。这类方

法通常需要

占用随

机量

的计算资源

（一般指内存

或运行时间

）。与此相对的

，蒙特卡罗方

法返回的答

案

具有随机

大小的错误

。花费更多的

计算资源（通

常包括内存

和运行时间

）可以减少

这

种错误。在任

意固定的计

算资源下，蒙

特卡罗算法

可以得到一

个近似解。

对

于机器学习

中的许多问

题来说，我们

很难得到精

确的答案。这

类问题很难

用

精确的确

定性算法如

Las Vegas 算法解决。取

而代之的是

确定性的近

似算法或蒙

特卡

罗近似

方法。这两种

方法在机器

学习中都非

常普遍。本章

主要关注蒙

特卡罗方法

。

17.1 采样和蒙特

卡罗方法

机

器学习中的

许多重要工

具都基于从

某种分布中

采样以及用

这些样本对

目标量

做一

个蒙特卡罗

估计。

17.1.1 为什么

需要采样？

有

许多原因使

我们希望从

某个分布中

采样。当我们

需要以较小

的代价近似

许多

项的和

或某个积分

时，采样是一

种很灵活的

选择。有时候

，我们使用它

加速一些很

费时却易于

处理的求和

估计，就像我

们使用小批

量对整个训

练代价进行

子采样一样

。

在其他情况

下，我们需要

近似一个难

以处理的求

和或积分，例

如估计一个

无向模

型中

配分函数对

数的梯度时

。在许多其他

情况下，抽样

实际上是我

们的目标，例

如

我们想训

练一个可以

从训练分布

采样的模型

。

502

17.1 采样和蒙特

卡罗方法 503

17.1.2 蒙

特卡罗采样

的基础

当无

法精确计算

和或积分（例

如，和具有指

数数量个项

，且无法被精

确简化）

时，通

常可以使用

蒙特卡罗采

样来近似它

。这种想法把

和或者积分

视作某分布

下的

期望，然

后通过估计

对应的平均

值来近似这

个期望。令

s =

∑

x

p(x)f(x) = Ep[f(x)]

(17.1)

或

者

s =

∫

p(x)f(x)dx = Ep[f(x)]

(17.2)

为我们所

需要估计的

和或者积分

，写成期望的

形式，p 是一个

关于随机变

量 x

的概

率分

布（求和时）或

者概率密度

函数（求积分

时）。

我们可以

通过从 p

中抽

取 n 个样本 x

(1)

, . .

. , x

(n)

来

近似 s 并得到

一个经验平

均

值

sˆn =

1

n

n∑

i=1

f(x

(i)

). (17.3)

下面几

个性质表明

了这种近似

的合理性。首

先很容易观

察到 sˆ

这个估

计是无偏的

，

由于

E[ˆsn] =

1

n

n∑

i=1

E[f(x

(i)

)] =

n

1 ∑n

i=1

s = s. (17.4)

此外，根

据 大数定理

（Law of large

number），如果样本 x

(i) 是

独立同分布

的，那么

其平

均值几乎必

然收敛到期

望值，即

lim n−→∞

sˆn

= s, (17.5)

只需

要满足各个

单项的方差

Var[f(x

(i)

)] 有界。详细地

说，我们考虑

当 n

增大时 sˆn

的

方差。只要满

足 Var[f(x

(i)

)] < ∞，方差

Var[ˆsn] 就会

减小并收敛

到 0：

Var[ˆsn]

= 1

n2

∑n

i=1

Var[f(x)] (17.6)

=

Var[f(x)]

n

. (17.7)

504 第十七章

蒙特卡罗方

法

这个简单

有用的结果

启迪我们如

何估计蒙特

卡罗均值中

的不确定性

，或者等价地

说

是蒙特卡

罗估计的期

望误差。我们

计算了

f(x

(i)

) 的经

验均值和方

差1，然后将估

计的

方差除

以样本数 n 来

得到 Var[ˆsn]

的估计

。 中心极限定

理（central limit theorem）

告诉我们

sˆn 的分布收敛

到以 s 为均值

以

Var[

n

f(x)] 为方差的

正态分布。这

使得我们可

以利用正态

分布的累积

函数来估计

sˆn

的置信区间

。

以上的所有

结论都依赖

于我们可以

从基准分布

p(x) 中轻易地采

样，但是这个

假设并不是

一直成立的

。当我们无法

从 p

中采样时

，一个备选方

案是用第 17.2 节

讲

到的重要

采样。一种更

加通用的方

式是构建一

个收敛到目

标分布的估

计序列。这就

是马尔可夫

链蒙特卡罗

方法（见第

17.3 节

）。

17.2 重要采样

如

方程 (17.2)所示，在

蒙特卡罗方

法中，对积分

（或者和）分解

，确定积分中

哪

一部分作

为概率分布

p(x) 以及哪一部

分作为被积

的函数

f(x)（我们

感兴趣的是

估

计 f(x) 在概率

分布

p(x) 下的期

望）是很关键

的一步。p(x)f(x) 不存

在唯一的分

解，

因为它总

是可以被写

成

p(x)f(x) = q(x)

p(x)f(x)

q(x)

, (17.8)

在这里，我

们从

q 分布中

采样，然后估

计 pf

q

在此分布

下的均值。许

多情况中，我

们

希望在给

定 p 和

f 的情况

下计算某个

期望，这个问

题既然是求

期望，那么很

自然地

p 和

f 是

一种分解选

择。然而，如果

考虑达到某

给定精度所

需要的样本

数量，这个

问

题最初的分

解选择不是

最优的选择

。幸运的是，最

优的选择 q

∗ 可

以被简单地

推导

出来。这

种最优的采

样函数 q

∗ 对应

所谓的最优

重要采样。

从

式 (17.8)

所示的关

系中可以发

现，任意蒙特

卡罗估计

sˆp =

n

1

n∑

i=1,x

(i)∼p

f(x

(i)

) (17.9)

可

以被转化为

一个重要采

样的估计

sˆq =

1

n

n∑

i=1,x

(i)∼q

p(x

(i)

)f(x

(i)

)

q(x

(i))

.

(17.10)

1通

常我们会倾

向于计算方

差的无偏估

计，它由偏差

的平方和除

以 n −

1 而非 n 得到

。

17.2 重要采样 505

我

们可以容易

地发现估计

的期望与

q 分

布无关：

Eq[ˆsq] =

Ep[ˆsp] = s. (17.11)

然而

，重要采样的

方差可能对

q 的选择非常

敏感。这个方

差可以表示

为

Var[ˆsq] =

Var [

p(x

q(

)

x

f

)

(x)

]

/n. (17.12)

方差想要

取到最小值

，q 需要满足

q

∗

(x) = p(x)|f(x)|

Z

, (17.13)

在

这里 Z

表示归

一化常数，选

择适当的 Z 使

得 q

∗

(x) 之和或者

积分为 1。一个

更好

的重要

采样分布会

把更多的权

重放在被积

函数较大的

地方。事实上

，当 f(x) 的正负

符

号不变时，Var[ˆsq

∗ ] = 0，这

意味着当使

用最优的

q 分

布时，只需要

一个样本就

足

够了。当然

，这仅仅是因

为计算 q

∗ 时已

经解决了原

问题。所以在

实践中这种

只需要

采样

一个样本的

方法往往是

无法实现的

。

对于重要采

样来说任意

q

分布都是可

行的（从得到

一个期望上

正确的值的

角度

来说），q

∗ 指

的是最优的

q

分布（从得到

最小方差的

角度上考虑

）。从 q

∗ 中采样往

往是不可行

的，但是其他

仍然能降低

方差的

q 的选

择还是可行

的。

另一种方

法是采用 有

偏重要采样

（biased

importance sampling），这种方法有

一个优势，即

不需要归一

化的 p 或

q 分布

。在处理离散

变量时，有偏

重要采样估

计

可以表示

为

sˆBIS

=

∑n

i=1

p(x

(i)

)

q(x

(i))

f(x

(i)

)

∑n

i=1

p(x

(i))

q(x

(i))

(17.14)

=

∑n

i=1

p(x

(i)

)

q˜(x

(i))

f(x

(i)

)

∑n

i=1

p(x

(i))

q˜(x

(i))

(17.15)

=

∑n

i=1

˜p(x

(i)

)

q˜(x

(i))

f(x

(i)

)

∑n

i=1

˜p(x

(i))

q˜(x

(i))

, (17.16)

其中

p˜ 和 q˜ 分

别是分布

p 和

q 的未经归一

化的形式，x

(i)

是

从分布 q 中抽

取的样本。

这

种估计是有

偏的，因为

E[ˆsBIS] = s，只

有当 n

→ ∞ 且方程

式 (17.14)

的分母收

敛

到 1 时，等式

才渐近地成

立。所以这一

估计也被称

为渐近无偏

的。

506 第十七章

蒙特卡罗方

法

一个好的

q 分布的选择

可以显著地

提高蒙特卡

罗估计的效

率，而一个糟

糕的

q

分布选

择则会使效

率更糟糕。我

们回过头来

看看方程 式

(17.12) 会发现，如果

存在一

个 q 使

得 p(x

q

)

(

f

x)

(x) 很大，那么

这个估计的

方差也会很

大。当 q(x)

很小，而

f(x) 和 p(x)

都较大并

且无法抵消

q

时，这种情况

会非常明显

。q 分布经常会

取一些简单

常用的分

布

使得我们能

够从 q

分布中

容易地采样

。当 x 是高维数

据时，q 分布的

简单性使得

它

很难与 p 或

者 p|f|

相匹配。当

q(x

(i)

) ≫

p(x

(i)

)|f(x

(i)

)| 时，重要采样

采到了很多

无

用的样本

（很小的数或

零相加）。另一

种相对少见

的情况是 q(x

(i)

) ≪ p(x

(i)

)|f(x

(i)

)|，

相

应的比值会

非常大。正因

为后一个事

件是很少发

生的，这种样

本很难被采

到，通

常使得

对 s 的估计出

现了典型的

欠估计，很难

被整体的过

估计抵消。这

样的不均匀

情况在高维

数据屡见不

鲜，因为在高

维度分布中

联合分布的

动态域可能

非常大。

尽管

存在上述的

风险，但是重

要采样及其

变种在机器

学习的应用

中仍然扮演

着

重要的角

色，包括深度

学习算法。例

如，重要采样

被应用于加

速训练具有

大规模词

表

的神经网络

语言模型的

过程中（见第

12.4.3.3 节）或者其他

有着大量输

出结点的神

经网络中。此

外，还可以看

到重要采样

应用于估计

配分函数（一

个概率分布

的归一

化常

数），详见第18.7 节

，以及在深度

有向图模型

比如变分自

编码器中估

计对数似然

（详见第 20.10.3 节）。采

用随机梯度

下降训练模

型参数时重

要采样可以

用来改进对

代

价函数梯

度的估计，尤

其是分类器

这样的模型

，其中代价函

数的大部分

代价来自于

少量错误分

类的样本。在

这种情况下

，更加频繁地

抽取这些困

难的样本可

以减小梯

度

估计的方差

(Hinton et al.,

2006a)。

17.3 马尔可夫链

蒙特卡罗方

法

在许多实

例中，我们希

望采用蒙特

卡罗方法，然

而往往又不

存在一种简

单的方法

可

以直接从目

标分布 pmodel(x) 中精

确采样或者

一个好的（方

差较小的）重

要采样分

布

q(x)。在深度学习

中，当分布

pmodel(x) 表

示成无向模

型时，这种情

况往往会发

生。

在这种情

况下，为了从

分布 pmodel(x)

中近似

采样，我们引

入了一种称

为 马尔可夫

链（Markov Chain）的数学工

具。利用马尔

可夫链来进

行蒙特卡罗

估计的这一

类算

法被称

为

马尔可夫

链蒙特卡罗

（Markov Chain Monte Carlo,

MCMC）方法。Koller

and Friedman (2009)

花了大

量篇幅来描

述马尔可夫

链蒙特卡罗

算法在机器

学习中的

应

用。MCMC 技术最标

准、最一般的

理论保证只

适用于那些

各状态概率

均不为零的

模型。因此，这

些技术最方

便的使用方

法是用于从

基于能量的

模型（Energy-based

model）即

p(x) ∝ exp(−E(x)) 中采

样，见第

16.2.4 节。在

EBM 的公式表述

中，每

17.3

马尔可

夫链蒙特卡

罗方法 507

一个

状态所对应

的概率都不

为零。事实上

，MCMC 方法可以被

广泛地应用

在包含

0

概率

状态的许多

概率分布中

。然而，在这种

情况下，关于

MCMC 方法性能的

理论保

证只

能依据具体

不同类型的

分布具体分

析证明。在深

度学习中，我

们通常依赖

于那

些一般

的理论保证

，其在所有基

于能量的模

型都能自然

成立。

为了解

释从基于能

量的模型中

采样困难的

原因，我们考

虑一个包含

两个变量

的

EBM 的例子，记

p(a, b) 为

其分布。为了

采 a，我们必须

先从

p(a | b) 中采样

；为

了采 b，我们

又必须从 p(b |

a) 中

采样。这似乎

成了棘手的

先有鸡还是

先有蛋的问

题。

有向模型

避免了这一

问题因为它

的图是有向

无环的。为了

完成 原始采

样（Ancestral

Sampling），在给定每

个变量的所

有父结点的

条件下，我们

根据拓扑顺

序采样每一

个

变量，这个

变量是确定

能够被采样

的（详见第 16.3 节

）。原始采样定

义了一种高

效

的、单遍的

方法来抽取

一个样本。

在

EBM 中，我们通过

使用马尔可

夫链来采样

，从而避免了

先有鸡还是

先有蛋

的问

题。马尔可夫

链的核心思

想是从某个

可取任意值

的状态

x 出发

。随着时间的

推

移，我们随

机地反复更

新状态 x。最终

x

成为了一个

从 p(x) 中抽出的

（非常接近）

比

较一般的样

本。在正式的

定义中，马尔

可夫链由一

个随机状态

x

和一个转移

分布

T(x

′

|

x) 定义而

成，T(x

′

|

x) 是一个概

率分布，说明

了给定状态

x 的情况下随

机地

转移到

x

′ 的概率。运行

一个马尔可

夫链意味着

根据转移分

布 T(x

′

| x) 采出的值

x

′

来更新状态

x。

为了给出 MCMC 方

法为何有效

的一些理论

解释，重参数

化这个问题

是很有用

的

。首先我们关

注一些简单

的情况，其中

随机变量 x 有

可数个状态

。我们将这种

状

态简单地

记作正整数

x。不同的整数

x

的大小对应

着原始问题

中 x 的不同状

态。

接下来我

们考虑如果

并行地运行

无穷多个马

尔可夫链的

情况。不同马

尔可夫

链的

所有状态都

采样自某一

个分布 q

(t)

(x)，在这

里

t 表示消耗

的时间数。开

始时，对

每个

马尔可夫链

，我们采用一

个分布 q

0 来任

意地初始化

x。之后，q

(t) 与所有

之前

运行的

马尔可夫链

有关。我们的

目标是 q

(t)

(x)

收敛

到 p(x)。

因为我们

已经用正整

数 x

重参数化

了这个问题

，我们可以用

一个向量 v 来

描述

这个概

率分布

q，

q(x = i)

= vi

. (17.17)

然后

我们考虑更

新单一的马

尔可夫链，从

状态 x 到新状

态 x

′。单一状态

转移到

508 第十

七章 蒙特卡

罗方法

x

′ 的概

率可以表示

为

q

(t+1)(x

′

) =

∑

x

q

(t)

(x)T(x

′

| x).

(17.18)

根据状态

为整数的参

数化设定，我

们可以将转

移算子 T 表示

成一个矩阵

A。矩

阵 A 的定义

如下：

Ai,j

= T(x

′ =

i | x =

j). (17.19)

使用这

一定义，我们

可以改写式

(17.18) 。不同于之前

使用

q 和 T 来理

解单个状态

的

更新，我们

现在可以使

用 v 和 A

来描述

当我们更新

时（并行运行

的）不同马尔

可夫

链上整

个分布是如

何变化的：

v

(t)

= Av(t−1)

. (17.20)

重

复地使用马

尔可夫链更

新相当于重

复地与矩阵

A 相乘。换言之

，我们可以认

为这

一过程

就是关于 A

的

幂乘：

v

(t) =

A

t

v

(0)

. (17.21)

矩阵 A

有

一种特殊的

结构，因为它

的每一列都

代表一个概

率分布。这样

的矩阵

被称

为 随机矩阵

（Stochastic Matrix）。如果对于任

意状态

x 到任

意其他状态

x

′ 存在

一个 t 使

得转移概率

不为 0，那么

Perron-Frobenius 定

理 (Perron, 1907;

Frobenius,

1908) 可以保证

这个矩阵的

最大特征值

是实数且大

小为 1。我们可

以看到所有

的特征

值随

着时间呈现

指数变化：

v

(t) =

(Vdiag(λ)V

−1

)

t

v

(0) = Vdiag(λ)

tV

−1

v

(0)

. (17.22)

这

个过程导致

了所有不等

于 1

的特征值

都衰减到 0。在

一些额外的

较为宽松的

假

设下，我们

可以保证矩

阵 A

只有一个

对应特征值

为 1 的特征向

量。所以这个

过程

收敛到

平稳分布（Stationary

Distribution），有

时也被称为

均衡分布（Equilibrium

Distribution）。收

敛时，我们得

到

v

′

= Av = v,

(17.23)

这个条件

也适用于收

敛之后的每

一步。这就是

特征向量方

程。作为收敛

的稳定点，v

一

定是特征值

为 1

所对应的

特征向量。这

个条件保证

收敛到了平

稳分布以后

，再重

17.3 马尔可

夫链蒙特卡

罗方法 509

复转

移采样过程

不会改变所

有不同马尔

可夫链上状

态的分布（尽

管转移算子

自然而

然地

会改变每个

单独的状态

）。

如果我们正

确地选择了

转移算子 T，那

么最终的平

稳分布q

将会

等于我们所

希

望采样的

分布 p。我们会

将第 17.4

节介绍

如何选择 T。

可

数状态马尔

可夫链的大

多数性质可

以被推广到

连续状态的

马尔可夫链

中。在

这种情

况下，一些研

究者把这种

马尔可夫链

称为

哈里斯

链（Harris Chain），但是我

们

将这两种情

况都称为马

尔可夫链。通

常在一些宽

松的条件下

，一个带有转

移算子

T

的马

尔可夫链都

会收敛到一

个不动点，这

个不动点可

以写成如下

形式：

q

′

(x

′

) = Ex∼qT(x

′

| x), (17.24)

这个方

程的离散版

本就相当于

重新改写方

程 式 (17.23) 。当

x 是离

散值时，这个

期

望对应着

求和，而当 x

是

连续值时，这

个期望对应

的是积分。

无

论状态是连

续的还是离

散的，所有的

马尔可夫链

方法都包括

了重复、随机

地

更新直到

最后状态开

始从均衡分

布中采样。运

行马尔可夫

链直到它达

到均衡分布

的

过程通常

被称为马尔

可夫链的

磨

合（Burning-in）过程。在马

尔可夫链达

到均衡分

布

之后，我们可

以从均衡分

布中抽取一

个无限多数

量的样本序

列。这些样本

服从同

一分

布，但是两个

连续的样本

之间会高度

相关。所以一

个有限的序

列无法完全

表

达均衡分

布。一种解决

这个问题的

方法是每隔

n

个样本返回

一个样本，从

而使得我

们

对于均衡分

布的统计量

的估计不会

被 MCMC 方法的样

本之间的相

关性所干扰

。所

以马尔可

夫链的计算

代价很高，主

要源于达到

均衡分布前

需要磨合的

时间以及在

达

到均衡分

布之后从一

个样本转移

到另一个足

够无关的样

本所需要的

时间。如果我

们

想要得到

完全独立的

样本，那么我

们可以同时

并行地运行

多个马尔可

夫链。这种方

法使用了额

外的并行计

算来减少时

延。使用一条

马尔可夫链

来生成所有

样本的策略

和（使用多条

马尔可夫链

）每条马尔可

夫链只产生

一个样本的

策略是两种

极端。深

度学

习的从业者

们通常选取

的马尔可夫

链的数目和

小批量中的

样本数相近

，然后从

这些

固定的马尔

可夫链集合

中抽取所需

要的样本。马

尔可夫链的

数目通常选

为 100。

另一个难

点是我们无

法预先知道

马尔可夫链

需要运行多

少步才能到

达均衡分布

。

这段时间通

常被称为

混

合时间（Mixing Time）。检测

一个马尔可

夫链是否达

到平衡

是很

困难的。我们

并没有足够

完善的理论

来解决这个

问题。理论只

能保证马尔

可夫

链会最

终收敛，但是

无法保证其

他。如果我们

从矩阵

A 作用

在概率向量

v 上的角度

来

分析马尔可

夫链，那么我

们可以发现

当

A

t 除了单个

1 以外的特征

值都趋于

0 时

，

马尔可夫链

混合成功（收

敛到了均衡

分布）。这也意

味着矩阵 A

的

第二大特征

值决

510 第十七

章 蒙特卡罗

方法

定了马

尔可夫链的

混合时间。然

而，在实践中

，我们通常不

能真的将马

尔可夫链表

示

成矩阵的

形式。我们的

概率模型所

能够达到的

状态是变量

数的指数级

别，所以表达

v，A 或者 A

的特征

值是不现实

的。由于以上

在内的诸多

阻碍，我们通

常无法知道

马

尔可夫链

是否已经混

合成功。作为

替代，我们只

能运行一定

量时间马尔

可夫链直到

我们粗略估

计这段时间

是足够的，然

后使用启发

式的方法来

判断马尔可

夫链是否混

合成功。这些

启发性的算

法包括了手

动检查样本

或者衡量前

后样本之间

的相关性。

17.4 Gibbs

采

样

目前为止

我们已经了

解了如何通

过反复更新

x ←− x

′ ∼ T(x

′

| x) 从一个分布

q(x) 中采样。然而

我们还没有

介绍过如何

确定

q(x) 是否是

一个有效的

分布。本书

中

将会描述两

种基本的方

法。第一种方

法是从已经

学习到的分

布 pmodel

中推导出

T，下文描述了

如何从基于

能量的模型

中采样。第二

种方法是直

接用参数描

述 T，然

后学习

这些参数，其

平稳分布隐

式地定义了

我们所感兴

趣的模型 pmodel。我

们将在

第 20.12 节

和第 20.13

节中讨

论第二种方

法的例子。

在

深度学习中

，我们通常使

用马尔可夫

链从定义为

基于能量的

模型的分布

pmodel(x) 中采样。在这

种情况下，我

们希望马尔

可夫链的 q(x)

分

布就是 pmodel(x)。

为了

得到所期望

的 q(x)

分布，我们

必须选取合

适的 T(x

′

|

x)。

Gibbs 采样（Gibbs Sampling）是

一种概念简

单而又有效

的方法。它构

造一个

从 pmodel(x) 中

采样的马尔

可夫链，其中

在基于能量

的模型中从

T(x

′

| x) 采样是通

过

选择一个变

量

xi，然后从 pmodel 中

该点关于在

无向图 G（定义

了基于能量

的模

型结构

）中邻接点的

条件分布中

采样。只要一

些变量在给

定相邻变量

时是条件独

立

的，那么这

些变量就可

以被同时采

样。正如在第

16.7.1 节中看到的

RBM 示例一样，

RBM 中

所有的隐藏

单元可以被

同时采样，因

为在给定所

有可见单元

的条件下它

们相

互条件

独立。同样地

，所有的可见

单元也可以

被同时采样

，因为在给定

所有隐藏单

元的情况下

它们相互条

件独立。以这

种方式同时

更新许多变

量的 Gibbs

采样通

常被

称为 块

吉布斯采样

（block Gibbs

Sampling）。

设计从 pmodel 中采

样的马尔可

夫链还存在

其他备选方

法。比如说，Metropolis￾Hastings

算

法在其他领

域中广泛使

用。不过在深

度学习的无

向模型中，我

们主要使

用

Gibbs 采样，很少使

用其他方法

。改进采样技

巧也是一个

潜在的研究

热点。

17.5

不同的

峰值之间的

混合挑战 511

17.5 不

同的峰值之

间的混合挑

战

使用 MCMC 方法

的主要难点

在于马尔可

夫链的 混合

（Mixing）通常不理想

。在

理想情况

下，从设计好

的马尔可夫

链中采出的

连续样本之

间是完全独

立的，而且在

x 空间中，马尔

可夫链会按

概率大小访

问许多不同

区域。

然而， MCMC

方

法采出的样

本可能会具

有很强的相

关性，尤其是

在高维的情

况

下。我们把

这种现象称

为慢混合甚

至混合失败

。具有缓慢混

合的 MCMC 方法可

以被

视为对

能量函数无

意地执行类

似于带噪声

的梯度下降

的操作，或者

说等价于相

对于

链的状

态（被采样的

随机变量）依

据概率进行

噪声爬坡。（在

马尔可夫链

的状态空

间

中）从 x

(t−1) 到 x

(t)

该链

倾向于选取

很小的步长

，其中能量 E(x

(t)

)

通

常低于或

者

近似等于能

量 E(x

(t−1))，倾向于向

较低能量的

区域移动。当

从可能性较

小的状态

（比

来自 p(x) 的典型

样本拥有更

高的能量）开

始时，链趋向

于逐渐减少

状态的能量

，

并且仅仅偶

尔移动到另

一个峰值。一

旦该链已经

找到低能量

的区域（例如

，如果变量

是

图像中的像

素，则低能量

的区域可以

是同一对象

所对应图像

的一个连通

的流形），

我们

称之为峰值

，链将倾向于

围绕着这个

峰值游走（按

某一种形式

随机游走）。它

时不时会走

出该峰值，但

是结果通常

会返回该峰

值或者（如果

找到一条离

开的路线）

移

向另一个峰

值。问题是对

于很多有趣

的分布来说

成功的离开

路线很少，所

以马尔

可夫

链将在一个

峰值附近抽

取远超过需

求的样本。

当

我们考虑 Gibbs 采

样算法（见第

17.4 节）时，这种现

象格外明显

。在这种情

况

下，我们考虑

在一定步数

内从一个峰

值移动到一

个临近峰值

的概率。决定

这个概

率的

是两个峰值

之间的 ‘‘能量

障碍’’ 的形状

。隔着一个巨

大

‘‘能量障碍

” （低概率

的区

域）的两个峰

值之间的转

移概率是（随

着能量障碍

的高度）指数

下降的，如

图

17.1

所示。当目标

分布有多个

高概率峰值

并且被低概

率区域所分

割，尤其当Gibbs

采

样的每一步

都只是更新

变量的一小

部分而这一

小部分变量

又严重依赖

其他的变量

时，就会产生

问题。

举一个

简单的例子

，考虑两个变

量 a，b

的基于能

量的模型，这

两个变量都

是二

值的，取

值 +1 或者

−1。如果

对某个较大

的正数 w，E(a, b) =

−wab，那么

这个模

型传

达了一个强

烈的信息，a 和

b 有相同的符

号。当

a = 1 时用

Gibbs 采

样更新 b。

给定

b

时的条件分

布满足 p(b = 1

| a = 1)

= σ(w)。如果

w 的值很大，sigmoid 函

数趋近于饱

和，那么

b 也取

到 1 的概率趋

近于

1。同理，如

果 a = −1，那么

b 取

到

−1 的概率也趋

于

1。根据模型

pmodel(a, b)，两个变量取

一样的符号

的概率几乎

相

等。根据 pmodel(a

| b)，两

个变量应该

有相同的符

号。这也意味

着 Gibbs 采样很难

会

512 第十七章

蒙特卡罗方

法

图 17.1:

对于三

种分布使用

Gibbs 采样所产生

的路径，所有

的分布马尔

可夫链初始

值都设为峰

值。(左) 一个带

有两个独立

变量的多维

正态分布。由

于变量之间

是相互独立

的，Gibbs 采样混合

得

很好。(中) 变

量之间存在

高度相关性

的一个多维

正态分布。变

量之间的相

关性使得马

尔可夫链很

难混合。因为

每一个变量

的更新需要

相对其他变

量求条件分

布，相关性减

慢了马尔可

夫链远离初

始点的速度

。(右) 峰值之间

间距很大且

不在轴上对

齐的混合高

斯分布。Gibbs 采样

混合得很慢

，因

为每次更

新仅仅一个

变量很难跨

越不同的峰

值。

改变这些

变量的符号

。

在更实际的

问题中，这种

挑战更加艰

巨因为在实

际问题中我

们不能仅仅

关注在

两个

峰值之间的

转移，更要关

注在多个峰

值之间的转

移。如果由于

峰值之间混

合困

难，而导

致某几个这

样的转移难

以完成，那么

得到一些可

靠的覆盖大

部分峰值的

样

本集合的

计算代价是

很高的，同时

马尔可夫链

收敛到它的

平稳分布的

过程也会非

常

缓慢。

通过

寻找一些高

度依赖变量

的组以及分

块同时更新

块（组）中的变

量，这个问

题

有时候是可

以被解决的

。然而不幸的

是，当依赖关

系很复杂时

，从这些组中

采样

的过程

从计算角度

上说是难以

处理的。归根

结底，马尔可

夫链最初就

是被提出来

解

决这个问

题，即从大量

变量中采样

的问题。

在定

义了一个联

合分布

pmodel(x, h) 的潜

变量模型中

，我们经常通

过交替地从

pmodel(x |

h) 和 pmodel(h |

x) 中采样来

达到抽 x 的目

的。从快速混

合的角度上

说，我

们更希

望 pmodel(h | x)

有很大的

熵。然而，从学

习一个 h 的有

用表示的角

度上考虑，

我

们还是希望

h

能够包含 x 的

足够信息从

而能够较完

整地重构它

，这意味 h

和 x

要

有非常高的

互信息。这两

个目标是相

互矛盾的。我

们经常学习

到能够将 x

精

确地

17.5 不同的

峰值之间的

混合挑战 513

编

码为 h 的生成

模型，但是无

法很好混合

。这种情况在

玻尔兹曼机

中经常出现

，一

个玻尔兹

曼机学到的

分布越尖锐

，该分布的马

尔可夫链采

样越难混合

得好。这个问

题在图

17.2 中有

所描述。

图 17.2:

深

度概率模型

中一个混合

缓慢问题的

例证。每张图

都是按照从

左到右从上

到下的顺序

的。

(左) Gibbs 采样从

MNIST

数据集训练

成的深度玻

尔兹曼机中

采出的连续

样本。这些连

续的样本

之

间非常相似

。由于 Gibbs 采样作

用于一个深

度图模型，相

似度更多地

是基于语义

而非原始视

觉

特征。但是

对于吉布斯

链来说从分

布的一个峰

值转移到另

一个仍然是

很困难的，比

如说改变数

字。

(右) 从生成

式对抗网络

中抽出的连

续原始样本

。因为原始采

样生成的样

本之间互相

独立，所以不

存在混合问

题。

当

感 兴 趣

的 分

布 对 于

每 个

类 具 有

单 独

的流 形

结 构 时，

所 有

这 些 问

题 都

使 MCMC 方法变得

不那么有用

：分布集中在

许多峰值周

围，并且这些

峰值由大量

高

能量区域

分割。我们在

许多分类问

题中遇到的

是这种类型

的分布，由于

峰值之间混

合缓慢，它将

使得 MCMC 方法非

常缓慢地收

敛。

17.5.1

不同峰值

之间通过回

火来混合

当

一个分布有

一些陡峭的

峰并且被低

概率区域包

围时，很难在

分布的不同

峰

值之间混

合。一些加速

混合的方法

是基于构造

一个概率分

布替代目标

分布，这个概

率分布的峰

值没有那么

高，峰值周围

的低谷也没

有那么低。基

于能量的模

型为这个

想

法提供一种

简单的做法

。目前为止，我

们一直将基

于能量的模

型描述为定

义一个

概率

分布：

p(x) ∝ exp(−E(x)).

(17.25)

514 第十七

章 蒙特卡罗

方法

基于能

量的模型可

以通过添加

一个额外的

控制峰值尖

锐程度的参

数 β 来加强：

pβ(x)

∝ exp(−βE(x)). (17.26)

β

参

数可以被理

解为 温度（temperature）的

倒数，反映了

基于能量的

模型的统计

物

理学起源

。当温度趋近

于 0

时，β 趋近于

无穷大，此时

的基于能量

的模型是确

定性

的。当温

度趋近于无

穷大时，β 趋近

于零，基于能

量的模型（对

离散的

x）成了

均匀

分布。

通

常情况下，在

β =

1 时训练一个

模型。但我们

也可以利用

其他温度，尤

其是

β <

1 的情况

。 回火（tempering）作为一

种通用的策

略，它通过从

β <

1 模型中采

样

来实现在 p1

的

不同峰值之

间快速混合

。

基于 回火转

移（tempered transition）

(Neal, 1994) 的马尔可

夫链临时从

高温

度的分

布中采样使

其在不同峰

值之间混合

，然后继续从

单位温度的

分布中采样

。这

些技巧被

应用在一些

模型比如 RBM中

(Salakhutdinov, 2010)。另一种方法

是利用 并

行

回火（parallel tempering） (Iba, 2001)。其中马

尔可夫链并

行地模拟许

多不同温

度

的不同状态

。最高温度的

状态混合较

慢，相比之下

最低温度的

状态，即温度

为 1

时，采出了

精确的样本

。转移算子包

括了两个温

度之间的随

机跳转，所以

一个高温

度

状态分布槽

中的样本有

足够大的概

率跳转到低

温度分布的

槽中。这个方

法也被应

用

到了 RBM中 (Desjardins et

al., 2010; Cho et

al., 2010a)。尽管

回火这种方

法前景

可期

，现今它仍然

无法让我们

在采样复杂

的基于能量

的模型中更

进一步。一个

可能的

原因

是在

临界温

度（critical temperatures）时温度转

移算子必须

设置得非常

慢（因

为温度

需要逐渐下

降）来确保回

火的有效性

。

17.5.2

深度也许会

有助于混合

当我们从潜

变量模型 p(h, x) 中

采样时，我们

可以发现如

果

p(h | x) 将

x 编码

得

非常好，那么

从 p(x

| h) 中采样时

，并不会太大

地改变 x，那么

混合结果会

很糟

糕。解决

这个问题的

一种方法是

使得 h 成为一

种将 x

编码为

h 的深度表示

，从而使

得马

尔可夫链在

h 空间中更容

易混合。在许

多表示学习

算法如自编

码器和

RBM 中，

h 的

边缘分布相

比于

x 上的原

始数据分布

，通常表现为

更加均匀、更

趋近于单峰

值。

或许可以

说，这是因为

利用了所有

可用的表示

空间并尽量

减小重构误

差。因为当训

练集上的不

同样本之间

在 h

空间能够

被非常容易

地区分时，我

们也会很容

易地最

小化

重构误差。Bengio et al.

(2013a) 观

察到这样的

现象，堆叠越

深的正则化

自编码

17.5 不同

的峰值之间

的混合挑战

515

器或者 RBM，顶端

h 空间的边缘

分布越趋向

于均匀和发

散，而且不同

峰值（比如

说

实验中的类

别）所对应区

域之间的间

距也会越小

。在高层空间

中训练

RBM 会使

得 Gibbs 采样在峰

值间混合得

更快。然而，如

何利用这种

观察到的现

象来辅助训

练

深度生成

模型或者从

中采样仍然

有待探索。

尽

管存在混合

的难点，蒙特

卡罗技术仍

然是一个有

用的工具，通

常也是最好

的

可用工具

。事实上，在遇

到难以处理

的无向模型

中的配分函

数时，蒙特卡

罗方法仍

然

是最主要的

工具，这将在

下一章详细

阐述。

第十八

章 直面配分

函数

在第 16.2.2

节

中，我们看到

许多概率模

型（通常是无

向图模型）由

一个未归一

化的概率分

布 p˜(x, θ) 定义。我们

必须通过除

以配分函数

Z(θ)

来归一化 p˜，以

获得

一个有

效的概率分

布：

p(x;

θ) = 1

Z(θ)

p˜(x; θ). (18.1)

配分函数

是未归一化

概率所有状

态的积分（对

于连续变量

）或求和（对于

离散变量）：

∫

p˜(x)dx (18.2)

或

者

∑

x

p˜(x). (18.3)

对于很多

有趣的模型

而言，以上积

分或求和难

以计算。

正如

我们将在第

二十章看到

的，有些深度

学习模型被

设计成具有

一个易于处

理

的归一化

常数，或被设

计成能够在

不涉及计算

p(x) 的情况下使

用。然而，其他

一些

模型会

直接面对难

以计算的配

分函数的挑

战。在本章中

，我们会介绍

用于训练和

评

估那些具

有难以处理

的配分函数

的模型的技

术。

18.1 对数似然

梯度

通过最

大似然学习

无向模型特

别困难的原

因在于配分

函数依赖于

参数。对数似

然相对于参

数的梯度具

有一项对应

于配分函数

的梯度：

∇θ log p(x;

θ) = ∇θ log

p˜(x; θ) − ∇θ

logZ(θ). (18.4)

516

18.1

对数

似然梯度 517

这

是机器学习

中非常著名

的 正相（positive

phase）和 负

相（negative phase）的

分解。

对

于大多数感

兴趣的无向

模型而言，负

相是困难的

。没有潜变量

或潜变量之

间

很少相互

作用的模型

通常会有一

个易于计算

的正相。RBM 的隐

藏单元在给

定可见单

元

的情况下彼

此条件独立

，是一个典型

的具有简单

正相和困难

负相的模型

。正相计

算困

难，潜变量之

间具有复杂

相互作用的

情况将主要

在第十九章

中讨论。本章

主要

探讨负

相计算中的

难点。

让我们

进一步分析

logZ 的梯度：

∇θ logZ (18.5)

=

∇θZ

Z

(18.6)

=

∇θ

∑

x

p˜(x)

Z

(18.7)

=

∑

x ∇θp˜(x)

Z

.

(18.8)

对于

保证所有的

x 都有 p(x)

> 0 的模型

，我们可以用

exp(log p˜(x))

代替 p˜(x)：

∑

x

∇θ exp(log p˜(x))

Z

(18.9)

=

∑

x

exp(log p˜(x))∇θ log p˜(x)

Z

(18.10)

=

∑

x

p˜(x)∇θ log p˜(x)

Z

(18.11)

=

∑

x

p(x)∇θ log p˜(x)

(18.12)

= Ex∼p(x)∇θ log

p˜(x). (18.13)

上述推

导对离散的

x 进行求和，对

连续的

x 进行

积分也可以

得到类似结

果。在

连续版

本的推导中

，使用在积分

符号内取微

分的莱布尼

兹法则可以

得到等式

∇θ

∫

p˜(x)dx =

∫

∇θp˜(x)dx. (18.14)

该

等式只适用

于 p˜

和 ∇θp˜(x) 上的一

些特定规范

条件。在测度

论术语中，这

些条件

是：(1)

对

每一个 θ 而言

，未归一化分

布 p˜

必须是 x 的

勒贝格可积

函数。(2) 对于所

518

第十八章 直

面配分函数

有的 θ 和几乎

所有

x，梯度 ∇θp˜(x) 必

须存在。(3) 对于

所有的

θ 和几

乎所有的 x，

必

须存在一个

可积函数

R(x) 使

得 maxi

|

∂

∂θi

p˜(x)| ≤

R(x)。幸运的是

，大多数感兴

趣

的机器学

习模型都具

有这些性质

。

等式

∇θ

logZ = Ex∼p(x)∇θ log

p˜(x) (18.15)

是使用

各种蒙特卡

罗方法近似

最大化（具有

难计算配分

函数模型的

）似然的基础

。

蒙特卡罗方

法为学习无

向模型提供

了直观的框

架，我们能够

在其中考虑

正相和负

相

。在正相中，我

们增大从数

据中采样得

到的 log p˜(x)。在负相

中，我们通过

降低从

模型

分布中采样

的

log p˜(x) 来降低配

分函数。

在深

度学习文献

中，经常会看

到用能量函

数（式

(16.7) ）来参数

化 log p˜。在这

种情

况下，正相可

以解释为压

低训练样本

的能量，负相

可以解释为

提高模型抽

出的

样本的

能量，如图 18.1 所

示。

18.2 随机最大

似然和对比

散度

实现式

(18.15) 的一个朴素

方法是，每次

需要计算梯

度时，磨合随

机初始化的

一

组马尔可

夫链。当使用

随机梯度下

降进行学习

时，这意味着

马尔可夫链

必须在每次

梯度步骤中

磨合。这种方

法引导下的

训练过程如

算法 18.1 所示。内

循环中磨合

马尔

可夫链

的计算代价

过高，导致这

个过程在实

际中是不可

行的，但是这

个过程是其

他

更加实际

的近似算法

的基础。

我们

可以将最大

化似然的 MCMC 方

法视为在两

种力之间平

衡，一种力拉

高数据

出现

时的模型分

布，一种拉低

模型采样出

现时的模型

分布。图 18.1 展示

了这个过程

。

这两种力分

别对应最大

化

log p˜ 和最小化

logZ。对于负相会

有一些近似

方法。这些

近

似都可以被

理解为使负

相更容易计

算，但是也可

能将其推向

错误的位置

。

因为负相涉

及到从模型

分布中抽样

，所以我们可

以认为它在

找模型信任

度很高

的点

。因为负相减

少了这些点

的概率，它们

一般被认为

代表了模型

不正确的信

念。在

文献中

，它们经常被

称为 ‘‘幻觉’’

或

‘‘幻想粒子’’。事

实上，负相已

经被作为人

类和其

他动

物做梦的一

种可能解释

(Crick and Mitchison,

1983)。这个想法是

说，大脑维持

着世界的概

率模型，并且

在醒着经历

真实事件时

会遵循 log p˜ 的梯

度，在睡觉时

会遵

循 log p˜ 的负

梯度最小化

logZ，其经历的样

本采样自当

前的模型。这

个视角解释

了

具有正相

和负相的大

多数算法，但

是它还没有

被神经科学

实验证明是

正确的。在机

18.2 随机最大似

然和对比散

度 519

算法

18.1 一种

朴素的 MCMC 算法

，使用梯度上

升最大化具

有难以计算

配分函数的

对数似然。

设

步长 ϵ 为一个

小正数。

设吉

布斯步数

k 大

到足以允许

磨合。在小图

像集上训练

一个 RBM 大致设

为

100。

while 不收敛 do

从

训练集中采

包含 m 个样本

{x

(1)

, . . .

, x

(m)} 的小批量。

g ← 1

m

∑m

i=1 ∇θ log

p˜(x

(i)

; θ).

初

始化 m 个样本

{x˜

(1)

, . . .

, x˜

(m)} 为随机值（例

如，从均匀或

正态分布中

采，或

大致与

模型边缘分

布匹配的分

布）。

for i =

1 to k do

for j = 1

to m do

x˜

(j) ← gibbs_update(x˜

(j)

).

end for

end

for

g ← g

−

1

m

∑m

i=1 ∇θ log p˜(x˜

(i)

; θ).

θ

← θ + ϵg.

end while

器学习模

型中，通常有

必要同时使

用正相和负

相，而不是按

不同时间阶

段分为清醒

和 REM

睡眠时期

。正如我们将

在第 19.5 节中看

到的，一些其

他机器学习

算法出于

其

他原因从模

型分布中采

样，这些算法

也能提供睡

觉做梦的解

释。

这样理解

学习正相和

负相的作用

之后，我们设

计了一个比

算法 18.1 计算代

价更

低的替

代算法。简单

的

MCMC 算法的计

算成本主要

来自每一步

的随机初始

化磨合马

尔

可夫链。一个

自然的解决

方法是初始

化马尔可夫

链为一个非

常接近模型

分布的分

布

，从而大大减

少磨合步骤

。

对比散度（CD，或

者是具有 k 个

Gibbs 步骤的

CD-k）算法

在每个步骤

中初始

化马

尔可夫链为

采样自数据

分布中的样

本 (Hinton, 2000,

2010)，如算法 18.2 所

示。

从数据分

布中获取样

本是计算代

价最小的，因

为它们已经

在数据集中

了。初始时，数

据分布并不

接近模型分

布，因此负相

不是非常准

确。幸运的是

，正相仍然可

以准确

地增

加数据的模

型概率。进行

正相阶段一

段时间之后

，模型分布会

更接近于数

据分

布，并且

负相开始变

得准确。

当然

，CD 仍然是真实

负相的一个

近似。CD

未能定

性地实现真

实负相的主

要原

520 第十八

章 直面配分

函数

x

The positive phase

pmodel(x)

pdata(x)

x

The

negative phase

pmodel(x)

pdata(x)

图 18.1: 算法

18.1 角度的

“正相

’’ 和 “负相’’。(左) 在

正相中，我们

从数据分布

中采样，然后

推高

它们未

归一化的概

率。这意味着

概率越高的

数据点未归

一化的概率

被推高得越

多。(右) 在负相

中，

我们从模

型分布中采

样，然后压低

它们未归一

化的概率。这

与正相的倾

向相反，给未

归一化的概

率处处添加

了一个大常

数。当数据分

布和模型分

布相等时，正

相推高数据

点和负相压

低数据点的

机会相等。此

时，不再有任

何的梯度（期

望上说），训练

也必须停止

。

因是，它不能

抑制远离真

实训练样本

的高概率区

域。这些区域

在模型上具

有高概率，

但

是在数据生

成区域上具

有低概率，被

称为 虚假模

态（spurious modes）。图18.2 解

释了

这种现象发

生的原因。基

本上，除非 k 非

常大，模型分

布中远离数

据分布的峰

值不会被使

用训练数据

初始化的马

尔可夫链访

问到。

Carreira-Perpiñan

and Hinton (2005) 实验上

证明

CD 估计偏

向于 RBM 和完全

可见的玻尔

兹曼机，因为

它会收敛到

与最大似然

估计不同的

点。他们认为

，由于偏

差较

小，CD 可以作为

一种计算代

价低的方式

来初始化模

型，之后可以

通过计算代

价

高的 MCMC

方法

进行精调。Bengio and Delalleau (2009)

表

明，CD 可以被理

解为去

掉了

正确 MCMC

梯度更

新中的最小

项，这解释了

偏差的由来

。

在训练诸如

RBM 的浅层网络

时 CD

是很有用

的。反过来，这

些可以堆叠

起来初

始化

更深的模型

，如DBN 或 DBM。但是CD

并

不直接有助

于训练更深

的模型。这是

因为在给定

可见单元样

本的情况下

，很难获得隐

藏单元的样

本。由于隐藏

单元不包

括

在数据中，所

以使用训练

点初始化无

法解决这个

问题。即使我

们使用数据

初始化

可见

单元，我们仍

然需要磨合

在给定这些

可见单元的

隐藏单元条

件分布上采

样的马

尔可

夫链。

CD 算法可

以被理解为

惩罚某类模

型，这类模型

的马尔可夫

链会快速改

变来自数

p(x)

p(x)

18.2 随

机最大似然

和对比散度

521

算法 18.2

对比散

度算法，使用

梯度上升作

为优化过程

。

设步长 ϵ 为一

个小正数。

设

吉布斯步数

k 大到足以让

从 pdata 初始化并

从

p(x; θ) 采样的马

尔可夫链混

合 。

在小图像

集上训练一

个 RBM 大致设为

1-20。

while

不收敛 do

从训

练集中采包

含 m

个样本 {x

(1)

,

. . . ,

x

(m)} 的

小批量。

g

← 1

m

∑m

i=1 ∇θ log p˜(x

(i)

; θ).

for

i = 1 to

m do

x˜

(i)

← x

(i)

.

end for

for i

= 1 to k

do

for j =

1 to m do

x˜

(j) ← gibbs_update(x˜

(j)

).

end for

end for

g ←

g −

1

m

∑m

i=1 ∇θ log

p˜(x˜

(i)

; θ).

θ ← θ +

ϵg.

end while

据的

输入。这意味

着使用CD

训练

从某种程度

上说类似于

训练自编码

器。即使CD 估

计

比一些其他

训练方法具

有更大偏差

，但是它有助

于预训练之

后会堆叠起

来的浅层

模

型。这是因为

堆栈中最早

的模型会受

激励复制更

多的信息到

其潜变量，使

其可用

于随

后的模型。这

应该更多地

被认为是CD 训

练中经常可

利用的副产

品，而不是主

要

的设计优

势。

Sutskever

and Tieleman (2010) 表明，CD

的更

新方向不是

任何函数的

梯度。这

使得

CD 可能存在永

久循环的情

况，但在实践

中这并不是

一个严重的

问题。

另一个

解决

CD 中许多

问题的不同

策略是，在每

个梯度步骤

中初始化马

尔可夫

链为

先前梯度步

骤的状态值

。这个方法首

先被应用数

学和统计学

社群发现，命

名

为随机最

大似然（SML）(Younes,

1998)，后来

又在深度学

习社群中以

名称持续性

对

比散度（PCD，或

者每个更新

中具有 k 个

Gibbs 步

骤的 PCD-k）独立地

被重新发

现

(Tieleman,

2008)。具体可以参

考算法18.3 。这种

方法的基本

思想是，只要

随机梯

度算

法得到的步

长很小，那么

前一步骤的

模型将类似

于当前步骤

的模型。因此

，来

522

第十八章

直面配分函

数

x

pmodel(x)

pdata(x)

图 18.2: 一个虚

假模态。说明

对比散度（算

法 18.2

）的负相为

何无法抑制

虚假模态的

例子。一个虚

假模态指的

是一个在模

型分布中出

现数据分布

中却不存在

的模式。由于

对比散度从

数据点中初

始

化它的马

尔可夫链然

后仅仅运行

了几步马尔

可夫链，不太

可能到达模

型中离数据

点较远的模

式。这

意味着

从模型中采

样时，我们有

时候会得到

一些与数据

并不相似的

样本。这也意

味着由于在

这些

模式上

浪费了一些

概率质量，模

型很难把较

高的概率质

量集中于正

确的模式上

。出于可视化

的目

的，这个

图使用了某

种程度上说

更加简单的

距离的概念

——在 R 的数轴上

虚假模态与

正确的模式

有很大的距

离。这对应着

基于局部移

动 R

上的单个

变量 x 的马尔

可夫链。对于

大部分深度

概率模

型来

说，马尔可夫

链是基于

Gibbs 采

样的，并且对

于单个变量

产生非局部

的移动但是

无法同时移

动所有的变

量。对于这些

问题来说，考

虑编辑距离

比欧式距离

通常更好。然

而，高维空间

的编辑距

离

很难在二维

空间作图展

示。

自先前模

型分布的样

本将非常接

近来自当前

模型分布的

客观样本，用

这些样本初

始

化的马尔

可夫链将不

需要花费很

多时间来完

成混合。

因为

每个马尔可

夫链在整个

学习过程中

不断更新，而

不是在每个

梯度步骤中

重

新开始，马

尔可夫链可

以自由探索

很远，以找到

模型的所有

峰值。因此，SML 比

CD

更

不容易形

成具有虚假

模态的模型

。此外，因为可

以存储所有

采样变量的

状态，无论

是

可见的还是

潜在的，SML 为隐

藏单元和可

见单元都提

供了初始值

。CD

只能为可

见

单元提供初

始化，因此深

度模型需要

进行磨合步

骤。SML 能够高效

地训练深度

模

型。Marlin

et al. (2010) 将

SML 与本

章中提出的

许多其他标

准方法进行

比较。他们

发

现，SML 在

RBM 上得到

了最佳的测

试集对数似

然，并且如果

RBM 的隐藏单元

被

用作

SVM 分类

器的特征，那

么 SML 会得到最

好的分类精

度。

在 k 太小或

ϵ 太大时，随机

梯度算法移

动模型的速

率比马尔可

夫链在迭代

步

中混合更

快，此时 SML 容易

变得不准确

。不幸的是，这

些值的容许

范围高度依

赖

p(x)

18.2 随机最大

似然和对比

散度 523

算法

18.3 随

机最大似然

/持续性对比

散度算法，使

用梯度上升

作为优化过

程。

设步长 ϵ

为

一个小正数

。

设吉布斯步

数 k 大到足以

让从

p(x; θ+ϵg) 采样的

马尔可夫链

磨合（从采自

p(x; θ)

的样本开始

）。在小图像集

上训练一个

RBM大致设为 1，对

于更复杂的

模型如深度

玻尔兹曼机

可能要设为

5 到 50。

初始化 m 个

样本 {x˜

(1)

, . .

. , x˜

(m)}

为随机

值（例如，从均

匀或正态分

布中采，或大

致与模型边

缘分布匹配

的分布）。

while 不收

敛 do

从训练集

中采包含 m 个

样本 {x

(1)

, . .

. , x

(m)}

的小批

量。

g ← 1

m

∑m

i=1 ∇θ

log p˜(x

(i)

;

θ).

for i =

1 to k do

for j = 1

to m do

x˜

(j) ← gibbs_update(x˜

(j)

).

end for

end

for

g ← g

−

1

m

∑m

i=1 ∇θ log p˜(x˜

(i)

; θ).

θ

← θ + ϵg.

end while

于具体问

题。现在还没

有方法能够

正式地测试

马尔可夫链

是否能够在

迭代步骤之

间

成功混合

。主观地，如果

对于

Gibbs 步骤数

目而言学习

率太大的话

，那么梯度步

骤

中负相采

样的方差会

比不同马尔

可夫链中负

相采样的方

差更大。例如

，一个 MNIST

模型在

一个步骤中

只采样得到

了 7。然后学习

过程将会极

大降低 7 对应

的峰值，在

下

一个步骤中

，模型可能会

只采样得到

9。

从使用 SML 训练

的模型中评

估采样必须

非常小心。在

模型训练完

之后，有必要

从一个随机

起点初始化

的新马尔可

夫链抽取样

本。用于训练

的连续负相

链中的样本

受到了模型

最近几个版

本的影响，会

使模型看起

来具有比其

实际更大的

容量。

Berglund and Raiko (2013)

进行了

实验来检验

由 CD 和 SML

进行梯

度估计带来

的偏差和方

差。结果证明

CD 比基于精确

采样的估计

具有更低的

方差。而 SML 有更

高的方差。CD

方

差低的原因

是，其在正相

和负相中使

用了相同的

训练点。如果

从不

同的训

练点来初始

化负相，那么

方差会比基

于精确采样

的估计的方

差更大。

524 第十

八章

直面配

分函数

所有

基于 MCMC 从模型

中抽取样本

的方法在原

则上几乎可

以与

MCMC 的任何

变体一起使

用。这意味着

诸如 SML 这样的

技术可以使

用第十七章

中描述的任

何增

强 MCMC 的技

术（例如并行

回火）来加以

改进 (Desjardins

et al., 2010; Cho

et al.,

2010b)。

一种在

学习期间加

速混合的方

法是，不改变

蒙特卡罗采

样技术，而是

改变模型的

参数化和代

价函数。

快速

持续性对比

散度（fast persistent contrastive divergence），

或者 FPCD (Tieleman and

Hinton, 2009) 使

用如下表达

式去替换传

统模型的参

数 θ

θ = θ

(slow)

+ θ

(fast)

.

(18.16)

现在的参

数是以前的

两倍多，将其

逐个相加以

定义原始模

型的参数。快

速复制参数

可以使用更

大的学习率

来训练，从而

使其快速响

应学习的负

相，并促使马

尔可夫链探

索新的区域

。这能够使马

尔可夫链快

速混合，尽管

这种效应只

会发生在学

习期间快

速

权重可以自

由改变的时

候。通常，在短

时间地将快

速权重设为

大值并保持

足够长

时间

，使马尔可夫

链改变峰值

之后，我们会

对快速权重

使用显著的

权重衰减，促

使

它们收敛

到较小的值

。

本节介绍的

基于 MCMC 的方法

的一个关键

优点是它们

提供了

logZ 梯度

的估

计，因此

我们可以从

本质上将问

题分解为 log

p˜ 和

logZ 两块。然后我

们可以使用

任

何其他的

方法来处理

log

p˜(x)，只需将我们

的负相梯度

加到其他方

法的梯度中

。特别

地，这意

味着正相可

以使用那些

仅提供 p˜ 下限

的方法。然而

，本章介绍处

理

logZ 的

大多数

其他方法都

和基于边界

的正相方法

是不兼容的

。

18.3

伪似然

蒙特

卡罗近似配

分函数及其

梯度需要直

接处理配分

函数。有些其

他方法通过

训

练不需要

计算配分函

数的模型来

绕开这个问

题。这些方法

大多数都基

于以下观察

：

无向概率模

型中很容易

计算概率的

比率。这是因

为配分函数

同时出现在

比率的分子

和分母中，互

相抵消：

p(x)

p(y)

=

1

Z

˜p(x)

1

Z

˜p(y)

=

p˜(x)

p˜(y)

. (18.17)

伪似

然正是基于

条件概率可

以采用这种

基于比率的

形式，因此可

以在没有配

分

函数的情

况下进行计

算。假设我们

将

x 分为 a，b 和

c，其

中 a 包含我们

想要的条

18.3

伪

似然 525

件分布

的变量，b 包含

我们想要条

件化的变量

，c

包含除此之

外的变量：

p(a | b)

= p(a, b)

p(b)

=

p(a, b)

∑

a,c

p(a, b, c)

=

p˜(a, b)

∑

a,c

p˜(a, b, c)

. (18.18)

以

上计算需要

边缘化 a，假设

a

和 c 包含的变

量并不多，那

么这将是非

常高效的操

作。在极端情

况下，a 可以是

单个变量，c

可

以为空，那么

该计算仅需

要估计与单

个随机变量

值一样多的

p˜。

不幸的是，为

了计算对数

似然，我们需

要边缘化很

多变量。如果

总共有 n 个变

量，那么我们

必须边缘化

n

− 1 个变量。根据

概率的链式

法则，我们有

log p(x)

= log p(x1) +

log p(x2 | x1)

+ · · ·

+ log p(xn |

x1:n−1). (18.19)

在这种情况

下，我们已经

使 a

尽可能小

，但是 c 可以大

到 x2:n。如果我们

简单地将

c 移

到 b 中以减少

计算代价，那

么会发生什

么呢？这便产

生了

伪似然

（pseudolikelihood）

(Besag, 1975)目标函数，给

定所有其他

特征 x−i，预测特

征

xi 的值：

n∑

i=1

log p(xi

| x−i).

(18.20)

如果

每个随机变

量有 k 个不同

的值，那么计

算

p˜ 需要 k ×

n 次估

计，而计算配

分函数需要

k

n 次估计。

这看

起来似乎是

一个没有道

理的策略，但

可以证明最

大化伪似然

的估计是渐

近

一致的 (Mase, 1995)。当

然，在数据集

不趋近于大

采样极限的

情况下，伪似

然可能表

现

出与最大似

然估计不同

的结果。

我们

可以使用 广

义伪似然估

计（generalized pseudolikelihood

estimator）来权

衡计

算复杂度和

最大似然表

现的偏差 (Huang and

Ogata, 2002)。广

义伪似然估

计使

用 m

个不

同的集合 S

(i)，i =

1, . . .

, m 作

为变量的指

标出现在条

件棒的左侧

。在

m

= 1 和 S

(1) = 1, .

. . , n

的极端

情况下，广义

伪似然估计

会变为对数

似然。在 m = n

和 S

(i) =

{i} 的

极端情况下

，广义伪似然

会恢复为伪

似然。广义伪

似然估计目

标函

数如下

所示 m∑

i=1

log p(xS

(i)

| x−S

(i) ).

(18.21)

基于伪

似然的方法

的性能在很

大程度上取

决于模型是

如何使用的

。对于完全联

合分布 p(x) 模型

的任务（例如

密度估计和

采样），伪似然

通常效果不

好。对于在训

526

第十八章 直

面配分函数

练期间只需

要使用条件

分布的任务

而言，它的效

果比最大似

然更好，例如

填充少量

的

缺失值。如果

数据具有规

则结构，使得

S 索引集可以

被设计为表

现最重要的

相关

性质，同

时略去相关

性可忽略的

变量，那么广

义伪似然策

略将会非常

有效。例如，在

自然图像中

，空间中相隔

很远的像素

也具有弱相

关性，因此广

义伪似然可

以应用于

每

个 S 集是小的

局部空间窗

口的情况。

伪

似然估计的

一个弱点是

它不能与仅

在 p˜(x) 上提供下

界的其他近

似一起使用

，

例如第十九

章中介绍的

变分推断。这

是因为

p˜ 出现

在了分母中

。分母的下界

仅提供

了整

个表达式的

上界，然而最

大化上界没

有什么意义

。这使得我们

难以将伪似

然方

法应用

于诸如深度

玻尔兹曼机

的深度模型

，因为变分方

法是近似边

缘化互相作

用的

多层隐

藏变量的主

要方法之一

。尽管如此，伪

似然仍然可

以用在深度

学习中，它可

以用于单层

模型，或使用

不基于下界

的近似推断

方法的深度

模型中。

伪似

然比 SML 在每个

梯度步骤中

的计算代价

要大得多，这

是由于其对

所有条

件进

行显式计算

。但是，如果每

个样本只计

算一个随机

选择的条件

，那么广义伪

似然和类似

标准仍然可

以很好地运

行，从而使计

算代价降低

到和 SML 差不多

的程

度

(Goodfellow et al., 2013d)。

虽然

伪似然估计

没有显式地

最小化 logZ，但是

我们仍然认

为它具有类

似负相的

效

果。每个条件

分布的分母

会使得学习

算法降低所

有仅具有一

个变量不同

于训练样

本

的状态的概

率。

读者可以

参考 Marlin and de

Freitas (2011) 了解伪

似然渐近效

率的理论分

析，。

18.4

得分匹配

和比率匹配

得分匹配 (Hyvärinen, 2005b) 提

供了另一种

训练模型而

不需要估计

Z

或其导数

的

一致性方法

。对数密度关

于参数的导

数 ∇x log

p(x)，被称为其

得分（score），得分

匹

配这个名称

正是来自这

样的术语。得

分匹配采用

的策略是，最

小化模型对

数密度

和数

据对数密度

关于输入的

导数之间的

平方差期望

：

L(x,

θ) = 1

2

∥∇x log pmodel(x; θ)

− ∇x log pdata(x)∥

2

2

, (18.22)

J(θ) = 1

2

Epdata(x)L(x, θ), (18.23)

θ

∗ = min

θ

J(θ). (18.24)

18.4 得分匹配和

比率匹配

527

该

目标函数避

免了微分配

分函数 Z 带来

的难题，因为

Z

不是 x 的函数

，所以

∇xZ

= 0。最初，得

分匹配似乎

有一个新的

困难：计算数

据分布的得

分需要知道

生成

训练数

据的真实分

布 pdata。幸运的是

，最小化

L(x, θ) 的期

望等价于最

小化下式的

期望

˜L(x,

θ) =

n∑

j=1

(

∂x

∂

2

2

j

log pmodel(x;

θ) + 1

2

(

∂x

∂

j

log pmodel(x; θ)

)2

)

, (18.25)

其中

n 是

x 的维度。

因为

得分匹配需

要关于

x 的导

数，所以它不

适用于具有

离散数据的

模型，但是

模

型中的潜变

量可以是离

散的。

类似于

伪似然，得分

匹配只有在

我们能够直

接估计

log p˜(x) 及其

导数的时候

才

有效。它与

对

log p˜(x) 仅提供下

界的方法不

兼容，因为得

分匹配需要

log p˜(x)

的导

数和二

阶导数，而下

限不能传达

关于导数的

任何信息。这

意味着得分

匹配不能应

用

于隐藏单

元之间具有

复杂相互作

用的模型估

计，例如稀疏

编码模型或

深度玻尔兹

曼

机。虽然得

分匹配可以

用于预训练

较大模型的

第一个隐藏

层，但是它没

有被用于预

训练较大模

型的较深层

网络。这可能

是因为这些

模型的隐藏

层通常包含

一些离散变

量。

虽然得分

匹配没有明

确显示具有

负相信息，但

是它可以被

视为使用特

定类型马

尔

可夫链的对

比散度的变

种 (Hyvärinen, 2007a)。在这种情

况下，马尔可

夫链并没有

采用

Gibbs 采样，而

是采用一种

由梯度引导

局部更新的

不同方法。当

局部更新的

大

小接近于

零时，得分匹

配等价于具

有这种马尔

可夫链的对

比散度。

Lyu

(2009) 将得

分匹配推广

到离散的情

况（但是推导

有误，后由 Marlin et

al.

(2010) 修

正）。Marlin et

al. (2010) 发现，广义

得分匹配（generalized score

match￾ing，GSM）在

许多样本观

测概率为 0 的

高维离散空

间中不起作

用。

一种更成

功地将得分

匹配的基本

想法扩展到

离散数据的

方法是

比率

匹配（ratio

matching） (Hyvärinen, 2007b)。比率匹

配特别适用

于二值数据

。比率匹配最

小化以

下目

标函数在样

本上的均值

：

L

(RM)

(x,

θ) =

n∑

j=1

(

1

1 +

pmodel(x;θ)

pmodel(f(x),j;θ)

)2

.

(18.26)

其中 f(x, j)

返回 j 处

位值取反的

x。比率匹配使

用了与伪似

然估计相同

的策略来绕

开配分函数

：配分函数会

在两个概率

的比率中抵

消掉。Marlin et

al. (2010) 发现，训

528 第十八章

直

面配分函数

练模型给测

试集图像去

噪时，比率匹

配的效果要

优于 SML、伪似然

和 GSM。

类似于伪

似然估计，比

率匹配对每

个数据点都

需要

n 个 p˜ 的估

计，因此每次

更

新的计算

代价大约比

SML 的计算代价

高出 n 倍。

与伪

似然估计一

样，我们可以

认为比率匹

配减小了所

有只有一个

变量不同于

训

练样本的

状态的概率

。由于比率匹

配特别适用

于二值数据

，这意味着在

与数据的汉

明距离为 1 内

的所有状态

上，比率匹配

都是有效的

。

比率匹配还

可以作为处

理高维稀疏

数据（例如词

计数向量）的

基础。这类稀

疏

数据对基

于 MCMC 的方法提

出了挑战，因

为以密集格

式表示数据

是非常消耗

计算资

源的

，而只有在模

型学会表示

数据分布的

稀疏性之后

，MCMC 采样才会产

生稀疏值。

Dauphin and

Bengio (2013) 设

计了比率匹

配的无偏随

机近似来解

决这个问题

。该近

似只估

计随机选择

的目标子集

，不需要模型

生成完整的

样本。

读者可

以参考 Marlin and de

Freitas (2011) 了解

比率匹配渐

近效率的理

论分

析，。

18.5 去噪

得分匹配

某

些情况下，我

们希望拟合

以下分布来

正则化得分

匹配

psmoothed(x)

= ∫

pdata(y)q(x |

y)dy (18.27)

而不是

拟合真实分

布 pdata。分布

q(x | y) 是一

个损坏过程

，通常在形成

x

的过程中

会

向 y 中添加少

量噪声。

去噪

得分匹配非

常有用，因为

在实践中，通

常我们不能

获取真实的

pdata，而只

能得到

其样本确定

的经验分布

。给定足够容

量，任何一致

估计都会使

pmodel 成为一

组以

训练点为中

心的

Dirac 分布。考

虑在第 5.4.5 节介

绍的渐近一

致性上的损

失，通

过 q 来平

滑有助于缓

解这个问题

。Kingma and

LeCun (2010b) 介绍了平滑

分布 q

为

正态

分布噪声的

正则化得分

匹配。

回顾第

14.5.1 节，有一些自

编码器训练

算法等价于

得分匹配或

去噪得分匹

配。因

此，这些

自编码器训

练算法也是

解决配分函

数问题的一

种方式。

18.6 噪声

对比估计 529

18.6 噪

声对比估计

具有难求解

的配分函数

的大多数模

型估计都没

有估计配分

函数。SML 和 CD

只

估

计对数配分

函数的梯度

，而不是估计

配分函数本

身。得分匹配

和伪似然避

免了和配

分

函数相关的

计算。

噪声对

比估计（noise-contrastive

estimation，NCE）(Gutmann and Hyvari￾nen, 2010)

采取

了一种不同

的策略。在这

种方法中，模

型估计的概

率分布被明

确表示

为

log pmodel(x)

= log p˜model(x; θ)

+ c, (18.28)

其

中

c 是 − logZ(θ)

的近似

。噪声对比估

计过程将 c 视

为另一参数

，使用相同的

算

法同时估

计

θ 和 c，而不是

仅仅估计 θ，。因

此，所得到的

log

pmodel(x) 可能并不完

全对应有效

的概率分布

，但随着 c 估计

的改进，它将

变得越来越

接近有效值

1。

这种方法不

可能使用最

大似然作为

估计的标准

。最大似然标

准可以设置

c 为任

意大的

值，而不是设

置 c

以创建一

个有效的概

率分布。

NCE 将估

计 p(x)

的无监督

学习问题转

化为学习一

个概率二元

分类器，其中

一

个类别对

应模型生成

的数据。该监

督学习问题

中的最大似

然估计定义

了原始问题

的

渐近一致

估计。

具体地

说，我们引入

第二个分布

，

噪声分布（noise distribution）pnoise(x)。噪

声分布应该

易于估计和

从中采样。我

们现在可以

构造一个联

合 x 和新二值

变量

y 的

模型

。在新的联合

模型中，我们

指定

pjoint(y

= 1) = 1

2

, (18.29)

pjoint(x

| y = 1)

= pmodel(x), (18.30)

和

pjoint(x | y =

0) = pnoise(x). (18.31)

换言

之，y 是一个决

定我们从模

型还是从噪

声分布中生

成 x 的开关变

量。

我们可以

在训练数据

上构造一个

类似的联合

模型。在这种

情况下，开关

变量决定

是

从 数据 还是

从噪声分布

中抽取

x。正式

地，ptrain(y = 1) =

1

2，ptrain(x | y

= 1) =

pdata(x)，和

ptrain(x | y =

0) = pnoise(x)。

1NCE

也适用

于具有易于

处理的，不需

要引入额外

参数 c 的配分

函数的问题

。它已经是最

令人感兴趣

的，估计具

有

复杂配分函

数模型的方

法。

530 第十八章

直面配分函

数

现在我们

可以应用标

准的最大似

然学习拟合

pjoint 到

ptrain 的 监督学

习问题：

θ,

c = arg max

θ,c

Ex,y∼ptrain log pjoint(y

| x). (18.32)

分布

pjoint

本质上是将

逻辑回归模

型应用于模

型和噪声分

布之间的对

数概率之

差

：

pjoint(y =

1 | x) =

pmodel(x)

pmodel(x) + pnoise(x)

(18.33)

=

1

1

+ pnoise(x)

pmodel(x)

(18.34)

=

1

1 +

exp (

log pnoise(x)

pmodel(x)

) (18.35)

=

σ

(

− log

pnoise(x)

pmodel(x)

)

(18.36)

= σ(log pmodel(x) −

log pnoise(x)). (18.37)

因此，只要

log p˜model 易

于反向传播

，并且如上所

述，pnoise 应易于估

计（以便

评估

pjoint）和采样（以生

成训练数据

），那么NCE 就易于

使用。

NCE 能够非

常成功地应

用于随机变

量较少的问

题，但即使随

机变量有很

多可以

取的

值时，它也很

有效。例如，它

已经成功地

应用于给定

单词上下文

建模单词的

条

件分布 (Mnih and

Kavukcuoglu, 2013)。虽

然单词可以

采样自一个

很大的词汇

表，但

是只能

采样一个单

词。

当

NCE 应用于

具有许多随

机变量的问

题时，其效率

会变得较低

。当逻辑回归

分

类器发现

某个变量的

取值不大可

能时，它会拒

绝这个噪声

样本。这意味

着在 pmodel

学习了

基本的边缘

统计之后，学

习进程会大

大减慢。想象

一个使用非

结构化高斯

噪

声作为 pnoise 来

学习面部图

像的模型。如

果

pmodel 学会了眼

睛，就算没有

学习任何

其

他面部特征

，比如嘴，它也

会拒绝几乎

所有的非结

构化噪声样

本。

噪声分布

pnoise

必须是易于

估计和采样

的约束可能

是过于严格

的限制。当 pnoise

比

较简单时，大

多数采样可

能与数据有

着明显不同

，而不会迫使

pmodel 进行显著改

进。

类似于得

分匹配和伪

似然，如果 p˜ 只

有下界，那么

NCE 不会有效。这

样的下界

能

够用于构建

pjoint(y = 1 |

x) 的下界，但是

它只能用于

构建 pjoint(y =

0 | x)（出现

18.7

估

计配分函数

531

在一半的 NCE 对

象中）的上界

。同样地，pnoise

的下

界也没有用

，因为它只提

供了

pjoint(y = 1

| x) 的上界

。

在每个梯度

步骤之前，模

型分布被复

制来定义新

的噪声分布

时，NCE

定义了一

个被称为 自

对比估计（self-contrastive estimation）的

过程，其梯度

期望等价于

最大

似然的

梯度期望

(Goodfellow, 2014)。特

殊情况的 NCE（噪

声采样由模

型生成）表

明

最大似然可

以被解释为

使模型不断

学习以将现

实与自身发

展的信念区

分的过程，

而

噪声对比估

计通过让模

型区分现实

和固定的基

准（噪声模型

），我们降低了

计算成

本。

在

训练样本和

生成样本（使

用模型能量

函数定义分

类器）之间进

行分类以得

到模型的梯

度的方法，已

经在更早的

时候以各种

形式提出来

(Welling et

al., 2003b;

Bengio, 2009)。

噪声对比估

计是基于良

好生成模型

应该能够区

分数据和噪

声的想法。一

个密切

相关

的想法是，良

好的生成模

型能够生成

分类器无法

将其与数据

区分的样本

。这个

想法诞

生了生成式

对抗网络（第

20.10.4 节）。

18.7 估计配分

函数

尽管本

章中的大部

分内容都在

避免计算与

无向图模型

相关的难以

计算的配分

函

数

Z(θ)，但在本

节中我们将

会讨论几种

直接估计配

分函数的方

法。

估计配分

函数可能会

很重要，当我

们希望计算

数据的归一

化似然时，我

们会需

要它

。在评估模型

，监控训练性

能，和比较模

型时，这通常

是很重要的

。

例如，假设我

们有两个模

型：概率分布

为

pA(x; θA) = Z

1

A

p˜A(x; θA)

的模型 MA

和

概率分布为

pB(x; θB)

= Z

1

B

p˜B(x; θB) 的模型 MB。比较

模型的常用

方法是评估

和比较两个

模型分配给

独立同分布

测试数据集

的似然。假设

测试集含

m 个

样本

{x

(1)

, . . .

, x

(m)}。如果 ∏

i

pA(x

(i)

;

θA) >

∏

i

pB(x

(i)

; θB)，或

等价地，如果

∑

i

log pA(x

(i)

; θA) −

∑

i

log pB(x

(i)

; θB) > 0,

(18.38)

那么我们说

MA 是一个比 MB

更

好的模型（或

者，至少可以

说，它在测试

集上是

一个

更好的模型

），这是指它有

一个更好的

测试对数似

然。不幸的是

，测试这个条

件

是否成立

需要知道配

分函数。式(18.38) 看

起来需要估

计模型分配

给每个点的

对数概

率，因

而需要估计

配分函数。我

们可以通过

将式 (18.38) 重新转

化为另一种

形式来简

532

第

十八章 直面

配分函数

化

情况，在该形

式中我们只

需要知道两

个模型的配

分函数的比

率：

∑

i

log pA(x

(i)

; θA) −

∑

i

log pB(x

(i)

; θB) = ∑

i

(

log p˜A(x

(i)

; θA)

p˜B(x(i)

; θB)

)

−

m log Z(θA)

Z(θB)

.

(18.39)

因此，我们

可以在不知

道任一模型

的配分函数

，而只知道它

们比率的情

况下，判断

模

型

MA 是否比模

型 MB 更优。正如

我们将很快

看到的，在两

个模型相似

的情况

下，我

们可以使用

重要采样来

估计比率。

然

而，如果我们

想要计算测

试数据在 MA 或

MB

上的真实概

率，我们需要

计

算配分函

数的真实值

。如果我们知

道两个配分

函数的比率

，r =

Z(θB)

Z(θA)，并且我们知

道两者中一

个的实际值

，比如说 Z(θA)，那么

我们可以计

算另一个的

值：

Z(θB) =

rZ(θA) = Z(θB)

Z(θA)

Z(θA). (18.40)

一种估计

配分函数的

简单方法是

使用蒙特卡

罗方法，例如

简单重要采

样。以下

用连

续变量积分

来表示该方

法，也可以替

换积分为求

和，很容易将

其应用到离

散变

量的情

况。我们使用

提议分布 p0(x) = Z

1

0

p˜0(x)，其

在配分函数

Z0 和未归一化

分布

p˜0(x) 上易于

采样和估计

。

Z1 =

∫

p˜1(x)dx (18.41)

=

∫

p0(x)

p0(x)

p˜1(x)dx

(18.42)

= Z0

∫

p0(x)

p˜1(x)

p˜0(x)

dx

(18.43)

Zˆ

1 =

Z0

K

∑

K

k=1

p˜1(x

(k)

)

p˜0(x(k))

s.t. : x

(k) ∼ p0 (18.44)

在最后一行

，我们使用蒙

特卡罗估计

，使用从 p0(x) 中抽

取的采样计

算积分 Zˆ

1，

然后

用未归一化

的 p˜1 和提议分

布

p0 的比率对

每个采样加

权。

这种方法

使得我们可

以估计配分

函数之间的

比率：

1

K

K

∑

k=1

˜p1(x

(k)

)

p˜0(x(k))

s.t. : x

(k)

∼ p0. (18.45)

然后该

值可以直接

比较式

(18.39) 中的

两个模型。

18.7 估

计配分函数

533

如果分布 p0 接

近 p1，那么式

(18.44) 能

够有效地估

计配分函数

(Minka, 2005)。

不幸的是，大

多数时候

p1 都

很复杂（通常

是多峰值的

），并且定义在

高维空间中

。

很难找到一

个易求解的

p0，既能易于评

估，又能充分

接近 p1

以保持

高质量的近

似。

如果 p0 和

p1 不

接近，那么 p0 的

大多数采样

将在

p1 中具有

较低的概率

，从而在

式 (18.44)

的

求和中产生

（相对的）可忽

略的贡献。

如

果求和中只

有少数几个

具有显著权

重的样本，那

么将会由于

高方差而导

致估

计的效

果很差。这可

以通过估计

Zˆ

1

的方差来定

量地理解：

ˆVar (

Zˆ

1

)

=

K

Z0

2

∑

K

k=1

(

p˜1(x

(k)

)

p˜0(x(k))

− Zˆ

1

)2

. (18.46)

当

重要性权重

˜p1(x

(k)

)

p˜0(x(k))

存在显著偏

差时，上式的

值是最大的

。

我们现在关

注两个解决

高维空间复

杂分布上估

计配分函数

的方法：退火

重要采

样和

桥式采样。两

者都始于上

面介绍的简

单重要采样

方法，并且都

试图通过引

入缩

小

p0 和 p1 之

间差距的中

间分布，来解

决

p0 远离 p1 的问

题。

18.7.1 退火重要

采样

在 DKL(p0∥p1)

很大

的情况下（即

p0 和 p1 之间几乎

没有重叠），一

种称为退火

重要采样（annealed

importance sampling，AIS）的

方法试图通

过引入中间

分

布来缩小

这种差距 (Jarzynski,

1997; Neal, 2001)。考

虑分布序列

pη0

,

. . . ,

pηn，其中

0 = η0

< η1 < ·

· · < ηn−1

< ηn = 1，分布序

列中的第一

个和最后一

个分别是

p0 和

p1。

这种方法使

我们能够估

计定义在高

维空间多峰

分布（例如训

练 RBM

时定义

的

分布）上的配

分函数。我们

从一个已知

配分函数的

简单模型（例

如，权重为零

的 RBM）开始，估计

两个模型配

分函数之间

的比率。该比

率的估计基

于许多个相

似

分布的比

率估计，例如

在零和学习

到的权重之

间插值一组

权重不同的

RBM。

534 第十八章 直

面配分函数

现在我们可

以将比率 Z

Z

1

0 写

作

Z1

Z0

=

Z1

Z0

Zη1

Zη1

.

. .

Zηn−1

Zηn−1

(18.47)

=

Zη1

Z0

Zη2

Zη1

. .

.

Zηn−1

Zηn−2

Z1

Zηn−1

(18.48)

=

n−1

∏

j=0

Zηj+1

Zηj

. (18.49)

如果对于

所有的 0

≤ j ≤ n

− 1，分布

pηj 和 pηj+1

足够接近

，那么我们能

够使用简

单

的重要采样

来估计每个

因子 Z

Z

ηj+1

ηj

，然后使

用这些得到

Z

Z

1

0 的估计。

这些

中间分布是

从哪里来的

呢？正如最先

的提议分布

p0

是一种设计

选择，分布

序

列 pη1

.

. . pηn−1 也是如此

。也就是说，它

们可以被特

别设计为特

定的问题领

域。中

间分布

的一个通用

和流行选择

是使用目标

分布 p1 的加权

几何平均，起

始分布（其配

分函数是已

知的）为 p0：

pηj ∝ p

η

1

j

p

1

0

−ηj

. (18.50)

为了

从这些中间

分布中采样

，我们定义了

一组马尔可

夫链转移函

数 Tηj

(x

′

| x)，

定义了给

定 x

转移到 x

′ 的

条件概率分

布。转移算子

Tηj

(x

′

| x)

定义如下，保

持

pηj

(x) 不变：

pηj

(x) = ∫

pηj

(x

′

)Tηj

(x | x

′

)dx

′

. (18.51)

这些

转移可以被

构造为任何

马尔可夫链

蒙特卡罗方

法（例如，Metropolis-Hastings，

Gibbs），包括

涉及多次遍

历所有随机

变量或其他

迭代的方法

。

然后，AIS 采样方

法从

p0 开始生

成样本，并使

用转移算子

从中间分布

顺序地生

成

采样，直到我

们得到目标

分布 p1

的采样

：

• 对于 k

= 1 . .

. K

– 采样

x

(k)

η1 ∼

p0(x)

– 采

样 x

(k)

η2 ∼ Tη1

(x

(k)

η2

|

x

(k)

η1

)

– . . .

– 采样 x

(k)

ηn−1 ∼ Tηn−2

(x

(k)

ηn−1

| x

(k)

ηn−2

)

–

采样

x

(k)

ηn ∼

Tηn−1

(x

(k)

ηn

| x

(k)

ηn−1

)

• 结束

18.7

估计配

分函数 535

对于

采样 k，通过连

接式

(18.49) 给出的

中间分布之

间的重要性

权重，我们可

以

导出目标

重要性权重

：

w

(k) =

˜pη1

(x

(k)

η1

)

˜p0(x

(k)

η1

)

p˜η2

(x

(k)

η2

)

p˜η1

(x

(k)

η2

)

. . .

p˜1(x

(

1

k)

)

˜pηn−1

(x

(k)

ηn )

. (18.52)

为了避免诸

如上溢的数

值问题，最佳

方法可能是

通过加法或

减法计算 log w

(k)，而

不

是通过概

率乘法和除

法计算 w

(k)。

利用

由此定义的

采样过程和

式

(18.52) 中给出的

重要性权重

，配分函数的

比率估

计如

下所示：

Z1

Z0

≈

K

1

K

∑

k=1

w

(k)

(18.53)

为 了

验

证 该 过 程

定

义 的重 要

采 样方

案 是

否 有 效，

我 们

可 以 展

示 (Neal,

2001) AIS

过

程对应着扩

展状态空间

上的简单重

要采样，其中

数据点采样

自乘

积空间

[xη1

, .

. . , xηn−1

, x1]。为此，我们将

扩展空间上

的分布定义

为

˜p(xη1

,

. . . ,

xηn−1

, x1) (18.54)

=˜p1(x1)

˜Tηn−1

(xηn−1

|

x1)

˜Tηn−2

(xηn−2

|

xηn−1

). . .

˜Tη1

(xη1

| xη2

), (18.55)

其中 T˜

a 是由

Ta 定义的转移

算子的逆（应

用贝叶斯规

则）：

˜Ta(x

′

| x) =

pa(x

′

)

pa(x)

Ta(x | x

′

) = p˜a(x

′

)

p˜a(x)

Ta(x |

x

′

). (18.56)

将以上代

入到式 (18.55) 给出

的扩展状态

空间上的联

合分布中，我

们得到：

˜p(xη1

, . . .

, xηn−1

, x1)

(18.57)

=˜p1(x1)

p˜ηn−1

(xηn−1

)

˜pηn−1

(x1)

Tηn−1

(x1 | xηn−1

)

n∏−2

i=1

p˜ηi

(xηi

)

p˜ηi

(xηi+1 )

Tηi

(xηi+1 | xηi

) (18.58)

=

p˜1(x1)

˜pηn−1

(x1)

Tηn−1

(x1

| xηn−1

)˜pη1

(xη1

)

n−2

∏

i=1

˜pηi+1 (xηi+1 )

p˜ηi

(xηi+1 )

Tηi

(xηi+1

| xηi

). (18.59)

通过

上面给定的

采样方案，现

在我们可以

从扩展样本

上的联合提

议分布 q 上生

成采

样，联合

分布如下

q(xη1

, . .

. , xηn−1

,

x1) = p0(xη1

)Tη1

(xη2

| xη1

).

. . Tηn−1

(x1

| xηn−1

). (18.60)

536 第

十八章 直面

配分函数

式

(18.59)

给出了扩展

空间上的联

合分布。将 q(xη1

, .

. . , xηn−1

, x1) 作

为扩展状态

空间

上的提

议分布（我们

会从中抽样

），重要性权重

如下

w

(k) =

˜p(xη1

, . . .

, xηn−1

, x1)

q(xη1

, . .

. , xηn−1

,

x1)

=

p˜1(x

(

1

k)

)

˜pηn−1

(x

(k)

ηn−1

)

. . .

˜pη2

(x

(k)

η2

)

˜pη1

(x

(k)

η1

)

p˜η1

(x

(k)

η1

)

p˜0(x

(

0

k)

)

.

(18.61)

这些权

重和 AIS 上的权

重相同。因此

，我们可以将

AIS

解释为应用

于扩展状态

上的

简单重

要采样，其有

效性直接来

源于重要采

样的有效性

。

退火重要采

样首先由 Jarzynski

(1997) 发

现，然后由 Neal (2001)

再

次独立发现

。

目前它是估

计无向概率

模型的配分

函数的最常

用方法。其原

因可能与一

篇有影响力

的论文 (Salakhutdinov and

Murray, 2008) 有关

，该论文并没

有讨论该方

法相对于其

他方法的优

点，而是介绍

了将其应用

于估计受限

玻尔兹曼机

和深度信念

网络的配分

函数。

关于

AIS 估

计性质（例如

，方差和效率

）的讨论，请参

看 Neal (2001)。

18.7.2 桥式采样

类似于 AIS，桥式

采样 (Bennett,

1976) 是另一

种处理重要

采样缺点的

方法。并

非将

一系列中间

分布连接在

一起，桥式采

样依赖于单

个分布 p∗（被称

为桥），在已

知

配分函数的

分布 p0 和分布

p1（我们试图估

计其配分函

数 Z1）之间插值

。

桥式采样估

计比率 Z1/Z0：p˜0 和 p˜∗

之

间重要性权

重期望与 p˜1 和

p˜∗ 之间重要

性

权重的比率

，

Z1

Z0

≈

K

∑

k=1

˜p∗(x

(k)

0

)

˜p0(x

(k)

0

)

/

K

∑

k=1

˜p∗(x

(k)

1

)

˜p1(x

(k)

1

)

.

(18.62)

如果仔细选

择桥式采样

p∗，使其与 p0 和

p1 都

有很大重合

的话，那么桥

式采样能够

允许两个分

布（或更正式

地，DKL(p0∥p1)）之间有较

大差距（相对

标准重要采

样而

言）。

可以

表明，最优的

桥式采样是

p

(

∗

opt)

(x)

∝

˜p0(x)˜p1(x)

rp˜0(x)+˜p1(x)，其中 r

= Z1/Z0。这似乎

是一个不可

行的解决方

案，因为它似

乎需要我们

估计数值 Z1/Z0。然

而，可以从粗

糙的 r

开始估

计，然后使用

得到的桥式

采样逐步迭

代以改进估

计 (Neal, 2005)。也就

是说

，我们会迭代

地重新估计

比率，并使用

每次迭代更

新

r 的值。

18.7 估计

配分函数

537

链

接重要采样

AIS 和桥式采样

各有优点。如

果 DKL(p0∥p1)

不太大（由

于 p0 和 p1

足够接

近）的话，那么

桥式采样能

比 AIS 更高效地

估计配分函

数比率。然而

，如果

对于单

个分布

p∗ 而言

，两个分布相

距太远难以

桥接差距，那

么 AIS 至少可以

使用许

多潜

在中间分布

来跨越 p0 和 p1

之

间的差距。Neal (2005) 展

示链接重要

采样方法如

何利用桥式

采样的优点

，桥接 AIS

中使用

的中间分布

，并且显著改

进了整个配

分函

数的估

计。

在训练期

间估计配分

函数 虽然

AIS 已

经被认为是

用于估计许

多无向模型

配分函

数的

标准方法，但

是它在计算

上代价很高

，以致其在训

练期间仍然

不很实用。研

究

者探索了

一些在训练

过程中估计

配分函数的

替代方法。

使

用桥式采样

、短链 AIS 和并行

回火的组合

，Desjardins et

al. (2011) 设计了一

种

在训练过程

中追踪

RBM 配分

函数的方法

。该策略的基

础是，在并行

回火方法操

作

的每个温

度下，RBM 配分函

数的独立估

计会一直保

持。作者将相

邻链（来自并

行回

火）的配

分函数比率

的桥式采样

估计和跨越

时间的 AIS 估计

组合起来，提

出一个在

每

次迭代学习

时估计配分

函数的（且方

差较小的）方

法。

本章中描

述的工具提

供了许多不

同的方法，以

解决难处理

的配分函数

问题，但

是在

训练和使用

生成模型时

，可能会存在

一些其他问

题。其中最重

要的是我们

接下

来会遇

到的难以推

断的问题。

第

十九章

近似

推断

许多概

率模型很难

训练的原因

是很难进行

推断。在深度

学习中，通常

我们有一

系

列可见变量

v 和一系列潜

变量

h。推断困

难通常是指

难以计算 p(h | v)

或

其期望。

而这

样的操作在

一些诸如最

大似然学习

的任务中往

往是必需的

。

许多仅含一

个隐藏层的

简单图模型

会定义成易

于计算 p(h

| v) 或其

期望的形式

，

例如受限玻

尔兹曼机和

概率

PCA。不幸的

是，大多数具

有多层隐藏

变量的图模

型的

后验分

布都很难处

理。对于这些

模型而言，精

确推断算法

需要指数量

级的运行时

间。

即使一些

只有单层的

模型，如稀疏

编码，也存在

着这样的问

题。

在本章中

，我们将会介

绍几个用来

解决这些难

以处理的推

断问题的技

巧。稍后，

在第

二十章中，我

们还将描述

如何将这些

技巧应用到

训练其他方

法难以奏效

的概率

模型

中，如深度信

念网络、深度

玻尔兹曼机

。

在深度学习

中难以处理

的推断问题

通常源于结

构化图模型

中潜变量之

间的相互

作

用。读者可以

参考图

19.1 的几

个例子。这些

相互作用可

能是无向模

型的直接相

互

作用，也可

能是有向模

型中同一个

可见变量的

共同祖先之

间的 “相消解

释’’

作用。

538

19.1 把推

断视作优化

问题

539

图 19.1: 深度

学习中难以

处理的推断

问题通常是

由于结构化

图模型中潜

变量的相互

作用。这些

相

互作用产生

于一个潜变

量与另一个

潜变量或者

当V-结构的子

节点可观察

时与更长的

激活路径

相

连。(左) 一个隐

藏单元存在

连接的 半受

限玻尔兹曼

机（semi-restricted

Boltzmann Machine）

(Osindero and

Hinton, 2008)。由于存在

大量潜变量

的团，潜变量

的直接连接

使得后验分

布难以处

理

。(中) 一个深度

玻尔兹曼机

，被分层从而

使得不存在

层内连接，由

于层之间的

连接其后验

分布仍

然难

以处理。(右) 当

可见变量可

观察时这个

有向模型的

潜变量之间

存在相互作

用，因为每两

个潜

变量都

是共父。即使

拥有上图中

的某一种结

构，一些概率

模型依然能

够获得易于

处理的关于

潜变

量的后

验分布。如果

我们选择条

件概率分布

来引入相对

于图结构描

述的额外的

独立性这种

情况也

是可

能出现的。举

个例子，概率

PCA的图结构如

右图所示，然

而由于其条

件分布的特

殊性质（带

有

相互正交基

向量的线性

高斯条件分

布）依然能够

进行简单的

推断。

19.1 把推断

视作优化问

题

精确推断

问题可以描

述为一个优

化问题，有许

多方法正是

由此解决了

推断的困

难

。通过近似这

样一个潜在

的优化问题

，我们往往可

以推导出近

似推断算法

。

为了构造这

样一个优化

问题，假设我

们有一个包

含可见变量

v 和潜变量

h 的

概

率模型。我

们希望计算

观察数据的

对数概率 log

p(v; θ)。有

时候如果边

缘化消去 h 的

操作很费时

，我们会难以

计算

log p(v; θ)。作为替

代，我们可以

计算一个 log

p(v; θ)

的

下界 L(v,

θ, q)。这个下

界被称为 证

据下界（evidence lower

bound, ELBO）。这个

下界的另一

个常用名称

是负 变分自

由能（variational free

energy）。具体地

，这个证

据下

界是这样定

义的：

L(v, θ,

q) = log p(v;

θ) − DKL(q(h |

v)∥p(h | v; θ)),

(19.1)

其中 q 是

关于

h 的一个

任意概率分

布。

因为 log

p(v) 和 L(v, θ,

q) 之

间的距离是

由 KL 散度来衡

量的，且

KL 散度

总是

540 第十九

章

近似推断

非负的，我们

可以发现 L 总

是小于等于

所求的对数

概率。当且仅

当分布 q

完全

相等

于 p(h |

v) 时取

到等号。

令人

吃惊的是，对

于某些分布

q，计算 L

可以变

得相当简单

。通过简单的

代数

运算我

们可以把 L 重

写成一个更

加简单的形

式：

L(v, θ, q) =

log p(v; θ) −

DKL(q(h | v)∥p(h |

v; θ)) (19.2)

=

log p(v; θ) −

Eh∼q log q(h |

v)

p(h | v)

(19.3)

= log p(v;

θ) − Eh∼q log

q(h | v)

p(h,v;θ)

p(v;θ)

(19.4)

= log

p(v; θ) − Eh∼q[log

q(h | v) −

log p(h, v; θ)

+ log p(v; θ)]

(19.5)

= − Eh∼q[log

q(h | v) −

log p(h, v; θ)].

(19.6)

这也给出

了证据下界

的标准定义

：

L(v, θ,

q) = Eh∼q[log p(h,

v)] + H(q). (19.7)

对于一个选

择的合适分

布 q 来说，L 是容

易计算的。对

任意分布

q 的

选择来说，

L 提

供了似然函

数的一个下

界。越好地近

似

p(h | v) 的分布

q(h | v)，得

到的下界就

越紧，换言之

，就是与 log

p(v) 更加

接近。当 q(h |

v) = p(h |

v) 时，这

个近似是完

美的，也意味

着 L(v, θ,

q) = log p(v;

θ)。

因此我们

可以将推断

问题看作是

找一个分布

q 使得 L

最大的

过程。精确推

断能

够在包

含分布 p(h |

v) 的函

数族中搜索

一个函数，完

美地最大化

L。在本章中，我

们

将会讲到

如何通过近

似优化寻找

分布 q

的方法

来推导出不

同形式的近

似推断。我们

可以通过限

定分布 q 的形

式或者使用

并不彻底的

优化方法来

使得优化的

过程更加高

效（却更粗略

），但是优化的

结果是不完

美的，不求彻

底地最大化

L，而只要显著

地

提升

L。

无论

我们选择什

么样的分布

q，L 始终是一个

下界。我们可

以通过选择

一个更简

单

或更复杂的

计算过程来

得到对应的

更松或更紧

的下界。通过

一个不彻底

的优化过

程

或者将分布

q 做很强的限

定（并且使用

一个彻底的

优化过程）我

们可以获得

一个

很差的

分布 q，但是降

低了计算开

销。

19.2 期望最大

化 541

19.2

期望最大

化

我们介绍

的第一个最

大化下界 L 的

算法是

期望

最大化（expectation maximiza￾tion, EM）算法

。在潜变量模

型中，这是一

个非常常见

的训练算法

。在这里我们

描

述

Neal and Hinton (1999)

所提出

的 EM 算法。与大

多数我们在

本章中介绍

的其他

算法

不同的是，EM

并

不是一个近

似推断算法

，而是一种能

够学到近似

后验的算法

。

EM算法由交替

迭代，直到收

敛的两步运

算组成：

• E

步（expectation step）: 令

θ

(0)

表示在这一

步开始时的

参数值。对任

何我们

想要

训练的（对所

有的或者小

批量数据均

成立）索引为

i 的训练样本

v

(i)，令

q(h

(i)

| v)

= p(h

(i)

|

v

(i)

; θ

(0))。通过这个

定义，我们认

为 q 在当前参

数 θ

(0) 下

定义。如

果我们改变

θ，那么 p(h

| v; θ) 将会相

应地变化，但

是

q(h | v) 还是

不变

并且等于 p(h | v;

θ

(0))。

• M

步

（maximization step）：使用选择的

优化算法完

全地或者部

分地关于 θ 最

大化

∑

i

L(v

(i)

, θ, q). (19.8)

这可以

被看作通过

坐标上升算

法来最大化

L。在第一步中

，我们更新分

布 q 来

最大化

L，而在另一步

中，我们更新

θ

来最大化 L。

基

于潜变量模

型的随机梯

度上升可以

被看作是一

个 EM

算法的特

例，其中 M

步包

括了单次梯

度操作。EM 算法

的其他变种

可以实现多

次梯度操作

。对一些模型

族来说，M

步甚

至可以直接

推出解析解

，不同于其他

方法，在给定

当前 q 的情况

下

直接求出

最优解。

尽管

E 步采用的是

精确推断，我

们仍然可以

将 EM 算法视作

是某种程度

上的近

似推

断。具体地说

，M 步假设一个

分布 q 可以被

所有的

θ 值分

享。当 M 步越来

越

远离 E 步中

的 θ

(0) 时，这将会

导致 L 和真实

的

log p(v) 之间出现

差距。幸运的

是，

在进入下

一个循环时

，E

步把这种差

距又降到了

0。

EM 算法还包含

一些不同的

见解。首先，它

包含了学习

过程的一个

基本框架，就

是我们通过

更新模型参

数来提高整

个数据集的

似然，其中缺

失变量的值

是通过后验

分布来估计

的。这种特定

的性质并非

EM 算法独有的

。例如，使用梯

度下降来最

大化

对数似

然函数的方

法也有相同

的性质。计算

对数似然函

数的梯度需

要对隐藏单

元的

542 第十九

章 近似推断

后验分布求

期望。EM

算法另

一个关键的

性质是当我

们移动到另

一个 θ 时候，我

们

仍然可以

使用旧的分

布

q。在传统机

器学习中，这

种特有的性

质在推导大

M 步更新

时候

得到了广泛

的应用。在深

度学习中，大

多数模型太

过于复杂以

致于在最优

大 M

步更新中

很难得到一

个简单的解

。所以 EM 算法的

第二个特质

，更多为其所

独有，

较少被

使用。

19.3 最大后

验推断和稀

疏编码

我们

通常使用 推

断（inference）这个术语

来指代给定

一些其他变

量的情况下

计

算某些变

量概率分布

的过程。当训

练带有潜变

量的概率模

型时，我们通

常关注于计

算 p(h | v)。另一种可

选的推断形

式是计算一

个缺失变量

的最可能值

来代替在所

有可

能值的

完整分布上

的推断。在潜

变量模型中

，这意味着计

算

h

∗ =

arg max

h

p(h

| v). (19.9)

这被称作

最大后验（Maximum

A Posteriori）推

断，简称 MAP 推断

。

MAP 推断并不被

视作是一种

近似推断，它

只是精确地

计算了最有

可能的一个

h

∗。然而，如果我

们希望设计

一个最大化

L(v, h,

q) 的学习过程

，那么把 MAP 推断

视作是输出

一个

q 值的学

习过程是很

有帮助的。在

这种情况下

，我们可以将

MAP 推

断视作是

近似推断，因

为它并不能

提供一个最

优的

q。

我们回

过头来看看

第 19.1 节中所描

述的精确推

断，它指的是

关于一个在

无限制

的概

率分布族中

的分布 q 使用

精确的优化

算法来最大

化

L(v,

θ, q) = Eh∼q[log

p(h, v)] + H(q).

(19.10)

我们通过

限定分布 q 属

于某个分布

族，能够使得

MAP

推断成为一

种形式的近

似推

断。具体

地说，我们令

分布 q 满足一

个

Dirac 分布：

q(h |

v) = δ(h −

µ). (19.11)

这也

意味着现在

我们可以通

过 µ

来完全控

制分布 q。将 L 中

不随

µ 变化的

项丢弃，

我们

只需解决一

个优化问题

：

µ

∗ = arg max

µ

log p(h =

µ, v), (19.12)

19.3

最大后验推

断和稀疏编

码 543

这等价于

MAP 推断问题

h

∗ = arg

max

h

p(h |

v). (19.13)

因

此我们能够

证明一种类

似于 EM

算法的

学习算法，其

中我们轮流

迭代两步，

一

步是用 MAP 推断

估计出

h

∗，另一

步是更新 θ 来

增大

log p(h

∗

,

v)。从 EM 算法

角

度看，这也

是对

L 的一种

形式的坐标

上升，交替迭

代时通过推

断来优化关

于 q 的

L

以及通

过参数更新

来优化关于

θ 的 L。作为一个

整体，这个算

法的正确性

可以得到

保

证，因为 L 是 log

p(v) 的

下界。在 MAP 推断

中，这个保证

是无效的，因

为

Dirac

分布的微

分熵趋近于

负无穷，使得

这个界会无

限地松。然而

，人为加入一

些 µ 的噪

声会

使得这个界

又有了意义

。

MAP 推断作为特

征提取器以

及一种学习

机制被广泛

地应用在了

深度学习中

。它

主要用于

稀疏编码模

型中。

我们回

过头来看第

13.4 节中的稀疏

编码，稀疏编

码是一种在

隐藏单元上

加上了

诱导

稀疏性的先

验知识的线

性因子模型

。一个常用的

选择是可分

解的 Laplace

先验，

表

示为

p(hi) =

λ

2

exp(−λ|hi

|).

(19.14)

可见的

节点是由一

个线性变化

加上噪声生

成的：

p(v |

h) = N (v;Wh

+ b, β−1

I).

(19.15)

分布 p(h |

v) 难

以计算，甚至

难以表达。每

一对 hi，hj 变量都

是

v 的母节点

。

这也意味着

当 v

可被观察

时，图模型包

含了一条连

接 hi 和 hj

的活跃

路径。因此

p(h | v)

中

所有的隐藏

单元都包含

在了一个巨

大的团中。如

果是高斯模

型，那么这些

相互作用关

系可以通过

协方差矩阵

来高效地建

模。然而稀疏

型先验使得

这些相互作

用关系并不

服从高斯分

布。

分布 p(x |

h) 的难

处理性导致

了对数似然

及其梯度也

很难得到。因

此我们不能

使用精确的

最大似然估

计来进行学

习。取而代之

的是，我们通

过 MAP 推断以及

最

大化由以

h 为中心的 Dirac 分

布所定义而

成的

ELBO 来学习

模型参数。

如

果我们将训

练集中所有

的向量 h

拼成

矩阵 H，并将所

有的向量 v 拼

起来组成

矩

阵 V，那么稀疏

编码问题意

味着最小化

J(H,W) = ∑

i,j

|Hi,j | +

∑

i,j

(

V

− HW⊤

)2

i,j

. (19.16)

544 第十九章

近

似推断

为了

避免如极端

小的 H 和极端

大的

W 这样的

病态的解，大

多数稀疏编

码的应用包

含了权重衰

减或者对 H 列

范数的限制

。

我们可以通

过交替迭代

，分别关于 H 和

W 最小化

J 的方

式来最小化

J。且两

个子问

题都是凸的

。事实上，关于

W 的最小化问

题就是一个

线性回归问

题。然而关

于

这两个变量

同时最小化

J 的问题通常

并不是凸的

。

关于 H

的最小

化问题需要

某些特别设

计的算法，例

如特征符号

搜索方法 (Lee

et al.,

2007)。

19.4 变

分推断和变

分学习

我们

已经说明过

了为什么证

据下界

L(v, θ, q) 是

log p(v; θ) 的

一个下界、如

何将

推断看

作是关于分

布 q 最大化 L

的

过程以及如

何将学习看

作是关于参

数 θ 最大化 L

的

过程。我们也

讲到了 EM 算法

在给定了分

布 q

的条件下

能够进行大

学习步骤，而

基于 MAP 推断的

学习算法则

是学习一个

p(h |

v) 的点估计而

非推断整个

完整的分

布

。在这里我们

介绍一些变

分学习中更

加通用的算

法。

变分学习

的核心思想

就是在一个

关于

q 的有约

束的分布族

上最大化 L。选

择这

个分布

族时应该考

虑到计算

Eq log p(h, v)

的

难易度。一个

典型的方法

就是添加分

布

q 如何分解

的假设。

一种

常用的变分

学习的方法

是加入一些

限制使得

q 是

一个因子分

布：

q(h |

v) = ∏

i

q(hi

| v). (19.17)

这被称为

均值场（mean-field）方法

。更一般地说

，我们可以通

过选择分布

q 的

形式来选

择任何图模

型的结构，通

过选择变量

之间相互作

用的多少来

灵活地决定

近似程度的

大小。这种完

全通用的图

模型方法被

称为 结构化

变分推断（structured

variational inference）(Saul and Jordan,

1996)。

变

分方法的优

点是我们不

需要为分布

q 设定一个特

定的参数化

形式。我们设

定

它如何分

解，之后通过

解决优化问

题来找出在

这些分解限

制下最优的

概率分布。对

离散型潜变

量来说，这意

味着我们使

用传统的优

化技巧来优

化描述分布

q

的有限个

变

量。对连续型

潜变量来说

，这意味着我

们使用一个

被称为变分

法的数学分

支工具

来解

决函数空间

上的优化问

题。然后决定

哪一个函数

来表示分布

q。变分法是 ‘‘变

分

学习’’ 或者

‘‘变分推断’’ 这

些名字的来

因，尽管当潜

变量是离散

时变分法并

没有用武

19.4

变

分推断和变

分学习 545

之地

。当遇到连续

型潜变量时

，变分法不需

要过多地人

工选择模型

，是一种很有

用

的工具。我

们只需要设

定分布

q 如何

分解，而不需

要去猜测一

个特定的能

够精确近

似

原后验分布

的分布 q。

因为

L(v, θ, q) 被定义成

log p(v; θ) −

DKL(q(h | v)∥p(h |

v; θ))，我

们可以认为

关于 q 最大化

L

的问题等价

于（关于 q）最小

化 DKL(q(h |

v)∥p(h | v))。在这种

情

况下，我们要

用

q 来拟合 p。然

而，与以前方

法不同，我们

使用 KL

散度的

相

反方向来

拟合一个近

似。当我们使

用最大似然

估计来用模

型拟合数据

时，我们最小

化 DKL(pdata∥pmodel)。如图 3.6

所示

，这意味着最

大似然鼓励

模型在每一

个数据达

到

高概率的地

方达到高概

率，而基于优

化的推断则

鼓励了 q 在每

一个真实后

验分

布概率

低的地方概

率较小。这两

种基于 KL 散度

的方法都有

各自的优点

与缺点。选

择

哪一种方法

取决于在具

体每一个应

用中哪一种

性质更受偏

好。在基于优

化的推断

问

题中，从计算

角度考虑，我

们选择使用

DKL(q(h | v)∥p(h |

v))。具体地说，计

算

DKL(q(h | v)∥p(h

| v)) 涉及到了

计算分布 q

下

的期望。所以

通过将分布

q 设计得较

为

简单，我们可

以简化求所

需要的期望

的计算过程

。KL 散度的相反

方向需要计

算真

实后验

分布下的期

望。因为真实

后验分布的

形式是由模

型的选择决

定的，所以我

们

不能设计

出一种能够

精确计算 DKL(p(h |

v)∥q(h | v)) 的

开销较小的

方法。

19.4.1 离散型

潜变量

关于

离散型潜变

量的变分推

断相对来说

比较直接。我

们定义一个

分布 q，通常

分

布 q 的每个因

子都由一些

离散状态的

可查询表格

定义。在最简

单的情况中

，h

是二值的并

且我们做了

均值场假定

，分布

q 可以根

据每一个 hi 分

解。在这种情

况

下，我们可

以用一个向

量 hˆ 来参数化

分布 q，hˆ

的每一

个元素都代

表一个概率

，即

q(hi = 1

| v) = hˆ

i。

在确定了

如何表示分

布 q 以后，我们

只需要优化

它的参数。在

离散型潜变

量模

型中，这

是一个标准

的优化问题

。基本上分布

q 的选择可以

通过任何优

化算法解决

，

比如梯度下

降算法。

因为

它在许多学

习算法的内

循环中出现

，所以这个优

化问题必须

可以很快求

解。

为了追求

速度，我们通

常使用特殊

设计的优化

算法。这些算

法通常能够

在极少的循

环内解决一

些小而简单

的问题。一个

常见的选择

是使用不动

点方程，换句

话说，就

是解

关于 hˆ

i

的方程

∂

∂hˆ

i

L

= 0. (19.18)

546

第十九章 近

似推断

我们

反复地更新

hˆ 不同的元素

直到满足收

敛准则。

为了

具体化这些

描述，我们接

下来会讲如

何将变分推

断应用到 二

值稀疏编码

（binary sparse coding）模型（这里我

们所描述的

模型是

Henniges et al. (2010)

提出

的，但是我们

采用了传统

、通用的均值

场方法，而原

文作者采用

了一种特殊

设计的

算法

）中。数学推导

过程非常详

细，为希望完

全了解我们

描述过的变

分推断和变

分

学习高级

概念描述的

读者所准备

。而对于并不

计划推导或

者实现变分

学习算法的

读

者来说，可

以放心跳过

，直接阅读下

一节，这并不

会遗漏新的

高级概念。建

议那些

从事

二值稀疏编

码研究的读

者可以重新

看一下第 3.10 节

中描述的一

些经常在概

率模

型中出

现的有用的

函数性质。我

们在推导过

程中随意地

使用了这些

性质，并没有

特

别强调它

们。

在二值稀

疏编码模型

中，输入 v ∈

R

n，是由

模型通过添

加高斯噪声

到 m 个或

有或

无的不同成

分的和而生

成的。每一个

成分可以是

开或者关的

，对应着隐藏

单

元 h ∈

{0, 1}

m:

p(hi

= 1) = σ(bi),

(19.19)

p(v | h)

= N (v;Wh, β

−1

), (19.20)

其中

b 是

一个可以学

习的偏置集

合，W 是一个可

以学习的权

值矩阵，β 是一

个可以

学习

的对角精度

矩阵。

使用最

大似然来训

练这样一个

模型需要对

参数进行求

导。我们考虑

对其中一

19.4 变

分推断和变

分学习

547

个偏

置进行求导

的过程：

∂

∂bi

log p(v) (19.21)

=

∂

∂bi

p(v)

p(v)

(19.22)

=

∂

∂bi

∑

h

p(h, v)

p(v)

(19.23)

=

∂

∂bi

∑

h

p(h)p(v

| h)

p(v)

(19.24)

=

∑

h

p(v

| h)

∂b

∂

i

p(h)

p(v)

(19.25)

=

∑

h

p(h

| v)

∂

∂bi

p(h)

p(h)

(19.26)

=Eh∼p(h|v)

∂

∂bi

log p(h).

(19.27)

这需

要计算 p(h |

v) 下的

期望。不幸的

是，p(h | v)

是一个很

复杂的分布

。关于

p(h, v) 和

p(h | v) 的图

结构可以参

考图

19.2 。隐藏单

元的后验分

布对应的是

关于隐

藏单

元的完全图

，所以相对于

暴力算法，变

量消去算法

并不能有助

于提高计算

期望

的效率

。

hh11 hh22 hh33

vv11

vv22 vv33

hh44

hh11

hh22

hh33

hh44

图

19.2: 包含四个

隐藏单元的

二值稀疏编

码的图结构

。(左) p(h, v)

的图结构

。要注意边是

有向的，

每两

个隐藏单元

都是每个可

见单元的共

父。(右) p(h, v)

的图结

构。为了解释

共父之间的

活跃路径，

后

验分布所有

隐藏单元之

间都有边。

取

而代之的是

，我们可以应

用变分推断

和变分学习

来解决这个

难点。

我们可

以做一个均

值场近似：

q(h | v) =

∏

i

q(hi

|

v). (19.28)

548 第

十九章

近似

推断

二值稀

疏编码中的

潜变量是二

值的，所以为

了表示可分

解的 q 我们假

设对

m

个 Bernoulli 分布

q(hi

| v) 建模。表示 Bernoulli

分

布的一种很

自然的方法

是使用一

个

概率向量 hˆ，满

足 q(hi

| v) = hˆ

i。为了避免

计算中的误

差，比如说计

算 log hˆ

i

时，

我们对

hˆ

i 添加一个约

束，即

hˆ

i 不等于

0 或者

1。

我们将

会看到变分

推断方程理

论上永远不

会赋予 hˆ

i

0 或者

1。然而在软件

实现

过程中

，机器的舍入

误差会导致

0 或者

1 的值。在

二值稀疏编

码的软件实

现中，我

们希

望使用一个

没有限制的

变分参数向

量 z

以及通过

关系 hˆ = σ(z)

来获得

h。因此

通过使

用等式 log σ(zi)

= −ζ(−zi) 来建

立 sigmoid

函数和 softplus 函

数的关系，我

们

可以放心

地在计算机

上计算

log hˆ

i。

在开

始二值稀疏

编码模型中

变分学习的

推导时，我们

首先说明了

均值场近似

的

使用可以

使得学习过

程更加简单

。

证据下界可

以表示为

L(v, θ,

q) (19.29)

=Eh∼q[log p(h,

v)] + H(q) (19.30)

=Eh∼q[log p(h) + log

p(v | h) −

log q(h | v)]

(19.31)

=Eh∼q

[ m∑

i=1

log p(hi) +

n∑

i=1

log p(vi

| h) −

m∑

i=1

log q(hi

|

v)

]

(19.32)

=

m∑

i=1

[

hˆ

i(log σ(bi) − log

hˆ

i) + (1

− hˆ

i)(log σ(−bi)

− log(1 − hˆ

i))]

(19.33)

+ Eh∼q

[

n∑

i=1

log

√

βi

2π

exp(−

βi

2

(vi −

Wi,:h)

2

)

]

(19.34)

=

m∑

i=1

[

hˆ

i(log σ(bi)

− log hˆ

i)

+ (1 − hˆ

i)(log σ(−bi) − log(1

− hˆ

i))]

(19.35)

+

1

2

n∑

i=1 [

log βi

2π

− βi

(

vi

2 − 2viWi,:hˆ

+

∑

j

[

Wi,j

2 hˆ

j

+

∑

k=j

Wi,jWi,khˆ

jhˆ

k

]

)].

(19.36)

尽

管这些方程

从美学观点

来看有些不

尽如人意。他

们展示了 L 可

以被表示为

少量简

单的

代数运算。因

此证据下界

L 是易于处理

的。我们可以

把 L 看作是难

以处理的对

数似然函数

的一个替代

。

原则上说，我

们可以使用

关于 v 和 h

的梯

度上升。这会

成为一个推

断和学习算

19.4 变分推断和

变分学习 549

法

的完美组合

。但是，由于两

个原因，我们

往往不这么

做。第一点，对

每一个

v 我们

需要存储 hˆ。我

们通常更加

偏向于那些

不需要为每

一个样本都

准备内存的

算法。如

果我

们需要为每

一个样本都

存储一个动

态更新的向

量，使得算法

很难处理几

十亿的

样本

。第二个原因

就是为了能

够识别 v 的内

容，我们希望

能够有能力

快速提取特

征

hˆ。在实际应

用场景中，我

们需要在有

限时间内计

算出

hˆ。

由于以

上两个原因

，我们通常不

会采用梯度

下降来计算

均值场参数

hˆ。取而代

之的

是，我们使用

不动点方程

来快速估计

。

不

动 点 方 程

的

核 心 思 想

是

我 们 寻 找

一

个 关 于 h

的

局 部 极 大

点

， 满 足

∇hL(v,

θ, hˆ) = 0。我们无

法同时高效

地计算所有

hˆ

的元素。然而

，我们可以

解

决单个变量

的问题：

∂

∂ˆhi

L(v, θ, hˆ) =

0. (19.37)

我们

可以迭代地

将这个解应

用到 i

= 1, . .

. , m，然后重

复这个循环

直到我们满

足

了收敛准

则。常见的收

敛准则包含

了当整个循

环所改进的

L

不超过预设

的容差量时

停止，或者是

循环中改变

的 hˆ 不超过某

个值时停止

。

在很多不同

的模型中，迭

代的均值场

不动点方程

是一种能够

提供快速变

分推断

的通

用算法。为了

使它更加具

体，我们详细

地讲一下如

何推导出二

值稀疏编码

模型

的更新

过程。

首先，我

们给出了对

hˆ

i

的导数表达

式。为了得到

这个表达式

，我们将式(19.36) 代

550 第十九章 近

似推断

入到

式 (19.37) 的左边：

∂

∂ˆhi

L(v, θ, hˆ)

(19.38)

=

∂

∂hˆ

i

[ m∑

j=1

[

hˆ

j (log

σ(bj ) − log

hˆ

j ) +

(1 − hˆ

j

)(log σ(−bj ) −

log(1 − hˆ

j

))]

(19.39)

+

1

2

n∑

j=1 [

log βj

2π

−

βj

(

vj

2

− 2vjWj,:hˆ +

∑

k

[

Wj,k

2

hˆ

k +

∑

l=k

Wj,kWj,lhˆ

khˆ

l

])]]

(19.40)

= log

σ(bi) − log hˆ

i − 1 +

log(1 − hˆ

i)

+ 1 − log

σ(−bi) (19.41)

+

n∑

j=1 [

βj

(

vjWj,i −

2

1Wj,i

2 −

∑

k=i

Wj,kWj,ihˆ

k

)] (19.42)

=bi − log ˆhi

+ log(1 − ˆhi)

+ v

⊤βW:,i −

1

2

W⊤

:,iβW:,i

−

∑

j=i

W⊤

:,jβW:,ihˆ

j . (19.43)

为

了应用固定

点更新的推

断规则，我们

通过令式 (19.43) 等

于 0

来解 hˆ

i：

ˆhi

= σ

(

bi

+ v

⊤βW:,i −

2

1W⊤

:,iβW:,i −

∑

j=i

W⊤

:,jβW:,ihˆ

j

)

. (19.44)

此时

，我们可以发

现图模型中

的推断和循

环神经网络

之间存在着

紧密的联系

。

具体地说，均

值场不动点

方程定义了

一个循环神

经网络。这个

神经网络的

任务就是

完

成推断。我们

已经从模型

描述的角度

介绍了如何

推导这个网

络，但是直接

训练这

个推

断网络也是

可行的。有关

这种思路的

一些想法在

第二十章中

有所描述。

在

二值稀疏编

码模型中，我

们可以发现

式 (19.44) 中描述的

循环网络连

接包含

了根

据相邻隐藏

单元变化值

来反复更新

当前隐藏单

元的操作。输

入层通常给

隐藏单

元发

送一个固定

的信息 v

⊤βW，然而

隐藏单元不

断地更新互

相传送的信

息。具体地

说

，当

hˆ

i 和 hˆ

j 两个单

元的权重向

量平行时，它

们会互相抑

制。这也是一

种形式的

竞

争——两个解释

输入的隐藏

单元之间，只

有一个解释

得更好的才

被允许继续

保持

活跃。在

二值稀疏编

码的后验分

布中，均值场

近似试图捕

获到更多的

相消解释相

互

作用，从而

产生了这种

竞争。事实上

，相消解释效

应会产生一

个多峰值的

后验分布，

以

致于如果我

们从后验分

布中采样，一

些样本在一

个单元是活

跃的，其他的

样本在

另一

个单元活跃

，只有很少的

样本能够两

者都处于活

跃状态。不幸

的是，相消解

释作

19.4

变分推

断和变分学

习 551

用无法通

过均值场中

因子分布 q

来

建模，因此建

模时均值场

近似只能选

择一个峰值

。

这个现象的

一个例子可

以参考图 3.6 。

我

们将式 (19.44) 重写

成等价的形

式来揭示一

些深层的含

义：

ˆhi

= σ

(

bi

+

(

v −

∑

j=i

W:,jhˆ

j

)⊤

βW:,i −

1

2

W⊤

:,iβW:,i)

.

(19.45)

在这种新

的形式中，我

们可以将 v −

∑

j=i W:,jhˆ

j

看

作是输入，而

不是 v。因此，我

们可以把第

i 个单元视作

给定其他单

元编码时给

v 中的剩余误

差编码。由此

我们可

以将

稀疏编码视

作是一个迭

代的自编码

器，将输入反

复地编码解

码，试图在每

一轮

迭代后

都能修复重

构中的误差

。

在这个例子

中，我们已经

推导出了每

一次更新单

个结点的更

新规则。如果

能够

同时更

新更多的结

点，那会更令

人满意。某些

图模型，比如

深度玻尔兹

曼机，我们

可

以同时解出

hˆ 中的许多元

素。不幸的是

，二值稀疏编

码并不适用

这种块更新

。取

而代之的

是，我们使用

一种被称为

衰减（damping）的启发

式技巧来实

现块更新。

在

衰减方法中

，对

hˆ 中的每一

个元素我们

都可以解出

最优值，然后

对于所有的

值都

在这个

方向上移动

一小步。这个

方法不能保

证每一步都

能增加 L，但是

对于许多模

型都很有效

。关于在信息

传输算法中

如何选择同

步程度以及

使用衰减策

略可以参考

Koller

and Friedman (2009) 。

19.4.2 变分法

在继

续介绍变分

学习之前，我

们有必要简

单地介绍一

种变分学习

中重要的数

学

工具：

变分

法（calculus of variations）。

许多机器

学习的技巧

是基于寻找

一个输入向

量

θ ∈ R

n

来最小化

函数 J(θ)，

使得它

取到最小值

。这个步骤可

以利用多元

微积分以及

线性代数的

知识找到满

足

∇θJ(θ)

= 0 的临界点

来完成。在某

些情况下，我

们希望能够

解一个函数

f(x)，比如

当我们

希望找到一

些随机变量

的概率密度

函数时。正是

变分法能够

让我们完成

这个

目标。

函

数 f 的函数被

称为

泛函（functional）J[f]。正

如我们许多

情况下对一

个函

数求关

于以向量的

元素为变量

的偏导数一

样，我们可以

使用 泛函导

数（functional

derivative），即在任意

特定的

x 值，对

一个泛函 J[f] 求

关于函数

f(x) 的

导数，这

也被

称为 变分导

数（variational

derivative）。泛函 J 的关

于函数 f

在点

x 处的泛函

552 第

十九章

近似

推断

导数被

记作 δf

δ

(x)

J。

完整正

式的泛函导

数的推导不

在本书的范

围之内。对于

我们的目标

而言，了解

可

微分函数

f(x) 以

及带有连续

导数的可微

分函数 g(y, x)

就足

够了：

δf

δ

(x)

∫

g(f(x), x)dx =

∂y

∂

g(f(x), x).

(19.46)

为了使

上述等式更

加直观，我们

可以把 f(x) 看作

是一个有着

无穷不可数

多元素的向

量，由一个实

数向量

x 表示

。在这里（看作

是一个不完

全的介绍），这

种关系式中

描

述的泛函

导数和向量

θ ∈

R

n 的导数相同

：

∂

∂θi

∑

j

g(θj

, j) = ∂θ

∂

i

g(θi

,

i). (19.47)

在其他机器

学习文献中

的许多结果

则使用了更

为通用的 欧

拉-拉格朗日

方程（Euler￾Lagrange

Equation），它能够

使得 g 不仅依

赖于 f

的值，还

依赖于 f 的导

数。但是

在本

书中我们不

需要这个通

用版本。

为了

关于一个向

量优化某个

函数，我们求

出了这个函

数关于这个

向量的梯度

，

然后找这个

梯度中每一

个元素都为

0 的点。类似地

，我们可以通

过寻找一个

函数使

得泛

函导数的每

个点都等于

0

从而来优化

一个泛函。

下

面介绍一个

该过程如何

运行的例子

，我们考虑寻

找一个定义

在 x ∈

R 上的有

最

大微分熵的

概率密度函

数。我们回过

头来看一下

一个概率分

布 p(x)

的熵，定义

如

下：

H[p] =

−Ex log p(x). (19.48)

对于连

续的值，这个

期望可以被

看作一个积

分：

H[p] = −

∫

p(x)log p(x)dx. (19.49)

我们不能

简单地仅仅

关于函数 p(x) 最

大化 H[p]，因为那

样的话结果

可能不是一

个概率分布

。为了解决这

个问题，我们

需要使用一

个拉格朗日

乘子来添加

一个分布

p(x) 积

分值为 1 的约

束。同样地，当

方差增大时

，熵也会无限

制地增加。因

此，寻

找哪一

个分布有最

大熵这个问

题是没有意

义的。但是，在

给定固定的

方差 σ

2 时，我

们

可以寻找一

个最大熵的

分布。最后，这

个问题还是

欠定的，因为

在不改变熵

的条

件下一

个分布可以

被随意地改

变。为了获得

一个唯一的

解，我们再加

一个约束：分

19.4 变分推断和

变分学习 553

布

的均值必须

为 µ。那么这个

问题的拉格

朗日泛函如

下：

L[p] =

λ1

( ∫

p(x)dx

− 1

)

+

λ2(E[x] − µ) +

λ3(E[(x − µ)

2

] − σ

2

) + H[p] (19.50)

=

∫ (

λ1p(x)

+ λ2p(x)x + λ3p(x)(x

− µ)

2 −

p(x)log p(x)

)

dx

− λ1 − µλ2

− σ

2λ3.

(19.51)

为了关于

p 最小化拉格

朗日乘子，我

们令泛函导

数等于 0：

∀x,

δ

δp(x)

L =

λ1 + λ2x +

λ3(x − µ)

2

− 1 − log

p(x) = 0. (19.52)

这个

条件告诉我

们 p(x) 的泛函形

式。通过代数

运算重组上

述方程，我们

可以得

到

p(x) = exp (

λ1 + λ2x +

λ3(x − µ)

2

− 1

)

.

(19.53)

我

们并没有直

接假设 p(x) 取这

种形式，而是

通过最小化

泛函从理论

上得到了这

个

p(x) 的表达式

。为了解决这

个最小化问

题，我们需要

选择 λ 的值来

确保所有的

约

束都能够

满足。我们有

很大的自由

去选择 λ。因为

只要满足约

束，拉格朗日

关于 λ 这

个变

量的梯度就

为 0。为了满足

所有的约束

，我们可以令

λ1 = 1

− log σ

√

2π,λ2 = 0,

λ3

= −

1

2σ2，从而得到

p(x) = N (x;

µ, σ2

). (19.54)

这

也是当我们

不知道真实

的分布时总

是使用正态

分布的一个

原因。因为正

态分布拥

有

最大的熵，我

们通过这个

假定来保证

了最小可能

量的结构。

当

寻找熵的拉

格朗日泛函

的临界点并

且给定一个

固定的方差

时，我们只能

找到

一个对

应最大熵的

临界点。那最

小化熵的概

率密度函数

是什么样的

呢？为什么我

们

无法发现

对应着极小

点的第二个

临界点呢？原

因是没有一

个特定的函

数能够达到

最

小的熵值

。当函数把越

多的概率密

度加到 x =

µ + σ 和

x = µ −

σ 两

个点上，越少

的

概率密度

到其他点上

时，它们的熵

值会减少，而

方差却不变

。然而任何把

所有的权

重

都放在这两

点的函数的

积分都不为

1，不是一个有

效的概率分

布。所以不存

在一

个最小

熵的概率密

度函数，就像

不存在一个

最小的正实

数一样。然而

，我们发现存

在一个收敛

的概率分布

的序列，收敛

到权重都在

两个点上。这

种情况能够

退化为混

合

Dirac 分布。因为 Dirac

分

布并不是一

个单独的概

率密度函数

，所以 Dirac 分布或

554 第十九章

近

似推断

者混

合 Dirac 分布并不

能对应函数

空间的一个

点。所以对我

们来说，当寻

找一个泛

函

导数为 0 的函

数空间的点

时，这些分布

是不可见的

。这就是这种

方法的局限

之处。

诸如

Dirac 分

布这样的分

布可以通过

其他方法被

找到，比如可

以先猜测一

个解，然后

证

明它是满足

条件的。

19.4.3

连续

型潜变量

当

我们的图模

型包含连续

型潜变量时

，我们仍然可

以通过最大

化 L 进行变分

推

断和变分

学习。然而，我

们需要使用

变分法来实

现关于 q(h | v)

最大

化 L。

在大多数

情况下，研究

者并不需要

解决任何变

分法的问题

。取而代之的

是，均

值场固

定点迭代更

新有一个通

用的方程。如

果我们做了

均值场近似

：

q(h | v) =

∏

i

q(hi

|

v), (19.55)

并且对任何

的 j

= i 固定 q(hj

| v)，那么

只需要满足

分布 p 中任何

联合分布变

量的

概率值

不为 0，我们就

可以通过归

一化下面这

个未归一的

分布

˜q(hi

|

v) = exp (

Eh−i∼q(h−i|v)

log p˜(v, h)

)

(19.56)

来得到

最优的 q(hi

| v)。在这

个方程中计

算期望就能

得到正确的

q(hi

| v)

的表达式。

我

们只有在希

望提出一种

新形式的变

分学习算法

时才需要使

用变分法来

直接推导 q

的

函数形式。式

(19.56)

给出了适用

于任何概率

模型的均值

场近似。

式 (19.56) 是

一个不动点

方程，对每一

个

i 它都被迭

代地反复使

用直到收敛

。然

而，它还包

含着更多的

信息。它还包

含了最优解

取到的泛函

形式，无论我

们是否能

够

通过不动点

方程来解出

它。这意味着

我们可以利

用方程中的

泛函形式，把

其中一

些值

当成参数，然

后通过任何

我们想用的

优化算法来

解决这个问

题。

我们拿一

个简单的概

率模型作为

例子，其中潜

变量满足 h ∈

R

2，可

见变量只有

一个 v。假设 p(h)

= N (h; 0,

I) 以

及 p(v |

h) = N (v;

w⊤h; 1)，我们可以

积掉 h 来简

化

这个模型，结

果是关于 v 的

高斯分布。这

个模型本身

并不有趣。只

是为了说明

变

分法如何

应用在概率

建模之中，我

们才构造了

这个模型。

19.4 变

分推断和变

分学习 555

忽略

归一化常数

时，真实的后

验分布如下

：

p(h | v) (19.57)

∝p(h, v) (19.58)

=p(h1)p(h2)p(v

| h) (19.59)

∝

exp (

−

1

2

[h

2

1

+ h

2

2

+ (v − h1w1

− h2w2)

2

]

)

(19.60)

= exp

(

−

1

2

[h

2

1 +

h

2

2 +

v

2 + h

2

1w1

2 +

h

2

2w2

2

− 2vh1w1 − 2vh2w2

+ 2h1w1h2w2]

)

.

(19.61)

在上式中，我

们发现由于

带有 h1, h2

乘积项

的存在，真实

的后验并不

能关于 h1, h2

分解

。

应用式 (19.56) ，我们

可以得到

q˜(h1

| v) (19.62)

=

exp (

Eh2∼q(h2|v)

log

p˜(v, h)

)

(19.63)

= exp (

−

2

1

Eh2∼q(h2|v)

[h

2

1 + h

2

2 + v

2 + h

2

1w1

2 + h

2

2w2

2

(19.64)

− 2vh1w1 − 2vh2w2

+ 2h1w1h2w2]

)

.

(19.65)

从

这里，我们可

以发现其中

我们只需要

从 q(h2 |

v) 中获得两

个有效值：Eh2∼q(h|v)

[h2]

和

Eh2∼q(h|v)

[h

2

2

]。把这两项记

作

⟨h2⟩ 和 ⟨h

2

2

⟩，我们可

以得到：

˜q(h1 |

v) = exp(−

1

2

[h

2

1

+ ⟨h

2

2

⟩ + v

2

+ h

2

1w1

2 + ⟨h

2

2

⟩w2

2

(19.66)

− 2vh1w1 − 2v⟨h2⟩w2

+ 2h1w1⟨h2⟩w2]). (19.67)

从这

里，我们可以

发现

q˜ 的泛函

形式满足高

斯分布。因此

，我们可以得

到

q(h |

v) = N (h;

µ, β

−1

)，其中

µ 和对

角的 β 是变分

参数，我们可

以使用任何

方法

来优化

它。有必要再

强调一下，我

们并没有假

设 q 是一个高

斯分布，这个

高斯的形

式

是使用变分

法来关于分

布

q 最大化 L 而

推导出来的

。在不同的模

型上应用相

同的

方法可

能会得到不

同泛函形式

的分布 q。

当然

，上述模型只

是为了说明

情况的一个

简单例子。深

度学习中关

于变分学习

中连续型变

量的实际应

用可以参考

Goodfellow et

al. (2013f)。

556 第十九章

近

似推断

19.4.4 学习

和推断之间

的相互作用

在学习算法

中使用近似

推断会影响

学习的过程

，反过来学习

的过程也会

影响推

断算

法的准确性

。

具体来说，训

练算法倾向

于朝使得近

似推断算法

中的近似假

设变得更加

真实的

方向

来适应模型

。当训练参数

时，变分学习

增加

Eh∼q log

p(v, h). (19.68)

对于一

个特定的

v，对

于 q(h | v)

中概率很

大的 h 它增加

了 p(h

| v)；对于 q(h |

v)

中概

率很小的 h 它

减小了

p(h | v)。

这种

行为使得我

们做的近似

假设变得合

理。如果我们

用单峰值近

似后验来训

练

模型，那么

所得具有真

实后验的模

型会比我们

使用精确推

断训练模型

获得的模型

更

接近单峰

值。

因此，估计

变分近似对

模型的破坏

程度是很困

难的。存在几

种估计 log

p(v) 的方

式。通常我们

在训练模型

之后估计 log p(v;

θ)，然

后发现它和

L(v, θ, q) 的差距是很

小的。从这里

我们可以得

出结论，对于

特定的从学

习过程中获

得的

θ 来说，变

分近似

是很

准确的。然而

我们无法直

接得到变分

近似普遍很

准确或者变

分近似几乎

不会对

学习

过程产生任

何负面影响

这样的结论

。为了准确衡

量变分近似

带来的危害

，我们

需要知

道 θ

∗ =

maxθ log p(v; θ)。L(v,

θ, q) ≈ log

p(v; θ) 和 log

p(v; θ) ≪ log

p(v; θ

∗

)

同时成

立是有可能

的。如果存在

maxq L(v, θ

∗

, q) ≪ log

p(v; θ

∗

)，即在

θ

∗ 点处后

验

分布太过

复杂使得

q 分

布族无法准

确描述，那么

学习过程永

远无法到达

θ

∗。这样的

一类

问题是很难

发现的，因为

只有在我们

有一个能够

找到

θ

∗ 的较好

的学习算法

时，

才能确定

地进行上述

的比较。

19.5 学成

近似推断

我

们已经看到

了推断可以

被视作一个

增加函数 L

值

的优化过程

。显式地通

过

迭代方法（比

如不动点方

程或者基于

梯度的优化

算法）来进行

优化的过程

通常

是代价

很高且耗时

巨大的。通过

学习一个近

似推断，许多

推断算法避

免了这种

代

价。具体地说

，我们可以将

优化过程视

作将一个输

入

v 投影到一

个近似分布

q

∗ =

arg maxq L(v, q)

的一个 f 的函

数。一旦我们

将多步的迭

代优化过程

看作是一

个

函数，我们可

以用一个近

似函数为

f

ˆ(v; θ) 的

神经网络来

近似它。

19.5 学成

近似推断 557

19.5.1

醒

眠算法

训练

一个可以用

v 来推断 h

的模

型的一个主

要难点在于

我们没有一

个监督训

练

集来训练模

型。给定一个

v，我们无法获

知一个合适

的 h。从 v

到 h 的映

射依赖

于模

型族的选择

，并且在学习

过程中随着

θ

的改变而变

化。 醒眠（wake sleep）算

法

(Hinton

et al., 1995b; Frey

et al., 1996) 通过从模型

分布中抽取

v

和 h 的样本来

解决这个问

题。例如，在有

向模型中，这

可以通过执

行从 h

开始并

在 v 结束的原

始

采样来高

效地完成。然

后这个推断

网络可以被

训练来执行

反向的映射

：预测哪一个

h

产生了当前

的 v。这种方法

的主要缺点

是我们将只

能在那些在

当前模型上

有较高概

率

的 v

值上训练

推断网络。在

学习早期，模

型分布与数

据分布偏差

较大，因此推

断

网络将不

具有在类似

数据的样本

上学习的机

会。

在第 18.2

节中

，我们看到睡

眠做梦在人

类和动物中

作用的一个

可能解释是

，做

梦可以提

供蒙特卡罗

训练算法用

于近似无向

模型中对数

配分函数负

梯度的负相

样本。

生物做

梦的另一个

可能解释是

它提供来自

p(h, v)

的样本，这可

以用于训练

推断网络

在

给定 v 的情况

下预测

h。在某

些意义上，这

种解释比配

分函数的解

释更令人满

意。

如果蒙特

卡罗算法仅

使用梯度的

正相运行几

个步骤，然后

仅对梯度的

负相运行几

个

步骤，那么

结果通常不

会很好。人类

和动物通常

连续清醒几

个小时，然后

连续睡着

几

个小时。这个

时间表如何

支持无向模

型的蒙特卡

罗训练尚不

清楚。然而，基

于最

大化 L 的

学习算法可

以通过长时

间调整改进

q 和长期调整

θ

来实现。如果

生物做梦

的

作用是训练

网络来预测

q，那么这解释

了动物如何

能够保持清

醒几个小时

（它们

清醒的

时间越长，L 和

log

p(v) 之间的差距

越大，但是 L 仍

然是下限）并

且睡眠几

个

小时（生成模

型本身在睡

眠期间不被

修改），而不损

害它们的内

部模型。当然

，这

些想法纯

粹是猜测性

的，没有任何

确定的证据

表明做梦实

现了这些目

标之一。做梦

也可以通过

从动物的过

渡模型（用来

训练动物策

略）采样合成

经验来服务

于强化学

习

而不是概率

建模。也许睡

眠可以服务

于一些机器

学习社区尚

未发现的其

他目的。

19.5.2

学成

推断的其他

形式

这 种学

成近 似

推 断

策 略 已

经 被

应 用 到

了 其

他 模 型

中。Salakhutdinov and

Larochelle (2010)

证

明了在学成

推断网络中

的单遍传递

相比于在深

度玻尔兹曼

机中

的迭代

均值场不动

点方程能够

得到更快的

推断。其训练

过程是基于

运行推断网

络的，

然后运

行一步均值

场来改进其

估计，并训练

推断网络来

输出这个更

精细的估计

以代

替其原

始估计。

558 第十

九章 近似推

断

我们已经

在第

14.8 节中看

到，预测性的

稀疏分解模

型训练一个

浅层编码器

网络，

从而预

测输入的稀

疏编码。这可

以被看作是

自编码器和

稀疏编码之

间的混合。为

模型

设计概

率语义是可

能的，其中编

码器可以被

视为执行学

成近似

MAP 推断

。由于其浅

层

的编码器，PSD 不

能实现我们

在均值场推

断中看到的

单元之间的

那种竞争。然

而，

该问题可

以通过训练

深度编码器

实现学成近

似推断来补

救，如 ISTA 技术 (Gregor

and LeCun, 2010b)。

近

来学成近似

推断已经成

为了变分自

编码器形式

的生成模型

中的主要方

法之一

(Kingma, 2013; Rezende et

al., 2014)。在这

种优美的方

法中，不需要

为推断网络

构

造显式的

目标。反之，推

断网络仅仅

被用来定义

L，然后调整推

断网络的参

数来增

大

L。我

们将在第 20.10.3 节

中详细介绍

这种模型。

我

们可以使用

近似推断来

训练和使用

很多不同的

模型。其中许

多模型将在

下一

章中描

述。

第二十章

深度生成模

型

在本章中

，我们介绍几

种具体的生

成模型，这些

模型可以使

用第十六章

至第十

九章

中出现的技

术构建和训

练。所有这些

模型在某种

程度上都代

表了多个变

量的概

率分

布。有些模型

允许显式地

计算概率分

布函数。其他

模型则不允

许直接评估

概率

分布函

数，但支持隐

式获取分布

知识的操作

，如从分布中

采样。这些模

型中的一部

分使用第十

六章中的图

模型语言，从

图和因子的

角度描述为

结构化概率

模型。其他

的

不能简单地

从因子角度

描述，但仍然

代表概率分

布。

20.1

玻尔兹曼

机

玻尔兹曼

机最初作为

一种广义的

“联结主义’’ 引

入，用来学习

二值向量上

的任意

概率

分布

(Fahlman et al., 1983;

Ackley et al., 1985;

Hinton et al., 1984b;

Hinton and

Sejnowski, 1986)。玻尔兹

曼机的变体

（包含其他类

型的变量）早

已超过了原

始玻尔

兹曼

机的流行程

度。在本节中

，我们简要介

绍二值玻尔

兹曼机并讨

论训练模型

和进

行推断

时出现的问

题。

我们在 d

维

二值随机向

量 x ∈ {0,

1}

d 上定义玻

尔兹曼机。玻

尔兹曼机是

一种基

于能

量的模型（第

16.2.4

节），意味着我

们可以使用

能量函数定

义联合概率

分布：

P(x) = exp(−E(x))

Z

, (20.1)

其中

E(x) 是

能量函数，Z 是

确保 ∑

x P(x) = 1

的配分

函数。玻尔兹

曼机的能量

函

数如下给

出：

E(x) =

−x

⊤Ux − b

⊤

x, (20.2)

其中

U 是模

型参数的 ‘‘权

重’’ 矩阵，b

是偏

置向量。

559

560 第二

十章

深度生

成模型

在一

般设定下，给

定一组训练

样本，每个样

本都是 n 维的

。式

(20.1) 描述了观

察到的变量

的联合概率

分布。虽然这

种情况显然

可行，但它限

制了观察到

的变量和

权

重矩阵描述

的变量之间

相互作用的

类型。具体来

说，这意味着

一个单元的

概率由

其他

单元值的线

性模型（逻辑

回归）给出。

当

不是所有变

量都能被观

察到时，玻尔

兹曼机变得

更强大。在这

种情况下，潜

变

量类似于

多层感知机

中的隐藏单

元，并模拟可

见单元之间

的高阶交互

。正如添加隐

藏单元将逻

辑回归转换

为 MLP，导致 MLP

成为

函数的万能

近似器，具有

隐藏单

元的

玻尔兹曼机

不再局限于

建模变量之

间的线性关

系。相反，玻尔

兹曼机变成

了离

散变量

上概率质量

函数的万能

近似器 (Le

Roux and Bengio, 2008)。

正式

地，我们将单

元 x 分解为两

个子集：可见

单元 v

和潜在

（或隐藏）单元

h。

能量函数变

为

E(v, h)

= −v

⊤Rv −

v

⊤Wh − h

⊤Sh − b

⊤

v − c

⊤h.

(20.3)

玻尔兹曼

机的学习 玻

尔兹曼机的

学习算法通

常基于最大

似然。所有玻

尔兹曼机都

具有难以处

理的配分函

数，因此最大

似然梯度必

须使用第十

八章中的技

术来近似。

玻

尔兹曼机有

一个有趣的

性质，当基于

最大似然的

学习规则训

练时，连接两

个单

元的特

定权重的更

新仅取决于

这两个单元

在不同分布

下收集的统

计信息：Pmodel(v)

和 Pˆ

data(v)Pmodel(h

| v)。网

络的其余部

分参与塑造

这些统计信

息，但权重可

以在完

全不

知道网络其

余部分或这

些统计信息

如何产生的

情况下更新

。这意味着学

习规则

是

‘‘局

部’’ 的，这使得

玻尔兹曼机

的学习似乎

在某种程度

上是生物学

合理的。我们

可以设想每

个神经元都

是玻尔兹曼

机中随机变

量的情况，那

么连接两个

随机变量的

轴突和树突

只能通过观

察与它们物

理上实际接

触细胞的激

发模式来学

习。特别地，

正

相期间，经常

同时激活的

两个单元之

间的连接会

被加强。这是

Hebbian 学习规则

(Hebb, 1949) 的

一个例子，经

常总结为好

记的短语——“fire together,

wire together’’。

Hebbian 学

习规则是生

物系统学习

中最古老的

假设性解释

之一，直至今

天仍然有重

大意义

(Giudice et al., 2009)。

不仅

仅使用局部

统计信息的

其他学习算

法似乎需要

假设更多的

学习机制。例

如，

对于大脑

在多层感知

机中实现的

反向传播，似

乎需要维持

一个辅助通

信的网络，并

借此向后传

输梯度信息

。已经有学者

(Hinton, 2007a; Bengio,

2015) 提出生物学

上可

行（和近

似）的反向传

播实现方案

，但仍然有待

验证，Bengio (2015)

还将梯

度的反

向传

播关联到类

似于玻尔兹

曼机（但具有

连续潜变量

）的能量模型

中的推断。

20.2 受

限玻尔兹曼

机

561

从生物学

的角度看，玻

尔兹曼机学

习中的负相

阶段有点难

以解释。正如

第18.2 节

所主张

的，人类在睡

眠时做梦可

能是一种形

式的负相采

样。尽管这个

想法更多的

只

是猜测。

20.2 受

限玻尔兹曼

机

受限玻尔

兹曼机以

簧

风琴（harmonium）之名 (Smolensky, 1986) 面

世之后，成

为

了深度概率

模型中最常

见的组件之

一。我们之前

在第 16.7.1 节简要

介绍了 RBM。

在这

里我们回顾

以前的内容

并探讨更多

的细节。RBM 是包

含一层可观

察变量和单

层潜变量的

无向概率图

模型。RBM 可以堆

叠起来（一个

在另一个的

顶部）形成更

深

的模型。图

20.1

展示了一些

例子。特别地

，图20.1 a 显示 RBM

本身

的图结构。它

是

一个二分

图，观察层或

潜层中的任

何单元之间

不允许存在

连接。

我们从

二值版本的

受限玻尔兹

曼机开始，但

如我们之后

所见，这还可

以扩展为

其

他类型的可

见和隐藏单

元。

更正式地

说，令观察层

由一组 nv 个二

值随机变量

组成，我们统

称为向量 v。我

们将

nh 个二值

随机变量的

潜在或隐藏

层记为 h。

就像

普通的玻尔

兹曼机，受限

玻尔兹曼机

也是基于能

量的模型，其

联合概率分

布由能量函

数指定：

P(v = v, h

= h) = 1

Z

exp(−E(v, h)). (20.4)

RBM 的能

量函数由下

给出

E(v, h)

= −b

⊤

v

− c

⊤h −

v

⊤Wh, (20.5)

其中

Z 是

被称为配分

函数的归一

化常数：

Z =

∑

v

∑

h

exp{−E(v, h)} (20.6)

从配

分函数

Z 的定

义显而易见

，计算 Z 的朴素

方法（对所有

状态进行穷

举求和）计

算

上可能是难

以处理的，除

非有巧妙设

计的算法可

以利用概率

分布中的规

则来更快

地

计算 Z。在受限

玻尔兹曼机

的情况下，Long and

Servedio (2010) 正

式证明配分

函

数

Z 是难解

的。难解的配

分函数 Z 意味

着归一化联

合概率分布

P(v)

也难以评估

。

562 第二十章 深

度生成模型

hh11

hh22 hh33

vv11 vv22

vv33

hh44 hh(1)

1

(1)

1 hh(1)

2

(1)

2 hh(1)

3

(1)

3

vv11 vv22

vv33

hh(2)

1

(2)

1 hh(2)

2

(2)

2 hh(2)

3

(2)

3

hh(1)

4

(1)

4

(a) (b)

hh(1)

1

(1)

1 hh(1)

2

(1)

2 hh(1)

3

(1)

3

vv11

vv22 vv33

hh(2)

1

(2)

1 hh(2)

2

(2)

2 hh(2)

3

(2)

3

hh(1)

4

(1)

4

(c)

图

20.1: 可以用受

限玻尔兹曼

机构建的模

型示例。(a)受限

玻尔兹曼机

本身是基于

二分图的无

向图

模型，在

图的一部分

具有可见单

元，另一部分

具有隐藏单

元。可见单元

之间没有连

接，隐藏单元

之

间也没有

任何连接。通

常每个可见

单元连接到

每个隐藏单

元，但也可以

构造稀疏连

接的

RBM，如

卷积

RBM。(b)深度信念网

络是涉及有

向和无向连

接的混合图

模型。与 RBM 一样

，它也没有层

内

连接。然而

，DBN 具有多个隐

藏层，因此隐

藏单元之间

的连接在分

开的层中。深

度信念网络

所需

的所有

局部条件概

率分布都直

接复制 RBM

的局

部条件概率

分布。或者，我

们也可以用

完全无向

图

表示深度信

念网络，但是

它需要层内

连接来捕获

父节点间的

依赖关系。(c)深

度玻尔兹曼

机是具

有几

层潜变量的

无向图模型

。与 RBM

和 DBN 一样，DBM 也

缺少层内连

接。DBM

与 RBM 的

联系

不如

DBN 紧密。当

从 RBM 堆栈初始

化

DBM 时，有必要

对 RBM 的参数稍

作修改。某些

种类的

DBM 可以

直接训练，而

不用先训练

一组 RBM。

20.2.1

条件分

布

虽然 P(v) 难解

，但

RBM 的二分图

结构具有非

常特殊的性

质，其条件分

布

P(h |

v) 和 P(v |

h) 是因子

的，并且计算

和采样是相

对简单的。

20.2 受

限玻尔兹曼

机

563

从联合分

布中导出条

件分布是直

观的：

P(h |

v) = P(h, v)

P(v)

(20.7)

=

1

P(v)

1

Z

exp

{

b

⊤

v

+ c

⊤h +

v

⊤Wh}

(20.8)

=

1

Z′

exp {

c

⊤h + v

⊤Wh}

(20.9)

=

1

Z′

exp { nh

∑

j=1

c

⊤

j hj +

j=1

∑

nh

v

⊤W:,jhj

}

(20.10)

=

Z

1

′

nh ∏

j=1

exp {

c

⊤

j hj +

v

⊤W:,jhj

}

.

(20.11)

由于我

们相对可见

单元 v 计算条

件概率，相对

于分布

P(h | v) 我们

可以将它们

视为

常数。条

件分布 P(h | v)

因子

相乘的本质

，我们可以将

向量 h 上的联

合概率写成

单

独元素

hj 上

（未归一化）分

布的乘积。现

在原问题变

成了对单个

二值 hj 上的分

布

进行归一

化的简单问

题。

P(hj = 1

| v) = P˜(hj

= 1 | v)

P˜(hj = 0 |

v) + P˜(hj =

1 | v)

(20.12)

=

exp{cj + v

⊤W:,j}

exp{0} + exp{cj

+ v⊤W:,j}

(20.13)

=

σ(cj + v

⊤W:,j

). (20.14)

现在我们

可以将关于

隐藏层的完

全条件分布

表达为因子

形式：

P(h

| v) =

nh

∏

j=1

σ

(

(2h − 1) ⊙

(c + W⊤

v)

)

j

. (20.15)

类似的

推导将显示

我们感兴趣

的另一条件

分布，P(v | h) 也是因

子形式的分

布：

P(v | h) =

nv ∏

i=1

σ

(

(2v − 1)

⊙ (b + Wh)

)

i

. (20.16)

20.2.2 训练受限

玻尔兹曼机

因为 RBM 允许高

效计算

P˜(v) 的估

计和微分，并

且还允许高

效地（以块吉

布

斯采样的

形式）进行MCMC 采

样，所以我们

很容易使用

第十八章中

训练具有难

以计

564 第二十

章 深度生成

模型

算配分

函数的模型

的技术来训

练

RBM。这包括 CD、 SML（PCD）、比

率匹配等。

与

深度学习中

使用的其他

无向模型相

比，RBM

可以相对

直接地训练

，因为我们可

以

以闭解形

式计算 P(h |

v)。其他

一些深度模

型，如深度玻

尔兹曼机，同

时具备难处

理

的配分函

数和难以推

断的难题。

20.3 深

度信念网络

深度信念网

络（deep

belief network, DBN）是第一批

成功应用深

度架构训练

的

非卷积模

型之一

(Hinton et al., 2006a;

Hinton, 2007b)。2006 年深

度信念网络

的引入

开始

了当前深度

学习的复兴

。在引入深度

信念网络之

前，深度模型

被认为太难

以优

化。具有

凸目标函数

的核机器引

领了研究前

沿。深度信念

网络在 MNIST 数据

集上表

现超

过内核化支

持向量机，以

此证明深度

架构是能够

成功的

(Hinton et al., 2006a)。

尽管

现在与其他

无监督或生

成学习算法

相比，深度信

念网络大多

已经失去了

青睐并

很少

使用，但它们

在深度学习

历史中的重

要作用仍应

该得到承认

。

深度信念网

络是具有若

干潜变量层

的生成模型

。潜变量通常

是二值的，而

可见

单元可

以是二值或

实数。尽管构

造连接比较

稀疏的

DBN 是可

能的，但在一

般的模型

中

，每层的每个

单元连接到

每个相邻层

中的每个单

元（没有层内

连接）。顶部两

层之

间的连

接是无向的

。而所有其他

层之间的连

接是有向的

，箭头指向最

接近数据的

层。

见图 20.1 b 的例

子。

具有 l 个隐

藏层的 DBN

包含

l 个权重矩阵

：W(1)

, .

. . ,W(l)。同时也包含

l +

1

个偏置向量

：b

(0)

,

. . . ,

b

(l)，其中 b

(0)

是可见

层的偏置。DBN 表

示的概率分

布由下式

给

出：

P(h

(l)

, h

(l−1))

∝ exp (

b

(l)

⊤

h

(l)

+ b

(l−1)⊤

h

(l−1) + h

(l−1)⊤W(l)

h

(l)

)

,

(20.17)

P(h

(

i

k) = 1 |

h

(k+1)) = σ

(

b

(

i

k) + W(

:,i

k+1)⊤

h

(k+1))

∀i,

∀k ∈ 1, .

. . , l

− 2, (20.18)

P(vi

= 1 | h

(1)) = σ

(

b

(0)

i +

W(1)

:,i

⊤

h

(1))

∀i. (20.19)

在实值可

见单元的情

况下，替换

v ∼ N (

v; b

(0) +

W(1)⊤

h

(1)

,

β

−1

)

(20.20)

为

便于处理，β 为

对角形式。至

少在理论上

，推广到其他

指数族的可

见单元是直

观

的。只有一

个隐藏层的

DBN 只是一个

RBM。

20.3 深

度信念网络

565

为了从

DBN 中生

成样本，我们

先在顶部的

两个隐藏层

上运行几个

Gibbs 采

样步骤。这

个阶段主要

从

RBM（由顶部两

个隐藏层定

义）中采一个

样本。然后，我

们可以对模

型的其余部

分使用单次

原始采样，以

从可见单元

绘制样本。

深

度信念网络

引发许多与

有向模型和

无向模型同

时相关的问

题。

由于每个

有向层内的

相消解释效

应，并且由于

无向连接的

两个隐藏层

之间的相

互

作用，深度信

念网络中的

推断是难解

的。评估或最

大化对数似

然的标准证

据下界也

是

难以处理的

，因为证据下

界基于大小

等于网络宽

度的团的期

望。

评估或最

大化对数似

然，不仅需要

面对边缘化

潜变量时难

以处理的推

断问题，而

且

还需要处理

顶部两层无

向模型内难

处理的配分

函数问题。

为

训练深度信

念网络，我们

可以先使用

对比散度或

随机最大似

然方法训

练

RBM 以最大化 Ev∼pdata log

p(v)。 RBM 的

参数定义了

DBN 第一层的参

数。

然后，第二

个 RBM 训练为近

似最大化

Ev∼pdata

Eh(1)∼p(1)(h

(1)|v)

log p

(2)(h

(1)), (20.21)

其

中

p

(1) 是第一个

RBM 表示的概率

分布，p

(2) 是第二

个 RBM 表示的概

率分布。

换句

话说，第二个

RBM 被训练为模

拟由第一个

RBM 的隐藏单元

采样定义的

分布，

而第一

个

RBM 由数据驱

动。这个过程

能无限重复

，从而向 DBN 添加

任意多层，其

中每个新的

RBM

对前一个 RBM 的

样本建模。每

个 RBM

定义 DBN 的另

一层。这

个过

程可以被视

为提高数据

在

DBN 下似然概

率的变分下

界 (Hinton et

al., 2006a)。

在大多数

应用中，对 DBN

进

行贪心逐层

训练后，不需

要再花功夫

对其进行联

合

训练。然而

，使用醒眠算

法对其进行

生成精调是

可能的。

训练

好的 DBN

可以直

接用作生成

模型，但是 DBN 的

大多数兴趣

来自于它们

改

进分类模

型的能力。我

们可以从

DBN 获

取权重，并使

用它们定义

MLP：

h

(1)

= σ

(

b

(1) + v

⊤W(1))

, (20.22)

h

(l)

= σ

(

b

(

i

l) +

h

(l−1)⊤W(l)

)

∀l

∈ 2, . .

. , m. (20.23)

利用 DBN 的生成

训练后获得

的权重和偏

置初始化该

MLP 之后，我们可

以训练

该 MLP 来

执行分类任

务。这种 MLP

的额

外训练是判

别性精调的

示例。

与第十

九章中从基

本原理导出

的许多推断

方程相比，这

种特定选择

的 MLP 有

些随意

。这个 MLP 是一个

启发式选择

，似乎在实践

中效果不错

，并在文献中

一贯使

用。许

多近似推断

技术是由它

们在一些约

束下，并在对

数似然上找

到最大紧变

分下

566 第二十

章 深度生成

模型

界的能

力所驱动的

。我们可以使

用

DBN 中 MLP 定义的

隐藏单元的

期望，构造对

数

似然的变

分下界，但这

对于隐藏单

元上的任何

概率分布都

是如此，并没

有理由相信

该 MLP 提供了一

个特别的紧

界。特别地，MLP 忽

略了

DBN 图模型

中许多重要

的

相互作用

。MLP 将信息从可

见单元向上

传播到最深

的隐藏单元

，但不向下或

侧向传

播任

何信息。DBN 图模

型解释了同

一层内所有

隐藏单元之

间的相互作

用以及层之

间

的自顶向

下的相互作

用。

虽然

DBN 的对

数似然是难

处理的，但它

可以使用 AIS 近

似

(Salakhutdinov and

Murray, 2008)。通过近似

，可以评估其

作为生成模

型的质量。

术

语 “深度信念

网络’’ 通常不

正确地用于

指代任意种

类的深度神

经网络，甚至

没

有潜变量

意义的网络

。这个术语应

特指最深层

中具有无向

连接，而在所

有其他连续

层之间存在

向下有向连

接的模型。

这

个术语也可

能导致一些

混乱，因为术

语 ‘‘信念网络

’’ 有时指纯粹

的有向模

型

，而深度信念

网络包含一

个无向层。深

度信念网络

也与动态贝

叶斯网络（dynamic

Bayesian networks）(Dean and Kanazawa,

1989) 共

享首字母缩

写 DBN，动态贝叶

斯网络表示

马尔可夫链

的贝叶斯网

络。

20.4

深度玻尔

兹曼机

深度

玻尔兹曼机

（Deep Boltzmann Machine,

DBM）(Salakhutdinov and Hin￾ton, 2009a)

是另一种深

度生成模型

。与深度信念

网络（DBN）不同的

是，它是一

个

完全无向的

模型。与 RBM 不同

的是，DBM

有几层

潜变量（RBM 只有

一层）。

但是像

RBM 一样，每一层

内的每个变

量是相互独

立的，并条件

于相邻层中

的变

量。见图

20.2 中的图结构

。深度玻尔兹

曼机已经被

应用于各种

任务，包括文

档建模

(Srivastava et

al., 2013)。

与 RBM

和

DBN 一样，DBM 通常仅

包含二值单

元（正如我们

为简化模型

的演

示而假

设的），但很容

易就能扩展

到实值可见

单元。

DBM 是基于

能量的模型

，这意味着模

型变量的联

合概率分布

由能量函数

E 参

数化。在一

个深度玻尔

兹曼机包含

一个可见层

v

和三个隐藏

层 h

(1)

,

h

(2) 和 h

(3) 的情

况

下，联合概率

由下式给出

：

P(v,

h

(1)

, h

(2)

, h

(3))

= 1

Z(θ)

exp

(

− E(v, h

(1)

, h

(2)

, h

(3)

;

θ)

)

. (20.24)

20.4 深度玻尔兹

曼机 567

hh(1)

1

(1)

1 hh(1)

2

(1)

2 hh(1)

3

(1)

3

vv11

vv22 vv33

hh(2)

1

(2)

1 hh(2)

2

(2)

2 hh(2)

3

(2)

3

hh(1)

4

(1)

4

图 20.2:

具有

一个可见层

（底部）和两个

隐藏层的深

度玻尔兹曼

机的图模型

。仅在相邻层

的单元之

间

存在连接。没

有层内连接

。

为简化表示

，下式省略了

偏置参数。DBM 能

量函数定义

如下：

E(v, h

(1)

,

h

(2)

, h

(3)

; θ) =

−v

⊤W(1)h

(1) −

h

(1)⊤W(2)h

(2) −

h

(2)⊤W(3)h

(3)

.

(20.25)

与 RBM 的能

量函数（式

(20.5) ）相

比，DBM 能量函数

以权重矩阵

（W(2) 和

W(3)）的形式表

示隐藏单元

（潜变量）之间

的连接。正如

我们将看到

的，这些连接

对模型行为

以及我们如

何在模型中

进行推断都

有重要的影

响。

hh(1)

1

(1)

1 hh(1)

2

(1)

2 hh(1)

3

(1)

3

vv11 vv22

hh(2)

1

(2)

1 hh(2)

2

(2)

2 hh(2)

3

(2)

3

hh(3)

1

(3)

1 hh(3)

2

(3)

2

v1

v2

hh(2)

1

(2)

1

hh(2)

2

(2)

2

hh(2)

3

(2)

3

hh(1)

1

(1)

1

hh(1)

2

(1)

2

hh(1)

3

(1)

3

hh(3)

1

(3)

1

hh(3)

2

(3)

2

图 20.3: 深度玻

尔兹曼机，重

新排列后显

示为二分图

结构。

与全连

接的玻尔兹

曼机（每个单

元连接到其

他每个单元

）相比，DBM 提供了

类

568 第二十章

深度生成模

型

似于 RBM 的一

些优点。

具体

来说，如图20.3

所

示，DBM 的层可以

组织成一个

二分图，其中

奇数层在一

侧，偶数层在

另一侧。容易

发现，当我们

条件于偶数

层中的变量

时，奇数层中

的变

量变得

条件独立。当

然，当我们条

件于奇数层

中的变量时

，偶数层中的

变量也会变

得条件独立

。

DBM

的二分图结

构意味着我

们可以应用

之前用于 RBM 条

件分布的相

同式子

来确

定

DBM 中的条件

分布。在给定

相邻层值的

情况下，层内

的单元彼此

条件独立，

因

此二值变量

的分布可以

由 Bernoulli

参数（描述

每个单元的

激活概率）完

全描述。

在具

有两个隐藏

层的示例中

，激活概率由

下式给出：

P(vi =

1 | h

(1))

= σ

(W(1)

i,:

h

(1))

, (20.26)

P(h

(1)

i =

1 | v, h

(2)) = σ

(

v

⊤W(1)

:,i +

W(2)

i,: h

(2))

, (20.27)

和

P(h

(2)

k = 1 |

h

(1)) = σ

(

h

(1)⊤W(2)

:,k

)

. (20.28)

二分图结构

使

Gibbs 采样能在

深度玻尔兹

曼机中高效

采样。Gibbs 采样的

方法

是一次

只更新一个

变量。RBM

允许所

有可见单元

以一个块的

方式更新，而

所有隐藏

单

元在另一个

块上更新。我

们可以简单

地假设具有

l 层的 DBM

需要 l + 1

次

更新，

每次迭

代更新由某

层单元组成

的块。然而，我

们可以仅在

两次迭代中

更新所有单

元。

Gibbs 采样可以

将更新分成

两个块，一块

包括所有偶

数层（包括可

见层），另一个

包括所有奇

数层。由于

DBM 二

分连接模式

，给定偶数层

，关于奇数层

的分布是因

子的，因此可

以作为块同

时且独立地

采样。类似地

，给定奇数层

，可以同时且

独立

地将偶

数层作为块

进行采样。高

效采样对使

用随机最大

似然算法的

训练尤其重

要。

20.4.1

有趣的性

质

深度玻尔

兹曼机具有

许多有趣的

性质。

DBM 在

DBN 之后

开发。与 DBN 相比

，DBM

的后验分布

P(h | v) 更简单。

有点

违反直觉的

是，这种后验

分布的简单

性允许更加

丰富的后验

近似。在 DBN 的

情

况下，我们使

用启发式的

近似推断过

程进行分类

，其中我们可

以通过

MLP（使

用

sigmoid 激活函数并

且权重与原

始 DBN

相同）中的

向上传播猜

测隐藏单元

合理

的均匀

场期望值。任

何分布 Q(h) 可用

于获得对数

似然的变分

下界。因此这

种启发

20.4 深度

玻尔兹曼机

569

式的过程让

我们能够获

得这样的下

界。但是，该界

没有以任何

方式显式优

化，所以

该界

可能是远远

不紧的。特别

地，Q

的启发式

估计忽略了

相同层内隐

藏单元之间

的

相互作用

以及更深层

中隐藏单元

对更接近输

入的隐藏单

元自顶向下

的反馈影响

。因

为 DBN

中基于

启发式 MLP 的推

断过程不能

考虑这些相

互作用，所以

得到的 Q

想

必

远不是最优

的。DBM 中，在给定

其他层的情

况下，层内的

所有隐藏单

元都是条件

独立的。这种

层内相互作

用的缺失使

得通过不动

点方程优化

变分下界并

找到真正最

佳的均匀场

期望（在一些

数值容差内

）变得可能的

。

使用适当的

均匀场允许

DBM

的近似推断

过程捕获自

顶向下反馈

相互作用的

影

响。这从神

经科学的角

度来看是有

趣的，因为根

据已知，人脑

使用许多自

上而下的反

馈连接。由于

这个性质，DBM 已

被用作真实

神经科学现

象的计算模

型 (Series

et al.,

2010; Reichert

et al., 2011)。

DBM

一个不理

想的特性是

从中采样是

相对困难的

。DBN 只需要在其

顶部的一

对

层中使用 MCMC

采

样。其他层仅

在采样过程

末尾涉及，并

且只需在一

个高效的原

始采样过程

。要从 DBM 生成样

本，必须在所

有层中使用

MCMC，并且模型的

每一

层都参

与每个马尔

可夫链转移

。

20.4.2 DBM均匀场推断

给定相邻层

，一个 DBM 层上的

条件分布是

因子的。在有

两个隐藏层

的

DBM 的

示例中

，这些分布是

P(v |

h

(1)), P(h

(1)

| v, h

(2))

和 P(h

(2) |

h

(1))。因为层之

间的相

互作

用，所有隐藏

层上的分布

通常不是因

子的。在有两

个隐藏层的

示例中，由于

h

(1)

和 h

(2) 之间的交

互权重

W(2) 使得

这些变量相

互依赖，P(h

(1) |

v, h

(2)) 不是

因子的。

与 DBN 的

情况一样，我

们还是要找

出近似 DBM

后验

分布的方法

。然而，

与 DBN 不同

，DBM

在其隐藏单

元上的后验

分布（复杂的

）很容易用变

分近似来近

似（如第 19.4 节所

讨论），具体是

一个均匀场

近似。均匀场

近似是变分

推断的简单

形

式，其中我

们将近似分

布限制为完

全因子的分

布。在

DBM 的情况

下，均匀场方

程

捕获层之

间的双向相

互作用。在本

节中，我们推

导出由 Salakhutdinov

and Hinton

(2009a) 最初

引入的迭代

近似推断过

程。

在推断的

变分近似中

，我们通过一

些相当简单

的分布族近

似特定目标

分布——

在这里

指给定可见

单元时隐藏

单元的后验

分布。在均匀

场近似的情

况下，近似族

是隐

藏单元

条件独立的

分布集合。

570

第

二十章 深度

生成模型

我

们现在为具

有两个隐藏

层的示例推

导均匀场方

法。令 Q(h

(1)

, h

(2)

| v) 为

P(h

(1)

, h

(2)

| v) 的近

似。均匀场假

设意味着

Q(h

(1)

, h

(2)

| v) = ∏

j

Q(h

(1)

j

| v)

∏

k

Q(h

(2)

k

|

v). (20.29)

均

匀场近似试

图找到这个

分布族中最

适合真实后

验 P(h

(1)

, h

(2)

| v) 的成员。重

要的是，每次

我们使用 v

的

新值时，必须

再次运行推

断过程以找

到不同的分

布 Q。

我们可以

设想很多方

法来衡量 Q(h

| v) 与

P(h |

v) 的拟合程度

。均匀场方法

是

最小化

KL(Q

|| P) = ∑

h

Q(h

(1)

,

h

(2) | v)log

(Q(h

(1)

, h

(2) | v)

P(h

(1)

, h

(2)

| v)

)

.

(20.30)

一

般来说，除了

要保证独立

性假设，我们

不必提供参

数形式的近

似分布。变分

近似过程通

常能够恢复

近似分布的

函数形式。然

而，在二值隐

藏单元（我们

在这里

推导

的情况）的均

匀场假设的

情况下，不会

由于预先固

定模型的参

数而损失一

般性。

我们将

Q

作为 Bernoulli 分布的

乘积进行参

数化，即我们

将 h

(1) 每个元素

的

概率与一

个参数相关

联。具体来说

，对于每个 j，hˆ(1)

j = Q(h

(1)

j = 1 |

v)，其

中

ˆh

(1)

j

∈ [0, 1]。另外，对于

每个 k，hˆ(2)

k = Q(h

(2)

k = 1 |

v)，其中 hˆ(2)

k ∈

[0, 1]。因

此，我

们有以

下近似后验

：

Q(h

(1)

, h

(2)

| v) = ∏

j

Q(h

(1)

j

| v)

∏

k

Q(h

(2)

k

|

v) (20.31)

=

∏

j

(hˆ(1)

j

)

h

(1)

j (1

− hˆ(1)

j

)

(1−h

(1)

j

)

×

∏

k

(hˆ(2)

k

)

h

(2)

k (1 − hˆ(2)

k

)

(1−h

(2)

k

)

.

(20.32)

当然，对于具

有更多层的

DBM，近似后验的

参数化可以

通过明显的

方式扩展，即

利

用图的二

分结构，遵循

Gibbs 采样相同的

调度，同时更

新所有偶数

层，然后同时

更

新所有奇

数层。

现在我

们已经指定

了近似分布

Q 的函数族，但

仍然需要指

定用于选择

该函数族

中

最适合 P

的成

员的过程。最

直接的方法

是使用式 (19.56) 指

定的均匀场

方程。这些

方

程是通过求

解变分下界

导数为零的

位置而导出

。他们以抽象

的方式描述

如何优化

任

意模型的变

分下界（只需

对 Q 求期望）。

20.4

深

度玻尔兹曼

机 571

应用这些

一般的方程

，我们得到以

下更新规则

（再次忽略偏

置项）：

h

(1)

j = σ

(∑

i

viW(1)

i,j

+

∑

k′

W(2)

j,k′hˆ(2)

k′

)

,

∀j, (20.33)

ˆh

(2)

k = σ

(∑

j

′

W(2)

j

′

,khˆ(1)

j

′

)

, ∀k. (20.34)

在该方

程组的不动

点处，我们具

有变分下界

L(Q) 的局部最大

值。因此，这些

不动点

更新

方程定义了

迭代算法，其

中我们交替

更新 h

(1)

j （使用式

(20.33) ）和

h

(2)

k （使

用式 (20.34) ）。对

于诸如 MNIST

的小

问题，少至 10 次

迭代就足以

找到用于学

习的

近似正

相梯度，而

50 次

通常足以获

得要用于高

精度分类的

单个特定样

本的高质量

表

示。将近似

变分推断扩

展到更深的

DBM 是直观的。

20.4.3 DBM 的

参数学习

DBM

中

的学习必须

面对难解配

分函数的挑

战（使用第十

八章中的技

术），以及

难解

后验分布的

挑战（使用第

十九章中的

技术）。

如第 20.4.2

节

中所描述的

，变分推断允

许构建近似

难处理的 P(h | v)

的

分布

Q(h | v)。然后通

过最大化

L(v, Q, θ)（难

处理的对数

似然的变分

下界 log

P(v; θ)）

学习。

对

于具有两个

隐藏层的深

度玻尔兹曼

机，L

由下式给

出

L(Q, θ) =

∑

i

∑

j

′

viWi,j

(1)

′hˆ(1)

j

′ +

∑

j

′

∑

k′

hˆ(1)

j

′ Wj

(2)

′

,k′hˆ(2)

k′

− logZ(θ) + H(Q).

(20.35)

该表达式

仍然包含对

数配分函数

logZ(θ)。由于深度玻

尔兹曼机包

含受限玻尔

兹曼

机作为

组件，用于计

算受限玻尔

兹曼机的配

分函数和采

样的困难同

样适用于深

度玻

尔兹曼

机。这意味着

评估玻尔兹

曼机的概率

质量函数需

要近似方法

，如退火重要

采

样。同样，训

练模型需要

近似对数配

分函数的梯

度。见第十八

章对这些方

法的一般

性

描述。DBM 通常使

用随机最大

似然训练。第

十八章中描

述的许多其

他技术都不

适

用。诸如伪

似然的技术

需要评估非

归一化概率

的能力，而不

是仅仅获得

它们的变分

下界。对于深

度玻尔兹曼

机，对比散度

是缓慢的，因

为它们不能

在给定可见

单元时

对隐

藏单元进行

高效采样——反

而，每当需要

新的负相样

本时，对比散

度将需要磨

合一条马尔

可夫链。

非变

分版本的随

机最大似然

算法已经在

第 18.2 节讨论过

。算法

20.1 给出了

应用

572 第二十

章

深度生成

模型

于 DBM 的变

分随机最大

似然算法。回

想一下，我们

描述的是

DBM 的

简化变体（缺

少偏置参数

）; 很容易推广

到包含偏置

参数的情况

。

20.4.4

逐层预训练

不幸的是，随

机初始化后

使用随机最

大似然训练

（如上所述）的

DBM 通常导致

失

败。在一些情

况下，模型不

能学习如何

充分地表示

分布。在其他

情况下，DBM 可

以

很好地表示

分布，但是没

有比仅使用

RBM 获得更高的

似然。除第一

层之外，所

有

层都具有非

常小权重的

DBM 与

RBM 表示大致

相同的分布

。

如第 20.4.5

节所述

，目前已经开

发了允许联

合训练的各

种技术。然而

，克

服 DBM 的联合

训练问题最

初和最流行

的方法是贪

心逐层预训

练。在该方法

中，

DBM 的每一层

被单独视为

RBM，进行训练。第

一层被训练

为对输入数

据进行建模

。

每个后续 RBM

被

训练为对来

自前一 RBM 后验

分布的样本

进行建模。在

以这种方

式

训练了所有

RBM

之后，它们可

以被组合成

DBM。然后可以用

PCD 训练 DBM。

通常，PCD

训

练将仅使模

型的参数、由

数据上的对

数似然衡量

的性能、或区

分输入

的能

力发生微小

的变化。见图

20.4 展示的训练

过程。

这种贪

心逐层训练

过程不仅仅

是坐标上升

。因为我们在

每个步骤优

化参数的一

个子集，它与

坐标上升具

有一些传递

相似性。这两

种方法是不

同的，因为贪

心逐层

训练

过程中，我们

在每个步骤

都使用了不

同的目标函

数。

DBM 的贪心逐

层预训练与

DBN 的贪心逐层

预训练不同

。每个单独的

RBM

的参

数可以

直接复制到

相应的 DBN。在 DBM

的

情况下，RBM 的参

数在包含到

DBM 中

之前必须

修改。RBM

栈的中

间层仅使用

自底向上的

输入进行训

练，但在栈组

合

形成 DBM 后，该

层将同时具

有自底向上

和自顶向下

的输入。为了

解释这种效

应，

Salakhutdinov and Hinton (2009a)

提倡在将

其插入 DBM 之前

，将所有 RBM（顶

部

和底部 RBM 除外

）的权重除 2。另

外，必须使用

每个可见单

元的两个

‘‘副

本’’ 来

训练底

部 RBM，并且两个

副本之间的

权重约束为

相等。这意味

着在向上传

播时，权

重能

有效地加倍

。类似地，顶部

RBM 应当使用最

顶层的两个

副本来训练

。

为了使用深

度玻尔兹曼

机获得最好

结果，我们需

要修改标准

的 SML

算法，即在

联

合 PCD 训练步

骤的负相期

间使用少量

的均匀场

(Salakhutdinov and Hinton, 2009a)。

具

体来说，应当

相对于其中

所有单元彼

此独立的均

匀场分布来

计算能量梯

度的期望。

这

个均匀场分

布的参数应

该通过运行

一次均匀场

不动点方程

获得。Goodfellow et al.

(2013d) 比较了

在负相中使

用和不使用

部分均匀场

的中心化 DBM 的

性能。

20.4 深度玻

尔兹曼机 573

算

法

20.1 用于训练

具有两个隐

藏层的DBM的变

分随机最大

似然算法

设

步长 ϵ

为一个

小正数

设定

吉布斯步数

k，大到足以让

p(v, h

(1)

, h

(2)

;

θ + ϵ∆θ) 的马尔可夫

链能磨合

（从

来自 p(v, h

(1)

, h

(2)

;

θ) 的样本

开始）。

初始化

三个矩阵，V˜ ,

H˜

(1) 和

H˜

(2)

每个都将 m 行

设为随机值

（例如，来自 Bernoulli

分

布，边缘分布

大致与模型

匹配）。

while 没有收

敛（学习循环

） do

从训练数据

采包含 m 个样

本的小批量

，并将它们排

列为设计矩

阵 V

的行。

初始

化矩阵 Hˆ

(1)

和 Hˆ

(2)，使

其大致符合

模型的边缘

分布。

while

没有收

敛（均匀场推

断循环） do

Hˆ

(1)

← sigmoid (

VW(1)

+ Hˆ

(2)W(2)⊤

)

.

Hˆ

(2)

←

sigmoid (

Hˆ

(1)W(2))

.

end while

∆W(1)

← 1

m V

⊤Hˆ

(1)

∆W(2) ←

1

m Hˆ

(1)

⊤

Hˆ

(2)

for

l = 1 to

k （Gibbs 采样

） do

Gibbs block 1:

∀i,

j, ˜Vi,j 采自P(

˜Vi,j

= 1) = sigmoid

(

W(1)

j,:

(

H˜

(1)

i,:

)⊤

)

.

∀i, j,

H˜

i,j

(2) 采自P(H˜

i,j

(2) = 1)

= sigmoid (

H˜

(1)

i,: W(2)

:,j

)

.

Gibbs block

2:

∀i, j, H˜

i,j

(1) 采

自P(H˜

i,j

(1) = 1) =

sigmoid (

V˜

i,:W(1)

:,j + H˜

(2)

i,: W(2)

j,:

⊤

)

.

end for

∆W(1) ← ∆W(1) −

1

m V

⊤

˜H

(1)

∆W(2) ←

∆W(2) −

1

m

H˜

(1)⊤ ˜H

(2)

W(1) ← W(1) +

ϵ∆W(1) （这是大概

的描述，实践

中使用的算

法更高效，如

具有

衰减学

习率的动量

）

W(2)

← W(2) + ϵ∆W(2)

end while

574 第二十章

深

度生成模型

d)

a) b)

c)

图 20.4: 用于分类

MNIST 数据集的深

度玻尔兹曼

机训练过程

(Salakhutdinov

and Hinton, 2009a;

Srivastava

et al., 2014)。(a) 使用CD近似最

大化

log P(v) 来训练

RBM。(b) 训练第二个

RBM，使

用CD-k 近似最

大化 log P(h

(1)

, y) 来建模

h

(1) 和目标类 y，其

中 h

(1) 采自第一

个RBM条件于数

据的后验。在

学习期间将

k 从 1

增加到 20。(c) 将

两个RBM组合为

DBM。使用 k

= 5 的随机

最

大似然训

练，近似最大

化

log P(v, y)。(d) 将

y 从模型

中删除。定义

新的一组特

征 h

(1)

和 h

(2)，可

在缺

少

y 的模型中

运行均匀场

推断后获得

。使用这些特

征作为MLP的输

入，其结构与

均匀场的额

外轮相同，并

且具有用于

估计 y 的额外

输出层。初始

化MLP的权重与

DBM的权重相同

。使用随机

梯

度下降和Dropout训

练MLP近似最大

化 log P(y |

v)。图来自 Goodfellow et al.

(2013d)。

20.4.5 联

合训练深度

玻尔兹曼机

经典 DBM

需要贪

心无监督预

训练，并且为

了更好的分

类，需要在它

们提取

的隐

藏特征之上

，使用独立的

基于 MLP 的分类

器。这种方法

有一些不理

想的性

质。因

为我们不能

在训练第一

个 RBM 时评估完

整 DBM

的属性，所

以在训练期

间

难以跟踪

性能。因此，直

到相当晚的

训练过程，我

们都很难知

道我们的超

参数表

20.4 深度

玻尔兹曼机

575

现如何。DBM 的软

件实现需要

很多不同的

模块，如用于

单个 RBM 的

CD 训练

、

完整 DBM

的 PCD 训练

以及基于反

向传播的 MLP

训

练。最后，玻尔

兹曼机顶部

的 MLP 失去了玻

尔兹曼机概

率模型的许

多优点，例如

当某些输入

值丢失时仍

能够

进行推

断的优点。

主

要有两种方

法可以处理

深度玻尔兹

曼机的联合

训练问题。第

一个是中心

化深

度玻尔

兹曼机(centered deep Boltzmann

machine) (Montavon and Muller,

2012)，通

过

重参数化模

型使其在开

始学习过程

时代价函数

的 Hessian 具有更好

的条件数。这

个模型不用

经过贪心逐

层预训练阶

段就能训练

。这个模型在

测试集上获

得出色的

对

数似然，并能

产生高质量

的样本。不幸

的是，作为分

类器，它仍然

不能与适当

正

则化的 MLP 竞

争。联合训练

深度玻尔兹

曼机的第二

种方式是使

用

多预测深

度玻尔

兹曼

机（multi-prediction deep Boltzmann

machine, MP-DBM）(Goodfellow et al.,

2013d)。该模型的

训练准则允

许反向传播

算法，以避免

使用 MCMC 估计梯

度的问

题。不

幸的是，新的

准则不会导

致良好的似

然性或样本

，但是相比

MCMC 方

法，它

确实会

导致更好的

分类性能和

良好的推断

缺失输入的

能力。

如果我

们回到玻尔

兹曼机的一

般观点，即包

括一组权重

矩阵

U 和偏置

b 的单元

x，玻尔

兹曼机中心

化技巧是最

容易描述的

。回顾式

(20.2) ，能量

函数由下式

给出

E(x) =

−x

⊤Ux − b

⊤

x. (20.36)

在权重

矩阵

U 中使用

不同的稀疏

模式，我们可

以实现不同

架构的玻尔

兹曼机，

如 RBM

或

具有不同层

数的 DBM。将 x 分割

成可见和隐

藏单元并将

U

中不相互作

用的单元的

归零可以实

现这些架构

。中心化玻尔

兹曼机引入

了一个向量

µ，并从所

有状

态中减去：

E

′

(x; U, b) =

−(x − µ)

⊤U(x

− µ) − (x

− µ)

⊤b. (20.37)

通

常 µ 在开始训

练时固定为

一个超参数

。当模型初始

化时，通常选

择为 x

− µ ≈ 0。

这种重

参数化不改

变模型可表

示的概率分

布的集合，但

它确实改变

了应用于似

然

的随机梯

度下降的动

态。具体来说

，在许多情况

下，这种重参

数化导致更

好条件数

的

Hessian 矩阵。Melchior

et al. (2013) 通过实

验证实了

Hessian 矩

阵条件数的

改

善，并观察

到中心化技

巧等价于另

一个玻尔兹

曼机学习技

术——增强梯度

(enhanced

gradient)

(Cho et al., 2011)。即使在困难

的情况下，例

如训练多层

的深度玻尔

兹曼

机，Hessian 矩阵

条件数的改

善也能使学

习成功。

联合

训练深度玻

尔兹曼机的

另一种方法

是多预测深

度玻尔兹曼

机（MP-DBM），

576

第二十章

深度生成模

型

它将均匀

场方程视为

定义一系列

用于近似求

解每个可能

推断问题的

循环网络 (Good￾fellow et

al., 2013d)。模

型被训练为

使每个循环

网络获得对

相应推断问

题的准确答

案，而不是训

练模型来最

大化似然。训

练过程如图

20.5 所示。它包括

随机采一个

训

练样本、随

机采样推断

网络的输入

子集，然后训

练推断网络

来预测剩余

单元的值。

这

种用于近似

推断，通过计

算图进行反

向传播的一

般原理已经

应用于其他

模

型 (Stoyanov et

al., 2011; Brakel et

al., 2013)。在这些

模型和 MP-DBM 中，最

终损

失不是

似然的下界

。相反，最终损

失通常基于

近似推断网

络对缺失值

施加的近似

条

件分布。这

意味着这些

模型的训练

有些启发式

。如果我们检

查由 MP-DBM 学习出

来

的玻尔兹

曼机表示 p(v)，在

Gibbs 采样产生较

差样本的意

义下，它倾向

于有些缺陷

。

通过推断图

的反向传播

有两个主要

优点。首先，它

以模型真正

使用的方式

训练

模型——使

用近似推断

。这意味着在

MP-DBM 中，进行如填

充缺失的输

入或执行

分

类（尽管存在

缺失的输入

）的近似推断

比在原始 DBM

中

更准确。原始

DBM 不

会自己做

出准确的分

类器; 使用原

始

DBM 的最佳分

类结果是基

于 DBM 提取的特

征训练独立

的分类器，而

不是通过使

用

DBM 中的推断

来计算关于

类标签的分

布。

MP-DBM 中的均匀

场推断作为

分类器，不需

要进行特殊

修改就获得

良好的表现

。通

过近似推

断反向传播

的另一个优

点是反向传

播计算损失

的精确梯度

。对于优化而

言，

比 SML 训练中

具有偏差和

方差的近似

梯度更好。这

可能解释了

为什么

MP-DBM 可

以

联合训练，而

DBM 需要贪心逐

层预训练。近

似推断图反

向传播的缺

点是它不提

供一种优化

对数似然的

方法，而提供

广义伪似然

的启发式近

似。

MP-DBM 启发了对

NADE 框架的扩展

NADE-k (Raiko

et al., 2014) ，我们将

在第

20.10.10 节中描述。

MP-DBM 与

Dropout

有一定联系

。Dropout 在许多不同

的计算图之

间共享相

同

的参数，每个

图之间的差

异是包括还

是排除每个

单元。MP-DBM 还在许

多计算

图之

间共享参数

。在 MP-DBM 的情况下

，图之间的差

异是每个输

入单元是否

被观

察到。当

没有观察到

单元时，MP-DBM

不会

像 Dropout 那样将其

完全删除。相

反，

MP-DBM

将其视为

要推断的潜

变量。我们可

以想象将 Dropout 应

用到 MP-DBM，

即额外

去除一些单

元而不是将

它们变为潜

变量。

20.4 深度玻

尔兹曼机 577

图

20.5: 深度玻尔兹

曼机多预测

训练过程的

示意图。每一

行指示相同

训练步骤内

小批量中的

不同

样本。每

列表示均匀

场推断过程

中的时间步

。对于每个样

本，我们对数

据变量的子

集进行采样

，作

为推断过

程的输入。这

些变量以黑

色阴影表示

条件。然后我

们运行均匀

场推断过程

，箭头指示过

程中的哪些

变量会影响

其他变量。在

实际应用中

，我们将均匀

场展开为几

个步骤。在此

示意图中，

我

们只展开为

两个步骤。虚

线箭头表示

获得更多步

骤需要如何

展开该过程

。未用作推断

过程输入

的

数据变量成

为目标，以灰

色阴影表示

。我们可以将

每个样本的

推断过程视

为循环网络

。为了使

其在

给定输入后

能产生正确

的目标，我们

使用梯度下

降和反向传

播训练这些

循环网络。这

可以训

练

MP-DBM 均

匀场过程产

生准确的估

计。图改编自

Goodfellow et al.

(2013d)。

578 第二十章 深

度生成模型

20.5

实值数据上

的玻尔兹曼

机

虽然玻尔

兹曼机最初

是为二值数

据而开发的

，但是许多应

用，例如图像

和音频

建模

似乎需要表

示实值上概

率分布的能

力。在一些情

况下，我们可

以将区间 [0,

1] 中

的实值数据

视为表示二

值变量的期

望。例如，Hinton (2000) 将训

练集中灰度

图像的

像素

值视为定义

[0, 1] 间的概率值

。每个像素定

义二值变量

为 1

的概率，并

且二值像

素

的采样都彼

此独立。这是

评估灰度图

像数据集上

二值模型的

常见过程。然

而，这

种方法

理论上并不

特别令人满

意，并且以这

种方式独立

采样的二值

图像具有噪

声表

象。在本

节中，我们介

绍概率密度

定义在实值

数据上的玻

尔兹曼机。

20.5.1 Gaussian-Bernoulli RBM

受

限玻尔兹曼

机可以用于

许多指数族

的条件分布

(Welling

et al., 2005)。其中，

最常见

的是具有二

值隐藏单元

和实值可见

单元的

RBM，其中

可见单元上

的条件分布

是高斯分布

（均值为隐藏

单元的函数

）。

有很多方法

可以参数化

Gaussian-Bernoulli RBM。首先，我们可

以选择协方

差

矩阵或精

度矩阵来参

数化高斯分

布。这里，我们

介绍选择精

度矩阵的情

况。我们可

以

通过简单的

修改获得协

方差的形式

。我们希望条

件分布为

p(v | h)

= N (v;Wh, β

−1

). (20.38)

通

过扩展未归

一化的对数

条件分布可

以找到需要

添加到能量

函数中的项

：

log N (v;Wh, β

−1

) = −

1

2

(v −

Wh)

⊤β(v − Wh)

+ f(β). (20.39)

此处

f 封装所

有的参数，但

不包括模型

中的随机变

量。因为 f 的唯

一作用是归

一化分布，并

且我们选择

的任何可作

为配分函数

的能量函数

都能起到这

个作用，所

以

我们可以忽

略 f。

如果我们

在能量函数

中包含式 (20.39)

中

涉及 v 的所有

项（其符号被

翻转），并

且不

添加任何其

他涉及

v 的项

，那么我们的

能量函数就

能表示想要

的条件分布

p(v | h)。

其他条件分

布比较自由

，如 p(h | v)。注意式

(20.39) 包

含一项

1

2

h

⊤W⊤βWh. (20.40)

20.5

实值

数据上的玻

尔兹曼机 579

因

为该项包含

hihj 项，它不能被

全部包括在

内。这些对应

于隐藏单元

之间的边。如

果我们包括

这些项，我们

将得到一个

线性因子模

型，而不是受

限玻尔兹曼

机。当设

计我

们的玻尔兹

曼机时，我们

简单地省略

这些 hihj 交叉项

。省略这些项

不改变条件

分布 p(v

| h)，因此式

(20.39) 仍满足。然而

，我们仍然可

以选择是否

包括仅涉及

单个

hi

的项。如

果我们假设

精度矩阵是

对角的，就能

发现对于每

个隐藏单元

hi，我们有

一项

1

2

hi

∑

j

βjWj,i

2

. (20.41)

在上面，我们

使用了 h

2

i = hi

的事

实（因为 hi ∈ {0,

1}）。如果

我们在能量

函数中包

含

此项（符号被

翻转），则当该

单元的权重

较大且以高

精度连接到

可见单元时

，偏

置 hi

将自然

被关闭。是否

包括该偏置

项不影响模

型可以表示

的分布族（假

设我们包

括

隐藏单元的

偏置参数），但

是它确实会

影响模型的

学习动态。包

括该项可以

帮助隐

藏单

元（即使权重

在幅度上快

速增加时）保

持合理激活

。

因此，在

Gaussian-Bernoulli RBM 上定

义能量函数

的一种方式

：

E(v,

h) = 1

2

v

⊤(β ⊙ v)

− (v ⊙ β)

⊤Wh − b

⊤

h, (20.42)

但我们还可

以添加额外

的项或者通

过方差而不

是精度参数

化能量。

在这

个推导中，我

们没有在可

见单元上添

加偏置项，但

添加这样的

偏置是容易

的。Gaussian-Bernoulli

RBM 参数化一

个最终变化

的来源是如

何处理精度

矩阵的选

择

。它可以被固

定为常数（可

能基于数据

的边缘精度

估计）或学习

出来。它也可

以

是标量乘

以单位矩阵

，或者是一个

对角矩阵。在

此情况下，由

于一些操作

需要对矩

阵

求逆，我们通

常不允许非

对角的精度

矩阵，因为高

斯分布的一

些操作需要

对矩阵求

逆

，一个对角矩

阵可以非常

容易地被求

逆。在接下来

的章节中，我

们将看到其

他形式

的玻

尔兹曼机，它

们允许对协

方差结构建

模，并使用各

种技术避免

对精度矩阵

求逆。

20.5.2

条件协

方差的无向

模型

虽然高

斯 RBM 已成为实

值数据的标

准能量模型

，Ranzato

et al. (2010a) 认为高

斯 RBM 感

应偏置不能

很好地适合

某些类型的

实值数据中

存在的统计

变化，特别是

自然图像。问

题在于自然

图像中的许

多信息内容

嵌入于像素

之间的协方

差而不是

原

始像素值中

。换句话说，图

像中的大多

数有用信息

在于像素之

间的关系，而

不是

其绝对

值。由于高斯

RBM 仅对给定隐

藏单元的输

入条件均值

建模，所以它

不能捕

580 第二

十章

深度生

成模型

获条

件协方差信

息。为了回应

这些评论，已

经有学者提

出了替代模

型，设法更好

地

考虑实值

数据的协方

差。这些模型

包括 均值和

协方差

RBM（mean and covariance

RBM,

mcRBM）1、学生

t 分布均值乘

积（mean product of

Student t-distribution,

mPoT）模型和 尖

峰和平板

RBM（spike and slab RBM,

ssRBM）。

均

值和协方差

RBM mcRBM 使用隐藏单

元独立地编

码所有可观

察单元的条

件均

值和协

方差。mcRBM 的隐藏

层分为两组

单元：均值单

元和协方差

单元。建模条

件

均值的那

组单元是简

单的高斯 RBM。另

一半是

协方

差 RBM（covariance RBM,

cRBM）(Ranzato

et al., 2010a)，对条件协

方差的结构

进行建模（如

下所述）。

具体

来说，在二值

均值的单元

h

(m) 和二值协方

差单元 h

(c)

的情

况下，mcRBM 模

型被

定义为两个

能量函数的

组合：

Emc(x,

h

(m)

, h

(c)

) = Em(x,

h

(m)

) +

Ec(x, h

(c)

),

(20.43)

其中 Em 为

标准的

Gaussian-Bernoulli RBM 能量

函数2，

Em(x,

h

(m)

) =

1

2

x

⊤x

−

∑

j

x

⊤W:,jh

(

j

m)

−

∑

j

b

(

j

m)

h

(

j

m)

,

(20.44)

Ec 是 cRBM

建模

条件协方差

信息的能量

函数：

Ec(x, h

(c)

) = 1

2

∑

j

h

(

j

c)

(

x

⊤r

(j)

)2

−

∑

j

b

(

j

c)

h

(

j

c)

. (20.45)

参数 r

(j) 与

h

(

j

c) 关联的协方

差权重向量

对应，b

(c) 是一个

协方差偏置

向量。组合后

的能量函数

定义联合分

布，

pmc(x, h

(m)

, h

(c)

) = 1

Z

exp {

− Emc(x,

h

(m)

, h

(c)

)

}

,

(20.46)

以及给定

h

(m) 和

h

(c) 后，关于观

察数据相应

的条件分布

（为一个多元

高斯分布）：

pmc(x

| h

(m)

,

h

(c)

) =

N

(

x ;

Cx

mc

|h

(∑

j

W:,jh

(

j

m)

)

, Cx

mc

|h

)

.

(20.47)

注

意协方差矩

阵 Cx

mc

|h =

(∑

j

h

(

j

c)

r

(j)r

(j)T +

I

)−1

是非对角

的，且 W

是与建

模条件

均值

的高斯 RBM 相关

联的权重矩

阵。由于非对

角的条件协

方差结构，难

以通过对

1术

语 “mcRBM’’ 根据字母

M-C-R-B-M 发音；“mc’’

不是 “McDonald’s’’ 中

的 “Mc’’

的发音。

2这

个版本的 Gaussian-Bernoulli RBM

能

量函数假定

图像数据的

每个像素具

有零均值。考

虑非零像素

均值时，可

以

简单地将像

素偏移添加

到模型中。

20.5 实

值数据上的

玻尔兹曼机

581

比散度或持

续性对比散

度来训练 mcRBM。CD 和

PCD 需要从

x, h

(m)

,

h

(c) 的联

合

分布中采

样，这在标准

RBM

中可以通过

Gibbs 采样在条件

分布上采样

实现。但是，

在

mcRBM 中，从

pmc(x | h

(m)

, h

(c)

)

中抽样

需要在学习

的每个迭代

计算 (C

mc)

−1。

这对于

更大的观察

数据可能是

不切实际的

计算负担。Ranzato and Hinton (2010)

通

过使用 mcRBM 自由

能上的哈密

尔顿（混合）蒙

特卡罗 (Neal,

1993) 直接

从边缘

p(x) 采样

，避免了直接

从条件

pmc(x | h

(m)

, h

(c)

)

抽样

。

学生 t 分布均

值乘积

学生

t 分布均值乘

积（mPoT）模型 (Ranzato et

al., 2010b)

以类

似 mcRBM

扩展 cRBM 的方

式扩展 PoT

模型

(Welling et al., 2003a)。通过添

加类

似高斯 RBM 中隐

藏单元的非

零高斯均值

来实现。与 mcRBM

一

样，观察值上

的 PoT 条件分布

是多元高斯

（具有非对角

的协方差）分

布; 然而，不同

于

mcRBM ，

隐藏变量

的互补条件

分布是由条

件独立的 Gamma

分

布给出。Gamma 分布

G(k, θ)

是关于正实

数且均值为

kθ

的概率分布

。我们只需简

单地了解 Gamma 分

布就足以理

解 mPoT

模型的基

本思想。

mPoT 的能

量函数为：

EmPoT(x,

h

(m)

, h

(c)

) (20.48)

=

Em(x, h

(m)

)

+∑

j

(

h

(

j

c)

(

1 +

2

1

(r

(j)T x)

2

)

+ (1 −

γj )log h

(

j

c)

)

,

(20.49)

其

中 r

(j)

是与单元

h

(

j

c)

相关联的协

方差权重向

量，Em(x, h

(m)

)

如式 (20.44) 所定

义。

正如

mcRBM 一样

，mPoT 模型能量函

数指定一个

多元高斯分

布，其中关于

x

的条件分布

具有非对角

的协方差。mPoT

模

型中的学习

（也像 mcRBM ）由于无

法

从非对角

高斯条件分

布

pmPoT(x | h

(m)

, h

(c)

)

采样而变

得复杂。因此

Ranzato et al.

(2010b)

也倡导通过

哈密尔顿（混

合）蒙特卡罗

(Neal, 1993) 直接采样 p(x)。

尖

峰和平板 RBM 尖

峰和平板 RBM（spike

and slab RBM, ssRBM）(Courville

et al., 2011b) 提

供对实值数

据的协方差

结构建模的

另一种方法

。与

mcRBM 相

比，ssRBM 具有

既不需要矩

阵求逆也不

需要哈密尔

顿蒙特卡罗

方法的优点

。就

像 mcRBM 和 mPoT

模型

，ssRBM 的二值隐藏

单元通过使

用辅助实值

变量来编码

跨像素的条

件协方差。

尖

峰和平板 RBM

有

两类隐藏单

元：二值尖峰

(spike) 单元 h 和实值

平板

(slab)

单元 s。条

件于隐藏单

元的可见单

元均值由 (h⊙s)W⊤

给

出。换句话说

，每一列 W:,i

582 第二

十章

深度生

成模型

定义

当 hi =

1 时可出现

在输入中的

分量。相应的

尖峰变量 hi 确

定该分量是

否存在。

如果

存在的话，相

应的平板变

量 si 确定该分

量的强度。当

尖峰变量激

活时，相应的

平板变量将

沿着 W:,i

定义的

轴的输入增

加方差。这允

许我们对输

入的协方差

建模。

幸运的

是，使用 Gibbs 采样

的对比散度

和持续性对

比散度仍然

适用。此处无

需对任

何矩

阵求逆。

形式

上，ssRBM 模型通过

其能量函数

定义：

Ess(x,

s, h) = −

∑

i

x

⊤W:,isihi

+

2

1

x

⊤

(

Λ +

∑

i

Φihi

)

x (20.50)

+

1

2

∑

i

αis

2

i −

∑

i

αiµisihi −

∑

i

bihi +

∑

i

αiµ

2

i

hi

, (20.51)

其中

bi 是

尖峰 hi 的偏置

，Λ

是观测值 x 上

的对角精度

矩阵。参数 αi

> 0 是

实值平

板变

量

si 的标量精

度参数。参数

Φi 是定义 x

上的

h 调制二次惩

罚的非负对

角矩

阵。每个

µi 是平板变量

si

的均值参数

。

利用能量函

数定义的联

合分布，能相

对容易地导

出 ssRBM 条件分布

。例如，通

过边

缘化平板变

量 s，给定二值

尖峰变量 h，关

于观察量的

条件分布由

下式给出

pss(x

| h) =

P(

1

h) Z

1

∫

exp{−E(x, s, h)}ds

(20.52)

= N

(

x ; Cx

ss

|h

∑

i

W:,iµihi

, Cx

ss

|h

)

(20.53)

其

中 Cx

ss

|h = (Λ

+

∑

i Φihi

−

∑

i αi

−1hiW:,iW⊤

:,i)

−1。最后的等

式只有在协

方差矩阵

Cx

ss

|h 正

定时成立。

由

尖峰变量选

通意味着

h ⊙ s 上

的真实边缘

分布是稀疏

的。这不同于

稀疏编码，

其

中来自模型

的样本在编

码中 ‘‘几乎从

不’’（在测度理

论意义上）包

含零，并且需

要MAP推断来强

加稀疏性。

相

比 mcRBM

和 mPoT 模型，ssRBM 以

明显不同的

方式参数化

观察量的条

件

协方差。mcRBM 和

mPoT 都通过 (∑

j

h

(

j

c)

r

(j)r

(j)⊤

+ I

)−1 建模

观察量的协

方差

结构，使

用 hj > 0

的隐藏单

元的激活来

对方向 r

(j) 的条

件协方差施

加约束。相反

，

ssRBM 使用隐藏尖

峰激活 hi =

1 来指

定观察结果

的条件协方

差，以沿着由

相应权

重向

量指定的方

向捏合精度

矩阵。ssRBM 条件协

方差与一个

不同模型给

出的类似：

概

率主成分分

析的乘积（PoPPCA）(Williams and Agakov, 2002)。在

过完备的设

定

下，ssRBM 参数化

的稀疏激活

仅允许在稀

疏激活 hi 的所

选方向上有

显著方差（高

20.6

卷积玻尔兹

曼机 583

于由 Λ

−1 给

出的近似方

差）。在 mcRBM 或

mPoT 模型

中，过完备的

表示意味着

，

捕获观察空

间中特定方

向上的变化

需要在该方

向上的正交

投影下去除

潜在的所有

约

束。这表明

这些模型不

太适合于过

完备设定。

尖

峰和平板 RBM 的

主要缺点是

参数的一些

设置会对应

于非正定的

协方差矩阵

。

这种协方差

矩阵会在离

均值更远的

值上放置更

大的未归一

化概率，导致

所有可能结

果上的积分

发散。通常这

个问题可以

通过简单的

启发式技巧

来避免。理论

上还没有

任

何令人满意

的解决方法

。使用约束优

化来显式地

避免概率未

定义的区域

（不过分

保守

是很难做到

的），并且这还

会阻止模型

到达参数空

间的高性能

区域。

定性地

，ssRBM 的卷积变体

能产生自然

图像的优秀

样本。图

16.1 中展

示了一些

样

例。

ssRBM

允许几个

扩展，包括平

板变量的高

阶交互和平

均池化 (Courville et al.,

2014) 使得

模型能够在

标注数据稀

缺时为分类

器学习到出

色的特征。向

能量函

数添

加一项能防

止配分函数

在稀疏编码

模型下变得

不确定，如尖

峰和平板稀

疏编

码

(Goodfellow et al., 2013g)，也称

为

S3C。

20.6 卷积玻尔

兹曼机

如第

九章所示，超

高维度输入

（如图像）会对

机器学习模

型的计算、内

存和统

计要

求造成很大

的压力。通过

使用小核的

离散卷积来

替换矩阵乘

法是解决具

有空间

平移

不变性或时

间结构的输

入问题的标

准方式。Desjardins and Bengio

(2008) 表明

这种方法应

用于 RBM 时效果

很好。

深度卷

积网络通常

需要池化操

作，使得每个

连续层的空

间大小减小

。前馈卷积

网

络通常使用

池化函数，例

如池化元素

的最大值。目

前尚不清楚

如何将其推

广到基

于能

量的模型的

设定中。我们

可以在 n

个二

值检测器单

元 d 上引入二

值池化单元

p，

强制

p = maxi di，并且当

违反约束时

将能量函数

设置为

∞。因为

它需要评估

2

n 个

不同的能

量设置来计

算归一化常

数，这种方式

不能很好地

扩展。对于小

的

3 × 3 池化

区域

，每个池化单

元需要评估

2

9 = 512

个能量函数

！

Lee et al.

(2009) 针对这个问

题，开发了一

个称为 概率

最大池化 (probabilistic

max pooling) 的

解决方案（不

要与 ‘‘随机池

化’’

混淆，‘‘随机

池化’’ 是用于

隐含地构

建

卷积前馈网

络集成的技

术）。概率最大

池化背后的

策略是约束

检测器单元

，使得一

次最

多只有一个

可以处于活

动状态。这意

味着仅存在

n

+ 1 个总状态（n 个

检测器

584 第二

十章 深度生

成模型

单元

中某一个状

态为开和一

个对应于所

有检测器单

元关闭的附

加状态）。当且

仅当检

测器

单元中的一

个开启时，池

化单元打开

。所有单元的

状态关闭时

，能量被分配

为

零。我们可

以认为这是

在用包含 n +

1 个

状态的单个

变量来描述

模型，或者等

价地

具有 n

+ 1 个

变量的模型

，除了 n

+ 1 个联合

分配的变量

之外的能量

赋为 ∞。

虽然高

效的概率最

大池化确实

能强迫检测

器单元互斥

，这在某些情

景下可能是

有用的正则

化约束而在

其他情景下

是对模型容

量有害的限

制。它也不支

持重叠池化

区域。从前馈

卷积网络获

得最佳性能

通常需要重

叠的池化区

域，因此这种

约束可能

大

大降低了卷

积玻尔兹曼

机的性能。

Lee et

al. (2009) 证

明概率最大

池化可以用

于构建卷积

深度玻尔兹

曼机3。该模

型

能够执行诸

如填补输入

缺失部分的

操作。虽然这

种模型在理

论上有吸引

力，让它

在实

践中工作是

具有挑战性

的，作为分类

器通常不如

通过监督训

练的传统卷

积网络。

许多

卷积模型对

于许多不同

空间大小的

输入同样有

效。对于玻尔

兹曼机，由于

各种原因很

难改变输入

尺寸。配分函

数随着输入

大小的改变

而改变。此外

，许多卷积

网

络按与输入

大小成比例

地缩放池化

区域来实现

尺寸不变性

，但缩放玻尔

兹曼机池

化

区域是不优

雅的。传统的

卷积神经网

络可以使用

固定数量的

池化单元并

且动态地

增

加它们池化

区域的大小

，以此获得可

变大小输入

的固定尺寸

的表示。对于

玻尔兹

曼机

，大型池化区

域的计算成

本比朴素方

法高很多。Lee et al.

(2009) 的

方法使得每

个检测器单

元在相同的

池化区域中

互斥，解决了

计算问题，但

仍然不允许

大小可变

的

池化区域。例

如，假设我们

在学习边缘

检测器时，检

测器单元上

具有 2

× 2 的概率

最大池化。这

强制约束在

每个 2

× 2 的区域

中只能出现

这些边中的

一条。如果我

们随

后在每

个方向上将

输入图像的

大小增加

50%，则

期望边缘的

数量会相应

地增加。相

反

，如果我们在

每个方向上

将池化区域

的大小增加

50% 到 3

× 3，则互斥性

约束现

在指

定这些边中

的每一个在

3 ×

3 区域中仅可

以出现一次

。当我们以这

种方式增长

模

型的输入

图像时，模型

会生成密度

较小的边。当

然，这些问题

只有在模型

必须使用

可

变数量的池

化，以便产出

固定大小的

输出向量时

才会出现。只

要模型的输

出是可

以与

输入图像成

比例缩放的

特征图，使用

概率最大池

化的模型仍

然可以接受

可变大

小的

输入图像。

图

像边界处的

像素也带来

一些困难，由

于玻尔兹曼

机中的连接

是对称的事

实而

加剧。如

果我们不隐

式地补零输

入，则将会导

致比可见单

元更少的隐

藏单元，并且

图像边界处

的可见单元

将不能被良

好地建模，因

为它们位于

较少隐藏单

元的接受场

3该论文将模

型描述为

“深

度信念网络

’’，但因为它可

以被描述为

纯无向模型

（具有易处理

逐层均匀场

不动点更新

），

所以它最适

合深度玻尔

兹曼机的定

义。

20.7 用于结构

化或序列输

出的玻尔兹

曼机

585

中。然而

，如果我们隐

式地补零输

入，则边界处

的隐藏单元

将由较少的

输入像素驱

动，并且可能

在需要时无

法激活。

20.7 用于

结构化或序

列输出的玻

尔兹曼机

在

结构化输出

场景中，我们

希望训练可

以从一些输

入 x 映射到一

些输出 y

的模

型，y 的不同条

目彼此相关

，并且必须遵

守一些约束

。例如，在语音

合成任务中

，y

是波形，并且

整个波形听

起来必须像

连贯的发音

。

表示

y 中的条

目之间关系

的自然方式

是使用概率

分布 p(y |

x)。扩展到

建模条

件分

布的玻尔兹

曼机可以支

持这种概率

模型。

使用玻

尔兹曼机条

件建模的相

同工具不仅

可以用于结

构化输出任

务，还可以用

于序列建模

。在后一种情

况下，模型必

须估计变量

序列上的概

率分布 p(x

(1)

, . .

. , x

(τ)

)，

而不

仅仅是将输

入 x 映射到输

出

y。为完成这

个任务，条件

玻尔兹曼机

可以表示

p(x

(τ)

|

x

(1)

, .

. . , x

(τ−1)) 形

式的因子。

视

频游戏和电

影工业中一

个重要序列

建模任务是

建模用于渲

染 3-D

人物骨架

关

节角度的

序列。这些序

列通常通过

记录角色移

动的运动捕

获系统收集

。人物运动的

概

率模型允

许生成新的

（之前没见过

的）但真实的

动画。为了解

决这个序列

建模任务，

Taylor

et al. (2007) 针

对小的

m 引入

了条件 RBM 建模

p(x

(t)

| x

(t−1)

, . . .

, x

(t−m)

)。

该模型是 p(x

(t)

)

上

的 RBM，其偏置参

数是 x 前面

m 个

值的线性函

数。当我们条

件

于 x

(t−1) 的不同

值和更早的

变量时，我们

会得到一个

关于 x 的新

RBM。RBM 关

于

x 的权重不

会改变，但是

条件于不同

的过去值，我

们可以改变

RBM

中的不同隐

藏单

元处于

活动状态的

概率。通过激

活和去激活

隐藏单元的

不同子集，我

们可以对 x 上

诱导的概率

分布进行大

的改变。条件

RBM

的其他变体

(Mnih et al., 2011)

和使用

条件

RBM 进行序列建

模的其他变

体是可能的

(Taylor and

Hinton, 2009; Sutskever

et

al., 2009; Boulanger-Lewandowski et

al., 2012)。

另一个序列

建模任务是

对构成歌曲

音符序列的

分布进行建

模。Boulanger￾Lewandowski et

al. (2012) 引入了 RNN-RBM

序

列模型并应

用于这个任

务。RNN￾RBM 由 RNN（产生用

于每个时间

步的 RBM

参数）组

成，是帧序列

x

(t) 的生成模

型

。与之前只有

RBM

的偏置参数

会在一个时

间步到下一

个发生变化

的方法不同

，

RNN-RBM 使用 RNN

来产生

RBM 的所有参数

（包括权重）。为

了训练模型

，我们

需要能

够通过 RNN

反向

传播损失函

数的梯度。损

失函数不直

接应用于 RNN 输

出。

586

第二十章

深度生成模

型

相反，它应

用于 RBM。这意味

着我们必须

使用对比散

度或相关算

法关于 RBM

参数

进行近似的

微分。然后才

可以使用通

常的通过时

间反向传播

算法通过 RNN 反

向传

播该近

似梯度。

20.8 其他

玻尔兹曼机

玻尔兹曼机

的许多其他

变种是可能

的。

玻尔兹曼

机可以用不

同的训练准

则扩展。我们

专注于训练

为大致最大

化生成标

准

log

p(v) 的玻尔兹曼

机。相反，旨在

最大化 log p(y

| v) 来训

练判别的 RBM

也

是

有可能的

(Larochelle and Bengio,

2008a)。当使用生成

性和判别性

标准的线性

组合

时，该方

法通常表现

最好。不幸的

是，至少使用

现有的方法

来看，RBM 似乎并

不

如

MLP 那样的

监督学习器

强大。

在实践

中使用的大

多数玻尔兹

曼机在其能

量函数中仅

具有二阶相

互作用，意味

着它们的能

量函数是许

多项的和，并

且每个单独

项仅包括两

个随机变量

之间的乘积

。

这种项的一

个例子是

viWi,jhj。我

们还可以训

练高阶玻尔

兹曼机 (Sejnowski, 1987)

，其中

能量函数项

涉及许多变

量的乘积。隐

藏单元和两

个不同图像

之间的三向

交互

可以建

模从一个视

频帧到下一

个帧的空间

变换 (Memisevic and Hinton,

2007, 2010)。

通过one-hot类

别变量的乘

法可以根据

存在哪个类

来改变可见

单元和隐藏

单元之间的

关系 (Nair

and Hinton, 2009)。使用高

阶交互的一

个最近的示

例是具有两

组隐藏单

元

的玻尔兹曼

机，一组同时

与可见单元

v

和类别标签

y 交互，另一组

仅与输入值

v

交互 (Luo

et al., 2011)。这可以

被解释为鼓

励一些隐藏

单元学习使

用与类相关

的特

征来建

模输入，而且

还学习额外

的隐藏单元

（不需要根据

样本类别，学

习逼真

v 样

本

所需的繁琐

细节）。高阶交

互的另一个

用途是选通

一些特征。Sohn et

al. (2013) 介

绍了一个带

有三阶交互

的玻尔兹曼

机，以及与每

个可见单元

相关的二进

制掩码变量

。

当这些掩码

变量设置为

零时，它们消

除可见单元

对隐藏单元

的影响。这允

许将与分

类

问题不相关

的可见单元

从估计类别

的推断路径

中移除。

更一

般地说，玻尔

兹曼机框架

是一个丰富

的模型空间

，允许比迄今

为止已经探

索的更多的

模型结构。开

发新形式的

玻尔兹曼机

相比于开发

新的神经网

络层需要更

多细心和创

造力，因为它

通常很难找

到一个能保

持玻尔兹曼

机所需的所

有不同条件

分布的可解

性的能量函

数。尽管这需

要努力，该领

域仍对创新

开放。

20.9 通过随

机操作的反

向传播

587

20.9 通过

随机操作的

反向传播

传

统的神经网

络对一些输

入变量

x 施加

确定性变换

。当开发生成

模型时，我们

经常希望扩

展神经网络

以实现 x 的随

机变换。这样

做的一个直

接方法是使

用额外输

入

z（从一些简单

的概率分布

采样得到，如

均匀或高斯

分布）来增强

神经网络。神

经

网络在内

部仍可以继

续执行确定

性计算，但是

函数 f(x, z)

对于不

能访问 z 的观

察者

来说将

是随机的。假

设

f 是连续可

微的，我们可

以像往常一

样使用反向

传播计算训

练所需的梯

度。

作为示例

，让我们考虑

从均值 µ

和方

差 σ

2 的高斯分

布中采样

y 的

操作：

y ∼

N (µ, σ2

).

(20.54)

因为 y 的

单个样本不

是由函数产

生的，而是由

一个采样过

程产生，它的

输出会随我

们的每次查

询变化，所以

取

y 相对于其

分布的参数

µ 和 σ

2 的导数似

乎是违反直

觉

的。然而，我

们可以将采

样过程重写

，对基本随机

变量 z

∼ N (z; 0,

1) 进行转

换以从

期望

的分布获得

样本：

y

= µ + σz.

(20.55)

现在我

们将其视为

具有额外输

入 z 的确定性

操作，可以通

过采样操作

来反向传

播

。至关重要的

是，额外输入

是一个随机

变量，其分布

不是任何我

们想对其计

算导

数的变

量的函数。如

果我们可以

用相同的 z 值

再次重复采

样操作，结果

会告诉我们

µ

或 σ 的微小变

化将会如何

改变输出。

能

够通过该采

样操作反向

传播允许我

们将其并入

更大的图中

。我们可以在

采样

分布的

输出之上构

建图元素。例

如，我们可以

计算一些损

失函数J(y) 的导

数。我们

还可

以构建这样

的图元素，其

输出是采样

操作的输入

或参数。例如

，我们可以通

过

µ

= f(x; θ) 和

σ = g(x; θ)

构建更

大的图。在这

个增强图中

，我们可以通

过这些函数

的反向传播

导出 ∇θJ(y)。

在该高

斯采样示例

中使用的原

理能更广泛

地应用。我们

可以将任何

形为 p(y;

θ)

或 p(y |

x; θ) 的概

率分布表示

为 p(y

| ω)，其中 ω 是同

时包含参数

θ

和输入 x 的变

量 (如果适用

的话)。给定从

分布

p(y | ω) 采样的

值

y（其中 ω 可以

是其他变量

的函

数），我们

可以将

y ∼ p(y |

ω) (20.56)

588 第二

十章

深度生

成模型

重写

为

y =

f(z; ω), (20.57)

其中

z 是随

机性的来源

。只要 f 是几乎

处处连续可

微的，我们就

可以使用传

统

工具（例如

应用于 f 的反

向传播算法

）计算 y

相对于

ω 的导数。至关

重要的是，

ω 不

能是

z 的函数

，且 z 不能是

ω 的

函数。这种技

术通常被称

为 重参数化

技巧

（reparametrization

trick）、随机反

向传播(stochastic back-propagation) 或扰

动分析

(perturbation

analysis)。

要求

f 是连续可微

的，当然需要

y 是连续的。如

果我们希望

通过产生离

散值

样本的

采样过程进

行反向传播

，则可以使用

强化学习算

法（如 REINFORCE 算法

(Williams,

1992) 的

变体）来估计

ω 上的梯度，这

将在第 20.9.1

节中

讨论。

在神经

网络应用中

，我们通常选

择从一些简

单的分布中

采样 z，如单位

均匀分布

或

单位高斯分

布，并通过网

络的确定性

部分重塑其

输入来实现

更复杂的分

布。

通过随机

操作扩展梯

度或优化的

想法可追溯

到二十世纪

中叶 (Price, 1958;

Bonnet,

1964)，并且首

先在强化学

习 (Williams, 1992) 的情景下

用于机器学

习。

最近，它已

被应用于变

分近似 (Opper and Archambeau,

2009) 和随

机生成神经

网

络 (Bengio

et al., 2013b; Kingma,

2013; Kingma and Welling,

2014b,a; Rezende et al.,

2014; Goodfellow et al.,

2014c)。许多网

络，如去噪自

编码器或使

用 Dropout 的正则

化

网络，也被自

然地设计为

将噪声作为

输入，而不需

要任何特殊

的重参数化

就能使

噪声

独立于模型

。

20.9.1 通过离散随

机操作的反

向传播

当模

型发射离散

变量

y 时，重参

数化技巧不

再适用。假设

模型采用输

入 x 和参

数 θ，两

者都封装在

向量 ω 中，并且

将它们与随

机噪声

z 组合

以产生 y：

y

= f(z; ω). (20.58)

因为

y 是离散的，f 必

须是一个阶

跃函数。阶跃

函数的导数

在任何点都

是没用的。

在

每个阶跃边

界，导数是未

定义的，但这

是一个小问

题。大问题是

导数在阶跃

边界

之间的

区域几乎处

处为零。因此

，任何代价函

数 J(y) 的导数无

法给出如何

更新模型

参

数

θ 的任何信

息。

20.9 通过随机

操作的反向

传播

589

REINFORCE 算法（REward Increment

= nonnegative Factor ×

Offset Rein￾forcement × Characteristic

Eligibility）提

供了定义一

系列简单而

强大解决方

案的框

架 (Williams, 1992)。其

核心思想是

，即使

J(f(z; ω)) 是具有

无用导数的

阶跃函数，

期

望代价

Ez∼p(z)J(f(z; ω)) 通常

是服从梯度

下降的光滑

函数。虽然当

y 是高维（或

者

是许多离散

随机决策组

合的结果）时

，该期望通常

是难解的，但

我们可以使

用蒙

特卡罗

平均进行无

偏估计。梯度

的随机估计

可以与 SGD 或其

他基于随机

梯度的优化

技术一起使

用。

通过简单

地微分期望

成本，我们可

以推导出 REINFORCE 最

简单的版本

：

Ez[J(y)]

= ∑

y

J(y)p(y),

(20.59)

∂E[J(y)]

∂ω

=

∑

y

J(y)

∂p

∂

(

ω

y)

(20.60)

=

∑

y

J(y)p(y)

∂ log

∂ω

p(y)

(20.61)

≈

1

m

m∑

y

(i)∼p(y),i=1

J(y

(i)

)

∂

log p(y

(i)

)

∂ω

. (20.62)

式

(20.60) 依赖于 J 不

直接引用

ω 的

假设。放松这

个假设来扩

展该方法是

简单的。

式 (20.61)

利

用对数的导

数规则，∂ log

∂ω

p(y)

= p(

1

y)

∂p

∂

(

ω

y)。式 (20.62) 给

出了该梯度

的无

偏蒙特

卡罗估计。

在

本节中我们

写的 p(y)，可以等

价地写成 p(y |

x)。这

是因为 p(y) 由 ω

参

数化，

并且如

果 x 存在，ω

包含

θ 和 x 两者。

简单

REINFORCE 估计的一个

问题是其具

有非常高的

方差，需要采

y 的许多

样本

才能获得对

梯度的良好

估计，或者等

价地，如果仅

绘制一个样

本，SGD

将收

敛得

非常缓慢并

将需要较小

的学习率。通

过使用 方差

减小（variance reduction）方

法 (Wilson, 1984; L’Ecuyer,

1994)，可

以地减少该

估计的方差

。想法是修改

估计量，

使其

预期值保持

不变，但方差

减小。在 REINFORCE 的情

况下提出的

方差减小方

法，涉及计算

用于偏移

J(y) 的

基线 (baseline)。注意，不

依赖于 y

的任

何偏移 b(w)

590 第二

十章

深度生

成模型

都不

会改变估计

梯度的期望

，因为

Ep(y)

[

∂ log

∂ω

p(y)

]

=

∑

y

p(y)

∂ log p(y)

∂ω

(20.63)

=

∑

y

∂p

∂

(

ω

y)

(20.64)

=

∂

∂

ω

∑

y

p(y) = ∂

∂

ω

1 =

0, (20.65)

这意味

着

Ep(y)

[

(J(y) − b(ω))∂

log

∂ω

p(y)

]

= Ep(y)

[

J(y)

∂ log

∂ω

p(y)

]

− b(ω)Ep(y)

[

∂ log

∂ω

p(y)

]

(20.66)

= Ep(y)

[

J(y)

∂ log

∂ω

p(y)

]

.

(20.67)

此外，我们

可以通过计

算 (J(y) −

b(ω)) ∂ log

∂ω

p(y) 关于 p(y) 的方

差，并关于

b(ω) 最

小

化获得最

优 b(ω)。我们发现

这个最佳基

线

b

∗

(ω)i 对于向量

ω

的每个元素

ωi 是不同

的：

b

∗

(ω)i =

Ep(y)

[

J(y)

∂ log

p(y)

2

∂ωi

]

Ep(y)

[

∂ log

p(y)

2

∂ωi

]

. (20.68)

相

对于 ωi

的梯度

估计则变为

(J(y) − b(ω)i)

∂

log p(y)

∂ωi

,

(20.69)

其中 b(ω)i 估计上

述

b

∗

(ω)i。获得估计

b 通常需要将

额外输出添

加到神经网

络，并训

练新

输出对 ω 的每

个元素估计

Ep(y)

[J(y)

∂ log p(y)

2

∂ωi

] 和 Ep(y)

[

∂ log p(y)

2

∂ωi

]。这些额外

的输

出可以

用均方误差

目标训练，对

于给定的

ω，从

p(y) 采样 y 时，分别

用

J(y)

∂ log p(y)

2

∂ωi

和 ∂

log

∂ω

p(y)

2

i 作目标

。然后可以将

这些估计代

入式(20.68) 就能恢

复估计 b。Mnih

and

Gregor (2014) 倾向

于使用通过

目标

J(y) 训练的

单个共享输

出（跨越 ω 的所

有元素

i），并使

用 b(ω) ≈ Ep(y)

[J(y)] 作为基线

。

在强化学习

背景下引入

的方差减小

方法 (Sutton

et al., 2000; Weaver

and Tao,

2001)，Dayan (1990)

推广了

二值奖励的

前期工作。可

以参考 Bengio et al.

(2013b)、

20.10 有向

生成网络 591

Mnih and Gregor (2014)、Ba

et al. (2014)、Mnih et

al. (2014) 或

Xu et

al. (2015) 中

在深度学

习的背景下

使用减少方

差的

REINFORCE 算法的

现代例子。除

了使用与输

入相关的基

线 b(ω)，Mnih and

Gregor (2014) 发现可以

在训练期间

调整 (J(y)−b(ω))

的尺度

（即除以训练

期间的移动

平均估计的

标准差），即作

为一种适应

性学习率，可

以抵消训练

过程中该量

大小发生的

重要变化的

影响。Mnih and Gregor (2014)

称之

为

启发式方差

归一化 (variance normalization)。

基于

REINFORCE 的估计器可

以被理解为

将 y 的选择与

J(y)

的对应值相

关联

来估计

梯度。如果在

当前参数化

下不太可能

出现 y 的良好

值，则可能需

要很长时间

来偶然获得

它，并且获得

所需信号的

配置应当被

加强。

20.10 有向生

成网络

如第

十六章所讨

论的，有向图

模型构成了

一类突出的

图模型。虽然

有向图模型

在

更大的机

器学习社群

中非常流行

，但在较小的

深度学习社

群中，大约直

到

2013 年它

们都

掩盖在无向

模型（如 RBM）的光

彩之下。

在本

节中，我们回

顾一些传统

上与深度学

习社群相关

的标准有向

图模型。

我们

已经描述过

部分有向的

模型——深度信

念网络。我们

还描述过可

以被认为

是

浅度有向生

成模型的稀

疏编码模型

。尽管在样本

生成和密度

估计方面表

现不佳，

在深

度学习的背

景下它们通

常被用作特

征学习器。我

们接下来描

述多种深度

完全有

向的

模型。

20.10.1 sigmoid 信念网

络

sigmoid 信念网络

(Neal, 1990) 是一种具有

特定条件概

率分布的有

向图模型的

简

单形式。一

般来说，我们

可以将 sigmoid 信念

网络视为具

有二值向量

的状态 s，其中

状态的每个

元素都受其

祖先影响：

p(si) = σ

(∑

j<i

Wj,isj + bi

)

. (20.70)

sigmoid

信

念网络最常

见的结构是

被分为许多

层的结构，其

中原始采样

通过一系

列

多个隐藏层

进行，然后最

终生成可见

层。这种结构

与深度信念

网络非常相

似，但

它们在

采样过程开

始时的单元

彼此独立，而

不是从受限

玻尔兹曼机

采样。这种结

构

592

第二十章

深度生成模

型

由于各种

原因而令人

感兴趣。一个

原因是该结

构是可见单

元上概率分

布的通用近

似，

即在足够

深的情况下

，可以任意良

好地近似二

值变量的任

何概率分布

（即使各个层

的宽度受限

于可见层的

维度）(Sutskever and

Hinton, 2008)。

虽然生

成可见单元

的样本在 sigmoid

信

念网络中是

非常高效的

，但是其他大

多

数操作不

是很高效。给

定可见单元

，对隐藏单元

的推断是难

解的。因为变

分下界涉

及

对包含整个

层的团求期

望，均匀场推

断也是难以

处理的。这个

问题一直困

难到足

以限

制有向离散

网络的普及

。

在 sigmoid 信念网络

中执行推断

的一种方法

是构造专用

于 sigmoid

信念网络

的

不同下界

(Saul et al.,

1996)。这种方法只

适用于非常

小的网络。另

一种方法是

使用学

成推

断机制，如第

19.5 节中描述的

。Helmholtz 机

(Dayan et al., 1995;

Dayan and

Hinton, 1996)

结合了一

个 sigmoid 信念网络

与一个预测

隐藏单元上

均匀场分布

参数

的推断

网络。sigmoid

信念网

络的现代方

法 (Gregor et al.,

2014; Mnih and Gregor,

2014) 仍然使用

这种推断网

络的方法。因

为潜变量的

离散本质，这

些技术仍然

是困

难的。人

们不能简单

地通过推断

网络的输出

反向传播，而

必须使用相

对不可靠的

机

制即通过

离散采样过

程进行反向

传播（如第

20.9.1 节

所述）。最近基

于重要采样

、重

加权的醒

眠(Bornschein and

Bengio, 2015) 或双向 Helmholtz

机

(Bornschein et al.,

2015)

的方法使得

我们可以快

速训练 sigmoid 信念

网络，并在基

准任务上达

到最好的

表

现。

sigmoid 信念网络

的一种特殊

情况是没有

潜变量的情

况。在这种情

况下学习是

高

效的，因为

没有必要将

潜变量边缘

化到似然之

外。一系列称

为自回归网

络的模型将

这个完全可

见的信念网

络泛化到其

他类型的变

量（除二值变

量）和其他结

构（除对

数线

性关系）的条

件分布。自回

归网络将在

第

20.10.7 节中描述

。

20.10.2 可微生成器

网络

许多生

成模型基于

使用可微 生

成器网络（generator network）的

想法。这种模

型使用可微

函数 g(z;

θ

(g)

) 将潜变

量

z 的样本变

换为样本 x 或

样本

x 上的分

布，可

微函数

通常可以由

神经网络表

示。这类模型

包括将生成

器网络与推

断网络配对

的变

分自编

码器、将生成

器网络与判

别器网络配

对的生成式

对抗网络，以

及孤立地训

练生

成器网

络的技术。

生

成器网络本

质上仅是用

于生成样本

的参数化计

算过程，其中

的体系结构

提供

了从中

采样的可能

分布族以及

选择这些族

内分布的参

数。

20.10

有向生成

网络 593

作为示

例，从具有均

值 µ

和协方差

Σ 的正态分布

绘制样本的

标准过程是

将来自

零均

值和单位协

方差的正态

分布的样本

z 馈送到非常

简单的生成

器网络中。这

个生

成器网

络只包含一

个仿射层：

x = g(z)

= µ + Lz,

(20.71)

其

中 L 由

Σ 的 Cholesky 分解

给出。

伪随机

数发生器也

可以使用简

单分布的非

线性变换。例

如，逆变换采

样 (inverse

transform sampling)(Devroye,

2013) 从 U(0, 1)

中采一

个标量 z，并且

对标量 x 应用

非线性变换

。在这种情况

下，g(z)

由累积分

布函数 F(x) = ∫

x

−∞ p(v)dv 的反

函数给

出。如

果我们能够

指定 p(x)，在 x 上积

分，并取所得

函数的反函

数，我们不用

通过

机器学

习就能从 p(x) 进

行采样。

为了

从更复杂的

分布（难以直

接指定、难以

积分或难以

求所得积分

的反函数）

中

生成样本，我

们使用前馈

网络来表示

非线性函数

g 的参数族，并

使用训练数

据

来推断参

数以选择所

期望的函数

。

我们可以认

为

g 提供了变

量的非线性

变化，将 z 上的

分布变换成

x

上想要的分

布。

回顾式 (3.47) ，对

于可求反函

数的、可微的

、连续的

g，

pz(z) = px(g(z))

det(

∂g

∂z

)

.

(20.72)

这隐

含地对 x 施加

概率分布：

px(x) = pz(g

−1

(x))

| det(

∂g

∂z

)|

. (20.73)

当

然，取决于 g 的

选择，这个公

式可能难以

评估，因此我

们经常需要

使用间接学

习

g

的方法，而

不是直接尝

试最大化 log p(x)。

在

某些情况下

，我们使用

g 来

定义 x 上的条

件分布，而不

是使用

g 直接

提供 x

的样本

。例如，我们可

以使用一个

生成器网络

，其最后一层

由

sigmoid 输出组成

，可

以提供 Bernoulli

分

布的平均参

数：

p(xi = 1

| z) = g(z)i

. (20.74)

在这种情

况下，我们使

用 g

来定义 p(x | z)

时

，我们通过边

缘化 z 来对 x

施

加分布：

p(x) = Ezp(x

| z). (20.75)

594

第二

十章 深度生

成模型

两种

方法都定义

了一个分布

pg(x)，并允许我们

使用第 20.9

节中

的重参数化

技

巧来训练

pg 的各种评估

准则。

表示生

成器网络的

两种不同方

法（发出条件

分布的参数

相对直接发

射样品）具

有

互补的优缺

点。当生成器

网络在 x 上定

义条件分布

时，它不但能

生成连续数

据，

也能生成

离散数据。当

生成器网络

直接提供采

样时，它只能

产生连续的

数据（我们

可

以在前向传

播中引入离

散化，但这样

做意味着模

型不再能够

使用反向传

播进行训

练

）。直接采样的

优点是，我们

不再被迫使

用条件分布

（可以容易地

写出来并由

人类

设计者

进行代数操

作的形式）。

基

于可微生成

器网络的方

法是由分类

可微前馈网

络中梯度下

降的成功应

用而推

动的

。在监督学习

的背景中，基

于梯度训练

学习的深度

前馈网络在

给定足够的

隐藏

单元和

足够的训练

数据的情况

下，在实践中

似乎能保证

成功。这个同

样的方案能

成

功转移到

生成式建模

上吗？

生成式

建模似乎比

分类或回归

更困难，因为

学习过程需

要优化难以

处理的准则

。

在可微生成

器网络的情

况中，准则是

难以处理的

，因为数据不

指定生成器

网络的输

入

z 和输出 x。在监

督学习的情

况下，输入

x 和

输出 y 同时给

出，并且优化

过程只

需学

习如何产生

指定的映射

。在生成建模

的情况下，学

习过程需要

确定如何以

有用

的方式

排布 z 空间，以

及额外的如

何从

z 映射到

x。

Dosovitskiy et

al. (2015) 研究了一个

简化问题，其

中 z

和 x 之间的

对应关系已

经给出。具体

来说，训练数

据是计算机

渲染的椅子

图。潜变量 z

是

渲染引擎的

参数，

描述了

椅子模型的

选择、椅子的

位置以及影

响图像渲染

的其他配置

细节。使用这

种

合成的生

成数据，卷积

网络能够学

习将图像内

容的描述 z

映

射到渲染图

像的近似 x。

这

表明当现代

可微生成器

网络具有足

够的模型容

量时，足以成

为良好的生

成模型，

并且

现代优化算

法具有拟合

它们的能力

。困难在于当

每个

x 的 z 的值

不是固定的

且

在每次训

练前是未知

时，如何训练

生成器网络

。

在接下来的

章节中，我们

讨论仅给出

x 的训练样本

，训练可微生

成器网络的

几

种方法。

20.10.3 变

分自编码器

变分自编码

器（variational auto-encoder, VAE）(Kingma,

2013; Rezende et al.,

2014) 是一个使

用学好的近

似推断的有

向模型，可以

纯粹地使用

基于梯度的

方法进行

20.10 有

向生成网络

595

训练。

为了从

模型生成样

本，VAE 首先从编

码分布 pmodel(z)

中采

样 z。然后使样

本通

过可微

生成器网络

g(z)。最后，从分布

pmodel(x; g(z))

= pmodel(x | z)

中采样 x。然

而

在训练期间

，近似推断网

络（或编码器

）q(z |

x) 用于获得 z，而

pmodel(x |

z) 则

被视为解

码器网络。

变

分自编码器

背后的关键

思想是，它们

可以通过最

大化与数据

点

x 相关联的

变

分下界 L(q)

来

训练：

L(q) = Ez∼q(z|x)

log pmodel(z, x) +

H(q(z | x)) (20.76)

= Ez∼q(z|x)

log pmodel(x

| z) − DKL(q(z

| x) || pmodel(z))

(20.77)

≤ log pmodel(x).

(20.78)

在式 (20.76) 中

，我们将第一

项视为潜变

量的近似后

验下可见和

隐藏变量的

联合对数

似

然性（正如 EM 一

样，不同的是

我们使用近

似而不是精

确后验）。第二

项则可视

为

近似后验的

熵。当

q 被选择

为高斯分布

，其中噪声被

添加到预测

平均值时，最

大

化该熵项

促使该噪声

标准偏差的

增加。更一般

地，这个熵项

鼓励变分后

验将高概率

质量置于可

能已经产生

x 的许多

z 值上

，而不是坍缩

到单个估计

最可能值的

点。在

式 (20.77)

中，我

们将第一项

视为在其他

自编码器中

出现的重构

对数似然。第

二项试

图使

近似后验分

布 q(z |

x) 和模型先

验 pmodel(z) 彼此接近

。

变分推断和

学习的传统

方法是通过

优化算法推

断 q，通常是迭

代不动点方

程

（第19.4 节）。这些

方法是缓慢

的，并且通常

需要以闭解

形式计算

Ez∼q log pmodel(z, x)。

变

分自编码器

背后的主要

思想是训练

产生 q 参数的

参数编码器

（有时也称为

推断网

络或

识别模型）。只

要

z 是连续变

量，我们就可

以通过从 q(z |

x) = q(z; f(x;

θ)) 中

采样 z 的样本

反向传播，以

获得相对于

θ

的梯度。学习

则仅包括相

对于编码器

和解

码器的

参数最大化

L。L 中的所有期

望都可以通

过蒙特卡罗

采样来近似

。

变分自编码

器方法是优

雅的，理论上

令人愉快的

，并且易于实

现。它也获得

了出

色的结

果，是生成式

建模中的最

先进方法之

一。它的主要

缺点是从在

图像上训练

的变

分自编

码器中采样

的样本往往

有些模糊。这

种现象的原

因尚不清楚

。一种可能性

是

模糊性是

最大似然的

固有效应，因

为我们需要

最小化 DKL(pdata||pmodel)。如图

3.6

所

示，这意味

着模型将为

训练集中出

现的点分配

高的概率，但

也可能为其

他点分配高

的

概率。还有

其他原因可

以导致模糊

图像。模型选

择将概率质

量置于模糊

图像而不是

空

间的其他

部分的部分

原因是实际

使用的变分

自编码器通

常在

pmodel(x; g(z)) 使用高

斯分布。最大

化这种分布

似然性的下

界与训练具

有均方误差

的传统自编

码器类似，

596

第

二十章 深度

生成模型

这

意味着它倾

向于忽略由

少量像素表

示的特征或

其中亮度变

化微小的像

素。如 Theis

et al. (2015) 和

Huszar (2015) 指出

的，该问题不

是 VAE

特有的，而

是与优化对

数

似然或 DKL(pdata||pmodel) 的

生成模型共

享的。现代

VAE 模

型另一个麻

烦的问题是

，

它们倾向于

仅使用 z

维度

中的小子集

，就像编码器

不能够将具

有足够局部

方向的输

入

空间变换到

边缘分布与

分解前匹配

的空间。

VAE 框架

可以直接扩

展到大范围

的模型架构

。相比玻尔兹

曼机，这是关

键的优

势，因

为玻尔兹曼

机需要非常

仔细地设计

模型来保持

易解性。VAE 可以

与广泛的可

微算子族一

起良好工作

。一个特别复

杂的 VAE 是深度

循环注意写

者

(DRAW) 模型

(Gregor et

al., 2015)。DRAW 使用

一个循环编

码器和循环

解码器并结

合注意力机

制。

DRAW

模型的生

成过程包括

顺序访问不

同的小图像

块并绘制这

些点处的像

素值。

我们还

可以通过在

VAE 框架内使用

循环编码器

和解码器来

定义变分 RNN

(Chung

et al., 2015b)

来

扩展 VAE 以生成

序列。从传统

RNN 生成样本仅

在输出空间

涉及

非确定

性操作。而变

分 RNN 还具有由

VAE 潜变量捕获

的潜在更抽

象层的随机

变化

性。

VAE 框架

已不仅仅扩

展到传统的

变分下界，还

有重要加权

自编码器(importance￾weighted autoencoder)(Burda

et al., 2015) 的

目标：

Lk(x, q) = Ez(1),...,z(k)∼q(z|x)

[

log k

1

k

∑

i=1

pmodel(x,

z

(i)

)

q(z

(i)

| x)

]

. (20.79)

这个新

的目标在 k

= 1 时

等同于传统

的下界 L。然而

，它也可以被

解释为基于

提议

分布 q(z | x)

中

z 的重要采样

而形成的真

实 log pmodel(x)

估计。重要

加权自编码

器目

标也是

log pmodel(x) 的下界，并且

随着

k 增加而

变得更紧。

变

分自编码器

与 MP-DBM

和其他涉

及通过近似

推断图的反

向传播方法

有一些

有趣

的联系 (Goodfellow et

al., 2013d; Stoyanov et

al., 2011; Brakel et

al., 2013)。

这些

以前的方法

需要诸如均

匀场不动点

方程的推断

过程来提供

计算图。变分

自编码

器被

定义为任意

计算图，这使

得它能适用

于更广泛的

概率模型族

，因为它不需

要将

模型的

选择限制到

具有易处理

的均匀场不

动点方程的

那些模型。变

分自编码器

还具

有增加

模型对数似

然边界的优

点，而 MP-DBM 和相关

模型的准则

更具启发性

，并

且除了使

近似推断的

结果准确外

很少有概率

的解释。变分

自编码器的

一个缺点是

它

仅针对一

个问题学习

推断网络，即

给定 x 推断

z。较

老的方法能

够在给定任

何其他

变量

子集的情况

下对任何变

量子集执行

近似推断，因

为均匀场不

动点方程指

定如何

在所

有这些不同

问题的计算

图之间共享

参数。

20.10

有向生

成网络 597

变分

自编码器的

一个非常好

的特性是，同

时训练参数

编码器与生

成器网络的

组

合迫使模

型学习一个

编码器可以

捕获的可预

测的坐标系

。这使得它成

为一个优秀

的流形学习

算法。图

20.6 展示

了由变分自

编码器学到

的低维流形

的例子。图中

所示

的情况

之一，算法发

现了存在于

面部图像中

两个独立的

变化因素：旋

转角和情绪

表

达。

图 20.6: 由变

分自编码器

学习的高维

流形在 2

维坐

标系中的示

例 (Kingma and Welling,

2014a)。

我们可以

在纸上直接

绘制两个可

视化的维度

，因此可以使

用 2 维潜在编

码训练模型

来了解模型

的

工作原理

（即使我们认

为数据流形

的固有维度

要高得多）。图

中所示的图

像不是来自

训练集的样

本，

而是仅仅

通过改变 2 维

‘‘编码”z，由模型

p(x

| z) 实际生成的

图像 x（每个图

像对应于

‘‘编

码”z

位于 2 维均

匀网格的不

同选择）。(左)

Frey 人

脸流形的 2 维

映射。其中一

个维度（水平

）已发现

大致

对应于面部

的旋转，而另

一个（垂直）对

应于情绪表

达。(右) MNIST 流形的

2 维映射。

20.10.4 生成

式对抗网络

生成式对抗

网络（generative adversarial network,

GAN）(Goodfellow et al.,

2014c)

是基于

可微生成器

网络的另一

种生成式建

模方法。

生成

式对抗网络

基于博弈论

场景，其中生

成器网络必

须与对手竞

争。生成器网

络直接产生

样本 x =

g(z; θ

(g)

)。其对手

，

判别器网络

（discriminator network），试

图区分从

训练数据抽

取的样本和

从生成器抽

取的样本。判

别器发出由

d(x; θ

(d)

) 给出

的概率

值，指示

x 是真

实训练样本

而不是从模

型抽取的伪

造样本的概

率。

598 第二十章

深度生成模

型

形式化表

示生成式对

抗网络中学

习的最简单

方式是零和

游戏，其中函

数

v(θ

(g)

,

θ

(d)

) 确定判别

器的收益。生

成器接收

−v(θ

(g)

, θ

(d)

) 作

为它自己的

收益。

在学习

期间，每个玩

家尝试最大

化自己的收

益，因此收敛

在

g

∗ = arg

min

g

max

d

v(g, d). (20.80)

v

的默认选

择是

v(θ

(g)

,

θ

(d)

) =

Ex∼pdata log d(x) +

Ex∼pmodel log(1 − d(x)).

(20.81)

这驱使

判别器试图

学习将样品

正确地分类

为真的或伪

造的。同时，生

成器试图欺

骗

分类器以

让其相信样

本是真实的

。在收敛时，生

成器的样本

与实际数据

不可区分，并

且判别器处

处都输出 2

1。然

后就可以丢

弃判别器。

设

计 GAN 的主要动

机是学习过

程既不需要

近似推断也

不需要配分

函数梯度的

近似。当

maxd v(g, d) 在

θ

(g) 中

是凸的（例如

，在概率密度

函数的空间

中直接执行

优化的情况

）时，该过程保

证收敛并且

是渐近一致

的。

不幸的是

，在实践中由

神经网络表

示的

g 和 d 以及

maxd

v(g, d) 不凸时，GAN 中

的

学习可能是

困难的。Goodfellow (2014) 认为

不收敛可能

会引起 GAN

的欠

拟合问

题。一

般来说，同时

对两个玩家

的成本梯度

下降不能保

证达到平衡

。例如，考虑价

值函数 v(a, b)

= ab，其中

一个玩家控

制 a 并产生成

本

ab，而另一玩

家控制 b 并接

收成本 −ab。如果

我们将每个

玩家建模为

无穷小的梯

度步骤，每个

玩家以另一

个玩

家为代

价降低自己

的成本，则 a 和

b 进入稳定的

圆形轨迹，而

不是到达原

点处的平

衡

点。注意，极小

极大化游戏

的平衡不是

v 的局部最小

值。相反，它们

是同时最小

化的两个玩

家成本的点

。这意味着它

们是 v 的鞍点

，相对于第一

个玩家的参

数是局

部最

小值，而相对

于第二个玩

家的参数是

局部最大值

。两个玩家可

以永远轮流

增加

然后减

少 v，而不是正

好停在玩家

没有能力降

低其成本的

鞍点。目前不

知道这种不

收

敛的问题

会在多大程

度上影响

GAN。

Goodfellow (2014) 确

定了另一种

替代的形式

化收益公式

，其中博弈不

再是零和，

每

当判别器最

优时，具有与

最大似然学

习相同的预

期梯度。因为

最大似然训

练收敛，

这种

GAN 博弈的重述

在给定足够

的样本时也

应该收敛。不

幸的是，这种

替代的形

式

化似乎并没

有提高实践

中的收敛，可

能是由于判

别器的次优

性或围绕期

望梯度的

高

方差。

在真实

实验中，GAN 博弈

的最佳表现

形式既不是

零和也不等

价于最大似

然，而

是Goodfellow

et al. (2014c) 引入

的带有启发

式动机的不

同形式化。在

这种最佳性

能

20.10 有向生成

网络 599

的形式

中，生成器旨

在增加判别

器发生错误

的对数概率

，而不是旨在

降低判别器

进

行正确预

测的对数概

率。这种重述

仅仅是观察

的结果，即使

在判别器确

信地拒绝所

有生成器样

本的情况下

，它也能导致

生成器代价

函数的导数

相对于判别

器的对数保

持很大。

稳定

GAN 学习仍然是

一个开放的

问题。幸运的

是，当仔细选

择模型架构

和

超参数时

，GAN

学习效果很

好。Radford et al. (2015)

设计了一

个深度卷积

GAN

（DCGAN），在图像合成

的任务上表

现非常好，并

表明其潜在

的表示空间

能捕获到变

化的重要因

素，如图 15.9 所示

。图

20.7 展示了 DCGAN 生

成器生成的

图像示例。

图

20.7: 在 LSUN 数据集上

训练后，由

GAN 生

成的图像。(左

) 由 DCGAN

模型生成

的卧室图

像

，经Radford et al.

(2015) 许可转载

。(右) 由 LAPGAN

模型生

成的教堂图

像，经 Denton et al.

(2015) 许可转

载。

GAN 学习问题

也可以通过

将生成过程

分成许多级

别的细节来

简化。我们可

以训

练有条

件的 GAN (Mirza and

Osindero, 2014)，并学习

从分布 p(x |

y) 中采

样，而不

是简

单地从边缘

分布 p(x)

中采样

。Denton et al. (2015)

表明一系列

的条件 GAN 可

以

被训练为首

先生成非常

低分辨率的

图像，然后增

量地向图像

添加细节。由

于使用

拉普

拉斯金字塔

来生成包含

不同细节水

平的图像，这

种技术被称

为 LAPGAN 模型。

LAPGAN

生成

器不仅能够

欺骗判别器

网络，而且能

够欺骗人类

观察者，实验

主体将

高达

40％的网络输出

识别为真实

数据。请看图

20.7 中 LAPGAN

生成器生

成的图像

示

例。

GAN 训练过程

中一个不寻

常的能力是

它可以拟合

向训练点分

配零概率的

概率

分布。生

成器网络学

习跟踪其点

在某种程度

上类似于训

练点的流形

，而不是最大

化

特定点的

对数概率。有

点矛盾的是

，这意味着模

型可以将负

无穷大的对

数似然分配

600 第二十章 深

度生成模型

给测试集，同

时仍然表示

人类观察者

判断为能捕

获生成任务

本质的流形

。这不是明

显

的优点或缺

点，并且只要

向生成器网

络最后一层

所有生成的

值添加高斯

噪声，就

可以

保证生成器

网络向所有

点分配非零

概率。以这种

方式添加高

斯噪声的生

成器网

络从

相同分布的

采样，即使用

生成器网络

参数化条件

高斯分布的

均值所获得

的分布。

Dropout

似乎

在判别器网

络中很重要

。特别地，在计

算生成器网

络的梯度时

，单

元应当被

随机地丢弃

。使用权重除

以二的确定

性版本的判

别器的梯度

似乎不是那

么

有效。同样

，从不使用 Dropout

似

乎会产生不

良的结果。

虽

然 GAN 框架被设

计为用于可

微生成器网

络，但是类似

的原理可以

用于训练其

他类型的模

型。例如，自监

督提升

( self-supervised boosting) 可以

用于训练

RBM 生

成器以欺骗

逻辑回归判

别器 (Welling et

al., 2002)。

20.10.5 生成矩

匹配网络

生

成矩匹配网

络（generative moment matching network）(Li

et al., 2015; Dzi￾ugaite

et al., 2015) 是另一种

基于可微生

成器网络的

生成模型。与

VAE

和 GAN 不

同，它们

不需要将生

成器网络与

任何其他网

络配对，如不

需要与用于

VAE

的推断网

络

配对，也不需

要与 GAN 的判别

器网络。

生成

矩匹配网络

使用称为 矩

匹配（moment matching）的技术

训练。矩匹配

背

后的基本

思想是以如

下的方式训

练生成器——令

模型生成的

样本的许多

统计量尽可

能与训练集

中的样本相

似。在此情景

下，

矩（moment）是对随

机变量不同

幂的期

望。例

如，第一矩是

均值，第二矩

是平方值的

均值，以此类

推。多维情况

下，随机向

量

的每个元素

可以被升高

到不同的幂

，因此使得矩

可以是任意

数量的形式

Ex

∏

i

x

n

i

i

, (20.82)

其中

n = [n1, n2,

. . . ,

nd]

⊤ 是一个

非负整数的

向量。

在第一

次检查时，这

种方法似乎

在计算上是

不可行的。例

如，如果我们

想匹配

形式

为 xixj 的所有矩

，那么我们需

要最小化在

x 的维度上是

二次的多个

值之间的

差

。此外，甚至匹

配所有第一

和第二矩将

仅足以拟合

多变量高斯

分布，其仅捕

获值

之间的

线性关系。我

们使用神经

网络的野心

是捕获复杂

的非线性关

系，这将需要

更

多的矩。GAN 通

过使用动态

更新的判别

器避免了穷

举所有矩的

问题，该判别

器自动

将其

注意力集中

在生成器网

络最不匹配

的统计量上

。

20.10 有向生成网

络 601

相反，我们

可以通过最

小化一个被

称为 最大平

均偏差（maximum mean dis￾crepancy,

MMD）(Schölkopf and Smola, 2002;

Gretton et al., 2012)

的代

价函数来

训

练生成矩匹

配网络。该代

价函数通过

向核函数定

义的特征空

间隐式映射

，在无限

维空

间中测量第

一矩的误差

，使得对无限

维向量的计

算变得可行

。当且仅当所

比较

的两个

分布相等时

，MMD

代价为零。

从

可视化方面

看，来自生成

矩匹配网络

的样本有点

令人失望。幸

运的是，它们

可以通过将

生成器网络

与自编码器

组合来改进

。首先，训练自

编码器以重

构训练集。

接

下来，自编码

器的编码器

用于将整个

训练集转换

到编码空间

。然后训练生

成器网

络以

生成编码样

本，这些编码

样本可以经

解码器映射

到视觉上令

人满意的样

本。

与 GAN 不同，代

价函数仅关

于一批同时

来自训练集

和生成器网

络的实例定

义。

我们不可

能将训练更

新作为一个

训练样本或

仅来自生成

器网络的一

个样本的函

数。

这是因为

必须将矩计

算为许多样

本的经验平

均值。当批量

大小太小时

，MMD 可能

低估采

样分布的真

实变化量。有

限的批量大

小都不足以

大到完全消

除这个问题

，但

是更大的

批量大小减

少了低估的

量。当批量大

小太大时，训

练过程就会

慢得不可行

，

因为计算单

个小梯度步

长必须一下

子处理许多

样本。

与 GAN 一样

，即使生成器

网络为训练

点分配零概

率，仍可以使

用

MMD 训练生

成

器网络。

20.10.6

卷积

生成网络

当

生成图像时

，将卷积结构

的引入生成

器网络通常

是有用的（见

Goodfellow

et al.

(2014c) 或 Dosovitskiy et

al. (2015) 的例子）。为

此，我们使用

卷积算子的

‘‘转

置’’，如第9.5

节

所述。这种方

法通常能产

生更逼真的

图像，并且比

不使用参数

共享的

全连

接层使用更

少的参数。

用

于识别任务

的卷积网络

具有从图像

到网络顶部

的某些概括

层（通常是类

标签）

的信息

流。当该图像

通过网络向

上流动时，随

着图像的表

示变得对于

有害变换保

持

不变，信息

也被丢弃。在

生成器网络

中，情况恰恰

相反。要生成

图像的表示

通过网络

传

播时必须添

加丰富的详

细信息，最后

产生图像的

最终表示，这

个最终表示

当然是

带有

所有细节的

精细图像本

身（具有对象

位置、姿势、纹

理以及明暗

）。在卷积识别

网络中丢弃

信息的主要

机制是池化

层。而生成器

网络似乎需

要添加信息

。由于大多

数

池化函数不

可逆，我们不

能将池化层

求逆后放入

生成器网络

。更简单的操

作是仅

仅增

加表示的空

间大小。似乎

可接受的方

法是使用 Dosovitskiy et al.

(2015) 引

入的

602 第二十

章

深度生成

模型

‘‘去池化

’’。该层对应于

某些简化条

件下最大池

化的逆操作

。首先，最大池

化操作的

步

幅被约束为

等于池化区

域的宽度。其

次，每个池化

区域内的最

大输入被假

定为左

上角

的输入。最后

，假设每个池

化区域内所

有非最大的

输入为零。这

些是非常强

和

不现实的

假设，但它们

允许我们对

最大池化算

子求逆。逆去

池化的操作

分配一个零

张量，然后将

每个值从输

入的空间坐

标 i 复制到输

出的空间坐

标 i

× k。整数值 k 定

义池化区域

的大小。即使

驱动去池化

算子定义的

假设是不现

实的，后续层

也能够学

习

补偿其不寻

常的输出，所

以由整体模

型生成的样

本在视觉上

令人满意。

20.10.7 自

回归网络

自

回归网络是

没有潜在随

机变量的有

向概率模型

。这些模型中

的条件概率

分布

由神经

网络表示（有

时是极简单

的神经网络

，例如逻辑回

归）。这些模型

的图结构

是

完全图。它们

可以通过概

率的链式法

则分解观察

变量上的联

合概率，从而

获得形

如 P(xd

| xd−1, . .

. , x1) 条

件概率的乘

积。这样的模

型被称为

完

全可见的贝

叶斯网

络（fully-visible Bayes networks,

FVBN），并

成功地以许

多形式使用

，首先是对每

个条件分布

逻辑回归 (Frey, 1998) ，然

后是带有隐

藏单元的神

经网络

(Bengio and

Bengio, 2000b;

Larochelle and Murray, 2011)。在某

些形式的自

回归网络中

，例如在

第 20.10.10 节

中描述的 NADE

(Larochelle and Murray, 2011)，我

们可以引入

参数共

享的

一种形式，它

能带来统计

优点（较少的

唯一参数）和

计算优势（较

少计算量）。

这

是深度学习

中反复出现

的主题——特征

重用的另一

个实例。

20.10.8 线性

自回归网络

自回归网络

的最简单形

式是没有隐

藏单元、没有

参数或特征

共享的形式

。每个

P(xi

| xi−1, .

. . , x1)

被参数

化为线性模

型（对于实值

数据的线性

回归，对于二

值数据

的逻

辑回归，对于

离散数据的

softmax回归）。这个模

型由 Frey (1998)

引入，当

有 d

个变量要

建模时，该模

型有 O(d

2

) 个参数

。如图 20.8

所示。

如

果变量是连

续的，线性自

回归网络只

是表示多元

高斯分布的

另一种方式

，只

能捕获观

察变量之间

线性的成对

相互作用。

线

性自回归网

络本质上是

线性分类方

法在生成式

建模上的推

广。因此，它们

具

有与线性

分类器相同

的优缺点。像

线性分类器

一样，它们可

以用凸损失

函数训练，并

且有时允许

闭解形式（如

在高斯情况

下）。像线性分

类器一样，模

型本身不提

供增加

20.10 有向

生成网络 603

xx11 xx22 xx33 xx44

PP((xx44 || xx11, x,

x22, x, x33))

PP((xx33

|| xx11, x, x22))

PP((xx22 || xx11))

PP((xx11))

xx11 xx22 xx33 xx44

图

20.8: 完全可见的

信念网络从

前 i −

1 个变量预

测第 i 个变量

。(上)

FVBN 的有向图

模型。(下)

对数

FVBN 相应的计算

图，其中每个

预测由线性

预测器作出

。

其容量的方

法，因此必须

使用其他技

术（如输入的

基扩展或核

技巧）来提高

容量。

20.10.9 神经自

回归网络

神

经自回归网

络

(Bengio and Bengio, 2000a,b)

具有与逻

辑自回归网

络相同的从

左到右的图

模型（图20.8 ），但在

该图模型结

构内采用不

同的条件分

布参数。新的

参

数化更强

大，它可以根

据需要随意

增加容量，并

允许近似任

意联合分布

。新的参数

化

还可以引入

深度学习中

常见的参数

共享和特征

共享原理来

改进泛化能

力。设计这

些

模型的动机

是避免传统

表格图模型

引起的维数

灾难，并与图

20.8 共享相同的

结构。

在表格

离散概率模

型中，每个条

件分布由概

率表表示，其

中所涉及的

变量的每个

可

能配置都

具有一个条

目和一个参

数。通过使用

神经网络，可

以获得两个

优点：

1. 通过具

有 (i −

1) × k 个输入和

k

个输出的神

经网络（如果

变量是离散

的并有 k

个值

，使用one-hot编码）参

数化每个 P(xi

| xi−1, . .

. , x1)，让

我们不需要

指数

量级参

数（和样本）的

情况下就能

估计条件概

率，然而仍然

能够捕获随

机变量

之间

的高阶依赖

性。

2. 不需要对

预测每个 xi

使

用不同的神

经网络，如图

20.9 所示的从左

到右连接，允

604 第二十章 深

度生成模型

许将所有神

经网络合并

成一个。等价

地，它意味着

为预测

xi 所计

算的隐藏层

特

征可以重

新用于预测

xi+k (k

> 0)。因此隐藏单

元被组织成

第 i 组中的所

有单

元仅依

赖于输入值

x1, . . .

, xi 的特定的组

。用于计算这

些隐藏单元

的参数被联

合优化以改

进对序列中

所有变量的

预测。这是重

用原理的一

个实例，这是

从循

环和卷

积网络架构

到多任务和

迁移学习的

场景中反复

出现的深度

学习原理。

xx11 xx22 xx33 xx44

hh11 hh22 hh33

PP((xx44

|| xx11, x, x22,

x, x33))

PP((xx33 ||

xx11, x, x22))

PP((xx22

|| xx11))

PP((xx11))

图

20.9:

神经自回归

网络从前 i − 1

个

变量预测第

i 个变量 xi，但经

参数化后，作

为 x1,

. . . ,

xi 函

数的特

征（表示为 hi

的

隐藏单元的

组）可以在预

测所有后续

变量 xi+1, xi+2, .

. . , xd

时重用

。

如在第 6.2.2.1 节中

讨论的，使神

经网络的输

出预测

xi 条件

分布的参数

，每

个 P(xi

| xi−1, . .

. , x1) 就可以

表示一个条

件分布。虽然

原始神经自

回归网络最

初

是在纯粹

离散多变量

数据（带有 sigmoid 输

出的 Bernoulli

变量或

softmax 输出

的 Multinoulli

变量

）的背景下评

估，但我们可

以自然地将

这样的模型

扩展到连续

变

量或同时

涉及离散和

连续变量的

联合分布。

20.10.10 NADE

神

经自回归密

度估计器（neural auto-regressive density estimator,

NADE）是

最

近非常成

功的神经自

回归网络的

一种形式 (Larochelle and

Murray, 2011)。与

Bengio

and Bengio

(2000b) 的原始神经

自回归网络

中的连接相

同，但 NADE 引入了

附加

的参数

共享方案，如

图20.10 所示。不同

组 j 的隐藏单

元的参数是

共享的。

从第

i 个输入 xi 到第

j

组隐藏单元

的第 k 个元素

h

(

k

j)

(j ≥

i) 的权重 Wj,k,i

′

是

20.10 有

向生成网络

605

组内共享的

：

W

′

j,k,i =

Wk,i. (20.83)

其余 j

< i 的权重

为零。

xx11

xx22 xx33 xx44

hh11

hh22 hh33

PP((xx44 ||

xx11, x, x22, x,

x33))

PP((xx33 || xx11,

x, x22))

PP((xx22 ||

xx11))

PP((xx11))

W:,1 W:,1

W:,1

W:,2 W:,2 W:,3

图 20.10: 神经

自回归密度

估计器（NADE）的示

意图。隐藏单

元被组织在

组 h

(j) 中，使得只

有输

入 x1,

. . . ,

xi 参与

计算 h

(i)

和预测

P(xj | xj−1, .

. . , x1)（对于

j > i）。NADE 使用特

定的权重共

享模式区别

于早期的神

经自回归网

络：Wj,k,i

′

= Wk,i 被共享于

所有从

xi 到任

何 j ≥

i 组中第 k 个

单元的权重

（在图中使用

相同的线型

表示复制权

重的每个实

例）。注意向量

(W1,i,

W2,i, . . .

, Wn,i)

记为 W:,i。

Larochelle and Murray (2011)

选择了

这种共享方

案，使得 NADE 模型

中的正

向传

播与在均匀

场推断中执

行的计算大

致相似，以填

充

RBM 中缺失的

输入。这个均

匀场推断对

应于运行具

有共享权重

的循环网络

，并且该推断

的第一步与

NADE 中的

相同。使

用

NADE 的唯一区

别是，连接隐

藏单元到输

出的输出权

重独立于连

接输入

单元

和隐藏单元

的权重进行

参数化。在 RBM

中

，隐藏到输出

的权重是输

入到隐藏

权

重的转置。NADE 架

构可以扩展

为不仅仅模

拟均匀场循

环推断的一

个时间步，而

是 k

步。这种方

法称为 NADE-k (Raiko et

al., 2014)。

如前

所述，自回归

网络可以被

扩展成处理

连续数据。用

于参数化连

续密度的特

别

强大和通

用的方法是

混合权重为

αi（组

i 的系数或

先验概率），每

组条件均值

为 µi

和每组条

件方差为

σi

2 的

高斯混合体

。一个称为 RNADE

的

模型 (Uria et al.,

2013)

使用这

种参数化将

NADE 扩展到实值

。与其他混合

密度网络一

样，该分布的

参数是

网络

的输出，由

softmax 单

元产生混合

的权量概率

以及参数化

的方差，因此

可使它

606 第二

十章

深度生

成模型

们为

正的。由于条

件均值 µi 和条

件方差

σi

2 之间

的相互作用

，随机梯度下

降在数值

上

可能会表现

不好。为了减

少这种困难

，Uria

et al. (2013) 在后向传播

阶段使用伪

梯

度代替平

均值上的梯

度。

另一个非

常有趣的神

经自回归架

构的扩展摆

脱了为观察

到的变量选

择任意顺序

的需要 (Murray and

Larochelle, 2014)。在自

回归网络中

，该想法是训

练网络以能

够

通过随机

采样顺序来

处理任何顺

序，并将信息

提供给指定

哪些输入被

观察的隐藏

单

元（在条件

条的右侧），以

及哪些是被

预测并因此

被认为是缺

失的（在条件

条的左

侧）。这

是不错的性

质，因为它允

许人们非常

高效地使用

训练好的自

回归网络来

执行

任何推

断问题（即从

给定任何变

量的子集，从

任何子集上

的概率分布

预测或采样

）。

最后，由于变

量的许多顺

序是可能的

（对于 n

个变量

是 n!），并且变量

的每个顺序

o

产生不同的

p(x |

o)，我们可以组

成许多 o 值模

型的集成：

pensemble(x)

= 1

k

k

∑

i=1

p(x |

o

(i)

). (20.84)

这

个集成模型

通常能更好

地泛化，并且

为测试集分

配比单个排

序定义的单

个模型更

高

的概率。

在同

一篇文章中

，作者提出了

深度版本的

架构，但不幸

的是，这立即

使计算成

本

像原始神经

自回归网络

一样高

(Bengio and Bengio, 2000b)。第一

层和输出层

仍然

可以在

O(nh) 的乘法-加法

操作中计算

，如在常规 NADE 中

，其中

h 是隐藏

单元的

数量

（图 20.10

和图 20.9 中的

组 hi

的大小），而

它在 Bengio and Bengio

(2000b) 中

是 O(n

2h)。然

而，对于其他

隐藏层的计

算量是 O(n

2h

2

)（假设

在每个层存

在 n 组 h

个隐藏

单元，且在 l 层

的每个 ‘‘先前

’’

组参与预测

l + 1 层处的

‘‘下一

个’’ 组）。如

在 Murray

and Larochelle (2014) 中

，使

l + 1 层上的第

i

个组仅取决

于第 i 个组，l

层

处的计算量

将减少到

O(nh2

)，但

仍然比常规

NADE 差 h

倍。

20.11 从自编

码器采样

在

第十四章中

，我们看到许

多种学习数

据分布的自

编码器。得分

匹配、去噪自

编码器和收

缩自编码器

之间有着密

切的联系。这

些联系表明

某些类型的

自编码器以

某些方式学

习数据分布

。我们还没有

讨论如何从

这样的模型

中采样。

某些

类型的自编

码器，例如变

分自编码器

，明确地表示

概率分布并

且允许直接

的原始采样

。而大多数其

他类型的自

编码器则需

要 MCMC 采样。

20.11

从自

编码器采样

607

收缩自编码

器被设计为

恢复数据流

形切面的估

计。这意味着

使用注入噪

声的

重复编

码和解码将

引起沿着流

形表面的随

机游走 (Rifai

et al., 2012; Mesnil

et al.,

2012)。这种

流形扩散技

术是马尔可

夫链的一种

。

更一般的马

尔可夫链还

可以从任何

去噪自编码

器中采样。

20.11.1 与

任意去噪自

编码器相关

的马尔可夫

链

上述讨论

留下了一个

开放问题——注

入什么噪声

和从哪获得

马尔可夫链

（可以

根据自

编码器估计

的分布生成

样本）。Bengio

et al. (2013c) 展示了

如何构建这

种用

于广义

去噪自编码

器(generalized denoising autoencoder) 的马尔可

夫链。广义去

噪

自编码器

由去噪分布

指定，给定损

坏输入后，对

干净输入的

估计进行采

样。

根据估计

分布生成的

马尔可夫链

的每个步骤

由以下子步

骤组成，如图

20.11 所

示：

1. 从先前

状态 x 开始，注

入损坏噪声

，从

C(x˜ | x) 中采样

x˜。

2. 将

x˜ 编码为

h = f(x˜)。

3.

解码

h 以获得 p(x |

ω = g(h)) =

p(x | x˜) 的参

数

ω = g(h)。

4.

从 p(x | ω

= g(h)) = p(x

| x˜) 采样下

一状态 x。

Bengio et al. (2014)

表明

，如果自编码

器 p(x | x˜)

形成对应

真实条件分

布的一致估

计量，则上述

马尔可夫链

的平稳分布

形成数据生

成分布 x 的一

致估计量（虽

然是隐

式的

）。

20.11.2 夹合与条件

采样

与玻尔

兹曼机类似

，去噪自编码

器及其推广

（例如下面描

述的 GSN）可用于

从条件分布

p(xf

| xo) 中采样，只需

夹合观察单

元 xf

并在给定

xf 和采好的潜

变

量（如果有

的话）下仅重

采样自由单

元 xo。例如，MP-DBM

可以

被解释为去

噪自

编码器

的一种形式

，并且能够采

样丢失的输

入。GSN 随后将 MP-DBM

中

的一些想

法

推广以执行

相同的操作

(Bengio et al.,

2014)。Alain et al. (2015)

从 Bengio et al.

(2014) 的命题 1 中

发现了一个

缺失条件，即

转移算子（由

从链的一个

状态到下一

个

608 第二十章

深度生成模

型

x

xx˜˜

h

!

xxˆˆ

C(x˜

| x) p(x |

!)

f g

图

20.11: 马尔可

夫链的每个

步骤与训练

好的去噪自

编码器相关

联，根据由去

噪对数似然

准则隐式

训

练的概率模

型生成样本

。每个步骤包

括：(a) 通过损坏

过程

C 向状态

x 注入噪声产

生 x˜，(b)

用

函数 f 对

其编码，产生

h

= f(x˜)，(c) 用函数 g

解码

结果，产生用

于重构分布

的参数 ω，(d) 给

定

ω，从重构分布

p(x

| ω = g(f(x˜)))

采样新状态

。在典型的平

方重构误差

情况下，g(h) = xˆ，并

估

计

E[x | x˜]，损坏包括

添加高斯噪

声，并且从 p(x|ω)

的

采样包括第

二次向重构

xˆ 添加高斯噪

声。

后者的噪

声水平应对

应于重构的

均方误差，而

注入的噪声

是控制混合

速度以及估

计器平滑经

验分

布程度

的超参数

(Vincent, 2011)。在

这所示的例

子中，只有 C 和

p

条件是随机

步骤（f 和 g 是

确

定性计算），我

们也可以在

自编码器内

部注入噪声

，如生成随机

网络 (Bengio et al.,

2014)。

状态的

随机映射定

义）应该满足

细致平衡（detailed balance）的

属性，表明无

论转

移算子

正向或反向

运行，马尔可

夫链都将保

持平衡。

在图

20.12 中展示了夹

合一半像素

（图像的右部

分）并在另一

半上运行马

尔可夫

链的

实验。

20.11.3

回退训

练过程

回退

训练过程由

Bengio et al.

(2013c) 等人提出，作

为一种加速

去噪自编码

器生

成训练

收敛的方法

。不像执行一

步编码-解码

重建，该过程

由交替的多

个随机编码

-解

码步骤组

成（如在生成

马尔可夫链

中），以训练样

本初始化（正

如在第18.2

节中

描述

的对比

散度算法），并

惩罚最后的

概率重建（或

沿途的所有

重建）。

训练 k

个

步骤与训练

一个步骤是

等价的（在实

现相同稳态

分布的意义

上），但是

实际

上可以更有

效地去除来

自数据的伪

模式。

20.12 生成随

机网络

609

图 20.12: 在

每步仅重采

样左半部分

，夹合图像的

右半部分并

运行马尔可

夫链的示意

图。这些样本

来自重构

MNIST 数

字的 GSN（每个时

间步使用回

退过程）。

20.12

生成

随机网络

生

成随机网络

（generative stochastic network,

GSN）(Bengio et al., 2014)

是去

噪自编

码器的推广

，除可见变量

（通常表示为

x）之外，在生成

马尔可夫链

中还包

括潜

变量 h。

GSN 由两个

条件概率分

布参数化，指

定马尔可夫

链的一步：

1. p(x

(k)

| h

(k)

) 指

示在给定当

前潜在状态

下如何产生

下一个可见

变量。这种 ‘‘重

建分布’’ 也可

以在去噪自

编码器、RBM、DBN

和 DBM 中

找到。

2.

p(h

(k)

| h

(k−1)

, x

(k−1))

指示在

给定先前的

潜在状态和

可见变量下

如何更新潜

在状态变量

。

去噪自编码

器和 GSN 不同于

经典的概率

模型（有向或

无向），它们自

己参数化

生

成过程而不

是通过可见

和潜变量的

联合分布的

数学形式。相

反，后者如果

存在则

隐式

地定义为生

成马尔可夫

链的稳态分

布。存在稳态

分布的条件

是温和的，并

且需

要与标

准 MCMC

方法相同

的条件（见第

17.3 节）。这些条件

是保证链混

合的必要条

610 第二十章 深

度生成模型

件，但它们可

能被某些过

渡分布的选

择（例如，如果

它们是确定

性的）所违反

。

我们可以想

象 GSN 不同的训

练准则。由 Bengio

et al. (2014) 提

出和评估的

只对可见单

元上对数概

率的重建，如

应用于去噪

自编码器。通

过将

x

(0) = x

夹

合到

观察到的样

本并且在一

些后续时间

步处使生成

x 的概率最大

化，即最大化

log p(x

(k) = x |

h

(k)

)，其中给定 x

(0) = x 后

，h

(k) 从链中采样

。为了估计相

对于模

型其

他部分的 log

p(x

(k) = x

| h

(k)

)

的

梯度，Bengio et al. (2014)

使用了

在第 20.9 节

中介

绍的重参数

化技巧。

回退

训练过程（在

第20.11.3 节中描述

）可以用来改

善训练 GSN 的收

敛性

(Ben￾gio et al., 2014)

。

20.12.1 判别性

GSN

GSN的原始公式

(Bengio

et al., 2014) 用于无监督

学习和对观

察数据

x 的 p(x)

的

隐式建模，但

是我们可以

修改框架来

优化

p(y | x)。

例如，Zhou

and Troyanskaya (2014) 以

如下方式推

广

GSN，只反向传

播输出变

量

上的重建对

数概率，并保

持输入变量

固定。他们将

这种方式成

功应用于建

模序列

（蛋白

质二级结构

），并在马尔可

夫链的转换

算子中引入

（一维）卷积结

构。重要的

是

要记住，对于

马尔可夫链

的每一步，我

们需要为每

个层生成新

序列，并且该

序列

用于在

下一时间步

计算其他层

的值（例如下

面一个和上

面一个）的输

入。

因此，马尔

可夫链确实

不只是输出

变量（与更高

层的隐藏层

相关联），并且

输入

序列仅

用于条件化

该链，其中反

向传播使得

它能够学习

输入序列如

何条件化由

马尔

可夫链

隐含表示的

输出分布。因

此这是在结

构化输出中

使用

GSN 的一个

例子。

Zöhrer and

Pernkopf (2014) 引入了

一个混合模

型，通过简单

地添加（使用

不

同的权重

）监督和非监

督成本即

y 和

x 的重建对数

概率，组合了

监督目标（如

上

面的工作

）和无监督目

标（如原始的

GSN）。Larochelle

and Bengio (2008a) 以前

在 RBM 中就

提出了这样

的混合标准

。他们展示了

在这种方案

下分类性能

的提升。

20.13

其他

生成方案

目

前为止我们

已经描述的

方法，使用 MCMC 采

样、原始采样

或两者的一

些混

合来生

成样本。虽然

这些是生成

式建模中最

流行的方法

，但它们绝不

是唯一的方

法。

20.14 评估生成

模型 611

Sohl-Dickstein et al. (2015)

开发了

一种基于非

平衡热力学

学习生成模

型的 扩散

反

演 (diffusion

inversion) 训练方案

。该方法基于

我们希望从

中采样的概

率分布具有

结构的想法

。这种结构会

被递增地使

概率分布具

有更多熵的

扩散过程逐

渐破坏。为

了

形成生成模

型，我们可以

反过来运行

该过程，通过

训练模型逐

渐将结构恢

复到非

结构

化分布。通过

迭代地应用

使分布更接

近目标分布

的过程，我们

可以逐渐接

近该

目标分

布。在涉及许

多迭代以产

生样本的意

义上，这种方

法类似于 MCMC 方

法。然

而，模型

被定义为由

链的最后一

步产生的概

率分布。在这

个意义上，没

有由迭代过

程

诱导的近

似。Sohl-Dickstein et al. (2015)

介绍的方

法也非常接

近于去噪自

编码器的

生

成解释（第20.11.1 节

）。与去噪自编

码器一样，扩

散反演训练

一个尝试概

率地撤消

添

加的噪声效

果的转移算

子。不同之处

在于，扩散反

演只需要消

除扩散过程

的一个

步骤

，而不是一直

返回到一个

干净的数据

点。这解决了

去噪自编码

器的普通重

建对

数似然

目标中存在

的以下两难

问题：小噪声

的情况下学

习者只能看

到数据点附

近的

配置，而

在大噪声的

情况下，去噪

自编码器被

要求做几乎

不可能的工

作（因为去噪

分布是高度

复杂和多峰

值的）。利用扩

散反演目标

，学习者可以

更精确地学

习数据点

周

围的密度形

状，以及去除

可能在远离

数据点处出

现的假性模

式。

样本生成

的另一种方

法是 近似贝

叶斯计算（approximate Bayesian computation,

ABC）框

架 (Rubin et al.,

1984)。在这种方

法中，样本被

拒绝或修改

以使样本选

定

函数的矩

匹配期望分

布的那些矩

。虽然这个想

法与矩匹配

一样使用样

本的矩，但它

不同于矩匹

配，因为它修

改样本本身

，而不是训练

模型来自动

发出具有正

确矩的样

本

。Bachman and

Precup (2015) 展示了如何

在深度学习

的背景下使

用 ABC

中的想

法

，即使用 ABC 来塑

造

GSN 的 MCMC 轨迹。

我

们期待更多

其他等待发

现的生成式

建模方法。

20.14 评

估生成模型

研究生成模

型的研究者

通常需要将

一个生成模

型与另一个

生成模型比

较，通常

是为

了证明新发

明的生成模

型比之前存

在的模型更

能捕获一些

分布。

这可能

是一个困难

且微妙的任

务。通常，我们

不能实际评

估模型下数

据的对数

概

率，但仅可以

评估一个近

似。在这些情

况下，重要的

是思考和沟

通清楚正在

测量

什么。例

如，假设我们

可以评估模

型 A

对数似然

的随机估计

和模型 B 对数

似然的

确定

性下界。如果

模型

A 得分高

于模型 B，哪个

更好？如果我

们关心确定

哪个模型

612

第

二十章 深度

生成模型

具

有分布更好

的内部表示

，我们实际上

不能说哪个

更好，除非我

们有一些方

法来确

定模

型

B 的边界有

多松。然而，如

果我们关心

在实践中该

模型能用得

多好，例如执

行异常检测

，则基于特定

于感兴趣的

实际任务的

准则，可以公

平地说模型

是更好的，

例

如基于排名

测试样例和

排名标准，如

精度和召回

率。

评估生成

模型的另一

个微妙之处

是，评估指标

往往是自身

困难的研究

问题。可

能很

难确定模型

是否被公平

比较。例如，假

设我们使用

AIS 来估计 logZ 以便

为我

们刚刚

发明的新模

型计算 log p˜(x) −

logZ。AIS 计算

经济的实现

可能无法找

到模型

分布

的几种模式

并低估 Z，这将

导致我们高

估

log p(x)。因此可能

难以判断高

似然估

计是

否是良好模

型或不好的

AIS 实现导致的

结果。

机器学

习的其他领

域通常允许

在数据预处

理中有一些

变化。例如，当

比较对象

识

别算法的准

确性时，通常

可接受的是

对每种算法

略微不同地

预处理输入

图像（基

于每

种算法具有

何种输入要

求）。而因为预

处理的变化

，会导致生成

式建模的不

同，

甚至非常

小和微妙的

变化也是完

全不可接受

的。对输入数

据的任何更

改都会改变

要

捕获的分

布，并从根本

上改变任务

。例如，将输入

乘以 0.1 将人为

地将概率增

加 10

倍。

预处理

的问题通常

在基于 MNIST 数据

集上的生成

模型产生，MNIST

数

据集是

非常

受欢迎的生

成式建模基

准之一。MNIST 由灰

度图像组成

。一些模型将

MNIST

图像视为实

向量空间中

的点，而其他

模型将其视

为二值。还有

一些将灰度

值视为二

值

样本的概率

。我们必须将

实值模型仅

与其他实值

模型比较，二

值模型仅与

其他二

值模

型进行比较

。否则，测量的

似然性不在

相同的空间

。对于二值模

型，对数似然

可

以最多为

零，而对于实

值模型，它可

以是任意高

的，因为它是

关于密度的

测度。在

二值

模型中，比较

使用完全相

同的二值化

模型是重要

的。例如，我们

可以将

0.5 设

为

阈值后，将灰

度像素二值

化为 0

或 1，或者

通过由灰度

像素强度给

出样本为 1 的

概率来采一

个随机样本

。如果我们使

用随机二值

化，我们可能

将整个数据

集二值化

一

次，或者我们

可能为每个

训练步骤采

不同的随机

样例，然后采

多个样本进

行评估。

这三

个方案中的

每一个都会

产生极不相

同的似然数

，并且当比较

不同的模型

时，两

个模型

使用相同的

二值化方案

来训练和评

估是重要的

。事实上，应用

单个随机二

值

化步骤的

研究者共享

包含随机二

值化结果的

文件，使得基

于二值化步

骤的不同输

出

的结果没

有差别。

因为

从数据分布

生成真实样

本是生成模

型的目标之

一，所以实践

者通常通过

视

觉检查样

本来评估生

成模型。在最

好的情况下

，这不是由研

究人员本身

，而是由不

知

道样品来源

的实验受试

者完成

(Denton et al., 2015)。不幸

的是，非常差

的概率

20.15 结论

613

模型可能会

产生非常好

的样本。验证

模型是否仅

复制一些训

练示例的常

见做法如

图

16.1

所示。该想法

是根据在 x 空

间中的欧几

里得距离，为

一些生成的

样本显示它

们在训练集

中的最近邻

。此测试旨在

检测模型过

拟合训练集

并仅再现训

练实例的情

况。甚至可能

同时欠拟合

和过拟合，但

仍然能产生

单独看起来

好的样本。想

象一下，

生成

模型用狗和

猫的图像训

练时，但只是

简单地学习

来重现狗的

训练图像。这

样的

模型明

显过拟合，因

为它不能产

生不在训练

集中的图像

，但是它也欠

拟合，因为它

不给猫的训

练图像分配

概率。然而，人

类观察者将

判断狗的每

个个体图像

都是高质

量

的。在这个简

单的例子中

，对于能够检

查许多样本

的人类观察

者来说，确定

猫的

不存在

是容易的。在

更实际的设

定中，在具有

数万个模式

的数据上训

练后的生成

模

型可以忽

略少数模式

，并且人类观

察者不能容

易地检查或

记住足够的

图像以检测

丢

失的变化

。

由于样本的

视觉质量不

是可靠的标

准，所以当计

算可行时，我

们通常还评

估模

型分配

给测试数据

的对数似然

。不幸的是，在

某些情况下

，似然性似乎

不可能测量

我们真正关

心的模型的

任何属性。例

如，MNIST 的实值模

型可以将任

意低的方差

分配给从不

改变的背景

像素，获得任

意高的似然

。即使这不是

一个非常有

用的事情，

检

测这些常量

特征的模型

和算法可以

获得无限的

奖励。实现接

近负无穷代

价的可能

性

存在于任何

实值的最大

似然问题中

，但是对于 MNIST 的

生成模型问

题尤为严重

，

因为许多输

出值是不需

要预测的。这

强烈地表明

需要开发评

估生成模型

的其他方法

。

Theis et al.

(2015) 回顾了评估

生成模型所

涉及的许多

问题，包括上

述的许多想

法。他们强调

了生成模型

有许多不同

的用途，并且

指标的选择

必须与模型

的预期用

途

相匹配。例如

，一些生成模

型更好地为

大多数真实

的点分配高

概率，而其他

生成

模型擅

长于不将高

概率分配给

不真实的点

。这些差异可

能源于生成

模型是设计

为最

小化 DKL(pdata||pmodel) 还

是 DKL(pmodel||pdata)，如图

3.6 所示

。不幸的是，即

使我

们将每

个指标的使

用限制在最

适合的任务

上，目前使用

的所有指标

仍存在严重

的缺

陷。因此

，生成式建模

中最重要的

研究课题之

一不仅仅是

如何提升生

成模型，事实

上还包括了

设计新的技

术来衡量我

们的进步。

20.15 结

论

为了让模

型理解表示

在给定训练

数据中的大

千世界，训练

具有隐藏单

元的生成

模

型是一种有

力方法。通过

学习模型

pmodel(x) 和

表示 pmodel(h |

x)，生成模

型可以

解答

x 输入变量之

间关系的许

多推断问题

，并且可以在

层次的不同

层对 h

求期望

来

614 第二十章

深度生成模

型

提供表示

x

的许多不同

方式。生成模

型承诺为 AI 系

统提供它们

需要理解的

、所有

不同直

观概念的框

架，让它们有

能力在面对

不确定性的

情况下推理

这些概念。我

们

希望我们

的读者能够

找到增强这

些方法的新

途径，并继续

探究学习和

智能背后原

理

的旅程。

参

考文献

(-1).

JMLR. 618, 649

(-1a).

Icml’08. In ICML’08 .

ACM. 649, 674

(-1b).

Icml’11. In ICML’11 .

628, 634

(-1c). Icml’13.

In ICML’13 . 635,

660

(-1). International conference

on learning representations 2014.

In ICLR’2014 . 661,

675

(-1). Nips’13. In

NIPS26 . NIPS Foundation.

629, 635

Abadi, M.,

Agarwal, A., Barham, P.,

Brevdo, E., Chen, Z.,

Citro, C., Corrado, G.

S., Davis,

A., Dean,

J., Devin, M., Ghemawat,

S., Goodfellow, I., Harp,

A., Irving, G., Isard,

M., Jia,

Y., Jozefowicz,

R., Kaiser, L., Kudlur,

M., Levenberg, J., Mané,

D., Monga, R., Moore,

S.,

Murray, D., Olah,

C., Schuster, M., Shlens,

J., Steiner, B., Sutskever,

I., Talwar, K., Tucker,

P., Vanhoucke, V., Vasudevan,

V., Viégas, F., Vinyals,

O., Warden, P., Wattenberg,

M.,

Wicke, M., Yu,

Y., and Zheng, X.

(2015). TensorFlow: Large-scale machine

learning on

heterogeneous systems.

Software available from tensorflow.org.

24, 183, 380

Ackley,

D. H., Hinton, G.

E., and Sejnowski, T.

J. (1985). A learning

algorithm for Boltzmann

machines.

Cognitive Science, 9, 147–169.

486, 559

Alain, G.

and Bengio, Y. (2013).

What regularized auto-encoders learn

from the data generating

distribution. In ICLR’2013, arXiv:1211.4246

. 433, 439, 445

Alain, G., Bengio, Y.,

Yao, L., Éric Thibodeau-Laufer,

Yosinski, J., and Vincent,

P. (2015).

GSNs: Generative

stochastic networks. arXiv:1503.05571. 436,

607

Anderson, E. (1935).

The Irises of the

Gaspé Peninsula. Bulletin of

the American Iris Society,

59, 2–5. 18

615

616 参考

文献

Ba, J.,

Mnih, V., and Kavukcuoglu,

K. (2014). Multiple object

recognition with visual attention.

arXiv:1412.7755 . 591

Bachman,

P. and Precup, D.

(2015). Variational generative stochastic

networks with collabo￾rative shaping.

In Proceedings of the

32nd International Conference on

Machine Learning,

ICML 2015,

Lille, France, 6-11 July

2015 , pages 1964–1972.

611

Bacon, P.-L., Bengio,

E., Pineau, J., and

Precup, D. (2015). Conditional

computation in neu￾ral networks

using a decision-theoretic approach.

In 2nd Multidisciplinary Conference

on

Reinforcement Learning and

Decision Making (RLDM 2015).

383

Bagnell, J. A.

and Bradley, D. M.

(2009). Differentiable sparse coding.

In NIPS’2009 , pages

113–120. 425

Bahdanau, D.,

Cho, K., and Bengio,

Y. (2015). Neural machine

translation by jointly learning

to align and translate.

In ICLR’2015, arXiv:1409.0473 .

23, 89, 339, 356,

358, 395, 404, 405

Bahl, L. R., Brown,

P., de Souza, P.

V., and Mercer, R.

L. (1987). Speech recognition

with

continuous-parameter hidden Markov

models. Computer, Speech and

Language, 2, 219–234.

390

Baldi, P. and Hornik,

K. (1989). Neural networks

and principal component analysis:

Learning

from examples without

local minima. Neural Networks,

2, 53–58. 245

Baldi,

P., Brunak, S., Frasconi,

P., Soda, G., and

Pollastri, G. (1999). Exploiting

the past and

the

future in protein secondary

structure prediction. Bioinformatics, 15(11),

937–946. 337

Baldi, P.,

Sadowski, P., and Whiteson,

D. (2014). Searching for

exotic particles in high-energy

physics with deep learning.

Nature communications, 5. 24

Ballard, D. H., Hinton,

G. E., and Sejnowski,

T. J. (1983). Parallel

vision computation. Nature.

385

Barlow, H. B. (1989).

Unsupervised learning. Neural Computation,

1, 295–311. 128

Barron,

A. E. (1993). Universal

approximation bounds for superpositions

of a sigmoidal function.

IEEE Trans. on Information

Theory, 39, 930–945. 172

Bartholomew, D. J. (1987).

Latent variable models and

factor analysis. Oxford University

Press.

418

Basilevsky, A.

(1994). Statistical Factor Analysis

and Related Methods: Theory

and Applications.

Wiley. 418

参考文

献 617

Bastien, F.,

Lamblin, P., Pascanu, R.,

Bergstra, J., Goodfellow, I.,

Bergeron, A., Bouchard, N.,

Warde-Farley, D., and Bengio,

Y. (2012a). Theano: new

features and speed improvements.

Submited to the Deep

Learning and Unsupervised Feature

Learning NIPS 2012 Workshop,

http://www.iro.umontreal.ca/ lisa/publications2/index.php/publications/show/551. 23, 73,

380

Bastien, F., Lamblin,

P., Pascanu, R., Bergstra,

J., Goodfellow, I. J.,

Bergeron, A., Bouchard,

N.,

and Bengio, Y. (2012b).

Theano: new features and

speed improvements. Deep Learning

and Unsupervised Feature Learning

NIPS 2012 Workshop. 182,

191

Basu, S. and

Christensen, J. (2013). Teaching

classification boundaries to humans.

In

AAAI’2013 . 280

Baxter, J. (1995). Learning

internal representations. In Proceedings

of the 8th International

Conference on Computational Learning

Theory (COLT’95), pages 311–320,

Santa Cruz, Cal￾ifornia. ACM

Press. 211

Bayer, J.

and Osendorfer, C. (2014).

Learning stochastic recurrent networks.

ArXiv e-prints.

228

Becker,

S. and Hinton, G.

(1992). A self-organizing neural

network that discovers surfaces

in

random-dot stereograms. Nature,

355, 161–163. 462

Behnke,

S. (2001). Learning iterative

image reconstruction in the

neural abstraction pyramid.

Int.

J. Computational Intelligence and

Applications, 1(4), 427–438. 440

Beiu, V., Quintana, J.

M., and Avedillo, M.

J. (2003). VLSI implementations

of threshold logic-a

comprehensive

survey. Neural Networks, IEEE

Transactions on, 14(5), 1217–1243.

384

Belkin, M. and

Niyogi, P. (2002). Laplacian

eigenmaps and spectral techniques

for embedding

and clustering.

In T. Dietterich, S.

Becker, and Z. Ghahramani,

editors, Advances in Neural

Information Processing Systems 14

(NIPS’01), Cambridge, MA. MIT

Press. 210

Belkin, M.

and Niyogi, P. (2003a).

Laplacian eigenmaps for dimensionality

reduction and data

representation.

Neural Computation, 15(6), 1373–1396.

443

Belkin, M. and

Niyogi, P. (2003b). Using

manifold structure for partially

labeled classification. In

S.

Becker, S. Thrun, and

K. Obermayer, editors, Advances

in Neural Information Processing

Systems 15 (NIPS’02), Cambridge,

MA. MIT Press. 141

Bengio, E., Bacon, P.-L.,

Pineau, J., and Precup,

D. (2015a). Conditional computation

in neural

networks for

faster models. arXiv:1511.06297. 383

618 参考文献

Bengio, S. and

Bengio, Y. (2000a). Taking

on the curse of

dimensionality in joint distributions

using neural networks. IEEE

Transactions on Neural Networks,

special issue on Data

Mining

and Knowledge Discovery,

11(3), 550–557. 603

Bengio,

S., Vinyals, O., Jaitly,

N., and Shazeer, N.

(2015b). Scheduled sampling for

sequence

prediction with recurrent

neural networks. Technical report,

arXiv:1506.03099. 327

Bengio, Y.

(1991). Artificial Neural Networks

and their Application to

Sequence Recognition.

Ph.D. thesis,

McGill University, (Computer Science),

Montreal, Canada. 347

Bengio,

Y. (2000). Gradient-based optimization

of hyperparameters. Neural Computation,

12(8), 1889–1900. 370

Bengio,

Y. (2002). New distributed

probabilistic language models. Technical

Report 1215, Dept.

IRO,

Université de Montréal. 397

Bengio, Y. (2009). Learning

deep architectures for AI.

Now Publishers. 174, 531

Bengio, Y. (2013). Deep

learning of representations: looking

forward. In Statistical Language

and

Speech Processing, volume

7978 of Lecture Notes

in Computer Science, pages

1–37. Springer,

also in

arXiv at http://arxiv.org/abs/1305.0445. 382

Bengio, Y. (2015). Early

inference in energy-based models

approximates back-propagation.

Technical Report

arXiv:1510.02777, Universite de Montreal.

560

Bengio, Y. and

Bengio, S. (2000b). Modeling

high-dimensional discrete data with

multi-layer

neural networks. In

NIPS 12 , pages

400–406. MIT Press. 602,

603, 604, 606

Bengio,

Y. and Delalleau, O.

(2009). Justifying and generalizing

contrastive divergence. Neural

Computation,

21(6), 1601–1621. 438, 520

Bengio, Y. and Grandvalet,

Y. (2004). No unbiased

estimator of the variance

of k-fold cross￾validation. In

JML ( 1), pages

1089–1105. 107

Bengio, Y.

and LeCun, Y. (2007a).

Scaling learning algorithms towards

AI. In Large Scale

Kernel Machines. 17

Bengio,

Y. and LeCun, Y.

(2007b). Scaling learning algorithms

towards AI. In L.

Bottou,

O. Chapelle, D.

DeCoste, and J. Weston,

editors, Large Scale Kernel

Machines. MIT Press.

17

Bengio, Y. and Monperrus,

M. (2005). Non-local manifold

tangent learning. In L.

Saul, Y. Weiss,

and

L. Bottou, editors, Advances

in Neural Information Processing

Systems 17 (NIPS’04),

pages

129–136. MIT Press. 138,

444

参考文献 619

Bengio,

Y. and Sénécal, J.-S.

(2003). Quick training of

probabilistic neural nets by

importance

sampling. In Proceedings

of AISTATS 2003 .

400

Bengio, Y. and

Sénécal, J.-S. (2008). Adaptive

importance sampling to accelerate

training of a

neural

probabilistic language model. IEEE

Trans. Neural Networks, 19(4),

713–722. 400

Bengio, Y.,

De Mori, R., Flammia,

G., and Kompe, R.

(1991). Phonetically motivated acoustic

parameters for continuous speech

recognition using artificial neural

networks. In Proceedings

of

EuroSpeech’91 . 21, 390

Bengio, Y., De Mori,

R., Flammia, G., and

Kompe, R. (1992). Neural

network-Gaussian mixture

hybrid for

speech recognition or density

estimation. In NIPS 4

, pages 175–182. Morgan

Kaufmann. 390

Bengio, Y.,

Frasconi, P., and Simard,

P. (1993). The problem

of learning long-term dependencies

in recurrent networks. In

IEEE International Conference on

Neural Networks, pages 1183–

1195, San Francisco. IEEE

Press. (invited paper). 344

Bengio, Y., Simard, P.,

and Frasconi, P. (1994a).

Learning long-term dependencies with

gradient

descent is difficult.

IEEE Tr. Neural Nets.

16

Bengio, Y., Simard,

P., and Frasconi, P.

(1994b). Learning long-term dependencies

with gradient

descent is

difficult. IEEE Transactions on

Neural Networks, 5(2), 157–166.

343, 344, 345

Bengio,

Y., Simard, P., and

Frasconi, P. (1994c). Learning

long-term dependencies with gradient

descent is difficult. IEEE

Transactions on Neural Networks,

5(2), 157–166. 351

Bengio,

Y., Latendresse, S., and

Dugas, C. (1999). Gradient-based

learning of hyper-parameters.

In

Learning Conference. 370

Bengio,

Y., Ducharme, R., and

Vincent, P. (2001a). A

neural probabilistic language model.

In T. Leen, T.

Dietterich, and V. Tresp,

editors, Advances in Neural

Information Processing

Systems 13

(NIPS’00), pages 933–938. MIT

Press. 16

Bengio, Y.,

Ducharme, R., and Vincent,

P. (2001b). A neural

probabilistic language model. In

T. K. Leen, T.

G. Dietterich, and V.

Tresp, editors, NIPS’2000 ,

pages 932–938. MIT Press.

380, 394, 396, 402,

406, 410

Bengio, Y.,

Ducharme, R., Vincent, P.,

and Jauvin, C. (2003).

A neural probabilistic language

model. JMLR, 3, 1137–1155.

396, 402

Bengio, Y.,

Delalleau, O., and Le

Roux, N. (2006a). The

curse of highly variable

functions for

local kernel

machines. In NIPS’2005 .

137

620 参

考文献

Bengio,

Y., Larochelle, H., and

Vincent, P. (2006b). Non-local

manifold Parzen windows. In

NIPS’2005 . MIT Press.

138, 444

Bengio, Y.,

Lamblin, P., Popovici, D.,

and Larochelle, H. (2007a).

Greedy layer-wise training of

deep networks. In NIPS’2006

. 13, 276

Bengio,

Y., Lamblin, P., Popovici,

D., and Larochelle, H.

(2007b). Greedy layer-wise training

of deep networks. In

B. Schölkopf, J. Platt,

and T. Hoffman, editors,

Advances in Neural

Information

Processing Systems 19 (NIPS’06),

pages 153–160. MIT Press.

173

Bengio, Y., Lamblin,

P., Popovici, D., and

Larochelle, H. (2007c). Greedy

layer-wise training of

deep

networks. In Adv. Neural

Inf. Proc. Sys. 19

, pages 153–160. 275

Bengio, Y., Lamblin, P.,

Popovici, D., and Larochelle,

H. (2007d). Greedy layer-wise

training

of deep networks.

In NIPS 19 ,

pages 153–160. MIT Press.

276, 451, 452

Bengio,

Y., Louradour, J., Collobert,

R., and Weston, J.

(2009). Curriculum learning. In

ICML’09 . ACM. 279

Bengio, Y., Mesnil, G.,

Dauphin, Y., and Rifai,

S. (2013a). Better mixing

via deep representa￾tions. In

ICML’2013 . 514

Bengio,

Y., Léonard, N., and

Courville, A. (2013b). Estimating

or propagating gradients through

stochastic neurons for conditional

computation. arXiv:1308.3432. 382, 383,

588, 590

Bengio, Y.,

Yao, L., Alain, G.,

and Vincent, P. (2013c).

Generalized denoising auto-encoders as

generative models. In NIPS’2013

. 433, 607, 608

Bengio, Y., Courville, A.,

and Vincent, P. (2013d).

Representation learning: A review

and

new perspectives. Pattern

Analysis and Machine Intelligence,

IEEE Transactions on, 35(8),

1798–1828. 473

Bengio, Y.,

Thibodeau-Laufer, E., Alain, G.,

and Yosinski, J. (2014).

Deep generative stochastic

networks

trainable by backprop. In

ICML’2014 . 607, 608,

609, 610

Bennett, C.

(1976). Efficient estimation of

free energy differences from

Monte Carlo data. Journal

of Computational Physics, 22(2),

245–268. 536

Bennett, J.

and Lanning, S. (2007).

The Netflix prize. 408

Berger, A. L., Della

Pietra, V. J., and

Della Pietra, S. A.

(1996). A maximum entropy

approach

to natural language

processing. Computational Linguistics, 22,

39–71. 403

Berglund, M.

and Raiko, T. (2013).

Stochastic gradient estimate variance

in contrastive diver￾gence and

persistent contrastive divergence. CoRR,

abs/1312.6002. 523

参考

文献 621

Bergstra, J. (2011). Incorporating

Complex Cells into Neural

Networks for Pattern Classification.

Ph.D. thesis, Université de

Montréal. 219

Bergstra, J.

and Bengio, Y. (2009).

Slow, decorrelated features for

pretraining complex cell-like

networks.

In NIPS 22 ,

pages 99–107. MIT Press.

421

Bergstra, J. and

Bengio, Y. (2011). Random

search for hyper-parameter optimization.

The

Learning Workshop, Fort

Lauderdale, Florida. 369

Bergstra,

J. and Bengio, Y.

(2012). Random search for

hyper-parameter optimization. J.

Machine

Learning Res., 13, 281–305.

369, 370

Bergstra, J.,

Breuleux, O., Bastien, F.,

Lamblin, P., Pascanu, R.,

Desjardins, G., Turian, J.,

Warde-Farley, D., and Bengio,

Y. (2010a). Theano: a

CPU and GPU math

expression

compiler. In Proceedings

of the Python for

Scientific Computing Conference (SciPy).

Oral

Presentation. 23, 73

Bergstra, J., Breuleux, O.,

Bastien, F., Lamblin, P.,

Pascanu, R., Desjardins, G.,

Turian, J.,

Warde-Farley, D.,

and Bengio, Y. (2010b).

Theano: a CPU and

GPU math expression

compiler.

In Proc. SciPy. 182,

191

Bergstra, J., Breuleux,

O., Bastien, F., Lamblin,

P., Pascanu, R., Desjardins,

G., Turian, J.,

Warde-Farley,

D., and Bengio, Y.

(2010c). Theano: a CPU

and GPU math expression

compiler. In Proceedings of

the Python for Scientific

Computing Conference (SciPy). 380

Bergstra, J., Bardenet, R.,

Bengio, Y., and Kégl,

B. (2011). Algorithms for

hyper-parameter

optimization. In NIPS’2011

. 371

Berkes, P.

and Wiskott, L. (2005).

Slow feature analysis yields

a rich repertoire of

complex cell

properties. Journal

of Vision, 5(6), 579–602.

423

Bertsekas, D. P.

and Tsitsiklis, J. (1996).

Neuro-Dynamic Programming. Athena Scientific.

93

Besag, J. (1975).

Statistical analysis of non-lattice

data. The Statistician, 24(3),

179–195. 525

Bishop, C.

M. (1994). Mixture density

networks. 163

Bishop, C.

M. (1995a). Regularization and

complexity control in feed-forward

networks. In

Proceedings International

Conference on Artificial Neural

Networks ICANN’95 , volume

1,

page 141–148. 208,

215

Bishop, C. M.

(1995b). Training with noise

is equivalent to Tikhonov

regularization. Neural

Computation, 7(1),

108–116. 208

622 参考文

献

Bishop, C. M. (2006).

Pattern Recognition and Machine

Learning. Springer. 87, 126

Blum, A. L. and

Rivest, R. L. (1992).

Training a 3-node neural

network is NP-complete. 250

Blumer, A., Ehrenfeucht, A.,

Haussler, D., and Warmuth,

M. K. (1989). Learnability

and the

Vapnik–Chervonenkis dimension.

Journal of the ACM,

36(4), 929--–865. 100

Bonnet,

G. (1964). Transformations des

signaux aléatoires à travers

les systèmes non linéaires

sans mémoire. Annales des

Télécommunications, 19(9–10), 203–220. 588

Bordes, A., Weston, J.,

Collobert, R., and Bengio,

Y. (2011). Learning structured

embeddings

of knowledge bases.

In AAAI 2011 .

411, 412

Bordes, A.,

Glorot, X., Weston, J.,

and Bengio, Y. (2012).

Joint learning of words

and meaning

representations for

open-text semantic parsing. AISTATS’2012

. 343, 411, 412

Bordes, A., Glorot, X.,

Weston, J., and Bengio,

Y. (2013a). A semantic

matching energy

function for

learning with multi-relational data.

Machine Learning: Special Issue

on Learning

Semantics. 411

Bordes, A., Usunier, N.,

Garcia-Duran, A., Weston, J.,

and Yakhnenko, O. (2013b).

Trans￾lating embeddings for modeling

multi-relational data. In C.

Burges, L. Bottou, M.

Welling,

Z. Ghahramani, and

K. Weinberger, editors, Advances

in Neural Information Processing

Sys￾tems 26 , pages

2787–2795. Curran Associates, Inc.

411

Bornschein, J. and

Bengio, Y. (2015). Reweighted

wake-sleep. In ICLR’2015, arXiv:1406.2751

.

592

Bornschein, J.,

Shabanian, S., Fischer, A.,

and Bengio, Y. (2015).

Training bidirectional

Helmholtz machines.

Technical report, arXiv:1506.03877. 592

Boser, B. E., Guyon,

I. M., and Vapnik,

V. N. (1992). A

training algorithm for optimal

margin

classifiers. In COLT

’92: Proceedings of the

fifth annual workshop on

Computational learning

theory, pages

144–152, New York, NY,

USA. ACM. 16, 123

Bottou, L. (1998). Online

algorithms and stochastic approximations.

In D. Saad, editor,

Online

Learning in Neural

Networks. Cambridge University Press,

Cambridge, UK. 253

Bottou,

L. (2011). From machine

learning to machine reasoning.

Technical report,

arXiv.1102.1808. 341,

342

Bottou, L. (2015).

Multilayer neural networks. Deep

Learning Summer School. 374

参考文献

623

Bottou, L. and

Bousquet, O. (2008a). The

tradeoffs of large scale

learning. In J. Platt,

D. Koller,

Y. Singer,

and S. Roweis, editors,

Advances in Neural Information

Processing Systems 20

(NIPS’07),

volume 20. MIT Press,

Cambridge, MA. 241

Bottou,

L. and Bousquet, O.

(2008b). The tradeoffs of

large scale learning. In

NIPS’2008 . 252

Boulanger-Lewandowski,

N., Bengio, Y., and

Vincent, P. (2012). Modeling

temporal depen￾dencies in high-dimensional

sequences: Application to polyphonic

music generation and tran￾scription.

In ICML’12 . 585

Boureau, Y., Ponce, J.,

and LeCun, Y. (2010).

A theoretical analysis of

feature pooling in vision

algorithms. In Proc. International

Conference on Machine learning

(ICML’10). 292

Boureau, Y.,

Le Roux, N., Bach,

F., Ponce, J., and

LeCun, Y. (2011). Ask

the locals: multi-way

local

pooling for image recognition.

In Proc. International Conference

on Computer Vision

(ICCV’11).

IEEE. 293

Bourlard, H.

and Kamp, Y. (1988).

Auto-association by multilayer perceptrons

and singular

value decomposition.

Biological Cybernetics, 59, 291–294.

429

Bourlard, H. and

Wellekens, C. (1989). Speech

pattern discrimination and multi-layered

per￾ceptrons. Computer Speech and

Language, 3, 1–19. 390

Boyd, S. and Vandenberghe,

L. (2004). Convex Optimization.

Cambridge University Press, New

York, NY, USA. 82

Brady, M. L., Raghavan,

R., and Slawny, J.

(1989). Back-propagation fails to

separate where

perceptrons succeed.

IEEE Transactions on Circuits

and Systems, 36(5), 665–674.

243

Brakel, P., Stroobandt,

D., and Schrauwen, B.

(2013). Training energy-based models

for time￾series imputation. Journal

of Machine Learning Research,

14, 2771–2797. 576, 596

Brand, M. (2003a). Charting

a manifold. In S.

Becker, S. Thrun, and

K. Obermayer, editors,

Advances

in Neural Information Processing

Systems 15 (NIPS’02), pages

961–968. MIT Press.

141

Brand, M. (2003b). Charting

a manifold. In NIPS’2002

, pages 961–968. MIT

Press. 443

Breiman, L.

(1994). Bagging predictors. Machine

Learning, 24(2), 123–140. 220

Breiman, L., Friedman, J.

H., Olshen, R. A.,

and Stone, C. J.

(1984). Classification and

Regression

Trees. Wadsworth International Group,

Belmont, CA. 125

Bridle,

J. S. (1990). Alphanets:

a recurrent ‘neural’ network

architecture with a hidden

Markov

model interpretation. Speech

Communication, 9(1), 83–92. 160

624 参考文献

Briggman, K.,

Denk, W., Seung, S.,

Helmstaedter, M. N., and

Turaga, S. C. (2009).

Maximin

affinity learning of

image segmentation. In NIPS’2009

, pages 1865–1873. 306

Brown, P. F., Cocke,

J., Pietra, S. A.

D., Pietra, V. J.

D., Jelinek, F., Lafferty,

J. D., Mercer,

R.

L., and Roossin, P.

S. (1990). A statistical

approach to machine translation.

Computational

linguistics, 16(2), 79–85.

18

Brown, P. F.,

Pietra, V. J. D.,

DeSouza, P. V., Lai,

J. C., and Mercer,

R. L. (1992). Class-based

n-gram models of natural

language. Computational Linguistics, 18,

467–479. 394

Bryson, A.

and Ho, Y. (1969).

Applied optimal control: optimization,

estimation, and control.

Blaisdell

Pub. Co. 194

Bryson,

Jr., A. E. and

Denham, W. F. (1961).

A steepest-ascent method for

solving optimum

programming problems.

Technical Report BR-1303, Raytheon

Company, Missle and Space

Division. 194

Buciluˇa, C.,

Caruana, R., and Niculescu-Mizil,

A. (2006). Model compression.

In Proceedings of

the

12th ACM SIGKDD international

conference on Knowledge discovery

and data mining,

pages

535–541. ACM. 381

Burda,

Y., Grosse, R., and

Salakhutdinov, R. (2015). Importance

weighted autoencoders. arXiv

preprint

arXiv:1509.00519 . 596

Cai,

M., Shi, Y., and

Liu, J. (2013). Deep

maxout neural networks for

speech recognition. In

Automatic

Speech Recognition and Understanding

(ASRU), 2013 IEEE Workshop

on, pages

291–296. IEEE.

167

Carreira-Perpiñan, M. A.

and Hinton, G. E.

(2005). On contrastive divergence

learning. In

AISTATS’2005 ,

pages 33–40. 520

Caruana,

R. (1993). Multitask connectionist

learning. In Proceedings of

the 1993 Connectionist

Models

Summer School, pages 372–379.

210

Cauchy, A. (1847).

Méthode générale pour la

résolution de systèmes d’équations

simultanées.

In Compte rendu

des séances de l’académie

des sciences, pages 536–538.

74, 194

Cayton, L.

(2005). Algorithms for manifold

learning. Technical Report CS2008-0923,

UCSD.

141

Chandola, V.,

Banerjee, A., and Kumar,

V. (2009). Anomaly detection:

A survey. ACM

computing

surveys (CSUR), 41(3), 15.

90

参

考文献 625

Chapelle,

O., Weston, J., and

Schölkopf, B. (2003). Cluster

kernels for semi-supervised learning.

In S. Becker, S.

Thrun, and K. Obermayer,

editors, Advances in Neural

Information Processing

Systems 15

(NIPS’02), pages 585–592, Cambridge,

MA. MIT Press. 210

Chapelle, O., Schölkopf, B.,

and Zien, A., editors

(2006). Semi-Supervised Learning. MIT

Press,

Cambridge, MA. 210,

462

Chellapilla, K., Puri,

S., and Simard, P.

(2006). High Performance Convolutional

Neural Net￾works for Document

Processing. In Guy Lorette,

editor, Tenth International Workshop

on

Frontiers in Handwriting

Recognition, La Baule (France).

Université de Rennes 1,

Suvisoft.

http://www.suvisoft.com. 20, 21,

379

Chen, B., Ting,

J.-A., Marlin, B. M.,

and de Freitas, N.

(2010). Deep learning of

invariant

spatio-temporal features from

video. NIPS*2010 Deep Learning

and Unsupervised Feature

Learning

Workshop. 307

Chen, S.

F. and Goodman, J.

T. (1999). An empirical

study of smoothing techniques

for language

modeling. Computer,

Speech and Language, 13(4),

359–393. 393, 394, 402

Chen, T., Du, Z.,

Sun, N., Wang, J.,

Wu, C., Chen, Y.,

and Temam, O. (2014a).

DianNao: A

small-footprint high-throughput

accelerator for ubiquitous machine-learning.

In Proceedings

of the

19th international conference on

Architectural support for programming

languages and

operating systems,

pages 269–284. ACM. 384

Chen, T., Li, M.,

Li, Y., Lin, M.,

Wang, N., Wang, M.,

Xiao, T., Xu, B.,

Zhang, C., and

Zhang,

Z. (2015). MXNet: A

flexible and efficient machine

learning library for heterogeneous

distributed systems. arXiv preprint

arXiv:1512.01274 . 23

Chen,

Y., Luo, T., Liu,

S., Zhang, S., He,

L., Wang, J., Li,

L., Chen, T., Xu,

Z., Sun, N., et

al.

(2014b). DaDianNao: A

machine-learning supercomputer. In Microarchitecture

(MICRO),

2014 47th Annual

IEEE/ACM International Symposium on,

pages 609–622. IEEE. 384

Chilimbi, T., Suzue, Y.,

Apacible, J., and Kalyanaraman,

K. (2014). Project Adam:

Building

an efficient and

scalable deep learning training

system. In 11th USENIX

Symposium on

Operating Systems

Design and Implementation (OSDI’14).

381

Cho, K., Raiko,

T., and Ilin, A.

(2010a). Parallel tempering is

efficient for learning restricted

Boltzmann machines. In Proceedings

of the International Joint

Conference on Neural Net￾works

(IJCNN 2010), Barcelona, Spain.

514

Cho, K., Raiko,

T., and Ilin, A.

(2010b). Parallel tempering is

efficient for learning restricted

Boltzmann machines. In IJCNN’2010

. 524

626 参考

文献

Cho, K., Raiko, T.,

and Ilin, A. (2011).

Enhanced gradient and adaptive

learning rate for

training

restricted Boltzmann machines. In

ICML’2011 , pages 105–112.

575

Cho, K., Van

Merriënboer, B., Gülçehre, Ç.,

Bahdanau, D., Bougares, F.,

Schwenk, H., and

Bengio,

Y. (2014a). Learning phrase

representations using RNN encoder–decoder

for sta￾tistical machine translation.

In Proceedings of the

2014 Conference on Empirical

Methods

in Natural Language

Processing (EMNLP), pages 1724–1734.

Association for Computational

Linguistics.

338

Cho, K., van

Merriënboer, B., Gulcehre, C.,

Bougares, F., Schwenk, H.,

and Bengio, Y. (2014b).

Learning phrase representations using

RNN encoder-decoder for statistical

machine trans￾lation. In Proceedings

of the Empiricial Methods

in Natural Language Processing

(EMNLP

2014). 403

Cho,

K., Van Merriënboer, B.,

Bahdanau, D., and Bengio,

Y. (2014c). On the

properties of

neural machine

translation: Encoder-decoder approaches. ArXiv

e-prints, abs/1409.1259.

351

Choromanska,

A., Henaff, M., Mathieu,

M., Arous, G. B.,

and LeCun, Y. (2014).

The loss

surface of

multilayer networks. 244, 245

Chorowski, J., Bahdanau, D.,

Cho, K., and Bengio,

Y. (2014). End-to-end continuous

speech

recognition using attention-based

recurrent NN: First results.

arXiv:1412.1602. 392

Christianson, B.

(1992). Automatic Hessians by

reverse accumulation. IMA Journal

of Numerical

Analysis, 12(2),

135–150. 193

Chrupala, G.,

Kadar, A., and Alishahi,

A. (2015). Learning language

through pictures. arXiv

1506.03694.

351

Chung, J., Gulcehre,

C., Cho, K., and

Bengio, Y. (2014). Empirical

evaluation of gated recurrent

neural networks on sequence

modeling. NIPS’2014 Deep Learning

workshop, arXiv 1412.3555.

351,

392

Chung, J., Gülçehre,

Ç., Cho, K., and

Bengio, Y. (2015a). Gated

feedback recurrent neural

networks.

In ICML’15 . 351

Chung, J., Kastner, K.,

Dinh, L., Goel, K.,

Courville, A., and Bengio,

Y. (2015b). A recurrent

latent variable model for

sequential data. In NIPS’2015

. 596

Ciresan, D.,

Meier, U., Masci, J.,

and Schmidhuber, J. (2012).

Multi-column deep neural network

for traffic sign classification.

Neural Networks, 32, 333–338.

22, 174

参考文

献 627

Ciresan, D. C., Meier,

U., Gambardella, L. M.,

and Schmidhuber, J. (2010).

Deep big simple

neural

nets for handwritten digit

recognition. Neural Computation, 22,

1–14. 20, 21, 379

Coates, A. and Ng,

A. Y. (2011). The

importance of encoding versus

training with sparse coding

and vector quantization. In

ICML’2011 . 21, 220,

425

Coates, A., Lee,

H., and Ng, A.

Y. (2011). An analysis

of single-layer networks in

unsuper￾vised feature learning. In

Proceedings of the Thirteenth

International Conference on Artificial

Intelligence and Statistics (AISTATS

2011). 310, 387

Coates,

A., Huval, B., Wang,

T., Wu, D., Catanzaro,

B., and Andrew, N.

(2013). Deep learning

with

COTS HPC systems. In

S. Dasgupta and D.

McAllester, editors, Proceedings of

the 30th

International Conference

on Machine Learning (ICML-13),

volume 28 (3), pages

1337–1345.

JMLR Workshop and

Conference Proceedings. 20, 21,

310, 381

Cohen, N.,

Sharir, O., and Shashua,

A. (2015). On the

expressive power of deep

learning: A

tensor analysis.

arXiv:1509.05009. 472

Collobert, R.

(2004). Large Scale Machine

Learning. Ph.D. thesis, Université

de Paris VI, LIP6.

170

Collobert, R. (2011).

Deep learning for efficient

discriminative parsing. In AISTATS’2011

. 89,

406

Collobert,

R. and Weston, J.

(2008a). A unified architecture

for natural language processing:

Deep neural networks with

multitask learning. In ICML’2008

. 401, 406

Collobert,

R. and Weston, J.

(2008b). A unified architecture

for natural language processing:

Deep neural networks with

multitask learning. In ICML’2008

. 455

Collobert, R.,

Bengio, S., and Bengio,

Y. (2001). A parallel

mixture of SVMs for

very large

scale problems.

Technical Report 12, IDIAP.

383

Collobert, R., Bengio,

S., and Bengio, Y.

(2002). Parallel mixture of

SVMs for very large

scale

problem. Neural Computation.

383

Collobert, R., Weston,

J., Bottou, L., Karlen,

M., Kavukcuoglu, K., and

Kuksa, P. (2011a). Nat￾ural

language processing (almost) from

scratch. The Journal of

Machine Learning Research,

12,

2493–2537. 279, 406, 455,

456

Collobert, R., Kavukcuoglu,

K., and Farabet, C.

(2011b). Torch7: A Matlab-like

environment

for machine learning.

In BigLearn, NIPS Workshop.

23, 182, 380

628

参考文献

Comon, P. (1994). Independent

component analysis - a

new concept? Signal Processing,

36,

287–314. 419

Cortes,

C. and Vapnik, V.

(1995). Support vector networks.

Machine Learning, 20, 273–297.

16, 123

Couprie, C.,

Farabet, C., Najman, L.,

and LeCun, Y. (2013).

Indoor semantic segmentation using

depth information. In International

Conference on Learning Representations

(ICLR2013). 22,

174

Courbariaux,

M., Bengio, Y., and

David, J.-P. (2015). Low

precision arithmetic for deep

learning.

In Arxiv:1412.7024, ICLR’2015

Workshop. 384

Courville, A.,

Bergstra, J., and Bengio,

Y. (2011a). Unsupervised models

of images by spike￾and-slab

RBMs. In ICML’2011 .

477

Courville, A., Bergstra,

J., and Bengio, Y.

(2011b). Unsupervised models of

images by spike￾and-slab RBMs.

In ICM ( 1b).

581

Courville, A., Desjardins,

G., Bergstra, J., and

Bengio, Y. (2014). The

spike-and-slab RBM

and extensions

to discrete and sparse

data distributions. Pattern Analysis

and Machine

Intelligence, IEEE

Transactions on, 36(9), 1874–1887.

583

Cover, T. M.

and Thomas, J. A.

(2006). Elements of Information

Theory, 2nd Edition. Wiley￾Interscience.

66

Cox, D. and

Pinto, N. (2011). Beyond

simple features: A large-scale

feature search approach

to

unconstrained face recognition. In

Automatic Face & Gesture

Recognition and Workshops

(FG

2011), 2011 IEEE International

Conference on, pages 8–15.

IEEE. 310

Cramér, H.

(1946). Mathematical methods of

statistics. Princeton University Press.

118, 252

Crick, F.

H. C. and Mitchison,

G. (1983). The function

of dream sleep. Nature,

304, 111–114.

518

Cybenko,

G. (1989). Approximation by

superpositions of a sigmoidal

function. Mathematics of

Control,

Signals, and Systems, 2,

303–314. 171

Dahl, G.

E., Ranzato, M., Mohamed,

A., and Hinton, G.

E. (2010). Phone recognition

with the

mean-covariance restricted

Boltzmann machine. In Advances

in Neural Information Process￾ing

Systems (NIPS). 22

Dahl,

G. E., Yu, D.,

Deng, L., and Acero,

A. (2012). Context-dependent pre-trained

deep neural

networks for

large vocabulary speech recognition.

IEEE Transactions on Audio,

Speech, and

Language Processing,

20(1), 33–42. 391

参考文献

629

Dahl, G. E.,

Sainath, T. N., and

Hinton, G. E. (2013).

Improving deep neural networks

for

LVCSR using rectified

linear units and dropout.

In ICASSP’2013 . 391

Dahl, G. E., Jaitly,

N., and Salakhutdinov, R.

(2014). Multi-task neural networks

for QSAR

predictions. arXiv:1406.1231.

24

Dauphin, Y. and

Bengio, Y. (2013). Stochastic

ratio matching of RBMs

for sparse high￾dimensional inputs.

In NIP ( 1).

528

Dauphin, Y., Glorot,

X., and Bengio, Y.

(2011). Large-scale learning of

embeddings with

reconstruction sampling.

In ICML’2011 . 401

Dauphin, Y., Pascanu, R.,

Gulcehre, C., Cho, K.,

Ganguli, S., and Bengio,

Y. (2014). Identifying

and

attacking the saddle point

problem in high-dimensional non-convex

optimization. In

NIPS’2014 .

244, 245

Davis, A.,

Rubinstein, M., Wadhwa, N.,

Mysore, G., Durand, F.,

and Freeman, W. T.

(2014).

The visual microphone:

Passive recovery of sound

from video. ACM Transactions

on Graphics

(Proc. SIGGRAPH),

33(4), 79:1–79:10. 385

Dayan,

P. (1990). Reinforcement comparison.

In Connectionist Models: Proceedings

of the 1990

Connectionist

Summer School, San Mateo,

CA. 590

Dayan, P.

and Hinton, G. E.

(1996). Varieties of Helmholtz

machine. Neural Networks, 9(8),

1385–1403. 592

Dayan, P.,

Hinton, G. E., Neal,

R. M., and Zemel,

R. S. (1995). The

Helmholtz machine. Neural

computation,

7(5), 889–904. 592

Dean,

J., Corrado, G., Monga,

R., Chen, K., Devin,

M., Le, Q., Mao,

M., Ranzato, M., Senior,

A., Tucker, P., Yang,

K., and Ng, A.

Y. (2012). Large scale

distributed deep networks. In

NIPS’2012 . 23, 381

Dean, T. and Kanazawa,

K. (1989). A model

for reasoning about persistence

and causation.

Computational Intelligence,

5(3), 142–150. 566

Deerwester,

S., Dumais, S. T.,

Furnas, G. W., Landauer,

T. K., and Harshman,

R. (1990). In￾dexing by

latent semantic analysis. Journal

of the American Society

for Information Science,

41(6),

391–407. 406, 410

Delalleau,

O. and Bengio, Y.

(2011). Shallow vs. deep

sum-product networks. In NIPS.

17, 472

Deng, J.,

Dong, W., Socher, R.,

Li, L.-J., Li, K.,

and Fei-Fei, L. (2009).

ImageNet: A Large-Scale

Hierarchical

Image Database. In CVPR09

. 18

630 参

考文献

Deng, J., Berg, A.

C., Li, K., and

Fei-Fei, L. (2010a). What

does classifying more than

10,000

image categories tell

us? In Proceedings of

the 11th European Conference

on Computer Vision:

Part

V, ECCV’10, pages 71–84,

Berlin, Heidelberg. Springer-Verlag. 18

Deng, L. and Yu,

D. (2014). Deep learning

– methods and applications.

Foundations and Trends

in

Signal Processing. 391

Deng,

L., Seltzer, M., Yu,

D., Acero, A., Mohamed,

A., and Hinton, G.

(2010b). Binary coding

of

speech spectrograms using a

deep auto-encoder. In Interspeech

2010 , Makuhari, Chiba,

Japan. 22

Denil, M.,

Bazzani, L., Larochelle, H.,

and de Freitas, N.

(2012). Learning where to

attend with

deep architectures

for image tracking. Neural

Computation, 24(8), 2151–2184. 313

Denton, E., Chintala, S.,

Szlam, A., and Fergus,

R. (2015). Deep generative

image models using

a

Laplacian pyramid of adversarial

networks. NIPS. 599, 612

Desjardins, G. and Bengio,

Y. (2008). Empirical evaluation

of convolutional RBMs for

vision.

Technical Report 1327,

Département d’Informatique et de

Recherche Opérationnelle, Univer￾sité de

Montréal. 583

Desjardins, G.,

Courville, A. C., Bengio,

Y., Vincent, P., and

Delalleau, O. (2010). Tempered

Markov chain Monte Carlo

for training of restricted

Boltzmann machines. In International

Conference on Artificial Intelligence

and Statistics, pages 145–152.

514, 524

Desjardins, G.,

Courville, A., and Bengio,

Y. (2011). On tracking

the partition function. In

NIPS’2011 . 537

Devlin,

J., Zbib, R., Huang,

Z., Lamar, T., Schwartz,

R., and Makhoul, J.

(2014). Fast and

robust

neural network joint models

for statistical machine translation.

In Proc. ACL’2014 .

403

Devroye, L. (2013).

Non-Uniform Random Variate Generation.

SpringerLink : Bücher. Springer

New York. 593

DiCarlo,

J. J. (2013). Mechanisms

underlying visual object recognition:

Humans vs. neurons

vs.

machines. NIPS Tutorial. 24,

312

Dinh, L., Krueger,

D., and Bengio, Y.

(2014). NICE: Non-linear independent

components

estimation. arXiv:1410.8516. 421

Donahue, J., Hendricks, L.

A., Guadarrama, S., Rohrbach,

M., Venugopalan, S., Saenko,

K.,

and Darrell, T.

(2014). Long-term recurrent convolutional

networks for visual recognition

and

description. arXiv:1411.4389. 90

参考

文献 631

Donoho, D.

L. and Grimes, C.

(2003). Hessian eigenmaps: new

locally linear embedding tech￾niques

for high-dimensional data. Technical

Report 2003-08, Dept. Statistics,

Stanford Uni￾versity. 141, 443

Dosovitskiy, A., Springenberg, J.

T., and Brox, T.

(2015). Learning to generate

chairs with

convolutional neural

networks. In Proceedings of

the IEEE Conference on

Computer Vision

and Pattern

Recognition, pages 1538–1546. 594,

601

Doya, K. (1993).

Bifurcations of recurrent neural

networks in gradient descent

learning. IEEE

Transactions on

Neural Networks, 1, 75–80.

343, 345

Dreyfus, S.

E. (1962). The numerical

solution of variational problems.

Journal of Mathematical

Analysis

and Applications, 5(1), 30–45.

194

Dreyfus, S. E.

(1973). The computational solution

of optimal control problems

with time lag.

IEEE

Transactions on Automatic Control,

18(4), 383–385. 194

Drucker,

H. and LeCun, Y.

(1992). Improving generalisation performance

using double back￾propagation. IEEE

Transactions on Neural Networks,

3(6), 991–997. 233

Duchi,

J., Hazan, E., and

Singer, Y. (2011). Adaptive

subgradient methods for online

learning

and stochastic optimization.

Journal of Machine Learning

Research. 261

Dudik, M.,

Langford, J., and Li,

L. (2011). Doubly robust

policy evaluation and learning.

In

Proceedings of the

28th International Conference on

Machine learning, ICML ’11.

410

Dugas, C., Bengio,

Y., Bélisle, F., and

Nadeau, C. (2001). Incorporating

second-order functional

knowledge for

better option pricing. In

T. Leen, T. Dietterich,

and V. Tresp, editors,

Advances

in Neural Information

Processing Systems 13 (NIPS’00),

pages 472–478. MIT Press.

61, 170

Dziugaite, G.

K., Roy, D. M.,

and Ghahramani, Z. (2015).

Training generative neural networks

via maximum mean discrepancy

optimization. arXiv preprint arXiv:1505.03906

. 600

El Hihi,

S. and Bengio, Y.

(1996). Hierarchical recurrent neural

networks for long-term depen￾dencies.

In NIPS 8 .

MIT Press. 340, 348

Elkahky, A. M., Song,

Y., and He, X.

(2015). A multi-view deep

learning approach for cross

domain user modeling in

recommendation systems. In Proceedings

of the 24th International

Conference on World Wide

Web, pages 278–288. 408

Elman, J. L. (1993).

Learning and development in

neural networks: The importance

of starting

small. Cognition,

48, 781–799. 279

632

参考文

献

Erhan, D., Manzagol,

P.-A., Bengio, Y., Bengio,

S., and Vincent, P.

(2009). The difficulty of

training deep architectures and

the effect of unsupervised

pre-training. In AISTATS’2009 ,

pages 153–160. 174

Erhan,

D., Bengio, Y., Courville,

A., Manzagol, P., Vincent,

P., and Bengio, S.

(2010). Why

does unsupervised

pre-training help deep learning?

J. Machine Learning Res.

452, 454, 455,

456

Fahlman, S. E., Hinton,

G. E., and Sejnowski,

T. J. (1983). Massively

parallel architectures for

AI:

NETL, thistle, and Boltzmann

machines. In Proceedings of

the National Conference on

Artificial Intelligence AAAI-83 .

486, 559

Fang, H.,

Gupta, S., Iandola, F.,

Srivastava, R., Deng, L.,

Dollár, P., Gao, J.,

He, X., Mitchell,

M.,

Platt, J. C., Zitnick,

C. L., and Zweig,

G. (2015). From captions

to visual concepts and

back. arXiv:1411.4952. 90

Farabet,

C., LeCun, Y., Kavukcuoglu,

K., Culurciello, E., Martini,

B., Akselrod, P., and

Talay,

S. (2011). Large-scale

FPGA-based convolutional networks. In

R. Bekkerman, M. Bilenko,

and J. Langford, editors,

Scaling up Machine Learning:

Parallel and Distributed Approaches.

Cambridge University Press. 447

Farabet, C., Couprie, C.,

Najman, L., and LeCun,

Y. (2013). Learning hierarchical

features

for scene labeling.

IEEE Transactions on Pattern

Analysis and Machine Intelligence,

35(8),

1915–1929. 22, 174,

306

Fei-Fei, L., Fergus,

R., and Perona, P.

(2006). One-shot learning of

object categories. IEEE

Transactions

on Pattern Analysis and

Machine Intelligence, 28(4), 594–611.

459

Finn, C., Tan,

X. Y., Duan, Y.,

Darrell, T., Levine, S.,

and Abbeel, P. (2015).

Learning

visual feature spaces

for robotic manipulation with

deep spatial autoencoders. arXiv

preprint

arXiv:1509.06113 . 23

Fisher, R. A. (1936).

The use of multiple

measurements in taxonomic problems.

Annals of

Eugenics, 7,

179–188. 18, 92

Földiák,

P. (1989). Adaptive network

for optimal linear feature

extraction. In International

Joint

Conference on Neural Networks

(IJCNN), volume 1, pages

401–405, Washington 1989.

IEEE,

New York. 421

Franzius,

M., Sprekeler, H., and

Wiskott, L. (2007). Slowness

and sparseness lead to

place,

head-direction, and spatial-view

cells. 423

参考文献

633

Franzius,

M., Wilbert, N., and

Wiskott, L. (2008). Invariant

object recognition with slow

feature

analysis. In Proceedings

of the 18th international

conference on Artificial Neural

Networks,

Part I, ICANN

’08, pages 961–970, Berlin,

Heidelberg. Springer-Verlag. 423

Frasconi,

P., Gori, M., and

Sperduti, A. (1997). On

the efficient classification of

data structures

by neural

networks. In Proc. Int.

Joint Conf. on Artificial

Intelligence. 341, 342

Frasconi,

P., Gori, M., and

Sperduti, A. (1998). A

general framework for adaptive

processing of

data structures.

IEEE Transactions on Neural

Networks, 9(5), 768–786. 341,

342

Freund, Y. and

Schapire, R. E. (1996a).

Experiments with a new

boosting algorithm. In Machine

Learning: Proceedings of Thirteenth

International Conference, pages 148–156,

USA. ACM.

222

Freund,

Y. and Schapire, R.

E. (1996b). Game theory,

on-line prediction and boosting.

In

Proceedings of the

Ninth Annual Conference on

Computational Learning Theory, pages

325–

332. 222

Frey,

B. J. (1998). Graphical

models for machine learning

and digital communication. MIT

Press. 602

Frey, B.

J., Hinton, G. E.,

and Dayan, P. (1996).

Does the wake-sleep algorithm

learn good

density estimators?

In D. Touretzky, M.

Mozer, and M. Hasselmo,

editors, Advances in

Neural

Information Processing Systems 8

(NIPS’95), pages 661–670. MIT

Press, Cambridge,

MA. 557

Frobenius, G. (1908). Über

matrizen aus positiven elementen,

s. B. Preuss. Akad.

Wiss. Berlin,

Germany. 508

Fukushima, K. (1975). Cognitron:

A self-organizing multilayered neural

network. Biological

Cybernetics, 20,

121–136. 14, 195, 451

Fukushima, K. (1980). Neocognitron:

A self-organizing neural network

model for a mechanism

of pattern recognition unaffected

by shift in position.

Biological Cybernetics, 36, 193–202.

14, 20, 21, 195,

313

Gal, Y. and

Ghahramani, Z. (2015). Bayesian

convolutional neural networks with

Bernoulli

approximate variational inference.

arXiv preprint arXiv:1506.02158 .

227

Gallinari, P., LeCun,

Y., Thiria, S., and

Fogelman-Soulie, F. (1987). Memoires

associatives

distribuees. In Proceedings

of COGNITIVA 87 ,

Paris, La Villette. 440

634 参考文献

Garcia-Duran, A.,

Bordes, A., Usunier, N.,

and Grandvalet, Y. (2015).

Combining two

and three-way

embeddings models for link

prediction in knowledge bases.

arXiv preprint

arXiv:1506.00999 .

412

Garofolo, J. S.,

Lamel, L. F., Fisher,

W. M., Fiscus, J.

G., and Pallett, D.

S. (1993). Darpa timit

acoustic-phonetic continous speech corpus

cd-rom. nist speech disc

1-1.1. NASA STI/Recon

Technical

Report N, 93, 27403.

390

Garson, J. (1900).

The metric system of

identification of criminals, as

used in Great Britain

and Ireland. The Journal

of the Anthropological Institute

of Great Britain and

Ireland, (2),

177–227. 18

Gers, F. A., Schmidhuber,

J., and Cummins, F.

(2000). Learning to forget:

Continual prediction

with LSTM.

Neural computation, 12(10), 2451–2471.

349, 352

Ghahramani, Z.

and Hinton, G. E.

(1996). The EM algorithm

for mixtures of factor

analyzers.

Technical Report CRG-TR-96-1,

Dpt. of Comp. Sci.,

Univ. of Toronto. 417

Gillick, D., Brunk, C.,

Vinyals, O., and Subramanya,

A. (2015). Multilingual language

processing

from bytes. arXiv

preprint arXiv:1512.00103 . 406

Girshick, R., Donahue, J.,

Darrell, T., and Malik,

J. (2015). Region-based convolutional

networks

for accurate object

detection and segmentation. 363

Giudice, M. D., Manera,

V., and Keysers, C.

(2009). Programmed to learn?

The ontogeny of

mirror

neurons. Dev. Sci., 12(2),

350--–363. 560

Glorot, X.

and Bengio, Y. (2010).

Understanding the difficulty of

training deep feedforward

neural

networks. In AISTATS’2010 .

258

Glorot, X., Bordes,

A., and Bengio, Y.

(2011a). Deep sparse rectifier

neural networks. In

AISTATS’2011

. 15, 150, 170,

195

Glorot, X., Bordes,

A., and Bengio, Y.

(2011b). Domain adaptation for

large-scale sentiment

classification: A

deep learning approach. In

ICML’2011 . 433

Glorot,

X., Bordes, A., and

Bengio, Y. (2011c). Domain

adaptation for large-scale sentiment

classification: A deep learning

approach. In ICM (

1b), pages 97–110. 457

Goldberger, J., Roweis, S.,

Hinton, G. E., and

Salakhutdinov, R. (2005). Neighbourhood

compo￾nents analysis. In L.

Saul, Y. Weiss, and

L. Bottou, editors, Advances

in Neural Information

Processing

Systems 17 (NIPS’04). MIT

Press. 101

参

考文献 635

Gong, S., McKenna, S.,

and Psarrou, A. (2000).

Dynamic Vision: From Images

to Face Recog￾nition. Imperial

College Press. 142, 443

Goodfellow, I., Le, Q.,

Saxe, A., and Ng,

A. (2009). Measuring invariances

in deep networks.

In

Y. Bengio, D. Schuurmans,

C. Williams, J. Lafferty,

and A. Culotta, editors,

Advances in

Neural Information

Processing Systems 22 (NIPS’09),

pages 646–654. 219

Goodfellow,

I., Koenig, N., Muja,

M., Pantofaru, C., Sorokin,

A., and Takayama, L.

(2010).

Help me help

you: Interfaces for personal

robots. In Proc. of

Human Robot Interaction

(HRI),

Osaka, Japan. ACM Press,

ACM Press. 88

Goodfellow,

I., Mirza, M., Xiao,

D., Courville, A., and

Bengio, Y. (2014a). An

empirical

investigation of catastrophic

forgetting in gradient-based neural

networks. In ICLR’14 .

168

Goodfellow, I. J.

(2010). Technical report: Multidimensional,

downsampled convolution for

autoencoders.

Technical report, Université de

Montréal. 302

Goodfellow, I.

J. (2014). On distinguishability

criteria for estimating generative

models. In

International Conference

on Learning Representations, Workshops

Track. 531, 598

Goodfellow,

I. J., Courville, A.,

and Bengio, Y. (2011).

Spike-and-slab sparse coding for

unsu￾pervised feature discovery. In

NIPS Workshop on Challenges

in Learning Hierarchical Models.

454, 458

Goodfellow, I.

J., Warde-Farley, D., Mirza,

M., Courville, A., and

Bengio, Y. (2013a). Maxout

networks. In ICML’2013 .

167

Goodfellow, I. J.,

Warde-Farley, D., Mirza, M.,

Courville, A., and Bengio,

Y. (2013b). Maxout

networks.

In ICM ( 1c),

pages 1319–1327. 227, 292,

312

Goodfellow, I. J.,

Warde-Farley, D., Mirza, M.,

Courville, A., and Bengio,

Y. (2013c). Maxout

networks.

Technical Report arXiv:1302.4389, Université

de Montréal. 387

Goodfellow,

I. J., Mirza, M.,

Courville, A., and Bengio,

Y. (2013d). Multi-prediction deep

Boltzmann machines. In NIP

( 1). 89, 526,

572, 574, 575, 576,

577, 596

Goodfellow, I.

J., Warde-Farley, D., Lamblin,

P., Dumoulin, V., Mirza,

M., Pascanu, R.,

Bergstra,

J., Bastien, F., and

Bengio, Y. (2013e). Pylearn2:

a machine learning research

library. arXiv preprint arXiv:1308.4214

. 23, 380

Goodfellow,

I. J., Courville, A.,

and Bengio, Y. (2013f).

Scaling up spike-and-slab models

for

unsupervised feature learning.

IEEE T. PAMI, pages

1902–1914. 425, 426, 555

636 参考

文献

Goodfellow, I.

J., Courville, A., and

Bengio, Y. (2013g). Scaling

up spike-and-slab models

for

unsupervised feature learning. IEEE

Transactions on Pattern Analysis

and Machine

Intelligence, 35(8),

1902–1914. 583

Goodfellow, I.

J., Shlens, J., and

Szegedy, C. (2014b). Explaining

and harnessing adversarial

examples.

CoRR, abs/1412.6572. 230, 231,

233, 473, 474

Goodfellow,

I. J., Pouget-Abadie, J.,

Mirza, M., Xu, B.,

Warde-Farley, D., Ozair, S.,

Courville,

A., and Bengio,

Y. (2014c). Generative adversarial

networks. In NIPS’2014 .

464, 588, 597,

598,

601

Goodfellow, I. J.,

Bulatov, Y., Ibarz, J.,

Arnoud, S., and Shet,

V. (2014d). Multi-digit number

recognition from Street View

imagery using deep convolutional

neural networks. In Interna￾tional

Conference on Learning Representations.

22, 89, 174, 175,

334, 359, 382

Goodfellow,

I. J., Vinyals, O.,

and Saxe, A. M.

(2015). Qualitatively characterizing neural

network optimization problems. In

International Conference on Learning

Representations.

244, 245, 246,

248

Goodman, J. (2001).

Classes for fast maximum

entropy training. In International

Conference

on Acoustics, Speech

and Signal Processing (ICASSP),

Utah. 397

Gori, M.

and Tesi, A. (1992).

On the problem of

local minima in backpropagation.

IEEE

Transactions on Pattern

Analysis and Machine Intelligence,

PAMI-14(1), 76–86. 243

Gosset,

W. S. (1908). The

probable error of a

mean. Biometrika, 6(1), 1–25.

Originally published

under the

pseudonym “Student”. 18

Gouws,

S., Bengio, Y., and

Corrado, G. (2014). BilBOWA:

Fast bilingual distributed represen￾tations

without word alignments. Technical

report, arXiv:1410.2455. 406, 459

Graf, H. P. and

Jackel, L. D. (1989).

Analog electronic neural network

circuits. Circuits and

Devices

Magazine, IEEE, 5(4), 44–49.

384

Graves, A. (2011).

Practical variational inference for

neural networks. In NIPS’2011

. 208

Graves, A.

(2012). Supervised Sequence Labelling

with Recurrent Neural Networks.

Studies in

Computational Intelligence.

Springer. 320, 336, 351,

392

Graves, A. (2013).

Generating sequences with recurrent

neural networks. Technical report,

arXiv:1308.0850. 164, 349, 351,

354, 358

Graves, A.

and Jaitly, N. (2014).

Towards end-to-end speech recognition

with recurrent neural

networks.

In ICML’2014 . 349

参考文

献 637

Graves, A.

and Schmidhuber, J. (2005).

Framewise phoneme classification with

bidirectional

LSTM and other

neural network architectures. Neural

Networks, 18(5), 602–610. 337

Graves, A. and Schmidhuber,

J. (2009). Offline handwriting

recognition with multidimensional

recurrent

neural networks. In D.

Koller, D. Schuurmans, Y.

Bengio, and L. Bottou,

editors,

NIPS’2008 , pages

545–552. 337

Graves, A.,

Fernández, S., Gomez, F.,

and Schmidhuber, J. (2006).

Connectionist tempo￾ral classification: Labelling

unsegmented sequence data with

recurrent neural networks. In

ICML’2006 , pages 369–376,

Pittsburgh, USA. 392

Graves,

A., Liwicki, M., Bunke,

H., Schmidhuber, J., and

Fernández, S. (2008). Unconstrained

on-line handwriting recognition with

recurrent neural networks. In

J. Platt, D. Koller,

Y. Singer, and S.

Roweis, editors, NIPS’2007 ,

pages 577–584. 337

Graves,

A., Liwicki, M., Fernández,

S., Bertolami, R., Bunke,

H., and Schmidhuber, J.

(2009).

A novel connectionist

system for unconstrained handwriting

recognition. Pattern Analysis

and

Machine Intelligence, IEEE Transactions

on, 31(5), 855–868. 349

Graves, A., Mohamed, A.,

and Hinton, G. (2013).

Speech recognition with deep

recurrent neural

networks. In

ICASSP’2013 , pages 6645–6649.

337, 340, 349, 392

Graves, A., Wayne, G.,

and Danihelka, I. (2014).

Neural Turing machines. arXiv:1410.5401.

23,

356

Grefenstette, E.,

Hermann, K. M., Suleyman,

M., and Blunsom, P.

(2015). Learning to transduce

with unbounded memory. In

NIPS’2015 . 356

Greff,

K., Srivastava, R. K.,

Koutník, J., Steunebrink, B.

R., and Schmidhuber, J.

(2015).

LSTM: a search

space odyssey. arXiv preprint

arXiv:1503.04069 . 352

Gregor,

K. and LeCun, Y.

(2010a). Emergence of complex-like

cells in a temporal

product

network with local

receptive fields. Technical report,

arXiv:1006.0448. 300

Gregor, K.

and LeCun, Y. (2010b).

Learning fast approximations of

sparse coding. In L.

Bottou

and M. Littman,

editors, Proceedings of the

Twenty-seventh International Conference on

Machine Learning (ICML-10). ACM.

558

Gregor, K., Danihelka,

I., Mnih, A., Blundell,

C., and Wierstra, D.

(2014). Deep autoregressive

networks.

In International Conference on

Machine Learning (ICML’2014). 592

Gregor, K., Danihelka, I.,

Graves, A., and Wierstra,

D. (2015). DRAW: A

recurrent neural

network for

image generation. arXiv preprint

arXiv:1502.04623 . 596

638

参考文献

Gretton, A., Borgwardt, K.

M., Rasch, M. J.,

Schölkopf, B., and Smola,

A. (2012). A kernel

two-sample test. The Journal

of Machine Learning Research,

13(1), 723–773. 601

Guillaume

Desjardins, Karen Simonyan, R.

P. K. K. (2015).

Natural neural networks. Technical

report, arXiv:1507.00210. 273

Gulcehre,

C. and Bengio, Y.

(2013). Knowledge matters: Importance

of prior information for

optimization. Technical Report arXiv:1301.4083,

Universite de Montreal. 22

Guo, H. and Gelfand,

S. B. (1992). Classification

trees with neural network

feature extraction.

Neural Networks,

IEEE Transactions on, 3(6),

923–933. 383

Gupta, S.,

Agrawal, A., Gopalakrishnan, K.,

and Narayanan, P. (2015).

Deep learning with

limited

numerical precision. CoRR, abs/1502.02551.

384

Gutmann, M. and

Hyvarinen, A. (2010). Noise-contrastive

estimation: A new estimation

prin￾ciple for unnormalized statistical

models. In Proceedings of

The Thirteenth International

Conference

on Artificial Intelligence and

Statistics (AISTATS’10). 529

Hadsell,

R., Sermanet, P., Ben,

J., Erkan, A., Han,

J., Muller, U., and

LeCun, Y. (2007). Online

learning for offroad robots:

Spatial label propagation to

learn long-range traversability. In

Proceedings of Robotics: Science

and Systems, Atlanta, GA,

USA. 386

Hajnal, A.,

Maass, W., Pudlak, P.,

Szegedy, M., and Turan,

G. (1993). Threshold circuits

of

bounded depth. J.

Comput. System. Sci., 46,

129–154. 172

Håstad, J.

(1986). Almost optimal lower

bounds for small depth

circuits. In Proceedings of

the 18th annual ACM

Symposium on Theory of

Computing, pages 6–20, Berkeley,

California.

ACM Press. 172

Håstad, J. and Goldmann,

M. (1991). On the

power of small-depth threshold

circuits. Compu￾tational Complexity, 1,

113–129. 172

Hastie, T.,

Tibshirani, R., and Friedman,

J. (2001). The elements

of statistical learning: data

mining, inference and prediction.

Springer Series in Statistics.

Springer Verlag. 126

He,

K., Zhang, X., Ren,

S., and Sun, J.

(2015). Delving deep into

rectifiers: Surpassing human￾level performance

on ImageNet classification. arXiv

preprint arXiv:1502.01852 . 23,

167

Hebb, D. O.

(1949). The Organization of

Behavior . Wiley, New

York. 13, 15, 560

Henaff, M., Jarrett, K.,

Kavukcuoglu, K., and LeCun,

Y. (2011). Unsupervised learning

of

sparse features for

scalable audio classification. In

ISMIR’11 . 447

参考文献

639

Henderson, J. (2003).

Inducing history representations for

broad coverage statistical parsing.

In

HLT-NAACL, pages 103–110.

406

Henderson, J. (2004).

Discriminative training of a

neural network statistical parser.

In Pro￾ceedings of the

42nd Annual Meeting on

Association for Computational Linguistics,

page 95.

406

Henniges,

M., Puertas, G., Bornschein,

J., Eggert, J., and

Lücke, J. (2010). Binary

sparse

coding. In Latent

Variable Analysis and Signal

Separation, pages 450–457. Springer.

546

Herault, J. and

Ans, B. (1984). Circuits

neuronaux à synapses modifiables:

Décodage de mes￾sages composites

par apprentissage non supervisé.

Comptes Rendus de l’Académie

des Sci￾ences, 299(III-13), 525--–528.

419

Hinton, G., Deng,

L., Dahl, G. E.,

Mohamed, A., Jaitly, N.,

Senior, A., Vanhoucke, V.,

Nguyen,

P., Sainath, T.,

and Kingsbury, B. (2012a).

Deep neural networks for

acoustic modeling in

speech

recognition. IEEE Signal Processing

Magazine, 29(6), 82–97. 22,

391

Hinton, G., Vinyals,

O., and Dean, J.

(2015). Distilling the knowledge

in a neural network.

arXiv preprint arXiv:1503.02531 .

381

Hinton, G. E.

(1989). Connectionist learning procedures.

Artificial Intelligence, 40, 185–234.

421

Hinton, G. E.

(1990). Mapping part-whole hierarchies

into connectionist networks. Artificial

Intelligence, 46(1), 47–75. 356

Hinton, G. E. (1999).

Products of experts. In

Proceedings of the Ninth

International Conference

on Artificial

Neural Networks (ICANN), volume

1, pages 1–6, Edinburgh,

Scotland. IEE. 486

Hinton,

G. E. (2000). Training

products of experts by

minimizing contrastive divergence. Tech￾nical

Report GCNU TR 2000-004,

Gatsby Unit, University College

London. 519, 578

Hinton,

G. E. (2006). To

recognize shapes, first learn

to generate images. Technical

Report

UTML TR 2006-003,

University of Toronto. 451

Hinton, G. E. (2007a).

How to do backpropagation

in a brain. Invited

talk at the NIPS’2007

Deep Learning Workshop. 560

Hinton, G. E. (2007b).

Learning multiple layers of

representation. Trends in cognitive

sciences,

11(10), 428–434. 564

Hinton, G. E. (2010).

A practical guide to

training restricted Boltzmann machines.

Technical

Report UTML TR

2010-003, Comp. Sc., University

of Toronto. 519

640

参

考文献

Hinton, G. E.

(2012). Tutorial on deep

learning. IPAM Graduate Summer

School: Deep

Learning, Feature

Learning. 262

Hinton, G.

E. and Ghahramani, Z.

(1997). Generative models for

discovering sparse distributed

representations.

Philosophical Transactions of the

Royal Society of London.

128

Hinton, G. E.

and McClelland, J. L.

(1988). Learning representations by

recirculation. In

NIPS’1987 ,

pages 358–366. 429

Hinton,

G. E. and Roweis,

S. (2003). Stochastic neighbor

embedding. In NIPS’2002 .

443

Hinton, G. E.

and Salakhutdinov, R. (2006).

Reducing the dimensionality of

data with neural

networks.

Science, 313(5786), 504–507. 435,

448, 451, 452, 454

Hinton, G. E. and

Sejnowski, T. J. (1986).

Learning and relearning in

Boltzmann machines.

In D.

E. Rumelhart and J.

L. McClelland, editors, Parallel

Distributed Processing, volume 1,

chapter 7, pages 282–317.

MIT Press, Cambridge. 486,

559

Hinton, G. E.

and Sejnowski, T. J.

(1999). Unsupervised learning: foundations

of neural com￾putation. MIT

press. 462

Hinton, G.

E. and Shallice, T.

(1991). Lesioning an attractor

network: investigations of acquired

dyslexia. Psychological review, 98(1),

74. 12

Hinton, G.

E. and Zemel, R.

S. (1994). Autoencoders, minimum

description length, and

Helmholtz

free energy. In NIPS’1993

. 429

Hinton, G.

E., Sejnowski, T. J.,

and Ackley, D. H.

(1984a). Boltzmann machines: Constraint

satisfaction networks that learn.

Technical Report TR-CMU-CS-84-119, Carnegie-Mellon

University, Dept. of Computer

Science. 486

Hinton, G.

E., Sejnowski, T. J.,

and Ackley, D. H.

(1984b). Boltzmann machines: Constraint

satisfaction networks that learn.

Technical Report TR-CMU-CS-84-119, Carnegie-Mellon

University, Dept. of Computer

Science. 559

Hinton, G.

E., McClelland, J., and

Rumelhart, D. (1986). Distributed

representations. In D. E.

Rumelhart and J. L.

McClelland, editors, Parallel Distributed

Processing: Explorations in the

Microstructure of Cognition, volume

1, pages 77–109. MIT

Press, Cambridge. 16, 194,

449

Hinton, G. E.,

Revow, M., and Dayan,

P. (1995a). Recognizing handwritten

digits using mixtures

of

linear models. In G.

Tesauro, D. Touretzky, and

T. Leen, editors, Advances

in Neural

Information Processing

Systems 7 (NIPS’94), pages

1015–1022. MIT Press, Cambridge,

MA.

417

参考

文献 641

Hinton, G. E., Dayan,

P., Frey, B. J.,

and Neal, R. M.

(1995b). The wake-sleep algorithm

for

unsupervised neural networks.

Science, 268, 1558–1161. 431,

557

Hinton, G. E.,

Dayan, P., and Revow,

M. (1997). Modelling the

manifolds of images of

hand￾written digits. IEEE Transactions

on Neural Networks, 8,

65–74. 426

Hinton, G.

E., Welling, M., Teh,

Y. W., and Osindero,

S. (2001). A new

view of ICA. In

Proceedings of 3rd International

Conference on Independent Component

Analysis and Blind

Signal

Separation (ICA’01), pages 746–751,

San Diego, CA. 419

Hinton, G. E., Osindero,

S., and Teh, Y.

(2006a). A fast learning

algorithm for deep belief

nets.

Neural Computation, 18,

1527–1554. 13, 17, 21,

506, 564, 565

Hinton,

G. E., Osindero, S.,

and Teh, Y.-W. (2006b).

A fast learning algorithm

for deep belief

nets.

Neural Computation, 18, 1527–1554.

125, 451, 452

Hinton,

G. E., Deng, L.,

Yu, D., Dahl, G.

E., Mohamed, A., Jaitly,

N., Senior, A., Vanhoucke,

V., Nguyen, P., Sainath,

T. N., and Kingsbury,

B. (2012b). Deep neural

networks for acoustic

modeling

in speech recognition: The

shared views of four

research groups. IEEE Signal

Process. Mag., 29(6), 82–97.

89

Hinton, G. E.,

Srivastava, N., Krizhevsky, A.,

Sutskever, I., and Salakhutdinov,

R. (2012c).

Improving neural

networks by preventing co-adaptation

of feature detectors. Technical

report,

arXiv:1207.0580. 205, 226

Hinton, G. E., Srivastava,

N., Krizhevsky, A., Sutskever,

I., and Salakhutdinov, R.

(2012d).

Improving neural networks

by preventing co-adaptation of

feature detectors. Technical report,

arXiv:1207.0580. 229

Hinton, G.

E., Vinyals, O., and

Dean, J. (2014). Dark

knowledge. Invited talk at

the BayLearn

Bay Area

Machine Learning Symposium. 381

Hochreiter, S. (1991a). Untersuchungen

zu dynamischen neuronalen Netzen.

Diploma thesis,

T.U. München.

343, 344

Hochreiter, S.

(1991b). Untersuchungen zu dynamischen

neuronalen Netzen. Diploma thesis,

Institut für Informatik, Lehrstuhl

Prof. Brauer, Technische Universität

München. 16

Hochreiter, S.

and Schmidhuber, J. (1995).

Simplifying neural nets by

discovering flat minima.

In

Advances in Neural Information

Processing Systems 7 ,

pages 529–536. MIT Press.

209

Hochreiter, S. and

Schmidhuber, J. (1997). Long

short-term memory. Neural Computation,

9(8), 1735–1780. 16, 349,

351

642 参考文

献

Hochreiter,

S., Bengio, Y., and

Frasconi, P. (2001). Gradient

flow in recurrent nets:

the difficulty

of learning

long-term dependencies. In J.

Kolen and S. Kremer,

editors, Field Guide to

Dynamical Recurrent Networks. IEEE

Press. 351

Holi, J.

L. and Hwang, J.-N.

(1993). Finite precision error

analysis of neural network

hardware

implementations. Computers, IEEE

Transactions on, 42(3), 281–290.

384

Holt, J. L.

and Baker, T. E.

(1991). Back propagation simulations

using limited precision

calculations.

In Neural Networks, 1991.,

IJCNN-91-Seattle International Joint Conference

on, volume 2, pages

121–126. IEEE. 384

Hornik,

K., Stinchcombe, M., and

White, H. (1989). Multilayer

feedforward networks are uni￾versal

approximators. Neural Networks, 2,

359–366. 171

Hornik, K.,

Stinchcombe, M., and White,

H. (1990). Universal approximation

of an unknown

mapping

and its derivatives using

multilayer feedforward networks. Neural

networks, 3(5),

551–560. 171

Hsu, F.-H. (2002). Behind

Deep Blue: Building the

Computer That Defeated the

World Chess

Champion. Princeton

University Press, Princeton, NJ,

USA. 2

Huang, F.

and Ogata, Y. (2002).

Generalized pseudo-likelihood estimates for

Markov random

fields on

lattice. Annals of the

Institute of Statistical Mathematics,

54(1), 1–18. 525

Huang,

P.-S., He, X., Gao,

J., Deng, L., Acero,

A., and Heck, L.

(2013). Learning deep struc￾tured

semantic models for web

search using clickthrough data.

In Proceedings of the

22nd

ACM international conference

on Conference on information

& knowledge management, pages

2333–2338. ACM. 408

Hubel,

D. and Wiesel, T.

(1968). Receptive fields and

functional architecture of monkey

striate

cortex. Journal of

Physiology (London), 195, 215–243.

311

Hubel, D. H.

and Wiesel, T. N.

(1959). Receptive fields of

single neurons in the

cat’s striate

cortex. Journal

of Physiology, 148, 574–591.

311

Hubel, D. H.

and Wiesel, T. N.

(1962). Receptive fields, binocular

interaction, and functional

architecture

in the cat’s visual

cortex. Journal of Physiology

(London), 160, 106–154. 311

Huszar, F. (2015). How

(not) to train your

generative model: schedule sampling,

likelihood,

adversary? arXiv:1511.05101 .

596

Hutter, F., Hoos,

H., and Leyton-Brown, K.

(2011). Sequential model-based optimization

for

general algorithm configuration.

In LION-5 . Extended

version as UBC Tech

report TR-2010-

10. 371

参考文献

643

Hyotyniemi, H. (1996).

Turing machines are recurrent

neural networks. In STeP’96

, pages

13–24. 325

Hyvärinen, A. (1999). Survey

on independent component analysis.

Neural Computing Surveys,

2,

94–128. 419

Hyvärinen, A.

(2005a). Estimation of non-normalized

statistical models using score

matching.

Journal of Machine

Learning Research, 6, 695–709.

437

Hyvärinen, A. (2005b).

Estimation of non-normalized statistical

models using score matching.

J. Machine Learning Res.,

6. 526

Hyvärinen, A.

(2007a). Connections between score

matching, contrastive divergence, and

pseu￾dolikelihood for continuous-valued variables.

IEEE Transactions on Neural

Networks, 18,

1529–1531. 527

Hyvärinen, A. (2007b). Some

extensions of score matching.

Computational Statistics and Data

Analysis, 51, 2499–2512. 527

Hyvärinen, A. and Hoyer,

P. O. (1999). Emergence

of topography and complex

cell properties

from natural

images using extensions of

ica. In NIPS, pages

827–833. 421

Hyvärinen, A.

and Pajunen, P. (1999).

Nonlinear independent component analysis:

Existence

and uniqueness results.

Neural Networks, 12(3), 429–439.

420

Hyvärinen, A., Karhunen,

J., and Oja, E.

(2001a). Independent Component Analysis.

Wiley￾Interscience. 419

Hyvärinen, A.,

Hoyer, P. O., and

Inki, M. O. (2001b).

Topographic independent component

analysis.

Neural Computation, 13(7), 1527–1558.

421

Hyvärinen, A., Hurri,

J., and Hoyer, P.

O. (2009). Natural Image

Statistics: A probabilistic

approach

to early computational vision.

Springer-Verlag. 316

Iba, Y.

(2001). Extended ensemble Monte

Carlo. International Journal of

Modern Physics,

C12, 623–656.

514

Inayoshi, H. and

Kurita, T. (2005). Improved

generalization by adding both

auto-association and

hidden-layer noise

to neural-network-based-classifiers. IEEE Workshop

on Machine Learning

for

Signal Processing, pages 141––146.

440

Ioffe, S. and

Szegedy, C. (2015). Batch

normalization: Accelerating deep network

training by

reducing internal

covariate shift. 88, 271,

273

644 参考文献

Jacobs,

R. A. (1988). Increased

rates of convergence through

learning rate adaptation. Neural

networks, 1(4), 295–307. 261

Jacobs, R. A., Jordan,

M. I., Nowlan, S.

J., and Hinton, G.

E. (1991). Adaptive mixtures

of

local experts. Neural

Computation, 3, 79–87. 163,

383

Jaeger, H. (2003).

Adaptive nonlinear system identification

with echo state networks.

In Ad￾vances in Neural

Information Processing Systems 15

. 345

Jaeger, H.

(2007a). Discovering multiscale dynamical

features with hierarchical echo

state net￾works. Technical report,

Jacobs University. 340

Jaeger,

H. (2007b). Echo state

network. Scholarpedia, 2(9), 2330.

345

Jaeger, H. (2012).

Long short-term memory in

echo state networks: Details

of a simulation

study.

Technical report, Technical report,

Jacobs University Bremen. 346

Jaeger, H. and Haas,

H. (2004). Harnessing nonlinearity:

Predicting chaotic systems and

saving

energy in wireless

communication. Science, 304(5667), 78–80.

21, 345

Jaeger, H.,

Lukosevicius, M., Popovici, D.,

and Siewert, U. (2007).

Optimization and applica￾tions of

echo state networks with

leaky- integrator neurons. Neural

Networks, 20(3), 335–352.

348

Jain, V., Murray, J.

F., Roth, F., Turaga,

S., Zhigulin, V., Briggman,

K. L., Helmstaedter,

M.

N., Denk, W., and

Seung, H. S. (2007).

Supervised learning of image

restoration with

convolutional networks.

In Computer Vision, 2007.

ICCV 2007. IEEE 11th

International

Conference on, pages

1–8. IEEE. 306

Jaitly,

N. and Hinton, G.

(2011). Learning a better

representation of speech soundwaves

using

restricted Boltzmann machines.

In Acoustics, Speech and

Signal Processing (ICASSP), 2011

IEEE International Conference on,

pages 5884–5887. IEEE. 390

Jaitly, N. and Hinton,

G. E. (2013). Vocal

tract length perturbation (VTLP)

improves speech

recognition. In

ICML’2013 . 207

Jarrett,

K., Kavukcuoglu, K., Ranzato,

M., and LeCun, Y.

(2009a). What is the

best multi-stage

architecture for

object recognition? In Proc.

International Conference on Computer

Vision

(ICCV’09), pages 2146–2153.

IEEE. 15, 167

Jarrett,

K., Kavukcuoglu, K., Ranzato,

M., and LeCun, Y.

(2009b). What is the

best multi-stage

architecture for

object recognition? In ICCV’09

. 20, 21, 150,

195, 310, 447

参

考文献

645

Jarzynski, C. (1997).

Nonequilibrium equality for free

energy differences. Phys. Rev.

Lett., 78,

2690–2693. 533,

536

Jaynes, E. T.

(2003). Probability Theory: The

Logic of Science. Cambridge

University Press. 47

Jean,

S., Cho, K., Memisevic,

R., and Bengio, Y.

(2014). On using very

large target vocabulary

for

neural machine translation. arXiv:1412.2007.

403

Jelinek, F. and

Mercer, R. L. (1980).

Interpolated estimation of Markov

source parameters from

sparse

data. In E. S.

Gelsema and L. N.

Kanal, editors, Pattern Recognition

in Practice.

North-Holland, Amsterdam.

393, 402

Jia, Y.

(2013). Caffe: An open

source convolutional architecture for

fast feature embedding.

http://caffe.berkeleyvision.org/.

23, 182

Jia, Y.,

Huang, C., and Darrell,

T. (2012). Beyond spatial

pyramids: Receptive field learning

for pooled image features.

In Computer Vision and

Pattern Recognition (CVPR), 2012

IEEE

Conference on, pages

3370–3377. IEEE. 293

Jim,

K.-C., Giles, C. L.,

and Horne, B. G.

(1996). An analysis of

noise in recurrent neural

networks: convergence and generalization.

IEEE Transactions on Neural

Networks, 7(6),

1424–1438. 208

Jordan, M. I. (1998).

Learning in Graphical Models.

Kluwer, Dordrecht, Netherlands. 16

Joulin, A. and Mikolov,

T. (2015). Inferring algorithmic

patterns with stack-augmented recurrent

nets. arXiv preprint arXiv:1503.01007

. 356

Jozefowicz, R.,

Zaremba, W., and Sutskever,

I. (2015). An empirical

evaluation of recurrent

network

architectures. In ICML’2015 .

260, 351, 352

Judd,

J. S. (1989). Neural

Network Design and the

Complexity of Learning. MIT

press. 250

Jutten, C.

and Herault, J. (1991).

Blind separation of sources,

part I: an adaptive

algorithm

based on neuromimetic

architecture. Signal Processing, 24,

1–10. 419

Kahou, S.

E., Pal, C., Bouthillier,

X., Froumenty, P., Gülçehre,

c., Memisevic, R., Vincent,

P., Courville, A., Bengio,

Y., Ferrari, R. C.,

Mirza, M., Jean, S.,

Carrier, P. L., Dauphin,

Y., Boulanger-Lewandowski, N., Aggarwal,

A., Zumer, J., Lamblin,

P., Raymond, J.-P.,

Desjardins,

G., Pascanu, R., Warde-Farley,

D., Torabi, A., Sharma,

A., Bengio, E., Côté,

M., Konda, K. R.,

and Wu, Z. (2013).

Combining modality specific deep

neural networks for

emotion

recognition in video. In

Proceedings of the 15th

ACM on International Conference

on Multimodal Interaction. 174

646 参考

文献

Kalchbrenner, N.

and Blunsom, P. (2013).

Recurrent continuous translation models.

In

EMNLP’2013 . 403

Kalchbrenner, N., Danihelka, I.,

and Graves, A. (2015).

Grid long short-term memory.

arXiv

preprint arXiv:1507.01526 .

338

Kamyshanska, H. and

Memisevic, R. (2015). The

potential energy of an

autoencoder. IEEE

Transactions on

Pattern Analysis and Machine

Intelligence. 439

Karpathy, A.

and Li, F.-F. (2015).

Deep visual-semantic alignments for

generating image de￾scriptions. In

CVPR’2015 . arXiv:1412.2306. 90

Karpathy, A., Toderici, G.,

Shetty, S., Leung, T.,

Sukthankar, R., and Fei-Fei,

L. (2014). Large￾scale video

classification with convolutional neural

networks. In CVPR. 18

Karush, W. (1939). Minima

of Functions of Several

Variables with Inequalities as

Side Con￾straints. Master’s thesis,

Dept. of Mathematics, Univ.

of Chicago. 85

Katz,

S. M. (1987). Estimation

of probabilities from sparse

data for the language

model compo￾nent of a

speech recognizer. IEEE Transactions

on Acoustics, Speech, and

Signal Processing,

ASSP-35(3), 400–401.

393, 402

Kavukcuoglu, K.,

Ranzato, M., and LeCun,

Y. (2008). Fast inference

in sparse coding algo￾rithms

with applications to object

recognition. Technical report, Computational

and Biolog￾ical Learning Lab,

Courant Institute, NYU. Tech

Report CBLL-TR-2008-12-01. 447

Kavukcuoglu,

K., Ranzato, M.-A., Fergus,

R., and LeCun, Y.

(2009). Learning invariant features

through topographic filter maps.

In CVPR’2009 . 447

Kavukcuoglu, K., Sermanet, P.,

Boureau, Y.-L., Gregor, K.,

Mathieu, M., and LeCun,

Y. (2010).

Learning convolutional

feature hierarchies for visual

recognition. In NIPS’2010 .

310, 447

Kelley, H.

J. (1960). Gradient theory

of optimal flight paths.

ARS Journal, 30(10), 947–954.

194

Khan, F., Zhu,

X., and Mutlu, B.

(2011). How do humans

teach: On curriculum learning

and

teaching dimension. In

Advances in Neural Information

Processing Systems 24 (NIPS’11),

pages 1449–1457. 280

Kim,

S. K., McAfee, L.

C., McMahon, P. L.,

and Olukotun, K. (2009).

A highly scalable

restricted

Boltzmann machine FPGA implementation.

In Field Programmable Logic

and

Applications, 2009. FPL

2009. International Conference on,

pages 367–372. IEEE. 384

参考文

献 647

Kindermann, R.

(1980). Markov Random Fields

and Their Applications (Contemporary

Math￾ematics ; V. 1).

American Mathematical Society. 482

Kingma, D. and Ba,

J. (2014). Adam: A

method for stochastic optimization.

arXiv preprint

arXiv:1412.6980 .

262

Kingma, D. and

LeCun, Y. (2010a). Regularized

estimation of image statistics

by score matching.

In

NIPS’2010 . 438

Kingma,

D. and LeCun, Y.

(2010b). Regularized estimation of

image statistics by score

match￾ing. In J. Lafferty,

C. K. I. Williams,

J. Shawe-Taylor, R. Zemel,

and A. Culotta, editors,

Advances in Neural Information

Processing Systems 23 ,

pages 1126–1134. 528

Kingma,

D., Rezende, D., Mohamed,

S., and Welling, M.

(2014). Semi-supervised learning with

deep generative models. In

NIPS’2014 . 363

Kingma,

D. P. (2013). Fast

gradient-based inference with continuous

latent variable models in

auxiliary form. Technical report,

arxiv:1306.0733. 558, 588, 594

Kingma, D. P. and

Welling, M. (2014a). Auto-encoding

variational bayes. In Proceedings

of the

International Conference

on Learning Representations (ICLR).

588, 597

Kingma, D.

P. and Welling, M.

(2014b). Efficient gradient-based inference

through transforma￾tions between bayes

nets and neural nets.

Technical report, arxiv:1402.0480. 588

Kirkpatrick, S., Jr., C.

D. G., , and

Vecchi, M. P. (1983).

Optimization by simulated annealing.

Science, 220, 671–680. 279

Kiros, R., Salakhutdinov, R.,

and Zemel, R. (2014a).

Multimodal neural language models.

In

ICML’2014 . 90

Kiros, R., Salakhutdinov, R.,

and Zemel, R. (2014b).

Unifying visual-semantic embeddings with

multimodal neural language models.

arXiv:1411.2539 [cs.LG]. 90, 349

Klementiev, A., Titov, I.,

and Bhattarai, B. (2012).

Inducing crosslingual distributed represen￾tations

of words. In Proceedings

of COLING 2012 .

406, 459

Knowles-Barley, S.,

Jones, T. R., Morgan,

J., Lee, D., Kasthuri,

N., Lichtman, J. W.,

and

Pfister, H. (2014).

Deep learning for the

connectome. GPU Technology Conference.

24

Koller, D. and

Friedman, N. (2009). Probabilistic

Graphical Models: Principles and

Techniques.

MIT Press. 496,

506, 551

648 参考文献

Konig,

Y., Bourlard, H., and

Morgan, N. (1996). REMAP:

Recursive estimation and maxi￾mization

of a posteriori probabilities

– application to transition-based

connectionist speech

recognition. In

D. Touretzky, M. Mozer,

and M. Hasselmo, editors,

Advances in Neural In￾formation

Processing Systems 8 (NIPS’95).

MIT Press, Cambridge, MA.

390

Koren, Y. (2009).

The BellKor solution to

the Netflix grand prize.

222, 408

Kotzias, D.,

Denil, M., de Freitas,

N., and Smyth, P.

(2015). From group to

individual labels

using deep

features. In ACM SIGKDD.

93

Koutnik, J., Greff,

K., Gomez, F., and

Schmidhuber, J. (2014). A

clockwork RNN. In

ICML’2014

. 348

Kočiský, T.,

Hermann, K. M., and

Blunsom, P. (2014). Learning

Bilingual Word Representations

by

Marginalizing Alignments. In Proceedings

of ACL. 404

Krause,

O., Fischer, A., Glasmachers,

T., and Igel, C.

(2013). Approximation properties of

DBNs with binary hidden

units and real-valued visible

units. In ICML’2013 .

472

Krizhevsky, A. (2010).

Convolutional deep belief networks

on CIFAR-10. Technical report,

Uni￾versity of Toronto. Unpublished

Manuscript: http://www.cs.utoronto.ca/ kriz/conv-cifar10-

aug2010.pdf.

380

Krizhevsky, A. and

Hinton, G. (2009). Learning

multiple layers of features

from tiny images.

Technical

report, University of Toronto.

18, 477

Krizhevsky, A.

and Hinton, G. E.

(2011). Using very deep

autoencoders for content-based image

retrieval. In ESANN. 448

Krizhevsky, A., Sutskever, I.,

and Hinton, G. (2012a).

ImageNet classification with deep

convo￾lutional neural networks. In

NIPS’2012 . 20, 21,

88, 174, 317

Krizhevsky,

A., Sutskever, I., and

Hinton, G. (2012b). ImageNet

classification with deep

convolutional

neural networks. In Advances

in Neural Information Processing

Systems 25

(NIPS’2012). 22,

386, 389

Krueger, K.

A. and Dayan, P.

(2009). Flexible shaping: how

learning in small steps

helps.

Cognition, 110, 380–394.

279

Kuhn, H. W.

and Tucker, A. W.

(1951). Nonlinear programming. In

Proceedings of the Second

Berkeley Symposium on Mathematical

Statistics and Probability, pages

481–492, Berkeley,

Calif. University

of California Press. 85

参考文献 649

Kumar, A.,

Irsoy, O., Ondruska, P.,

Iyyer, M., Bradbury, J.,

Gulrajani, I., and Socher,

R.

(2015a). Ask me

anything: Dynamic memory networks

for natural language processing.

Technical report, arXiv:1506.07285. 356

Kumar, A., Irsoy, O.,

Su, J., Bradbury, J.,

English, R., Pierce, B.,

Ondruska, P., Iyyer, M.,

Gulrajani, I., and Socher,

R. (2015b). Ask me

anything: Dynamic memory networks

for

natural language processing.

arXiv:1506.07285 . 412

Kumar,

M. P., Packer, B.,

and Koller, D. (2010).

Self-paced learning for latent

variable models.

In J.

Lafferty, C. K. I.

Williams, J. Shawe-Taylor, R.

Zemel, and A. Culotta,

editors, Advances

in Neural

Information Processing Systems 23

, pages 1189–1197. 279

Lang, K. J. and

Hinton, G. E. (1988).

The development of the

time-delay neural network

architecture

for speech recognition. Technical

Report CMU-CS-88-152, Carnegie-Mellon Uni￾versity.

313, 319, 347

Lang,

K. J., Waibel, A.

H., and Hinton, G.

E. (1990). A time-delay

neural network architecture

for

isolated word recognition. Neural

networks, 3(1), 23–43. 319

Langford, J. and Zhang,

T. (2008). The epoch-greedy

algorithm for contextual multi-armed

bandits. In NIPS’2008 ,

pages 1096--–1103. 409

Lappalainen,

H., Giannakopoulos, X., Honkela,

A., and Karhunen, J.

(2000). Nonlinear inde￾pendent component

analysis using ensemble learning:

Experiments and discussion. In

Proc.

ICA. Citeseer. 420

Larochelle, H. and Bengio,

Y. (2008a). Classification using

discriminative restricted Boltzmann

machines.

In ICML’2008 . 210,

586, 610

Larochelle, H.

and Bengio, Y. (2008b).

Classification using discriminative restricted

Boltzmann

machines. In ICM

( 1a), pages 536–543.

219, 453

Larochelle, H.

and Hinton, G. E.

(2010). Learning to combine

foveal glimpses with a

third￾order Boltzmann machine. In

Advances in Neural Information

Processing Systems 23 ,

pages

1243–1251. 313

Larochelle,

H. and Murray, I.

(2011). The Neural Autoregressive

Distribution Estimator. In

AISTATS’2011

. 602, 604, 605

Larochelle, H., Erhan, D.,

and Bengio, Y. (2008).

Zero-data learning of new

tasks. In AAAI

Conference

on Artificial Intelligence. 459

Larochelle, H., Bengio, Y.,

Louradour, J., and Lamblin,

P. (2009). Exploring strategies

for

training deep neural

networks. In JML (

1), pages 1–40. 455

650 参

考文献

Lasserre, J.

A., Bishop, C. M.,

and Minka, T. P.

(2006). Principled hybrids of

generative

and discriminative models.

In Proceedings of the

Computer Vision and Pattern

Recognition

Conference (CVPR’06), pages

87–94, Washington, DC, USA.

IEEE Computer Society. 210,

218

Le, Q., Ngiam,

J., Chen, Z., hao

Chia, D. J., Koh,

P. W., and Ng,

A. (2010). Tiled convolutional

neural networks. In J.

Lafferty, C. K. I.

Williams, J. Shawe-Taylor, R.

Zemel, and A. Culotta,

editors, Advances in Neural

Information Processing Systems 23

(NIPS’10), pages 1279–1287.

300

Le, Q., Ngiam, J.,

Coates, A., Lahiri, A.,

Prochnow, B., and Ng,

A. (2011). On optimization

methods for deep learning.

In Proc. ICML’2011 .

ACM. 270

Le, Q.,

Ranzato, M., Monga, R.,

Devin, M., Corrado, G.,

Chen, K., Dean, J.,

and Ng, A. (2012).

Building high-level features using

large scale unsupervised learning.

In ICML’2012 . 20,

21

Le Roux, N.

and Bengio, Y. (2008).

Representational power of restricted

Boltzmann machines

and deep

belief networks. Neural Computation,

20(6), 1631–1649. 472, 560

Le Roux, N. and

Bengio, Y. (2010). Deep

belief networks are compact

universal approximators.

Neural Computation,

22(8), 2192–2207. 472

LeCun,

Y. (1985). Une procédure

d’apprentissage pour Réseau à

seuil assymétrique. In Cogni￾tiva

85: A la Frontière

de l’Intelligence Artificielle, des

Sciences de la Connaissance

et des

Neurosciences, pages

599–604, Paris 1985. CESTA,

Paris. 194

LeCun, Y.

(1986). Learning processes in

an asymmetric threshold network.

In E. Bienenstock,

F.

Fogelman-Soulié, and G. Weisbuch,

editors, Disordered Systems and

Biological Organiza￾tion, pages 233–240.

Springer-Verlag, Berlin, Les Houches

1985. 298

LeCun, Y.

(1987). Modèles connexionistes de

l’apprentissage. Ph.D. thesis, Université

de Paris

VI. 16,

429, 440

LeCun, Y.

(1989). Generalization and network

design strategies. Technical Report

CRG-TR-

89-4, University of

Toronto. 281, 298

LeCun,

Y., Jackel, L. D.,

Boser, B., Denker, J.

S., Graf, H. P.,

Guyon, I., Henderson, D.,

Howard, R. E., and

Hubbard, W. (1989). Handwritten

digit recognition: Applications of

neural network chips and

automatic learning. IEEE Communications

Magazine, 27(11), 41–

46.

314

LeCun, Y., Bottou,

L., Orr, G. B.,

and Müller, K.-R. (1998a).

Efficient backprop. In Neural

Networks, Tricks of the

Trade, Lecture Notes in

Computer Science LNCS 1524.

Springer

Verlag. 265

参考

文献

651

LeCun, Y., Bottou,

L., Orr, G. B.,

and Müller, K. (1998b).

Efficient backprop. In Neural

Networks, Tricks of the

Trade. 365

LeCun, Y.,

Bottou, L., Bengio, Y.,

and Haffner, P. (1998c).

Gradient based learning applied

to

document recognition. Proc.

IEEE. 14, 16, 18,

21, 317, 390, 392

LeCun, Y., Kavukcuoglu, K.,

and Farabet, C. (2010).

Convolutional networks and applications

in

vision. In Circuits

and Systems (ISCAS), Proceedings

of 2010 IEEE International

Symposium

on, pages 253–256.

IEEE. 317

L’Ecuyer, P.

(1994). Efficiency improvement and

variance reduction. In Proceedings

of the 1994

Winter

Simulation Conference, pages 122--–132.

589

Lee, C.-Y., Xie,

S., Gallagher, P., Zhang,

Z., and Tu, Z.

(2014). Deeply-supervised nets. arXiv

preprint arXiv:1409.5185 . 278

Lee, H., Battle, A.,

Raina, R., and Ng,

A. (2007). Efficient sparse

coding algorithms. In

B.

Schölkopf, J. Platt, and

T. Hoffman, editors, Advances

in Neural Information Processing

Systems 19 (NIPS’06), pages

801–808. MIT Press. 544

Lee, H., Ekanadham, C.,

and Ng, A. (2008).

Sparse deep belief net

model for visual area

V2.

In NIPS’07 .

219

Lee, H., Grosse,

R., Ranganath, R., and

Ng, A. Y. (2009).

Convolutional deep belief net￾works

for scalable unsupervised learning

of hierarchical representations. In

L. Bottou and

M.

Littman, editors, Proceedings of

the Twenty-sixth International Conference

on Machine

Learning (ICML’09).

ACM, Montreal, Canada. 310,

583, 584

Lee, Y.

J. and Grauman, K.

(2011). Learning the easy

things first: self-paced visual

category

discovery. In CVPR’2011

. 279

Leibniz, G.

W. (1676). Memoir using

the chain rule. (Cited

in TMME 7:2&3 p

321-332, 2010).

194

Lenat,

D. B. and Guha,

R. V. (1989). Building

large knowledge-based systems; representation

and inference in the

Cyc project. Addison-Wesley Longman

Publishing Co., Inc. 2

Leshno, M., Lin, V.

Y., Pinkus, A., and

Schocken, S. (1993). Multilayer

feedforward networks

with a

nonpolynomial activation function can

approximate any function. Neural

Networks,

6, 861--–867. 171,

172

Levenberg, K. (1944).

A method for the

solution of certain non-linear

problems in least squares.

Quarterly Journal of Applied

Mathematics, II(2), 164–168. 266

652 参考文

献

L’Hôpital, G.

F. A. (1696). Analyse

des infiniment petits, pour

l’intelligence des lignes courbes.

Paris: L’Imprimerie Royale. 194

Li, Y., Swersky, K.,

and Zemel, R. S.

(2015). Generative moment matching

networks. CoRR,

abs/1502.02761. 600

Lin, T., Horne, B.

G., Tino, P., and

Giles, C. L. (1996).

Learning long-term dependencies is

not

as difficult with

NARX recurrent neural networks.

IEEE Transactions on Neural

Networks,

7(6), 1329–1338. 347

Lin, Y., Liu, Z.,

Sun, M., Liu, Y.,

and Zhu, X. (2015).

Learning entity and relation

embeddings

for knowledge graph

completion. In Proc. AAAI’15

. 412

Linde, N.

(1992). The machine that

changed the world, episode

3. Documentary miniseries. 2

Lindsey, C. and Lindblad,

T. (1994). Review of

hardware neural networks: a

user’s perspective.

In Proc.

Third Workshop on Neural

Networks: From Biology to

High Energy Physics, pages

195--–202, Isola d’Elba, Italy.

384

Linnainmaa, S. (1976).

Taylor expansion of the

accumulated rounding error. BIT

Numerical

Mathematics, 16(2), 146–160.

194

LISA (2008). Deep

learning tutorials: Restricted Boltzmann

machines. Technical report, LISA

Lab, Université de Montréal.

501

Long, P. M.

and Servedio, R. A.

(2010). Restricted Boltzmann machines

are hard to approxi￾mately

evaluate or simulate. In

Proceedings of the 27th

International Conference on Machine

Learning (ICML’10). 561

Lotter,

W., Kreiman, G., and

Cox, D. (2015). Unsupervised

learning of visual structure

using

predictive generative networks.

arXiv preprint arXiv:1511.06380 .

464, 465

Lovelace, A.

(1842). Notes upon L.

F. Menabrea’s “Sketch of

the Analytical Engine invented

by

Charles Babbage”. 1

Lu, L., Zhang, X.,

Cho, K., and Renals,

S. (2015). A study

of the recurrent neural

network

encoder-decoder for large

vocabulary speech recognition. In

Proc. Interspeech. 392

Lu,

T., Pál, D., and

Pál, M. (2010). Contextual

multi-armed bandits. In International

Confer￾ence on Artificial Intelligence

and Statistics, pages 485–492.

409

Luenberger, D. G.

(1984). Linear and Nonlinear

Programming. Addison Wesley. 270

Lukoševičius, M. and Jaeger,

H. (2009). Reservoir computing

approaches to recurrent neural

network training. Computer Science

Review, 3(3), 127–149. 345

参考文献

653

Luo, H., Shen,

R., Niu, C., and

Ullrich, C. (2011). Learning

class-relevant features and class￾irrelevant

features via a hybrid

third-order RBM. In International

Conference on Artificial

Intelligence

and Statistics, pages 470–478.

586

Luo, H., Carrier,

P. L., Courville, A.,

and Bengio, Y. (2013).

Texture modeling with convolu￾tional

spike-and-slab RBMs and deep

extensions. In AISTATS’2013 .

90

Lyu, S. (2009).

Interpretation and generalization of

score matching. In Proceedings

of the

Twenty-fifth Conference

in Uncertainty in Artificial

Intelligence (UAI’09). 527

Ma,

J., Sheridan, R. P.,

Liaw, A., Dahl, G.

E., and Svetnik, V.

(2015). Deep neural nets

as

a method for

quantitative structure –activity relationships.

J. Chemical information and

modeling. 452

Maas, A.

L., Hannun, A. Y.,

and Ng, A. Y.

(2013). Rectifier nonlinearities improve

neural

network acoustic models.

In ICML Workshop on

Deep Learning for Audio,

Speech, and

Language Processing.

167

Maass, W. (1992).

Bounds for the computational

power and learning complexity

of analog

neural nets

(extended abstract). In Proc.

of the 25th ACM

Symp. Theory of Computing,

pages 335–344. 172

Maass,

W., Schnitger, G., and

Sontag, E. D. (1994).

A comparison of the

computational power

of sigmoid

and Boolean threshold circuits.

Theoretical Advances in Neural

Computation and

Learning, pages

127–151. 172

Maass, W.,

Natschlaeger, T., and Markram,

H. (2002). Real-time computing

without stable

states: A

new framework for neural

computation based on perturbations.

Neural Computa￾tion, 14(11), 2531–2560.

345

MacKay, D. (2003).

Information Theory, Inference and

Learning Algorithms. Cambridge Uni￾versity

Press. 66

Maclaurin, D.,

Duvenaud, D., and Adams,

R. P. (2015). Gradient-based

hyperparameter opti￾mization through reversible

learning. arXiv preprint arXiv:1502.03492

. 370

Mao, J.,

Xu, W., Yang, Y.,

Wang, J., and Yuille,

A. (2014). Deep captioning

with multimodal

recurrent neural

networks (m-rnn). arXiv:1412.6632 [cs.CV].

90

Marcotte, P. and

Savard, G. (1992). Novel

approaches to the discrimination

problem. Zeitschrift

für Operations

Research (Theory), 36, 517–545.

237

Marlin, B. and

de Freitas, N. (2011).

Asymptotic efficiency of deterministic

estimators for

discrete energy-based

models: Ratio matching and

pseudolikelihood. In UAI’2011 .

526, 528

654 参考文献

Marlin, B., Swersky, K.,

Chen, B., and de

Freitas, N. (2010). Inductive

principles for restricted

Boltzmann

machine learning. In AISTATS’2010

, pages 509–516. 522,

527

Marquardt, D. W.

(1963). An algorithm for

least-squares estimation of non-linear

parameters.

Journal of the

Society of Industrial and

Applied Mathematics, 11(2), 431–441.

266

Marr, D. and

Poggio, T. (1976). Cooperative

computation of stereo disparity.

Science, 194. 313

Martens,

J. (2010). Deep learning

via Hessian-free optimization. In

ICML’2010 , pages 735–742.

259

Martens, J. and

Medabalimi, V. (2014). On

the expressive efficiency of

sum product networks.

arXiv:1411.7717

. 472

Martens, J.

and Sutskever, I. (2011).

Learning recurrent neural networks

with Hessian-free

optimization. In

Proc. ICML’2011 . ACM.

352, 353

Mase, S.

(1995). Consistency of the

maximum pseudo-likelihood estimator of

continuous state

space Gibbsian

processes. The Annals of

Applied Probability, 5(3), pp.

603–612. 525

McClelland, J.,

Rumelhart, D., and Hinton,

G. (1995). The appeal

of parallel distributed

processing.

In Computation & intelligence,

pages 305–341. American Association

for Artificial

Intelligence. 15

McCulloch, W. S. and

Pitts, W. (1943). A

logical calculus of ideas

immanent in nervous activity.

Bulletin of Mathematical Biophysics,

5, 115–133. 13

Mead,

C. and Ismail, M.

(2012). Analog VLSI implementation

of neural systems, volume

80.

Springer Science &

Business Media. 384

Melchior,

J., Fischer, A., and

Wiskott, L. (2013). How

to center binary deep

Boltzmann ma￾chines. arXiv preprint

arXiv:1311.1354 . 575

Memisevic,

R. and Hinton, G.

E. (2007). Unsupervised learning

of image transformations. In

Proceedings of the Computer

Vision and Pattern Recognition

Conference (CVPR’07). 586

Memisevic,

R. and Hinton, G.

E. (2010). Learning to

represent spatial transformations with

factored higher-order Boltzmann machines.

Neural Computation, 22(6), 1473–1492.

586

Mesnil, G., Dauphin,

Y., Glorot, X., Rifai,

S., Bengio, Y., Goodfellow,

I., Lavoie, E., Muller,

X., Desjardins, G., Warde-Farley,

D., Vincent, P., Courville,

A., and Bergstra, J.

(2011).

Unsupervised and transfer

learning challenge: a deep

learning approach. In JMLR

W&CP:

Proc. Unsupervised and

Transfer Learning, volume 7.

174, 454, 458

参

考文献

655

Mesnil, G., Rifai,

S., Dauphin, Y., Bengio,

Y., and Vincent, P.

(2012). Surfing on the

manifold.

Learning Workshop, Snowbird.

607

Miikkulainen, R. and

Dyer, M. G. (1991).

Natural language processing with

modular PDP

networks and

distributed lexicon. Cognitive Science,

15, 343–399. 406

Mikolov,

T. (2012). Statistical Language

Models based on Neural

Networks. Ph.D. thesis, Brno

University of Technology. 353

Mikolov, T., Deoras, A.,

Kombrink, S., Burget, L.,

and Cernocky, J. (2011a).

Empirical eval￾uation and combination

of advanced language modeling

techniques. In Proc. 12th

annual

conference of the

international speech communication association

(INTERSPEECH 2011).

402

Mikolov,

T., Deoras, A., Povey,

D., Burget, L., and

Cernocky, J. (2011b). Strategies

for training

large scale

neural network language models.

In Proc. ASRU’2011 .

279, 402

Mikolov, T.,

Chen, K., Corrado, G.,

and Dean, J. (2013a).

Efficient estimation of word

represen￾tations in vector space.

In International Conference on

Learning Representations: Workshops

Track.

456

Mikolov, T., Le,

Q. V., and Sutskever,

I. (2013b). Exploiting similarities

among languages for

machine

translation. Technical report, arXiv:1309.4168.

459

Minka, T. (2005).

Divergence measures and message

passing. Microsoft Research Cambridge

UK Tech Rep MSRTR2005173

, 72(TR-2005-173). 533

Minsky,

M. L. and Papert,

S. A. (1969). Perceptrons.

MIT Press, Cambridge. 14

Mirza, M. and Osindero,

S. (2014). Conditional generative

adversarial nets. arXiv preprint

arXiv:1411.1784 . 599

Mishkin,

D. and Matas, J.

(2015). All you need

is a good init.

arXiv preprint arXiv:1511.06422 .

259

Misra, J. and

Saha, I. (2010). Artificial

neural networks in hardware:

A survey of two

decades

of progress. Neurocomputing,

74(1), 239–255. 384

Mitchell,

T. M. (1997). Machine

Learning. McGraw-Hill, New York.

87

Miyato, T., Maeda,

S., Koyama, M., Nakae,

K., and Ishii, S.

(2015). Distributional smoothing

with

virtual adversarial training. In

ICLR. Preprint: arXiv:1507.00677. 231

Mnih, A. and Gregor,

K. (2014). Neural variational

inference and learning in

belief networks.

In ICML’2014

. 590, 591, 592

656 参考

文献

Mnih, A.

and Hinton, G. E.

(2007). Three new graphical

models for statistical language

mod￾elling. In Z. Ghahramani,

editor, Proceedings of the

Twenty-fourth International Conference

on

Machine Learning (ICML’07), pages

641–648. ACM. 396

Mnih,

A. and Hinton, G.

E. (2009). A scalable

hierarchical distributed language model.

In

D. Koller, D.

Schuurmans, Y. Bengio, and

L. Bottou, editors, Advances

in Neural Information

Processing

Systems 21 (NIPS’08), pages

1081–1088. 397

Mnih, A.

and Kavukcuoglu, K. (2013).

Learning word embeddings efficiently

with noise￾contrastive estimation. In

C. Burges, L. Bottou,

M. Welling, Z. Ghahramani,

and K. Wein￾berger, editors,

Advances in Neural Information

Processing Systems 26 ,

pages 2265–2273.

Curran Associates,

Inc. 401, 530

Mnih,

A. and Teh, Y.

W. (2012). A fast

and simple algorithm for

training neural probabilistic

language

models. In ICML’2012 ,

pages 1751–1758. 401

Mnih,

V. and Hinton, G.

(2010). Learning to detect

roads in high-resolution aerial

images. In

Proceedings of

the 11th European Conference

on Computer Vision (ECCV).

90

Mnih, V., Larochelle,

H., and Hinton, G.

(2011). Conditional restricted Boltzmann

machines for

structure output

prediction. In Proc. Conf.

on Uncertainty in Artificial

Intelligence (UAI).

585

Mnih,

V., Kavukcuoglo, K., Silver,

D., Graves, A., Antonoglou,

I., and Wierstra, D.

(2013).

Playing Atari with

deep reinforcement learning. Technical

report, arXiv:1312.5602. 93

Mnih,

V., Heess, N., Graves,

A., and Kavukcuoglu, K.

(2014). Recurrent models of

visual

attention. In Z.

Ghahramani, M. Welling, C.

Cortes, N. Lawrence, and

K. Weinberger,

editors, NIPS’2014

, pages 2204–2212. 591

Mnih, V., Kavukcuoglo, K.,

Silver, D., Rusu, A.

A., Veness, J., Bellemare,

M. G., Graves,

A.,

Riedmiller, M., Fidgeland, A.

K., Ostrovski, G., Petersen,

S., Beattie, C., Sadik,

A.,

Antonoglou, I., King,

H., Kumaran, D., Wierstra,

D., Legg, S., and

Hassabis, D. (2015).

Human-level

control through deep reinforcement

learning. Nature, 518, 529–533.

23

Mobahi, H. and

Fisher, III, J. W.

(2015). A theoretical analysis

of optimization by Gaussian

continuation. In AAAI’2015 .

279

Mobahi, H., Collobert,

R., and Weston, J.

(2009). Deep learning from

temporal coherence in

video.

In L. Bottou and

M. Littman, editors, Proceedings

of the 26th International

Conference

on Machine Learning,

pages 737–744, Montreal. Omnipress.

421

Mohamed, A., Dahl,

G., and Hinton, G.

(2009). Deep belief networks

for phone recognition.

391

参考文

献 657

Mohamed, A.,

Sainath, T. N., Dahl,

G., Ramabhadran, B., Hinton,

G. E., and Picheny,

M. A.

(2011). Deep

belief networks using discriminative

features for phone recognition.

In Acoustics,

Speech and

Signal Processing (ICASSP), 2011

IEEE International Conference on,

pages 5060–

5063. IEEE.

391

Mohamed, A., Dahl,

G., and Hinton, G.

(2012a). Acoustic modeling using

deep belief networks.

IEEE

Trans. on Audio, Speech

and Language Processing, 20(1),

14–22. 391

Mohamed, A.,

Hinton, G., and Penn,

G. (2012b). Understanding how

deep belief networks

perform

acoustic modelling. In Acoustics,

Speech and Signal Processing

(ICASSP), 2012

IEEE International

Conference on, pages 4273–4276.

IEEE. 391

Moller, M.

(1993). Efficient Training of

Feed-Forward Neural Networks. Ph.D.

thesis, Aarhus

University, Aarhus,

Denmark. 270

Montavon, G.

and Muller, K.-R. (2012).

Deep Boltzmann machines and

the centering

trick. In

G. Montavon, G. Orr,

and K.-R. Müller, editors,

Neural Networks: Tricks of

the Trade, volume 7700

of Lecture Notes in

Computer Science, pages 621–637.

Preprint:

http://arxiv.org/abs/1203.3783. 575

Montúfar,

G. (2014). Universal approximation

depth and errors of

narrow belief networks with

discrete units. Neural Computation,

26. 472

Montúfar, G.

and Ay, N. (2011).

Refinements of universal approximation

results for deep belief

networks and restricted Boltzmann

machines. Neural Computation, 23(5),

1306–1319. 472

Montufar, G.

F., Pascanu, R., Cho,

K., and Bengio, Y.

(2014). On the number

of linear regions

of

deep neural networks. In

NIPS’2014 . 17, 172,

173

Mor-Yosef, S., Samueloff,

A., Modan, B., Navot,

D., and Schenker, J.

G. (1990). Ranking the

risk factors for cesarean:

logistic regression analysis of

a nationwide study. Obstet

Gynecol,

75(6), 944–7. 2

Morin, F. and Bengio,

Y. (2005). Hierarchical probabilistic

neural network language model.

In

AISTATS’2005 . 397,

399

Mozer, M. C.

(1992). The induction of

multiscale temporal structure. In

J. M. S. Hanson

and R. Lippmann, editors,

Advances in Neural Information

Processing Systems 4 (NIPS’91),

pages 275–282, San Mateo,

CA. Morgan Kaufmann. 348

Murphy, K. P. (2012).

Machine Learning: a Probabilistic

Perspective. MIT Press, Cambridge,

MA, USA. 56, 87,

126

658 参考文献

Murray, B.

U. I. and Larochelle,

H. (2014). A deep

and tractable density estimator.

In

ICML’2014 . 164,

606

Nair, V. and

Hinton, G. (2010a). Rectified

linear units improve restricted

Boltzmann machines.

In ICML’2010

. 150, 170

Nair,

V. and Hinton, G.

E. (2009). 3d object

recognition with deep belief

nets. In Y. Bengio,

D. Schuurmans, J. D.

Lafferty, C. K. I.

Williams, and A. Culotta,

editors, Advances in Neural

Information Processing Systems 22

, pages 1339–1347. Curran

Associates, Inc. 586

Nair,

V. and Hinton, G.

E. (2010b). Rectified linear

units improve restricted Boltzmann

ma￾chines. In L. Bottou

and M. Littman, editors,

Proceedings of the Twenty-seventh

International

Conference on Machine

Learning (ICML-10), pages 807–814.

ACM. 14

Narayanan, H.

and Mitter, S. (2010).

Sample complexity of testing

the manifold hypothesis. In

J. Lafferty, C. K.

I. Williams, J. Shawe-Taylor,

R. Zemel, and A.

Culotta, editors, Advances

in

Neural Information Processing Systems

23 , pages 1786–1794.

141

Naumann, U. (2008).

Optimal Jacobian accumulation is

NP-complete. Mathematical Program￾ming, 112(2),

427–441. 191

Navigli, R.

and Velardi, P. (2005).

Structural semantic interconnections: a

knowledge-based

approach to word

sense disambiguation. IEEE Trans.

Pattern Analysis and Machine

Intelli￾gence, 27(7), 1075--–1086. 412

Neal, R. and Hinton,

G. (1999). A view

of the EM algorithm

that justifies incremental, sparse,

and other variants. In

M. I. Jordan, editor,

Learning in Graphical Models.

MIT Press, Cam￾bridge, MA.

541

Neal, R. M.

(1990). Learning stochastic feedforward

networks. Technical report. 591

Neal, R. M. (1993).

Probabilistic inference using Markov

chain Monte-Carlo methods. Technical

Report CRG-TR-93-1, Dept. of

Computer Science, University of

Toronto. 581

Neal, R.

M. (1994). Sampling from

multimodal distributions using tempered

transitions. Tech￾nical Report 9421,

Dept. of Statistics, University

of Toronto. 514

Neal,

R. M. (1996). Bayesian

Learning for Neural Networks.

Lecture Notes in Statistics.

Springer. 228

Neal, R.

M. (2001). Annealed importance

sampling. Statistics and Computing,

11(2), 125–139.

533, 535,

536

参考文献 659

Neal,

R. M. (2005). Estimating

ratios of normalizing constants

using linked importance sampling.

536, 537

Nesterov, Y.

(1983). A method of

solving a convex programming

problem with convergence rate

O(1/k

2

). Soviet

Mathematics Doklady, 27, 372–376.

256

Nesterov, Y. (2004).

Introductory lectures on convex

optimization : a basic

course. Applied

optimization. Kluwer

Academic Publ., Boston, Dordrecht,

London. 256

Netzer, Y.,

Wang, T., Coates, A.,

Bissacco, A., Wu, B.,

and Ng, A. Y.

(2011). Reading digits in

natural images with unsupervised

feature learning. Deep Learning

and Unsupervised Feature

Learning

Workshop, NIPS. 18

Ney,

H. and Kneser, R.

(1993). Improved clustering techniques

for class-based statistical lan￾guage

modelling. In European Conference

on Speech Communication and

Technology (Eu￾rospeech), pages 973–976,

Berlin. 394

Ng, A.

(2015). Advice for applying

machine learning.

https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf. 359

Niesler, T. R., Whittaker,

E. W. D., and

Woodland, P. C. (1998).

Comparison of part-of￾speech and

automatically derived category-based language

models for speech recognition.

In

International Conference on

Acoustics, Speech and Signal

Processing (ICASSP), pages 177–

180. 394

Ning, F.,

Delhomme, D., LeCun, Y.,

Piano, F., Bottou, L.,

and Barbano, P. E.

(2005). To￾ward automatic phenotyping

of developing embryos from

videos. Image Processing, IEEE

Transactions on, 14(9), 1360–1371.

306

Nocedal, J. and

Wright, S. (2006). Numerical

Optimization. Springer. 82, 85

Norouzi, M. and Fleet,

D. J. (2011). Minimal

loss hashing for compact

binary codes. In

ICML’2011

. 448

Nowlan, S.

J. (1990). Competing experts:

An experimental investigation of

associative mixture

models. Technical

Report CRG-TR-90-5, University of

Toronto. 383

Nowlan, S.

J. and Hinton, G.

E. (1992). Adaptive soft

weight tying using Gaussian

mixtures.

In J. M.

S. Hanson and R.

Lippmann, editors, Advances in

Neural Information Processing

Systems

4 (NIPS’91), pages 993–1000,

San Mateo, CA. Morgan

Kaufmann. 122

Olshausen, B.

and Field, D. J.

(2005). How close are

we to understanding V1?

Neural Compu￾tation, 17, 1665–1699.

14

660 参

考文献

Olshausen,

B. A. and Field,

D. J. (1996). Emergence

of simple-cell receptive field

properties by

learning a

sparse code for natural

images. Nature, 381, 607–609.

128, 219, 316, 423

Olshausen, B. A., Anderson,

C. H., and Van

Essen, D. C. (1993).

A neurobiological model of

visual attention and invariant

pattern recognition based on

dynamic routing of information.

J. Neurosci., 13(11), 4700–4719.

383

Opper, M. and

Archambeau, C. (2009). The

variational Gaussian approximation revisited.

Neural computation, 21(3), 786–792.

588

Oquab, M., Bottou,

L., Laptev, I., and

Sivic, J. (2014). Learning

and transferring mid-level

image

representations using convolutional neural

networks. In Computer Vision

and Pattern

Recognition (CVPR),

2014 IEEE Conference on,

pages 1717–1724. IEEE. 456

Osindero, S. and Hinton,

G. E. (2008). Modeling

image patches with a

directed hierarchy of

Markov

random fields. In J.

Platt, D. Koller, Y.

Singer, and S. Roweis,

editors, Advances

in Neural

Information Processing Systems 20

(NIPS’07), pages 1121–1128, Cambridge,

MA.

MIT Press. 539

Ovid and Martin, C.

(2004). Metamorphoses. W.W. Norton.

1

Paccanaro, A. and

Hinton, G. E. (2000).

Extracting distributed representations of

concepts

and relations from

positive and negative propositions.

In International Joint Conference

on

Neural Networks (IJCNN),

Como, Italy. IEEE, New

York. 411, 412

Paine,

T. L., Khorrami, P.,

Han, W., and Huang,

T. S. (2014). An

analysis of unsupervised

pre-training

in light of recent

advances. arXiv preprint arXiv:1412.6597

. 454

Palatucci, M.,

Pomerleau, D., Hinton, G.

E., and Mitchell, T.

M. (2009). Zero-shot learning

with

semantic output codes.

In Y. Bengio, D.

Schuurmans, J. D. Lafferty,

C. K. I. Williams,

and

A. Culotta, editors,

Advances in Neural Information

Processing Systems 22 ,

pages 1410–1418.

Curran Associates,

Inc. 459

Parker, D.

B. (1985). Learning-logic. Technical

Report TR-47, Center for

Comp. Research in

Economics

and Management Sci., MIT.

194

Pascanu, R., Mikolov,

T., and Bengio, Y.

(2013a). On the difficulty

of training recurrent neural

networks. In ICML’2013 .

247, 343, 348, 353,

354, 355

Pascanu, R.,

Mikolov, T., and Bengio,

Y. (2013b). On the

difficulty of training recurrent

neural

networks. In ICM

( 1c). 345

Pascanu,

R., Gulcehre, C., Cho,

K., and Bengio, Y.

(2014a). How to construct

deep recurrent

neural networks.

In ICLR. 17, 228,

340, 341, 349, 392

参考

文献 661

Pascanu, R.,

Montufar, G., and Bengio,

Y. (2014b). On the

number of inference regions

of deep

feed forward

networks with piece-wise linear

activations. In ICL (

1). 469

Pati, Y.,

Rezaiifar, R., and Krishnaprasad,

P. (1993). Orthogonal matching

pursuit: Recursive

function approximation

with applications to wavelet

decomposition. In Proceedings of

the 27

th Annual

Asilomar Conference on Signals,

Systems, and Computers, pages

40–44. 220

Pearl, J.

(1985). Bayesian networks: A

model of self-activated memory

for evidential reasoning.

In

Proceedings of the 7th

Conference of the Cognitive

Science Society, University of

California,

Irvine, pages 329–334.

480

Pearl, J. (1988).

Probabilistic Reasoning in Intelligent

Systems: Networks of Plausible

Inference.

Morgan Kaufmann. 48

Perron, O. (1907). Zur

theorie der matrices. Mathematische

Annalen, 64(2), 248–263. 508

Petersen, K. B. and

Pedersen, M. S. (2006).

The matrix cookbook. Version

20051003. 27

Peterson, G.

B. (2004). A day

of great illumination: B.

F. Skinner’s discovery of

shaping.

Journal of the

Experimental Analysis of Behavior

, 82(3), 317–328. 279

Pham, D.-T., Garat, P.,

and Jutten, C. (1992).

Separation of a mixture

of independent sources

through

a maximum likelihood approach.

In EUSIPCO, pages 771–774.

419

Pham, P.-H., Jelaca,

D., Farabet, C., Martini,

B., LeCun, Y., and

Culurciello, E. (2012). Neu￾Flow:

dataflow vision processing system-on-a-chip.

In Circuits and Systems

(MWSCAS),

2012 IEEE 55th

International Midwest Symposium on,

pages 1044–1047. IEEE. 384

Pinheiro, P. H. O.

and Collobert, R. (2014).

Recurrent convolutional neural networks

for scene

labeling. In

ICML’2014 . 306

Pinheiro,

P. H. O. and

Collobert, R. (2015). From

image-level to pixel-level labeling

with

convolutional networks. In

Conference on Computer Vision

and Pattern Recognition (CVPR).

306

Pinto, N., Cox,

D. D., and DiCarlo,

J. J. (2008). Why

is real-world visual object

recognition

hard? PLoS Comput

Biol, 4. 388

Pinto,

N., Stone, Z., Zickler,

T., and Cox, D.

(2011). Scaling up biologically-inspired

computer

vision: A case

study in unconstrained face

recognition on facebook. In

Computer Vision

and Pattern

Recognition Workshops (CVPRW), 2011

IEEE Computer Society Conference

on, pages 35–42. IEEE.

310

662 参考文

献

Pollack,

J. B. (1990). Recursive

distributed representations. Artificial Intelligence,

46(1), 77–

105. 341

Polyak, B. and Juditsky,

A. (1992). Acceleration of

stochastic approximation by averaging.

SIAM J. Control and

Optimization, 30(4), 838–855. 274

Polyak, B. T. (1964).

Some methods of speeding

up the convergence of

iteration methods. USSR

Computational

Mathematics and Mathematical Physics,

4(5), 1–17. 253

Poole,

B., Sohl-Dickstein, J., and

Ganguli, S. (2014). Analyzing

noise in autoencoders and

deep

networks. CoRR, abs/1406.1831.

207

Poon, H. and

Domingos, P. (2011). Sum-product

networks for deep learning.

In Learning

Workshop, Fort

Lauderdale, FL. 472

Presley,

R. K. and Haggard,

R. L. (1994). A

fixed point implementation of

the backpropaga￾tion learning algorithm.

In Southeastcon’94. Creative Technology

Transfer-A Global Affair.,

Proceedings

of the 1994 IEEE,

pages 136–138. IEEE. 384

Price, R. (1958). A

useful theorem for nonlinear

devices having Gaussian inputs.

IEEE Trans￾actions on Information

Theory, 4(2), 69–72. 588

Quiroga, R. Q., Reddy,

L., Kreiman, G., Koch,

C., and Fried, I.

(2005). Invariant visual

representation

by single neurons in

the human brain. Nature,

435(7045), 1102–1107. 312

Radford,

A., Metz, L., and

Chintala, S. (2015). Unsupervised

representation learning with deep

convolutional generative adversarial networks.

arXiv preprint arXiv:1511.06434 .

470, 471,

599

Raiko,

T., Yao, L., Cho,

K., and Bengio, Y.

(2014). Iterative neural autoregressive

distribution

estimator (NADE-k). Technical

report, arXiv:1406.1485. 576, 605

Raina, R., Madhavan, A.,

and Ng, A. Y.

(2009a). Large-scale deep unsupervised

learning using

graphics processors.

In L. Bottou and

M. Littman, editors, Proceedings

of the Twenty-sixth

International

Conference on Machine Learning

(ICML’09), pages 873–880, New

York, NY,

USA. ACM.

21

Raina, R., Madhavan,

A., and Ng, A.

Y. (2009b). Large-scale deep

unsupervised learning using

graphics

processors. In ICML’2009 .

379

Ramsey, F. P.

(1926). Truth and probability.

In R. B. Braithwaite,

editor, The Foundations

of

Mathematics and other Logical

Essays, chapter 7, pages

156–198. McMaster University

Archive

for the History of

Economic Thought. 49

参考文献

663

Ranzato, M. and Hinton,

G. H. (2010). Modeling

pixel means and covariances

using factorized

third-order Boltzmann

machines. In CVPR’2010 ,

pages 2551–2558. 581

Ranzato,

M., Poultney, C., Chopra,

S., and LeCun, Y.

(2007a). Efficient learning of

sparse

representations with an

energy-based model. In NIPS’2006

. 13, 433, 451,

452

Ranzato, M., Poultney,

C., Chopra, S., and

LeCun, Y. (2007b). Efficient

learning of sparse

representations

with an energy-based model.

In B. Schölkopf, J.

Platt, and T. Hoffman,

editors, Advances in Neural

Information Processing Systems 19

(NIPS’06), pages 1137–1144.

MIT

Press. 17

Ranzato, M.,

Huang, F., Boureau, Y.,

and LeCun, Y. (2007c).

Unsupervised learning of invariant

feature hierarchies with applications

to object recognition. In

CVPR’07 . 310

Ranzato,

M., Boureau, Y., and

LeCun, Y. (2008). Sparse

feature learning for deep

belief net￾works. In NIPS’2007

. 433

Ranzato, M.,

Krizhevsky, A., and Hinton,

G. E. (2010a). Factored

3-way restricted Boltzmann

machines

for modeling natural images.

In Proceedings of AISTATS

2010 . 579, 580

Ranzato, M., Mnih, V.,

and Hinton, G. (2010b).

Generating more realistic images

using gated

MRFs. In

NIPS’2010 . 581

Rao,

C. (1945). Information and

the accuracy attainable in

the estimation of statistical

param￾eters. Bulletin of the

Calcutta Mathematical Society, 37,

81–89. 118, 252

Rasmus,

A., Valpola, H., Honkala,

M., Berglund, M., and

Raiko, T. (2015). Semi-supervised

learning with ladder network.

arXiv preprint arXiv:1507.02672 .

363, 453

Recht, B.,

Re, C., Wright, S.,

and Niu, F. (2011).

Hogwild: A lock-free approach

to parallelizing

stochastic gradient

descent. In NIPS’2011 .

380

Reichert, D. P.,

Seriès, P., and Storkey,

A. J. (2011). Neuronal

adaptation for sampling-based

probabilistic

inference in perceptual bistability.

In Advances in Neural

Information Processing

Systems, pages

2357–2365. 569

Rezende, D.

J., Mohamed, S., and

Wierstra, D. (2014). Stochastic

backpropagation and approx￾imate inference

in deep generative models.

In ICML’2014 . Preprint:

arXiv:1401.4082. 558,

588, 594

Rifai, S., Vincent, P.,

Muller, X., Glorot, X.,

and Bengio, Y. (2011a).

Contractive auto-encoders:

Explicit invariance

during feature extraction. In

ICML’2011 . 445, 446,

447

664 参考文献

Rifai,

S., Mesnil, G., Vincent,

P., Muller, X., Bengio,

Y., Dauphin, Y., and

Glorot, X. (2011b).

Higher

order contractive auto-encoder. In

ECML PKDD. 445, 446

Rifai, S., Dauphin, Y.,

Vincent, P., Bengio, Y.,

and Muller, X. (2011c).

The manifold tangent

classifier.

In NIPS’2011 . 233,

446

Rifai, S., Dauphin,

Y., Vincent, P., Bengio,

Y., and Muller, X.

(2011d). The manifold tangent

classifier. In NIPS’2011 .

Student paper award. 233

Rifai, S., Bengio, Y.,

Dauphin, Y., and Vincent,

P. (2012). A generative

process for sampling

contractive

auto-encoders. In ICML’2012 .

607

Ringach, D. and

Shapley, R. (2004). Reverse

correlation in neurophysiology. Cognitive

Science,

28(2), 147–166. 314

Roberts, S. and Everson,

R. (2001). Independent component

analysis: principles and practice.

Cambridge University Press. 420

Robinson, A. J. and

Fallside, F. (1991). A

recurrent error propagation network

speech recognition

system. Computer

Speech and Language, 5(3),

259–274. 21, 390

Rockafellar,

R. T. (1997). Convex

analysis. princeton landmarks in

mathematics. 82

Romero, A.,

Ballas, N., Ebrahimi Kahou,

S., Chassang, A., Gatta,

C., and Bengio, Y.

(2015).

Fitnets: Hints for

thin deep nets. In

ICLR’2015, arXiv:1412.6550 . 277

Rosen, J. B. (1960).

The gradient projection method

for nonlinear programming. part

i. linear

constraints. Journal

of the Society for

Industrial and Applied Mathematics,

8(1), pp. 181–217.

83

Rosenblatt, F. (1958). The

perceptron: A probabilistic model

for information storage and

organization in the brain.

Psychological Review, 65, 386–408.

13, 21

Rosenblatt, F.

(1962). Principles of Neurodynamics.

Spartan, New York. 21

Rosenblatt, M. (1956). Remarks

on some nonparametric estimates

of a density function.

The

Annals of Mathematical

Statistics, 27(3), 832–837. 13

Roweis, S. and Saul,

L. K. (2000). Nonlinear

dimensionality reduction by locally

linear embed￾ding. Science, 290(5500).

141, 443

Roweis, S.,

Saul, L., and Hinton,

G. (2002). Global coordination

of local linear models.

In T. Di￾etterich, S.

Becker, and Z. Ghahramani,

editors, Advances in Neural

Information Processing

Systems 14

(NIPS’01), Cambridge, MA. MIT

Press. 417

参

考文献 665

Rubin, D. B. et

al. (1984). Bayesianly justifiable

and relevant frequency calculations

for the

applied statistician.

The Annals of Statistics,

12(4), 1151–1172. 611

Rumelhart,

D., Hinton, G., and

Williams, R. (1986a). Learning

representations by back￾propagating errors.

Nature, 323, 533–536. 13,

194, 406, 410

Rumelhart,

D. E., Hinton, G.

E., and Williams, R.

J. (1986b). Learning internal

representations

by error propagation.

In D. E. Rumelhart

and J. L. McClelland,

editors, Parallel Distributed

Processing,

volume 1, chapter 8,

pages 318–362. MIT Press,

Cambridge. 18, 21, 194

Rumelhart, D. E., Hinton,

G. E., and Williams,

R. J. (1986c). Learning

representations by

back-propagating errors.

Nature, 323, 533–536. 16,

175, 319

Rumelhart, D.

E., McClelland, J. L.,

and the PDP Research

Group (1986d). Parallel Distributed

Processing: Explorations in the

Microstructure of Cognition. MIT

Press, Cambridge. 15, 22

Russakovsky, O., Deng, J.,

Su, H., Krause, J.,

Satheesh, S., Ma, S.,

Huang, Z., Karpathy, A.,

Khosla, A., Bernstein, M.,

Berg, A. C., and

Fei-Fei, L. (2014a). ImageNet

Large Scale Visual

Recognition

Challenge. 18

Russakovsky, O.,

Deng, J., Su, H.,

Krause, J., Satheesh, S.,

Ma, S., Huang, Z.,

Karpathy, A.,

Khosla, A.,

Bernstein, M., et al.

(2014b). Imagenet large scale

visual recognition challenge.

arXiv

preprint arXiv:1409.0575 . 23

Russel, S. J. and

Norvig, P. (2003). Artificial

Intelligence: a Modern Approach.

Prentice Hall.

77

Rust,

N., Schwartz, O., Movshon,

J. A., and Simoncelli,

E. (2005). Spatiotemporal elements

of

macaque V1 receptive

fields. Neuron, 46(6), 945–956.

313

Sainath, T., Mohamed,

A., Kingsbury, B., and

Ramabhadran, B. (2013). Deep

convolutional

neural networks for

LVCSR. In ICASSP 2013

. 391

Salakhutdinov, R.

(2010). Learning in Markov

random fields using tempered

transitions. In

Y. Bengio,

D. Schuurmans, C. Williams,

J. Lafferty, and A.

Culotta, editors, Advances in

Neural Information Processing Systems

22 (NIPS’09). 514

Salakhutdinov,

R. and Hinton, G.

(2009a). Deep Boltzmann machines.

In Proceedings of the

International Conference on Artificial

Intelligence and Statistics, volume

5, pages 448–455.

20,

21, 452, 566, 569,

572, 574

Salakhutdinov, R.

and Hinton, G. (2009b).

Semantic hashing. In International

Journal of

Approximate Reasoning.

448

666 参考

文献

Salakhutdinov,

R. and Hinton, G.

E. (2007a). Learning a

nonlinear embedding by preserving

class neighbourhood structure. In

Proceedings of AISTATS-2007 .

450

Salakhutdinov, R. and

Hinton, G. E. (2007b).

Semantic hashing. In SIGIR’2007

. 448

Salakhutdinov, R.

and Hinton, G. E.

(2008). Using deep belief

nets to learn covariance

kernels

for Gaussian processes.

In J. Platt, D.

Koller, Y. Singer, and

S. Roweis, editors, Advances

in Neural Information Processing

Systems 20 (NIPS’07), pages

1249–1256, Cambridge, MA.

MIT

Press. 210

Salakhutdinov, R.

and Larochelle, H. (2010).

Efficient learning of deep

Boltzmann machines. In

Proceedings

of the Thirteenth International

Conference on Artificial Intelligence

and Statistics

(AISTATS 2010),

JMLR W&CP, volume 9,

pages 693–700. 557

Salakhutdinov,

R. and Mnih, A.

(2008). Probabilistic matrix factorization.

In NIPS’2008 . 408

Salakhutdinov, R. and Murray,

I. (2008). On the

quantitative analysis of deep

belief networks.

In W.

W. Cohen, A. McCallum,

and S. T. Roweis,

editors, Proceedings of the

Twenty-fifth

International Conference on

Machine Learning (ICML’08), volume

25, pages 872–879. ACM.

536, 566

Salakhutdinov, R.,

Mnih, A., and Hinton,

G. (2007). Restricted Boltzmann

machines for col￾laborative filtering.

In ICML. 408

Sanger,

T. D. (1994). Neural

network learning control of

robot manipulators using gradually

increasing task difficulty. IEEE

Transactions on Robotics and

Automation, 10(3). 279

Saul,

L. K. and Jordan,

M. I. (1996). Exploiting

tractable substructures in intractable

networks.

In D. Touretzky,

M. Mozer, and M.

Hasselmo, editors, Advances in

Neural Information Pro￾cessing Systems

8 (NIPS’95). MIT Press,

Cambridge, MA. 544

Saul,

L. K., Jaakkola, T.,

and Jordan, M. I.

(1996). Mean field theory

for sigmoid belief networks.

Journal of Artificial Intelligence

Research, 4, 61–76. 21,

592

Savich, A. W.,

Moussa, M., and Areibi,

S. (2007). The impact

of arithmetic representation on

implementing mlp-bp on fpgas:

A study. Neural Networks,

IEEE Transactions on, 18(1),

240–252. 384

Saxe, A.

M., Koh, P. W.,

Chen, Z., Bhand, M.,

Suresh, B., and Ng,

A. (2011). On random

weights and unsupervised feature

learning. In Proc. ICML’2011

. ACM. 310

Saxe,

A. M., McClelland, J.

L., and Ganguli, S.

(2013). Exact solutions to

the nonlinear

dynamics of

learning in deep linear

neural networks. In ICLR.

244, 245, 258

参考文

献

667

Schaul, T., Antonoglou,

I., and Silver, D.

(2014). Unit tests for

stochastic optimization. In

International

Conference on Learning Representations.

263

Schmidhuber, J. (1992).

Learning complex, extended sequences

using the principle of

history

compression. Neural Computation,

4(2), 234–242. 340

Schmidhuber,

J. (1996). Sequential neural

text compression. IEEE Transactions

on Neural

Networks, 7(1),

142–146. 406

Schmidhuber, J.

(2012). Self-delimiting neural networks.

arXiv preprint arXiv:1210.0118 .

333

Schölkopf, B. and

Smola, A. J. (2002).

Learning with kernels: Support

vector machines, regu￾larization, optimization,

and beyond. MIT press.

601

Schölkopf, B., Burges,

C. J. C., and

Smola, A. J. (1998a).

Advances in kernel methods:

support

vector learning. MIT

Press, Cambridge, MA. 141

Schölkopf, B., Smola, A.,

and Müller, K.-R. (1998b).

Nonlinear component analysis as

a kernel

eigenvalue problem.

Neural Computation, 10, 1299–1319.

443

Schölkopf, B., Burges,

C. J. C., and

Smola, A. J. (1999).

Advances in Kernel Methods

— Support

Vector Learning.

MIT Press, Cambridge, MA.

16, 124

Schölkopf, B.,

Janzing, D., Peters, J.,

Sgouritsa, E., Zhang, K.,

and Mooij, J. (2012).

On causal

and anticausal

learning. In ICML’2012 ,

pages 1255–1262. 465

Schuster,

M. (1999). On supervised

learning from sequential data

with applications for speech

recognition. 164

Schuster, M.

and Paliwal, K. (1997).

Bidirectional recurrent neural networks.

IEEE Transactions

on Signal

Processing, 45(11), 2673–2681. 336

Schwenk, H. (2007). Continuous

space language models. Computer

speech and language, 21,

492–518. 396

Schwenk, H.

(2010). Continuous space language

models for statistical machine

translation. The

Prague Bulletin

of Mathematical Linguistics, 93,

137–146. 402

Schwenk, H.

(2014). Cleaned subset of

WMT ’14 dataset. 18

Schwenk, H. and Bengio,

Y. (1998). Training methods

for adaptive boosting of

neural networks.

In M.

Jordan, M. Kearns, and

S. Solla, editors, Advances

in Neural Information Processing

Systems 10 (NIPS’97), pages

647–653. MIT Press. 222

668 参考文献

Schwenk, H. and

Gauvain, J.-L. (2002). Connectionist

language modeling for large

vocabulary

continuous speech recognition.

In International Conference on

Acoustics, Speech and Signal

Processing (ICASSP), pages 765–768,

Orlando, Florida. 396

Schwenk,

H., Costa-jussà, M. R.,

and Fonollosa, J. A.

R. (2006). Continuous space

language

models for the

IWSLT 2006 task. In

International Workshop on Spoken

Language Translation,

pages 166–173.

402

Seide, F., Li,

G., and Yu, D.

(2011). Conversational speech transcription

using context￾dependent deep neural

networks. In Interspeech 2011

, pages 437–440. 22

Sejnowski, T. (1987). Higher-order

Boltzmann machines. In AIP

Conference Proceedings 151

on

Neural Networks for Computing,

pages 398–403. American Institute

of Physics Inc. 586

Series, P., Reichert, D.

P., and Storkey, A.

J. (2010). Hallucinations in

Charles Bonnet syn￾drome induced

by homeostasis: a deep

Boltzmann machine model. In

Advances in Neural

Information

Processing Systems, pages 2020–2028.

569

Sermanet, P., Chintala,

S., and LeCun, Y.

(2012). Convolutional neural networks

applied to

house numbers

digit classification. In International

Conference on Pattern Recognition

(ICPR

2012). 388

Sermanet,

P., Kavukcuoglu, K., Chintala,

S., and LeCun, Y.

(2013). Pedestrian detection with

unsupervised multi-stage feature learning.

In Proc. International Conference

on Computer

Vision and

Pattern Recognition (CVPR’13). IEEE.

22, 174

Shilov, G.

(1977). Linear Algebra. Dover

Books on Mathematics Series.

Dover Publications. 27

Siegelmann,

H. (1995). Computation beyond

the Turing limit. Science,

268(5210), 545–548.

324

Siegelmann,

H. and Sontag, E.

(1991). Turing computability with

neural nets. Applied Mathe￾matics

Letters, 4(6), 77–80. 324

Siegelmann, H. T. and

Sontag, E. D. (1995).

On the computational power

of neural nets. Journal

of Computer and Systems

Sciences, 50(1), 132–150. 324,

325, 345

Sietsma, J.

and Dow, R. (1991).

Creating artificial neural networks

that generalize. Neural

Networks,

4(1), 67–79. 207

Simard,

D., Steinkraus, P. Y.,

and Platt, J. C.

(2003). Best practices for

convolutional neural

networks. In

ICDAR’2003 . 317

参考文献

669

Simard, P. and

Graf, H. P. (1994).

Backpropagation without multiplication. In

Advances in

Neural Information

Processing Systems, pages 232–239.

384

Simard, P., Victorri,

B., LeCun, Y., and

Denker, J. (1992). Tangent

prop - A formalism

for

specifying selected invariances

in an adaptive network.

In NIPS’1991 . 232,

233, 301

Simard, P.

Y., LeCun, Y., and

Denker, J. (1993). Efficient

pattern recognition using a

new

transformation distance. In

NIPS’92 . 232

Simard,

P. Y., LeCun, Y.

A., Denker, J. S.,

and Victorri, B. (1998).

Transformation invariance in

pattern

recognition — tangent distance

and tangent propagation. Lecture

Notes in Computer

Science,

1524. 232

Simons, D.

J. and Levin, D.

T. (1998). Failure to

detect changes to people

during a real-world

interaction.

Psychonomic Bulletin & Review,

5(4), 644–649. 463

Simonyan,

K. and Zisserman, A.

(2015). Very deep convolutional

networks for large-scale image

recognition. In ICLR. 275

Sjöberg, J. and Ljung,

L. (1995). Overtraining, regularization

and searching for a

minimum,

with application to

neural networks. International Journal

of Control, 62(6), 1391–1407.

215

Skinner, B. F.

(1958). Reinforcement today. American

Psychologist, 13, 94–99. 279

Smolensky, P. (1986). Information

processing in dynamical systems:

Foundations of harmony

theory.

In D. E. Rumelhart

and J. L. McClelland,

editors, Parallel Distributed Processing,

volume 1, chapter 6,

pages 194–281. MIT Press,

Cambridge. 486, 499, 561

Snoek, J., Larochelle, H.,

and Adams, R. P.

(2012). Practical Bayesian optimization

of machine

learning algorithms.

In NIPS’2012 . 371

Socher, R., Huang, E.

H., Pennington, J., Ng,

A. Y., and Manning,

C. D. (2011a). Dynamic

pooling and unfolding recursive

autoencoders for paraphrase detection.

In NIPS’2011 . 341,

342

Socher, R., Manning,

C., and Ng, A.

Y. (2011b). Parsing natural

scenes and natural language

with recursive neural networks.

In Proceedings of the

Twenty-Eighth International Conference

on

Machine Learning (ICML’2011). 341

Socher, R., Pennington, J.,

Huang, E. H., Ng,

A. Y., and Manning,

C. D. (2011c). Semi￾supervised

recursive autoencoders for predicting

sentiment distributions. In EMNLP’2011

.

341, 342

670

参

考文献

Socher, R., Perelygin,

A., Wu, J. Y.,

Chuang, J., Manning, C.

D., Ng, A. Y.,

and Potts, C.

(2013a).

Recursive deep models for

semantic compositionality over a

sentiment treebank. In

EMNLP’2013

. 341, 342

Socher,

R., Ganjoo, M., Manning,

C. D., and Ng,

A. Y. (2013b). Zero-shot

learning through

cross-modal transfer.

In 27th Annual Conference

on Neural Information Processing

Systems

(NIPS 2013). 459

Sohl-Dickstein, J., Weiss, E.

A., Maheswaranathan, N., and

Ganguli, S. (2015). Deep

unsuper￾vised learning using nonequilibrium

thermodynamics. 610, 611

Sohn,

K., Zhou, G., and

Lee, H. (2013). Learning

and selecting features jointly

with point-wise

gated Boltzmann

machines. In ICML’2013 .

586

Solomonoff, R. J.

(1989). A system for

incremental learning based on

algorithmic probability.

279

Sontag,

E. D. (1998). VC

dimension of neural networks.

NATO ASI Series F

Computer and

Systems Sciences,

168, 69–96. 467, 470

Sontag, E. D. and

Sussman, H. J. (1989).

Backpropagation can give rise

to spurious local minima

even for networks without

hidden layers. Complex Systems,

3, 91–106. 243

Sparkes,

B. (1996). The Red

and the Black: Studies

in Greek Pottery. Routledge.

1

Spitkovsky, V. I.,

Alshawi, H., and Jurafsky,

D. (2010). From baby

steps to leapfrog: how

“less

is more” in

unsupervised dependency parsing. In

HLT’10 . 279

Squire,

W. and Trapp, G.

(1998). Using complex variables

to estimate derivatives of

real func￾tions. SIAM Rev.,

40(1), 110--–112. 373

Srebro,

N. and Shraibman, A.

(2005). Rank, trace-norm and

max-norm. In Proceedings of

the

18th Annual Conference

on Learning Theory, pages

545–560. Springer-Verlag. 206

Srivastava,

N. (2013). Improving Neural

Networks With Dropout. Master’s

thesis, U. Toronto.

456

Srivastava, N. and Salakhutdinov,

R. (2012). Multimodal learning

with deep Boltzmann ma￾chines.

In NIPS’2012 . 460

Srivastava, N., Salakhutdinov, R.

R., and Hinton, G.

E. (2013). Modeling documents

with deep

Boltzmann machines.

arXiv preprint arXiv:1309.6865 .

566

参考

文献 671

Srivastava,

N., Hinton, G., Krizhevsky,

A., Sutskever, I., and

Salakhutdinov, R. (2014). Dropout:

A simple way to

prevent neural networks from

overfitting. Journal of Machine

Learning

Research, 15, 1929–1958.

222, 227, 228, 229,

574

Srivastava, R. K.,

Greff, K., and Schmidhuber,

J. (2015). Highway networks.

arXiv:1505.00387 .

278

Steinkrau,

D., Simard, P. Y.,

and Buck, I. (2005).

Using GPUs for machine

learning algorithms.

2013 12th

International Conference on Document

Analysis and Recognition, 0,

1115–1119.

379

Stoyanov, V.,

Ropson, A., and Eisner,

J. (2011). Empirical risk

minimization of graphical model

parameters given approximate inference,

decoding, and model structure.

In Proceedings of

the

14th International Conference on

Artificial Intelligence and Statistics

(AISTATS), vol￾ume 15 of

JMLR Workshop and Conference

Proceedings, pages 725–733, Fort

Lauderdale.

Supplementary material (4

pages) also available. 576,

596

Sukhbaatar, S., Szlam,

A., Weston, J., and

Fergus, R. (2015). Weakly

supervised memory

networks. arXiv

preprint arXiv:1503.08895 . 356

Supancic, J. and Ramanan,

D. (2013). Self-paced learning

for long-term tracking. In

CVPR’2013 . 280

Sussillo,

D. (2014). Random walks:

Training very deep nonlinear

feed-forward networks with

smart

initialization. CoRR, abs/1412.6558. 248,

259, 260, 344

Sutskever,

I. (2012). Training Recurrent

Neural Networks. Ph.D. thesis,

Department of computer

science,

University of Toronto. 347,

353

Sutskever, I. and

Hinton, G. E. (2008).

Deep narrow sigmoid belief

networks are universal

approximators.

Neural Computation, 20(11), 2629–2636.

592

Sutskever, I. and

Tieleman, T. (2010). On

the Convergence Properties of

Contrastive Divergence.

In AISTATS’2010

. 521

Sutskever, I.,

Hinton, G., and Taylor,

G. (2009). The recurrent

temporal restricted Boltzmann

machine.

In NIPS’2008 . 585

Sutskever, I., Martens, J.,

and Hinton, G. E.

(2011). Generating text with

recurrent neural

networks. In

ICML’2011 , pages 1017–1024.

406

Sutskever, I., Martens,

J., Dahl, G., and

Hinton, G. (2013). On

the importance of initialization

and momentum in deep

learning. In ICML. 256,

347, 353

672 参考文

献

Sutskever, I., Vinyals, O.,

and Le, Q. V.

(2014). Sequence to sequence

learning with neural

networks.

In NIPS’2014, arXiv:1409.3215 .

23, 89, 338, 349,

351, 403

Sutton, R.

and Barto, A. (1998).

Reinforcement Learning: An Introduction.

MIT Press. 93

Sutton,

R. S., Mcallester, D.,

Singh, S., and Mansour,

Y. (2000). Policy gradient

methods for

reinforcement learning

with function approximation. In

NIPS’1999 , pages 1057--–1063.

MIT

Press. 590

Swersky,

K., Ranzato, M., Buchman,

D., Marlin, B., and

de Freitas, N. (2011).

On autoencoders

and score

matching for energy based

models. In ICML’2011 .

ACM. 438

Swersky, K.,

Snoek, J., and Adams,

R. P. (2014). Freeze-thaw

Bayesian optimization. arXiv

preprint

arXiv:1406.3896 . 371

Szegedy,

C., Liu, W., Jia,

Y., Sermanet, P., Reed,

S., Anguelov, D., Erhan,

D., Van￾houcke, V., and

Rabinovich, A. (2014a). Going

deeper with convolutions. Technical

report,

arXiv:1409.4842. 20, 21,

174, 222, 231, 278,

295

Szegedy, C., Zaremba,

W., Sutskever, I., Bruna,

J., Erhan, D., Goodfellow,

I. J., and Fergus,

R.

(2014b). Intriguing properties

of neural networks. ICLR,

abs/1312.6199. 230, 233

Szegedy,

C., Vanhoucke, V., Ioffe,

S., Shlens, J., and

Wojna, Z. (2015). Rethinking

the Inception

Architecture for

Computer Vision. ArXiv e-prints.

209, 275

Taigman, Y.,

Yang, M., Ranzato, M.,

and Wolf, L. (2014).

DeepFace: Closing the gap

to

human-level performance in

face verification. In CVPR’2014

. 88

Tandy, D.

W. (1997). Works and

Days: A Translation and

Commentary for the Social

Sciences.

University of California

Press. 1

Tang, Y.

and Eliasmith, C. (2010).

Deep networks for robust

visual recognition. In Proceedings

of the 27th International

Conference on Machine Learning,

June 21-24, 2010, Haifa,

Israel.

207

Tang, Y.,

Salakhutdinov, R., and Hinton,

G. (2012). Deep mixtures

of factor analysers. arXiv

preprint arXiv:1206.4635 . 417

Taylor, G. and Hinton,

G. (2009). Factored conditional

restricted Boltzmann machines for

modeling motion style. In

L. Bottou and M.

Littman, editors, Proceedings of

the Twenty￾sixth International Conference

on Machine Learning (ICML’09),

pages 1025–1032, Montreal,

Quebec,

Canada. ACM. 585

参考文献

673

Taylor, G., Hinton, G.

E., and Roweis, S.

(2007). Modeling human motion

using binary latent

variables.

In B. Schölkopf, J.

Platt, and T. Hoffman,

editors, Advances in Neural

Information

Processing Systems 19

(NIPS’06), pages 1345–1352. MIT

Press, Cambridge, MA. 585

Teh, Y., Welling, M.,

Osindero, S., and Hinton,

G. E. (2003). Energy-based

models for sparse

overcomplete

representations. Journal of Machine

Learning Research, 4, 1235–1260.

419

Tenenbaum, J., de

Silva, V., and Langford,

J. C. (2000). A

global geometric framework for

nonlinear dimensionality reduction. Science,

290(5500), 2319–2323. 141, 443,

456

Theis, L., van

den Oord, A., and

Bethge, M. (2015). A

note on the evaluation

of generative

models. arXiv:1511.01844.

596, 613

Thompson, J.,

Jain, A., LeCun, Y.,

and Bregler, C. (2014).

Joint training of a

convolutional

network and a

graphical model for human

pose estimation. In NIPS’2014

. 306

Thrun, S.

(1995). Learning to play

the game of chess.

In NIPS’1994 . 232

Tibshirani, R. J. (1995).

Regression shrinkage and selection

via the lasso. Journal

of the Royal

Statistical

Society B, 58, 267–288.

204

Tieleman, T. (2008).

Training restricted Boltzmann machines

using approximations to the

likelihood gradient. In ICML’2008

, pages 1064–1071. 521

Tieleman, T. and Hinton,

G. (2009). Using fast

weights to improve persistent

contrastive diver￾gence. In ICML’2009

. 524

Tipping, M.

E. and Bishop, C.

M. (1999). Probabilistic principal

components analysis. Journal

of

the Royal Statistical Society

B, 61(3), 611–622. 419

Torralba, A., Fergus, R.,

and Weiss, Y. (2008).

Small codes and large

databases for recognition.

In

Proceedings of the Computer

Vision and Pattern Recognition

Conference (CVPR’08), pages

1–8.

448

Touretzky, D. S.

and Minton, G. E.

(1985). Symbols among the

neurons: Details of a

con￾nectionist inference architecture. In

Proceedings of the 9th

International Joint Conference on

Artificial Intelligence - Volume

1 , IJCAI’85, pages

238–243, San Francisco, CA,

USA. Morgan

Kaufmann Publishers

Inc. 15

Tu, K.

and Honavar, V. (2011).

On the utility of

curricula in unsupervised learning

of proba￾bilistic grammars. In

IJCAI’2011 . 279

Turaga,

S. C., Murray, J.

F., Jain, V., Roth,

F., Helmstaedter, M., Briggman,

K., Denk, W.,

and

Seung, H. S. (2010).

Convolutional networks can learn

to generate affinity graphs

for

image segmentation. Neural

Computation, 22, 511–538. 306

674 参考文献

Turian, J.,

Ratinov, L., and Bengio,

Y. (2010). Word representations:

A simple and general

method for semi-supervised learning.

In Proc. ACL’2010 ,

pages 384–394. 455

Töscher,

A., Jahrer, M., and

Bell, R. M. (2009).

The BigChaos solution to

the Netflix grand

prize.

408

Uria, B., Murray,

I., and Larochelle, H.

(2013). Rnade: The real-valued

neural autoregressive

density-estimator. In

NIPS’2013 . 605, 606

van den Oörd, A.,

Dieleman, S., and Schrauwen,

B. (2013). Deep content-based

music recom￾mendation. In NIPS’2013

. 408

van der

Maaten, L. and Hinton,

G. E. (2008). Visualizing

data using t-SNE. J.

Machine Learning

Res., 9.

406, 443

Vanhoucke, V.,

Senior, A., and Mao,

M. Z. (2011). Improving

the speed of neural

networks on

CPUs. In

Proc. Deep Learning and

Unsupervised Feature Learning NIPS

Workshop. 378, 384

Vapnik,

V. N. (1982). Estimation

of Dependences Based on

Empirical Data. Springer-Verlag,

Berlin.

100

Vapnik, V. N.

(1995). The Nature of

Statistical Learning Theory. Springer,

New York. 100

Vapnik,

V. N. and Chervonenkis,

A. Y. (1971). On

the uniform convergence of

relative frequen￾cies of events

to their probabilities. Theory

of Probability and Its

Applications, 16, 264–280.

100

Vincent, P. (2011). A

connection between score matching

and denoising autoencoders. Neural

Computation, 23(7). 438, 439,

440, 608

Vincent, P.

and Bengio, Y. (2003).

Manifold Parzen windows. In

NIPS’2002 . MIT Press.

444

Vincent, P., Larochelle,

H., Bengio, Y., and

Manzagol, P.-A. (2008a). Extracting

and composing

robust features

with denoising autoencoders. In

ICM ( 1a), pages

1096–1103. 207

Vincent, P.,

Larochelle, H., Bengio, Y.,

and Manzagol, P.-A. (2008b).

Extracting and composing

robust

features with denoising autoencoders.

In ICML 2008 .

440

Vincent, P., Larochelle,

H., Lajoie, I., Bengio,

Y., and Manzagol, P.-A.

(2010). Stacked denois￾ing autoencoders:

Learning useful representations in

a deep network with

a local denoising

criterion.

J. Machine Learning Res.,

11. 440

Vincent, P.,

de Brébisson, A., and

Bouthillier, X. (2015). Efficient

exact gradient update for

training deep networks with

very large sparse targets.

In C. Cortes, N.

D. Lawrence, D. D.

Lee,

M. Sugiyama, and

R. Garnett, editors, Advances

in Neural Information Processing

Systems

28 , pages

1108–1116. Curran Associates, Inc.

396

参

考文献 675

Vinyals,

O., Kaiser, L., Koo,

T., Petrov, S., Sutskever,

I., and Hinton, G.

(2014a). Grammar as

a

foreign language. arXiv preprint

arXiv:1412.7449 . 349

Vinyals,

O., Toshev, A., Bengio,

S., and Erhan, D.

(2014b). Show and tell:

a neural image

caption

generator. arXiv 1411.4555. 349

Vinyals, O., Fortunato, M.,

and Jaitly, N. (2015a).

Pointer networks. arXiv preprint

arXiv:1506.03134 . 356

Vinyals,

O., Toshev, A., Bengio,

S., and Erhan, D.

(2015b). Show and tell:

a neural image

caption

generator. In CVPR’2015 .

arXiv:1411.4555. 90

Viola, P.

and Jones, M. (2001).

Robust real-time object detection.

In International Journal of

Computer Vision. 382

Visin,

F., Kastner, K., Cho,

K., Matteucci, M., Courville,

A., and Bengio, Y.

(2015). ReNet:

A recurrent

neural network based alternative

to convolutional networks. arXiv

preprint

arXiv:1505.00393 . 338

Von Melchner, L., Pallas,

S. L., and Sur,

M. (2000). Visual behaviour

mediated by retinal

projections

directed to the auditory

pathway. Nature, 404(6780), 871–876.

14

Wager, S., Wang,

S., and Liang, P.

(2013). Dropout training as

adaptive regularization. In

Advances

in Neural Information Processing

Systems 26 , pages

351–359. 228

Waibel, A.,

Hanazawa, T., Hinton, G.

E., Shikano, K., and

Lang, K. (1989). Phoneme

recogni￾tion using time-delay neural

networks. IEEE Transactions on

Acoustics, Speech, and Signal

Processing, 37, 328–339. 319,

386, 390

Wan, L.,

Zeiler, M., Zhang, S.,

LeCun, Y., and Fergus,

R. (2013). Regularization of

neural

networks using dropconnect.

In ICML’2013 . 229

Wang, S. and Manning,

C. (2013). Fast dropout

training. In ICML’2013 .

228

Wang, Z., Zhang,

J., Feng, J., and

Chen, Z. (2014a). Knowledge

graph and text jointly

embed￾ding. In Proc. EMNLP’2014

. 411

Wang, Z.,

Zhang, J., Feng, J.,

and Chen, Z. (2014b).

Knowledge graph embedding by

translating

on hyperplanes. In

Proc. AAAI’2014 . 412

Warde-Farley, D., Goodfellow, I.

J., Courville, A., and

Bengio, Y. (2014). An

empirical analysis

of dropout

in piecewise linear networks.

In ICL ( 1).

225, 228, 229

Wawrzynek,

J., Asanovic, K., Kingsbury,

B., Johnson, D., Beck,

J., and Morgan, N.

(1996).

Spert-II: A vector

microprocessor system. Computer, 29(3),

79–86. 384

676 参考

文献

Weaver, L. and Tao,

N. (2001). The optimal

reward baseline for gradient-based

reinforcement

learning. In Proc.

UAI’2001 , pages 538–545.

590

Weinberger, K. Q.

and Saul, L. K.

(2004a). Unsupervised learning of

image manifolds by

semidefinite

programming. In Proceedings of

the Computer Vision and

Pattern Recognition

Conference (CVPR’04),

volume 2, pages 988–995,

Washington D.C. 141

Weinberger,

K. Q. and Saul,

L. K. (2004b). Unsupervised

learning of image manifolds

by

semidefinite programming. In

CVPR’2004 , pages 988–995.

443

Weiss, Y., Torralba,

A., and Fergus, R.

(2008). Spectral hashing. In

NIPS, pages 1753–1760.

448

Welling, M., Zemel, R.

S., and Hinton, G.

E. (2002). Self supervised

boosting. In Advances in

Neural Information Processing Systems,

pages 665–672. 600

Welling,

M., Hinton, G. E.,

and Osindero, S. (2003a).

Learning sparse topographic representa￾tions

with products of Student-t

distributions. In NIPS’2002 .

581

Welling, M., Zemel,

R., and Hinton, G.

E. (2003b). Self-supervised boosting.

In S. Becker,

S.

Thrun, and K. Obermayer,

editors, Advances in Neural

Information Processing Systems

15

(NIPS’02), pages 665–672. MIT

Press. 531

Welling, M.,

Rosen-Zvi, M., and Hinton,

G. E. (2005). Exponential

family harmoniums with an

application to information retrieval.

In L. Saul, Y.

Weiss, and L. Bottou,

editors, Advances

in Neural

Information Processing Systems 17

(NIPS’04), volume 17, Cambridge,

MA. MIT

Press. 578

Werbos, P. J. (1981).

Applications of advances in

nonlinear sensitivity analysis. In

Proceedings

of the 10th

IFIP Conference, 31.8 -

4.9, NYC, pages 762–770.

194

Weston, J., Bengio,

S., and Usunier, N.

(2010). Large scale image

annotation: learning to rank

with joint word-image embeddings.

Machine Learning, 81(1), 21–35.

343

Weston, J., Chopra,

S., and Bordes, A.

(2014). Memory networks. arXiv

preprint

arXiv:1410.3916 . 356,

412

Widrow, B. and

Hoff, M. E. (1960).

Adaptive switching circuits. In

1960 IRE WESCON

Convention

Record, volume 4, pages

96–104. IRE, New York.

13, 18, 20, 21

Wikipedia (2015). List of

animals by number of

neurons — Wikipedia, the

free encyclopedia.

[Online; accessed

4-March-2015]. 20, 21

参考文

献

677

Williams, C. K.

I. and Agakov, F.

V. (2002). Products of

Gaussians and Probabilistic Minor

Component Analysis. Neural Computation,

14(5), 1169–1182. 582

Williams,

C. K. I. and

Rasmussen, C. E. (1996).

Gaussian processes for regression.

In D. Touret￾zky, M.

Mozer, and M. Hasselmo,

editors, Advances in Neural

Information Processing Systems

8

(NIPS’95), pages 514–520. MIT

Press, Cambridge, MA. 124

Williams, R. J. (1992).

Simple statistical gradient-following algorithms

connectionist reinforce￾ment learning. Machine

Learning, 8, 229–256. 588,

589

Williams, R. J.

and Zipser, D. (1989).

A learning algorithm for

continually running fully recur￾rent

neural networks. Neural Computation,

1, 270–280. 192

Wilson,

D. R. and Martinez,

T. R. (2003). The

general inefficiency of batch

training for gradient

descent

learning. Neural Networks, 16(10),

1429–1451. 239

Wilson, J.

R. (1984). Variance reduction

techniques for digital simulation.

American Journal of

Mathematical

and Management Sciences, 4(3),

277--–312. 589

Wiskott, L.

and Sejnowski, T. J.

(2002). Slow feature analysis:

Unsupervised learning of invari￾ances.

Neural Computation, 14(4), 715–770.

421, 422

Wolpert, D.

and MacReady, W. (1997).

No free lunch theorems

for optimization. IEEE Trans￾actions

on Evolutionary Computation, 1,

67–82. 250

Wolpert, D.

H. (1996). The lack

of a priori distinction

between learning algorithms. Neural

Computation, 8(7), 1341–1390. 102

Wu, R., Yan, S.,

Shan, Y., Dang, Q.,

and Sun, G. (2015).

Deep image: Scaling up

image

recognition. arXiv:1501.02876. 381

Wu, Z. (1997). Global

continuation for distance geometry

problems. SIAM Journal of

Opti￾mization, 7, 814–836. 279

Xiong, H. Y., Barash,

Y., and Frey, B.

J. (2011). Bayesian prediction

of tissue-regulated splicing

using

RNA sequence and cellular

context. Bioinformatics, 27(18), 2554–2562.

228

Xu, K., Ba,

J. L., Kiros, R.,

Cho, K., Courville, A.,

Salakhutdinov, R., Zemel, R.

S., and Bengio,

Y.

(2015). Show, attend and

tell: Neural image caption

generation with visual attention.

In

ICML’2015, arXiv:1502.03044 .

90, 349, 591

Yildiz,

I. B., Jaeger, H.,

and Kiebel, S. J.

(2012). Re-visiting the echo

state property. Neural

networks,

35, 1–9. 346

678

参考文献

Yosinski, J., Clune, J.,

Bengio, Y., and Lipson,

H. (2014). How transferable

are features in deep

neural networks? In NIPS

27 , pages 3320–3328.

Curran Associates, Inc. 277,

456

Younes, L. (1998).

On the convergence of

Markovian stochastic algorithms with

rapidly decreas￾ing ergodicity rates.

In Stochastics and Stochastics

Models, pages 177–228. 521

Yu, D., Wang, S.,

and Deng, L. (2010).

Sequential labeling using deep-structured

conditional

random fields. IEEE

Journal of Selected Topics

in Signal Processing. 276

Zaremba, W. and Sutskever,

I. (2014). Learning to

execute. arXiv 1410.4615. 280

Zaremba, W. and Sutskever,

I. (2015). Reinforcement learning

neural Turing machines.

arXiv:1505.00521

. 358

Zaslavsky, T.

(1975). Facing Up to

Arrangements: Face-Count Formulas for

Partitions of Space

by

Hyperplanes. Number no. 154

in Memoirs of the

American Mathematical Society. American

Mathematical Society. 469

Zeiler,

M. D. and Fergus,

R. (2014). Visualizing and

understanding convolutional networks. In

ECCV’14 . 5

Zeiler,

M. D., Ranzato, M.,

Monga, R., Mao, M.,

Yang, K., Le, Q.,

Nguyen, P., Senior, A.,

Vanhoucke, V., Dean, J.,

and Hinton, G. E.

(2013). On rectified linear

units for speech

processing.

In ICASSP 2013 .

391

Zhou, B., Khosla,

A., Lapedriza, A., Oliva,

A., and Torralba, A.

(2015). Object detectors emerge

in deep scene CNNs.

ICLR’2015, arXiv:1412.6856. 470

Zhou,

J. and Troyanskaya, O.

G. (2014). Deep supervised

and convolutional generative stochastic

network for protein secondary

structure prediction. In ICML’2014

. 610

Zhou, Y.

and Chellappa, R. (1988).

Computation of optical flow

using a neural network.

In

Neural Networks, 1988.,

IEEE International Conference on,

pages 71–78. IEEE. 290

Zöhrer, M. and Pernkopf,

F. (2014). General stochastic

networks for classification. In

NIPS’2014 .

610

术语

绝对值

整流 absolute value rectification

167, 172, 173

准确率

accuracy

91, 360, 372–375

声学

acoustic 392

激活函

数 activation

function 147, 245, 257,

258, 260, 271–273, 277,

278

AdaGrad AdaGrad 261,

262

对抗 adversarial 464

对抗

样本 adversarial example 230,

231

对抗训

练 adversarial training

230, 231, 233, 474

几乎处处

almost everywhere 64

几乎必然

almost sure 114

几

乎必然收敛

almost

sure convergence 114

选择性剪接

数据集

alternative splicing dataset 456

原始

采样 Ancestral Sampling 494,

495, 507, 513, 557,

565, 569, 591, 606,

610

退火重

要采样 annealed importance

sampling 533–537, 566, 571,

612

专用

集成电路 application-specific integrated

circuit 384

近

似贝叶斯计

算 approximate

Bayesian computation 611

近似推断

approximate

inference 490, 497, 499,

539–542, 556–558

架构 architecture

170

人工智

能 artificial intelligence

1–4, 6–10, 16, 17,

21, 47, 49, 136,

138, 141, 279, 362,

377, 385,

411, 416,

444, 462, 471, 472,

476, 614

人工神经

网络 artificial

neural network 12, 13,

20, 21, 377

渐近无

偏

asymptotically unbiased 109

679

680 术语

异步

随机梯度下

降 Asynchoronous

Stochastic Gradient Descent 380

异步 asynchronous 240

注意

力机制

attention mechanism 313, 339,

358, 382, 383, 404,

405, 596

属性

attribute 411

自编码器 autoencoder xv, 4,

20, 21, 169, 233,

234, 245, 260, 293,

301–303, 322, 373, 420,

425,

426, 428–442, 445–448,

450, 452, 453, 464,

474, 514, 521, 528,

551, 558, 595, 596,

601,

606–608

自

动微分 automatic

differentiation 191

自动

语音识别 Automatic

Speech Recognition 390, 391

自

回归网络 auto-regressive network 592,

602, 603, 605, 606

反

向传播 back propagate 425

反向

传播 back propagation 147,

175, 406, 429, 530,

560, 575–577, 585–588, 592,

594–596, 610

回退 back-off

478

反

向传播 backprop 153,

176, 181, 182, 185,

187, 188, 384, 385

通过

时间反向传

播 back-propagation through time

326–328, 586

反向传播

backward propagation

257–259, 271, 326, 328,

329, 345–347, 354, 355,

358

词袋 bag of

words 401

Bagging bootstrap

aggregating 220–222, 224, 225,

229

bandit bandit 409

批量 batch viii, 237–239,

251–253, 256, 261, 273

批

标准化 batch normalization 230,

271–273, 362, 455, 456

贝叶

斯误差 Bayes error 102,

103, 360

贝叶

斯规则 Bayes’

rule 63, 64, 119,

463, 465, 535

贝叶

斯推断

Bayesian inference 87, 121,

122, 450

贝叶

斯网络 Bayesian

network 480, 483, 496,

566

贝叶

斯概率 Bayesian probability

49

贝叶

斯统计 Bayesian statistics

118

基准

bechmark 106, 360

信念网络 belief network 21,

480, 592, 603

Bernoulli

分

布 Bernoulli distribution 56,

61, 157–159, 369, 435,

548, 570, 573, 593

术语 681

基准

baseline 362,

363, 375

BFGS BFGS

270

偏置 bias in

affine function 96, 199,

202, 243, 257, 260,

326, 334, 350–354, 371,

396, 408, 546,

547,

559, 564, 565, 567,

571, 572, 575, 579,

580, 582, 585

偏差

bias in statistics 197,

198, 265, 400

有

偏

biased 240, 248

有偏重要

采样

biased importance sampling 400,

505

偏差 biass 114

二

元语法 bigram 393, 400

二元

关系 binary relation 410

二值稀

疏编码 binary sparse coding

546–551

比特

bit 66

块坐标下降

block

coordinate descent 274

块吉布斯采

样

block Gibbs Sampling 500,

510, 563

玻尔兹曼

分布 Boltzmann

distribution 485

玻尔兹

曼机 Boltzmann

Machine 248, 260, 293,

485, 486, 500, 513,

520, 559–561, 567, 571,

575,

576, 578, 579,

584–586, 596, 607

Boosting

Boosting 222, 229

桥式采

样

bridge sampling 533, 536,

537

广播 broadcasting 29

磨合

Burning-in 509, 518–520, 522,

523, 571, 573

变分法

calculus of variations 155,

156, 544, 545, 551,

554, 555

容量

capacity 98,

99, 101, 104, 106,

114, 215, 222, 237,

359, 364–367, 381, 382,

394, 401, 402,

430,

431, 433, 434, 436,

440, 441, 470, 523,

528

级联 cascade 382,

384

灾难遗

忘 catastrophic forgetting

168

范畴分布

categorical distribution 56,

369

因果因子 causal factor

466, 470, 472, 473

因

果模型 causal modeling 53

中心

差分 centered difference 373

682 术语

中

心极限定理

central limit

theorem 58, 504

链式法则

chain rule 53, 76,

525

混

沌 chaos 258

弦 chord 492, 493

弦图 chordal graph 493

梯

度截断 clip gradient 164

截断

梯度 clipping the gradient

353

团 clique 482–486,

491–494, 496, 497, 539,

543, 565

团势

能 clique

potential 482, 484, 485

闭式解 closed form solution

206, 420, 422

级

联

coalesced 379, 383

编码

code 429–431, 433–435, 445,

447, 448

协同

过滤 collaborative

filtering 407, 408

列

column 28

列空

间 column

space 33

共因 common

cause 489

完全

图 complete

graph 491

复杂细胞

complex cell

312

计算图 computational graph

176, 247, 320–322, 328–330,

341, 355, 498, 576,

596, 603

计算

机视觉 Computer

Vision 218, 363, 377,

384–386, 389, 421, 470

概念

漂移 concept drift 457,

458

条件计

算 conditional computation

382

条件概率

conditional probability 52,

53, 64, 69, 524

条件独立的

conditionally independent 53, 418,

481, 487, 488, 492

共轭 conjugate 268

共轭方

向

conjugate directions 267

共轭梯度

conjugate

gradient 267–270

联结主义 connectionism

12, 13, 15, 16,

19, 377, 559

一

致性

consistency 114

约束优

化 constrained

optimization 82, 83, 85,

220, 485

术语 683

特定

环境下的独

立 context-specific independences 488

contextual bandit contextual bandit

409, 410

延拓法 continuation

method 278, 279

收

缩

contractive 346, 445–447

收缩自编

码器

contractive autoencoder 434, 438,

440, 442, 445, 446,

606, 607

对比散

度 contrastive

divergence 248, 438, 519–523,

527, 529, 564, 565,

571, 574, 575, 580–582,

586, 608

凸优化 Convex

optimization 82, 241–243, 261,

274

卷

积 convolution 281,

282, 450, 499

卷积玻尔

兹曼机

Convolutional Boltzmann Machine 293

卷积

玻尔兹曼机

convolutional Boltzmann machine 584

卷积网络 convolutional net 472

卷

积网络 convolutional network 20,

21, 144, 175, 242,

246, 281, 282, 285,

287, 288, 290, 293–297,

299, 301, 302, 304,

306–314, 317–319, 337, 338,

360, 362, 363, 375,

379, 391, 395, 402,

403,

408, 456, 469,

470, 583, 584, 594,

601, 604

卷积

神经网络 convolutional

neural network 145, 218,

229, 281, 284, 285,

290, 295, 306

坐

标上升

coordinate ascent 541, 543,

572

坐标

下降 coordinate descent

274

共父 coparent 539,

547

相

关系数 correlation 55

代价

cost 119, 134, 243–246,

248, 252, 257, 360,

361, 365, 370, 455,

506

代价函数 cost function

26, 74, 76, 78,

87, 104, 115, 116,

132–134, 152, 201, 203,

204, 208, 209,

214,

215, 231, 235–237, 242–249,

251, 252, 255, 269,

271, 272, 274, 275,

278, 279, 353, 360,

365, 375, 413, 421,

423, 433, 437, 438,

453, 465, 506, 524,

575, 588, 601

协

方差

covariance 55, 60, 202,

220, 427

协方差

矩阵 covariance

matrix 55, 58, 60,

418, 427

协方差

RBM covariance

RBM 580, 581

覆盖

coverage 361, 375

准则

criterion 74, 210, 251,

254, 256, 262–265, 267,

269, 322, 327, 345,

401, 435, 437–439, 446,

447, 575, 586, 594,

596, 608, 610

临

界点

critical point 74–77, 79–82,

242–245, 249, 250, 266,

453, 551, 553

684

术语

临

界温度 critical temperatures

514

互相

关函数 cross-correlation 283

交叉

熵 cross-entropy 68, 116,

153–156, 189–191, 194, 330,

333, 396, 397

累积函数

cumulative

function 504

课程学习 curriculum

learning 279, 280, 327

维

数灾难 curse of dimensionality

135, 136, 138, 394,

395, 468, 473, 603

曲率

curvature 78–81, 99, 201,

242, 253, 266

控制论

cybernetics 12, 13

衰减

damping

551

数据生成分

布 data generating

distribution 97, 236, 240,

241, 251

数据生成

过程 data

generating process 97, 449

数据并

行 data parallelism 380

数据点 data point 92

数

据集 dataset 87, 92–95,

97, 98, 101, 104,

106, 107, 113–115, 118,

119, 125, 128, 131,

133, 134,

141

数据集

增强

dataset augmentation 386, 389

决策树

decision tree 125, 127,

382–384, 466

解码器 decoder

4, 338, 339, 402–404,

417, 420, 421, 423–427,

429–431, 434–436, 439–441, 447,

469, 595

分解

decompose 38

深度信念网

络 deep belief network

17, 21, 310, 452,

472, 520, 536, 538,

562, 564–566, 568, 569,

572, 584, 591, 609

深度玻尔

兹曼机 Deep Boltzmann Machine

xiv, 20, 21, 452,

513, 520, 523, 526,

527, 538, 539,

551,

557, 562, 564, 566–577,

584, 609

深度

回路 deep

circuit 472

深度前

馈网络 deep

feedforward network 145, 147,

391, 417, 428

深度

生成模型

deep generative model 452

深

度学习 deep learning 1,

4–7, 10–15, 17, 18,

22–24, 26, 73, 74,

76, 79, 82, 87–89,

92, 93, 100,

105,

125, 128, 132, 133,

135–138, 141, 144, 197,

198, 210–212, 230, 235,

237, 239, 248, 251,

256, 261, 262, 266,

269, 270, 275, 345,

358, 362, 364, 371,

374, 377, 379, 381,

383–386,

390–392, 407, 408,

410, 412, 415, 416,

444, 448, 456, 458,

462, 466, 472, 474–476,

484,

496–499, 501, 506,

507, 510, 516, 518,

521, 526, 538, 539,

542, 543, 555

术语

685

深度模型 deep model 93,

235, 236, 241, 243,

245, 257, 263, 277,

452, 522, 526

深

度网络

deep network 144, 211,

258, 272, 278, 471

信任

度 degree of belief

49

去噪 denoising 90,

92, 433, 437, 438,

440, 445, 476, 528

去噪

自编码器 denoising autoencoder xv,

207, 433, 434, 436–440,

442, 445, 454, 457,

588, 606–

611

去

噪得分匹配

denoising

score matching 438, 528

依赖 dependency 474, 476,

488, 492, 496

深度

depth 145

导

数 derivative

74, 76, 77, 81,

86

描述 description 70

设计

矩阵 design matrix 93–95,

129

细致平

衡 detailed balance

608

探测级 detector stage

290

确

定性 deterministic 238

对角矩

阵 diagonal matrix 36

微分熵 differential entropy 67,

552

微

分方程 differential equation

255

降维

dimensionality reduction 406,

429, 448

Dirac delta

函数 Dirac delta function

59

Dirac 分布 dirac

distribution 59, 60, 528,

542, 543, 553, 554

有

向 directed 69

有向图模

型

directed graphical model 331,

334, 418, 462, 480–482,

491, 494, 495, 591,

603

有向模型

Directed Model 481,

482, 485, 488, 490–492,

495, 507, 538, 557,

565, 566, 594

方向导数

directional derivative 76, 77

判

别 RBM discriminative RBM

453

判别器网

络 discriminator network

597

分布式表

示 distributed representation

16, 138, 228, 394–396,

404, 406–408, 410–412, 444,

449,

459, 466–471, 473,

498, 499

深度神经

网络 DNN

247, 261, 262, 265,

271, 273, 381, 384,

391, 450–453, 471, 566

领域自

适应 domain adaption 457

686 术语

点

积 dot

product 30, 35, 123,

124

双反向传

播 double backprop

233, 474

双重分块

循环矩阵 doubly

block circulant matrix 284,

307

降

采样 downsampling 293,

298

Dropout Dropout 208,

222–230, 252, 257, 362,

364, 366, 367, 381,

383, 391, 455, 456,

574, 576,

588, 600

Dropout Boosting Dropout Boosting

229

d-分离 d-separation 488,

490

动

态规划 dynamic programming

188

动态

结构 dynamic structure

382, 383

提前终

止 early

stopping 212–217, 237, 258,

362, 454, 455

回声状态

网络

echo state network 21,

345–348

有效容

量 effective capacity

100

特征分解

eigendecomposition 37–39

特征值

eigenvalue 37

特征

向量 eigenvector

37

基本单

位向量 elementary basis

vectors 485

元素

对应乘积 element-wise

product 30

嵌

入 embedding

442, 443

经验分布

empirical distribution

59, 60, 236, 238,

528

经验频率 empirical frequency

59

经

验风险 empirical risk

236

经验

风险最小化

empirical risk minimization

236, 237

编码器 encoder

4, 338, 339, 402–404,

421, 424–427, 429–432, 434–440,

442, 443, 445, 447,

451,

558, 595, 596

端到

端的 end-to-end 359, 362,

363, 374, 392, 496

能量函

数 energy function 485,

486, 499, 500, 511,

518, 559–561, 566, 567,

575, 578–583, 586

基于能量

的模型

Energy-based model 485–487, 499,

506, 507, 510, 511,

513, 514, 559, 561,

566,

583

集成

ensemble 197,

220–223, 225–227, 229, 381,

402, 450

术语 687

集成学

习 ensemble learning 420

轮 epoch 242, 374

轮数 epochs 213

等

式约束

equality constraint 83, 84

均衡

分布 Equilibrium Distribution 508,

509

等变 equivariance 286

等

变表示 equivariant representations 285

误差

条 error bar 103

误差函数

error function 74

误差度量

error metric 359, 360

错

误率 error rate 91,

360, 361, 366

估计量

estimator

108–115, 197, 456, 468,

520, 523

欧几里得范

数 Euclidean

norm 34

欧拉-拉格

朗日方程 Euler-Lagrange

Equation 552

证

据下界 evidence

lower bound 539, 540,

543, 544, 548, 565

样本

example 13, 23, 88,

90–95, 97, 99, 100,

102, 106, 107, 109,

110, 112–119, 123–125, 128,

129, 131–133, 135–138, 141,

210

额外误差 excess error

252, 256

期

望 expectation

54, 56

期望最大

化 expectation

maximization 419, 541–544, 595

E 步 expectation step

541

期望值

expected value 54

经验 experience, E 87,

88, 92, 94, 95

专家网

络 expert network 383

相消解释

explaining away 538, 550,

565

相消解释作

用 explaining away

effect 489

解释因子

explanatory factort

463, 471, 473, 474

梯度爆炸 exploding gradient 248

利

用 exploitation 409, 410

探索 exploration 409, 410

688 术语

指数分布 exponential distribution

58

因

子 factor 482–484,

486, 493, 494, 559,

585

因子分析

factor analysis 418,

420, 426

因子图 factor

graph 493, 494

因子

factorial

417, 425, 426, 501,

544, 551, 562, 563,

568, 569

分解 factorization

69, 70

分解的

factorized 474

变差因素 factors of variation

4, 6, 173, 470,

472, 473

快

速 Dropout

fast dropout 228

快速持续

性对比散度

fast

persistent contrastive divergence 524

可行 feasible 83, 84,

86

特征 feature 88,

92–96, 98, 99, 104,

123–125, 128–131

特

征提取器 feature

extractor 422, 425, 453,

469, 543

特

征映射 feature

map 282, 389

特征

选择

feature selection 204

反馈

feedback 145

前

向 feedforward

145

前馈分类

器 feedforward classifier

464

前馈网络

feedforward network 145–150,

156, 169, 171, 172,

174, 193–196, 245, 247,

248, 259,

276, 319,

321, 330, 334, 337,

344, 347, 361, 362,

429, 432, 434, 435,

437, 449, 450, 464,

465, 472, 474, 593

前馈神经网

络 feedforward neural network

145–148, 151, 153, 165,

171, 175, 246, 434

现场可编

程门阵列 field programmable gated

array 384

精

调 fine-tune

451, 452, 455, 520

精调 fine-tuning 275, 276,

425, 565

有限

差分 finite

difference 373

第一层

first layer

145

不动点方程

fixed point equation

545, 549, 550, 554,

556, 557, 569, 572

定点运算 fixed-point arithmetic 378

翻

转 flip 283

术语

689

浮点

运算 float-point arithmetic

378

遗忘门

forget gate 350–352

前向模式累

加 forward mode accumulation

192

前向传播

forward propagation 175,

182, 183, 257–259, 285,

301, 302, 309, 325,

326, 338, 346,

349

傅立叶变换

Fourier transform 308, 309

中央凹 fovea 313

自由

能

free energy 487

频率派概

率

frequentist probability 49

频率派统

计

frequentist statistics 118

Frobenius

范数 Frobenius norm 35,

41, 44, 45

F

分数

F-score 361

全 full

297

泛函 functional 155,

551–555

泛函

导数 functional derivative

551–554

Gabor 函数 Gabor

function 314–317

Gamma 分

布

Gamma distribution 581

门控

gated 349–352, 355

门控

循环网络

gated recurrent net 362

门

控循环单元

gated recurrent unit 349,

351, 362

门控 RNN

gated RNN 349, 351

选通器

gater 383

高斯分布 Gaussian

distribution xxvi, 57, 58,

60, 68, 154, 156,

162, 163, 165, 295,

418, 426, 554,

555,

578, 580, 581, 587,

588, 595, 600, 602

高

斯核 Gaussian kernel 124,

466

高斯混

合模型 Gaussian Mixture

Model 60, 61, 390,

391, 496

高斯

混合体 Gaussian

mixtures 466

高斯

输出分布 Gaussian

output distribution 155

高

斯

RBM Gaussian RBM 579–581

Gaussian-Bernoulli RBM Gaussian-Bernoulli RBM

xiv, 578–580

690 术语

通用

GPU general purpose GPU

379

泛化 generalization 97,

99, 136, 137, 146–149,

151, 172, 174, 194,

197, 198, 257, 277,

364, 381,

386, 389,

425, 457–459, 465, 468,

469, 472

泛化误

差 generalization

error 97, 100–102, 114,

236, 239–241, 250, 252,

257, 259, 261, 362,

364–367, 425

泛化 generalize

257, 457–459, 468–470, 473,

592, 603, 606

广义

函数

generalized function 59

广义

Lagrange 函

数 generalized Lagrange

function 83, 84, 204

广义 Lagrangian generalized Lagrangian

83, 85

广义

伪似然 generalized

pseudolikelihood 525, 526, 576

广义

伪似然估计

generalized pseudolikelihood estimator 525

广义得分匹

配 generalized score matching

527, 528

生成式对

抗框架 generative

adversarial framework 465

生成

式对抗网络

generative

adversarial network 464, 465,

513, 531, 592, 597–601

生成模型 generative model 385,

417, 419, 420, 422,

425, 426, 428, 431–433,

440, 453, 464, 465,

470, 471, 498, 513,

515, 531, 537, 557–559,

564–566, 585, 587, 591,

592, 594, 596, 600,

611–614

生

成式建模 generative modeling

594, 595, 597, 602,

610–613

生

成矩匹配网

络 generative moment

matching network 600, 601

生成随机

网络 generative stochastic network

xv, 431, 607–611

生成器

网络

generator network 592–595, 597,

599–601

吉布斯

分布 Gibbs distribution

484

Gibbs 采样 Gibbs

Sampling 495, 499–501, 510–513,

515, 522, 527, 565,

568, 570, 573, 576,

581,

582

吉

布斯步数 Gibbs

steps 519, 521, 523,

573

全

局对比度归

一化 Global contrast

normalization 387–389

全局极

小值 global

minima 245, 246

全局最

小点

global minimum 75, 76,

82, 85, 243, 244,

249, 279

梯度 gradient

76–78, 82, 83, 85,

86, 199–201, 203, 205,

214, 215, 323, 326–330,

343, 344, 346,

347,

349, 352–358, 438, 439

梯

度上升 gradient ascent 548

术语

691

梯度截断 gradient clipping

246, 248, 258, 354,

355

梯

度下降 gradient descent

74, 75, 77–83, 85,

123, 132–134, 205, 206,

215, 237, 238, 242,

245–247,

249, 251–255, 258,

259, 266, 272–274, 354,

365, 371, 380, 381,

405, 421, 429, 437,

447, 453,

470, 511,

541, 545, 549, 577,

589, 594

图模

型 graphical

model 69, 331–334, 396,

475, 476, 479, 481,

487, 488, 491, 494–499,

501, 538,

543, 544,

550, 551, 554, 559,

561, 562, 566, 567,

591, 603

图形处理

器 Graphics

Processing Unit 239, 378–380,

383, 384

贪心 greedy

451, 452

贪心

算法 greedy

algorithm 275, 451

贪心逐

层预训练

greedy layer-wise pretraining 310,

572, 575, 576

贪

心逐层训练

greedy

layer-wise training 572

贪心逐层无

监督预训练

greedy

layer-wise unsupervised pretraining 450–452

贪心监督预

训练 greedy supervised pretraining

275, 276

贪心无

监督预训练

greedy unsupervised

pretraining 452, 574

网格搜索

grid search 368–370

Hadamard

乘

积 Hadamard product xxv,

30

汉明距离

Hamming distance 528

硬专家混合

体 hard mixture of

experts 383

硬双曲正

切函数 hard

tanh 170

簧风

琴 harmonium

499, 561

哈里斯链

Harris Chain

509

Helmholtz 机 Helmholtz

machine 431, 592

Hessian

Hessian xxv, 78–82, 200,

201, 203, 204, 215,

239, 242, 244, 246,

248, 253, 266–268,

270,

271, 279, 352, 453,

454, 575

异方差 heteroscedastic

162

隐

藏层 hidden layer

5, 13, 146–148, 150,

165, 171–173, 184, 188,

190, 195, 224, 271,

272, 275–

278, 301,

324, 429, 434, 440,

446, 448, 449, 471,

472, 527, 538, 561–571,

573, 580, 591,

604,

606, 610

隐马尔

可夫模型 Hidden

Markov Model 390–392

692

术

语

隐藏单元

hidden unit vi,

5, 15, 16, 20,

21, 148, 154, 156,

165, 166, 168–172, 175,

190, 195,

206–208, 211,

215, 218, 220, 222–224,

226, 229, 230, 243,

257, 260, 273, 295,

300, 321,

323–327, 329,

332, 334, 335, 339,

345, 348–350, 352, 363,

365–368, 374, 382, 383,

387, 405,

421, 434,

437, 445, 446, 466,

469–472, 492, 496, 499,

500, 510, 517, 520,

522, 527, 539,

541,

543, 546, 547, 550,

560–562, 565–571, 575, 578–582,

584–586, 592, 594, 602,

604–606,

613

隐藏变量 hidden

variable 526, 538

爬

山

hill climbing 77

超参数

hyperparameter 253, 254, 259,

261–264, 359, 363–371, 375,

455

超

参数优化 hyperparameter optimization

368

假

设空间 hypothesis space

98

同分

布的 identically distributed

97

可辨认

的 identifiable 243

单位矩阵

identity matrix xxiii, 31

独立同分布

假设 i.i.d. assumption 97

病态 ill conditioning 242

不

道德 immorality 491, 492

重要采

样 Importance Sampling 400,

401, 504–506, 532–536, 592,

596

相互独立

的 independent 53,

97

独立成分

分析 independent component

analysis 418–422

独立同

分布 independent

identically distributed 503, 531

独立子

空间分析 independent subspace analysis

421

索

引 index of

matrix 27, 28

指示函数

indicator

function 58

不等式约束

inequality constraint

83–85

推断 inference xiv,

2, 208, 225, 227–229,

393, 394, 415, 431,

432, 497, 542, 559,

560, 565,

567–571, 573–577,

582, 586, 592–596, 598,

600, 605, 606, 613

无限 infinite 456

信

息检索

information retrieval 448

内积

inner

product 123

输入 input

282, 453

术语 693

输

入分布 input distribution 453,

454, 457

干预

查询 intervention

query 53

不变 invariant

291

求

逆 invert 579

Isomap Isomap 456

各向同性

isotropic

58, 61

Jacobian Jacobian

xxv, 77, 78, 176,

178, 180, 185–187, 233,

278, 329, 343, 345,

346, 373, 421,

445,

446

Jacobian 矩阵 Jacobian

matrix 65, 178, 192

联合概

率分布 joint probability distribution

50, 52, 53, 69,

559–561, 566

Karush–Kuhn–Tucker Karush–Kuhn–Tucker

83–85, 204, 206

核函

数

kernel function 123, 282

核机器 kernel machine 124,

125, 146, 210, 345,

466, 564

核

方法 kernel

method 124

核技巧

kernel trick

123, 124, 133, 146

KL 散度 KL divergence

116, 219, 539, 545

知识库

knowledge base 2, 411,

412

知识图谱 knowledge graph

412

Krylov 方

法 Krylov

method 193

KL 散度

Kullback-Leibler (KL) divergence xxvi,

67, 68

标签

label 92,

94, 124, 136, 453,

459, 470, 472

标注

labeled 363, 364, 375,

450, 454, 456, 458,

459, 461, 462

拉格朗

日乘子

Lagrange multiplier 552, 553

语言

模型 language model 355,

392–394, 402, 403, 406,

410, 506

Laplace 分布

Laplace distribution 58

大

学习步骤

large learning step 544

潜

在 latent 163, 418,

419, 426, 431, 451,

463, 496, 522, 560,

561, 597, 599, 602,

609

潜层 latent layer

561

694 术语

潜变量 latent

variable xiii, 60, 163,

243, 396, 417–419, 429,

431–433, 435, 452, 462,

466, 472,

486, 487,

496–499, 501, 512, 514,

517, 521, 527, 538,

539, 541, 542, 544,

545, 548, 554,

560–562,

564–567, 576, 592, 594–596,

607, 609

大数

定理 Law

of large number 503

逐层的

layer-wise 451

L-BFGS L-BFGS

270, 271

渗漏整流线

性单元 Leaky

ReLU 167, 362

渗漏

单元

leaky unit 347–349

学成

learned 450, 454, 458,

459, 465, 467, 470,

473, 474, 557, 558,

592

学

习近似推断

learned approximate inference

447

学习器 learner 106,

138, 240, 457, 459,

463, 469, 472, 473

学习

率 learning rate 77,

79, 133, 235, 239,

242, 251, 252, 254,

256, 261–264, 266, 268,

271, 362,

363, 365–368,

372, 523, 524, 573,

589, 591

勒贝格可

积 Lebesgue-integrable

517

左特征向

量 left eigenvector

37

左奇异向

量 left singular

vector 40

莱布尼兹

法则 Leibniz’s

rule 517

似然 likelihood

49

线

搜索 line search

77, 83, 269

线性自

回归网络

linear auto-regressive network 602

线

性分类器 linear classifier 237,

428, 449, 453, 458,

467, 470

线

性组合 linear

combination 33

线性

相关 linear

dependence 33

线性因

子模型 linear

factor model 417, 418,

420, 421, 423, 425,

426, 428, 501, 543,

579

线性

模型 linear model

14, 198, 203, 204,

206, 215, 228, 231,

560, 602

线性回

归 linear

regression 87, 94, 96–98,

100, 101, 104, 108,

117–119, 121–123, 133, 134,

198,

200–203, 205, 206,

219, 228, 260, 345,

428, 544, 602

线性阀值

单元

linear threshold units 469,

470

线性无

关 linearly independent

33

链接预测

link prediction 412

链接重要采

样 linked importance sampling

537

术语 695

Lipschitz

Lipschitz 82

Lipschitz 常数

Lipschitz

constant 82

Lipschitz 连续

Lipschitz continuous 82

流体状

态机

liquid state machine 345

局部条

件概率分布

local conditional probability distribution

480

局部不变性

先验 local constancy

prior 136

局部对

比度归一化

local contrast

normalization 388, 389

局部下降

local descent 250

局

部核

local kernel 137, 466

局部极

大值 local maxima 127,

245

局部极

大点 local maximum

74, 75, 79, 80,

244, 549

局部极

小值 local

minima 243–245, 249, 279,

453

局部极

小点 local minimum

74–76, 79, 80, 82,

213, 214, 237, 243,

244, 249, 255, 453

对数尺

度 logarithmic scale 368,

369

逻辑回归

logistic regression 2,

3, 6, 123, 146,

153, 155, 177, 198,

206, 231, 310, 362,

367, 397,

530, 560,

600, 602

logistic sigmoid

logistic sigmoid vi, 61,

62, 122, 157, 159,

168, 171

分对数 logit

63, 158

对数

线性模型 log-linear

model 486

长

短期记忆 long

short-term memory ix, 16,

22, 260, 278, 349–353,

355, 356, 358, 362,

392

长

期依赖 long-term dependency

247, 341, 343–345, 347,

348, 351, 355

环

loop 492, 493

环

状信念传播

loopy

belief propagation 498, 499

损失 loss 91, 116,

132, 528, 576

损失函

数

loss function 74, 107,

134, 219, 236, 237,

245, 248, 249, 253,

278, 325–327, 355, 365,

396, 401, 422, 430,

431, 433, 435, 447,

585, 587, 602

机器学习

machine

learning 2–4, 7, 10,

12–18, 20, 24, 26,

72, 86–95, 97–100, 102,

104, 105, 108,

112,

113, 118, 119, 123,

126, 132, 134, 135,

138, 139, 141, 197,

204, 206–208, 220, 222,

232, 234–237, 240, 241,

251, 252, 260, 279,

319, 353, 359–364, 371,

372, 374, 377, 378,

380–382, 401, 407, 408,

410, 411, 429, 440,

443, 449, 453, 458,

473, 474, 476, 486,

490,

496, 498, 502,

506, 518, 519, 542,

551, 552, 557

696

术语

机器学

习模型 machine learning

model 452

机器

翻译 machine

translation 362, 459

主对角

线

main diagonal 29

流形

manifold 139, 141, 142,

233, 426, 427, 438–446,

473, 474, 496, 511,

513, 597

流形

假设 manifold

hypothesis 140

流形学

习 manifold

learning 139, 434, 442–444,

597

边缘概率

分布 marginal probability

distribution 52

马尔可

夫链 Markov

Chain xv, 506–514, 518–524,

527, 534, 566, 569,

571, 573, 607–610

马尔可

夫链蒙特卡

罗

Markov Chain Monte Carlo

415, 504, 506, 507,

509, 511, 513, 518–520,

524, 528, 534, 563,

569, 575, 606, 609–611

马尔可夫

网络 Markov network 482,

486, 496, 500

马尔可

夫随机场

Markov random field 482,

486

掩

码 mask 222–225,

228, 229

矩阵 matrix

28

矩阵

逆 matrix inversion

31, 32

矩阵乘积

matrix product

29

最大范数 max norm

35

池

pool 291, 293,

294

最大池化 max pooling

290–293, 301, 469, 602

极

大值 maxima 244, 245

M 步 maximization step

541, 542

最大

后验 Maximum

A Posteriori v, 121,

122, 204, 392, 432,

542–544, 558, 582

最大似

然

maximum likelihood 420, 424,

516, 545, 546

最大似然

估计

maximum likelihood estimation 115–119,

121, 122, 134, 238,

393, 520, 525, 529,

543, 545

最大平

均偏差 maximum

mean discrepancy 601

maxout

maxout 213, 243, 259,

278, 292, 317, 362

maxout 单元

maxout unit 167,

168, 172, 317, 365

平均绝对误

差 mean absolute error

156

均值和协

方差 RBM mean

and covariance RBM 580–583

学生 t 分

布均值乘积

mean product

of Student t-distribution 580–583

术语 697

均方误

差 mean

squared error 95, 96,

103, 104, 113, 116–118,

120, 129, 148, 154–156,

158, 194,

195, 345,

422, 430, 435, 437,

464, 465, 590, 595,

608

均值-协方

差 RBM mean-covariance

restricted Boltzmann machine 486

均匀场 meanfield 21, 568–570,

572–574, 576, 577, 584,

592, 596, 605

均

值场

mean-field 544–551, 554, 557,

558

测度论

measure theory 64

零测度 measure zero 64

记忆

网络 memory network 356,

358, 412

信息传

输 message

passing 551

小批量 minibatch

viii, 132, 183, 189,

190, 221–223, 237–241, 248,

251–254, 256, 259, 261–265,

270, 272, 320, 353,

354, 374, 380, 383,

429, 436, 453, 502,

509, 519, 521, 523,

541, 573, 577

小

批量随机

minibatch stochastic 239

极

小值

minima 245, 249

极小点

minimum

250, 251, 553

混合

Mixing 511–515, 521–524

混合时

间

Mixing Time 509, 510

混合密度

网络 mixture density network

163

混合分

布 mixture distribution

59

专家混合

体 mixture of

experts 383, 466

模态

modality 460

峰值

mode xiii,

511–515, 520, 522–524, 551

模型 model 452

模型平

均

model averaging 220–222

模型压缩

model

compression 381

模型可辨识

性 model

identifiability 243

模型并行

model parallelism

380

矩 moment 600,

601, 611

矩匹配 moment

matching 600, 611

动

量

momentum 253–256, 261, 263,

264, 277, 362

蒙特卡罗

Monte

Carlo 227, 400, 502–504,

506, 515, 518, 524,

532, 557, 581, 589,

595

Moore-Penrose 伪逆 Moore-Penrose

pseudoinverse xxv, 41, 99,

105

698 术语

道

德化

moralization 491, 492

道德图

moralized

graph 491, 492

多层感知机

multilayer

perceptron 5, 20, 21,

145, 188, 189, 194,

275, 276, 298, 340,

341, 403,

440, 471,

560, 565, 566, 568,

569, 574, 575, 586

多峰值 multimodal 533, 550,

611

多模

态学习 multimodal learning

460

多项

式分布 multinomial distribution

56

Multinoulli 分布

multinoulli distribution

56, 59, 60, 73,

159, 163

多预测深度

玻尔兹曼机

multi-prediction deep

Boltzmann machine 575–577, 596,

607

多任务学习

multitask learning 210,

211, 457, 458

多维正态分

布

multivariate normal distribution 58,

418, 512

朴素贝叶

斯 naive

Bayes 2

奈特 nats

66

自然

语言处理 Natural Language

Processing 246, 363, 377,

392, 395, 396, 406,

407, 410, 455

最

近邻

nearest neighbor 137, 450,

466–468

最近邻

图 nearest neighbor

graph 443

最近邻回

归 nearest

neighbor regression 101, 125

负定 negative definite 38

负部

函数 negative part function

63

负相 negative phase

517–520, 522–524, 526, 527,

557, 561, 571, 572

半

负定 negative semidefinite 38

Nesterov 动量 Nesterov momentum

256

网

络 network 145

神经自回

归密度估计

器 neural auto-regressive density

estimator xiv, 602, 604–606

神经自回

归网络 neural auto-regressive network

603–606

神经

语言模型 Neural Language

Model 394, 396, 397,

399, 401, 402, 406,

411

神

经机器翻译

Neural Machine Translation

395

神经网络 neural network

12–17, 19–23, 197–199, 205–207,

215, 218, 221, 222,

225, 229–232, 234,

235,

241–250, 257, 258, 261,

262, 266, 267, 269,

270, 273–275, 277–280, 319,

341, 349, 356,

358,

377–379, 384, 387, 390–392,

395, 396, 401, 402,

405, 406, 408, 411,

429, 444, 447,

452–455,

466, 470, 506, 556,

587

术

语 699

神经网络

图灵机

neural Turing machine 356,

357

牛顿

法 Newton’s method

81, 82, 85, 242,

243, 245, 250, 266–268,

270, 274

n-gram n-gram

393, 394, 396, 397,

401–403, 467, 478

没有免费

午餐定理

no free lunch theorem

102, 105, 472

噪

声

noise 101, 140, 239,

248, 253, 279, 362,

363, 453, 528–531

噪声分布

noise

distribution 529–531

噪声对比估

计 noise-contrastive

estimation 529–531

非凸 nonconvex

241, 243–246, 262, 266,

275, 279

非分

布式 nondistributed

467–469

非分布

式表示 nondistributed representation

466–468

非线

性共轭梯度

nonlinear conjugate gradients

269, 270

非线性独立

成分估计 nonlinear

independent components estimation 420,

421

非

参数 non-parametric 100,

394, 442–444

范数 norm

34

正

态分布 normal distribution

57, 58, 61, 504,

553

正规

方程 normal equation

96, 98, 99, 133,

148

归一化

的 normalized 51

标准初始

化 normalized initialization 258

数值 numeric value 182

数值

优化 numerical optimization 235,

242, 246

对象识

别 object

recognition 246, 362, 364,

385, 389, 390, 423,

425, 459, 612

目标

objective 455

目标

函数 objective

function 74, 77, 84,

197–202, 204, 205, 213,

214, 217, 221, 236–238,

241,

246–248, 250, 252,

253, 265–267, 269, 274,

278, 279, 353, 359,

368, 374, 450, 470,

525, 527,

564, 572

奥卡姆

剃刀 Occam’s razor 100

one-hot one-hot 125, 131,

161, 193, 394, 395,

454, 455, 459, 466,

468, 586, 603

一次学

习

one-shot learning 459

在线

online 238

在线

学习 online

learning 240

700 术语

操

作 operation 176

最佳容量

optimal

capacity 101, 103, 114

原点 origin 33

正交

orthogonal 36

正

交矩阵 orthogonal

matrix 37

标准

正交 orthonormal

36, 39

输出 output

453

输

出层 output layer

145

过完备

overcomplete 431, 434,

582, 583

过估计 overestimation

506

过拟

合 overfitting 98,

99, 105, 114, 197,

198, 215, 237, 241,

252, 258, 359, 363,

365, 366, 372,

375,

381, 450, 454, 455,

478, 613

过拟合机

制 overfitting

regime 101

上溢 overflow

72, 73, 535

并行

分布式处理

Parallel

Distributed Processing 194

并行回火

parallel tempering 514, 524,

537

参

数 parameter 94

参数服务

器 parameter server 381

参数共享

parameter sharing 218, 225,

229, 285, 286, 288,

300, 313, 319, 320,

322, 323, 332, 333,

402, 601, 602, 604

有参情况 parametric case 118

参

数化整流线

性单元 parametric ReLU 167,

362

偏导

数 partial derivative

76, 77, 445, 551

配分函数

Partition Function 415, 484,

486, 502, 506, 515,

516, 518, 519, 524,

525, 527–529,

531–537, 557,

559–561, 564, 565, 571,

578, 583, 584, 598

性能度量 performance measures 87,

88, 91, 95, 361,

362

性

能度量 performance metrics

359, 360, 362, 370,

372, 374, 375

置换

不变性

permutation invariant 296

持续

性对比散度

persistent

contrastive divergence 521, 523,

564, 572, 575, 581,

582

音素 phoneme 390–392,

457

术语 701

语

音

phonetic 392

分段 piecewise

362

点估

计 point estimator

108

策略 policy 409,

410

策略

梯度 policy gradient

383

池化 pooling 207,

229, 281, 287, 290–295,

299, 306, 309, 310,

312, 313, 386, 421

池

化函数 pooling function 290

病态

条件 poor conditioning 74,

81, 239, 242, 246,

248, 250, 253, 454

正定 positive definite 38

正

部函数 positive part function

63

正相

positive phase 517–520,

523, 524, 557, 560,

571

半正定 positive semidefinite

38

后验

概率 posterior probability

60

幂方法

power method 248

PR 曲线 PR curve

361

精度 precision 57,

361, 373, 612

精

度矩阵

precision matrix 58

预测

稀疏分解

predictive sparse decomposition 447

预

训练 pretraining 275–278, 391,

425, 451–456, 498, 521,

527

初级视

觉皮层 primary visual

cortex 311

主成

分分析 principal

components analysis xi, 42–44,

128–130, 134, 210, 235,

302, 388, 418–420,

422,

424, 426, 427, 430,

441, 446, 448

先验

概率

prior probability 60

先验概

率分布

prior probability distribution 118,

295

概率

PCA probabilistic PCA

418–420, 426, 538, 539

概率密度函

数 probability density function

51, 52, 57–59, 64,

503, 551–553, 598

概率分布

probability

distribution 47, 50–56, 58–61,

66, 67, 69, 70,

360, 472, 516, 529,

531

概率质量函

数 probability mass

function 50, 51, 90,

560, 571

专家之积

product of

expert 486

乘法法则 product

rule 53

702 术

语

成比例 proportional 70

提

议分布

proposal distribution 400, 532,

534–536

伪似

然 pseudolikelihood 524–530,

571

象限对 quadrature pair

316

量

子力学 quantum mechanics

48

径向

基函数 radial basis

function 124, 146, 170,

471

随机

搜索 random search

369–371

随机变

量 random variable

49–56, 58–60, 64, 65,

67, 69, 70, 472,

525, 530, 534

值域

range 33

比率

匹配 ratio

matching 527, 528, 564

召回率

recall 361, 382, 612

接受域 receptive field 287,

295

再循

环 recirculation 429

推荐系统

recommender system 407–409

重构

reconstruction 429, 430, 436–439,

441, 442, 445–447, 608,

609

重构误

差 reconstruction error

419, 422, 426, 427,

431, 433, 437, 438,

440, 445, 446, 448,

454,

514, 608

整流线性

rectified

linear 151, 167, 230,

243, 273, 290

整流线性变

换

rectified linear transformation 152

整流线性

单元 rectified linear unit

14, 15, 150, 151,

165–168, 170–172, 177, 195,

233, 278, 362,

375,

391, 433, 455

整流网

络

rectifier network 172, 173,

195

循环 recurrence 450

循环

卷积网络 recurrent convolutional network

307

循

环网络 recurrent network

145, 246–248, 307, 319–324,

326, 330, 333, 338,

341, 343–347, 349,

350,

353, 354, 357, 412,

417, 440, 474, 550,

576, 577

循环

神经网络 recurrent

neural network ix, 21,

22, 144, 145, 208,

228, 247, 306, 318–325,

328,

330–341, 343–345, 348,

349, 352, 355, 358,

392, 403, 550, 585,

586, 596

回

归 regression

103

正则化 regularization 104,

105, 118, 122, 197–206,

208, 209, 212–220, 222,

227–236, 258, 355,

359,

362, 364–366, 387–389, 422,

431, 432, 434, 438,

440, 446, 453, 455,

472

术

语 703

正则化

regularize 239, 365, 421,

422, 455, 456, 514,

528, 575, 584, 588

正

则化项 regularizer 104, 122,

126, 134, 362, 452,

454, 455, 467

强化

学习

reinforcement learning 23, 93,

232, 383, 409, 410,

458, 557, 588, 590

关系 relation 410–412

关

系型数据库

relational

database 411

重参数化 reparametrization

575, 588

重

参数化技巧

reparametrization trick

588, 594, 610

表示

representation 2–7, 16, 210,

219, 220, 297, 357,

367, 394, 395, 403,

404, 411, 430, 431,

433,

440–442, 448

表示学

习

representation learning 4, 403,

417, 419, 448–450, 452,

457, 458, 461–463, 466,

472–

474, 501, 514

表示容量

representational capacity 100, 104

储层计算 reservoir computing 345

受

限玻尔兹曼

机 Restricted Boltzmann Machine

228, 301, 391, 408,

437, 438, 448, 450,

472, 490,

499–501, 510,

514, 515, 517, 519–523,

533, 536–538, 561–568, 571,

572, 574, 575, 578,

579,

581, 583, 585,

586, 591, 600, 605,

609, 610

反向相关

reverse correlation

314

反向模式累

加 reverse mode

accumulation 191

岭回归 ridge

regression 199

右

特征向量 right

eigenvector 37

右

奇异向量 right

singular vector 40

风

险

risk 236

行 row

28

扫视 saccade 313

鞍

点 saddle point 75,

76, 79, 80, 82,

244–246, 248, 249, 266,

267

无鞍牛顿

法 saddle-free Newton

method 245

相同 same

297, 298

样本

均值 sample

mean 110

样本方

差 sample

variance 110, 111

饱和

saturate 61

标量

scalar 27

704 术语

得分 score

437–440, 526, 527

得

分匹配

score matching 437, 438,

445, 526–530, 606

二阶

导数

second derivative 77–80

二阶导

数测试

second derivative test 80

第二

层 second layer 145

二阶方法

second-order method 245

自对比估计

self-contrastive

estimation 531

自信息 self-information

66

语义

哈希 semantic hashing

448

半受限

玻尔兹曼机

semi-restricted Boltzmann Machine

539

半监督 semi-supervised 363,

415

半监

督学习 semi-supervised learning

209, 210, 231, 450,

452, 454, 462, 463,

473

可分

离的 separable 309,

449, 453

分离的

separate 473

分离 separation 487, 488,

495

情景 setting 458,

459, 469, 471

浅

度回路

shadow circuit 472

香农

熵

Shannon entropy xxvi, 66,

67

香农 shannons 66

塑造

shaping 279, 560, 611

短列表 shortlist 396, 397

sigmoid sigmoid 157–162, 168,

169, 195, 278, 362,

425, 511

sigmoid 信念

网络

sigmoid Belief Network 591,

592

简单细

胞 simple cell

311

奇异的 singular 34

奇

异值 singular value 39,

40

奇异值

分解 singular value

decomposition 39–41, 130, 408

奇异向

量 singular vector 39

跳跃连接

skip connection 340, 341,

347, 348

慢特征分析

slow feature

analysis 421–423, 474

术语

705

慢性原

则 slowness principle

421–423

平滑 smoothing 394

平滑

先验 smoothness prior 136

softmax softmax 449

softmax

函数 softmax function 72,

73, 209, 226, 227,

325, 328, 372, 375,

383

softmax 单

元 softmax

unit 375

softplus softplus

170

softplus 函数 softplus

function 61–63, 158, 170

生成

子空间 span 33

稀疏

sparse

203, 204, 218–220, 227,

431–434, 440

稀疏激活 sparse

activation 195

稀

疏编码 sparse

coding 274, 423–426, 432,

440, 447, 451, 490,

492, 496, 501, 527,

538, 543, 544,

551,

558, 582, 583, 591

稀疏

连接 sparse connectivity 285–287

稀疏初

始化 sparse initialization 259

稀疏交

互 sparse interactions 285

稀疏权重

sparse weights 285

谱半径

spectral radius 345–347

语音

识别

Speech Recognition 362, 377,

381, 390–392, 457

sphering

sphering 388

尖峰和

平板 spike

and slab 317, 425,

426

尖峰和

平板 RBM spike

and slab RBM 580–583

虚假模

态 spurious modes 520,

522

方阵 square 34

标准

差 standard deviation 54,

112, 238, 272, 273,

386–389

标准差 standard error

57, 111, 112, 238

标

准正态分布

standard normal distribution 57

声明 statement 47, 48

平稳的

stationary 333

平稳分布 Stationary

Distribution 508–510, 512

706

术

语

驻点 stationary point

74, 84

统计

效率 statistic

efficiency 118

统计学

习理论 statistical

learning theory 97

统计

量

statistics 108

最陡下降

steepest descent

247

随机 stochastic 238,

239

随机课

程 stochastic curriculum

280

随机梯度

上升 Stochastic Gradient

Ascent 541

随机梯

度下降 stochastic

gradient descent 14, 87,

132, 133, 205, 206,

216, 222, 228, 238–242,

246, 251–254, 256, 258,

270, 277, 344, 353,

354, 356, 362, 380,

437, 506, 518, 574,

575,

589, 606

随机

矩阵

Stochastic Matrix 508

随机最

大似然

stochastic maximum likelihood 521–524,

526, 528, 529, 564,

565, 568, 571–574,

576

流 stream 240

步

幅

stride 287, 291, 293,

294, 297, 298, 301,

302, 306

结构学习

structure learning

496, 498

结构化概率

模型 structured

probabilistic model 47, 69,

70, 472, 475, 477,

479–482, 495, 498, 559

结构化

变分推断 structured variational inference

544

亚

原子 subatomic 48

子采样

subsample 502

求和法则 sum

rule 52

和

-积网络 sum-product

network 472

监督

supervised 92,

210, 211, 218, 231,

236, 310, 311, 317,

379, 425, 440, 449–453,

455, 557, 584

监督学习

supervised learning xxvii, 87,

92–94, 101, 107, 116,

122, 123, 125, 126,

134, 140, 144,

210,

232, 236, 342, 362,

397, 407, 409, 410,

415, 432, 449, 450,

452, 453, 455–458, 462,

463, 472, 529, 594

监

督学习算法

supervised learning algorithm 92

监督模型 supervised model 453

监

督预训练 supervised pretraining 456

支

持向量 support vector 124,

466

术语

707

代理损失函

数 surrogate

loss function 237, 248

符号 symbol 182

符号

表示

symbolic representation 182, 466,

468

对称 symmetric 36

切

面距离 tangent distance 232

切平

面 tangent plane 440,

443, 446

正切传播

tangent prop

232–234

目标 target 92–95,

101, 102, 105, 108,

116, 122, 128, 134,

135, 137, 138, 141

泰勒 taylor 79, 81,

203, 215, 242

导

师驱动过程

teacher

forcing 327, 328

温度

temperature 514

回火转

移 tempered

transition 514

回火 tempering

514

张量

tensor 28

测试误差

test error 97, 98,

101, 103, 241, 363,

365, 366, 371, 372,

375, 452, 454, 455

测

试集 test set 91,

95, 97, 98, 106,

107, 112, 235, 237,

252, 277, 363, 364,

366, 372, 375, 454

碰撞情

况 the collider case

489

绑定的权

重 tied weights

285

Tikhonov 正则 Tikhonov

regularization 199

平铺

卷积 tiled

convolution 300, 301, 303,

305

时延神

经网络 time delay

neural network 314, 319,

391

时间

步 time step

168, 247, 248, 265,

319–335, 339–341, 343, 346,

348–350, 352–354, 357, 392,

404, 405, 423, 577,

585, 605, 609, 610

Toeplitz 矩阵 Toeplitz matrix

284

标记

token 392, 393,

411

容差 tolerance 85,

549

地质 ICA topographic

ICA 421

训

练误差 training

error 97, 98, 100–103,

236, 241, 364–366, 372,

375, 454

训练

集 training

set 97, 98, 235–241,

243, 249, 251, 252,

254, 256, 260, 262–265,

267, 269, 274,

277,

280, 360, 362–364, 366,

367, 372, 373, 375,

462, 464, 468

708

术语

转录

transcribe 89, 91,

94

转录系统 transcription system

359, 361, 372, 374,

375

迁

移学习 transfer learning

454, 456–461, 604

转移

transition

322

转置 transpose 29

三角不

等式 triangle inequality 34

三角形

化 triangulate 493

三角形化

图

triangulated graph 493

三元语法

trigram

393

无偏 unbiased 109,

240, 241, 251, 503–505,

528

无偏样

本方差 unbiased sample

variance 111

欠完

备 undercomplete

430, 431

欠定的 underdetermined

552

欠

估计 underestimation 506

欠拟合

underfitting 98, 99, 105,

114, 197–199, 241, 295,

359, 365, 366, 372,

373, 375, 598, 613

欠拟合机制

underfitting regime 101

下溢

underflow 72, 73

潜在

underlying 236, 237, 462–466,

470–474

潜

在成因 underlying cause

461, 463, 473

无向

undirected

69

无向模型 undirected Model

482–488, 490–493, 495, 500,

502, 510, 515–518, 538,

557, 564, 565,

591

展

开图 unfolded graph 322,

323, 326, 392

展开

unfolding 320–322, 340, 392

均

匀分布 uniform distribution 51,

52, 55, 67, 165,

456

一元

语法 unigram 393,

400

单峰值

unimodal 514, 556

单元 unit 146

单位范

数

unit norm 36, 43

单位向量

unit vector 36

术语

709

万能近

似定理 universal approximation

theorem 171, 172, 434

万能

近似器 universal approximator 60,

471, 472, 560

万能

函数近似器

universal

function approximator 151

未标注

unlabeled 450, 454, 455,

459, 461, 463, 472

未归

一化概率函

数 unnormalized probability function

483, 484, 486, 493

非共享卷

积 unshared convolution 299

无监督 unsupervised 20, 21,

92, 210, 218, 228,

363, 391, 415, 423,

425, 440, 447, 449–453,

455,

458, 459, 462,

463

无

监督学习 unsupervised learning

87, 92–94, 107, 128,

134, 207, 210, 211,

234, 236, 363, 391,

415, 432, 443, 450–455,

457, 458, 462–464, 529,

610

无

监督学习算

法 unsupervised learning

algorithm 92

无监督预

训练 unsupervised

pretraining 450, 452–457

有效

valid 284, 297, 298

验

证集 validation set 106,

237, 242, 259, 368–370,

455

梯度消

失与爆炸问

题 vanishing and

exploding gradient problem 247,

248, 259

梯度消失

vanishing gradient

248

Vapnik-Chervonenkis 维度 Vapnik-Chervonenkis

dimension 100, 467, 470

变量消

去 variable elimination 547

方差 variance 54, 56,

57, 111, 197–199, 202,

206, 220

方差

减小 variance

reduction 589, 590

变分自

编码器

variational auto-encoder 195, 431,

506, 558, 592, 594–597,

600, 606

变分

导数 variational

derivative 551

变分自

由能 variational

free energy 539

变分推

断

variational inference 497, 499,

526

去噪 denoise 128,

386

向量

vector 27

虚拟对抗样

本

virtual adversarial example 231

虚拟对抗

训练 virtual adversarial training

452

可见层

visible layer 5

V-结构 V-structure 489, 539

710 术语

醒

眠 wake

sleep 557, 565, 592

warp warp 380, 383

支持向量

机 support vector machine

123–125, 153, 310, 367,

522

无向图模

型 undirected graphical

model 516, 531

权重

weight 94

权重

衰减 weight

decay 104–106, 199–202, 205,

206, 209, 213, 215,

217, 218, 227, 228,

243, 258,

274, 364–367,

432, 454, 524, 544

权重比

例推断规则

weight scaling inference rule

226–229

权重空间对

称性 weight space

symmetry 243

条件概

率分布 conditional

probability distribution 534

白化

whitening

388

宽度 width 146

赢者通

吃 winner-take-all 161

正切传播

tangent

propagation 474

流形正切分

类器 manifold

tangent classifier 474

词嵌入

word

embedding 363, 395, 404,

406, 408, 454, 459

词义消歧 word-sense disambiguation 412

零

数据学习 zero-data learning 459,

461

零

次学习 zero-shot learning

459–461
