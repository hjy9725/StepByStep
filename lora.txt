1

{

}

}

{

LORA: LOW-RANK ADAPTATION

OF LARGE LANï¿¾GUAGE MODELS

åŠ³æ‹‰: ä½çº§çš„

é€‚åº” å…³äº å¤§

çš„

è¯­è¨€æ¨¡å‹

Edward Huâˆ— Yelong Shenâˆ—

Phillip Wallis Zeyuan Allen-Zhu

Yuanzhi Li Shean Wang

Lu Wang Weizhu Chen

èƒ¡æ²ˆç‹é™ˆ

Microsoft Corporation

å¾®

è½¯å…¬å¸

yuanzhil,

yuanzhil@andrew.cmu.edu

edwardhu, yeshe,

phwallis, zeyuana, 

swang,

luw, wzchen @microsoft.com

edwardhuï¼Œyesheï¼Œphwallisï¼Œzeyuanaï¼Œyuanzhilï¼Œswang

ï¼Œ

(Version

luwï¼Œwzchen

@microsoft.com

2)

yuanzhil@andrew.cmu.edu

(ç¬¬äºŒ

ç‰ˆ)

ABSTRACT

æ‘˜è¦

An important

paradigm of natural language

processing consists of large-scale

pre- training on general

domain data and adaptation

to particular tasks or

domains. As we pre-train

larger models, full fine-tuning,

which retrains all

model

parameters, becomes less feasible.

Using GPT-3 175B as

an example â€“

deploying

indepen- dent instances of

fine-tuned models, each with

175B

parameters, is prohibitively

expensive. We propose Low-Rank

Adaptation, or

LoRA, which

freezes the pre- trained

model weights and injects

trainable rank

decomposition matrices

into each layer of

the Transformer architecture, greatly

reducing the number of

trainable pa- rameters for

downstream tasks. Compared

to

GPT-3 175B fine-tuned with

Adam, LoRA can reduce

the number of trainable

parameters by 10,000 times

and the GPU memory

requirement by 3 times.

LoRA performs on-par or

better than fine- tuning

in model quality on

RoBERTa,

DeBERTa, GPT-2, and

GPT-3, despite hav- ing

fewer trainable parameters, a

higher training throughput, and,

unlike adapters, no additional

inference latency.

We also

provide an empirical investigation

into rank-deficiency in language

model adaptation, which sheds

light on the efficacy

of LoRA. We release

a

package that facilitates

the integration of LoRA

with PyTorch models and

provide our implementations and

model checkpoints for RoBERTa,

DeBERTa,

and GPT-2 at

https://github.com/microsoft/LoRA.

è‡ªç„¶

è¯­è¨€å¤„ç†çš„

ä¸€ä¸ªé‡è¦èŒƒ

ä¾‹åŒ…æ‹¬å¯¹ä¸€

èˆ¬é¢†åŸŸæ•°æ®

çš„å¤§è§„æ¨¡é¢„

è®­ç»ƒå’Œå¯¹ç‰¹

å®šä»»åŠ¡æˆ–é¢†

åŸŸçš„é€‚åº”ã€‚å½“

æˆ‘ä»¬é¢„è®­ç»ƒ

æ›´å¤§çš„æ¨¡å‹

æ—¶ï¼Œé‡æ–°è®­ç»ƒ

æ‰€æœ‰æ¨¡å‹å‚

æ•°çš„å®Œå…¨å¾®

è°ƒå˜å¾—ä¸å¤ª

å¯è¡Œã€‚ä»¥ GPT-3 175B

ä¸ºä¾‹

â€”â€”éƒ¨ç½²å¾®è°ƒæ¨¡

å‹çš„ç‹¬ç«‹

å®

ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹

éƒ½æœ‰ 175B å‚æ•°ï¼Œè¿™

æ˜¯éå¸¸æ˜‚è´µ

çš„ã€‚æˆ‘ä»¬æå‡º

äº†ä½ç§©è‡ªé€‚

åº”ï¼Œå³

LoRAï¼Œå®ƒå†»ç»“

äº†é¢„å…ˆè®­ç»ƒ

çš„æ¨¡å‹æƒé‡

ï¼Œå¹¶å°†å¯è®­ç»ƒ

çš„ç§©åˆ†è§£çŸ©

é˜µæ³¨

å…¥åˆ°å˜

æ¢å™¨æ¶æ„çš„

æ¯ä¸€å±‚ä¸­ï¼Œä»

è€Œå¤§å¤§å‡å°‘

äº†ç”¨äºä¸‹æ¸¸

ä»»åŠ¡çš„å¯è®­

ç»ƒå‚æ•°

2

ğµ

= 0

Pretrained Weights

ğ‘Š âˆˆ â„ğ‘‘Ã—ğ‘‘

ğµ

= 0

Pretrained Weights

ğ‘Š âˆˆ â„ğ‘‘Ã—ğ‘‘

ğ´

= ğ’©(0, ğœ2)

ğ‘‘

x

ğ´ = ğ’©(0,

ğœ2)

ğ‘‘

x

çš„æ•°

é‡ã€‚ä¸ä½¿ç”¨

Adam å¾®

è°ƒçš„ GPT-3 175B

ç›¸æ¯”ï¼ŒLoRA å¯

ä»¥å°†å¯è®­ç»ƒ

å‚æ•°çš„

æ•°é‡

å‡å°‘ 10ï¼Œ000

å€ï¼Œå¹¶å°†

GPU å†…å­˜è¦æ±‚å‡

å°‘ 3 å€ã€‚LoRA

åœ¨ç½—ä¼¯

å¡”ã€å¾·ä¼¯

å¡”ã€GPT-2 å’Œ

GPT-3 ä¸Šçš„æ¨¡å‹è´¨

é‡è¡¨ç°ç›¸å½“

äºæˆ–ä¼˜äºå¾®

è°ƒï¼Œå°½ç®¡å…·æœ‰

æ›´å°‘

çš„å¯è®­

ç»ƒå‚æ•°ã€æ›´é«˜

çš„è®­ç»ƒåå

é‡ï¼Œå¹¶ä¸”ä¸é€‚

é…å™¨ä¸åŒï¼Œæ²¡

æœ‰é¢å¤–çš„æ¨

ç†

å»¶è¿Ÿã€‚æˆ‘ä»¬

è¿˜æä¾›äº†ä¸€

ä¸ªå…³äºè¯­è¨€

æ¨¡å‹é€‚åº”ä¸­

ç§©äºçš„å®è¯

ç ”ç©¶ï¼Œå®ƒæ­ç¤º

äº†

LoRA çš„æœ‰æ•ˆæ€§

ã€‚æˆ‘ä»¬å‘å¸ƒäº†

ä¸€ä¸ªæœ‰åŠ©äº

é›†æˆ

LoRA å’Œ PyTorch æ¨¡å‹

çš„åŒ…ï¼Œ

å¹¶åœ¨ https://github.com/microsoft/LoRAã€‚

1 INTRODUCTION

2 ä»‹

ç»

Many applications

in natural language processing

rely on adapt-

è‡ªç„¶è¯­è¨€

å¤„ç†ä¸­çš„è®¸

å¤šåº”ç”¨ä¾èµ–

äº

adaptï¿¾ing one large-scale, pre-trained

language model to multiple

down- h

å°†ä¸€ä¸ªå¤§

è§„æ¨¡çš„ã€é¢„å…ˆ

è®­ç»ƒå¥½çš„è¯­

è¨€æ¨¡å‹æ‰©å±•

åˆ°å¤šä¸ª h

stream applications. Such adaptation

is usually done via

fineï¿¾tuning, which updates all

the parameters of the

pre-trained model.

The ma-

jor downside of fine-tuning

is that the new

model contains

as many

æµåº”

ç”¨ç¨‹åºã€‚è¿™ç§

é€‚åº”é€šå¸¸é€š

è¿‡å¾®è°ƒæ¥å®Œ

æˆï¼Œå¾®è°ƒæ›´æ–°

é¢„è®­ç»ƒ

æ¨¡å‹

çš„æ‰€æœ‰å‚æ•°

ã€‚å¾®è°ƒçš„ä¸»è¦

ç¼ºç‚¹æ˜¯æ–°æ¨¡

å‹åŒ…å«å°½å¯

èƒ½å¤šçš„

parameters as

in the original model.

As larger models are

trained ğ‘Ÿ

åŸå§‹

æ¨¡å‹ä¸­çš„å‚

æ•°ã€‚éšç€æ›´å¤§

çš„æ¨¡å‹è¢«è®­

ç»ƒ ğ‘Ÿ

every few months, this

changes from a mere

â€œinconvenienceâ€ for

GPT-2 (Radford

et al., b) or

RoBERTa large (Liu et

al., 2019) to a

critical deployment challenge for

GPT-3 (Brown et al.,

2020) with

175 billion

trainable parameters.1

æ¯éš”å‡ ä¸ª

æœˆï¼Œè¿™å¯¹ GPT-2

å·æ¥

è¯´ä»…ä»…æ˜¯â€œä¸

æ–¹ä¾¿â€(Radford

et al.,b)æˆ–è€…ç½—

ä¼¯å¡”Â·æ‹‰å¥‡(Liu et

al.,2019)GPT 3 å·

çš„å…³

é”®éƒ¨ç½²

æŒ‘æˆ˜(Brown

et al.,2020)æœ‰ 1750 äº¿ä¸ª

å¯è®­ç»ƒå‚æ•°

ã€‚1

Many sought to mitigate

this by adapting only

some parameters or

learning

external modules for new

tasks. This way, we

only need

to store

and load a small

number of task-specific parameters

in adï¿¾dition to the

pre-trained model for each

task, greatly boosting the

operational efficiency when deployed.

However, existing techniques

è®¸å¤šäººè¯•å›¾

é€šè¿‡è°ƒæ•´ä¸€

äº›å‚æ•°æˆ–å­¦

ä¹ æ–°ä»»åŠ¡çš„

å¤–éƒ¨æ¨¡å—æ¥

ç¼“è§£

è¿™ä¸€é—®

é¢˜ã€‚è¿™æ ·ï¼Œé™¤äº†

æ¯ä¸ªä»»åŠ¡çš„

é¢„è®­ç»ƒæ¨¡å‹

ä¹‹å¤–ï¼Œæˆ‘ä»¬åª

éœ€

è¦å­˜å‚¨å’Œ

åŠ è½½å°‘é‡ç‰¹

å®šäºä»»åŠ¡çš„

å‚æ•°ï¼Œå¤§å¤§æ

é«˜äº†éƒ¨ç½²æ—¶

çš„æ“

ä½œæ•ˆç‡

ã€‚ç„¶è€Œï¼Œç°æœ‰çš„

æŠ€æœ¯

âˆ—Equal

contribution.

*åŒç­‰è´¡

çŒ®ã€‚

3

Figure

1: Our reparametriza- tion.

We only train A

and B.

å›¾ 1:æˆ‘ä»¬çš„

é‡æ–°å‚æ•°åŒ–

ã€‚æˆ‘

ä»¬åªè®­ç»ƒ

A å’Œ bã€‚

0Compared

to V1, this draft

includes better baselines, experiments

on GLUE, and more

on adapter latency.

0

ä¸ V1 ç›¸æ¯”ï¼Œè¯¥

è‰æ¡ˆåŒ…æ‹¬æ›´

å¥½çš„åŸºçº¿ã€èƒ¶

æ°´å®éªŒå’Œæ›´

å¤šå…³äºé€‚é…

å™¨å»¶è¿Ÿçš„å†…

å®¹ã€‚

1While

GPT-3 175B achieves non-trivial

performance with few-shot learning,

fine-tuning boosts its perforï¿¾mance

significantly as shown in

Appendix A.

1 è™½ç„¶

GPT-3 175B é€šè¿‡

å°‘é‡å­¦ä¹ å®

ç°äº†éåŒå¯»

å¸¸çš„æ€§èƒ½ï¼Œä½†

å¾®è°ƒæ˜¾è‘—æ

å‡äº†å…¶æ€§èƒ½

ï¼Œå¦‚æ‰€ç¤º Appendix

A.

a

r

X

i

v:2

1

0

6.0

9

6

8

5

v

2 [c

s.C

L] 1

6

O

c

t

a

r

X

i

v:2

1

0

6.0

9

6

8

5

v

2

[

c

s.C

L

]

1

6

often introduce inference latency

(Houlsby et al., 2019;

Rebuffi et al., 2017)

by extending model

depth

or reduce the modelâ€™s

usable sequence length (Li

& Liang, 2021; Lester

et al., 2021; Hamï¿¾bardzumyan

et al., 2020; Liu

et al., 2021) (Section

3). More importantly, these

method often fail to

match the fine-tuning baselines,

posing a trade-off between

efficiency and model quality.

é€šå¸¸

ä¼šå¼•å…¥æ¨ç†

å»¶è¿Ÿ(Houlsby et al.,2019;Rebuffi et

al.,2017)é€šè¿‡æ‰©

å±•æ¨¡å‹æ·±åº¦

æˆ–å‡

å°‘ æ¨¡ å‹

çš„

å¯ ç”¨ åº åˆ—

é•¿

åº¦ (Li & Liang,2021;Lester

et al.,2021;Ham-bardzumyan et

al.,2020;Liu

et al.,2021)(Section3).æ›´é‡è¦

çš„æ˜¯ï¼Œè¿™äº›æ–¹

æ³•ç»å¸¸æ— æ³•

åŒ¹é…å¾®è°ƒåŸº

çº¿ï¼Œ

ä»è€Œåœ¨æ•ˆ

ç‡å’Œæ¨¡å‹è´¨

é‡ä¹‹é—´è¿›è¡Œ

æƒè¡¡ã€‚

We

take inspiration from Li

et al. (2018a); Aghajanyan

et al. (2020) which

show that the learned

over-parametrized models in fact

reside on a low

intrinsic dimension. We hypothesize

that the

change in

weights during model adaptation

also has a low

â€œintrinsic rankâ€, leading to

our proposed

Low-Rank Adaptation

(LoRA) approach. LoRA allows

us to train some

dense layers in a

neural

network indirectly by

optimizing rank decomposition matrices

of the dense layersâ€™

change during

adaptation instead,

while keeping the pre-trained

weights frozen, as shown

in Figure 1. Using

GPT-3 175B as an

example, we show that

a very low rank

(i.e., r in Figure

1 can be one

or two)

suffices even

when the full rank

(i.e., d) is as

high as 12,288, making

LoRA both storage- and

compute-efficient.

æˆ‘ä»¬çš„

çµæ„Ÿæ¥è‡ªäº

Li et al.(2018a);Aghajanyan

et al.(2020)è¿™è¡¨æ˜æ‰€å­¦

ä¹ çš„è¿‡å‚æ•°

åŒ–

æ¨¡å‹å®é™…

ä¸Šä½äºä½å›º

æœ‰ç»´åº¦ä¸Šã€‚æˆ‘

ä»¬å‡è®¾åœ¨æ¨¡

å‹é€‚åº”è¿‡ç¨‹

ä¸­æƒé‡çš„å˜

åŒ–ä¹Ÿæœ‰ä¸€ä¸ª

ä½çš„â€œå›º

æœ‰ç§©

â€ï¼Œå¯¼è‡´æˆ‘ä»¬æ

å‡ºçš„ä½ç§©é€‚

åº”(LoRA)æ–¹æ³•ã€‚LoRA

å…è®¸

æˆ‘ä»¬é€šè¿‡ä¼˜

åŒ–è‡ªé€‚åº”æœŸ

é—´å¯†é›†å±‚

å˜

åŒ–çš„ç§©åˆ†è§£

çŸ©é˜µæ¥é—´æ¥

è®­ç»ƒç¥ç»ç½‘

ç»œä¸­çš„ä¸€äº›

å¯†é›†å±‚ï¼ŒåŒæ—¶

ä¿æŒé¢„è®­ç»ƒ

æƒé‡ä¸å˜ï¼Œå¦‚

æ‰€

ç¤º Figure

1.ä½¿ç”¨ GPT-3 175B ä½œ

ä¸ºä¾‹å­ï¼Œæˆ‘ä»¬

è¡¨æ˜éå¸¸ä½

çš„ç§©(å³ï¼Œr

inFigure 1 å¯ä»¥

æ˜¯ä¸€ä¸ª

æˆ–ä¸¤

ä¸ª)å°±è¶³å¤Ÿäº†

ï¼Œå³ä½¿æ»¡ç§©(å³

d)é«˜è¾¾

12ï¼Œ288ï¼Œä½¿å¾— LoRA åœ¨

å­˜å‚¨å’Œè®¡ç®—

ä¸Šéƒ½æ˜¯é«˜æ•ˆ

çš„ã€‚

LoRA

possesses several key advantages.

LoRA æ‹¥æœ‰å‡ ä¸ª

å…³é”®ä¼˜åŠ¿ã€‚

â€¢ A

pre-trained model can be

shared and used to

build many small LoRA

modules for difï¿¾ferent tasks.

We can freeze the

shared model and efficiently

switch tasks by replacing

the

matrices A and

B in Figure 1,

reducing the storage requirement

and task-switching overï¿¾head significantly.

â€¢ ä¸€

ä¸ªé¢„å…ˆè®­ç»ƒ

å¥½çš„æ¨¡å‹å¯

ä»¥è¢«å…±äº«å¹¶

ç”¨äºä¸ºä¸åŒ

çš„ä»»åŠ¡å»ºç«‹

è®¸å¤šå°çš„ LoRA æ¨¡

å—ã€‚

æˆ‘ä»¬å¯ä»¥

å†»ç»“å…±äº«æ¨¡

å‹ï¼Œå¹¶é€šè¿‡æ›¿

æ¢ä¸­çš„çŸ©é˜µ

A å’Œ B æ¥æœ‰æ•ˆåœ°

åˆ‡æ¢ä»»åŠ¡

Figure 1,

æ˜¾

è‘—é™ä½äº†å­˜

å‚¨éœ€æ±‚å’Œä»»

åŠ¡åˆ‡æ¢å¼€é”€

ã€‚

â€¢

LoRA makes training more

efficient and lowers the

hardware barrier to entry

by up to 3

times when using adaptive

optimizers since we do

not need to calculate

the gradients or

maintain

the optimizer states for

most parameters. Instead, we

only optimize the injected,

much smaller low-rank matrices.

â€¢ å½“ä½¿ç”¨è‡ªé€‚

åº”ä¼˜åŒ–å™¨æ—¶

ï¼ŒLoRA ä½¿è®­ç»ƒæ›´æœ‰

æ•ˆï¼Œå¹¶é™ä½è¿›

å…¥çš„ç¡¬ä»¶éšœ

ç¢è¾¾ 3

å€ï¼Œå› 

ä¸º

æˆ‘ä»¬ä¸éœ€è¦

è®¡ç®—æ¢¯åº¦æˆ–

ç»´æŠ¤å¤§å¤šæ•°

å‚æ•°çš„ä¼˜åŒ–

å™¨çŠ¶æ€ã€‚ç›¸å

ï¼Œæˆ‘ä»¬åªä¼˜åŒ–

æ³¨å…¥

çš„ã€å°å¾—

å¤šçš„ä½ç§©çŸ©

é˜µã€‚

â€¢

Our simple linear design

allows us to merge

the trainable matrices with

the frozen

weights when

deployed, introducing no inference

latency compared to a

fully fine-tuned

model, by

construction.

â€¢ æˆ‘ä»¬ç®€å•

çš„çº¿æ€§è®¾è®¡

å…è®¸æˆ‘ä»¬åœ¨

éƒ¨ç½²æ—¶å°†å¯

è®­ç»ƒçŸ©é˜µä¸

å†»ç»“çš„æƒé‡

åˆå¹¶ï¼Œä¸å®Œå…¨

å¾®

è°ƒçš„æ¨¡å‹

ç›¸æ¯”ï¼Œé€šè¿‡æ„

é€ ä¸ä¼šå¼•å…¥

æ¨ç†å»¶è¿Ÿã€‚

â€¢ LoRA is orthogonal

to many prior methods

and can be combined

with many of them,

such as prefix-tuning. We

provide an example in

Appendix E.

â€¢ LoRA

ä¸

è®¸å¤šç°æœ‰æ–¹

æ³•æ­£äº¤ï¼Œå¹¶ä¸”

å¯ä»¥ä¸å…¶ä¸­

çš„è®¸å¤šæ–¹æ³•

ç›¸ç»“åˆï¼Œä¾‹å¦‚

å‰ç¼€è°ƒæ•´ã€‚

æˆ‘

ä»¬åœ¨ä¸­æä¾›

äº†ä¸€ä¸ªç¤ºä¾‹

Appendix E.

4

|

|

Z {

}

|

|

Z

{ }

5

Terminologies

and Conventions We make

frequent references to the

Transformer architecture

and use

the conventional terminologies for

its dimensions. We call

the input and output

diï¿¾mension size of a

Transformer layer dmodel. We

use Wq, Wk, Wv,

and Wo to refer

to the

query/key/value/output projection

matrices in the self-attention

module. W or W0

refers to a preï¿¾trained

weight matrix and âˆ†W

its accumulated gradient update

during adaptation. We use

r to

denote the

rank of a LoRA

module. We follow the

conventions set out by

(Vaswani et al., 2017;

Brown et al., 2020)

and use Adam (Loshchilov

& Hutter, 2019; Kingma

& Ba, 2017) for

model

æœ¯è¯­å’Œçº¦å®š

æˆ‘ä»¬ç»å¸¸æ

åˆ°å˜å‹å™¨æ¶

æ„ï¼Œå¹¶ä½¿ç”¨å…¶

ç»´åº¦çš„å¸¸è§„

æœ¯è¯­ã€‚æˆ‘ä»¬ç§°

å˜å‹å™¨å±‚çš„

è¾“å…¥

å’Œè¾“å‡º

ç»´åº¦å¤§å°ä¸º

dmodelã€‚æˆ‘ä»¬ä½¿ç”¨ Wqã€Wkã€Wv

å’Œ

Wo æ¥æŒ‡ä»£è‡ªæˆ‘

å…³æ³¨æ¨¡å—ä¸­

çš„æŸ¥

è¯¢/é”®/å€¼

/è¾“å‡ºæŠ•å½±çŸ©

é˜µã€‚W æˆ–

W0 æ˜¯æŒ‡é¢„

è®­ç»ƒçš„æƒé‡

çŸ©é˜µï¼ŒW æ˜¯æŒ‡è‡ª

é€‚åº”è¿‡ç¨‹ä¸­

ç´¯ç§¯çš„æ¢¯åº¦

æ›´æ–°ã€‚æˆ‘ä»¬ç”¨

r æ¥è¡¨ç¤º

LoRA æ¨¡å—

çš„ç§©ã€‚æˆ‘ä»¬éµ

å¾ªç”±(Vaswani et al.,2017;Brown

et

al.,2020)åˆ©ç”¨äºš

å½“(Loshchilov & Hutter,2019;Kingma

& Ba,2017)å¯¹äºæ¨¡å‹

optimization and use

a Transformer MLP feedforward

dimension dffn = 4

Ã— dmodel.

ä¼˜åŒ–å¹¶ä½¿ç”¨

ä¸€ä¸ªå˜å‹å™¨

MLP å‰é¦ˆç»´æ•°

dffn = 4 Ã—

dmodelã€‚

3 PROBLEM STATEMENT

4 é—®

é¢˜é™ˆè¿°

While our

proposal is agnostic to

training objective, we focus

on language modeling as

our

motivat- ing use

case. Below is a

brief description of the

language modeling problem and,

in

particular, the maximization

of conditional probabilities given

a task-specific prompt.

è™½ç„¶

æˆ‘ä»¬çš„å»ºè®®

ä¸åŸ¹è®­ç›®æ ‡

æ— å…³ï¼Œä½†æ˜¯æˆ‘

ä»¬å…³æ³¨è¯­è¨€

å»ºæ¨¡ä½œä¸ºæˆ‘

ä»¬çš„æ¿€åŠ±ç”¨

ä¾‹ã€‚ä¸‹é¢æ˜¯å¯¹

è¯­è¨€å»ºæ¨¡é—®

é¢˜çš„ç®€è¦æ

è¿°ï¼Œç‰¹åˆ«æ˜¯ç»™

å®šç‰¹å®šä»»åŠ¡

æç¤ºçš„æ¡ä»¶

æ¦‚ç‡çš„æœ€å¤§

åŒ–ã€‚

Suppose we are given

a pre-trained autoregressive language

model 

For

et

al.,

instance,

2020) based

on the Transformer architecture

(

PÎ¦(y x) can

be a generic multi-task

learner

Vaswani et al.,

such as GPT

2017).

PÎ¦(

(Radford

y x

Consider adapting this

)

parametrized by Î¦.

et

al., b; Brown

pre-trained

model to downstream conditional

text generation tasks, such

as summarization,

machine reading

comprehension (MRC), and natural

language to SQL (NL2SQL).

Each

downstream task is

represented by a training

dataset of context-target pairs:=

(xi, yi) i=1,..,N ,

where both xi and

yi are sequences of

tokens. For example, in

NL2SQL, xi is a

natural language

query and

yi its corresponding SQL

command; for summarization, xi

is the content of

an article

and yi

its summary.

å‡è®¾ç»™æˆ‘

ä»¬ä¸€ä¸ªç”¨ Ï†

å‚

æ•°åŒ–çš„é¢„è®­

ç»ƒè‡ªå›å½’è¯­

è¨€æ¨¡å‹ pÏ†(y x)ã€‚ä¾‹å¦‚

ï¼ŒpÏ†(y x)å¯ä»¥æ˜¯ä¸€

ä¸ª

é€šç”¨çš„å¤šä»»

åŠ¡

(Vaswani et al.,

å­¦ä¹ è€…

2017).

ï¼Œ

è€ƒ

è™‘

å¦‚ GPT

å°† è¿™

ç§

é¢„ å…ˆ è®­ ç»ƒ

çš„

æ¨¡ å‹ åº” ç”¨

äº

ä¸‹ æ¸¸ çš„

(Radford

et al.,b;Brownet al.,2020)åŸº

æ¡

ä»¶

æ–‡ æœ¬ ç”Ÿ

äº

å˜å‹å™¨æ¶æ„

æˆ

ä»» åŠ¡ ï¼Œ å¦‚

æ‘˜

è¦ ã€ æœº å™¨

é˜… è¯»

ç† è§£ (

M R C )

å’Œ è‡ª ç„¶

è¯­ è¨€

è½¬ S Q L

( N L 2

S Q L )

ã€‚ æ¯ ä¸ª

ä¸‹

æ¸¸

ä»» åŠ¡ ç”±

ä¸Š ä¸‹

æ–‡ - ç›® æ ‡

å¯¹

çš„ è®­ ç»ƒ æ•°

æ®

é›† æ¥ è¡¨ ç¤º

:

= ( x i

ï¼Œ æ˜“ ) i

= 1 ï¼Œ .

. ï¼Œ N ï¼Œ

å…¶

ä¸­ å’Œ y

i éƒ½

æ˜¯ è®° å·

åº åˆ—

ã€‚ æ¯” å¦‚

åœ¨ N L 2

S Q L ä¸­

ï¼Œ æ˜¯

è‡ª ç„¶ è¯­

è¨€ æŸ¥

è¯¢ ï¼Œ y

i æ˜¯ å…¶ å¯¹

åº”

çš„ S Q L

å‘½ ä»¤ ï¼› æ¦‚

æ‹¬

åœ° è¯´ ï¼Œ æ˜¯

æ–‡ ç« 

çš„ å†… å®¹

ï¼Œ æ˜“ æ˜¯

æ–‡ ç« 

çš„ æ‘˜ è¦

ã€‚

6

X

X

During full

fine-tuning, the model is

initialized to pre-trained weights

Î¦0 and updated to

Î¦0 + âˆ†Î¦

åœ¨å®Œå…¨å¾®è°ƒ

æœŸé—´ï¼Œæ¨¡å‹è¢«

åˆå§‹åŒ–ä¸ºé¢„

è®­ç»ƒçš„æƒé‡

Ï†0ï¼Œå¹¶è¢«æ›´æ–°ä¸º

Ï†0+âˆÏ†

by repeatedly following the

gradient to maximize the

conditional language modeling objective:

é€šè¿‡é‡å¤éµ

å¾ªæ¢¯åº¦æ¥æœ€

å¤§åŒ–æ¡ä»¶è¯­

è¨€å»ºæ¨¡ç›®æ ‡

:

max

æœ€

å¤§

Î¦

Î¦

7

X

X

|y|

|y|

log

(PÎ¦(yt|x, y<t)) (1)

log(pÏ†(yt

| xï¼Œy<t)) (1)

8

| |

| |

|

| |

|

| |

X

X

(x,y)âˆˆZ t=1

(xï¼Œy)âˆˆZ t=1

One of the main

drawbacks for full fine-tuning

is that for each

downstream task, we learn

a

different 

large

(such as GPT-3 with

fine-tuned models can be

challenging, if at all

feasible.

set of parameters

âˆ†Î¦ whose dimension

Î¦0175

Billion), storing and deploying

many independent instances of

âˆ†Î¦ equals Î¦0 .

Thus, if the pre-trained

model is

å®Œå…¨å¾®

è°ƒçš„ä¸€ä¸ªä¸»

è¦ç¼ºç‚¹æ˜¯ï¼Œå¯¹

äºæ¯ä¸ªä¸‹æ¸¸

ä»»åŠ¡ï¼Œæˆ‘ä»¬å­¦

ä¹ ä¸€ç»„ä¸åŒ

çš„å‚æ•°âˆÏ†ï¼Œå…¶ç»´

æ•°

âˆ

çš„è®¸å¤šç‹¬

ç«‹å®ä¾‹å¯èƒ½

å…·æœ‰

Ï† ç­‰äº Ï†0ã€‚å› 

æ­¤ï¼Œå¦‚æœ

æŒ‘æˆ˜

é¢„è®­ç»ƒæ¨¡å‹

æ€§ï¼Œå¦‚æœå¯è¡Œ

çš„

å¾ˆå¤§(å¦‚ Ï†1750 äº¿

çš„

GPT-3)ï¼Œå­˜å‚¨å’Œéƒ¨

ç½²å¾®è°ƒæ¨¡å‹

è¯ã€‚

In this paper,

we adopt a more

parameter-efficient approach, where the

task-specific parameter

increment âˆ†Î¦

= âˆ†Î¦(Î˜) is further

encoded by a much

smaller-sized set of parameters

Î˜ with

åœ¨ æœ¬

æ–‡ ä¸­

ï¼Œ æˆ‘ ä»¬

é‡‡ ç”¨ äº†

ä¸€ ç§

å‚ æ•° æ•ˆ

ç‡ æ›´

é«˜ çš„ æ–¹

æ³• ï¼Œ

å…¶ ä¸­ ç‰¹ å®š

äº

ä»» åŠ¡ çš„ å‚

æ•°

å¢ é‡

âˆÏ†=âˆÏ†(Î¸)ç”±ä¸€

ç»„æ›´å°çš„å‚

æ•° Î¸

è¿›ä¸€æ­¥ç¼–

ç ï¼Œå…¶ä¸­

|Î˜||Î¦0|. The task

of finding âˆ†Î¦ thus

becomes optimizing over Î˜:

|Î˜||Î¦0|.å› æ­¤

ï¼Œå¯»æ‰¾âˆÏ† çš„ä»»åŠ¡

å˜æˆäº†å¯¹ Î¸ è¿›

è¡Œä¼˜åŒ–:

|y|

|y|

max

æœ€

å¤§

Î˜

Î˜

X

log

pÎ¦0 +âˆ†Î¦(Î˜)(yt|x, y<t) (2)

9

x log pÏ†0+âˆÏ†(Î¸)(yt

| xï¼Œy<t)

(2)

(x,y)âˆˆZ

t=1

(xï¼Œy)âˆˆZ t=1

In

the subsequent sections, we

propose to use a

low-rank representation to encode

âˆ†Î¦ that is both

compute- and memory-efficient. When

the pre-trained model is

GPT-3 175B, the number

of trainï¿¾able parameters |Î˜|

can be as small

as 0.01% of |Î¦0|.

åœ¨éšåçš„éƒ¨

åˆ†ä¸­ï¼Œæˆ‘ä»¬å»º

è®®ä½¿ç”¨ä½ç§©

è¡¨ç¤ºæ¥ç¼–ç 

âˆÏ†ï¼Œè¿™åœ¨è®¡ç®—å’Œ

å­˜å‚¨ä¸Šéƒ½æ˜¯

é«˜æ•ˆçš„ã€‚å½“

é¢„

è®­ç»ƒæ¨¡å‹æ˜¯

GPT-3 175B æ—¶ï¼Œå¯è®­ç»ƒå‚

æ•°|Î¸|çš„æ•°ç›®å¯

ä»¥å°åˆ°|Ï†0

|çš„ 0.01%ã€‚

5 ARENâ€™T

EXISTING SOLUTIONS GOOD ENOUGH?

6 ç°

æœ‰çš„è§£å†³æ–¹

æ¡ˆè¿˜ä¸å¤Ÿå¥½

å—ï¼Ÿ

The problem

we set out to

tackle is by no

means new. Since the

inception of transfer learning,

dozens of works have

sought to make model

adaptation more parameter- and

compute-efficient.

See Sec- tion

6 for a survey

of some of the

well-known works. Using language

modeling as an

example,

there are two prominent

strategies when it comes

to efficient adaptations: adding

adapter

layers (Houlsby et

al., 2019; Rebuffi et

al., 2017; Pfeiffer et

al., 2021; RuÂ¨ckleÂ´ et

al., 2020) or

optimizing

some forms of the

input layer activations (Li

& Liang, 2021; Lester

et al., 2021;

Hambardzumyan

et al., 2020; Liu

et al., 2021). However,

both strategies have their

limitations,

especially in a

large-scale and latency-sensitive production

scenario.

æˆ‘ä»¬ç€æ‰‹

è§£å†³çš„é—®é¢˜

ç»ä¸æ˜¯æ–°çš„

ã€‚è‡ªä»è¿ç§»å­¦

ä¹ å¼€å§‹ä»¥æ¥

ï¼Œè®¸å¤šå·¥ä½œéƒ½

è¯•å›¾ä½¿æ¨¡å‹

é€‚åº”åœ¨

å‚æ•°

å’Œè®¡ç®—æ–¹é¢

æ›´åŠ æœ‰æ•ˆã€‚çœ‹

è§ Sec-tion

6 å¯¹ä¸€äº›è‘—

åçš„ä½œå“è¿›

è¡Œè°ƒæŸ¥ã€‚ä»¥è¯­

è¨€å»ºæ¨¡ä¸ºä¾‹

ï¼Œ

å½“æ¶‰åŠåˆ°æœ‰

æ•ˆçš„é€‚åº”æ—¶

ï¼Œæœ‰ä¸¤ä¸ªçªå‡º

çš„ç­–ç•¥:æ·»åŠ 

é€‚é…å™¨å±‚(Houlsbyet al.,2019;Rebuffi

et

al.,2017;Pfeiffer et al.,2021;RuÂ¨ckleÂ´

et al.,2020)æˆ–

è€…ä¼˜åŒ–è¾“å…¥

å±‚æ¿€æ´»çš„æŸ

äº›å½¢å¼

(Li &

Liang,2021;Lester et al.,2021;Hambardzumyan et

al.,2020;Liu et al.,2021).

ç„¶

è€Œ

ï¼Œ è¿™ ä¸¤ ç§

ç­– ç•¥

éƒ½ æœ‰ å…¶

å±€ é™

æ€§ ï¼Œ å°¤

å…¶ æ˜¯ åœ¨

å¤§ è§„

æ¨¡ å’Œ å»¶

è¿Ÿ æ•

æ„Ÿ çš„ ç”Ÿ

äº§ åœº

æ™¯

ä¸­ ã€‚

Adapter

Layers Introduce Inference Latency

There are many variants

of adapters. We focus

on the original design

by Houlsby et al.

(2019) which has two

adapter layers per Transformer

block and a more

recent one by Lin

et al. (2020) which

has only one per

block but with an

additional LayerNorm (Ba et

al., 2016). While one

can reduce the overall

latency by pruning

layers

or exploit- ing multi-task

settings (RuÂ¨ckleÂ´ et al.,

2020; Pfeiffer et al.,

2021), there is no

direct ways to bypass

the extra compute in

adapter layers. This seems

like a non-issue since

adapter layers are designed

to have few parameters

(sometimes <1% of the

original model) by

having

a small bottleneck di-

mension, which limits the

FLOPs they can add.

However, large

neural networks

rely on hardware parallelism

to keep the latency

low, and adapter layers

have to

be processed

sequentially. This makes a

difference in the online

inference setting where the

batch

size is typically

as small as one.

In a generic scenario

without model parallelism, such

as running

inference on

GPT-2 (Radford et al.,

b) medium on a

single GPU, we see

a noticeable increase in

latency when using adapters,

even with a very

small bottleneck dimension (Table

1).

é€‚

é…å™¨å±‚å¼•å…¥

æ¨ç†å»¶è¿Ÿé€‚

é…å™¨æœ‰è®¸å¤š

å˜ä½“ã€‚æˆ‘ä»¬é€š

è¿‡ä»¥ä¸‹æ–¹å¼

å…³æ³¨åŸåˆ›è®¾

è®¡ Houlsby et

al.(2019)å…¶ä¸­æ¯ä¸ª

å˜å‹å™¨å—æœ‰

ä¸¤ä¸ªé€‚é…å™¨

å±‚ï¼Œæœ€è¿‘çš„ä¸€

ä¸ªç”± Lin et al.(2020)å…¶æ¯ä¸ª

å—åª

æœ‰ä¸€ä¸ª

ï¼Œä½†æ˜¯å…·æœ‰é™„

åŠ çš„å±‚å½¢å¼

(Ba et al.,2016).è™½ç„¶å¯ä»¥é€š

è¿‡åˆ å‡å±‚æˆ–

åˆ©ç”¨å¤šä»»åŠ¡

è®¾ç½®

æ¥å‡å°‘

æ•´ä½“å»¶è¿Ÿ(RuÂ¨ckleÂ´

et al.,2020;Pfeiffer et al.,2021),æ²¡

æœ‰ç›´æ¥çš„æ–¹

æ³•å¯ä»¥ç»•

è¿‡

é€‚é…å™¨å±‚ä¸­

çš„é¢å¤–è®¡ç®—

ã€‚è¿™ä¼¼ä¹ä¸æ˜¯

é—®é¢˜ï¼Œå› ä¸ºé€‚

é…å™¨å±‚è¢«è®¾

è®¡ä¸ºå…·æœ‰å¾ˆ

å°‘çš„å‚æ•°(æœ‰

æ—¶

å°äºåŸå§‹

æ¨¡å‹çš„ 1%)ï¼Œå…·æœ‰

å°çš„ç“¶é¢ˆå°º

å¯¸ï¼Œè¿™é™åˆ¶äº†

å®ƒä»¬å¯ä»¥æ·»

åŠ çš„ FLOPsã€‚ç„¶è€Œï¼Œå¤§

å‹ç¥ç»

ç½‘ç»œ

ä¾èµ–äºç¡¬ä»¶

å¹¶è¡Œæ€§æ¥ä¿

æŒä½å»¶è¿Ÿï¼Œå¹¶

ä¸”é€‚é…å™¨å±‚

å¿…é¡»é¡ºåºå¤„

ç†ã€‚è¿™åœ¨æ‰¹é‡

é€šå¸¸åªæœ‰ä¸€

ä¸ª

çš„åœ¨çº¿æ¨

æ–­è®¾ç½®ä¸­äº§

ç”Ÿäº†å·®å¼‚ã€‚åœ¨

æ²¡æœ‰æ¨¡å‹å¹¶

è¡Œæ€§é€šç”¨åœº

æ™¯ä¸­ï¼Œä¾‹å¦‚åœ¨

GPT-2 ä¸Šè¿è¡Œæ¨ç†

(Radford et

al.,b)ä¸­å‹åœ¨å•ä¸ª

GPU ä¸Šï¼Œæˆ‘ä»¬çœ‹åˆ°

ä½¿ç”¨é€‚é…å™¨

æ—¶å»¶è¿Ÿæ˜æ˜¾

å¢åŠ ï¼Œå³ä½¿ç“¶

é¢ˆ

éå¸¸å°(Table1).

This

problem gets worse when

we need to shard

the model as done

in Shoeybi et al.

(2020); Lepï¿¾ikhin et al.

(2020), because the additional

depth requires more synchronous

GPU operations such

as

AllReduce and Broadcast, unless

we store the adapter

parameters redundantly many

times.

å½“

æˆ‘ä»¬éœ€è¦åˆ†

å‰²æ¨¡å‹æ—¶ï¼Œè¿™

ä¸ªé—®é¢˜ä¼šå˜

å¾—æ›´ç³Ÿ Shoeybi et al.(2020);Lep-ikhin

et al.

(2020),å› ä¸º

é¢å¤–çš„æ·±åº¦

éœ€è¦æ›´å¤šçš„

åŒæ­¥ GPU

æ“ä½œæ¯”

å¦‚ AllReduce å’Œ Broadcastï¼Œé™¤éæˆ‘

ä»¬å¤šæ¬¡

å†—ä½™

å­˜å‚¨é€‚é…å™¨

å‚æ•°ã€‚

Directly Optimizing the

Prompt is Hard The

other direction, as exemplified

by prefix tuning

(Li

& Liang, 2021), faces

a different challenge. We

observe that prefix tuning

is difficult to

optimize

and that its performance

changes non-monotonically in trainable

parameters, confirming

similar observations

in the original paper.

More fundamentally, reserving a

part of the sequence

length for adaptation necessarily

reduces the sequence length

available to process a

downstream

task, which we

suspect makes tuning the

prompt less performant compared

to other methods. We

defer the study on

task performance to Section

5.

ç›´æ¥ä¼˜

åŒ–æç¤ºç¬¦æ˜¯

å¾ˆéš¾çš„å¦ä¸€

ä¸ªæ–¹å‘ï¼Œä¾‹å¦‚

å‰ç¼€è°ƒæ•´(Li& Liang,2021),é¢

ä¸´ç€ä¸åŒçš„

æŒ‘

æˆ˜ã€‚æˆ‘ä»¬è§‚

å¯Ÿåˆ°å‰ç¼€è°ƒ

æ•´å¾ˆéš¾ä¼˜åŒ–

ï¼Œå¹¶ä¸”å…¶æ€§èƒ½

åœ¨å¯è®­ç»ƒå‚

æ•°ä¸­éå•è°ƒ

å˜åŒ–ï¼Œè¿™è¯å®

äº†åŸ

å§‹è®ºæ–‡

ä¸­çš„ç±»ä¼¼è§‚

å¯Ÿã€‚æ›´é‡è¦çš„

æ˜¯ï¼Œä¿ç•™ä¸€éƒ¨

åˆ†åºåˆ—é•¿åº¦

ç”¨äºè‡ªé€‚åº”

å¿…ç„¶ä¼šå‡å°‘

å¯ç”¨äºå¤„

ç†

ä¸‹æ¸¸ä»»åŠ¡çš„

åºåˆ—é•¿åº¦ï¼Œæˆ‘

ä»¬æ€€ç–‘è¿™ä½¿

å¾—ä¸å…¶ä»–æ–¹

æ³•ç›¸æ¯”ï¼Œè°ƒæ•´

æç¤ºçš„æ€§èƒ½

æ›´å·®ã€‚æˆ‘ä»¬å°†

ä»»åŠ¡ç»©æ•ˆçš„

ç ”ç©¶æ¨è¿Ÿåˆ°

Section 5.

1

0

1

1

Batch

Size

Sequence Length

æ‰¹é‡åºåˆ—é•¿

åº¦

|Î˜|

|Î˜|

Fine-Tune/LoRA

å¾®è°ƒ/LoRA

AdapterL

AdapterH

é€‚é…

å™¨ l

é€‚é…å™¨

h

32 16

1

1

2

|

|

âˆˆ

âˆˆ âˆˆ

âˆˆ

âˆˆ âˆˆ

32

16

ä¸€

512 256

128

512 256

128

0.5M

11M

11M

0.5M 11

ç±³

11 ç±³

1449.4Â±0.8

338.0Â±0.6 19.8Â±2.7

1449.4 0.8

338.0 0.6 19.8 2.7

1482.0Â±1.0 (+2.2%) 354.8Â±0.5 (+5.0%)

23.9Â±2.1 (+20.7%)

1482.0 1.0

(+2.2%) 354.8 0.5 (+5.0%)

23.9 2.1 (+20.7%)

1492.2Â±1.0

(+3.0%) 366.3Â±0.5 (+8.4%) 25.8Â±2.2

(+30.3%)

1492.2 1.0 (+3.0%)

366.3 0.5 (+8.4%) 25.8

2.2 (+30.3%)

Table 1:

Infernece latency of a

single forward pass in

GPT-2 medium measured in

milliseconds,

av- eraged over

100 trials. We use

an NVIDIA Quadro RTX8000.

â€œ Î˜ â€ denotes

the number of

trainable

parameters in adapter layers.

AdapterL

 and AdapterH

are two variants of

adapter tuning,

which we

describe in Section 5.1.

The inference latency introduced

by adapter layers can

be

significant in an

online, short-sequence-length scenario. See

the full study in

Appendix B.

è¡¨ 1:GPT-2

ä»‹è´¨

ä¸­å•æ¬¡å‰å‘

ä¼ é€’çš„æ¨æ–­

å»¶è¿Ÿï¼Œä»¥æ¯«ç§’

è®¡ï¼Œå¹³å‡è¶…è¿‡

100 æ¬¡è¯•éªŒã€‚æˆ‘ä»¬

ç”¨çš„

æ˜¯

adapter

2

NVIDIA 

æ˜¯é€‚

é…å™¨è°ƒä¼˜çš„

Quadro

RTX8000ã€‚

ä¸¤

â€œ

ç§å˜

Î¸â€

ä½“

è¡¨

ç¤ºé€‚é…å™¨å±‚

ä¸­å¯è®­ç»ƒå‚

æ•°çš„æ•°é‡ã€‚

ï¼Œæˆ‘

ä»¬åœ¨

Section 5.1.åœ¨çŸ­åº

åˆ—é•¿åº¦

adapter 1

çš„åœ¨

çº¿åœºæ™¯

å’Œ

ä¸­

ï¼Œé€‚é…å™¨å±‚å¼•

å…¥çš„æ¨ç†å»¶

è¿Ÿå¯èƒ½å¾ˆå¤§

ã€‚è¯·å‚é˜…ä¸­çš„

å®Œæ•´ç ”ç©¶ Appendix

B.

7 OUR METHOD

8 æˆ‘

ä»¬çš„æ–¹æ³•

We describe

the simple design of

LoRA and its practical

benefits. The principles outlined

here

apply to any

dense layers in deep

learning models, though we

only focus on certain

weights in

Transformer language

models in our experiments

as the motivating use

case.

æˆ‘

ä»¬æè¿°äº† LoRA çš„

ç®€å•è®¾è®¡å’Œ

å®ƒçš„å®é™…å¥½

å¤„ã€‚è¿™é‡Œæ¦‚è¿°

çš„åŸåˆ™é€‚ç”¨

äºæ·±åº¦å­¦ä¹ 

æ¨¡å‹ä¸­çš„ä»»

ä½•å¯†é›†å±‚ï¼Œå°½

ç®¡æˆ‘ä»¬åœ¨å®

éªŒä¸­åªå…³æ³¨

Transformer

è¯­è¨€æ¨¡å‹ä¸­

çš„æŸäº›æƒé‡

ä½œä¸ºæ¿€åŠ±ç”¨

ä¾‹ã€‚

8.1 LOW-RANK-PARAMETRIZED UPDATE

MATRICES

8.2 ä½ç§©å‚æ•°

åŒ–æ›´æ–°çŸ©é˜µ

A neural

network contains many dense

layers which perform matrix

multiplication. The weight

matrices

in these layers typically

have full-rank. When adapting

to a specific task,

Aghajanyan et

al. (2020)

shows that the pre-trained

language models have a

low â€œinstrisic dimensionâ€ and

can

still learn efficiently

despite a random projection

to a smaller subspace.

Inspired by this, we

hypothe- size the updates

to the weights also

have a low â€œintrinsic

rankâ€ during adaptation. For

a

pre-trained weight matrix

W0 R

dÃ—k

,

we constrain its update

by representing the latter

with a lowï¿¾rank de-

composition W0 + âˆ†W

= W0 + BA,

where BR

dÃ—r

,

AR

rÃ—k

, and

the rank rmin(d, k).

During training, W0 is

frozen and does not

receive gradient updates, while

A and B contain

trainable parameters. Note both

W0 and âˆ†W =

BA are multiplied with

the same input, and

their

respective output vectors

are summed coordinate-wise. For

h = W0x, our

modified forward pass

yields:

ç¥ç»ç½‘ç»œåŒ…

å«è®¸å¤šæ‰§è¡Œ

çŸ©é˜µä¹˜æ³•çš„

å¯†é›†å±‚ã€‚è¿™äº›

å±‚ä¸­çš„æƒé‡

çŸ©é˜µé€šå¸¸å…·

æœ‰æ»¡ç§©ã€‚å½“é€‚

åº”ç‰¹

å®šçš„ä»»

åŠ¡æ—¶ï¼ŒAghajanyan et al.(2020)è¡¨æ˜é¢„

è®­ç»ƒçš„è¯­è¨€

æ¨¡å‹å…·æœ‰ä½

çš„â€œå›ºæœ‰ç»´æ•°

â€,å¹¶

ä¸”å°½ç®¡éš

æœºæŠ•å½±åˆ°æ›´

å°çš„å­ç©ºé—´

ï¼Œä»ç„¶å¯ä»¥æœ‰

æ•ˆåœ°å­¦ä¹ ã€‚å—

æ­¤å¯å‘ï¼Œæˆ‘ä»¬

å‡è®¾åœ¨é€‚åº”

è¿‡ç¨‹

ä¸­å¯¹æƒ

é‡çš„æ›´æ–°ä¹Ÿ

å…·æœ‰è¾ƒä½çš„

â€œå›ºæœ‰ç­‰çº§â€ã€‚å¯¹

äºé¢„è®­ç»ƒçš„

æƒé‡çŸ©é˜µ W0 RdÃ—kï¼Œæˆ‘

ä»¬é€šè¿‡

ç”¨ä½

ç§©åˆ†è§£ W0 + W

= W0 âˆ† +

BA è¡¨ç¤º

åè€…æ¥çº¦æŸ

å…¶æ›´æ–°ï¼Œå…¶ä¸­

BRdÃ—rï¼ŒARrÃ—kï¼Œç§©

rmin(dï¼Œk)ã€‚åœ¨è®­ç»ƒæœŸ

é—´ï¼ŒW0 è¢«å†»ç»“å¹¶

ä¸”ä¸æ¥æ”¶æ¢¯

åº¦æ›´æ–°ï¼Œè€Œ

A å’Œ

B åŒ…å«å¯è®­ç»ƒ

å‚æ•°ã€‚æ³¨

æ„ï¼ŒW0

å’Œ

W = BA éƒ½ä¸ç›¸åŒçš„

è¾“å…¥ç›¸ä¹˜ï¼Œå®ƒ

ä»¬å„è‡ªçš„è¾“

å‡ºçŸ¢é‡ä»¥å

æ ‡æ–¹å¼ç›¸åŠ 

ã€‚å¯¹äº

h =

W0xï¼Œæˆ‘ä»¬æ”¹

è¿›çš„æ­£å‘ä¼ 

é€’äº§ç”Ÿ:

h

= W0x + âˆ†Wx

= W0x + BAx

(3)

h = W0x+â‡¼Wx

= W0x+BAx (3)

1

3

r

r

We

illustrate our reparametrization in

Figure 1. We use

a random Gaussian initialization

for A and

zero

for B, so âˆ†W

= BA is zero

at the beginning of

training. We then scale

âˆ†Wx by Î±

,

where

Î± is a

constant in r. When

optimizing with Adam, tuning

Î± is roughly the

same as tuning the

learning rate if we

scale the initialization appropriately.

As a result, we

simply set Î± to

the first r

we

try and do not

tune it. This scaling

helps to reduce the

need to retune hyperparameters

when

we vary r

(Yang & Hu, 2021).

æˆ‘ä»¬

åœ¨ä¸­è¯´æ˜æˆ‘

ä»¬çš„é‡æ–°å‚

æ•°åŒ– Figure 1.æˆ‘ä»¬å¯¹

A ä½¿ç”¨éšæœºé«˜

æ–¯åˆå§‹åŒ–ï¼Œå¯¹

B

ä½¿ç”¨é›¶

åˆå§‹

åŒ–ï¼Œå› æ­¤åœ¨è®­

ç»ƒå¼€å§‹æ—¶ W =

BA ä¸º

é›¶ã€‚ç„¶åï¼Œæˆ‘ä»¬

ç”¨ Î± è°ƒæ•´

Wxï¼Œå…¶ä¸­

Î± æ˜¯ r

ä¸­çš„å¸¸æ•°

ï¼Œä½¿ç”¨

Adam ä¼˜åŒ–æ—¶

ï¼Œå¦‚æœæˆ‘ä»¬é€‚

å½“è°ƒæ•´åˆå§‹

åŒ–ï¼Œè°ƒæ•´ Î± ä¸è°ƒ

æ•´å­¦ä¹ é€Ÿç‡

å¤§è‡´ç›¸åŒã€‚å› 

æ­¤ï¼Œæˆ‘ä»¬ç®€å•

åœ°å°†

Î± è®¾ç½®ä¸º

æˆ‘ä»¬å°è¯•çš„

ç¬¬ä¸€ä¸ª rï¼Œå¹¶ä¸”

ä¸è°ƒæ•´å®ƒã€‚å½“

æˆ‘ä»¬æ”¹å˜ r

æ—¶

ï¼Œè¿™ç§ç¼©æ”¾æœ‰

åŠ©äºå‡å°‘é‡

æ–°è°ƒæ•´è¶…å‚

æ•°çš„éœ€è¦(Yang & Hu,2021).

A

Generalization of Full Fine-tuning.

A more general form

of fine-tuning allows the

training of

a subset

of the pre-trained parameters.

LoRA takes a step

further and does not

require the accumuï¿¾lated gradient

update to weight matrices

to have full-rank during

adaptation. This means that

when

applying LoRA to

all weight matrices and

training all biases2

,

we roughly recover the

expressiveï¿¾ness of full fine-tuning

by setting the LoRA

rank r to the

rank of the pre-trained

weight matrices.

In other

words, as we increase

the number of trainable

parameters 3

, training

LoRA roughly

converges to

training the original model,

while adapter-based methods converges

to an MLP and

prefix-based methods to a

model that cannot take

long input sequences.

å…¨

é¢å¾®è°ƒçš„æ¨

å¹¿ã€‚æ›´ä¸€èˆ¬å½¢

å¼çš„å¾®è°ƒå…

è®¸è®­ç»ƒé¢„è®­

ç»ƒå‚æ•°çš„å­

é›†ã€‚LoRA

æ›´è¿›äº†ä¸€

æ­¥ï¼Œåœ¨è‡ª

é€‚åº”

è¿‡ç¨‹ä¸­ï¼Œä¸éœ€

è¦å¯¹æƒé‡çŸ©

é˜µè¿›è¡Œç´¯ç§¯

æ¢¯åº¦æ›´æ–°æ¥

è·å¾—æ»¡ç§©ã€‚è¿™

æ„å‘³ç€å½“å°†

LoRA åº”ç”¨äº

æ‰€æœ‰

æƒé‡çŸ©é˜µå¹¶

è®­ç»ƒæ‰€æœ‰å

å·®æ—¶

2ï¼Œæˆ‘ä»¬é€š

è¿‡å°† LoRA ç§© r

è®¾ç½®

ä¸ºé¢„å…ˆè®­ç»ƒ

çš„æƒé‡çŸ©é˜µ

çš„

ç§©ï¼Œç²—ç•¥åœ°

æ¢å¤äº†å®Œå…¨

å¾®è°ƒçš„è¡¨ç°

åŠ›ã€‚æ¢å¥è¯è¯´

ï¼Œéšç€æˆ‘ä»¬å¢

åŠ å¯è®­ç»ƒå‚

æ•°çš„æ•°é‡ 3è®­

ç»ƒ

LoRA

å¤§è‡´æ”¶æ•›

äºè®­ç»ƒåŸå§‹

æ¨¡å‹ï¼Œè€ŒåŸºäº

é€‚é…å™¨çš„æ–¹

æ³•æ”¶æ•›äº MLPï¼ŒåŸº

äºå‰ç¼€çš„æ–¹

æ³•æ”¶æ•›äº

ä¸

èƒ½é‡‡ç”¨é•¿è¾“

å…¥åºåˆ—çš„æ¨¡

å‹ã€‚

No

Additional Inference Latency. When

deployed in production, we

can explicitly compute and

store W = W0

+ BA and perform

inference as usual. Note

that both W0 and

BA are in R

dÃ—k

.

When we

need to switch to

another downstream task, we

can recover W0 by

subtracting BA and

then

adding a different B

0A

0

, a

quick operation with very

little memory overhead. Critically,

this

æ²¡æœ‰é¢å¤–

çš„æ¨ç†å»¶è¿Ÿ

ã€‚åœ¨ç”Ÿäº§ä¸­éƒ¨

ç½²æ—¶ï¼Œæˆ‘ä»¬å¯

ä»¥æ˜¾å¼åœ°è®¡

ç®—å’Œå­˜å‚¨ W =

W0 + BAï¼Œå¹¶

ç…§

å¸¸æ‰§è¡Œæ¨

ç†ã€‚æ³¨æ„ï¼ŒW0

å’Œ BA éƒ½

åœ¨ RdÃ—k

ä¸­ï¼Œå½“æˆ‘ä»¬

éœ€è¦åˆ‡æ¢åˆ°

å¦ä¸€ä¸ªä¸‹æ¸¸

ä»»åŠ¡æ—¶ï¼Œæˆ‘ä»¬

å¯

ä»¥é€šè¿‡å‡

å» BAï¼Œç„¶ååŠ ä¸Š

ä¸åŒçš„ B0A0

æ¥æ¢

å¤ W0ï¼Œè¿™æ˜¯ä¸€ä¸ª

éå¸¸å¿«é€Ÿçš„

æ“ä½œï¼Œå‡ ä¹æ²¡

æœ‰å†…

å­˜å¼€é”€

ã€‚å…³é”®çš„æ˜¯ï¼Œè¿™

2They represent

a negligible number of

parameters compared to weights.

2 ä¸æƒé‡ç›¸æ¯”

ï¼Œå®ƒä»¬ä»£è¡¨çš„

å‚æ•°æ•°é‡å¾®

ä¸è¶³é“ã€‚Th

3An inevitability

when adapting to hard

tasks.

3 é€‚åº”

è‰°éš¾ä»»åŠ¡çš„

å¿…ç„¶æ€§ã€‚

Ã—

Ã—

Ã—

Ã—

1

4

guarantees that we

do not introduce any

additional latency during inference

compared to a fineï¿¾tuned

model by construction.

ä¸é€š

è¿‡æ„é€ è¿›è¡Œ

å¾®è°ƒçš„æ¨¡å‹

ç›¸æ¯”ï¼Œä¿è¯æˆ‘

ä»¬åœ¨æ¨æ–­è¿‡

ç¨‹ä¸­ä¸ä¼šå¼•

å…¥ä»»ä½•é¢å¤–

çš„å»¶è¿Ÿã€‚

8.3 APPLYING LORA TO

TRANSFORMER

8.4 LORA åœ¨å˜

å‹å™¨ä¸­çš„åº”

ç”¨

In principle, we can

apply LoRA to any

subset of weight matrices

in a neural network

to reduce

the number

of trainable parameters. In

the Transformer architecture, there

are four weight

matrices

in the self-attention module

(Wq, Wk, Wv, Wo)

and two in the

MLP module. We treat

Wq (or Wk, Wv)

as a single matrix

of dimension dmodel dmodel,

even though the output

dimension is usually sliced

into attention heads. We

limit our study to

only adapting the

attention

weights for downstream tasks

and freeze the MLP

modules (so they are

not trained in

downstream

tasks) both for simplicity

and parameter-efficiency.We further study

the effect on

adapting

different types of attention

weight matrices in a

Transformer in Section 7.1.

We leave the

empirical

investigation of adapting the

MLP layers, LayerNorm layers,

and biases to a

future

work.

åŸåˆ™ä¸Šï¼Œæˆ‘

ä»¬å¯ä»¥å°† LoRA

åº”

ç”¨äºç¥ç»ç½‘

ç»œä¸­æƒé‡çŸ©

é˜µçš„ä»»ä½•å­

é›†ï¼Œä»¥å‡å°‘å¯

è®­ç»ƒå‚æ•°çš„

æ•°

é‡ã€‚åœ¨ Transformer æ¶æ„

ä¸­ï¼Œåœ¨è‡ªæˆ‘å…³

æ³¨æ¨¡å—ä¸­æœ‰

å››ä¸ªæƒé‡çŸ©

é˜µ(Wqã€Wkã€Wvã€Wo

),åœ¨ MLP

æ¨¡å—ä¸­

æœ‰ä¸¤ä¸ªã€‚æˆ‘ä»¬

å°† Wq(æˆ–

Wkï¼ŒWv)è§†ä¸ºç»´

åº¦ dmodel dmodel çš„å•ä¸€çŸ©

é˜µï¼Œå³ä½¿è¾“å‡º

ç»´åº¦

é€šå¸¸è¢«

åˆ†å‰²æˆæ³¨æ„

åŠ›å¤´éƒ¨ã€‚ä¸ºäº†

ç®€å•å’Œå‚æ•°

æ•ˆç‡ï¼Œæˆ‘ä»¬å°†

æˆ‘ä»¬çš„ç ”ç©¶

é™åˆ¶ä¸ºä»…è°ƒ

æ•´ä¸‹æ¸¸ä»»

åŠ¡

çš„æ³¨æ„åŠ›æƒ

é‡ï¼Œå¹¶å†»ç»“ MLP æ¨¡

å—(å› æ­¤å®ƒä»¬

ä¸åœ¨ä¸‹æ¸¸ä»»

åŠ¡ä¸­è¢«è®­ç»ƒ

)ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥

ç ”ç©¶äº†

åœ¨è½¬

æ¢å™¨ä¸­é€‚åº”

ä¸åŒç±»å‹çš„

æ³¨æ„åŠ›æƒé‡

çŸ©é˜µçš„æ•ˆæœ

Section 7.1.æˆ‘ä»¬æŠŠé€‚åº”

MLP å±‚ã€å±‚æ ‡

å‡†å±‚

å’Œåå·®çš„å®

è¯ç ”ç©¶ç•™ç»™

æœªæ¥çš„å·¥ä½œ

ã€‚

Practical Benefits and Limitations.

The most significant benefit

comes from the reduction

in

memory and storage

usage. For a large

Transformer trained with Adam,

we reduce that VRAM

usage by up to

2/3 if rdmodel as

we do not need

to store the optimizer

states for the frozen

parameters. On GPT-3 175B,

we reduce the VRAM

consumption during training from

1.2TB to

350GB. With

r = 4 and

only the query and

value projection matrices being

adapted, the

checkpoint size

is reduced by roughly

10,000 (from 350GB to

35MB)4

. This allows

us to train

with

signifi- cantly fewer GPUs

and avoid I/O bottlenecks.

Another benefit is that

we can switch

between

tasks while deployed at

a much lower cost

by only swapping the

LoRA weights as

opposed

to all the parameters.

This allows for the

creation of many customized

models that can be

swapped in and out

on the fly on

machines that store the

pre-trained weights in VRAM.

We also

observe a

25% speedup during training

on GPT-3 175B compared

to full fine-tuning5

as we do not

need to calculate the

gradient for the vast

majority of the parameters.

å®é™…å¥½å¤„å’Œ

å±€é™æ€§ã€‚æœ€å¤§

çš„å¥½å¤„æ¥è‡ª

å†…å­˜å’Œå­˜å‚¨

ä½¿ç”¨çš„å‡å°‘

ã€‚å¯¹äºä½¿ç”¨ Adam è®­

ç»ƒçš„å¤§å‹è½¬

æ¢å™¨ï¼Œå¦‚æœä½¿

ç”¨ rdmodelï¼Œæˆ‘ä»¬å¯ä»¥

å°†

VRAM çš„ä½¿ç”¨å‡

å°‘ 2/3ï¼Œå› ä¸ºæˆ‘ä»¬

ä¸éœ€è¦å­˜å‚¨

å†»ç»“å‚

æ•°çš„

ä¼˜åŒ–å™¨çŠ¶æ€

ã€‚åœ¨

GPT-3 175B ä¸Šï¼Œæˆ‘ä»¬å°†

è®­ç»ƒæœŸé—´çš„

VRAM æ¶ˆè€—ä»

1.2TB å‡å°‘

åˆ° 350GBã€‚

å½“

r = 4 å¹¶ä¸”åª

æœ‰æŸ¥è¯¢å’Œå€¼

æŠ•å½±çŸ©é˜µè¢«

ä¿®æ”¹æ—¶ï¼Œæ£€æŸ¥

ç‚¹å¤§å°å‡å°‘

äº†å¤§çº¦

10ï¼Œ000(ä» 350GB

å‡

å°‘åˆ° 35MB)4ã€‚è¿™ä½¿å¾—

æˆ‘ä»¬å¯ä»¥ç”¨

å°‘å¾—å¤šçš„

GPU è¿›

è¡Œè®­ç»ƒï¼Œå¹¶é¿

å… I/O ç“¶é¢ˆã€‚å¦ä¸€

ä¸ªå¥½å¤„

æ˜¯ï¼Œæˆ‘

ä»¬å¯ä»¥åœ¨éƒ¨

ç½²æ—¶ä»¥ä½å¾—

å¤šçš„æˆæœ¬åœ¨

ä»»åŠ¡ä¹‹é—´åˆ‡

æ¢ï¼Œåªéœ€äº¤æ¢

LoRA æƒé‡ï¼Œè€Œä¸æ˜¯

æ‰€æœ‰

å‚æ•°ã€‚è¿™

å…è®¸åˆ›å»ºè®¸

å¤šå®šåˆ¶çš„æ¨¡

å‹ï¼Œè¿™äº›æ¨¡å‹

å¯ä»¥åœ¨ VRAM

ä¸­å­˜

å‚¨é¢„å…ˆè®­ç»ƒ

çš„æƒé‡çš„æœº

å™¨ä¸Š

åŠ¨æ€äº¤

æ¢ã€‚æˆ‘ä»¬è¿˜è§‚

å¯Ÿåˆ°ï¼Œä¸å®Œå…¨

å¾®è°ƒç›¸æ¯”ï¼Œåœ¨

GPT-3 175B ä¸Šè¿›è¡Œè®­ç»ƒ

æ—¶ï¼Œé€Ÿåº¦æé«˜

äº†

25%

5å› ä¸ºæˆ‘ä»¬

ä¸éœ€è¦è®¡ç®—

ç»å¤§å¤šæ•°å‚

æ•°çš„æ¢¯åº¦ã€‚

LoRA also

has its limitations. For

example, it is not

straightforward to batch inputs

to different

tasks with

different A and B

in a single forward

pass, if one chooses

to absorb A and

B into W to

eliminate additional inference latency.

Though it is possible

to not merge the

weights and

dynamically choose

the LoRA modules to

use for samples in

a batch for scenarios

where latency is

not

critical.

1

5

LoRA

ä¹Ÿ

æœ‰å…¶å±€é™æ€§

ã€‚ä¾‹å¦‚ï¼Œå¦‚æœé€‰

æ‹©å°† A å’Œ B

å¸æ”¶

åˆ° W ä¸­ä»¥æ¶ˆé™¤

é¢å¤–çš„æ¨ç†

å»¶è¿Ÿï¼Œé‚£ä¹ˆåœ¨

å•æ¬¡å‰å‘ä¼ 

é€’ä¸­æ‰¹é‡è¾“

å…¥åˆ°å…·æœ‰ä¸

åŒ A

å’Œ B çš„ä¸åŒ

ä»»åŠ¡å¹¶ä¸ç®€

å•ã€‚å°½ç®¡å¯¹äº

ç­‰å¾…æ—¶é—´ä¸

é‡

è¦çš„æƒ…å†µ

ï¼Œå¯ä»¥ä¸åˆå¹¶

æƒé‡å¹¶åŠ¨æ€

åœ°é€‰æ‹©

LoRA æ¨¡å—

ç”¨äºä¸€æ‰¹æ ·

æœ¬ã€‚

9 EMPIRICAL

EXPERIMENTS

10 å®è¯å®éªŒ

We evaluate

the downstream task performance

of LoRA on RoBERTa

(Liu et al., 2019),

Deï¿¾BERTa (He et al.,

2021), and GPT-2 (Radford

et al., b), before

scaling up to GPT-3

175B (Brown

et al.,

2020). Our experiments cover

a wide range of

tasks, from natural language

understanding

(NLU) to generation

(NLG). Specifically, we evaluate

on the GLUE (Wang

et al., 2019)

benchmark

for RoBERTa and DeBERTa.

We follow the setup

of Li & Liang

(2021) on GPT-2 for

a direct com- parison

and add WikiSQL (Zhong

et al., 2017) (NL

to SQL queries) and

SAMSum

(Gliwa et al.,

2019) (conversation summarization) for

large-scale experiments on GPT-3.

See

Appendix C for

more details on the

datasets we use. We

use NVIDIA Tesla V100

for all

experiments.

æˆ‘ä»¬åœ¨

RoBERTa ä¸Šè¯„

ä¼°äº† LoRA çš„ä¸‹æ¸¸

ä»»åŠ¡æ€§èƒ½(Liu

et al.,2019),å¾·

è´å°”å¡”(He et

al.,2021),å’Œ

GPT-2(Radford et al.,b),åœ¨

å‡çº§åˆ° GPT-3

175B ä¹‹å‰

(Brownet al.,2020).

æˆ‘

ä»¬ çš„ å® éªŒ

æ¶µ

ç›– äº† å¹¿ æ³›

çš„

ä»» åŠ¡ ï¼Œ ä»

è‡ª

ç„¶ è¯­ è¨€ ç†

è§£

( N L U

) åˆ° ç”Ÿ æˆ

( N L G

) ã€‚ å…· ä½“

æ¥

è¯´ ï¼Œ æˆ‘ ä»¬

è¯„

ä¼° èƒ¶ æ°´ (Wang

et al.,2019)RoBERTa å’Œ DeBERTa

çš„

åŸºå‡†ã€‚æˆ‘ä»¬æŒ‰

ç…§çš„è®¾ç½® Li

& Liang(2021)åœ¨

GPT-2

ä¸Šè¿›è¡Œç›´æ¥

æ¯”è¾ƒï¼Œå¹¶æ·»åŠ 

WikiSQL(Zhong et al.,2017)(NL åˆ°

SQL æŸ¥

è¯¢)å’Œ SAMSum(Gliwa

et al.,2019)åœ¨

GPT ä¸‰å·ä¸Šè¿›è¡Œ

å¤§è§„æ¨¡å®éªŒ

ã€‚çœ‹è§ Appendix

C äº†è§£æˆ‘

ä»¬ä½¿ç”¨çš„æ•°

æ®é›†çš„æ›´å¤š

è¯¦ç»†ä¿¡æ¯ã€‚æ‰€

æœ‰å®éªŒæˆ‘ä»¬

éƒ½ç”¨è‹±ä¼Ÿè¾¾

ç‰¹æ–¯æ‹‰ V100ã€‚

10.1

BASELINES

10.2 åŸºçº¿

To compare

with other baselines broadly,

we replicate the setups

used by prior work

and reuse

their reported

numbers whenever possible. This,

however, means that some

baselines might only

appear

in certain experiments.

ä¸ºäº†ä¸å…¶ä»–

åŸºçº¿è¿›è¡Œå¹¿

æ³›çš„æ¯”è¾ƒï¼Œæˆ‘

ä»¬å¤åˆ¶äº†ä»¥

å‰å·¥ä½œä¸­ä½¿

ç”¨çš„è®¾ç½®ï¼Œå¹¶

å°½å¯èƒ½é‡ç”¨

ä»–ä»¬

æŠ¥å‘Šçš„

æ•°å­—ã€‚ç„¶è€Œï¼Œè¿™

æ„å‘³ç€ä¸€äº›

åŸºçº¿å¯èƒ½åª

å‡ºç°åœ¨æŸäº›

å®éªŒä¸­ã€‚

Fine-Tuning (FT) is

a common approach for

adaptation. During fine-tuning, the

model is

initialized to

the pre-trained weights and

biases, and all model

parameters undergo gradient

updates.A

simple variant is to

update only some layers

while freezing others. We

include one such

baseline

reported in prior work

(Li & Liang, 2021)

on GPT-2, which adapts

just the last two

layers

(FTTop2).

å¾®è°ƒ

æ˜¯ä¸€ç§å¸¸è§

çš„é€‚åº”æ–¹æ³•

ã€‚åœ¨å¾®è°ƒæœŸé—´

ï¼Œæ¨¡å‹è¢«åˆå§‹

åŒ–ä¸ºé¢„å…ˆè®­

ç»ƒçš„æƒé‡å’Œ

åå·®ï¼Œå¹¶ä¸”

æ‰€

æœ‰æ¨¡å‹å‚æ•°

ç»å†æ¢¯åº¦æ›´

æ–°ã€‚ä¸€ä¸ªç®€å•

çš„å˜ä½“æ˜¯åª

æ›´æ–°ä¸€äº›å±‚

ï¼Œè€Œå†»ç»“å…¶ä»–

å±‚ã€‚æˆ‘ä»¬åœ¨ä¹‹

å‰çš„å·¥ä½œä¸­

åŒ…æ‹¬äº†ä¸€ä¸ª

è¿™æ ·çš„åŸºçº¿

(Li

& Liang,2021)åœ¨ GPT-2 ä¸Šï¼Œå®ƒåªé€‚

åº”æœ€åä¸¤å±‚

(FTP

top 2)ã€‚

4We still

need the 350GB model

during deployment; however, storing

100 adapted models only

requires 

350GB +

35MB * 100 â‰ˆ

354GB as opposed to

100 * 350GB â‰ˆ

35TB.

4 åœ¨éƒ¨ç½²æœŸé—´

ï¼Œæˆ‘ä»¬ä»ç„¶éœ€

è¦ 350GB

å‹å·ï¼›ä½†æ˜¯

ï¼Œå­˜å‚¨ 100 ä¸ªæ”¹è£…

å‹å·åªéœ€è¦

350GB +

35MB * 100 â‰ˆ

354GBï¼Œè€Œä¸æ˜¯ 100 * 350GB

â‰ˆ 35TBã€‚

5For GPT-3

175B, the training throughput

for full fine-tuning is

32.5 tokens/s per V100

GPU; with the same

number of weight shards

for model parallelism, the

throughput is 43.1 tokens/s

per V100 GPU for

LoRA.

5 å¯¹äº

GPT-3 175Bï¼Œå®Œå…¨å¾®è°ƒçš„

è®­ç»ƒååé‡

ä¸ºæ¯

V100 GPU 32.5 ä»¤ç‰Œ/ç§’

ï¼›å¯¹äºç›¸åŒæ•°

é‡çš„æ¨¡å‹å¹¶

è¡Œæ€§ï¼ŒLoRA

çš„åå

é‡ä¸ºæ¯ V100 GPU 43.1

ä»¤ç‰Œ

/ç§’ã€‚

1

â€ 

â€ 

Model & Method #

Trainable

Parameters MNLI SST-2

MRPC CoLA QNLI QQP

RTE STS-B Avg.

æ¨¡å‹å’Œæ–¹

æ³•

#å¯è®­ç»ƒ

å› 

ç´  MNLI SST-2

MRPC å¯ä¹ QNLI QQP

RTE STS-B å¹³å‡

å€¼ã€‚

RoBbase

(FT)* 125.0M 87.6 94.8

90.2 63.6 92.8 91.9

78.7 91.2 86.4

RoBbase

(BitFit)* 0.1M 84.7 93.7

92.7 62.0 91.8 84.0

81.5 90.8 85.2

RoBbase

(AdptD

)* 0.3M 87.1Â±.0

94.2Â±.1 88.5Â±1.1 60.8Â±.4 93.1Â±.1

90.2Â±.0 71.5Â±2.7 89.7Â±.3 84.4

RoBbase (AdptD

)* 0.9M

87.3Â±.1 94.7Â±.3 88.4Â±.1 62.6Â±.9

93.0Â±.2 90.6Â±.0 75.9Â±2.2 90.3Â±.1

85.4

RoBbase (LoRA) 0.3M

87.5Â±.3 95.1Â±.2 89.7Â±.7 63.4Â±1.2

93.3Â±.3 90.8Â±.1 86.6Â±.7 91.5Â±.2

87.2

RoBbase (è‹±å°º)* 125.0

ç±³ 87.6 94.8 90.2

63.6 92.8 91.9 78.7

91.2 86.4

RoBbase (BitFit)

*

0.1 ç±³

84.7 93.7

92.7 62.0 91.8 84.0

81.5 90.8 85.2

RoBbase

(AdptD)* 0.3 ç±³ 87.1

.

0

94.2 .

1

88.5

1.1

60.8

.

4

93.1 .

1

90.2 

.0

71.5

2.7

89.7 .

3

84.4

RoBbase (AdptD)*

0.9 ç±³ 87.3 .

1

94.7 .

3

88.4 .

1

62.6

.

9

93.0 .

2

90.6

.0

75.9

2.2

90.3 .

1

85.4

RoBbase (åŠ³æ‹‰) 0.3

ç±³

87.5 .

3

95.1

.

2

89.7 .

7

63.4

1.2

93.3

.

3

90.8

.1

86.6 .

7

91.5

.

2

87.2

RoBlarge

(FT)* 355.0M 90.2 96.4

90.9 68.0 94.7 92.2

86.6 92.4 88.9

RoBlarge

(LoRA) 0.8M 90.6Â±.2 96.2Â±.5

90.9Â±1.2 68.2Â±1.9 94.9Â±.3 91.6Â±.1

87.4Â±2.5 92.6Â±.2 89.0

RoBlarge(è‹±å°º)*

355.0 ç±³ 90.2 96.4

90.9 68.0 94.7 92.2

86.6 92.4 88.9

å¤§å‹

æœºå™¨äºº(æ´›

æ‹‰

)

0.8 ç±³ 90.6

.2

96.2 

.5

90.9

1.2

68.2

1.9

94.9 

.3

91.6

.1

87.4

2.5

92.6

.2

89.0

RoBlarge (AdptP

)â€  3.0M 90.2Â±.3 96.1Â±.3

90.2Â±.7 68.3Â±1.0 94.8Â±.2 91.9Â±.1

83.8Â±2.9 92.1Â±.7 88.4

RoBlarge

(AdptP

)â€  0.8M 90.5Â±.3

96.6Â±.2 89.7Â±1.2 67.8Â±2.5 94.8Â±.3

91.7Â±.2 80.1Â±2.9 91.9Â±.4 87.9

RoBlarge (AdptH

)â€  6.0M

89.9Â±.5 96.2Â±.3 88.7Â±2.9 66.5Â±4.4

94.7Â±.2 92.1Â±.1 83.4Â±1.1 91.0Â±1.7

87.8

RoBlarge (AdptH

)â€ 

0.8M 90.3Â±.3 96.3Â±.5 87.7Â±1.7

66.3Â±2.0 94.7Â±.2 91.5Â±.1 72.9Â±2.9

91.5Â±.5 86.4

RoBlarge (LoRA)â€ 

0.8M 90.6Â±.2 96.2Â±.5 90.2Â±1.0

68.2Â±1.9 94.8Â±.3 91.6Â±.2 85.2Â±1.1

92.3Â±.5 88.6

å¤§å‹æœºå™¨

äºº (AdptP)

3.0 ç±³ 90.2 .

3

96.1 .

3

90.2 .

7

68.3

1.0

94.8 .

2

91.9 .

1

83.8

2.9

92.1 .

7

88.4

å¤§å‹æœº

å™¨äºº (AdptP) 0.8

ç±³ 90.5 .

3

96.6 .

2

89.7

1.2

67.8

2.5

94.8

.

3

91.7 .

2

80.1

2.9

91.9

.

4

87.9

å¤§å‹

æœºå™¨äºº

(AdptH) 6.0M 89.9 .

5

96.2 .

3

88.7

2.9

66.5

4.4

94.7 .

2

92.1 .

1

83.4

1.1

91.0 

1.7

87.8

å¤§å‹

æœºå™¨äºº (AdptH) 0.8

ç±³ 90.3 .

3

96.3 .

5

87.7

1.7

66.3 

2.0

94.7 .

2

91.5

.

1

72.9

2.9

91.5 .

5

86.4

å¤§

å‹æœºå™¨äºº (åŠ³

æ‹‰) 0.8 ç±³

90.6 .

2

96.2

.

5

90.2

1.0

68.2 

1.9

94.8

.

3

91.6 .

2

85.2

1.1

92.3

.

5

88.6

DeBXXL

(FT)* 1500.0M 91.8 97.2

92.0 72.0 96.0 92.7

93.9 92.9 91.1

DeBXXL

(LoRA) 4.7M 91.9Â±.2 96.9Â±.2

92.6Â±.6 72.4Â±1.1 96.0Â±.1 92.9Â±.1

94.9Â±.4 93.0Â±.2 91.3

DeBXXL(è‹±å°º)*

1500.0 ç±³

91.8 97.2 92.0

72.0 96.0 92.7 93.9

92.9 91.1

DeBXXL(åŠ³æ‹‰) 4.7

ç±³ 91.9 

.2

96.9

.2

92.6

.6

72.4

1.1

96.0

.1

92.9 

.1

94.9 

.4

93.0

.2

91.3

Table 2:

RoBERTabase, RoBERTalarge, and DeBERTaXXL

with different adaptation methods

on the

GLUE benchmark.

We report the overall

(matched and mismatched) accuracy

for MNLI,

Matthewâ€™s correlation

for CoLA, Pearson correlation

for STS-B, and accuracy

for other tasks.

Higher

configured

is better for

in a setup similar

to 

all metrics.

*

Houlsby et al.

indicates

(2019)

numbers

for a fair comparison.

published in prior works.

indicates runs

è¡¨ 2:

åœ¨

GLUE åŸº å‡† æµ‹

è¯• ä¸­

é‡‡ ç”¨ ä¸

åŒ é€‚

åº” æ–¹ æ³•

çš„ RoBERTabase ã€ RoBERTalarge

å’Œ

DeBERTaXXLã€‚æˆ‘ä»¬æŠ¥å‘Šäº†

MNLI çš„æ€»ä½“(åŒ¹é…

å’Œä¸åŒ¹é…)å‡†

ç¡®æ€§ã€å¯ä¹çš„

Matthew ç›¸å…³

æ€§ã€STS-B

çš„ Pearson ç›¸

å…³æ€§ä»¥åŠå…¶

ä»–ä»»åŠ¡çš„å‡†

ç¡®æ€§ã€‚å¯¹äºæ‰€

æœ‰æŒ‡æ ‡æ¥è¯´

ï¼Œè¶Šé«˜è¶Šå¥½ã€‚*è¡¨

ç¤ºå…ˆå‰ä½œå“

ä¸­å‘è¡¨çš„æ•°

å­—ã€‚è¡¨ç¤ºåœ¨ç±»

ä¼¼äºçš„è®¾ç½®

ä¸­é…ç½®çš„è¿

è¡Œ Houlsby

et al.(2019)ä¸ºäº†

å…¬å¹³

æ¯”è¾ƒã€‚

1

Ë† L

Ë† L

Bias-only or BitFit is

a baseline where we

only train the bias

vectors while freezing everything

else. Contemporarily, this baseline

has also been studied

by BitFit (Zaken et

al., 2021).

ä»…åç½®

æˆ–ä½åŒ¹é…æ˜¯

ä¸€ä¸ªåŸºçº¿ï¼Œæˆ‘

ä»¬åªè®­ç»ƒå

ç½®å‘é‡ï¼Œè€Œå†»

ç»“å…¶ä»–ä¸€åˆ‡

ã€‚åŒæ—¶ï¼ŒBitFit ä¹Ÿç ”

ç©¶

äº†è¿™ä¸€åŸºçº¿

(Zaken et al.,2021).

Prefix-embedding

tuning (PreEmbed) inserts special

tokens among the input

tokens. These speï¿¾cial tokens

have trainable word embeddings

and are generally not

in the modelâ€™s vocabulary.

Where to place such

tokens can have an

impact on performance. We

focus on â€œprefixingâ€, which

prepends such tokens to

the prompt, and â€œinfixingâ€,

which appends to the

prompt; both are

discussed

in Li & Liang

(2021). We use lp

(resp. li) denote the

number of prefix (resp.

infix)

tokens. The number

of

å‰ç¼€åµŒå…¥è°ƒ

ä¼˜(PreEmbed)åœ¨è¾“å…¥æ ‡

è®°ä¸­æ’å…¥ç‰¹

æ®Šæ ‡è®°ã€‚è¿™äº›

ç‰¹æ®Šæ ‡è®°å…·

æœ‰å¯è®­ç»ƒçš„

å•è¯åµŒ

å…¥ï¼Œå¹¶

ä¸”é€šå¸¸ä¸åœ¨

æ¨¡å‹çš„è¯æ±‡

è¡¨ä¸­ã€‚æ”¾ç½®è¿™

ç§ä»¤ç‰Œçš„ä½

ç½®ä¼šå¯¹æ€§èƒ½

äº§ç”Ÿå½±å“ã€‚æˆ‘

ä»¬å…³

æ³¨â€œå‰ç¼€

â€,å®ƒå°†è¿™ç§æ ‡

è®°æ·»åŠ åˆ°æ

ç¤ºçš„å‰é¢ï¼Œä»¥

åŠâ€œä¸­ç¼€â€,å®ƒæ·»

åŠ åˆ°æç¤ºçš„

åé¢ï¼›ä¸¤è€…

éƒ½

åœ¨ä¸­è®¨è®º Li &Liang(2021).æˆ‘

ä»¬ ä½¿

ç”¨ lp (resp ã€‚

li) è¡¨ ç¤º

å‰ ç¼€

(resp ã€‚ ä¸­ ç¼€

) ä»¤

ç‰Œã€‚â€¦çš„æ•°ç›®

trainable parameters

is |Î˜| = dmodel

Ã— (lp + li).

å¯

è®­ç»ƒå‚æ•°æ˜¯

|Î¸| = d modelÃ—(LP+Li)ã€‚

Prefix-layer tuning (PreLayer) is

an extension to prefix-embedding

tuning. Instead of just

learning the word embeddings

(or equivalently, the activations

after the embedding layer)

for

some special tokens,

we learn the activations

after every Transformer layer.

The activations

computed from

pre- vious layers are

simply replaced by trainable

ones. The resulting number

of

trainable parameters is

å‰ç¼€å±‚ä¼˜åŒ–

(PreLayer)æ˜¯å‰ç¼€åµŒå…¥

ä¼˜åŒ–çš„æ‰©å±•

ã€‚æˆ‘ä»¬ä¸æ˜¯ä»…

ä»…å­¦ä¹ å•è¯

åµŒå…¥(æˆ–è€…ç­‰

ä»·åœ°ï¼Œ

åœ¨åµŒå…¥

å±‚ä¹‹åçš„æ¿€

æ´»)æ¥è·å¾—ä¸€

äº›ç‰¹æ®Šçš„ä»¤

ç‰Œï¼Œè€Œæ˜¯åœ¨æ¯

ä¸ªå˜æ¢å™¨å±‚

ä¹‹åå­¦ä¹ æ¿€

æ´»ã€‚ä»å…ˆå‰

å±‚

è®¡ç®—çš„æ¿€æ´»

ç®€å•åœ°è¢«å¯

è®­ç»ƒçš„æ¿€æ´»

ä»£æ›¿ã€‚å¯è®­ç»ƒ

å‚æ•°çš„æœ€ç»ˆ

æ•°é‡ä¸º

|Î˜|

= L Ã— dmodel

Ã— (lp + li),

where L is the

number of Transformer layers.

|Î¸| = LÃ—d modelÃ—(LP+Li)ï¼Œå…¶ä¸­

L

ä¸ºå˜å‹å™¨å±‚

æ•°ã€‚

Adapter tuning as

proposed in Houlsby et

al. (2019) inserts adapter

layers between the selfï¿¾attention

module (and the MLP

module) and the subsequent

residual connection. There are

two

fully connected layers

with biases in an

adapter layer with a

nonlinearity in between. We

call this

original design

AdapterH

. Recently, Lin

et al. (2020) proposed

a more efficient design

with the

adapter layer

applied only after the

MLP module and after

a LayerNorm. We call

it AdapterL

.

This

is very similar to

another deign proposed in

Pfeiffer et al. (2021),

which we call AdapterP

.

We also include

another baseline call AdapterDrop

(RuÂ¨ckleÂ´ et al., 2020)

which drops some

adapter

layers for greater efficiency

(AdapterD

). We cite

numbers from prior works

whenever

possible to maximize

the number of baselines

we compare with; they

are in rows with

an asterisk

(*) in

the first column.

ä¸­å»ºè®®çš„

é€‚é…å™¨è°ƒæ•´

Houlsby

et al.(2019)åœ¨è‡ªå…³æ³¨æ¨¡

å—(å’Œ MLP æ¨¡å—)å’Œ

åç»­å‰©ä½™è¿

æ¥ä¹‹

é—´æ’å…¥

é€‚é…å™¨å±‚ã€‚æœ‰

ä¸¤ä¸ªå®Œå…¨è¿

æ¥çš„å±‚ï¼Œé€‚é…

å™¨å±‚ä¸­æœ‰å

ç½®ï¼Œå…¶é—´æœ‰é

çº¿æ€§ã€‚æˆ‘ä»¬ç§°

ä¹‹ä¸º

åŸå§‹è®¾

è®¡é€‚é…å™¨ã€‚æœ€

è¿‘ï¼ŒLin et al.(2020)æå‡ºäº†ä¸€

ç§æ›´æœ‰æ•ˆçš„

è®¾è®¡ï¼Œä»…åœ¨

MLP æ¨¡

å—å’Œå±‚

å‘½å

ä¹‹ååº”ç”¨é€‚

é…å™¨å±‚ã€‚æˆ‘ä»¬

ç§°ä¹‹ä¸º adapter

1ã€‚è¿™é

å¸¸ç±»ä¼¼äºå¦

ä¸€ä¸ªåœ¨ Pfeiffer et al.

(2021),æˆ‘ä»¬

ç§°ä¹‹ä¸º AdapterPã€‚æˆ‘ä»¬

è¿˜åŒ…æ‹¬å¦ä¸€

ä¸ªåŸºçº¿è°ƒç”¨

AdapterDrop(RuÂ¨ckleÂ´ et

al.,2020)è¿™å°±å‡å°‘äº†

ä¸€äº›é€‚é…å™¨

å±‚ä»¥æé«˜æ•ˆ

ç‡(AdapterD)ã€‚æˆ‘ä»¬å°½å¯

èƒ½å¼•ç”¨ä»¥å‰

ä½œå“ä¸­çš„æ•°

å­—ï¼Œä»¥æœ€å¤§åŒ–

æˆ‘ä»¬æ¯”è¾ƒçš„

åŸºçº¿æ•°é‡ï¼›å®ƒ

ä»¬ä½äºç¬¬ä¸€

åˆ—å¸¦æœ‰æ˜Ÿå·

(*)çš„è¡Œä¸­ã€‚

In all cases, we

have |Î˜| = LË†

Adpt Ã—(2 Ã— dmodel

Ã— r + r

+ dmodel) + 2

Ã— LË†

LN Ã—

dmodel where

LË†

Adpt

åœ¨æ‰€

æœ‰æƒ…å†µä¸‹ï¼Œæˆ‘

ä»¬éƒ½æœ‰|Î¸| = lË‡AdptÃ—(2Ã—d modelÃ—r+r+d

model)+2Ã—lË‡LNÃ—d 

model å…¶ä¸­

lË‡Adpt

is the number of

adapter layers and LLN

the number of trainable

LayerNorms (e.g., in Adapter

).

1

æ˜¯é€‚é…å™¨å±‚

æ•°ï¼ŒLLN æ˜¯å¯è®­ç»ƒ

å±‚æ•°(ä¾‹å¦‚ï¼Œåœ¨

é€‚é…å™¨ä¸­)ã€‚

LoRA adds trainable pairs

of rank decomposition matrices

in parallel to existing

weight matrices.

As mentioned

in Section 4.2, we

only apply LoRA to

Wq and Wv in

most experiments for

simplicity.

The number of trainable

parameters is determined by

the rank r and

the shape of the

original weights:

LoRA å°†

å¯è®­ç»ƒçš„ç§©

åˆ†è§£çŸ©é˜µå¯¹

å¹¶è¡Œæ·»åŠ åˆ°

ç°æœ‰çš„æƒé‡

çŸ©é˜µä¸­ã€‚å¦‚ä¸­

æ‰€è¿°

Section 4.2,ä¸ºäº†

ç®€

å•èµ·è§ï¼Œåœ¨å¤§

å¤šæ•°å®éªŒä¸­

æˆ‘ä»¬åªæŠŠ LoRA

åº”

ç”¨äº Wq å’Œ Wvã€‚å¯è®­

ç»ƒå‚æ•°çš„æ•°

é‡ç”±ç§©

r å’ŒåŸ

å§‹æƒé‡

çš„å½¢

çŠ¶å†³å®š:

|Î˜|

= 2 Ã— LË†

LoRA Ã— dmodel Ã—

r, where LË†

LoRA

is the number of

weight matrices we apply

LoRA

to.

|Î¸| =

2Ã—lË‡LoRAÃ—d modelÃ—rï¼Œå…¶ä¸­

lË‡LoRA æ˜¯æˆ‘ä»¬åº”ç”¨

LoRA çš„æƒé‡çŸ©é˜µ

çš„ä¸ªæ•°ã€‚

1

Model & Method

# Trainable

Parameters

E2E

NLG Challenge

BLEU NIST

MET ROUGE-L CIDEr

æ¨¡å‹

å’Œæ–¹æ³•

#å¯è®­

ç»ƒ

å› ç´ 

e2eÂ·NLG æŒ‘æˆ˜

èµ›

è“è‰² ç¾å›½

å›½å®¶æ ‡å‡†æŠ€

æœ¯ç ”ç©¶æ‰€(National

Institute of

Standards and Technology) é‡

è§äº†

èƒ­

è„‚-L è‹¹

æœé…’

GPT-2

M (FT)* 354.92M 68.2

8.62 46.2 71.0 2.47

GPT-2 M (AdapterL

)*

0.37M 66.3 8.41 45.0

69.8 2.40

GPT-2 M

(AdapterL

)* 11.09M 68.9

8.71 46.1 71.3 2.47

GPT-2 M (AdapterH

)

11.09M 67.3Â±.6 8.50Â±.07 46.0Â±.2

70.7Â±.2 2.44Â±.01

GPT-2 M

(FTTop2)* 25.19M 68.1 8.59

46.0 70.8 2.41

GPT-2

M (PreLayer)* 0.35M 69.7

8.81 46.1 71.4 2.49

GPT-2 M (LoRA) 0.35M

70.4Â±.1 8.85Â±.02 46.8Â±.2 71.8Â±.1

2.53Â±.02

GPT-2 ç±³(è‹±å°º

)* 354.92

ç±³ 68.2 8.62 46.2

71.0 2.47

GPT-2 M

(AdapterL)* 0.37 ç±³ 66.3

8.41 45.0 69.8 2.40

GPT-2 M (AdapterL)* 11.09

ç±³ 68.9 8.71 46.1

71.3 2.47

GPT-2 M

(AdapterH) 11.09 ç±³ 67.3

.6

8.50 .

07

46.0 .

2

70.7

.2

2.44 .

01

GPT-2 M (FTTop2)* 25.19

ç±³

68.1 8.59 46.0 70.8

2.41

GPT-2 ç±³(é¢„å±‚)* 0.35

ç±³ 69.7 8.81 46.1

71.4 2.49

GPT-2 M(æ´›

æ‹‰)

0.35 ç±³ 70.4

.1

8.85 .

02

46.8 .

2

71.8

.1

2.53 .

02

GPT-2 L (FT)* 774.03M

68.5 8.78 46.0 69.9

2.45

GPT-2 L (AdapterL

) 0.88M 69.1Â±.1 8.68Â±.03

46.3Â±.0 71.4Â±.2 2.49Â±.0

GPT-2

L (AdapterL

) 23.00M

68.9Â±.3 8.70Â±.04 46.1Â±.1 71.3Â±.2

2.45Â±.02

GPT-2 L (PreLayer)*

0.77M 70.3 8.85 46.2

71.7 2.47

GPT-2 L

(LoRA) 0.77M 70.4Â±.1 8.89Â±.02

46.8Â±.2 72.0Â±.2 2.47Â±.02

GPT-2

å‡(è‹±å°º

)* 774.03 ç±³ 68.5

8.78 46.0 69.9 2.45

GPT-2 L(é€‚é…å™¨ 1) 0.88

ç±³

69.1 

.1

8.68

.

03

46.3 .

0

71.4

.2

2.49

.

0

GPT-2 L(é€‚é…å™¨

1) 23.00 ç±³ 68.9

.3

8.70 .

04

46.1 .

1

71.3

.2

2.45 .

02

GPT-2 å‡

(é¢„å±‚)* 0.77 ç±³

70.3 8.85 46.2 71.7

2.47

GPT-2 L 0.77

ç±³ 70.4 

.1

8.89 .

02

46.8

.

2

72.0

.2

2.47 .

02

Table 3: GPT-2 medium

(M) and large (L)

with different adaptation methods

on the E2E NLG

Challenge. For all metrics,

higher is better. LoRA

outperforms several baselines with

comparable

or fewer trainable

parameters. Confidence intervals are

shown for experiments we

ran. * indicates

numbers

published in prior works.

è¡¨

3: GPT-2 ä¸­å‹(M)å’Œå¤§å‹

(L)åœ¨ E2E

NLG æŒ‘æˆ˜ä¸­é‡‡

ç”¨ä¸åŒçš„é€‚

åº”æ–¹æ³•ã€‚å¯¹äº

æ‰€æœ‰æŒ‡æ ‡ï¼Œè¶Š

é«˜è¶Šå¥½ã€‚LoRA ä¼˜äº

å‡ ä¸ªå…·æœ‰å¯

æ¯”æˆ–æ›´å°‘å¯

è®­ç»ƒå‚æ•°çš„

åŸºçº¿ã€‚æˆ‘ä»¬è¿

è¡Œçš„å®éªŒæ˜¾

ç¤ºäº†ç½®ä¿¡åŒº

é—´ã€‚*è¡¨ç¤ºå…ˆå‰

ä½œå“ä¸­å‘è¡¨

çš„æ•°å­—ã€‚

10.3

ROBERTA BASE/LARGE

10.4 ç½—ä¼¯

å¡”åŸºåœ°/å¤§

RoBERTa (Liu et al.,

2019) optimized the pre-training

recipe originally proposed in

BERT

(Devlin et al.,

2019a) and boosted the

latterâ€™s task performance without

introducing many more

trainable

parameters. While RoBERTa has

been overtaken by much

larger models on NLP

leaderboards such as the

GLUE benchmark (Wang et

al., 2019) in recent

years, it remains a

competitive and popular pre-trained

model for its size

among practitioners. We take

the preï¿¾trained RoBERTa base

(125M) and RoBERTa large

(355M) from the HuggingFace

Transformers

library (Wolf et

al., 2020) and evaluate

the performance of different

efficient adaptation

approaches on

tasks from the GLUE

benchmark. We also replicate

Houlsby et al. (2019)

and

Pfeiffer et al.

(2021) according to their

setup. To ensure a

fair comparison, we make

two crucial

changes to

how we evaluate LoRA

when comparing with adapters.

First, we use the

same batch

size for

all tasks and use

a sequence length of

128 to match the

adapter baselines. Second, we

initialize the model to

the pre-trained model for

MRPC, RTE, and STS-B,

not a model already

adapted to MNLI like

the fine-tuning baseline. Runs

following this more restricted

setup from

Houlsby et

al. (2019) are labeled

with . The result

is presented in Table

2 (Top Three Sections).

See Section D.1 for

details on the hyperparameters

used.

ç½—

ä¼¯å¡”(Liu et al.,2019)ä¼˜åŒ–äº†

æœ€åˆåœ¨

BERT ä¸­æ

å‡ºçš„é¢„è®­ç»ƒ

é…æ–¹(Devlinet al.,2019a)å¹¶

ä¸”åœ¨

ä¸å¼•å…¥æ›´å¤š

å¯è®­ç»ƒå‚æ•°

çš„æƒ…å†µä¸‹æ

é«˜äº†åè€…çš„

ä»»åŠ¡æ€§èƒ½ã€‚è™½

ç„¶

RoBERTa åœ¨ NLP æ’è¡Œæ¦œ

ä¸Šå·²ç»è¢«

GLUE benchmark ç­‰

æ›´å¤§çš„æ¨¡å‹

è¶…è¶Š(Wang et

al.,2019)è¿‘å¹´æ¥

ï¼Œå®ƒä»ç„¶æ˜¯ä¸€

ä¸ªæœ‰

ç«äº‰åŠ›

çš„å’Œå—æ¬¢è¿

çš„é¢„åŸ¹è®­æ¨¡

å¼ï¼Œå…¶è§„æ¨¡çš„

ä»ä¸šè€…ã€‚æˆ‘ä»¬

ä»æ‹¥æŠ±è„¸å˜

å½¢é‡‘åˆšåº“ä¸­

å–å‡ºé¢„å…ˆ

è®­

ç»ƒå¥½çš„ç½—ä¼¯

å¡”åº•åº§(125 ç±³)å’Œ

ç½—ä¼¯å¡”å¤§åº•

åº§(355

ç±³)(Wolf et al.,2020)å¹¶æ ¹æ®

GLUE åŸº

å‡†è¯„ä¼°ä¸

åŒæœ‰æ•ˆé€‚åº”

æ–¹æ³•åœ¨ä»»åŠ¡

ä¸Šçš„æ€§èƒ½ã€‚æˆ‘

ä»¬ä¹Ÿå¤åˆ¶ Houlsby et al.(2019)å’Œ

Pfeiffer

et al.(2021)æ ¹æ®ä»–ä»¬çš„

è®¾ç½®ã€‚ä¸ºäº†ç¡®

ä¿å…¬å¹³çš„æ¯”

è¾ƒï¼Œæˆ‘ä»¬åœ¨ä¸

é€‚é…å™¨è¿›è¡Œ

æ¯”è¾ƒæ—¶ï¼Œå¯¹è¯„

ä¼° LoRA çš„æ–¹å¼è¿›

è¡Œäº†ä¸¤é¡¹é‡

è¦çš„æ›´æ”¹ã€‚é¦–

å…ˆï¼Œæˆ‘ä»¬å¯¹æ‰€

æœ‰ä»»åŠ¡ä½¿ç”¨

ç›¸åŒçš„æ‰¹å¤„

ç†å¤§å°ï¼Œå¹¶

ä½¿

ç”¨é•¿åº¦ä¸º 128 çš„

åºåˆ—æ¥åŒ¹é…

é€‚é…å™¨åŸºçº¿

ã€‚ç¬¬äºŒï¼Œæˆ‘ä»¬å°†

æ¨¡å‹åˆå§‹åŒ–

ä¸ºç”¨äº MRPCã€RTE

å’Œ

STS-B çš„

é¢„è®­ç»ƒæ¨¡å‹

ï¼Œè€Œä¸æ˜¯åƒå¾®

è°ƒåŸºçº¿é‚£æ ·

å·²ç»é€‚åº” MNLI

çš„

æ¨¡å‹ã€‚ä»ä»¥ä¸‹

æ›´å—é™åˆ¶çš„

è®¾

ç½®è¿è¡Œ Houlsby et

al.(2019)éƒ½

æ ‡æœ‰ã€‚ç»“æœæ˜¾

ç¤ºåœ¨ä¸­ Table 2(å‰ä¸‰

èŠ‚)ã€‚çœ‹è§ Section

D.1

æœ‰å…³

æ‰€ç”¨è¶…å‚æ•°

çš„è¯¦ç»†ä¿¡æ¯

ã€‚

â€ 

10.5

DEBERTA XXL

10.6 å¾·è´å¡”Â·XXL

DeBERTa (He et al.,

2021) is a more

recent variant of BERT

that is trained on

a much larger

scale

and performs very competitively

on benchmarks such as

GLUE (Wang et al.,

2019) and Suï¿¾perGLUE (Wang

et al., 2020). We

evaluate if LoRA can

still match the performance

of a fully

fine-tuned

DeBERTa XXL (1.5B) on

GLUE. The result is

presented in Table 2

(Bottom Section).

See Section

D.2 for details on

the hyperparameters used.

å¾·ä¼¯

å¡”(He

et al.,2021)æ˜¯ BERT çš„ä¸€ä¸ª

è¾ƒæ–°çš„å˜ä½“

ï¼Œç»è¿‡äº†æ›´å¤§

è§„æ¨¡çš„è®­ç»ƒ

ï¼Œåœ¨

GLUE ç­‰

åŸºå‡†æµ‹

è¯•ä¸­è¡¨ç°å¾—

éå¸¸æœ‰ç«äº‰

åŠ›(Wang et

al.,2019)å’Œè¶…å¼ºåŠ›

èƒ¶(Wang et al.,2020).æˆ‘

ä»¬

è¯„ ä¼°

äº† L o

R A åœ¨ G

L U E ä¸Š

æ˜¯ å¦

ä» èƒ½ ä¸

å®Œ å…¨

å¾® è°ƒ çš„

D e B E

R T a X

X L ( 1

. 5 B )

çš„

æ€§

èƒ½ ç›¸ åŒ¹

é… ã€‚ ç»“

æœ æ˜¾

ç¤º åœ¨ ä¸­

Table 2(åº•éƒ¨)ã€‚çœ‹è§

Section D.2 æœ‰

å…³æ‰€ç”¨è¶…å‚

æ•°çš„è¯¦

ç»†ä¿¡

æ¯ã€‚

10.7 GPT-2 MEDIUM/LARGE

10.8

GPT-2 ä¸­å‹/å¤§å‹

Having shown that

LoRA can be a

competitive alternative to full

fine-tuning on NLU, we

hope to

answer if

LoRA still prevails on

NLG models, such as

GPT-2 medium and large

(Radford et al.,

b).

We keep our setup

as close as possible

to Li & Liang

(2021) for a direct

comparison. Due

to space

constraint, we only present

our result on E2E

NLG Challenge (Table 3)

in this section.

See

Section F.1 for results

on WebNLG (Gardent et

al., 2017) and DART

(Nan et al., 2020).

We

include a list

of the hyperparameters used

in Section D.3.

å·²ç»è¡¨æ˜

LoRA å¯

ä»¥æˆä¸º NLU ä¸Šå®Œ

å…¨å¾®è°ƒçš„æœ‰

ç«äº‰åŠ›çš„æ›¿

ä»£æ–¹æ¡ˆï¼Œæˆ‘ä»¬

å¸Œæœ›å›ç­”

LoRA æ˜¯

å¦

ä»ç„¶åœ¨ NLG

æ¨¡

å‹ä¸Šæµè¡Œï¼Œå¦‚

GPT-2 ä¸­å‹å’Œå¤§å‹

(Radford et al.,b).æˆ‘

ä»¬ å°½ å¯ èƒ½

ä¿

æŒ

æˆ‘ ä»¬ çš„

è®¾

ç½® Li & Liang(2021)ä¸ºäº†ç›´

æ¥æ¯”è¾ƒã€‚ç”±äº

ç¯‡å¹…æ‰€é™ï¼Œæˆ‘

ä»¬åªç»™å‡º

E2E

NLG æŒ‘

æˆ˜èµ›çš„ç»“æœ

(Table3)åœ¨æœ¬èŠ‚ä¸­ã€‚çœ‹

è§ Section

F.1 å¯¹äº WebNLG ä¸Šçš„

ç»“æœ(Gardent

et al.,2017)å’Œé£é•–

(Nan et al.,2020).æˆ‘

ä»¬ åŒ… æ‹¬ äº†

ä¸­

ä½¿ ç”¨ çš„ è¶…

å‚

æ•° åˆ— è¡¨ Section

2

D.3.

2

2

Model&Method # Trainable

Parameters

WikiSQL MNLI- m SAMSum

Acc. (%) Acc. (%)

R1/R2/RL

æ¨¡

å‹å’Œæ–¹æ³• #å¯

è®­ç»ƒ

å› ç´ 

W i k i

S Q L MNLI-m

è¨

å§†è¨å§† 

Accã€‚(%)

Accã€‚(%) R1/R2/æ³•å›½

GPT-3 (FT) 175,255.8M

73.8 89.5 52.0/28.0/44.5

GPT-3

(BitFit) 14.2M 71.3 91.0

51.3/27.4/43.5

GPT-3 (PreEmbed) 3.2M

63.1 88.6 48.3/24.2/40.5

GPT-3

(PreLayer) 20.2M 70.1 89.5

50.8/27.3/43.5

GPT-3 (AdapterH

)

7.1M 71.9 89.8 53.0/28.9/44.8

GPT-3 (AdapterH

) 40.1M

73.2 91.5 53.2/29.0/45.1

GPT-3

è‹±å°º 175255.8 ç±³ 73.

8

89.5 52.0/28.0/44.

5

GPT ä¸‰å·

14.2 ç±³ 71.

3

91.0 51.3/27.4/43.

5

GPT-3(é¢„åµŒå…¥) 3.2 ç±³

63.

1

88.6 48.3/24.2/40.

5

GPT-3(é¢„å±‚)

20.2 ç±³ 70.

1

89.5 50.8/27.3/43.

5

GPT

3 å·(é€‚

é…å™¨ h) 7.1

ç±³ 71.

9

89.8

53.0/28.9/44.

8

GPT 3

å·(é€‚

é…å™¨ h) 40.1 ç±³

73.

2

91.5 53.2/29.0/45.

1

GPT-3 (LoRA) 4.7M

73.4 91.7 53.8/29.8/45.9

GPT-3

(LoRA) 37.7M 74.0 91.6

53.4/29.2/45.1

GPT ä¸‰å·

4.7 ç±³

73.

4

91.7 53.8/29.8/45.

9

GPT ä¸‰å· 37.7

ç±³ 74.

0

91.6

53.4/29.2/45.

1

Table 4:

Performance of different adaptation

methods on GPT-3 175B.

We report the logical

form

validation accuracy on

WikiSQL, validation accuracy on

MultiNLI-matched, and Rouge-1/2/L on

SAMSum. LoRA performs better

than prior approaches, including

full fine-tuning. The results

on WikiSQL have a

fluctuation around Â±0.5%, MNLI-m

around Â±0.1%, and SAMSum

around

è¡¨

4:ä¸åŒé€‚åº”æ–¹

æ³•åœ¨ GPT-3 175B

ä¸Šçš„æ€§

èƒ½ã€‚æˆ‘ä»¬æŠ¥å‘Š

äº† WikiSQL ä¸Šçš„é€»è¾‘

å½¢å¼éªŒè¯å‡†

ç¡®

æ€§ã€MultiNLI-matched

ä¸Šçš„éªŒ

è¯å‡†ç¡®æ€§ä»¥

åŠ SAMSum ä¸Šçš„ Rouge-1/2/Lã€‚LoRA

æ¯”ä»¥

å‰çš„æ–¹æ³•

è¡¨

ç°å¾—æ›´å¥½ï¼ŒåŒ…

æ‹¬å®Œå…¨å¾®è°ƒ

ã€‚ WikiSQL ä¸Šçš„ç»“æœæ³¢

åŠ¨åœ¨

0.5%å·¦å³ï¼ŒMNLI-m åœ¨

0.1%å·¦

å³ï¼ŒSAMSum åœ¨

0.5%å·¦å³

Â±0.2/Â±0.2/Â±0.1 for the three

metrics.

ä¸‰ä¸ªæŒ‡æ ‡çš„

0.2/ 0.2/ 0.1ã€‚

10.9 SCALING UP TO

GPT-3 175B

10.10 å‡çº§åˆ°

GPT-3 175B

As a

final stress test for

LoRA, we scale up

to GPT-3 with 175

billion parameters. Due to

the high

training cost,

we only report the

typical standard deviation for

a given task over

random seeds, as

opposed

to providing one for

every entry. See Section

D.4 for details on

the hyperparameters used.

ä½œä¸º

å¯¹

LoRA çš„æœ€åä¸€

æ¬¡å‹åŠ›æµ‹è¯•

ï¼Œæˆ‘ä»¬æ‰©å¤§åˆ°

æ‹¥æœ‰ 1750 äº¿ä¸ªå‚

æ•°çš„

GPT-3ã€‚ç”±äºåŸ¹

è®­æˆæœ¬

é«˜ï¼Œæˆ‘

ä»¬åªæŠ¥å‘Šç»™

å®šä»»åŠ¡çš„éš

æœºç§å­çš„å…¸

å‹æ ‡å‡†å·®ï¼Œè€Œ

ä¸æ˜¯ä¸ºæ¯ä¸ª

æ¡ç›®æä¾›ä¸€

ä¸ªã€‚çœ‹è§

Section D.4

æœ‰å…³

æ‰€ç”¨è¶…å‚æ•°

çš„è¯¦ç»†ä¿¡æ¯

ã€‚

As shown in

Table 4, LoRA matches

or exceeds the fine-tuning

baseline on all three

datasets. Note

2

that

not all methods benefit

monotonically from having more

trainable parameters, as shown

in

Fig- ure 2.

We observe a significant

performance drop when we

use more than 256

special tokens

for prefix-embedding

tuning or more than

32 special tokens for

prefix-layer tuning. This

corroborates

similar observations in Li

& Liang (2021). While

a thorough investigation into

this

phenomenon is out-of-scope

for this work, we

suspect that having more

special tokens causes the

input distri- bution to

shift further away from

the pre-training data distribution.

Separately, we

investigate the

performance of different adaptation

approaches in the low-data

regime in Section

F.3.

å¦‚æ‰€ç¤º Table 4,LoRA åŒ¹é…

æˆ–è¶…è¿‡æ‰€æœ‰

ä¸‰ä¸ªæ•°æ®é›†

çš„å¾®è°ƒåŸºçº¿

ã€‚æ³¨æ„ï¼Œå¹¶ä¸æ˜¯

æ‰€æœ‰çš„æ–¹æ³•

éƒ½

å•è°ƒåœ°å—

ç›Šäºæ›´å¤šçš„

å¯è®­ç»ƒå‚æ•°

ï¼Œå¦‚ Fig-ure 2.å½“ æˆ‘

ä»¬ ä½¿

ç”¨ 2 5

6 ä¸ª ä»¥ ä¸Š

çš„

ç‰¹ æ®Š æ ‡ è®°

è¿›

è¡Œ å‰ ç¼€ åµŒ

å…¥

è°ƒ ä¼˜ ï¼Œ æˆ–

è€… ä½¿

ç”¨ 3 2

ä¸ª ä»¥ ä¸Š çš„

ç‰¹

æ®Š æ ‡ è®° è¿›

è¡Œ

å‰ ç¼€ å±‚ è°ƒ

ä¼˜

æ—¶ ï¼Œ æˆ‘

ä»¬

è§‚

å¯Ÿ åˆ° äº† æ˜¾

è‘—

çš„ æ€§ èƒ½ ä¸‹

é™

ã€‚ è¿™ è¯ å®

äº† ç±»

ä¼¼ çš„ è§‚

å¯Ÿ ç»“

æœ Li &

Liang(2021).è™½

ç„¶ å¯¹ è¿™

ç§

ç° è±¡ çš„ å½»

åº•

è°ƒ æŸ¥ è¶… å‡º

äº†

è¿™ é¡¹ å·¥ ä½œ

çš„

èŒƒ å›´ ï¼Œ ä½†

æˆ‘

ä»¬ æ€€ ç–‘ æœ‰

æ›´

å¤š çš„ ç‰¹ æ®Š

æ ‡

è®° ä¼š å¯¼ è‡´

è¾“

å…¥ åˆ† å¸ƒ è¿›

ä¸€

æ­¥ å ç¦» è®­

ç»ƒ

å‰ çš„ æ•° æ®

åˆ†

å¸ƒ ã€‚ å¦ å¤–

ï¼Œ æˆ‘ ä»¬

ç ” ç©¶

äº† ä¸ åŒ

çš„ é€‚

åº” æ–¹ æ³•

åœ¨ ä½

æ•° æ® åŒº

çš„ æ€§

èƒ½ Section F.3.

0.75

0.75

WikiSQL WikiS

QL

2

Method

Fine-Tune PrefixEmbed

PrefixLayer Adapter(H) Method LoRA

Fine-Tune PrefixEmbed PrefixLayer Adapter(H)

LoRA

0.92

0.92

Multi

NLIï¿¾mat

ched

å¤šå…ƒ

åŒ¹é…çš„

0.70

0.70

Validation Validation

0.90

0.90

0.65

0.65

2

0.88

0.88

0.60

0.60

0.55

0.55

2

2

0.86

0.86 0.84

0.84

6 7 8 9

10 11

6 ä¸ƒ

8 9 10 11

log10 # Trainable Parameters

log10 #å¯

è®­ç»ƒå‚æ•°

2

6

7 8 9 10

11

6 ä¸ƒ

8 9

10 11

log10 #

Trainable Parameters

log10 #å¯è®­ç»ƒå‚æ•°

Figure

2: GPT-3 175B validation

accuracy vs. number of

trainable parameters of several

adaptation methods on WikiSQL

and MNLI-matched. LoRA exhibits

better scalability and task

performance. See Section F.2

for more details on

the plotted data points.

å›¾ WikiSQL å’Œ MNLI-matched

ä¸Šå‡ ç§

è‡ªé€‚åº”æ–¹æ³•

çš„ GPT-3 175B éªŒè¯å‡†ç¡®

æ€§ä¸å¯è®­ç»ƒ

å‚æ•°æ•°

é‡çš„

å…³ç³»ã€‚LoRA å±•ç°äº†

æ›´å¥½çš„å¯æ‰©

å±•æ€§å’Œä»»åŠ¡

æ€§èƒ½ã€‚çœ‹è§ Section F.2

æœ‰

å…³ç»˜åˆ¶çš„æ•°

æ®ç‚¹

çš„æ›´å¤š

è¯¦ç»†ä¿¡æ¯ã€‚

11 RELATED

WORKS

12 ç›¸

å…³ä½œå“

Transformer

Language Models. Transformer (Vaswani

et al., 2017) is

a sequence-to-sequence

architecture that

makes heavy use of

self-attention. Radford et al.

(a) applied it to

autoregressive

lan- guage modeling

by using a stack

of Transformer decoders. Since

then, Transformer-based

language models

have dominated NLP, achieving

the state-of-the-art in many

tasks. A new

paradigm

emerged with BERT (Devlin

et al., 2019b) and

GPT-2 (Radford et al.,

b) â€“ both are

large Transformer lan-

å˜å‹

å™¨è¯­è¨€æ¨¡å‹

ã€‚å˜å‹å™¨(Vaswani

et al.,2017)æ˜¯ä¸€

ç§åºåˆ—åˆ°åº

åˆ—æ¶æ„ï¼Œå®ƒå¤§

é‡ä½¿ç”¨è‡ªæˆ‘

å…³æ³¨ã€‚Radford et al.(a)é€šè¿‡ä½¿

ç”¨ä¸€å †è½¬æ¢

å™¨è§£ç å™¨å°†

å…¶åº”ç”¨äºè‡ª

å›å½’è¯­è¨€å»º

æ¨¡ã€‚ä»é‚£æ—¶èµ·

ï¼Œ

åŸºäº Transformer çš„è¯­è¨€

æ¨¡å‹å°±ä¸»å¯¼

äº† NLPï¼Œåœ¨è®¸å¤šä»»

åŠ¡ä¸­å®ç°äº†

æœ€å…ˆè¿›çš„æŠ€

æœ¯ã€‚ä¼¯ç‰¹å¸¦æ¥

äº†ä¸€

ç§æ–°çš„

èŒƒå¼(Devlin et al.,2019b)å’Œ GPT-2(Radford

et al.,b)â€“ä¸¤è€…

éƒ½æ˜¯å¤§å‹å˜

å‹å™¨å±€

åŸŸç½‘

-

guage

models trained on a

large amount of text

â€“ where fine-tuning on

task-specific data after preï¿¾training

on general domain data

provides a significant performance

gain compared to training

on

task-specific data directly.

Training larger Transformers generally

results in better performance

and remains an active

research direction. GPT-3 (Brown

et al., 2020) is

the largest single

Transformer

language model trained to-date

with 175B parameters.

åœ¨å¤§é‡æ–‡æœ¬

ä¸Šè®­ç»ƒçš„é‡

è§„æ¨¡å‹â€”â€”ä¸ç›´

æ¥åœ¨ç‰¹å®šä»»

åŠ¡æ•°æ®ä¸Šè®­

ç»ƒç›¸æ¯”ï¼Œåœ¨å¯¹

ä¸€èˆ¬é¢†åŸŸæ•°

æ®

è¿›è¡Œé¢„è®­

ç»ƒä¹‹åï¼Œå¯¹ç‰¹

å®šä»»åŠ¡æ•°æ®

è¿›è¡Œå¾®è°ƒå¯

ä»¥æä¾›æ˜¾è‘—

çš„æ€§èƒ½å¢ç›Š

ã€‚è®­ç»ƒæ›´å¤§çš„

å˜å‹å™¨

é€šå¸¸

ä¼šäº§ç”Ÿæ›´å¥½

çš„æ€§èƒ½ï¼Œå¹¶ä¸”

ä»ç„¶æ˜¯ä¸€ä¸ª

æ´»è·ƒçš„ç ”ç©¶

æ–¹å‘ã€‚GPT-3(Brown et al.,2020)æ˜¯

è¿„ä»Š

ä¸ºæ­¢ç”¨ 175B å‚æ•°

è®­ç»ƒçš„æœ€å¤§

çš„å•ä¸ª Transformer

è¯­è¨€

æ¨¡å‹ã€‚

Prompt Engineering and

Fine-Tuning. While GPT-3 175B

can adapt its behavior

with just a

few

additional training examples, the

result depends heavily on

the input prompt (Brown

et al.,

2020). This

necessitates an empirical art

of composing and formatting

the prompt to maximize

a

modelâ€™s performance on

a desired task, which

is known as prompt

engineering or prompt hacking.

Fine-tuning retrains a model

pre-trained on general domains

to a specific task

Devlin et al.

(2019b);

Radford et al. (a).

Variants of it include

learning just a subset

of the parameters Devlin

et

al. (2019b); Collobert

& Weston (2008), yet

practitioners often retrain all

of them to maximize

the

downstream performance. However,

the enormity of GPT-3

175B makes it challenging

to perform

fine-tuning in

the usual way due

to the large checkpoint

it produces and the

high hardware barrier

to

entry since it has

the same memory footprint

as pre-training.

å¿«é€Ÿå·¥

ç¨‹å’Œå¾®è°ƒã€‚è™½

ç„¶ GPT-3

175B å¯ä»¥ä»…é€š

è¿‡å‡ ä¸ªé¢å¤–

çš„è®­ç»ƒç¤ºä¾‹

æ¥è°ƒæ•´å…¶è¡Œ

ä¸ºï¼Œä½†æ˜¯ç»“

æœ

ä¸¥é‡ä¾èµ–äº

è¾“å…¥æç¤º(Brown et

al.,2020).è¿™

å°± éœ€ è¦ ä¸€

ç§

ç» éªŒ è‰º æœ¯

æ¥

ç»„ åˆ å’Œ æ ¼

å¼

åŒ– æ ç¤º ï¼Œ

ä»¥ æœ€

å¤§ åŒ– æ¨¡

å‹ åœ¨

æœŸ æœ› ä»»

åŠ¡ ä¸Š

çš„ æ€§ èƒ½

ï¼Œ è¿™ å°±

æ˜¯ æ‰€

è°“ çš„ æ

ç¤º å·¥

ç¨‹ æˆ– æ

ç¤º

ç ´

è§£ ã€‚ å¾® è°ƒ

å°†

é¢„ å…ˆ åœ¨ ä¸€

èˆ¬

é¢† åŸŸ è®­ ç»ƒ

çš„

æ¨¡ å‹ é‡ æ–°

è®­

ç»ƒ åˆ° ç‰¹ å®š

ä»»

åŠ¡ Devlin et al.

(2019b);Radford et al.(a). å®ƒ

çš„ å˜

ä½“ åŒ… æ‹¬

ä»… å­¦

ä¹  å‚ æ•°

çš„ å­

é›† Devlin et

al.

(2019b);Collobert & Weston(2008),ç„¶è€Œï¼Œä»ä¸š

è€…ç»å¸¸é‡æ–°

åŸ¹è®­ä»–ä»¬æ‰€

æœ‰äººï¼Œä»¥æœ€å¤§

é™åº¦

åœ°æé«˜

ä¸‹æ¸¸æ€§èƒ½ã€‚ç„¶

è€Œï¼ŒGPT-3 175B çš„åºå¤§ä½¿

å¾—ä»¥é€šå¸¸çš„

æ–¹å¼æ‰§è¡Œå¾®

è°ƒå…·æœ‰æŒ‘æˆ˜

æ€§ï¼Œå› ä¸º

å®ƒäº§

ç”Ÿäº†å¤§çš„æ£€

æŸ¥ç‚¹å’Œé«˜çš„

ç¡¬ä»¶è¿›å…¥å£

å’ï¼Œå› ä¸ºå®ƒå…·

æœ‰ä¸é¢„è®­ç»ƒ

ç›¸åŒçš„å†…å­˜

å ç”¨é‡ã€‚

Parameter-Efficient Adaptation. Many have

proposed inserting adapter layers

between

existing layers in

a neural network (Houlsby

et al., 2019; Rebuffi

et al., 2017; Lin

et al., 2020).

Our

method uses a similar

bottleneck structure to impose

a low-rank constraint on

the weight

updates. The

key functional difference is

that our learned weights

can be merged with

the main

weights during

inference, thus not introducing

any latency, which is

not the case for

the adapter

layers (Section

3). A comtenporary extension

of adapter is COMPACTER

(Mahabadi et al., 2021),

which essentially parametrizes the

adapter layers using Kronecker

products with some

predetermined

weight sharing scheme. Similarly,

combining LoRA with other

tensor productï¿¾based methods could

potentially improve its parameter

efficiency, which we leave

to future work.

More

recently, many proposed optimizing

the input word embeddings

in lieu of fine-tuning,

akin

to a continuous

and differentiable generalization of

prompt engineering (Li &

Liang, 2021; Lester

et

al., 2021; Hambardzumyan et

al., 2020; Liu et

al., 2021). We include

comparisons with Li &

Liang (2021) in our

experiment section. However, this

line of works can

only scale up by

using

more special tokens

in the prompt, which

take up available sequence

length for task tokens

when

positional embeddings are

learned.

å‚æ•°

é«˜æ•ˆè‡ªé€‚åº”

ã€‚è®¸å¤šäººæå‡º

åœ¨ç¥ç»ç½‘ç»œ

çš„ç°æœ‰å±‚ä¹‹

é—´æ’å…¥é€‚é…

å™¨å±‚ (Houlsby et

al.,2019;Rebuffi et al.,2017;Lin et

al.,2020).æˆ‘ä»¬çš„

æ–¹æ³•ä½¿ç”¨ç±»

ä¼¼çš„ç“¶é¢ˆç»“

æ„å¯¹æƒ

é‡æ›´

æ–°æ–½åŠ ä½ç§©

çº¦æŸã€‚å…³é”®çš„

åŠŸèƒ½å·®å¼‚æ˜¯

ï¼Œæˆ‘ä»¬å­¦ä¹ çš„

æƒé‡å¯ä»¥åœ¨

æ¨æ–­è¿‡ç¨‹ä¸­

ä¸ä¸»æƒé‡åˆ

å¹¶ï¼Œå› æ­¤ä¸ä¼š

å¼•å…¥ä»»ä½•å»¶

è¿Ÿï¼Œè€Œé€‚é…å™¨

å±‚ä¸ä¼šå‡ºç°

è¿™ç§æƒ…å†µ(Section3).é€‚

é…å™¨çš„å½“ä»£

æ‰©å±•

æ›´ç´§å‡‘

(Mahabadi et

al.,2021),å…¶æœ¬è´¨ä¸Šä½¿

ç”¨å…·æœ‰æŸç§

é¢„å®šæƒé‡å…±

äº«æ–¹æ¡ˆçš„ Kronecker ç§¯

æ¥å‚æ•°åŒ–é€‚

é…å™¨å±‚ã€‚ç±»ä¼¼

åœ°ï¼Œå°† LoRA

ä¸å…¶ä»–

åŸºäºå¼ é‡ç§¯

çš„æ–¹æ³•ç›¸ç»“

åˆå¯èƒ½ä¼šæ

é«˜å…¶å‚æ•°æ•ˆ

ç‡ï¼Œè¿™ä¸€ç‚¹æˆ‘

ä»¬ç•™ç»™æœªæ¥

çš„å·¥ä½œã€‚æœ€è¿‘

ï¼Œè®¸å¤šäººæå‡º

ä¼˜åŒ–è¾“å…¥å•

è¯åµŒå…¥æ¥ä»£

æ›¿å¾®è°ƒï¼Œç±»ä¼¼

äº æ ç¤º å·¥

ç¨‹

çš„ è¿ ç»­ å’Œ

å¯

å¾® åˆ† çš„ ä¸€

èˆ¬

åŒ– (Li & Liang,2021;Lester

et

al.,2021;Hambardzumyan et al.,2020;Liu

et al.,2021).æˆ‘ä»¬åŒ…æ‹¬

ä¸ä»¥ä¸‹å†…å®¹

çš„æ¯”è¾ƒ Li

&

Liang(2021)åœ¨æˆ‘

ä»¬çš„å®éªŒåŒº

ã€‚ç„¶è€Œï¼Œè¿™ä¸€ç³»

åˆ—å·¥ä½œåªèƒ½

é€šè¿‡åœ¨æç¤º

ä¸­ä½¿ç”¨æ›´å¤š

çš„ç‰¹æ®Šæ ‡

2

è®°

æ¥æ‰©å¤§è§„æ¨¡

ï¼Œè¿™äº›æ ‡è®°åœ¨

å­¦ä¹ ä½ç½®åµŒ

å…¥æ—¶ä¼šå ç”¨

ä»»åŠ¡æ ‡è®°çš„

å¯ç”¨åºåˆ—é•¿

åº¦ã€‚

Low-Rank

Structures in Deep Learning.

Low-rank structure is very

common in machine learnï¿¾ing.

A lot of machine

learning problems have certain

intrinsic low-rank structure (Li

et al., 2016;

Cai

et al., 2010; Li

et al., 2018b; Grasedyck

et al., 2013). Moreover,

it is known that

for many

deep learning

tasks, especially those with

a heavily over-parametrized neural

network, the learned

neural

network will enjoy low-rank

properties after training (Oymak

et al., 2019). Some

prior

works even explicitly

impose the low-rank constraint

when training the original

neural network

(Sainath et

al., 2013; Povey et

al., 2018; Zhang et

al., 2014; Jaderberg et

al., 2014; Zhao et

al.,

2016; Kho- dak

et al., 2021; Denil

et al., 2014); however,

to the best of

our knowledge, none of

these works considers low-rank

update to a frozen

model for adaptation to

downstream tasks. In

theory

liter- ature, it is

known that neural networks

outperform other classical learning

methods,

including the corresponding

(finite-width) neural tangent kernels

(Allen-Zhu et al., 2019;

Li &

Liang, 2018)

when the underlying concept

class has certain low-rank

structure (Ghorbani et al.,

2020; Allen-Zhu & Li,

2019; Allen-Zhu & Li,

2020a). Another theoretical result

in Allen-Zhu &

Li

(2020b) suggests that low-rank

adaptations can be useful

for adversarial training. In

sum, we

believe that

our proposed low-rank adaptation

update is well-motivated by

the literature.

æ·±åº¦å­¦ä¹ 

ä¸­çš„ä½ç§©ç»“

æ„ã€‚ä½ç§©ç»“æ„

åœ¨æœºå™¨å­¦ä¹ 

ä¸­éå¸¸æ™®é

ã€‚è®¸å¤šæœºå™¨å­¦

ä¹ é—®é¢˜éƒ½æœ‰

ä¸€å®šçš„

å†…

åœ¨

ä½ ç§© ç»“ æ„

(Li et al.,2016;Cai et

al.,2010;Li et al.,2018b;Grasedyck et

al.,2013).æ­¤

å¤– ï¼Œ ä¼— æ‰€

å‘¨ çŸ¥

ï¼Œ å¯¹ äº

è®¸ å¤š æ·±

åº¦ å­¦

ä¹  ä»» åŠ¡

ï¼Œ å°¤

å…¶ æ˜¯ é‚£ äº›

å…·

æœ‰ ä¸¥ é‡ è¿‡

åº¦

å‚ æ•° åŒ– çš„

ç¥

ç» ç½‘ ç»œ çš„

ä»»

åŠ¡ ï¼Œ æ‰€ å­¦

ä¹ 

çš„ ç¥ ç» ç½‘

ç»œ

åœ¨ è®­ ç»ƒ å

å°†

äº« æœ‰ ä½ ç§©

å±

æ€§

(Oymak et al.,2019).ä¸€äº›å…ˆå‰

çš„å·¥ä½œç”šè‡³

åœ¨è®­ç»ƒåŸå§‹

ç¥ç»ç½‘ç»œæ—¶

æ˜ç¡®åœ°æ–½åŠ 

ä½ç§©çº¦æŸ

(Sainathet al.,2013;Povey et al.,2018;Zhang

et al.,2014;Jaderberg et

al.,2014;Zhao

et al.,2016;Kho-dak et al.,2021;Denil

et al.,2014);ç„¶

è€Œï¼Œæ®æˆ‘ä»¬æ‰€

çŸ¥ï¼Œè¿™äº›å·¥ä½œ

éƒ½æ²¡æœ‰è€ƒè™‘

ä½ç§©æ›´æ–°å†»

ç»“æ¨¡å‹ï¼Œä»¥é€‚

åº”ä¸‹æ¸¸ä»»åŠ¡

ã€‚åœ¨ç†è®ºæ–‡çŒ®

ä¸­ï¼Œå·²çŸ¥ç¥ç»

ç½‘ ç»œ ä¼˜

äº å…¶

ä»– ç» å…¸

å­¦ ä¹ 

æ–¹ æ³• ï¼Œ

åŒ… æ‹¬ ç›¸

åº” çš„

( æœ‰ é™ å®½

åº¦

) ç¥ ç» æ­£

åˆ‡

æ ¸ (Allen-Zhu et

al.,2019;Li

& Liang,2018) å½“ åº•

å±‚ æ¦‚

å¿µ ç±» å…·

æœ‰ ä¸€

å®š çš„ ä½

ç§© ç»“

æ„ æ—¶ (Ghorbani

et

al.,2020;Allen-Zhu & Li,2019;Allen-Zhu

& Li,2020a).å¦ä¸€ä¸ª

ç†è®ºç»“æœæ˜¯

Allen-Zhu

& Li(2020b)è¡¨æ˜ä½ç­‰çº§

çš„é€‚åº”å¯¹äº

å¯¹æŠ—æ€§è®­ç»ƒ

æ˜¯æœ‰ç”¨çš„ã€‚æ€»

ä¹‹ï¼Œæˆ‘ä»¬è®¤ä¸º

æˆ‘ä»¬æå‡ºçš„

ä½ç§©

é€‚åº”æ›´

æ–°æ˜¯ç”±æ–‡çŒ®

å……åˆ†æ¿€å‘çš„

ã€‚

13 UNDERSTANDING THE

LOW-RANK UPDATES

14 äº†è§£ä½çº§åˆ«

æ›´æ–°

Given the empirical advantage

of LoRA, we hope

to further explain the

properties of the low-rank

adaptation learned from downstream

tasks. Note that the

low-rank structure not only

lowers the

hardware barrier

to entry which allows

us to run multiple

experiments in parallel, but

also gives

better interpretability

of how the update

weights are correlated with

the pre-trained weights. We

focus our study on

GPT-3 175B, where we

achieved the largest reduction

of trainable parameters

(up

to 10,000Ã—) without adversely

affecting task performances.

é‰´äº

LoRA çš„

ç»éªŒä¼˜åŠ¿ï¼Œæˆ‘

ä»¬å¸Œæœ›è¿›ä¸€

æ­¥è§£é‡Šä»ä¸‹

æ¸¸ä»»åŠ¡ä¸­å­¦

ä¹ åˆ°çš„ä½ç§©

é€‚åº”çš„æ€§è´¨

ã€‚è¯·æ³¨

æ„ï¼Œä½ç§©

ç»“æ„ä¸ä»…é™

ä½äº†å…è®¸æˆ‘

ä»¬å¹¶è¡Œè¿è¡Œ

å¤šä¸ªå®éªŒçš„

ç¡¬ä»¶å‡†å…¥é—¨

æ§›ï¼Œè¿˜æä¾›äº†

æ›´æ–°æƒé‡

å¦‚

ä½•ä¸é¢„è®­ç»ƒ

æƒé‡ç›¸å…³çš„

æ›´å¥½çš„å¯è§£

é‡Šæ€§ã€‚æˆ‘ä»¬æŠŠ

ç ”ç©¶é‡ç‚¹æ”¾

åœ¨

GPT-3 175B ä¸Šï¼Œåœ¨é‚£é‡Œ

æˆ‘

ä»¬å®ç°äº†

å¯è®­ç»ƒå‚æ•°

çš„æœ€å¤§ç¨‹åº¦

çš„å‡å°‘(é«˜è¾¾

10000

Ã—),è€Œæ²¡æœ‰å¯¹ä»»

åŠ¡æ€§èƒ½äº§ç”Ÿ

ä¸åˆ©å½±

å“ã€‚

We perform

a sequence of empirical

studies to answer the

following questions: 1) Given

a

parameter budget constraint,

which subset of weight

matrices in a pre-trained

Transformer

should we adapt

æˆ‘

ä»¬æ‰§è¡Œä¸€ç³»

åˆ—çš„å®è¯ç ”

ç©¶æ¥å›ç­”ä»¥

ä¸‹é—®é¢˜:1)ç»™å®š

ä¸€ä¸ªå‚æ•°é¢„

ç®—çº¦æŸï¼Œæˆ‘ä»¬

åº”è¯¥é‡‡ç”¨é¢„

è®­

ç»ƒè½¬æ¢å™¨

ä¸­çš„å“ªä¸ªæƒ

é‡çŸ©é˜µå­é›†

3

to maximize

downstream performance? 2) Is

the â€œoptimalâ€ adaptation matrix

âˆ†W really rankï¿¾deficient? If

so, what is a

good rank to use

in practice? 3) What

is the connection between

âˆ†W

and W ?

Does âˆ†W highly correlate

with W ? How

large is âˆ†W comparing

to W ?

æœ€å¤§åŒ–ä¸‹æ¸¸

æ€§èƒ½ï¼Ÿ2)â€œæœ€ä¼˜â€é€‚

åº”çŸ©é˜µâˆ†W

çœŸçš„

æ˜¯ç§©äºçš„å—

ï¼Ÿå¦‚æœæ˜¯è¿™æ ·

ï¼Œåœ¨å®è·µä¸­ä½¿

ç”¨ä»€

ä¹ˆæ ·çš„

ç­‰çº§æ¯”è¾ƒå¥½

ï¼Ÿ3)W å’Œ W

æœ‰ä»€ä¹ˆè”

ç³»ï¼ŸW ä¸ W é«˜åº¦ç›¸

å…³å—ï¼Ÿä¸

W ç›¸æ¯”

ï¼ŒW æœ‰å¤šå¤§ï¼Ÿ

We

believe that our answers

to question (2) and

(3) shed light on

the fundamental principles of

using pre-trained language models

for downstream tasks, which

is a critical topic

in NLP.

æˆ‘ä»¬

ç›¸ä¿¡ï¼Œæˆ‘ä»¬å¯¹

é—®é¢˜(2)å’Œ(3)çš„å›

ç­”é˜æ˜äº†ä½¿

ç”¨é¢„è®­ç»ƒè¯­

è¨€æ¨¡å‹è¿›è¡Œ

ä¸‹æ¸¸ä»»åŠ¡çš„

åŸºæœ¬åŸ

åˆ™ï¼Œè¿™

æ˜¯

NLP ä¸­çš„ä¸€ä¸ª

å…³é”®ä¸»é¢˜ã€‚

14.1 WHICH

WEIGHT MATRICES IN TRANSFORMER

SHOULD WE APPLY LORA

TO?

14.2 æˆ‘

ä»¬åº”è¯¥å¯¹å˜

å‹å™¨ä¸­çš„å“ª

äº›æƒé‡çŸ©é˜µ

åº”ç”¨ LORAï¼Ÿ

Given a limited parameter

budget, which types of

weights should we adapt

with LoRA to obtain

the best performance on

downstream tasks? As mentioned

in Section 4.2, we

only consider weight

matrices

in the self-attention module.

We set a parameter

budget of 18M (roughly

35MB if stored

in

FP16) on GPT-3 175B,

which corresponds to r

= 8 if we

adapt one type of

attention weights or

r

= 4 if we

adapt two types, for

all 96 layers. The

result is presented in

Table 5.

ç»™å®šä¸€

ä¸ªæœ‰é™çš„å‚

æ•°é¢„ç®—ï¼Œä¸ºäº†

åœ¨ä¸‹æ¸¸ä»»åŠ¡

ä¸­è·å¾—æœ€ä½³

æ€§èƒ½ï¼ŒLoRA åº”è¯¥é‡‡

ç”¨å“ªç§ç±»å‹

çš„æƒ

é‡ï¼Ÿå¦‚ä¸­

æ‰€è¿° Section 4.2,åœ¨è‡ªæˆ‘

å…³æ³¨æ¨¡å—ä¸­

ï¼Œæˆ‘ä»¬åªè€ƒè™‘

æƒé‡çŸ©é˜µã€‚æˆ‘

ä»¬åœ¨ GPT-3

175B

ä¸Šè®¾ç½®

äº† 18M(å¦‚æœå­˜å‚¨

åœ¨ FP16

ä¸­ï¼Œå¤§çº¦ 35MB)çš„

å‚æ•°é¢„ç®—ï¼Œå¯¹

äºæ‰€æœ‰ 96 å±‚ï¼Œå¦‚

æœæˆ‘ä»¬é‡‡

ç”¨

ä¸€ç§ç±»å‹çš„

æ³¨æ„åŠ›æƒé‡

ï¼Œè¿™å¯¹åº”äº r = 8ï¼Œæˆ–

è€…å¦‚æœæˆ‘ä»¬

é‡‡ç”¨ä¸¤ç§ç±»

å‹ï¼Œè¿™å¯¹åº”äº

r

=

4ã€‚ç»“æœæ˜¾ç¤ºåœ¨

ä¸­ Table 5.

# of Trainable Parameters

= 18M

Weight Type

Rank r

é‡é‡ç±»å‹

ç­‰

çº§

r

WikiSQL

(Â±0.5%)

ç»´åŸºç™¾

ç§‘(0.5%)

MultiNLI

(Â±0.1%)

MultiNLI

(

0.1%)

3

3

å¯è®­ç»ƒå‚

æ•°çš„æ•°é‡=

18M

Wq Wk Wv

Wo Wq,

Wk Wq,

Wv

Wq, Wk, Wv,

Wo

ä½“

é‡å•†æ•° å‘¨

Wv

å

Wqï¼ŒWkWqã€Wq

è¥¿éƒ¨ã€è¥¿éƒ¨ã€æ²ƒ

8 8 8

8 4 4 2

8 8 8 8

å›› å›› 2

70.4

70.0 73.0 73.2 71.4

73.7 73.7

70.4 70.0

73.0 73.2 71.4 73.7

73.7

91.0 90.8 91.0

91.3 91.3 91.3 91.7

91.0 90.8 91.0 91.3

91.3 91.3 91.7

3

{ }

{ }

Table 5: Validation accuracy

on WikiSQL and MultiNLI

after applying LoRA to

different types of

attention

weights in GPT-3, given

the same number of

trainable parameters. Adapting both

Wq

and Wv gives

the best performance overall.

We find the standard

deviation across random seeds

to be consistent for

a given dataset, which

we report in the

first column.

è¡¨ 5:åœ¨ç»™

å®šç›¸åŒæ•°é‡

çš„å¯è®­ç»ƒå‚

æ•°çš„æƒ…å†µä¸‹

ï¼Œå°†

LoRA åº”ç”¨äº GPT-3 ä¸­

ä¸åŒç±»å‹çš„

æ³¨æ„åŠ›æƒ

é‡

åï¼ŒWikiSQL å’Œ MultiNLI çš„éªŒè¯

å‡†ç¡®æ€§ã€‚åŒæ—¶

é‡‡ç”¨

Wq å’Œ Wv å¯ä»¥

è·å¾—æœ€ä½³çš„

æ•´ä½“æ€§èƒ½ã€‚

æˆ‘

ä»¬å‘ç°ï¼Œå¯¹äº

ç»™å®šçš„æ•°æ®

é›†ï¼Œéšæœºç§å­

çš„æ ‡å‡†å·®æ˜¯

ä¸€è‡´çš„ï¼Œæˆ‘ä»¬

åœ¨ç¬¬ä¸€åˆ—ä¸­

æŠ¥å‘Šäº†è¿™ä¸€

ç‚¹ã€‚

Note that putting

all the parameters in

âˆ†Wq or âˆ†Wk results

in significantly lower performance,

while adapting both Wq

and Wv yields the

best result. This suggests

that even a rank

of four

captures enough

information in âˆ†W such

that it is preferable

to adapt more weight

matrices than

adapting a

single type of weights

with a larger rank.

è¯·æ³¨æ„ï¼Œå°†

æ‰€æœ‰å‚æ•°æ”¾

åœ¨ Wq æˆ– Wk

ä¸­ä¼šå¯¼

è‡´æ˜æ˜¾è¾ƒä½

çš„æ€§èƒ½ï¼ŒåŒæ—¶

è°ƒæ•´ Wq å’Œ Wv

ä¼šäº§

ç”Ÿæœ€ä½³

ç»“æœ

ã€‚è¿™è¡¨æ˜ï¼Œå³ä½¿

ç§©ä¸º 4 ä¹Ÿèƒ½åœ¨

W

ä¸­æ•è·è¶³å¤Ÿ

çš„ä¿¡æ¯ï¼Œå› æ­¤

é‡‡ç”¨æ›´å¤šçš„

æƒé‡çŸ©é˜µæ¯”

é‡‡ç”¨

ç§©æ›´å¤§

çš„å•ä¸€ç±»å‹

çš„æƒé‡æ›´å¯

å–ã€‚

14.3 WHAT

IS THE OPTIMAL RANK

r FOR LORA?

14.4

LORA çš„æœ€ä½³ç§©

r æ˜¯å¤šå°‘ï¼Ÿ

We

turn our attention to

the effect of rank

r on model performance.We

adapt {Wq, Wv},

æˆ‘ä»¬

å°†æ³¨æ„åŠ›è½¬

å‘ç§©

r å¯¹æ¨¡å‹

æ€§èƒ½çš„å½±å“

ã€‚æˆ‘ä»¬é€‚åº”{Wqï¼Œè¥¿

å¼—å‰å°¼äºšå·

}ï¼Œ

{Wq, Wk,

Wv, Wc}, and just

Wq for a comparison.

{Wqï¼ŒWkï¼ŒWvï¼ŒWc}ï¼Œåªæ¯”è¾ƒ Wqã€‚

Weight Type

r = 1 r

= 2 r =

4 r = 8

r = 64

é‡é‡

ç±»å‹

r = 1 r

= 2 r =

4 r = 8

r = 64

WikiSQL(Â±0.5%)

Wq

Wq, Wv

Wq,

Wk, Wv,

Wo

68.8

73.4

74.1

69.6

73.3

73.7

70.5

73.7

74.0

70.4

73.8

74.0

70.0

73.5

73.9

ç»´åŸºç™¾

ç§‘(0.5%) ä½“é‡å•†æ•°

è¥¿å¼—å‰å°¼äºš

å·

Wq

Wqï¼ŒWkï¼ŒWvï¼ŒWo

68.8

73.4

74.1

69.6

73.3

73.7

70.5

73.7

74.0

70.4

73.8

74.0

70.0

73.5

73.9

MultiNLI (Â±0.1%)

Wq

Wq, Wv

Wq, Wk,

Wv,

Wo

90.7

91.3

91.2

90.9

91.4

91.7

91.1

91.3

91.7

90.7

91.6

91.5

90.7

91.4

91.4

MultiNLI ( 0.1%)

ä½“é‡å•†æ•°

è¥¿å¼—å‰å°¼äºš

å· Wq

Wqï¼ŒWkï¼ŒWvï¼ŒWo

90.7

91.3

91.2

90.9

91.4

91.7

91.1

91.3

91.7

90.7

91.6

91.5

90.7

91.4

91.4

Table 6:

Validation accuracy on WikiSQL

and MultiNLI with different

rank r. To our

surprise, a

rank as

small as one suffices

for adapting both Wq

and Wv on these

datasets while training Wq

alone needs a larger

r. We conduct a

similar experiment on GPT-2

in Section H.2.

è¡¨

6:å…·æœ‰ä¸

åŒç§© r çš„ WikiSQL

å’Œ MultiNLI ä¸Š

çš„éªŒè¯å‡†ç¡®

æ€§ã€‚ä»¤æˆ‘ä»¬æƒŠ

è®¶çš„æ˜¯ï¼Œå°è‡³

1 çš„ç§©

è¶³ä»¥é€‚

åº”è¿™äº›æ•°æ®

é›†ä¸Šçš„ Wq å’Œ Wvï¼Œè€Œ

å•ç‹¬è®­ç»ƒ

Wq éœ€

è¦æ›´å¤§çš„ rSection H.2.

Table 6 shows that,

surprisingly, LoRA already performs

competitively with a very

small r (more

so

for Wq, Wv than

just Wq). This suggests

the update matrix âˆ†W

could have a very

small

â€œintrinsic rankâ€.6 To

further support this finding,

we check the overlap

of the subspaces learned

by

different choices of

r and by different

random seeds. We argue

that increasing r does

not cover a

more

meaningful subspace, which suggests

that a low-rank adaptation

matrix is sufficient.

Table

6 æ˜¾

ç¤ºï¼Œä»¤äººæƒŠè®¶

çš„æ˜¯ï¼ŒåŠ³æ‹‰å·²

ç»è¡¨ç°å‡ºå¾ˆ

å°çš„ç«äº‰åŠ›

(æ¯” Wq æ›´é€‚åˆ

Wqï¼Œè¥¿

å¼—å‰å°¼

3

äºšå·

)ã€‚è¿™è¡¨æ˜æ›´æ–°

çŸ©é˜µ W

å¯èƒ½å…·

æœ‰éå¸¸å°çš„

â€œå›ºæœ‰ç§©â€ã€‚6ä¸ºäº†

è¿›ä¸€æ­¥æ”¯æŒ

è¿™ä¸€å‘ç°ï¼Œ

æˆ‘

ä»¬æ£€æŸ¥äº†é€š

è¿‡ä¸åŒçš„ r é€‰

æ‹©å’Œä¸åŒçš„

éšæœºç§å­å­¦

ä¹ çš„å­ç©ºé—´

çš„é‡å ã€‚æˆ‘ä»¬

è®¤ä¸º

å¢åŠ  r å¹¶

ä¸è¦†ç›–æ›´æœ‰

æ„ä¹‰çš„å­ç©º

é—´ï¼Œè¿™è¡¨æ˜ä½

ç§©é€‚åº”çŸ©é˜µ

æ˜¯è¶³å¤Ÿçš„ã€‚

6However,

we do not expect

a small r to

work for every task

or dataset. Consider the

following thought

experiment: if

the downstream task were

in a different language

than the one used

for pre-training, retraining

the

entire model (similar to

LoRA with r =

dmodel) could certainly outperform

LoRA with a small

r.

6 ç„¶

è€Œï¼Œæˆ‘ä»¬å¹¶ä¸

æœŸæœ›å° r

é€‚ç”¨

äºæ¯ä¸ªä»»åŠ¡

æˆ–æ•°æ®é›†ã€‚è€ƒ

è™‘ä¸‹é¢çš„æ€

ç»´å®éªŒ:å¦‚æœ

ä¸‹æ¸¸ä»»åŠ¡ä½¿

ç”¨çš„è¯­è¨€ä¸

åŒäºé¢„è®­ç»ƒ

æ‰€ä½¿ç”¨çš„è¯­

è¨€ï¼Œé‚£ä¹ˆé‡æ–°

è®­ç»ƒæ•´ä¸ªæ¨¡

å‹(ç±»ä¼¼äº r =

dmodel

çš„

LoRA)è‚¯å®šä¼šä¼˜äº

r è¾ƒå°çš„ LoRAã€‚

3

Subspace similarity between different

r. Given Ar=8 and

Ar=64 which are the

learned adaptaï¿¾tion matrices with

rank r = 8

and 64 using the

same pre-trained model, we

perform singular value

ä¸åŒ

r

ä¹‹é—´çš„å­ç©º

é—´ç›¸ä¼¼æ€§ã€‚ç»™

å®š Ar=8 å’Œ Ar=64ï¼Œå®ƒä»¬æ˜¯

ä½¿ç”¨ç›¸åŒé¢„

è®­ç»ƒæ¨¡å‹çš„

ç§©

r=8 å’Œ 64

çš„å­¦ä¹ 

é€‚åº”çŸ©é˜µï¼Œæˆ‘

ä»¬æ‰§è¡Œå¥‡å¼‚

å€¼

decomposition and obtain the

right-singular unitary matrices UA

åˆ†è§£å¹¶å¾—

åˆ°å³å¥‡å¼‚é…‰

çŸ©é˜µ UA

r=8

r=8

an

d

U

A

å’Œ UA

3

â‰¤

â‰¤

â‰¤â‰¤

â‰¤

â‰¤

r=

64

r=6

4

.

7 We

hope

to

an- ã€‚7æˆ‘ ä»¬

å¸Œ

æœ› -

swer: how

much of the subspace

spanned by the top

i singular vectors in

UAr=8 (for 1 i

8) is

contained in

the subspace spanned by

top j singular vectors

of UAr=64 (for 1j64)?

We mea- sure

this

quantity with a normalized

subspace similarity based on

the Grassmann distance (See

Apï¿¾pendix G for a

more formal discussion)

swer:UAr

= 8(å¯¹äº 1 i

8)çš„

å‰ I ä¸ªå¥‡å¼‚å‘

é‡æ‰€è·¨è¶Šçš„

å­ç©ºé—´æœ‰å¤š

å°‘åŒ…å«åœ¨ UAr=64(å¯¹

äº

1j64)çš„å‰ j ä¸ªå¥‡

å¼‚å‘é‡æ‰€è·¨

è¶Šçš„å­ç©ºé—´

ä¸­ï¼Ÿæˆ‘ä»¬ç”¨åŸº

äºæ ¼æ‹‰æ–¯æ›¼

è·ç¦»çš„å½’ä¸€

åŒ–å­ç©ºé—´ç›¸

ä¼¼

æ€§æ¥æµ‹é‡

è¿™ä¸ªé‡(å‚è§

Ap-pendix

G æ›´æ­£å¼çš„è®¨

è®º)

i> j

2

æˆ‘> j 2

Ï†(A

Ï†(A

r=

8

r=8

, Ar=64 ï¼ŒAr=64

3

Ar

Ar

,

i, j) =

||UAr=8

UAr=64

||F ï¼Œï¼ŒI

j)

= ||

UAr=

8

UAr=

64

||F

min(

,

æœ€å°

(I

j)

âˆˆ [0, 1] (4)

âˆˆ [0, 1] (4)

where

Ui

å“ª

é‡Œ Ui

represents the columns of

UA

è¡¨

ç¤º

U

A

çš„

åˆ—

r=8

3

Â·

Â·

Wq Wv

Wq Wv

Wq Wv

Wq Wv

r=8

corresponding

to the top-i

singular

vectors.

å¯¹

åº”

äºå‰

I ä¸ª

å¥‡å¼‚å‘é‡ã€‚

Ï†( )

has a range of

[0, 1], where 1

represents a complete overlap

of subspaces and 0

a complete

separation. See

Figure 3 for how

Ï† changes as we

vary i and j.

We only look at

the 48th layer

(out

of 96) due to

space constraint, but the

conclusion holds for other

layers as well, as

shown

in Section H.1.

Ï†()çš„

å–å€¼èŒƒå›´ä¸º

[0ï¼Œ1]ï¼Œå…¶ä¸­ 1 è¡¨ç¤ºå­

ç©ºé—´çš„å®Œå…¨

é‡å ï¼Œ0 è¡¨ç¤ºå®Œ

å…¨åˆ†ç¦»ã€‚çœ‹è§

Figure

3 ç”±äºç©ºé—´é™

åˆ¶ï¼Œæˆ‘ä»¬åªæŸ¥

çœ‹ç¬¬ 48 å±‚(å…±

96 å±‚

),ä½†ç»“è®ºåŒæ ·

é€‚ç”¨äºå…¶ä»–

å±‚ï¼Œå¦‚æ‰€ç¤º

Section H.1.

(Ar = 64, Ar

= 8, i, j)

(Ar = 64ï¼ŒAr =

8ï¼ŒIï¼Œj)

1.0

1.0

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

0.0

1 2 3

4 5 6 7

8

1 2 3

4 5 6 7

8

j j

j

j j

j

1

2 3 4 5

6 7 8

i

i

1

6

1

2

1

8

2

3

2

9

3

1

6

1

2

1

8

2

3

2

9

3

1

6

1

2

1

8

2

3

2

9

3

1

6

1

2

1

8

2

3

2

9

3

3

1 2

3 4 5 6

7 8

j

j

Figure 3: Subspace similarity

between column vectors of

Ar=8 and Ar=64 for

both âˆ†Wq and âˆ†Wv.

The third and the

fourth figures zoom in

on the lower-left triangle

in the first two

figures. The top

directions

in r = 8

are included in r

= 64, and vice

versa.

å›¾

3:å¯¹äº Wq å’Œ

Wvï¼ŒAr=8 å’Œ Ar=64 çš„

åˆ—å‘é‡ä¹‹é—´

çš„å­ç©ºé—´ç›¸

ä¼¼æ€§ã€‚ç¬¬ä¸‰å’Œ

ç¬¬å››ä¸ªå›¾å½¢

æ”¾å¤§

å‰ä¸¤ä¸ª

å›¾å½¢çš„å·¦ä¸‹

è§’ä¸‰è§’å½¢ã€‚r = 8 ä¸­

çš„é¡¶éƒ¨æ–¹å‘

åŒ…å«åœ¨

r = 64 ä¸­ï¼Œå

ä¹‹äº¦ç„¶ã€‚

We make an important

observation from Figure 3.

æˆ‘ä»¬

è§‚å¯Ÿåˆ°ä¸€ä¸ª

é‡è¦çš„ç°è±¡

Figure 3.

Directions corresponding

to the top singular

vector overlap significantly between

Ar=8 and Ar=64, while

others do not. Specifically,

âˆ†Wv (resp. âˆ†Wq) of

Ar=8

and âˆ†Wv (resp.

âˆ†Wq) of Ar=64 share

a subspace of dimension

1 with normalized

similarity

> 0.5, providing an

explanation of why r

= 1 performs quite

well in our

downstream

tasks for GPT-3.

å¯¹åº”äºé¡¶éƒ¨

å¥‡å¼‚å‘é‡çš„

æ–¹å‘åœ¨

Ar=8 å’Œ Ar=64 ä¹‹

é—´æ˜æ˜¾é‡å 

ï¼Œè€Œå…¶ä»–æ–¹å‘

åˆ™ä¸

é‡å ã€‚å…·

ä½“æ¥è¯´ï¼ŒWv(åˆ†åˆ«

ä¸ºã€‚Wq)å’Œ Wv(åˆ†åˆ«ä¸º

ã€‚Wq)å…±äº«å½’ä¸€åŒ–

ç›¸ä¼¼æ€§>

0.5 çš„

1 ç»´

å­ç©ºé—´ï¼Œæä¾›

äº†ä¸ºä»€ä¹ˆ r =

1 åœ¨

æˆ‘ä»¬çš„ GPT-3 çš„ä¸‹

æ¸¸ä»»åŠ¡ä¸­è¡¨

ç°ç›¸

å½“å¥½çš„

è§£é‡Šã€‚

Since both Ar=8

and Ar=64 are learned

using the same pre-trained

model, Figure 3 indicates

that

the top singular-vector

directions of Ar=8 and

Ar=64 are the most

useful, while other directions

potentially contain mostly random

noises accumulated during training.

Hence, the adaptation

matrix

can indeed have a

very low rank.

ç”±äº

Ar=8 å’Œ

Ar=64 éƒ½æ˜¯ä½¿ç”¨ç›¸

åŒçš„é¢„è®­ç»ƒ

æ¨¡å‹å­¦ä¹ çš„

ï¼ŒFigure 3

è¡¨ç¤º Ar=8 å’Œ Ar=64

çš„é¡¶

éƒ¨å¥‡å¼‚å‘é‡

æ–¹å‘æ˜¯æœ€æœ‰

ç”¨çš„ï¼Œè€Œå…¶ä»–

æ–¹å‘å¯èƒ½ä¸»

è¦åŒ…å«è®­ç»ƒ

æœŸé—´ç§¯ç´¯çš„

éšæœºå™ªå£°ã€‚å› 

æ­¤ï¼Œ

é€‚åº”çŸ©é˜µ

å®é™…ä¸Šå¯ä»¥

å…·æœ‰éå¸¸ä½

çš„ç§©ã€‚

Subspace similarity

between different random seeds.

We further confirm this

by plotting the

normalized

subspace similarity between two

randomly seeded runs with

r = 64, shown

in Figure

4.

ä¸åŒéš

æœºç§å­ä¹‹é—´

çš„å­ç©ºé—´ç›¸

ä¼¼æ€§ã€‚æˆ‘ä»¬é€š

è¿‡ç»˜åˆ¶

r = 64 çš„ä¸¤

æ¬¡éšæœºæ’­ç§

è¿è¡Œä¹‹é—´çš„

æ ‡å‡†

åŒ–å­ç©º

é—´ç›¸ä¼¼æ€§è¿›

ä¸€æ­¥è¯å®äº†

è¿™ä¸€ç‚¹ï¼Œå¦‚æ‰€

ç¤º Figure 4.

âˆ†Wq

appears to have a

higher â€œintrinsic rankâ€ than

âˆ†Wv, since more common

singular value

direc- tions

are learned by both

runs for âˆ†Wq, which

is in line with

our empirical observation in

Table 6. As a

comparison, we also plot

two random Gaussian matrices,

which do not share

any

common singular value

directions with each other.

Wq ä¼¼ä¹æ¯” Wv å…·

æœ‰æ›´é«˜çš„â€œå›º

æœ‰ç­‰çº§â€,å› ä¸º

Wq

çš„ä¸¤æ¬¡è¿è¡Œ

éƒ½è·å¾—äº†æ›´

å¸¸è§çš„å¥‡å¼‚

å€¼æ–¹å‘ï¼Œ

è¿™ä¸

æˆ‘ä»¬åœ¨ä¸­çš„

ç»éªŒè§‚å¯Ÿä¸€

è‡´ Table 6.ä½œä¸ºæ¯”è¾ƒ

ï¼Œæˆ‘ä»¬è¿˜ç»˜åˆ¶

äº†ä¸¤ä¸ªéšæœº

é«˜æ–¯çŸ©é˜µï¼Œå®ƒ

ä»¬

å½¼æ­¤ä¸å…±

äº«ä»»ä½•å…±åŒ

çš„å¥‡å¼‚å€¼æ–¹

å‘ã€‚

14.5 HOW DOES

THE ADAPTATION MATRIX âˆ†W

COMPARE TO W ?

14.6 è‡ªé€‚åº”çŸ©

é˜µ W ä¸

W ç›¸æ¯”å¦‚

ä½•ï¼Ÿ

We further

investigate the relationship between

âˆ†W and W .

In particular, does âˆ†W

highly

correlate with W

? (Or mathematically, is

âˆ†W mostly contained in

the top singular directions

of

W ?) Also,

æˆ‘ä»¬è¿›ä¸€

æ­¥ç ”ç©¶äº† W å’Œ

W ä¹‹é—´çš„å…³ç³»

ï¼Œç‰¹åˆ«åœ°ï¼ŒW

å’Œ W é«˜

åº¦ç›¸å…³å—ï¼Ÿ(æˆ–

è€…æ•°å­¦ä¸ŠâˆW æ˜¯

å¦å¤§

éƒ¨åˆ†åŒ…

å«åœ¨ W çš„ä¸Šå¥‡

å¼‚æ–¹å‘ï¼Ÿ)è¿˜æœ‰

ï¼Œ

7Note

that a similar analysis

can be carried out

with B and the

left-singular unitary matrices â€“

we stick with

7

è¯·æ³¨æ„ï¼Œå¯ä»¥

å¯¹ B å’Œå·¦å¥‡å¼‚

é…‰çŸ©é˜µè¿›è¡Œ

ç±»ä¼¼çš„åˆ†æ

â€”â€”æˆ‘ä»¬åšæŒ

A

for our experiments.

a

ä»£

è¡¨æˆ‘ä»¬çš„å®

éªŒã€‚

4

r =

64 r

r =

64 r

(A ,

A

0

, i,

j)

(ä¸€) ï¼ŒA0 ï¼Œæˆ‘ï¼Œj)

Wq Wv

ä½“é‡

å•†æ•° Wv

1

ä¸€

8

8

16

16

24

24

32

32

40

40

48

48

56

56

Random

Gaussia

n

éšæœº

é«˜æ–¯

i i

1

5

1

0

1

5

2

0

2

5

3

0

3

4

1

5

1

0

1

5

2

0

2

5

3

0

3

4

1

5

1

0

1

5

2

0

2

5

3

0

3

4

1

5

1

0

1

5

2

0

2

5

3

0

3

4

4

>

>

> >

â‰ˆ

0.5

0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0.0

0.0

j j j

j

j j

Figure 4:

Left and Middle: Normalized

subspace similarity between the

column vectors of Ar=64

from two random seeds,

for both âˆ†Wq and

âˆ†Wv in the 48-th

layer. Right: the same

heat-map

between the column

vectors of two random

Gaussian matrices. See Section

H.1 for other layers.

å›¾ 4:å·¦è¾¹

å’Œä¸­é—´:å¯¹äº

ç¬¬ 48 å±‚ä¸­çš„

Wq å’Œ

Wvï¼Œæ¥è‡ªä¸¤ä¸ªéš

æœºç§å­çš„ Ar=64 çš„

åˆ—å‘é‡ä¹‹é—´

çš„å½’

ä¸€åŒ–å­

ç©ºé—´ç›¸ä¼¼æ€§

ã€‚å³å›¾:ä¸¤ä¸ªéš

æœºé«˜æ–¯çŸ©é˜µ

çš„åˆ—å‘é‡ä¹‹

é—´çš„ç›¸åŒçƒ­

å›¾ã€‚çœ‹è§ Section H.1

å¯¹äº

å…¶ä»–å±‚ã€‚

how â€œlargeâ€ is âˆ†W

comparing to its corresponding

directions in W ?

This can shed light

on the

underlying mechanism

for adapting pre-trained language

models.

ä¸ W ä¸­

ç›¸åº”çš„æ–¹å‘

ç›¸æ¯”ï¼ŒW

æœ‰å¤šå¤§

ï¼Ÿè¿™å¯ä»¥é˜æ˜

ç”¨äºé€‚åº”é¢„

å…ˆè®­ç»ƒçš„è¯­

è¨€æ¨¡å‹çš„åŸº

ç¡€æœºåˆ¶ã€‚

To answer these

questions, we project W

onto the r-dimensional subspace

of âˆ†W by

comput-

ing U >WV >

, with U /V

being the left/right singular-vector

matrix of âˆ†W .

Then, we com- pare

the Frobenius norm between

kU >WV >

kF

and kW kF .

As a

comparison, we

also compute

ä¸ºäº†

å›ç­”è¿™äº›é—®

é¢˜ï¼Œæˆ‘ä»¬é€šè¿‡

è®¡ç®— U

>WV >å°† W æŠ•å½±

åˆ°

W çš„ r ç»´å­ç©º

é—´ä¸Šï¼Œå…¶ä¸­

U /V æ˜¯

W çš„å·¦/å³å¥‡å¼‚

å‘é‡çŸ©é˜µã€‚ç„¶

åï¼Œæˆ‘ä»¬æ¯”è¾ƒ

kU

>WV >kF å’Œ kW

kF ä¹‹é—´çš„ Frobenius èŒƒ

æ•°ã€‚ä½œä¸ºæ¯”è¾ƒ

ï¼Œæˆ‘ä»¬è¿˜è®¡ç®—

äº†

kU WVkF by replacing

U, V with the

top r singular vectors

of W or a

random matrix.

kU WVkF

é€šè¿‡ç”¨ W æˆ–

éšæœºçŸ©é˜µçš„

å‰ r

ä¸ªå¥‡å¼‚å‘

é‡ä»£æ›¿ Uï¼ŒVã€‚

âˆ†Wq

r

= 4

Wq Random

âˆ†Wq

r =

64

Wq

Random

âˆ®Wq

r

= 

4

ä½“é‡

å•†æ•°

éšæ„ âˆ®Wq

r =

64

ä½“

é‡

å•†æ•°

éšæ„

>

>

||U WqV ||F

= 0.32 21.67 0.02

1.90 37.71 0.33

>

>

||U WqV ||F

= 0.32 21.67 0.02

1.90 37.71 0.33

||Wq||F

= 61.95 ||âˆ†Wq||F =

6.91 ||âˆ†Wq||F = 3.57

||Wq||F = 61.95 |

|âˆ®Wq | | F

= 

6.91

|

|âˆ®Wq | | F

= 

3.57

Table

7: The Frobenius norm

of U >WqV

>

where U and V

are the left/right top

r singular

vector directions

of either (1) âˆ†Wq,

(2) Wq, or (3)

a random matrix. The

weight matrices are taken

from the 48th layer

of GPT-3.

è¡¨ 7:U

> WqV >çš„ Frobenius

èŒƒæ•°å…¶

ä¸­ U å’Œ V

æ˜¯(1)Wqï¼Œ(2) Wqï¼Œæˆ–(3)éš

æœºçŸ©é˜µçš„å·¦

/å³ä¸Š r

å¥‡å¼‚å‘

é‡æ–¹å‘ã€‚æƒé‡

çŸ©é˜µå–è‡ª

GPT-3 çš„

ç¬¬ 48 å±‚ã€‚

We draw several conclusions

from Table 7. First,

âˆ†W has a stronger

correlation with W

compared

to a random matrix,

indicating that âˆ†W amplifies

some features that are

already in W .

1

5

1

0

1

5

2

0

2

5

3

0

3

4

1

5

1

0

1

5

2

0

2

5

3

0

3

4

Second, instead of repeating

the top singular directions

of W , âˆ†W

only amplifies directions that

are not emphasized in

W . Third, the

amplification factor is rather

huge: 21.56.91/0.32 for r

= 4. See Section

H.4 for why r

= 64 has a

smaller amplification factor. We

also provide a

visualization

in Section H.3 for

how the correlation changes

as we include more

top singular

directions from

Wq. This suggests that

the low-rank adaptation matrix

potentially amplifies the

important

features for specific downstream

tasks that were learned

but not emphasized in

the

general pre-training model.

æˆ‘ä»¬ä»

â€¦å¾—å‡ºå‡ ä¸ªç»“

è®º Table 7.é¦–å…ˆï¼Œä¸éš

æœºçŸ©é˜µç›¸æ¯”

ï¼ŒW ä¸

W å…·æœ‰æ›´å¼º

çš„ç›¸å…³æ€§ï¼Œè¡¨

æ˜ W

æ”¾å¤§äº†

W ä¸­

å·²ç»å­˜åœ¨çš„

ä¸€äº›ç‰¹å¾ã€‚å…¶

æ¬¡ï¼ŒW ä¸æ˜¯é‡å¤

W çš„é¡¶éƒ¨å¥‡å¼‚

æ–¹å‘ï¼Œè€Œæ˜¯ä»…

æ”¾å¤§

W ä¸­æœª

å¼º

è°ƒçš„æ–¹å‘ã€‚ç¬¬

ä¸‰ï¼Œæ”¾å¤§ç³»æ•°

ç›¸å½“å¤§:r =

4 æ—¶ä¸º

21.56.91/0.32ã€‚çœ‹è§ Section H.4

å¯¹äº

ä¸º

ä»€ä¹ˆ r =

64 æ”¾å¤§ç³»

æ•°è¾ƒå°ã€‚æˆ‘ä»¬

è¿˜æä¾›äº†å¯

è§†åŒ–çš„ Section H.3

å½“æˆ‘

ä»¬åŒ…æ‹¬æ›´å¤š

æ¥è‡ª Wq

çš„é¡¶éƒ¨

å¥‡å¼‚æ–¹å‘æ—¶

ï¼Œç›¸å…³æ€§å¦‚ä½•

å˜åŒ–ã€‚è¿™è¡¨æ˜

ï¼Œä½ç§©é€‚åº”çŸ©

é˜µæ½œåœ¨åœ°æ”¾

å¤§äº†ç‰¹å®šä¸‹

æ¸¸ä»»åŠ¡çš„â‰ˆ

é‡

è¦ç‰¹å¾ï¼Œè¿™äº›

ç‰¹å¾åœ¨ä¸€èˆ¬

é¢„è®­ç»ƒæ¨¡å‹

ä¸­è¢«å­¦ä¹ ä½†

æ²¡æœ‰è¢«å¼ºè°ƒ

ã€‚

15 CONCLUSION AND FUTURE

WORK

16 ç»“è®ºå’Œæœªæ¥

å·¥ä½œ

Fine-tuning

enormous language models is

prohibitively expensive in terms

of the hardware

required

and the storage/switching cost

for hosting independent instances

for different tasks. We

propose LoRA, an efficient

adaptation strategy that neither

introduces inference latency nor

reduces input sequence length

while retaining high model

quality. Importantly, it allows

for quick

task-switching when

deployed as a service

by sharing the vast

majority of the model

parameters.

While we focused

on Transformer language models,

the proposed principles are

generally

applicable to any

neural networks with dense

layers.

å°±æ‰€éœ€

çš„ç¡¬ä»¶å’Œä¸º

ä¸åŒä»»åŠ¡æ‰˜

ç®¡ç‹¬ç«‹å®ä¾‹

çš„å­˜å‚¨/äº¤æ¢

æˆæœ¬è€Œè¨€ï¼Œå¾®

è°ƒå·¨å¤§çš„è¯­

è¨€æ¨¡å‹æ˜¯æ

å…¶æ˜‚è´µçš„ã€‚æˆ‘

ä»¬æå‡º LoRAï¼Œä¸€ç§

æœ‰æ•ˆçš„è‡ªé€‚

åº”ç­–ç•¥ï¼Œæ—¢ä¸

ä¼šå¼•å…¥æ¨ç†

å»¶è¿Ÿï¼Œä¹Ÿä¸ä¼š

å‡å°‘è¾“

å…¥åº

åˆ—é•¿åº¦ï¼ŒåŒæ—¶

ä¿æŒé«˜æ¨¡å‹

è´¨é‡ã€‚é‡è¦çš„

æ˜¯ï¼Œå½“ä½œä¸ºæœ

åŠ¡éƒ¨ç½²æ—¶ï¼Œé€š

è¿‡å…±äº«ç»å¤§

å¤šæ•°æ¨¡

å‹å‚

æ•°ï¼Œå®ƒå…è®¸å¿«

é€Ÿçš„ä»»åŠ¡åˆ‡

æ¢ã€‚è™½ç„¶æˆ‘ä»¬

å…³æ³¨çš„æ˜¯ Transformer è¯­

è¨€æ¨¡å‹ï¼Œä½†æ˜¯

æ‰€æå‡º

çš„åŸ

åˆ™é€šå¸¸é€‚ç”¨

äºä»»ä½•å…·æœ‰

å¯†é›†å±‚çš„ç¥

ç»ç½‘ç»œã€‚

There are many directions

for future works. 1)

LoRA can be combined

with other efficient adaptaï¿¾tion

methods, potentially providing orthogonal

improvement. 2) The mechanism

behind fineï¿¾tuning or LoRA

is far from clear

â€“ how are features

learned during pre-training transformed

to do

well on

downstream tasks? We believe

that LoRA makes it

more tractable to answer

this than

full fine-

ä»¥å

çš„ä½œå“æœ‰å¾ˆ

å¤šæ–¹å‘ã€‚1) LoRA å¯ä»¥

ä¸å…¶ä»–æœ‰æ•ˆ

çš„è‡ªé€‚åº”æ–¹

æ³•ç›¸ç»“åˆï¼Œæ½œ

åœ¨åœ°æä¾›æ­£

äº¤

æ”¹è¿›ã€‚2)å¾®è°ƒ

æˆ–

LoRA èƒŒåçš„æœº

åˆ¶è¿˜è¿œä¸æ¸…

æ¥šâ€”â€”é¢„è®­ç»ƒæœŸ

é—´å­¦åˆ°çš„ç‰¹

å¾å¦‚ä½•è½¬åŒ–

ä¸ºåœ¨ä¸‹æ¸¸

ä»»

åŠ¡ä¸­è¡¨ç°è‰¯

å¥½ï¼Ÿæˆ‘ä»¬ç›¸ä¿¡

åŠ³æ‹‰ä½¿å®ƒæ¯”

å®Œå…¨ç½šæ¬¾æ›´

å®¹æ˜“å›ç­”è¿™

ä¸ªé—®é¢˜-

4

tuning. 3) We mostly

depend on heuristics to

select the weight matrices

to apply LoRA to.

Are

there more principled

ways to do it?

4) Finally, the rank-deficiency

of âˆ†W suggests that

W could

be rank-deficient

as well, which can

also be a source

of inspiration for future

works.

è°ƒéŸ³

ã€‚3)æˆ‘ä»¬ä¸»è¦ä¾

é è¯•æ¢æ³•æ¥

é€‰æ‹©åº”ç”¨ LoRA çš„

æƒé‡çŸ©é˜µã€‚æœ‰

æ²¡æœ‰æ›´æœ‰åŸ

åˆ™æ€§çš„åšæ³•

ï¼Ÿ4)

æœ€åï¼ŒW çš„ç§©äº

è¡¨æ˜ W ä¹Ÿå¯èƒ½

æ˜¯ç§©äºçš„ï¼Œè¿™

ä¹Ÿå¯ä»¥æˆä¸º

æœªæ¥å·¥ä½œçš„

çµæ„Ÿæ¥æºã€‚

REFERENCES

å‚

è€ƒ

Armen Aghajanyan,

Luke Zettlemoyer, and Sonal

Gupta. Intrinsic Dimensionality Explains

the

Effectiveness of Language

Model Fine-Tuning. arXiv:2012.13255 [cs],

December 2020. URL

http://arxiv.org/abs/2012.13255.

é˜¿é—¨Â·é˜¿åŠ 

è´¾å°¼æ‰¬ã€å¢å…‹

Â·å¡ç‰¹å‹’è«è€¶

å’Œç´¢çº³å°”Â·å¤

æ™®å¡”ã€‚å†…åœ¨ç»´

åº¦è§£é‡Šäº†è¯­

è¨€æ¨¡å‹å¾®è°ƒ

çš„ æœ‰ æ•ˆ æ€§

ã€‚ arXiv:2012.13255 [cs] ï¼Œ

2020 å¹´

12 æœˆ ã€‚

ç»Ÿ ä¸€ èµ„ æº

å®š

ä½

å™¨ http://arxiv.org/abs/2012.13255ã€‚

Zeyuan

Allen-Zhu and Yuanzhi Li.

What Can ResNet Learn

Efficiently, Going Beyond Kernels?

In

è‰¾ä¼¦

-æœ±å’Œã€‚é™¤äº†å†…

æ ¸ï¼ŒResNet è¿˜èƒ½é«˜æ•ˆ

åœ°å­¦ä¹ ä»€ä¹ˆ

ï¼Ÿåœ¨â€¦é‡Œ

NeurIPS,

2019. Full version available

at http://arxiv.org/abs/1905.10337.

NeurIPSï¼Œ2019ã€‚å®Œæ•´ç‰ˆ

æœ¬å¯ä»ä»¥ä¸‹

ç½‘å€è·å¾— http://arxiv.org/abs/1905.10337ã€‚

Zeyuan Allen-Zhu and Yuanzhi

Li. Backward feature correction:

How deep learning performs

deep learning. arXiv preprint

arXiv:2001.04413, 2020a.

è‰¾

ä¼¦ -

æœ± å’Œ ã€‚ å

å‘

ç‰¹ å¾ æ ¡ æ­£

: æ·±

åº¦ å­¦ ä¹ 

å¦‚ ä½•

æ‰§ è¡Œ æ·±

åº¦ å­¦

ä¹  ã€‚ arXiv

é¢„ å° æœ¬

arXiv:2001.04413ï¼Œ2020aã€‚

Zeyuan Allen-Zhu and Yuanzhi

Li. Feature purification: How

adversarial training performs robust

deep learning. arXiv preprint

arXiv:2005.10190, 2020b.

è‰¾

ä¼¦-æœ±å’Œã€‚å¯¹æŠ—

è®­ç»ƒå¦‚ä½•æ‰§

è¡Œå¼ºå¤§çš„æ·±

åº¦å­¦ä¹ ã€‚arXiv é¢„å°

æœ¬

arXiv:2005.10190ï¼Œ2020b

Zeyuan Allen-Zhu, Yuanzhi

Li, and Zhao Song.

A convergence theory for

deep learning via overï¿¾parameterization.

In ICML, 2019. Full

version available at http://arxiv.org/abs/1811.

03962.

è¢æ³½Â·è‰¾ä¼¦

-æœ±ã€å’Œã€‚åŸºäºè¿‡

å‚æ•°åŒ–çš„æ·±

åº¦å­¦ä¹ æ”¶æ•›

ç†è®ºã€‚åœ¨ ICMLï¼Œ2019 å¹´ã€‚å®Œ

æ•´ç‰ˆæœ¬å¯

ä»

ä»¥ä¸‹ç½‘å€è·

å¾— http://arxiv.org/abs/1811.03962ã€‚

Jimmy Lei

Ba, Jamie Ryan Kiros,

and Geoffrey E. Hinton.

Layer normalization, 2016.

å‰ç±³Â·å·´é›·

ï¼Œæ°ç±³Â·ç‘å®‰Â·åŸº

ç½—æ–¯ï¼Œæ°å¼—é‡Œ

Â·eÂ·è¾›é¡¿ã€‚å›¾å±‚å½’

ä¸€åŒ–ï¼Œ2016ã€‚

Tom B. Brown, Benjamin

Mann, Nick Ryder, Melanie

Subbiah, Jared Kaplan, Prafulla

Dhariï¿¾wal, Arvind Neelakantan, Pranav

Shyam, Girish Sastry, Amanda

Askell, Sandhini Agarwal,

Ariel

Herbert-Voss, Gretchen Krueger, Tom

Henighan, Rewon Child, Aditya

Ramesh, Daniel

M. Ziegler,

Jeffrey Wu, Clemens Winter,

Christopher Hesse, Mark Chen,

Eric Sigler, Mateusz

Litwin,

Scott Gray, Benjamin Chess,

Jack Clark, Christopher Berner,

Sam McCandlish, Alec

Radford,

Ilya Sutskever, and Dario

Amodei. Language Models are

Few-Shot Learners.

arXiv:2005.14165 [cs],

July 2020. URL http://arxiv.org/abs/2005.14165.

æ±¤å§†Â·å¸ƒ

æœ—ã€æœ¬æ°æ˜Â·æ›¼

ã€å°¼å…‹Â·èµ–å¾·ã€æ¢…

æ‹‰å¦®Â·è‹æ¯”äºš

ã€è´¾é‡Œå¾·Â·å¡æ™®

å…°ã€æ™®æ‹‰å¯Œæ‹‰

Â·

è¾¾é‡Œ-ç“¦å°”ã€é˜¿

å°”æ¸©å¾·Â·å°¼æ‹‰

åå¦ã€æ™®æ‹‰çº³

å¤«Â·å¸Œäºšå§†ã€å‰

é‡Œä»€Â·è¨æ–¯ç‰¹

é‡Œã€é˜¿æ›¼è¾¾Â·é˜¿

æ–¯å…‹å°”ã€æ¡‘è¿ª

å°¼Â·é˜¿åŠ ç“¦å°”

ã€é˜¿é‡Œå°”Â·èµ«ä¼¯

ç‰¹-æ²ƒæ–¯ã€æ ¼é›·

ç´Â·å…‹é²æ ¼ã€æ±¤

å§†Â·æµ·å°¼æ ¹ã€

é›·

æ–‡Â·è”¡å°”å¾·ã€é˜¿

è¿ªè’‚äºšÂ·æ‹‰æ¢…

ä»€ã€ä¸¹å°¼å°”Â·é½

æ ¼å‹’ã€æ°å¼—é‡Œ

Â·å´ã€å…‹è±é—¨æ–¯

Â·æ¸©ç‰¹ã€

å…‹é‡Œæ–¯

æ‰˜å¼—Â·é»‘å¡ã€é™ˆ

å”å±±ã€åŸƒé‡Œå…‹

Â·è¥¿æ ¼å‹’ã€é©¬ç‰¹

ä¹Œæ–¯Â·åˆ©ç‰¹æ¸©

ã€æ–¯ç§‘ç‰¹Â·æ ¼é›·

ã€æœ¬

æ°æ˜Â·åˆ‡æ–¯

ã€æ°å…‹Â·å…‹æ‹‰å…‹

ã€å…‹é‡Œæ–¯æ‰˜å¼—

Â·ä¼¯çº³ã€è¨å§†Â·éº¦

å¡å¾·é‡Œä»€è¯­

è¨€æ¨¡å‹æ˜¯ä¸€

æ¬¡æ€§

4

å­¦ ä¹ 

è€…

ã€‚ arXiv:2005.14165 [cs] ï¼Œ

2020 å¹´ 7 æœˆ

ã€‚ ç»Ÿ ä¸€ èµ„

æº

å®š ä½

å™¨ http://arxiv.org/abs/2005.14165ã€‚

Jian-Feng Cai, Emmanuel J

Cande



s, and Zuowei Shen.

A singular value thresholding

algorithm

for matrix completion.

SIAM Journal on optimization,

20(4):1956â€“1982, 2010.

å»ºã€ä¼Šæ›¼çº½å°”

Â·åå¾·å’Œæ²ˆã€‚çŸ©

é˜µè¡¥å…¨çš„å¥‡

å¼‚å€¼é˜ˆå€¼ç®—

æ³•ã€‚SIAM ä¼˜åŒ–æ‚å¿—

ï¼Œ20(4):1956â€“

1982ï¼Œ2010ã€‚

Daniel Cer, Mona

Diab, Eneko Agirre, Inigo

Lopez-Gazpio, and Lucia Specia.

Semeval-2017 task

1: Semantic

textual similarity multilingual and

crosslingual focused evaluation. Proceedings

of

the 11th International

Workshop on Semantic Evaluation

(SemEval-2017), 2017. doi: 10.18653/

v1/s17-2001. URL http://dx.doi.org/10.18653/v1/S17-2001.

ä¸¹å°¼å°”Â·ç‘Ÿå°”

ã€è«å¨œÂ·è¿ªäºšåœ

ã€åŸƒå†…ç§‘Â·é˜¿å‰

å°”ã€ä¼Šå°¼æˆˆÂ·æ´›

ä½©æ–¯Â·åŠ å…¹çš®

å¥¥å’Œéœ²è¥¿äºš

Â·

æ–¯åŸºäºšã€‚Semeval-2017 ä»»åŠ¡

1:è¯­ä¹‰æ–‡æœ¬ç›¸

ä¼¼åº¦å¤šè¯­ç§

å’Œè·¨è¯­ç§èš

ç„¦è¯„ä¼°ã€‚ç¬¬ 11 å±Š

è¯­ä¹‰

è¯„ä»·å›½

é™…ç ”è®¨ä¼šè®º

æ–‡é›†(SemEval-2017)ï¼Œ2017ã€‚doi: 10.18653/ v1/s17-2001ã€‚ç»Ÿä¸€èµ„

æºå®šä½å™¨ http://dx.doi.org/10.18653/v1/S17-2001ã€‚

Ronan Collobert and Jason

Weston. A unified architecture

for natural language processing:

deep

neural networks with

multitask learning. In Proceedings

of the 25th international

conference

on Machine learning,

ICML â€™08, pp. 160â€“167,

New York, NY, USA,

July 2008. Association

for

Computing Machinery. ISBN 978-1-60558-205-4.

doi: 10.1145/1390156.1390177. URL

https://doi.org/10.1145/1390156.1390177.

ç½—

å—Â·ç§‘æ´›æ³¢ç‰¹

å’Œæ°æ£®Â·éŸ¦æ–¯

é¡¿ã€‚è‡ªç„¶è¯­è¨€

å¤„ç†çš„ç»Ÿä¸€

æ¶æ„:å…·æœ‰å¤š

ä»»åŠ¡å­¦ä¹ çš„

æ·±åº¦ç¥ç»ç½‘

ç»œã€‚ã€Šç¬¬ 25 å±Šæœºå™¨

å­¦ä¹ å›½é™…ä¼š

è®®è®ºæ–‡é›†ã€‹, 2008

å¹´

ICMLï¼Œç¬¬ 160-167 é¡µï¼Œçº½çº¦å·

ï¼Œç¾

å›½

ï¼Œ 2008 å¹´ 7

æœˆ ã€‚ è®¡

ç®— æœº

å ä¼š ã€‚ å›½

é™…

æ ‡ å‡† ä¹¦ å·

978-1-60558-205-4

ã€‚ doi:

10.1145/1390156.1390177ã€‚ç»Ÿä¸€èµ„æºå®š

ä½å™¨ https://doi.org/10.1145/1390156.139017

7ã€‚

Misha Denil, Babak

Shakibi, Laurent Dinh, Marcâ€™Aurelio

Ranzato, and Nando de

Freitas. Predicting

parameters in

deep learning, 2014.

Misha

Denil ã€ Babak Shakibi

ã€ Laurent Dinh ã€

Marc'Aurelio Ranzato å’Œ Nando

de

Freitasã€‚æ·±åº¦

å­¦ä¹ ä¸­çš„é¢„

æµ‹å‚æ•°ï¼Œ2014ã€‚

Jacob Devlin,

Ming-Wei Chang, Kenton Lee,

and Kristina Toutanova. Bert:

Pre-training of deep

bidirectional

transformers for language understanding,

2019a.

é›…å„

å¸ƒÂ·å¾·å¤«æ—ã€å¼ 

æ˜è”šã€è‚¯é¡¿Â·æ

å’Œå…‹é‡Œæ–¯è’‚

å¨œÂ·å›¾å¡”è¯ºå¨ƒ

ã€‚Bert:è¯­è¨€ç†è§£æ·±

åº¦åŒå‘è½¬

æ¢

å™¨çš„é¢„è®­ç»ƒ

ï¼Œ2019aã€‚

Jacob

Devlin, Ming-Wei Chang, Kenton

Lee, and Kristina Toutanova.

BERT: Pre-training of

Deep

Bidirectional Transformers for Language

Understanding. arXiv:1810.04805 [cs], May

2019b. URL http://arxiv.org/abs/1810.04805. arXiv:

1810.04805.

é›…å„å¸ƒÂ·å¾·å¤«

æ—ã€å¼ æ˜è”šã€è‚¯

é¡¿Â·æå’Œå…‹é‡Œ

æ–¯è’‚å¨œÂ·å›¾å¡”

è¯ºå¨ƒã€‚BERT:ç”¨äºè¯­

è¨€ç†è§£çš„æ·±

åº¦

åŒå‘ è½¬æ¢

å™¨çš„

é¢„è®­ ç»ƒ

ã€‚ arXiv:1810.04805 [cs]

ï¼Œ2019 å¹´ 5 æœˆã€‚

ç»Ÿä¸€ èµ„

æº å®šä½ å™¨

http://arxiv.org/abs/1810.04805ã€‚arXiv: 1810.04805ã€‚

William B.

Dolan and Chris Brockett.

Automatically constructing a corpus

of sentential paraphrases.

In

Proceedings of the Third

International Workshop on Paraphrasing

(IWP2005), 2005. URL

https://aclanthology.org/I05-5002.

å¨

å»‰Â·å¤šå…°å’Œå…‹

é‡Œæ–¯Â·å¸ƒç½—å…‹

ç‰¹ã€‚è‡ªåŠ¨æ„å»º

å¥å­é‡Šä¹‰è¯­

æ–™åº“ã€‚è½½äº 2005 å¹´

ç¬¬ä¸‰å±Šå›½é™…

é‡Šä¹‰

ç ”è®¨ä¼š

ä¼šè®®å½•ã€‚ç»Ÿä¸€

èµ„æºå®šä½å™¨

https://aclanthology.org/I05-5002ã€‚

Claire Gardent, Anastasia Shimorina,

Shashi Narayan, and Laura

Perez-Beltrachini. The webnlg

challenge:

Generating text from rdf

data. In Proceedings of

the 10th International Conference

on Natural Language Generation,

pp. 124â€“133, 2017.

å…‹è±å°”Â·åŠ ç™»

ç‰¹ã€é˜¿çº³æ–¯å¡”

è¥¿å¨…Â·å¸Œè«é‡Œ

çº³ã€æ²™å¸ŒÂ·çº³æ‹‰

æ‰¬å’ŒåŠ³æ‹‰Â·ä½©

é›·æ–¯Â·è´å°”ç‰¹

æ‹‰å¥‡

å°¼ã€‚ webnlg æŒ‘æˆ˜

: ä»

rdf æ•°æ® ç”Ÿæˆ

æ–‡æœ¬ ã€‚ã€Š

ç¬¬å å±Š

è‡ª ç„¶è¯­ è¨€ç”Ÿ

æˆå›½

é™…ä¼š è®®

è®º æ–‡

é›†ã€‹ï¼Œ124â€“133

é¡µï¼Œ2017ã€‚

4

4

Behrooz

Ghorbani, Song Mei, Theodor

Misiakiewicz, and Andrea Montanari.

When do neural

networks

outperform kernel methods? arXiv

preprint arXiv:2006.13409, 2020.

Behrooz

Ghorbaniï¼Œå®‹

æ¢…ï¼Œè¥¿å¥¥å¤šÂ·ç±³

è¥¿äºšå‡¯ç»´å¥‡

å’Œå®‰å¾·çƒˆÂ·è’™

å¡”çº³é‡Œã€‚ç¥ç»

ç½‘ç»œä½•æ—¶ä¼˜

äºæ ¸æ–¹æ³•ï¼ŸarXiv é¢„

å°æœ¬ arXiv:2006.13409ï¼Œ2020ã€‚

Bogdan

Gliwa, Iwona Mochol, Maciej

Biesek, and Aleksander Wawer.

Samsum corpus: A

human-

annotated dialogue dataset for

abstractive summarization. CoRR, abs/1911.12237,

2019. URL http://arxiv.org/abs/1911.12237.

æ³¢æ ¼ä¸¹

ä¸€ä¸–Â·æ ¼åˆ©ç“¦

ã€è‰¾æ²ƒå¨œÂ·è«ç§‘

å°”ã€é©¬åˆ‡ä¼ŠÂ·æ¯”

å¡å…‹å’Œäºšå†

å±±å¤§Â·ç“¦ç»´å°”

ã€‚ä¸€ä¸ªç”¨äº

æŠ½

è±¡æ‘˜è¦çš„äºº

ç±»æ³¨é‡Šå¯¹è¯

æ•°æ®é›†ã€‚CoRRï¼Œabs/1911.12237ï¼Œ2019ã€‚ç»Ÿä¸€

èµ„æºå®šä½å™¨

http://arxiv.org/abs/1911.12237ã€‚

Lars Grasedyck, Daniel

Kressner, and Christine Tobler.

A literature survey of

low-rank tensor

approximation techniques.

GAMM-Mitteilungen, 36(1):53â€“78, 2013.

æ‹‰æ–¯Â·æ ¼æ‹‰å¡

è¿ªå…‹ï¼Œä¸¹å°¼å°”

Â·å…‹é‡Œæ–¯çº³å’Œ

å…‹é‡Œæ–¯æ±€Â·æ‰˜

å¸ƒå‹’ã€‚ä½ç§©å¼ 

é‡è¿‘ä¼¼æŠ€æœ¯

çš„æ–‡çŒ®ç»¼

è¿°

GAMM-ç±³ç‰¹ä¼¦æ ¹ï¼Œ36(1):53â€“78ï¼Œ2013ã€‚

Jihun Ham and

Daniel D. Lee. Grassmann

discriminant analysis: a unifying

view on subspaceï¿¾based learning.

In ICML, pp. 376â€“383,

2008. URL

https://doi.org/10.1145/1390156. 1390204.

å‰

æ´ªæ±‰å§†å’Œä¸¹

å°¼å°”æã€‚æ ¼æ‹‰

æ–¯æ›¼åˆ¤åˆ«åˆ†

æ:åŸºäºå­ç©º

é—´å­¦ä¹ çš„ç»Ÿ

ä¸€è§‚ç‚¹ã€‚åœ¨ ICMLï¼Œç¬¬

376â€“

383 é¡µï¼Œ2008

å¹´ã€‚ç»Ÿä¸€èµ„

æºå®šä½å™¨ https://doi.org/10.1145/1390156.1390204ã€‚

Karen Hambardzumyan,

Hrant Khachatrian, and Jonathan

May. WARP: Word-level Adversarial

ReProgramming. arXiv:2101.00121 [cs], December

2020. URL http://arxiv.org/abs/

2101.00121.

arXiv: 2101.00121.

å‡¯

ä¼¦Â·æ±‰å·´å°”ç¥–

ç±³æ‰¬ï¼Œèµ«å…°ç‰¹

Â·å“ˆæ°ç‰¹é‡Œå®‰

å’Œä¹”çº³æ£®Â·æ¢…

ã€‚WARP:å•è¯çº§å¯¹æŠ—

æ€§é‡æ–°ç¼–

ç¨‹

ã€‚

arXiv:2101.00121 [cs] ï¼Œ 2020

å¹´ 12 æœˆ ã€‚

ç»Ÿ ä¸€ èµ„

æº å®š

ä½

å™¨ http://arxiv.org/abs/2101.00121ã€‚arXiv: 2101.00121ã€‚

Pengcheng He, Xiaodong Liu,

Jianfeng Gao, and Weizhu

Chen. Deberta: Decoding-enhanced bert

with disentangled attention, 2021.

ä½•

é¹ç¨‹ï¼Œï¼Œé«˜å‰‘é”‹

ï¼Œé™ˆã€‚å¾·ä¼¯å¡”:è§£

ç å¢å¼ºä¼¯ç‰¹

ä¸è§£å¼€æ³¨æ„

ï¼Œ2021ã€‚

Neil Houlsby, Andrei

Giurgiu, Stanislaw Jastrzebski, Bruna

Morrone, Quentin de Laroussilhe,

Andrea Gesmundo, Mona Attariyan,

and Sylvain Gelly. Parameter-Efficient

Transfer Learning

for NLP.

arXiv:1902.00751 [cs, stat], June

2019. URL http://arxiv.org/abs/1902.

00751.

å°¼å°”Â·éœå°”æ–¯

æ¯”ã€å®‰å¾·çƒˆÂ·ä¹…

å°”ä¹…ã€æ–¯å¦å°¼

æ–¯åŠ³Â·é›…æ–¯ç‰¹

æ—¥å¸ƒæ–¯åŸºã€å¸ƒ

é²çº³Â·è«é¾™ã€æ˜†

å»·

Â·å¾·æ‹‰é²è¥¿

å°”ã€å®‰å¾·çƒˆÂ·æ ¼

æ–¯è’™å¤šã€è«å¨œ

Â·é˜¿å¡”åˆ©æ‰¬å’Œ

è¥¿å°”ä¸‡Â·ç›–åˆ©

ã€‚è‡ªç„¶è¯­è¨€å¤„

ç†ä¸­

çš„å‚æ•°

æœ‰æ•ˆè¿ç§»å­¦

ä¹ ã€‚arXiv:1902.00751 [csï¼Œstat]ï¼Œ2019

å¹´ 6 æœˆã€‚ç»Ÿä¸€

èµ„æºå®šä½å™¨

http://arxiv.org/abs/1902.00751ã€‚

Max

Jaderberg, Andrea Vedaldi, and

Andrew Zisserman. Speeding up

convolutional neural

networks with

low rank expansions. arXiv

preprint arXiv:1405.3866, 2014.

é©¬å…‹æ–¯Â·è´¾å¾·

ä¼¯æ ¼ã€å®‰å¾·é‡Œ

äºšÂ·ç»´è¾¾å°”è¿ª

å’Œå®‰å¾·é²Â·é½

æ³½æ›¼ã€‚ç”¨ä½ç§©

å±•å¼€åŠ é€Ÿå·

ç§¯ç¥ç»ç½‘

ç»œ

ã€‚arXiv é¢„å°æœ¬ arXiv:1405.3866ï¼Œ2014ã€‚

Mikhail

Khodak, Neil Tenenholtz, Lester

Mackey, and Nicolo



Fusi. Initialization and

regularization

of factorized neural layers,

2021.

ç±³å“ˆä¼Šå°”Â·ç§‘

è¾¾å…‹ã€å°¼å°”Â·ç‰¹

å—éœå°”èŒ¨ã€è±

æ–¯ç‰¹Â·éº¦åŸºå’Œ

å°¼ç§‘æ´›Â·å¯Œè¥¿

ã€‚å› å­åˆ†è§£ç¥

ç»å±‚

çš„åˆå§‹

åŒ–å’Œæ­£åˆ™åŒ–

ï¼Œ2021ã€‚

Diederik

P. Kingma and Jimmy

Ba. Adam: A method

for stochastic optimization, 2017.

4

è¿ªå¾·é‡Œå…‹. p .é‡‘

ç›å’Œå‰ç±³.å·´

ã€‚äºšå½“:éšæœºä¼˜

åŒ–çš„æ–¹æ³•ï¼Œ2017ã€‚

Dmitry Lepikhin, HyoukJoong Lee,

Yuanzhong Xu, Dehao Chen,

Orhan Firat, Yanping Huang,

Maxim Krikun, Noam Shazeer,

and Zhifeng Chen. Gshard:

Scaling giant models with

conditional computation and automatic

sharding, 2020.

Dmitry Lepikhin

ã€ HyoukJoong Lee ã€

Xu ã€ Dehao Chen

ã€ Orhan Firat ã€

ã€ Maxim

Krikunã€Noam Shazeer

å’Œ

ã€‚Gshard:ç”¨æ¡ä»¶è®¡ç®—

å’Œè‡ªåŠ¨åˆ†ç‰‡

ç¼©æ”¾å·¨å‹æ¨¡

å‹ï¼Œ2020ã€‚

Brian Lester, Rami

Al-Rfou, and Noah Constant.

The Power of Scale

for Parameter-Efficient

Prompt Tuning.

arXiv:2104.08691 [cs], April 2021.

URL

http://arxiv.org/abs/2104.08691. arXiv: 2104.08691.

å¸ƒè±æ©Â·è±

æ–¯ç‰¹ï¼Œæ‹‰ç±³Â·è‰¾

å°”å¼—å’Œè¯ºäºš

Â·åº·æ–¯å¦ç‰¹ã€‚å‚

æ•°é«˜æ•ˆçš„å¿«

é€Ÿè°ƒä¼˜çš„è§„

æ¨¡åŠ›

é‡ ã€‚ arXiv:2104.08691

[cs] ï¼Œ 2021 å¹´

4 æœˆ

ã€‚ ç»Ÿ ä¸€

èµ„ æº å®š

ä½

å™¨

http://arxiv.org/abs/2104.08691ã€‚arXiv: 2104.08691ã€‚

Chunyuan Li,

Heerad Farkhoor, Rosanne Liu,

and Jason Yosinski. Measuring

the Intrinsic Diï¿¾mension of

Objective Landscapes.arXiv:1804.08838 [cs, stat],

April 2018a.URL http:

ææ˜¥å…ƒ

ã€Heerad

Farkhoorã€Rosanne Liu å’Œ Jason

Yosinskiã€‚æµ‹é‡å®¢è§‚

æ™¯è§‚çš„å†…åœ¨

å°º

å¯¸ã€‚arXiv:1804.08838 [csï¼Œstat]ï¼Œ2018 å¹´

4 æœˆã€‚ç»Ÿ

ä¸€èµ„æºå®šä½

å™¨ http:

//arxiv.org/abs/1804.08838.

arXiv: 1804.08838.

//arxiv.org/abs/1804.08838ã€‚arXiv: 1804.08838ã€‚

Xiang Lisa Li and

Percy Liang. Prefix-Tuning: Optimizing

Continuous Prompts for Generation.

é¡¹ä¸æ¢ä½©

è¥¿ã€‚å‰ç¼€è°ƒæ•´

:ä¼˜åŒ–ç”Ÿæˆçš„

è¿ç»­æç¤ºã€‚

arXiv:2101.00190 [cs], January

2021. URL http://arxiv.org/abs/2101.00190.

arXiv:2101.00190

[cs]ï¼Œ2021 å¹´

1 æœˆã€‚ç»Ÿä¸€èµ„æº

å®šä½

å™¨

http://arxiv.org/abs/2101.00190ã€‚

Yuanzhi Li and

Yingyu Liang. Learning overparameterized

neural networks via stochastic

gradient descent on structured

data. In Advances in

Neural Information Processing Systems,

2018.

å’Œæ¢

ã€‚åŸºäºç»“æ„åŒ–

æ•°æ®çš„éšæœº

æ¢¯åº¦ä¸‹é™å­¦

ä¹ è¶…å‚æ•°åŒ–

ç¥ç»ç½‘ç»œã€‚ç¥

ç»ä¿¡æ¯å¤„ç†

ç³»ç»Ÿè¿›

å±•ï¼Œ2018 å¹´

ã€‚

Yuanzhi Li, Yingyu Liang,

and Andrej Risteski. Recovery

guarantee of weighted low-rank

apï¿¾proximation via alternating minimization.

In International Conference on

Machine Learning,

pp. 2358â€“2367.

PMLR, 2016.

ã€äºé¢–Â·æ¢å’Œå®‰

å¾·çƒˆÂ·é‡Œæ–¯ç‰¹

æ–¯åŸºã€‚é€šè¿‡äº¤

æ›¿æœ€å°åŒ–çš„

åŠ æƒä½ç§©é€¼

è¿‘çš„æ¢å¤ä¿

è¯ã€‚å›½é™…æœº

å™¨

å­¦ä¹ ä¼šè®®ï¼Œç¬¬

2358â€“2367

é¡µã€‚PMLRï¼Œ2016ã€‚

Yuanzhi Li, Tengyu

Ma, and Hongyang Zhang.

Algorithmic regularization in over-parameterized

matrix sensing and neural

networks with quadratic activations.

In Conference On Learning

Theï¿¾ory, pp. 2â€“47. PMLR,

2018b.

ææ²…èŠ·ï¼Œé©¬

è…¾å®‡å’Œå¼ å¼˜

æ‰¬ã€‚å…·æœ‰äºŒæ¬¡

æ¿€æ´»çš„è¿‡å‚

æ•°çŸ©é˜µä¼ æ„Ÿ

å’Œç¥ç»ç½‘ç»œ

ä¸­çš„ç®—æ³•æ­£

åˆ™åŒ–ã€‚

åœ¨å­¦ä¹ 

ç†è®ºä¼šè®®ä¸Š

ï¼Œç¬¬ 2-47

é¡µã€‚PMLRï¼Œ2018 å¹´ bã€‚

Zhaojiang

Lin, Andrea Madotto, and

Pascale Fung. Exploring versatile

generative language model

via

parameter-efficient transfer learning. In

Findings of the Association

for Computational Linï¿¾guistics: EMNLP

2020, pp. 441â€“459, Online,

November 2020. Association for

Computational

Linguistics. doi: 10.18653/v1/2020.findings-emnlp.41.

URL https://aclanthology.

org/2020.findings-emnlp.41.

èµµæ±Ÿ

Â·æ—ã€å®‰å¾·é‡Œäºš

Â·é©¬å¤šæ‰˜å’Œå¸•

æ–¯å¡å°”Â·å†¯ã€‚é€š

è¿‡å‚æ•°æœ‰æ•ˆ

è¿ç§»å­¦ä¹ æ¢

ç´¢é€šç”¨ç”Ÿæˆ

è¯­è¨€

æ¨¡å‹ã€‚è®¡

ç®—é€»è¾‘åä¼š

çš„å‘ç°:EMNLP 2020ï¼Œç¬¬ 441â€“459 é¡µ

ï¼Œåœ¨çº¿ï¼Œ2020

å¹´ 11 æœˆã€‚è®¡

ç®—è¯­

è¨€

å­¦ å

ä¼š ã€‚ doi:

10.18653/v1/2020 . è°ƒ æŸ¥

ç»“ æœ

-emnlp.41.

URLhttps://aclanthology.org/2020.findings-emnlp.41ã€‚

Xiao

Liu, Yanan Zheng, Zhengxiao

Du, Ming Ding, Yujie

Qian, Zhilin Yang, and

Jie Tang. GPT

Understands,

Too. arXiv:2103.10385 [cs], March

2021. URL http://arxiv.org/abs/

2103.10385.

arXiv: 2103.10385.

åˆ˜æ½‡ã€éƒ‘å»¶å®‰

ã€ã€æœã€ã€é’±ç‰æ°ã€ã€æ¨

ã€ã€‚GPT ä¹Ÿç†è§£ã€‚arXiv:2103.10385

[cs]ï¼Œ2021 å¹´

3 æœˆ

ã€‚ç»Ÿä¸€èµ„æºå®š

ä½å™¨

http://arxiv.org/abs/2103.10385ã€‚arXiv: 2103.10385ã€‚

Yinhan Liu,

Myle Ott, Naman Goyal,

Jingfei Du, Mandar Joshi,

Danqi Chen, Omer Levy,

Mike

Lewis, Luke Zettlemoyer,

and Veselin Stoyanov. Roberta:

A robustly optimized bert

pretraining approach, 2019.

åˆ˜ã€æ¢…å°”

Â·å¥¥ç‰¹ã€çº³æ›¼Â·æˆˆ

äºšå°”ã€Â·æœã€æ›¼è¾¾

å°”Â·ä¹”å¸Œã€Â·é™ˆã€å¥¥

æ¢…å°”Â·åˆ©ç»´ã€ã€å¢

å…‹Â·

æ³½ç‰¹å‹’è«

è€¶å’ŒéŸ¦å¡æ—

Â·æ–¯æ‰˜æ‰¬è¯ºå¤«

ã€‚Roberta:ä¸€ç§ç¨³å¥ä¼˜

åŒ–çš„ bert é¢„è®­ç»ƒ

æ–¹æ³•ï¼Œ2019ã€‚

Ilya

Loshchilov and Frank Hutter.

Decoupled weight decay regularization.

arXiv preprint

arXiv:1711.05101, 2017.

ä¼Š åˆ© äºš

Â· æ´›

å¸Œ æ´› å¤« å’Œ

å¼—

å…° å…‹ Â· å“ˆ

ç‰¹

ã€‚ å» è€¦ æƒ

é‡ è¡°

å‡ æ­£ åˆ™

åŒ– ã€‚ arXiv é¢„

å°

æœ¬

arXiv:1711.05101ï¼Œ2017ã€‚

Ilya Loshchilov

and Frank Hutter. Decoupled

weight decay regularization, 2019.

ä¼Šåˆ©äºš

Â·æ´›å¸Œæ´›å¤«å’Œ

å¼—å…°å…‹Â·å“ˆç‰¹

ã€‚è§£è€¦æƒé‡è¡°

å‡æ­£åˆ™åŒ–ï¼Œ2019ã€‚

Rabeeh Karimi Mahabadi,

James Henderson, and Sebastian

Ruder. Compacter: Efficient low-rank

hypercomplex adapter layers, 2021.

æ‹‰

æ¯”èµ«Â·å¡åˆ©ç±³

Â·é©¬å“ˆå·´è¿ªã€è©¹

å§†æ–¯Â·æ±‰å¾·æ£®

å’Œå¡å·´æ–¯è’‚

å®‰Â·é²å¾·ã€‚å‹ç¼©

ç¨‹åº:é«˜æ•ˆä½

ç§©è¶…

å¤æ•°é€‚

é…å™¨å±‚ï¼Œ2021ã€‚

Linyong Nan,

Dragomir Radev, Rui Zhang,

Amrit Rau, Abhinand Sivaprasad,

Chiachun Hsieh,

Xiangru Tang,

Aadit Vyas, Neha Verma,

Pranav Krishna, et al.

Dart: Open-domain structured

data

record to text generation.

arXiv preprint arXiv:2007.02871, 2020.

å—ï¼Œå¾·

æ‹‰æˆˆç±³å°”Â·æ‹‰

å¾·å¤«ï¼Œå¼ ç¿ï¼Œé˜¿

å§†é‡Œç‰¹Â·åŠ³ï¼Œé˜¿

æ¯”å—å¾·Â·è¥¿ç“¦

æ™®æ‹‰è¨å¾·ï¼Œè°¢

å®¶çº¯ï¼Œå”

æ¹˜å¦‚

ï¼Œé˜¿è¿ªç‰¹Â·ç»´äºš

æ–¯ï¼Œå†…å“ˆÂ·ç»´å°”

é©¬ï¼Œæ™®æ‹‰çº³å¤«

Â·å…‹é‡Œå¸Œçº³ï¼Œç­‰

ã€‚arXiv é¢„å°æœ¬

arXiv:2007.02871ï¼Œ2020

Jekaterina Novikova, OndË‡rej DusË‡ek,

and Verena Rieser. The

e2e dataset: New challenges

for

end- to-end generation.

arXiv preprint arXiv:1706.09254, 2017.

Jekaterina Novikovaã€OndË‡ rej DusË‡

ek å’Œ Verena Rieserã€‚e2e

æ•°

æ®é›†:ç«¯åˆ°ç«¯

ç”Ÿæˆçš„

æ–°æŒ‘

æˆ˜ã€‚arXiv é¢„å°æœ¬ arXiv:1706.09254ï¼Œ2017ã€‚

Samet Oymak, Zalan Fabian,

Mingchen Li, and Mahdi

Soltanolkotabi. Generalization guaranï¿¾tees for

neural networks via harnessing

the low-rank structure of

the jacobian. arXiv preprint

arXiv:1906.05392, 2019.

è¨

æ¢…ç‰¹Â·å¥¥ä¼Šé©¬

å…‹ã€æ‰å…°Â·æ³•æ¯”

å®‰ã€ææ˜è‡£å’Œ

é©¬èµ«è¿ªÂ·ç´¢å°”

å¡”è¯ºÂ·ç§‘å¡”æ¯”

ã€‚é€šè¿‡åˆ©ç”¨é›…

å¯

æ¯”çŸ©é˜µçš„

ä½ç§©ç»“æ„æ¥

ä¿è¯ç¥ç»ç½‘

ç»œçš„æ³›åŒ–ã€‚arXiv

é¢„

å°æœ¬ arXiv:1906.05392ï¼Œ2019ã€‚

Jonas Pfeiffer,

Aishwarya Kamath, Andreas RuÂ¨ckleÂ´,

Kyunghyun Cho, and Iryna

Gurevych. Adapterï¿¾fusion: Non-destructive task

composition for transfer learning,

2021.

Jonas Pfeifferã€Aishwarya Kamathã€Andreas

Ru ckleã€Kyunghyun Cho å’Œ

Iryna Gurevychã€‚

é€‚é…

å™¨èåˆ:è¿ç§»

å­¦ä¹ çš„éç ´

åæ€§ä»»åŠ¡åˆ

æˆï¼Œ2021ã€‚

Daniel

Povey, Gaofeng Cheng, Yiming

Wang, Ke Li, Hainan

Xu, Mahsa Yarmohammadi, and

San- jeev Khudanpur. Semi-orthogonal

low-rank matrix factorization for

deep neural networks.

In

Interspeech, pp. 3743â€“3747, 2018.

Daniel Poveyï¼ŒChengï¼Œï¼Œï¼ŒHainan Xuï¼ŒMahsa Yarmohammadi

å’Œ San- jeev Khudanpurã€‚

æ·±åº¦ç¥

ç»ç½‘ç»œçš„åŠ

æ­£äº¤ä½ç§©çŸ©

é˜µåˆ†è§£ã€‚åœ¨ Interspeechï¼Œ2018 å¹´

ç¬¬ 3743â€“3747

é¡µã€‚

4

4

Alec

Radford, Karthik Narasimhan, Tim

Salimans, and Ilya Sutskever.

Improving Language

Under- standing

by Generative Pre-Training. pp.

12, a.

äºšå†å…‹

Â·æ‹‰å¾·ç¦å¾·ã€å¡

è’‚å…‹Â·çº³æ‹‰è¾›

æ±‰ã€è’‚å§†Â·è¨åˆ©

æ›¼æ–¯å’Œä¼Šåˆ©

äºšÂ·è‹èŒ¨åŸºå¼—

ã€‚é€šè¿‡ç”Ÿæˆ

æ€§

é¢„è®­ç»ƒæé«˜

è¯­è¨€ç†è§£èƒ½

åŠ›ã€‚ç¬¬

12 é¡µï¼Œaã€‚

Alec Radford,

Jeffrey Wu, Rewon Child,

David Luan, Dario Amodei,

and Ilya Sutskever.

Language

Models are Unsupervised Multitask

Learners. pp. 24, b.

äºšå†

å…‹æ‹‰å¾·ç¦å¾·

ï¼Œæ°å¼—é‡Œå´ï¼ŒRewon å„¿

ç«¥ï¼Œå¤§å«æ ¾ï¼Œè¾¾

é‡Œå¥¥é˜¿è«ä»£

ä¼Šï¼Œä¼Šåˆ©äºš Sutskeverã€‚

è¯­

è¨€æ¨¡å‹æ˜¯æ— 

äººç›‘ç£çš„å¤š

ä»»åŠ¡å­¦ä¹ è€…

ã€‚ç¬¬

24 é¡µ bã€‚

Pranav

Rajpurkar, Robin Jia, and

Percy Liang. Know what

you donâ€™t know: Unanswerable

questions for squad. CoRR,

abs/1806.03822, 2018. URL

http://arxiv.org/abs/1806.03822.

Pranav Rajpurkarï¼ŒRobin Jia å’Œ

Percy Liangã€‚çŸ¥é“

ä½ ä¸çŸ¥é“çš„

:æ— æ³•å›ç­”çš„

é—®é¢˜ã€‚æ›´

æ­£ï¼Œabs/1806.03822ï¼Œ2018ã€‚ç»Ÿ

ä¸€èµ„æºå®šä½

å™¨ http://arxiv.org/abs/1806.03822ã€‚

Sylvestre-Alvise Rebuffi, Hakan Bilen,

and Andrea Vedaldi. Learning

multiple visual domains

with

residual adapters. arXiv:1705.08045 [cs,

stat], November 2017. URL

http://arxiv.org/ abs/1705.08045. arXiv: 1705.08045.

è¥¿å°”å¨æ–¯

ç‰¹Â·é˜¿å°”ç»´æ–¯

Â·é›·å¸ƒè²ã€å“ˆå

Â·æ¯”ä¼¦å’Œå®‰å¾·

é‡ŒäºšÂ·ç»´è¾¾å°”

è¿ªã€‚ç”¨å‰©ä½™é€‚

é…å™¨å­¦ä¹ 

å¤š

ä¸ª è§† è§‰

åŸŸ ã€‚ arXiv:1705.08045 [cs

ï¼Œ stat] ï¼Œ 2017

å¹´

11 æœˆ ã€‚ ç»Ÿ

ä¸€ èµ„ æº

å®š ä½

å™¨ http://arxiv.org/abs/1705.08045ã€‚arXiv: 1705.08045ã€‚

Andreas

RuÂ¨ckleÂ´, Gregor Geigle, Max

Glockner, Tilman Beck, Jonas

Pfeiffer, Nils Reimers, and

Iryna Gurevych. Adapterdrop: On

the efficiency of adapters

in transformers, 2020.

Andreas

Ru ckleã€Gregor Geigleã€Max Glocknerã€Tilman

Beckã€Jonas Pfeifferã€Nils

Reimers å’Œ

Iryna Gurevychã€‚Adapterdrop:å˜

å‹å™¨ä¸­é€‚é…

å™¨çš„æ•ˆç‡ï¼Œ2020ã€‚

Tara N

Sainath, Brian Kingsbury, Vikas

Sindhwani, Ebru Arisoy, and

Bhuvana Ramabhadran.

Low- rank

matrix factorization for deep

neural network training with

high-dimensional output

targets. In

2013 IEEE international conference

on acoustics, speech and

signal processing, pp.

6655â€“

6659. IEEE, 2013.

Tara

N Sainath ã€ Brian

Kingsbury ã€ Vikas Sindhwani

ã€ Ebru Arisoy å’Œ

Bhuvana

Ramabhadranã€‚ç”¨äºå…·æœ‰é«˜

ç»´è¾“å‡ºç›®æ ‡

çš„æ·±åº¦ç¥ç»

ç½‘ç»œè®­ç»ƒçš„

ä½ç§©çŸ©é˜µåˆ†

è§£ã€‚ 2013 å¹´

IEEE

å£°å­¦ã€è¯­

éŸ³å’Œä¿¡å·å¤„

ç†å›½é™…ä¼šè®®

ï¼Œç¬¬ 6655â€“6659 é¡µã€‚IEEEï¼Œ2013 å¹´ã€‚

Mohammad Shoeybi, Mostofa Patwary,

Raul Puri, Patrick LeGresley,

Jared Casper, and Bryan

Catanzaro. Megatron-lm: Training multi-billion

parameter language models using

model parï¿¾allelism, 2020.

Mohammad

Shoeybiï¼ŒMostofa Patwaryï¼ŒRaul Puriï¼ŒPatrick LeGresleyï¼ŒJared

Casper

å’Œ Bryan Catanzaroã€‚å¨

éœ‡å¤©-lm:ä½¿ç”¨æ¨¡

å‹å¹¶è¡Œæ€§è®­

ç»ƒæ•°åäº¿å‚

æ•°è¯­è¨€æ¨¡å‹

ï¼Œ2020ã€‚

Richard Socher, Alex Perelygin,

Jean Wu, Jason Chuang,

Christopher D. Manning, Andrew

Ng,

and Christopher Potts.

Recursive deep models for

semantic compositionality over a

sentiment

treebank. In Proceedings

of the 2013 Conference

on Empirical Methods in

Natural Language

Processing, pp.

1631â€“1642, Seattle, Washington, USA,

October 2013. Association for

Computa- tional Linguistics. URL

https://aclanthology.org/D13-1170.

Richard Socherã€Alex Perelyginã€Jean

Wuã€Jason Chuangã€Christopher D. Manningã€

å’Œ Christopher Pottsã€‚æƒ…æ„Ÿæ ‘åº“

è¯­ä¹‰åˆæˆçš„

é€’å½’æ·±åº¦æ¨¡

å‹ã€‚ã€Š2013 å¹´è‡ªç„¶è¯­

è¨€å¤„ç†ç»

éªŒ

æ–¹æ³•ä¼šè®®è®º

æ–‡é›†ã€‹ï¼Œç¬¬ 1631-1642 é¡µï¼Œç¾

å›½åç››é¡¿å·

è¥¿é›…å›¾ï¼Œ2013 å¹´

10 æœˆ

ã€‚è®¡ç®—è¯­è¨€

å­¦

åä¼šã€‚ç»Ÿä¸€èµ„

æºå®šä½å™¨ https://aclanthology.org/D13-1170ã€‚

Ashish Vaswani, Noam Shazeer,

Niki Parmar, Jakob Uszkoreit,

Llion Jones, Aidan N

Gomez,

Åukasz Kaiser, and

Illia Polosukhin. Attention is

all you need. In

Proceedings of the 31st

Inï¿¾ternational Conference on Neural

Information Processing Systems, pp.

6000â€“6010, 2017.

Ashish Vaswaniã€Noam

Shazeerã€Niki Parmarã€Jakob Uszkoreitã€Llion Jonesã€Aidan

Gomezã€ukasz Kaiser å’Œ

Illia Polosukhinã€‚ä½ éœ€è¦çš„åª

æ˜¯å…³æ³¨ã€‚ã€Šç¬¬

31 å±Š

å›½é™…ç¥ç»ä¿¡

æ¯å¤„ç†ç³»ç»Ÿ

ä¼šè®®è®ºæ–‡é›†

ã€‹ï¼Œç¬¬ 6000â€“6010 é¡µï¼Œ2017

å¹´ã€‚

Alex Wang, Amanpreet

Singh, Julian Michael, Felix

Hill, Omer Levy, and

Samuel R. Bowman.

Glue:

A multi-task benchmark and

analysis platform for natural

language understanding, 2019.

ç‹æ•¬

å®ã€é˜¿æ›¼æ™®ç‘

ç‰¹Â·è¾›æ ¼ã€æœ±åˆ©

å®‰Â·è¿ˆå…‹å°”ã€è²

åˆ©å…‹æ–¯Â·å¸Œå°”

ã€å¥¥é©¬å°”Â·åˆ©ç»´

å’Œå¡ç¼ªå°”

Â·é²

æ›¼ã€‚Glue:è‡ªç„¶è¯­è¨€

ç†è§£çš„å¤šä»»

åŠ¡åŸºå‡†å’Œåˆ†

æå¹³å°ï¼Œ2019ã€‚

Alex Wang, Yada

Pruksachatkun, Nikita Nangia, Amanpreet

Singh, Julian Michael, Felix

Hill, Omer

Levy, and

Samuel R. Bowman. Superglue:

A stickier benchmark for

general-purpose language

understanding systems,

2020.

ç‹æ•¬

å®ã€Yada Pruksachatkunã€Nikita Nangiaã€Amanpreet

Singhã€Julian Michaelã€Felix

Hillã€Omer Levy

å’Œ Samuel R. Bowmanã€‚å¼ºåŠ›èƒ¶

:é€šç”¨è¯­è¨€ç†

è§£ç³»ç»Ÿçš„ç²˜

æ€§åŸºå‡†ï¼Œ2020

å¹´ã€‚

Alex Warstadt, Amanpreet

Singh, and Samuel R

Bowman. Neural network acceptability

judgments.

äºš

å†å…‹æ–¯Â·ç“¦æ–½

å¡”ç‰¹ã€é˜¿æ›¼æ™®

é‡Œç‰¹Â·è¾›æ ¼å’Œ

å¡ç¼ªå°”Â·é²æ›¼

ã€‚ç¥ç»ç½‘ç»œå¯

æ¥å—æ€§åˆ¤æ–­

ã€‚

arXiv preprint

arXiv:1805.12471, 2018.

arXiv é¢„å°æœ¬

arXiv:1805.12471ï¼Œ2018ã€‚

Adina Williams, Nikita

Nangia, and Samuel Bowman.

A broad-coverage challenge corpus

for

sen- tence understanding

through inference. In Proceedings

of the 2018 Conference

of the

North American

Chapter of the Association

for Computational Linguistics: Human

Language

Technolo- gies, Volume

1 (Long Papers), pp.

1112â€“1122, New Orleans, Louisiana,

June 2018.

Association for

Computational Linguistics. doi: 10.18653/v1/N18-1101.

URL

https://www.aclweb. org/anthology/N18-1101.

è‰¾è¿ª

å¨œÂ·å¨å»‰å§†æ–¯

å°¼åŸºå¡”Â·å—å‰

äºšå’Œå¡ç¼ªå°”

Â·é²æ›¼ã€‚é€šè¿‡æ¨

ç†è¿›è¡Œç§‘å­¦

ç†è§£çš„å¤§èŒƒ

å›´æŒ‘æˆ˜

è¯­æ–™

åº“ã€‚è®¡ç®—è¯­è¨€

å­¦åä¼šåŒ—ç¾

åˆ†ä¼š 2018 å¹´ä¼šè®®

è®ºæ–‡é›†:äººç±»

è¯­è¨€æŠ€æœ¯ï¼Œç¬¬

1 å·(é•¿è®º

æ–‡)ï¼Œç¬¬

1112-1122 é¡µï¼Œè·¯æ˜“æ–¯å®‰

é‚£å·æ–°å¥¥å°”

è‰¯ï¼Œ2018 å¹´ 6

æœˆã€‚è®¡ç®—

è¯­è¨€å­¦åä¼š

ã€‚doi:

10.18653/v1/N18-1101 ã€‚ ç»Ÿ

ä¸€ èµ„ æº å®š

ä½

å™¨ https://www.aclweb.org/anthology/N18-

1101ã€‚

Thomas

Wolf, Lysandre Debut, Victor

Sanh, Julien Chaumond, Clement

Delangue, Anthony Moi,

Pierric

Cistac, Tim Rault, ReÂ´mi

Louf, Morgan Funtowicz, Joe

Davison, Sam Shleifer, Patrick

von Platen, Clara Ma,

Yacine Jernite, Julien Plu,

Canwen Xu, Teven Le

Scao, Sylvain Gugï¿¾ger, Mariama

Drame, Quentin Lhoest, and

Alexander M. Rush. Transformers:

State-of-the-art

natural language processing.

In Proceedings of the

2020 Conference on Empirical

Methods in

Natural Language

Processing: System Demonstrations, pp.

38â€“45, Online, October 2020.

Asï¿¾sociation for Computational Linguistics.

URL https://www.aclweb.org/anthology/

2020.emnlp-demos.6.

Thomas

Wolf ã€ å¼— æ‹‰

è¾¾

åˆ© Â· è‚– å°¼

ç‰¹ ã€ Victor Sanh

ã€ Julien Chaumond ã€

Clement

Delangue ã€ Anthony

Moi ã€ Pierric Cistac

ã€ Tim Rault ã€

Re mi Louf ã€

Morgan

Funtowiczã€Joe Davisonã€Sam Shleiferã€Patrick

von Platenã€Clara Maã€Yacine

Jerniteã€Julien

Pluã€Canwen Xu ã€Teven Le

Scao ã€Sylvain Gug- ger

ã€Mariama

Drameã€Quentin Lhoest å’Œ

Alexander

M. Rushã€‚å˜å½¢é‡‘åˆš:æœ€

å…ˆè¿›çš„è‡ªç„¶

è¯­è¨€å¤„ç†ã€‚

ã€Š2020 å¹´

è‡ªç„¶è¯­è¨€å¤„

ç†ç»éªŒæ–¹æ³•

ä¼šè®®è®ºæ–‡é›†

:ç³»ç»Ÿæ¼”ç¤ºã€‹,ç¬¬

38â€“45

é¡µï¼Œåœ¨çº¿ï¼Œ2020 å¹´

10 æœˆ

ã€‚

è®¡ ç®— è¯­ è¨€

å­¦

å ä¼š ã€‚ ç»Ÿ

ä¸€ èµ„

æº å®š ä½

å™¨ https://www.aclweb.org/anthology/

2020.emnlp-demos.6ã€‚

4

5

Greg Yang and

Edward J. Hu. Feature

Learning in Infinite-Width Neural

Networks.

arXiv:2011.14522 [cond-mat], May

2021. URL http://arxiv.org/abs/2011.14522.

arXiv:

2011.14522.

æ ¼

é›·æ ¼Â·æ¨å’Œçˆ±

å¾·åÂ·èƒ¡ã€‚æ— é™

å®½ç¥ç»ç½‘ç»œ

ä¸­çš„ç‰¹å¾å­¦

ä¹ ã€‚arXiv:2011.14522 [condï¿¾mat] ï¼Œ

2021 å¹´ 5 æœˆ

ã€‚ ç»Ÿ ä¸€

èµ„ æº

å®š ä½ å™¨

http://arxiv.org/abs/2011.14522 ã€‚

arXiv:

2011.14522ã€‚

Elad Ben

Zaken, Shauli Ravfogel, and

Yoav Goldberg. Bitfit: Simple

parameter-efficient fineï¿¾tuning for transformer-based

masked language-models, 2021.

Elad

Ben Zakenï¼ŒShauli Ravfogel å’Œ

Yoav Goldbergã€‚Bitfit:åŸºäº transformer çš„å±

è”½è¯­

è¨€æ¨¡å‹

çš„ç®€å•å‚æ•°

é«˜æ•ˆå¾®è°ƒï¼Œ2021ã€‚

Yu Zhang, Ekapol

Chuangsuwanich, and James Glass.

Extracting deep neural network

bottleneck

features using low-rank

matrix factorization. In 2014

IEEE international conference on

acoustics, speech and signal

processing (ICASSP), pp. 185â€“189.

IEEE, 2014.

å¼ 

ç‘œï¼ŒEkapol Chuangsuwanich

å’Œè©¹å§†æ–¯

Â·æ ¼æ‹‰æ–¯ã€‚åˆ©ç”¨

ä½ç§©çŸ©é˜µåˆ†

è§£æå–æ·±åº¦

ç¥ç»ç½‘ç»œ

ç“¶

é¢ˆç‰¹å¾ã€‚2014 å¹´ IEEE

å£°

å­¦ã€è¯­éŸ³å’Œä¿¡

å·å¤„ç†å›½é™…

ä¼šè®®ï¼Œç¬¬ 185â€“189 é¡µã€‚IEEEï¼Œ2014

å¹´

ã€‚

Yong Zhao, Jinyu Li,

and Yifan Gong. Low-rank

plus diagonal adaptation for

deep neural

networks. In

2016 IEEE International Conference

on Acoustics, Speech and

Signal Processing

(ICASSP),

ã€æé³å®‡å’Œé¾š

ä¸€å‡¡ã€‚æ·±åº¦ç¥

ç»ç½‘ç»œçš„ä½

ç§©åŠ å¯¹è§’è‡ª

é€‚åº”ã€‚2016

å¹´ IEEE å£°å­¦

ã€è¯­éŸ³å’Œä¿¡å·

å¤„

ç†å›½é™…ä¼š

è®®(ICASSP)ï¼Œ

pp. 5005â€“5009. IEEE, 2016.

ç¬¬ 5005â€“5009 é¡µã€‚IEEEï¼Œ2016ã€‚

Victor

Zhong, Caiming Xiong, and

Richard Socher. Seq2sql: Generating

structured queries from

natural

language using reinforcement learning.

CoRR, abs/1709.00103, 2017. URL

http://

arxiv.org/abs/1709.00103.

é’Ÿï¼Œç†Š

å’Œç†æŸ¥å¾·ç´¢

å¥‘ã€‚Seq2sql:ä½¿ç”¨å¼ºåŒ–

å­¦ä¹ ä»è‡ªç„¶

è¯­è¨€ç”Ÿæˆç»“

æ„åŒ–æŸ¥è¯¢ã€‚æ›´

æ­£ï¼Œabs/

1709.00103ï¼Œ2017ã€‚ç»Ÿä¸€èµ„æº

å®šä½å™¨

http://arxiv.org/abs/1709.00103ã€‚

A LARGE LANGUAGE

MODELS STILL NEED PARAMETER

UPDATES

B å¤§å‹

è¯­è¨€æ¨¡å‹ä»

ç„¶éœ€è¦å‚æ•°

æ›´æ–°

Few-shot

learning, or prompt engineering,

is very advantageous when

we only have a

handful of

training samples.

However, in practice, we

can often afford to

curate a few thousand

or more

training examples

for performance-sensitive applications. As

shown in Table 8,

fine-tuning

improves the model

performance drastically compared to

few-shot learning on datasets

large and

small. We

take the GPT-3 few-shot

result on RTE from

the GPT-3 paper (Brown

et al., 2020). For

MNLI-matched, we use two

demonstrations per class and

six in-context examples in

total.

å½“æˆ‘ä»¬

åªæœ‰å°‘æ•°å‡ 

ä¸ªè®­ç»ƒæ ·æœ¬

æ—¶ï¼Œå°‘é‡å­¦ä¹ 

æˆ–å¿«é€Ÿå·¥ç¨‹

æ˜¯éå¸¸æœ‰åˆ©

çš„ã€‚ç„¶è€Œï¼Œåœ¨å®

è·µä¸­ï¼Œ

æˆ‘ä»¬ç»

å¸¸èƒ½å¤Ÿä¸ºæ€§

èƒ½æ•æ„Ÿçš„åº”

ç”¨ç¨‹åºç­–åˆ’

å‡ åƒä¸ªç”šè‡³

æ›´å¤šçš„è®­ç»ƒ

ç¤ºä¾‹ã€‚å¦‚æ‰€ç¤º

Table 8,ä¸

åœ¨å¤§æ•°æ®

é›†å’Œå°æ•°æ®

é›†ä¸Šçš„å°‘é‡

å­¦ä¹ ç›¸æ¯”ï¼Œå¾®

è°ƒæ˜¾è‘—æé«˜

äº†æ¨¡å‹æ€§èƒ½

ã€‚æˆ‘ä»¬ä» GPT-3 çš„è®º

æ–‡ä¸­æå–äº†

GPT-3 åœ¨

RTE ä¸Šçš„å°‘é‡

å‘å°„ç»“æœ(Brown et al.,2020).å¯¹

äº

MNLI åŒ¹é…ï¼Œæˆ‘ä»¬

æ¯

ä¸ªç±»ä½¿ç”¨

ä¸¤ä¸ªæ¼”ç¤ºï¼Œæ€»

å…±ä½¿ç”¨å…­ä¸ª

ä¸Šä¸‹æ–‡ç¤ºä¾‹

ã€‚

5

Method

æ–¹æ³•

GPT-3 Few-Shot

GPT-3 Fine-Tuned

GPT-3 å°‘å°„

GPT-3

å¾®

è°ƒ

MNLI-m (Val.

Acc./%) RTE (Val. Acc./%)

5

MNLI-m (Valã€‚Accã€‚/%) RTE

(Valã€‚Accã€‚/%)

40.6

69.0

40.6

69.0

89.5 85.4

89.5

85.4

Table 8: Fine-tuning

significantly outperforms few-shot learning

on GPT-3 (Brown et

al., 2020).

è¡¨ 8:åœ¨

GPT-3 ä¸Šï¼Œå¾®

è°ƒæ˜æ˜¾ä¼˜äº

å°‘é‡å­¦ä¹ (Brown et al.,2020).

C INFERENCE LATENCY INTRODUCED

BY ADAPTER LAYERS

D

é€‚

é…å™¨å±‚å¼•å…¥

çš„æ¨ç†å»¶è¿Ÿ

Adapter layers are external

modules added to a

pre-trained model in a

sequential manner, whereas

our

proposal, LoRA, can be

seen as external modules

added in a parallel

manner. Consequently,

adapter layers

must be computed in

addition to the base

model, inevitably introducing additional

latency. While as pointed

out in RuÂ¨ckleÂ´ et

al. (2020), the latency

introduced by adapter layers

can be mitigated when

the model batch size

and/or sequence length is

large enough to full

utilize

the hardware parallelism.

We confirm their observation

with a similar latency

study on GPT-2

medium

and point out that

there are scenarios, notably

online inference where the

batch size is

small,

where the added latency

can be significant.

é€‚é…å™¨å±‚æ˜¯

ä»¥é¡ºåºæ–¹å¼

æ·»åŠ åˆ°é¢„è®­

ç»ƒæ¨¡å‹çš„å¤–

éƒ¨æ¨¡å—ï¼Œè€Œæˆ‘

ä»¬çš„æè®®

LoRA å¯

ä»¥è¢«è§†ä¸ºä»¥

å¹¶

è¡Œæ–¹å¼æ·»

åŠ çš„å¤–éƒ¨æ¨¡

å—ã€‚å› æ­¤ï¼Œé™¤äº†

åŸºæœ¬æ¨¡å‹ä¹‹

å¤–ï¼Œè¿˜å¿…é¡»è®¡

ç®—é€‚é…å™¨å±‚

ï¼Œè¿™ä¸å¯é¿å…

åœ°

ä¼šå¸¦æ¥é¢

å¤–çš„å»¶è¿Ÿã€‚æ­£

å¦‚åœ¨ä¸­æŒ‡å‡º

çš„

RuÂ¨ckleÂ´ et al.(2020),å½“æ¨¡å‹æ‰¹

é‡å¤§å°å’Œ/æˆ–

åºåˆ—

é•¿åº¦è¶³

å¤Ÿå¤§ä»¥å……åˆ†

åˆ©ç”¨ç¡¬ä»¶å¹¶

è¡Œæ€§æ—¶ï¼Œå¯ä»¥

å‡è½»é€‚é…å™¨

å±‚å¼•å…¥çš„å»¶

è¿Ÿã€‚æˆ‘ä»¬é€šè¿‡

åœ¨

GPT-2 åŸ¹

å…»åŸºä¸Š

è¿›è¡Œçš„ç±»ä¼¼

å»¶è¿Ÿç ”ç©¶è¯

å®äº†ä»–ä»¬çš„

è§‚å¯Ÿç»“æœï¼Œå¹¶

æŒ‡å‡ºå­˜åœ¨ä¸€

äº›æƒ…å†µï¼Œç‰¹åˆ«

æ˜¯åœ¨çº¿æ¨

æ–­

ï¼Œå…¶ä¸­æ‰¹é‡è¾ƒ

å°ï¼Œå¢åŠ çš„å»¶

è¿Ÿå¯èƒ½å¾ˆå¤§

ã€‚

We measure the latency

of a single forward

pass on an NVIDIA

Quadro RTX8000 by averaging

over 100 trials. We

vary the input batch

size, sequence length, and

the adapter bottleneck

dimension

æˆ‘ä»¬é€šè¿‡å¹³

å‡ 100 æ¬¡è¯•éªŒæ¥

æµ‹é‡ NVIDIA

Quadro RTX8000 ä¸Šå•æ¬¡

è½¬å‘çš„å»¶è¿Ÿ

ã€‚æˆ‘ä»¬æ”¹å˜è¾“

å…¥æ‰¹é‡å¤§å°

ã€åºåˆ—é•¿åº¦å’Œ

é€‚é…å™¨ç“¶é¢ˆ

å°ºå¯¸

r.

We test two adapter

designs: the original one

by Houlsby et al.

(2019), which we call

AdapterH

,

and a

recent, more efficient variant

by Lin et al.

(2020), which we call

AdapterL

. See Section

5.1

for more details

on the designs. We

plot the slow-down in

percentage compared to the

no-adapter

baseline in Figure

5.

r.æˆ‘ä»¬æµ‹

è¯•äº†ä¸¤ç§é€‚

é…å™¨è®¾è®¡:åŸ

å§‹è®¾è®¡ Houlsby et

al.(2019),æˆ‘ä»¬

ç§°ä¹‹ä¸º AdapterHï¼Œä»¥

åŠ

æœ€è¿‘çš„ä¸€ä¸ª

æ›´æœ‰æ•ˆçš„å˜

ä½“ Lin

et al.(2020),æˆ‘ä»¬ç§°ä¹‹

ä¸º adapter 1ã€‚çœ‹è§

Section 5.1

äº†è§£

æ›´å¤šè®¾è®¡ç»†

èŠ‚ã€‚æˆ‘ä»¬åœ¨ä¸­

ç»˜åˆ¶äº†ä¸æ— 

é€‚é…å™¨åŸºçº¿

ç›¸æ¯”çš„é€Ÿåº¦

ä¸‹é™ç™¾åˆ†æ¯”

Figure 5.

Seq Len = 128

Seq Len = 256

Seq Len = 512

åºåˆ—é•¿åº¦= 128 åº

åˆ—é•¿åº¦= 256

åºåˆ—

é•¿åº¦= 512

35

35

30

30

25

25

0 0

Adapter

250100

1

H

Adapter

250100

1

5

20

20

15

15

10

10

5

5

0

0

1 2 4 8

1632

ä¸€ 2 å››

8 1632

Batch Size

æ‰¹

é‡

1 2 4

8 1632 ä¸€ 2

å›› 8 1632

Batch

Size

æ‰¹é‡

0 0

Adapte

1

L

Adapter

1

250100 250100

5

1

2 4 8 1632

ä¸€ 2 å›› 8

1632

Batch Size

æ‰¹é‡

Figure 5: Percentage slow-down

of inference latency compared

to the no-adapter (r

= 0) baseline.

The

top row shows the

result for AdapterH

and the bottom row

AdapterL

. Larger batch

size and

sequence length

help to mitigate the

latency, but the slow-down

can be as high

as over 30% in

an

online, short-sequence-length scenario.

We tweak the colormap

for better visibility.

å›¾

5:ä¸æ— é€‚é…å™¨

(r

= 0)åŸºçº¿ç›¸æ¯”ï¼Œæ¨

ç†å»¶è¿Ÿé™ä½

çš„ç™¾åˆ†æ¯”ã€‚é¡¶

è¡Œæ˜¾ç¤º AdapterH çš„ç»“

æœï¼Œ

åº•è¡Œæ˜¾ç¤º

AdapterL çš„ç»“æœã€‚è¾ƒå¤§

çš„æ‰¹é‡å’Œåº

åˆ—é•¿åº¦æœ‰åŠ©

äºå‡å°‘å»¶è¿Ÿ

ï¼Œä½†åœ¨çŸ­åºåˆ—

é•¿åº¦çš„åœ¨

çº¿

åœºæ™¯ä¸­ï¼Œé€Ÿåº¦

ä¼šé™ä½ 30%ä»¥ä¸Š

ã€‚æˆ‘ä»¬è°ƒæ•´è‰²

å›¾ä»¥è·å¾—æ›´

å¥½çš„å¯è§†æ€§

ã€‚

E DATASET DETAILS

F

æ•°æ®é›†è¯¦ç»†

ä¿¡æ¯

GLUE Benchmark is

a wide-ranging collection of

natural language understanding tasks.

It

includes MNLI (inference,

Williams et al. (2018)),

SST-2 (sentiment analysis, Socher

et al.

(2013)), MRPC

(paraphrase detection, Dolan &

Brockett (2005)), CoLA (linguistic

acceptability,

Warstadt et al.

(2018)), QNLI (inference, Rajpurkar

et al. (2018)), QQP8

(question-answering),

RTE (inference),

GLUE

Benchmark æ˜¯ä¸€ä¸ª

å¹¿æ³›çš„è‡ªç„¶

è¯­è¨€ç†è§£ä»»

åŠ¡é›†åˆã€‚å®ƒåŒ…

æ‹¬ MNLI(æ¨è®ºï¼ŒWilliams et

al.(2018)),SST-2( æƒ… ç»ª

åˆ† æ

ï¼Œ Socher et al.(2013)),MRPC(

æ„ è¯‘ æ£€

æµ‹ ï¼Œ

Dolan &

Brockett(2005)),å¯ä¹(è¯­è¨€

å¯æ¥å—æ€§ï¼ŒWarstadt et

al.(2018)),QNLI(æ¨

è®ºï¼ŒRajpurkar

et al.(2018)),QQP

8

(é—®ç­”)ï¼ŒRTE(æ¨ç†

)ï¼Œ

8

https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs

8

https://quoradata . Quora .

com/First-Quora-Dataset-Release-Question-Pairs

{ } {

}

{ } {

}

{ }

\

\

{ }

\

\

5

and STS-B

(textual similarity, Cer et

al. (2017)). The broad

coverage makes GLUE benchmark

a

standard metric to

evaluate NLU models such

as RoBERTa and DeBERTa.

The individual

datasets are

released under different permissive

licenses.

å’Œ STS-B(æ–‡æœ¬ç›¸ä¼¼

æ€§ï¼ŒCer et

al.(2017)).å¹¿ æ³› çš„ è¦†

ç›–

é¢ ä½¿ G L

U E b e

n c h m

a r k æˆ

ä¸º

è¯„ ä¼° R o

B E R T

a å’Œ D e

B E R T

a ç­‰ N L

U æ¨¡

å‹ çš„ æ ‡

å‡† æŒ‡

æ ‡ ã€‚ å„

ä¸ª æ•° æ®

é›† æ ¹

æ® ä¸ åŒ

çš„ è®¸

å¯ å è®®

å‘ å¸ƒ

ã€‚

WikiSQL is introduced

in Zhong et al.

(2017) and contains 56,

355/8, 421 training/validation exï¿¾amples.

The task is to

generate SQL queries from

natural language questions and

table schemata.

We encode

context as 

under

the BSD 3-Clause License.

x = table schema,

query and target as

y = SQL .

The dataset is release

WikiSQL æ˜¯åœ¨ Zhong et

al.(2017)å¹¶

ä¸”åŒ…å« 56ï¼Œ355/8ï¼Œ421 ä¸ªè®­

ç»ƒ/éªŒè¯æ ·æœ¬

ã€‚ä»»åŠ¡æ˜¯ä»

è‡ª

ç„¶è¯­è¨€é—®é¢˜

å’Œè¡¨æ¨¡å¼ä¸­

ç”Ÿæˆ

SQL æŸ¥è¯¢ã€‚æˆ‘

ä»¬å°†ä¸Šä¸‹æ–‡

ç¼–ç ä¸º x =è¡¨æ¨¡

å¼ï¼Œå°†æŸ¥è¯¢å’Œ

ç›®æ ‡ç¼–

ç ä¸º

y = SQLã€‚æ•°æ®é›†æ˜¯åœ¨

BSD 3

æ¡æ¬¾è®¸å¯ä¸‹

å‘å¸ƒçš„ã€‚

SAMSum is introduced

in Gliwa et al.

(2019) and contains 14,

732/819 training/test examples. It

consists of staged chat

conversations between two people

and corresponding abstractive

summaries

written by linguists. We

encode context as â€

nâ€ concatenated utterances followed

by a

â€

Creative

Commons BY-NC-ND 4.0.

n

nâ€, and target as

y = summary .

The dataset is released

under the non-commercial licence:

SAMSum æ˜¯åœ¨

Gliwa et al.(2019)å¹¶ä¸”åŒ…å«

14ï¼Œ732/819 ä¸ª

è®­ç»ƒ/æµ‹è¯•ç¤º

ä¾‹ã€‚å®ƒç”±ä¸¤ä¸ª

äººä¹‹

é—´çš„é˜¶

æ®µæ€§èŠå¤©å¯¹

è¯å’Œè¯­è¨€å­¦

å®¶æ’°å†™çš„ç›¸

åº”æŠ½è±¡æ€»ç»“

ç»„æˆã€‚æˆ‘ä»¬å°†

ä¸Šä¸‹æ–‡ç¼–ç 

ä¸ºâ€œnâ€ä¸ªè¿

æ¥

å¸ƒ

:

çš„

Creati

è¯è¯­ï¼Œ

ve 

å

Commons

B

è·Ÿ

ä¸€ä¸ªâ€œ

Y-

n

n

NC-N

â€

D

ï¼Œ

4.0

ç›®æ ‡

ã€‚

ä¸º

y = summaryã€‚è¯¥æ•°æ®é›†åœ¨

éå•†ä¸šè®¸å¯

ä¸‹å‘

E2E

NLG Challenge was first

introduced in Novikova et

al. (2017) as a

dataset for training endï¿¾to-

end, data-driven natural language

generation systems and is

commonly used for data-to-text

evalua- tion. The E2E

dataset consists of roughly

42, 000 training, 4,

600 validation, and 4,

600

test exam- ples

from the restaurant domain.

Each source table used

as input can have

multiple

references. Each sample

input (x, y) consists

of a sequence of

slot-value pairs, along with

a

corresponding natural language

reference text. The dataset

is released under Creative

Commons

BY-NC-SA 4.0.

e2eÂ·NLG

æŒ‘æˆ˜èµ›

é¦–æ¬¡ä¸¾åŠäº

1989 å¹´ Novikova et

al.(2017)ä½œä¸ºç”¨äº

è®­ç»ƒç«¯åˆ°ç«¯

ã€æ•°æ®é©±åŠ¨

çš„

è‡ªç„¶è¯­è¨€ç”Ÿ

æˆç³»ç»Ÿçš„æ•°

æ®é›†ï¼Œå¹¶ä¸”é€š

å¸¸ç”¨äºæ•°æ®

åˆ°æ–‡æœ¬çš„è¯„

ä¼°ã€‚E2E æ•°æ®é›†åŒ…

æ‹¬å¤§çº¦ 42ï¼Œ000

ä¸ªè®­

ç»ƒã€4ï¼Œ600 ä¸ªéªŒè¯å’Œ

4ï¼Œ600 ä¸ªæ¥è‡ªé¤é¦†

é¢†åŸŸçš„æµ‹è¯•

æ ·æœ¬ã€‚ç”¨ä½œè¾“

å…¥çš„æ¯ä¸ªæº

è¡¨å¯ä»¥æœ‰å¤š

ä¸ªå¼•ç”¨ã€‚æ¯ä¸ª

æ ·æœ¬è¾“å…¥(xï¼Œy)ç”±

ä¸€ç³»åˆ—æ§½å€¼

å¯¹ä»¥åŠç›¸åº”

çš„è‡ªç„¶è¯­è¨€

å‚è€ƒæ–‡æœ¬ç»„

æˆã€‚è¯¥æ•°æ®é›†

ç”±-

NC-SA

4.0 åœ¨ Creative Commons

ä¸‹å‘å¸ƒ

ã€‚

DART is an

open-domain data-to-text dataset described

in Nan et al.

(2020). DART inputs are

structured as sequences of

ENTITY â€” RELATION â€”

ENTITY triples. With 82K

examples in

total, DART

is a significantly larger

and more complex data-to-text

task compared to E2E.

The

dataset is released

under the MIT license.

DART æ˜¯å¼€æ”¾åŸŸæ•°

æ®è½¬æ–‡æœ¬æ•°

æ®é›†ï¼Œå¦‚ä¸­æ‰€

è¿° Nan et

al.(2020).D A R T

è¾“ å…¥ çš„ ç»“

æ„

æ˜¯ å®

ä½“ -

å…³

ç³» - å® ä½“

ä¸‰ å…ƒ

ç»„ çš„ åº

åˆ— ã€‚ ä¸

E 2

E ç›¸ æ¯” ï¼Œ

D A R T

æ€» å…± æœ‰

8 2

K ä¸ª ç¤º ä¾‹

ï¼Œ æ˜¯ ä¸€

ä¸ª æ›´

å¤§ ã€ æ›´ å¤

æ‚

çš„ æ•° æ® è½¬

æ–‡

æœ¬ ä»» åŠ¡ ã€‚

è¯¥

æ•° æ® é›† æ˜¯

åœ¨

éº» çœ ç† å·¥

å­¦

é™¢ è®¸ å¯ ä¸‹

å‘

å¸ƒ

çš„ ã€‚

WebNLG

is another commonly used

dataset for data-to-text evaluation

(Gardent et al., 2017).

With 22K examples in

total WebNLG comprises 14

distinct categories, nine of

which are seen

during

training. Since five of

the 14 total categories

are not seen during

training, but are

represented

in the test set,

evaluation is typically broken

out by â€œseenâ€ categories

(S), â€œunseenâ€

categories (U)

and â€œallâ€ (A). Each

input example is represented

by a sequence of

SUBJECT â€”

PROPERTY â€”

OBJECT triples. The dataset

is released under Creative

Commons BY-NC-SA

4.0.

WebNLG

æ˜¯å¦ä¸€

ä¸ªå¸¸ç”¨äºæ•°

æ®åˆ°æ–‡æœ¬è¯„

ä¼°çš„æ•°æ®é›†

(Gardent et al.,2017).WebNLG æ€»å…±æœ‰

22K ä¸ªç¤º

ä¾‹ï¼ŒåŒ…æ‹¬ 14 ä¸ªä¸

åŒçš„ç±»åˆ«ï¼Œå…¶

ä¸­

9 ä¸ªæ˜¯åœ¨åŸ¹

è®­æœŸé—´çœ‹åˆ°

çš„ã€‚ç”±äº 14 ä¸ªæ€»

ç±»åˆ«ä¸­çš„

â€ 

â€ 

5

5

ä¸ª

åœ¨è®­ç»ƒæœŸé—´

ä¸å¯è§ï¼Œä½†æ˜¯

åœ¨æµ‹è¯•é›†ä¸­

å‡ºç°ï¼Œæ‰€ä»¥è¯„

ä¼°é€šå¸¸ç”±â€œå¯

è§â€ç±»åˆ«(S)ã€â€œä¸å¯

è§â€ç±»åˆ«(U)å’Œâ€œå…¨

éƒ¨â€(A)æ¥åˆ’åˆ†ã€‚æ¯

ä¸ªè¾“å…¥çš„ä¾‹

å­éƒ½ç”±ä¸€ç³»

åˆ—çš„ä¸»è¯­â€”â€”å±

æ€§â€”â€”å®¾è¯­

ä¸‰å…ƒ

ç»„è¡¨ç¤ºã€‚è¯¥æ•°

æ®é›†ç”±-NC-SA 4.0 åœ¨

Creative Commons ä¸‹

å‘å¸ƒã€‚

G

HYPERPARAMETERS USED IN EXPERIMENTS

H å®éªŒä¸­

ä½¿ç”¨çš„è¶…å‚

æ•°

H.1 ROBERTA

H.2 ç½—ä¼¯å¡”

We train

using AdamW with a

linear learning rate decay

schedule. We sweep learning

rate,

number of training

epochs, and batch size

for LoRA. Following Liu

et al. (2019), we

initialize the

LoRA modules

to our best MNLI

checkpoint when adapting to

MRPC, RTE, and STS-B,

instead

of the usual

initialization; the pre-trained model

stays frozen for all

tasks. We report the

median

over 5 random

seeds; the result for

each run is taken

from the best epoch.

For a fair comparison

with the setup in

Houlsby et al. (2019)

and Pfeiffer et al.

(2021), we restrict the

model sequence

length to

128 and used a

fixed batch size for

all tasks. Importantly, we

start with the pre-trained

RoBERTa large model when

adapting to MRPC, RTE,

and STS-B, instead of

a model already

adapted

to MNLI. The

hyperparameters

used in our

runs

runs in 

with

Table 9.

this restricted

setup are marked with

. See the

æˆ‘

ä»¬ä½¿ç”¨

AdamW å’Œçº¿

æ€§å­¦ä¹ ç‡è¡°

å‡æ—¶é—´è¡¨è¿›

è¡Œè®­ç»ƒã€‚æˆ‘ä»¬

æ‰«æå­¦ä¹ ç‡

ï¼Œè®­ç»ƒæ—¶æœŸçš„

æ•°é‡ï¼Œ

ä»¥åŠ LoRA

çš„

æ‰¹é‡å¤§å°ã€‚è·Ÿ

éš Liu et al.(2019),å½“é€‚åº”

MRPCã€RTE å’Œ

STS-B æ—¶ï¼Œæˆ‘ä»¬å°†

LoRA

æ¨¡

å—åˆå§‹åŒ–ä¸º

æˆ‘ä»¬çš„æœ€ä½³

MNLI æ£€æŸ¥ç‚¹ï¼Œè€Œä¸

æ˜¯é€šå¸¸çš„åˆ

å§‹åŒ–ï¼›é¢„è®­ç»ƒ

æ¨¡å‹åœ¨æ‰€æœ‰

ä»»åŠ¡

ä¸­ä¿æŒ

å†»ç»“ã€‚æˆ‘ä»¬æŠ¥

å‘Šäº† 5

ä¸ªéšæœº

ç§å­çš„ä¸­ä½

æ•°ï¼›æ¯æ¬¡è¿è¡Œ

çš„ç»“æœå–è‡ª

æœ€ä½³æ—¶æœŸã€‚ä¸º

äº†ä¸

ä¸­çš„è®¾

ç½®è¿›è¡Œå…¬å¹³

çš„æ¯”è¾ƒ Houlsby et

al.(2019)å’Œ Pfeiffer et al.(2021),æˆ‘

ä»¬å°†æ¨¡å‹åº

åˆ—é•¿åº¦é™åˆ¶

ä¸º

128ï¼Œå¹¶å¯¹æ‰€æœ‰

ä»»åŠ¡ä½¿ç”¨å›º

å®šçš„æ‰¹é‡å¤§

å°ã€‚é‡è¦çš„æ˜¯

ï¼Œå½“é€‚åº” MRPCã€RTE å’Œ STS-B

æ—¶

ï¼Œæˆ‘ä»¬ä»é¢„è®­

ç»ƒçš„ RoBERTa å¤§æ¨¡å‹

å¼€å§‹ï¼Œè€Œä¸æ˜¯

å·²ç»é€‚åº” MNLI

çš„

æ¨¡å‹ã€‚å…·æœ‰æ­¤

å—é™è®¾ç½®çš„

è¿

è¡Œæ ‡æœ‰ã€‚è¯·

å‚é˜…æˆ‘ä»¬åœ¨

è¿è¡Œä¸­ä½¿ç”¨

çš„è¶…å‚æ•° Table 9.

H.3 DEBERTA

H.4 å¾·

ä¼¯å¡”

We again train using

AdamW with a linear

learning rate decay schedule.

Following He et al.

(2021), we tune learning

rate, dropout probability, warm-up

steps, and batch size.

We use the

same

model sequence length used

by (He et al.,

2021) to keep our

comparison fair. Following He

et al. (2021), we

initialize the LoRA modules

to our best MNLI

checkpoint when adapting to

MRPC, RTE, and STS-B,

instead of the usual

initialization; the pre-trained model

stays frozen for

all

tasks. We report the

median over 5 random

seeds; the result for

each run is taken

from the best

epoch.

See the hyperparameters used

in our runs in

Table 10.

æˆ‘ä»¬å†

æ¬¡ä½¿ç”¨ AdamW

å’Œçº¿

æ€§å­¦ä¹ ç‡è¡°

å‡æ—¶é—´è¡¨è¿›

è¡Œè®­ç»ƒã€‚è·Ÿéš

He et al.(2021),æˆ‘ä»¬è°ƒæ•´

å­¦

ä¹ é€Ÿåº¦ã€é€€å‡º

æ¦‚ç‡ã€çƒ­èº«æ­¥

éª¤å’Œæ‰¹é‡å¤§

å°ã€‚æˆ‘ä»¬ä½¿ç”¨

çš„æ¨¡å‹åºåˆ—

é•¿åº¦ä¸(He

et

al.,2021)ä¸ºäº†

è®©æˆ‘ä»¬çš„æ¯”

è¾ƒå…¬å¹³ã€‚è·Ÿéš

He et al.(2021),å½“é€‚åº”

MRPCã€RTE å’Œ STS-B æ—¶

ï¼Œ

æˆ‘ä»¬å°† LoRA æ¨¡å—

åˆå§‹åŒ–ä¸ºæˆ‘

ä»¬çš„æœ€ä½³ MNLI

æ£€

æŸ¥ç‚¹ï¼Œè€Œä¸æ˜¯

é€šå¸¸çš„åˆå§‹

åŒ–ï¼›é¢„è®­ç»ƒæ¨¡

å‹åœ¨

æ‰€æœ‰ä»»

åŠ¡ä¸­ä¿æŒå†»

ç»“ã€‚æˆ‘ä»¬æŠ¥å‘Š

äº† 5 ä¸ªéšæœºç§

å­çš„ä¸­ä½æ•°

ï¼›æ¯æ¬¡è¿è¡Œçš„

ç»“æœå–è‡ªæœ€

ä½³æ—¶

æœŸã€‚è¯·å‚

é˜…æˆ‘ä»¬åœ¨è¿

è¡Œä¸­ä½¿ç”¨çš„

è¶…å‚æ•° Table 10.

5

Method Dataset MNLI SST-2

MRPC CoLA QNLI QQP

RTE STS-B

Optimizer AdamW

Warmup Ratio 0.06

LR

Schedule Linear

Batch Size

16 16 16 32

32 16 32 16

RoBERTa base # Epochs

30 60 30 80

25 25 80 40

LoRA Learning Rate 5E-04

5E-04 4E-04 4E-04 4E-04

5E-04 5E-04 4E-04

LoRA

Config. rq = rv

= 8

LoRA Î±

8

Max Seq. Len.

512

Batch Size 4

4 4 4 4

4 8 8

RoBERTa

large # Epochs 10

10 20 20 10

20 20 30

LoRA

Learning Rate 3E-04 4E-04

3E-04 2E-04 2E-04 3E-04

4E-04 2E-04

LoRA Config.

rq = rv =

8

LoRA Î± 16

Max Seq. Len. 128

128 512 128 512

512 512 512

Batch

Size 4

RoBERTa large

# Epochs 10 10

20 20 10 20

20 10

LoRAâ€ 

Learning

Rate 3E-04 4E-04 3E-04

2E-04 2E-04 3E-04 4E-04

2E-04

LoRA Config. rq

= rv = 8

LoRA Î± 16

Max

Seq. Len. 128

Batch

Size 32

RoBERTa large

# Epochs 10 20

20 20 10 20

20 20

AdptP

(3M)â€ 

Learning Rate 3E-05 3E-05

3E-04 3E-04 3E-04 3E-04

3E-04 3E-04

Bottleneck r

64

Max Seq. Len.

128

Batch Size 32

RoBERTa large # Epochs

5 20 20 20

10 20 20 20

AdptP

(0.8M)â€  Learning Rate

3E-04 3E-04 3E-04 3E-04

3E-04 3E-04 3E-04 3E-04

Bottleneck r 16

Max

Seq. Len. 128

Batch

Size 32

RoBERTa large

# Epochs 10 5

10 10 5 20

20 10

æ–¹æ³•

èµ„æ–™ç»„ MNLI

SST-2 MRPC å¯ä¹

QNLI QQP

RTE STS-B

ã€è®¡ç®—æœºã€‘ä¼˜

åŒ–

ç¨‹åº

é˜¿è¾¾å§†

é¢„çƒ­æ¯” 0.06

LR è®¡åˆ’

çº¿æ€§çš„

æ‰¹é‡

16 16 16 32

32 16 32 16

ç½—ä¼¯å¡”åŸºåœ°

#æ—¶ä»£ 30 60 30

80 25 25 80

40

åŠ³æ‹‰ å­¦

ä¹ ç‡ 5E-04

5E-04 4E-04 4E-04 4E-04

5E-04 5E-04 4E-04

LoRA

é…ç½®ã€‚ rq = rv

= 8

åŠ³

æ‹‰ Î±

8

æœ€å¤§åºåˆ—

ã€‚è±æ©ã€‚ 512

æ‰¹é‡

å››

å›› å›› å›› å››

å››

8 8

ç½—ä¼¯å¡”Â·æ‹‰å‰

#æ—¶ä»£ 10

10 20 20 10

20 20 30

åŠ³æ‹‰

å­¦

ä¹ ç‡ 3E-04 4E-04 3E-04

2E-04 2E-04 3E-04 4E-04

2E-04

LoRA é…ç½®ã€‚ rq

= rv = 8

åŠ³

æ‹‰ Î± 16

æœ€å¤§åºåˆ—

ã€‚è±æ©ã€‚

128 128 512 128

512 512 512 512

æ‰¹é‡ å››

ç½—ä¼¯å¡”Â·æ‹‰å‰

#æ—¶ä»£ 10 10

20 20 10 20

20 10

LoRA å­¦ä¹ ç‡

3E-04

4E-04 3E-04 2E-04 2E-04

3E-04 4E-04 2E-04

LoRA

é…ç½®ã€‚ rq = rv

= 8

åŠ³æ‹‰ Î±

16

æœ€

å¤§åºåˆ—ã€‚è±æ©

ã€‚ 128

5

æ‰¹é‡ 32

ç½—ä¼¯å¡”

Â·æ‹‰å‰ #æ—¶ä»£

10 20 20 20

10 20 20 20

AdptP (3M) å­¦

ä¹ ç‡ 3E-05

3E-05 3E-04 3E-04 3E-04

3E-04 3E-04 3E-04

ç“¶é¢ˆæ²³

64

æœ€å¤§åºåˆ—ã€‚è±

æ©ã€‚ 128

æ‰¹é‡ 32

ç½—ä¼¯

å¡”Â·æ‹‰å‰ #æ—¶ä»£

5 20 20

20 10 20 20

20

AdptP(0.8 ç±³) å­¦ä¹ ç‡

3E-04 3E-04 3E-04 3E-04

3E-04 3E-04 3E-04 3E-04

ç“¶

é¢ˆæ²³ 16

æœ€å¤§åº

åˆ—ã€‚è±æ©ã€‚ 128

æ‰¹é‡

32

ç½—ä¼¯å¡”Â·æ‹‰å‰

#æ—¶ä»£ 10 5

10 10 5 20

20 10

Table 9:

The hyperparameters we used

for RoBERTa on the

GLUE benchmark.

è¡¨ 9:æˆ‘ä»¬

åœ¨

GLUE åŸºå‡†æµ‹è¯•

ä¸­ä¸º RoBERTa ä½¿ç”¨çš„

è¶…å‚æ•°ã€‚

H.5 GPT-2

H.6 GPT-2

We train all of

our GPT-2 models using

AdamW (Loshchilov & Hutter,

2017) with a linear

learning rate schedule for

5 epochs. We use

the batch size, learning

rate, and beam search

beam

size described in

Li & Liang (2021).

Accordingly, we also tune

the above hyperparameters for

LoRA. We report the

mean over 3 random

seeds; the result for

each run is taken

from the best

epoch.

The hyperparameters used for

LoRA in GPT-2 are

listed in Table 11.

For those used for

other baselines, see Li

& Liang (2021).

æˆ‘ä»¬

ä½¿ç”¨

AdamW è®­ç»ƒæˆ‘

ä»¬æ‰€æœ‰çš„ GPT-2 æ¨¡

å‹(Loshchilov

& Hutter,2017)å…·æœ‰ 5 ä¸ªæ—¶

æœŸçš„çº¿

æ€§å­¦

ä¹ ç‡æ—¶é—´è¡¨

ã€‚æˆ‘ä»¬ä½¿ç”¨æ‰¹

æ¬¡å¤§å°ã€å­¦ä¹ 

ç‡å’Œå…‰æŸæœ

ç´¢å…‰æŸå¤§å°

ï¼Œå¦‚ä¸­æ‰€è¿° Li &

Liang(2021).ç›¸

åº”åœ°ï¼Œæˆ‘ä»¬ä¹Ÿ

ä¸º

LoRA è°ƒæ•´ä¸Šè¿°

è¶…å‚æ•°ã€‚æˆ‘ä»¬

æŠ¥å‘Šäº† 3 ä¸ªéš

æœºç§å­çš„å¹³

å‡å€¼ï¼›æ¯æ¬¡è¿

è¡Œçš„ç»“æœå–

è‡ªæœ€ä½³æ—¶æœŸ

ã€‚GPT-2

ä¸­ç”¨äº LoRA çš„è¶…

å‚æ•°åˆ—äº Table

11.æœ‰

å…³ç”¨äºå…¶ä»–

åŸºçº¿çš„ä¿¡æ¯

ï¼Œè¯·å‚è§ Li & Liang(2021).

H.7 GPT-3

H.8 GPT-3

For all GPT-3 experiments,

we train using AdamW

(Loshchilov & Hutter, 2017)

for 2 epochs with

a batch size of

128 samples and a

weight decay factor of

0.1. We use a

sequence length of 384

for

å¯¹äº

æ‰€æœ‰çš„ GPT-3 å®éªŒ

ï¼Œæˆ‘ä»¬ä½¿ç”¨

AdamW è¿›

è¡Œè®­ç»ƒ(Loshchilov & Hutter,2017)å¯¹äº

æ‰¹æ¬¡

å¤§å°ä¸º

128 ä¸ªæ ·æœ¬ä¸”é‡

é‡è¡°å‡å› å­

ä¸º 0.1 çš„

2 ä¸ªæ—¶æœŸ

ã€‚æˆ‘ä»¬ä½¿ç”¨åº

åˆ—é•¿åº¦ 384 æ¥è¡¨

ç¤º

AdptH

(6M)â€  Learning Rate

Bottleneck r

3E-05 3E-04

3E-04 3E-04 3E-04

64

3E-04 3E-04 3E-04

Max

Seq. Len. 128

Batch

Size 32

RoBERTa large

# Epochs 10 5

10 10 5 20

20 10

AdptH

(0.8M)â€ 

Learning Rate 3E-04 3E-04

3E-04 3E-04 3E-04 3E-04

3E-04 3E-04

Bottleneck r

8

Max Seq. Len.

128

AdptH

(6M)â€  Learning

Bottleneck 

Rate

r

3E-05 3E-04 3E-04 3E-04

64

3E-04 3E-04 3E-04

3E-04

Max Seq. Len.

128

Batch Size 32

RoBERTa large # Epochs

10 5 10 10

5 20 20 10

AdptH

(0.8M)â€  Learning

Bottleneck

Rate

r

3E-04 3E-04

3E-04 3E-04

8

3E-04

3E-04 3E-04 3E-04

Max

Seq. Len. 128

5

Dataset E2EWebNLGDART

Training Dataset

E2EWebNLGDART

Training

Method Dataset

MNLI SST-2 MRPC CoLA

QNLI QQP RTE STS-B

Optimizer AdamW

Warmup Ratio

0.1

LR Schedule Linear

Batch Size 8 8

32 4 6 8

4 4

DeBERTa XXL

# Epochs 5 16

30 10 8 11

11 10

LoRA Learning

Rate 1E-04 6E-05 2E-04

1E-04 1E-04 1E-04 2E-04

2E-04

Weight Decay 0

0.01 0.01 0 0.01

0.01 0.01 0.1

CLS

Dropout 0.15 0 0

0.1 0.1 0.2 0.2

0.2

LoRA Config. rq

= rv = 8

LoRA Î± 8

Max

Seq. Len. 256 128

128 64 512 320

320 128

æ–¹æ³• èµ„æ–™

ç»„

MNLI SST-2 MRPC å¯ä¹

QNLI QQP RTE STS-B

ã€è®¡ç®—

æœºã€‘ä¼˜

åŒ–ç¨‹åº

é˜¿è¾¾å§†

é¢„çƒ­

æ¯” 0.1

LR è®¡åˆ’ çº¿æ€§

çš„

æ‰¹é‡

8 8 32 å››

6 8 å››

å››

å¾·è´å¡”Â·XXL

#æ—¶

ä»£ 5 16 30

10 8 11 11

10

åŠ³æ‹‰ å­¦ä¹ 

ç‡ 1E-04

6E-05 2E-04 1E-04 1E-04

1E-04 2E-04 2E-04

é‡é‡è¡°å‡

0

0.01 0.01 0 0.01

0.01 0.01 0.1

CLS

è¾å­¦ 0.15 0 0

0.1 0.1 0.2 0.2

0.2

LoRA é…ç½®ã€‚ rq

= rv = 8

åŠ³

æ‹‰ Î± 8

æœ€å¤§åºåˆ—

ã€‚è±æ©ã€‚

256 128 128 64

512 320 320 128

Table 10: The hyperparameters

for DeBERTa XXL on

tasks included in the

GLUE benchmark.

è¡¨ 10:DeBERTa

XXL åœ¨ GLUE åŸº

å‡†æµ‹è¯•ä¸­åŒ…

å«çš„ä»»åŠ¡çš„

è¶…å‚æ•°ã€‚

Optimizer 

Weight Decay

0.01

AdamW

0.01 0.0

Dropout Prob 0.1 0.1

0.0

Batch Size 8

# Epoch 5

Warmup

Steps

Learning Rate Schedule

500

Linear

Label Smooth

0.1 0.1 0.0

Learning

Rate

Adaptation 

LoRA

Î±

0.0002

rq =

rv =

4

32

Inference

Beam Size

Length Penalty

no repeat

ngram size

10

0.9

0.8 0.8

4

ä¼˜åŒ–

å™¨æƒé‡

è¡°å‡

0.01

AdamW 

0.01

0.0

è¾å­¦é—®é¢˜ 0.1 0.1

0.0

æ‰¹

é‡ 8

6

#çºªå…ƒ 5

çƒ­èº«

æ­¥éª¤

å­¦ä¹ ç‡

è®¡åˆ’

500

çº¿æ€§çš„

æ ‡ç­¾å¹³æ»‘ 0.1 0.1

0.0

å­¦

ä¹ é€Ÿç‡é€‚

åº”

LoRA Î±

0.0002

rq = rv

= 4

32

æ¨ç†

å…‰æŸå°º

å¯¸é•¿åº¦

æŸå¤±

æ²¡æœ‰é‡å¤çš„

ngram å¤§å°

10

0.9 0.8 0.8

å››

Table 11: The hyperparameters

for GPT-2 LoRA on

E2E, WebNLG and DART.

è¡¨ 11:GPT-2 åŠ³

æ‹‰åœ¨ E2Eï¼ŒéŸ¦ä¼¯å°¼

æ ¼å’Œ

DART çš„è¶…å‚

æ•°ã€‚

WikiSQL (Zhong

et al., 2017), 768

for MNLI (Williams et

al., 2018), and 2048

for SAMSum

(Gliwa et

al., 2019). We tune

learning rate for all

method-dataset combinations. See Section

D.4

for more details

on the hyperparameters used.

For prefix-embedding tuning, we

find the

optimal lp

and li to be

256 and 8, respectively,

totalling 3.2M trainable parameters.

We use

lp =

8 and li =

8 for prefix-layer tuning

with 20.2M trainable parameters

to obtain the overall

best performance. We present

two parameter budgets for

LoRA: 4.7M (rq =

rv = 1 or

rv = 2)

and

37.7M (rq = rv

= 8 or rq

= rk = rv

= ro = 2).

We report the best

validation performance

from each

run. The training hyperparameters

used in our GPT-3

experiments are listed in

Table 12.

WikiSQL(Zhong et

al.,2017),MNLI çš„ 768(Williams et

al.,2018), è¨ å§† æ£®

çš„

2048 å¹´

(Gliwaet al.,2019).æˆ‘ä»¬è°ƒ

æ•´æ‰€æœ‰æ–¹æ³•

-æ•°æ®é›†ç»„åˆ

çš„å­¦ä¹ ç‡ã€‚çœ‹

è§

Section D.4 æœ‰å…³æ‰€

ç”¨

è¶…å‚æ•°çš„æ›´

å¤šè¯¦ç»†ä¿¡æ¯

ã€‚å¯¹äºå‰ç¼€åµŒ

å…¥è°ƒæ•´ï¼Œæˆ‘ä»¬

å‘ç°æœ€ä½³

lp å’Œ

li åˆ†åˆ«ä¸º 256

å’Œ 8ï¼Œæ€»

å…± 3.2M ä¸ªå¯è®­ç»ƒ

å‚æ•°ã€‚æˆ‘ä»¬ä½¿

ç”¨

lp = 8 å’Œ

li = 8ï¼Œé€šè¿‡ 20.2M

çš„

å¯è®­ç»ƒå‚æ•°

è¿›è¡Œå‰ç¼€å±‚

è°ƒæ•´ï¼Œä»¥è·å¾—

æ•´ä½“æœ€ä½³æ€§

èƒ½ã€‚æˆ‘ä»¬ä¸º LoRA æ

å‡ºä¸¤ä¸ªå‚æ•°

é¢„ç®—:4.7M (rq

= rv = 1

æˆ– rv =

2)å’Œ

37.7M (rq = rv

= 8 æˆ–

rq =

rk = rv =

ro = 2)ã€‚æˆ‘ä»¬æŠ¥å‘Šæ¯

æ¬¡è¿è¡Œçš„æœ€

ä½³éªŒè¯æ€§

èƒ½

ã€‚æˆ‘ä»¬åœ¨

GPT-3 å®éªŒ

ä¸­ä½¿ç”¨çš„è®­

ç»ƒè¶…å‚æ•°åˆ—

äº Table 12.

I COMBINING LORA WITH

PREFIX TUNING

J å°†

LORA ä¸å‰ç¼€

è°ƒæ•´ç›¸ç»“åˆ

LoRA can be

naturally combined with existing

prefix-based approaches. In this

section, we

evaluate two

combinations of LoRA and

variants of prefix-tuning on

WikiSQL and MNLI.

LoRA

å¯ä»¥è‡ªç„¶åœ°

ä¸ç°æœ‰çš„åŸº

äºå‰ç¼€çš„æ–¹

æ³•ç›¸ç»“åˆã€‚åœ¨

æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬

è¯„ä¼°äº†ä¸¤ç§

LoRA ç»„åˆä»¥

åŠ WikiSQL

å’Œ

MNLI ä¸Šçš„å‰ç¼€è°ƒ

æ•´å˜ä½“ã€‚

LoRA+PrefixEmbed (LoRA+PE)

combines LoRA with prefix-embedding

tuning, where we insert

lp + li special

tokens whose embeddings are

treated as trainable parameters.

For more on prefixï¿¾embedding

tuning, see Section 5.1.

LoRA+PrefixEmbed (LoRA+PE)ç»“åˆ

äº† LoRA å’Œå‰ç¼€åµŒ

å…¥è°ƒä¼˜ï¼Œå…¶ä¸­

æˆ‘ä»¬æ’å…¥

lp + li ç‰¹

æ®Šä»¤

ç‰Œï¼Œå…¶åµŒ

å…¥è¢«è§†ä¸ºå¯

è®­ç»ƒå‚æ•°ã€‚æœ‰

å…³å‰ç¼€åµŒå…¥

è°ƒæ•´çš„æ›´å¤š

ä¿¡æ¯ï¼Œè¯·å‚è§

Section 5.1.

LoRA+PrefixLayer (LoRA+PL)

combines LoRA with prefix-layer

tuning. We also insert

lp + li

LoRA+å‰ç¼€å±‚(LoRA+PL)ç»“åˆ

äº†

LoRA å’Œå‰ç¼€å±‚

è°ƒæ•´ã€‚æˆ‘ä»¬ä¹Ÿ

æ’å…¥ lp +

li

special tokens; however,

instead of letting the

hidden representations of these

tokens evolve natu-

ç‰¹æ®Šä»£

å¸ï¼›ç„¶è€Œï¼Œä¸å…¶

è®©è¿™äº›æ ‡è®°

çš„éšè—è¡¨ç¤º

è‡ªç„¶å‘å±•

6

Hyperparameters Fine-Tune PreEmbed

PreLayer BitFit AdapterH LoRA

Optimizer AdamW

Batch Size

128

# Epoch 2

Warmup Tokens 

LR

Schedule

250,000

Linear

Learning

Rate 5.00E-06 5.00E-04 1.00E-04

1.6E-03 1.00E-04 2.00E-04

è¶…

å‚æ•°

å¾®è°ƒ é¢„

åµŒå…¥ é¢„å±‚ æ¯”

ç‰¹

Fit

é€‚é…å™¨ h åŠ³

æ‹‰

ã€è®¡ç®—æœºã€‘ä¼˜

åŒ–

ç¨‹åº

é˜¿è¾¾

å§†

æ‰¹é‡

128

#çºªå…ƒ

2

é¢„çƒ­ä»¤ç‰Œ LR

è®¡

åˆ’ 250,000

çº¿æ€§çš„

å­¦

ä¹ ç‡

5.00E-06 5.00E-04 1.00E-04 1.6E-03

1.00E-04 2.00E-

04

Table

12: The training hyperparameters

used for different GPT-3

adaption methods. We use

the

same hyperparameters for

all datasets after tuning

learning rate.

è¡¨ 12:ç”¨äº

ä¸åŒ

GPT-3 é€‚åº”æ–¹

æ³•çš„è®­ç»ƒè¶…

å‚æ•°ã€‚åœ¨è°ƒæ•´

å­¦ä¹ ç‡åï¼Œæˆ‘

ä»¬å¯¹æ‰€æœ‰æ•°

æ®é›†ä½¿ç”¨ç›¸

åŒçš„è¶…å‚æ•°

ã€‚

rally, we

replace them after every

Transformer block with an

input agnostic vector. Thus,

both the

embeddings and

subsequent Transformer block activations

are treated as trainable

parameters. For

more on

prefix-layer tuning, see Section

5.1.

rallyï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ª

è¾“å…¥ä¸å¯çŸ¥

çš„å‘é‡åœ¨æ¯

ä¸ªå˜æ¢å™¨å—

åæ›¿æ¢å®ƒä»¬

ã€‚å› æ­¤ï¼ŒåµŒå…¥å’Œ

éšåçš„å˜

å‹

å™¨å—æ¿€æ´»éƒ½

è¢«è§†ä¸ºå¯è®­

ç»ƒå‚æ•°ã€‚æœ‰å…³

å‰ç¼€å±‚è°ƒæ•´

çš„æ›´å¤šä¿¡æ¯

ï¼Œè¯·å‚è§ Section

5.1.

In Table 15,

we show the evaluation

results of LoRA+PE and

LoRA+PL on WikiSQL and

MultiNLI. First of all,

LoRA+PE significantly outperforms both

LoRA and prefix-embedding

tuning

on WikiSQL, which indicates

that LoRA is somewhat

orthogonal to prefix-embedding

tuning.

On MultiNLI, the combination

of LoRA+PE doesnâ€™t perform

better than LoRA, possibly

because LoRA on its

own already achieves performance

comparable to the human

baseline.

Secondly, we notice

that LoRA+PL performs slightly

worse than LoRA even

with more trainable

parameters.

We at- tribute this

to the fact that

prefix-layer tuning is very

sensitive to the choice

of

learning rate and

thus makes the optimization

of LoRA weights more

difficult in LoRA+PL.

åœ¨â€¦é‡Œ

Table

15,æˆ‘ä»¬å±•ç¤ºäº†

LoRA+PE å’Œ LoRA+PL åœ¨

WikiSQL å’Œ MultiNLI ä¸Šçš„

è¯„æµ‹ç»“æœã€‚é¦–

å…ˆï¼Œåœ¨

WikiSQL ä¸Šï¼ŒLoRA+PE æ˜æ˜¾

ä¼˜äº LoRA

å’Œå‰ç¼€

åµŒå…¥è°ƒä¼˜ï¼Œè¿™

è¡¨æ˜ LoRA ä¸å‰ç¼€

åµŒå…¥è°ƒä¼˜æœ‰

äº›æ­£äº¤ã€‚åœ¨ MultiNLI

ä¸Š

ï¼ŒLoRA+PE çš„ç»„åˆå¹¶ä¸

æ¯” LoRA è¡¨ç°å¾—æ›´

å¥½ï¼Œå¯èƒ½æ˜¯å› 

ä¸º

LoRA æœ¬èº«å·²

ç»

è¾¾åˆ°äº†ä¸äºº

ç±»åŸºçº¿ç›¸å½“

çš„æ€§èƒ½ã€‚å…¶æ¬¡

ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°

ï¼Œå³ä½¿æœ‰æ›´å¤š

çš„å¯è®­ç»ƒå‚

æ•°ï¼ŒLoRA+PL

çš„æ€§èƒ½ä¹Ÿ

æ¯”

LoRA ç¨å·®ã€‚æˆ‘ä»¬

è®¤ä¸ºè¿™æ˜¯å› 

ä¸ºå‰ç¼€å±‚è°ƒ

æ•´å¯¹å­¦ä¹ é€Ÿ

ç‡çš„é€‰æ‹©é

å¸¸æ•æ„Ÿï¼Œä»è€Œ

ä½¿å¾—

LoRA+PL ä¸­

LoRA æƒé‡

çš„ä¼˜åŒ–æ›´åŠ 

å›°éš¾ã€‚

K ADDITIONAL

EMPIRICAL EXPERIMENTS

L é™„åŠ çš„

ç»éªŒå®éªŒ

6

L.1 ADDITIONAL EXPERIMENTS

ON GPT-2

L.2 GPT-2

å·

ä¸Šçš„é™„åŠ å®

éªŒ

We also repeat

our experiment on DART

(Nan et al., 2020)

and WebNLG (Gardent et

al., 2017)

following the

setup of Li &

Liang (2021). The result

is shown in Table

13. Similar to our

result

on E2E NLG

Challenge, reported in Section

5, LoRA performs better

than or at least

on-par with

prefix-based approaches

given the same number

of trainable parameters.

æˆ‘ä»¬è¿˜åœ¨

é£é•–ä¸Šé‡å¤

äº†æˆ‘ä»¬çš„å®

éªŒ(Nan

et al.,2020)å’Œ WebNLG(Gardent et

al.,2017)æŒ‰

ç…§çš„

è®¾ç½® Li &

Liang(2021).ç»“ æœ å¦‚

æ‰€ ç¤º

Table 13.ç±» ä¼¼ äº

æˆ‘

ä»¬ åœ¨ e 2

e Â· N L

G æŒ‘ æˆ˜

èµ› ä¸­

çš„ ç»“ æœ

Section 5,åœ¨ç»™å®šç›¸åŒ

æ•°é‡çš„å¯è®­

ç»ƒå‚æ•°çš„æƒ…

å†µä¸‹ï¼ŒLoRA

æ¯”åŸºäº

å‰ç¼€çš„æ–¹æ³•

è¡¨ç°æ›´å¥½æˆ–

è€…è‡³å°‘ä¸åŸº

äºå‰ç¼€çš„æ–¹

æ³•ä¸ç›¸ä¸Šä¸‹

ã€‚

Method # Trainable

DART

BLEU â†‘ MET

â†‘ TER â†“

GPT-2

Medium

Fine-Tune 354M

AdapterL

0.37M

AdapterL

11M

FTTop2

24M

46.2 0.39 0.46

42.4 0.36 0.48

45.2

0.38 0.46

41.0 0.34

0.56

PrefLayer 0.35M 46.4

0.38 0.46

LoRA 0.35M

47.1Â±.2 0.39 0.46

GPT-2

Large

Fine-Tune 774M 47.0

0.39 0.46

AdapterL

0.88M

45.7Â±.1 0.38 0.46

AdapterL

23M 47.1Â±.1 0.39 0.45

PrefLayer 0.77M 46.7 0.38

0.45

LoRA 0.77M 47.5Â±.1

0.39 0.45

æ–¹æ³• #å¯è®­ç»ƒ

é£é•–

è“è‰² é‡

è§â†‘ TERâ†“

GPT-2

åŸ¹å…»åŸº

å¾®

è°ƒ 354 ç±³

é€‚é…å™¨

1 0.37 ç±³

é€‚é…å™¨

1 11 ç±³

FTTop2 24M

46.2 0.39 0.46

42.4

0.36 0.48

45.2 0.38

0.46

41.0 0.34 0.56

é¢„æ’­æ”¾å™¨ 0.35 ç±³

46.4 0.38

0.4

6

åŠ³æ‹‰ 0.35

ç±³ 47.1 

.2

0.39 0.4

6

GPT-2

å¤§å·

å¾®è°ƒ 774 ç±³ 47.0

0.39 0.4

6

é€‚é…

å™¨

1 0.88 ç±³ 45.7

.1

0.38 0.4

6

é€‚é…å™¨

1 23 ç±³ 47.1

.1

0.39 0.4

5

é¢„æ’­æ”¾å™¨

0.77 ç±³ 46.7 0.38

0.4

5

åŠ³æ‹‰ 0.77

ç±³ 47.5 

.1

0.39 0.4

5

Table

13: GPT-2 with different

adaptation methods on DART.

The variances of MET

and TER are

less

than 0.01 for all

adaption approaches.

è¡¨

13:åœ¨ç¾éš¾æ´åŠ©

ååº”å †ä¸Šé‡‡

ç”¨ä¸åŒé€‚åº”

æ–¹æ³•çš„ GPT-2ã€‚å¯¹äº

æ‰€æœ‰é€‚åº”æ–¹

æ³•ï¼ŒMET

å’Œ TER çš„

æ–¹å·®

å°äº

0.01ã€‚

6

Method

U

BLEUâ†‘

S A

WebNLG

USA METâ†‘

USA

TERâ†“

Method

U

BLEUâ†‘

S

A

WebNLG

USA METâ†‘

USA

TERâ†“

6

GPT-2

Medium

Fine-Tune (354M) 27.7

64.2 46.5 .30 .45

.38 .76 .33 .53

AdapterL

(0.37M) 45.1 54.5

50.2 .36 .39 .38

.46 .40 .43

AdapterL

(11M) 48.3 60.4 54.9

.38 .43 .41 .45

.35 .39

FTTop2 (24M)

18.9 53.6 36.0 .23

.38 .31 .99 .49

.72

Prefix (0.35M) 45.6

62.9 55.1 .38 .44

.41 .49 .35 .40

LoRA (0.35M) 46.7Â±.4 62.1Â±.2

55.3Â±.2 .38 .44 .41

.46 .33 .39

GPT-2

Large

Fine-Tune (774M) 43.1

65.3 55.5 .38 .46

.42 .53 .33 .42

AdapterL

(0.88M) 49.8Â±.0 61.1Â±.0

56.0Â±.0 .38 .43 .41

.44 .35 .39

AdapterL

(23M) 49.2Â±.1 64.7Â±.2 57.7Â±.1

.39 .46 .43 .46

.33 .39

Prefix (0.77M)

47.7 63.4 56.3 .39

.45 .42 .48 .34

.40

LoRA (0.77M) 48.4Â±.3

64.0Â±.3 57.0Â±.1 .39 .45

.42 .45 .32 .38

é€šç”¨ç»ˆ

ç«¯

-2 ä¸­ç­‰

å¾®è°ƒ

(354

ç±³) 27.7 64.2 46.5

.3

0

.45 .38

.7

6

.3

3

.53

é€‚é…å™¨ 1(0.37 ç±³

)

45.1 54.5 50.2 .3

6

.39 .38 .4

6

.4

0

.43

é€‚é…å™¨ 1(11 ç±³) 48.3

60.4 54.9 .3

8

.43 .41 .4

5

.3

5

.39

fttop

2(24 ç±³

) 18.9 53.6

36.0 .2

3

.38

.31 .9

9

.4

9

.72

å‰ç¼€(0.35 ç±³)

45.6 62.9 55.1 .3

8

.44 .41 .4

9

.3

5

.40

æ´›æ‹‰

(0.35 ç±³) 46.7

.4

62.1 

.2

55.3 .

2

.3

8

.44 .41 .4

6

.3

3

.39

GPT-2 å¤§å·

å¾®è°ƒ

(774 ç±³)

43.1 65.3 55.5 .38

.46 .42 .5

3

.3

3

.42

é€‚é…å™¨

1(0.88 ç±³

) 49.8

.0

61.1 

.0

56.0 .

0

.38

.43 .41 .4

4

.3

5

.39

é€‚é…å™¨

1(23 ç±³) 49.2

.1

64.7 

.2

57.7 .

1

.39

.46 .43 .4

6

.3

3

.39

å‰

ç¼€(0.77

ç±³) 47.7 63.4 56.3

.39 .45 .42 .4

8

.3

4

.40

æ´›æ‹‰(0.77 ç±³

) 48.4

.3

64.0 

.3

57.0

.

1

.39 .45

.42 .4

5

.3

2

.38

Table 14:

GPT-2 with different adaptation

methods on WebNLG. The

variances of MET and

TER

are less than

0.01 for all the

experiments we ran. â€œUâ€

indicates unseen categories, â€œSâ€

indicates

seen categories, and

â€œAâ€ indicates all categories

in the test set

of WebNLG.

è¡¨ 14:åœ¨

WebNLG ä¸Šé‡‡ç”¨

ä¸åŒé€‚åº”æ–¹

æ³•çš„ GPT æ–°åè®®

ã€‚å¯¹äºæˆ‘ä»¬è¿

è¡Œçš„æ‰€æœ‰å®

éªŒï¼ŒMET

å’Œ TER

çš„æ–¹å·®

å°äº 0.01ã€‚â€œUâ€è¡¨ç¤ºä¸

å¯è§çš„ç±»åˆ«

ï¼Œâ€œSâ€è¡¨ç¤ºå¯è§çš„

ç±»åˆ«ï¼Œâ€œAâ€è¡¨ç¤º

WebNLG çš„

æµ‹è¯•é›†ä¸­çš„

æ‰€æœ‰ç±»åˆ«ã€‚

6

A

F

A F

L.3

ADDITIONAL EXPERIMENTS ON GPT-3

L.4 GPT 3 å·

ä¸Šçš„é™„åŠ å®

éªŒ

We present additional runs

on GPT-3 with different

adaptation methods in Table

15. The focus is

on identifying the trade-off

between performance and the

number of trainable parameters.

æˆ‘ä»¬åœ¨ GPT-3 ä¸Š

ç”¨ä¸åŒçš„é€‚

åº”æ–¹æ³•è¿›è¡Œ

äº†é¢å¤–çš„è¿

è¡Œ Table

15.é‡ç‚¹åœ¨äº

ç¡®å®šæ€§èƒ½å’Œ

å¯è®­ç»ƒ

å‚æ•°

æ•°é‡ä¹‹é—´çš„

æƒè¡¡ã€‚

L.5 LOW-DATA

REGIME

L.6 ä½æ•°æ®

çŠ¶æ€

To

evaluate the performance of

different adaptation approaches in

the low-data regime. we

randomly sample 100, 1k

and 10k training examples

from the full training

set of MNLI to

form the

low-data MNLI-n

tasks. In Table 16,

we show the performance

of different adaptation approaches

on MNLI-

è¯„ä¼°ä¸

åŒé€‚åº”æ–¹æ³•

åœ¨ä½æ•°æ®æƒ…

å†µä¸‹çš„æ€§èƒ½

ã€‚æˆ‘ä»¬ä» MNLI

çš„å®Œ

æ•´è®­ç»ƒé›†ä¸­

éšæœºæŠ½å– 100ã€1k

å’Œ

10k è®­ç»ƒæ ·æœ¬ï¼Œä»¥

å½¢æˆä½æ•°æ®

MNLI-n

ä»»åŠ¡ã€‚åœ¨â€¦é‡Œ Table 16,æˆ‘

ä»¬å±•ç¤ºäº†ä¸

åŒé€‚åº”æ–¹æ³•

åœ¨

MNLI-ä¸Šçš„æ€§èƒ½

n.

To our surprise, PrefixEmbed

and PrefixLayer performs very

poorly on MNLI-100 dataset,

with PrefixEmbed performing only

slightly better than random

chance (37.6% vs. 33.3%).

PrefixLayer performs better than

PrefixEmbed but is still

significantly worse than Fine-Tune

or

LoRA on MNLI-

åè¯ï¼ˆnoun çš„ç¼©å†™

ï¼‰ä»¤æˆ‘ä»¬æƒŠè®¶

çš„æ˜¯ï¼ŒPrefixEmbed å’Œ PrefixLayer

åœ¨ MNLI-100 æ•°

æ®é›†ä¸Š

çš„

æ€§

èƒ½ é å¸¸ å·®

ï¼Œ PrefixEmbed çš„

æ€§ èƒ½

ä»… ç•¥ å¥½

äº random

chance (37.6% æ¯”

33.3%)ã€‚PrefixLayer

çš„æ€§èƒ½

ä¼˜äº PrefixEmbedï¼Œä½†ä»æ˜

æ˜¾å·®äº MNLI-ä¸Šçš„

å¾®è°ƒæˆ– LoRA

100. The gap between

prefix-based approaches and LoRA/Fine-tuning

becomes smaller as we

inï¿¾crease the number of

training examples, which might

suggest that prefix-based approaches

are not

suitable for

low-data tasks in GPT-3.

LoRA achieves better performance

than fine-tuning on both

MNLI-100 and MNLI-Full, and

comparable results on MNLI-1k

and MNLI-10K considering the

(Â±0.3) variance due to

random seeds.

100.éšç€

è®­ç»ƒæ ·æœ¬æ•°

é‡çš„å¢åŠ ï¼ŒåŸº

äºå‰ç¼€çš„æ–¹

æ³•å’Œ LoRA/å¾®è°ƒä¹‹

é—´çš„å·®è·å˜

å¾—è¶Šæ¥è¶Šå°

ï¼Œ

è¿™å¯èƒ½è¡¨æ˜

åŸºäºå‰ç¼€çš„

æ–¹æ³•ä¸é€‚åˆ

GPT-3 ä¸­çš„ä½æ•°æ®

é‡ä»»åŠ¡ã€‚åœ¨ MNLI-100 å’Œ

MNLI-Full

ä¸Šï¼ŒLoRA å®ç°äº†æ¯”

å¾®è°ƒæ›´å¥½çš„

æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨

MNLI-1k å’Œ MNLI-10K

ä¸Šï¼Œè€ƒè™‘åˆ°

ç”±éšæœºç§å­

å¼•

èµ·çš„(0.3)æ–¹å·®

ï¼Œè·å¾—äº†å¯æ¯”

è¾ƒçš„ç»“æœã€‚

The training

hyperparameters of different adaptation

approaches on MNLI-n are

reported in Taï¿¾ble 17.

We use a smaller

learning rate for PrefixLayer

on the MNLI-100 set,

as the training loss

does not decrease with

a larger learning rate.

MNLI-n ä¸Š

ä¸åŒé€‚åº”æ–¹

æ³•çš„è®­ç»ƒè¶…

å‚æ•°åœ¨ Ta-ble 17.æˆ‘ä»¬

å¯¹

MNLI-100 é›†ä¸Šçš„ PrefixLayer

ä½¿

ç”¨è¾ƒå°çš„å­¦

ä¹ é€Ÿç‡ï¼Œå› ä¸º

è®­ç»ƒæŸå¤±ä¸

ä¼šéšç€è¾ƒå¤§

çš„å­¦ä¹ é€Ÿç‡

è€Œå‡å°‘ã€‚

M MEASURING SIMILARITY BETWEEN

SUBSPACES

N æµ‹é‡

å­ç©ºé—´ä¹‹é—´

çš„ç›¸ä¼¼æ€§

In

this paper we use

the measure Ï†(A, B,

i, j) = Ïˆ(Ui

, Uj

) =

kU

i>UB k

2

åœ¨

æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬

ä½¿ç”¨çš„åº¦é‡

Ï†(Aï¼ŒBï¼ŒIï¼Œj) = Ïˆ(Uiï¼ŒUj )

= 

kUi>UB k2

6

dÃ—i

A

dÃ—i

B

A B

to

measure the subspace æ¥æµ‹é‡å­ç©º

é—´

A B min{i,j}

A

B min{iï¼Œj}

similarity between

two column orthonormal matrices

Ui âˆˆ R and

U âˆˆ R

dÃ—j

, obtained by

ä¸¤åˆ—æ­£äº¤

çŸ©é˜µ

Ui âˆˆ R çš„ç›¸ä¼¼

æ€§

ä½ å‘¢ âˆˆ RdÃ—jï¼Œç”±ä¸‹

å¼è·å¾—

taking

columns of the left

singular matrices of A

and B. We point

out that this similarity

is simply

a reverse

of the standard Projection

Metric that measures distance

between subspaces Ham &

Lee

(2008).

å– A

å’Œ

b çš„å·¦å¥‡å¼‚çŸ©

é˜µçš„åˆ—ã€‚æˆ‘ä»¬

æŒ‡å‡ºï¼Œè¿™ç§ç›¸

ä¼¼æ€§åªæ˜¯æµ‹

é‡å­ç©ºé—´ä¹‹

é—´è·ç¦»çš„æ ‡

å‡†æŠ•å½±

åº¦é‡

çš„é€† Ham

& Lee(2008).

6

Method

Hyperparameters # Trainable Parameters

WikiSQL MNLI-m

æ–¹æ³• è¶…

å‚æ•°

#å¯è®­ç»ƒ

å‚æ•° WikiSQL MNLI-m

Fine-Tune

- 175B 73.8 89.5

å¾®è°ƒ - 175B 73.8

89.5

PrefixEmbed

lp =

32, li = 8

lp = 64, li

= 8

lp =

128, li = 8

lp = 256, li

= 8

lp =

512, li = 8

0.4 M

0.9 M

1.7 M

3.2 M

6.4 M

55.9

58.7

60.6

63.1

55.9

84.9

88.1

88.0

88.6

85.8

å‰

ç¼€åµŒå…¥

lp = 32ï¼Œli

= 8

lp =

64ï¼Œli = 8

lp

= 128ï¼Œli =

8

lp = 256ï¼Œli

= 

8

lp

= 512ï¼Œli =

8

0.4 ç±³

0.9

ç±³

1.7 ç±³

3.2 ç±³

6.4 ç±³

55.9

58.7

60.6

63.1

55.9

84.9

88.1

88.0

88.6

85.8

PrefixLayer

lp = 2,

li = 2

lp

= 8, li =

0

lp = 8,

li = 8

lp

= 32, li =

4

lp = 64,

li = 0

5.1

M

10.1 M

20.2

M

44.1 M

76.1

M

68.5

69.8

70.1

66.4

64.9

89.2

88.2

89.5

89.6

87.9

å‰ç½®

å±‚

lp = 2ï¼Œli =

2

lp = 8ï¼Œli

= 0

lp =

8ï¼Œli = 8

lp

= 32ï¼Œli = 4

lp = 64ï¼Œli =

0

5.1 ç±³

10.1

ç±³

20.2 ç±³

44.1

ç±³

76.1 ç±³

68.5

69.8

70.1

66.4

64.9

89.2

88.2

89.5

89.6

87.9

r = 1 7.1

M 71.9 89.8

AdapterH

r = 4

r

= 8

r =

16

21.2 M

40.1

M

77.9 M

73.2

73.2

73.2

91.0

91.5

91.5

r = 64

304.4 M 72.6 91.5

r = 1 7.1

ç±³ 71.9 89.

8

é€‚é…å™¨

h

r = 4

r = 8

r

= 16

21.2 ç±³

40.1 ç±³

77.9 ç±³

73.2

73.2

73.2

91.0

91.5

91.5

r =

64 304.4 ç±³ 72.6

91.

5

LoRA

rv

= 2

rq =

rv = 1

rq

= rv = 2

rq = rk =

rv = ro =

1

rq = rv

= 4

rq =

rk = rv =

ro = 2

rq

= rv = 8

rq = rk =

rv = ro =

4

rq = rv

= 64

rq =

rk = rv =

ro =

64

4.7

M

4.7 M

9.4

M

9.4 M

18.8

M

18.8 M

37.7

M

37.7 M

301.9

M

603.8 M

73.4

73.4

73.3

74.1

73.7

73.7

73.8

74.0

73.6

73.9

91.7

91.3

91.4

91.2

91.3

91.7

91.6

91.7

91.4

91.4

rv

= 2

rq =

rv = 1

4.7

ç±³

4.7 ç±³

73.4

73.4

91.7

91.3

6

åŠ³æ‹‰

rq = rv =

2

rq = rk

= rv = ro

= 1

rq =

rv = 4

rq

= rk = rv

= ro

= 2

rq = rv =

8

rq = rk

= rv = ro

= 4

rq =

rv = 64

rq

= rk = rv

= ro

= 64

9.4 ç±³

9.4 ç±³

18.8

ç±³

18.8 ç±³

37.7

ç±³

37.7 ç±³

301.9

ç±³

603.8 ç±³

73.3

74.1

73.7

73.7

73.8

74.0

73.6

73.9

91.4

91.2

91.3

91.7

91.6

91.7

91.4

91.4

LoRA+PE

rq

= rv = 8,

lp = 8, li

=

4

rq =

rv = 32, lp

= 8, li =

4

rq = rv

= 64, lp =

8, li =

4

37.8 M

151.1 M

302.1 M

75.0

75.9

76.2

91.4

91.1

91.3

åŠ³æ‹‰+ä½“è‚²

rq = rv =

8ï¼Œlp = 

8ï¼Œli

= 4

rq =

rv = 32ï¼Œlp =

8ï¼Œli = 4

rq

= rv = 64ï¼Œlp

= 

8ï¼Œli =

4

37.8 ç±³

151.1

ç±³

302.1 ç±³

75.0

75.9

76.2

91.4

91.1

91.3

LoRA+PL rq =

rv = 8, lp

= 8, li =

4

52.8 M 72.9

90.2

åŠ³æ‹‰

+PL rq =

rv = 8ï¼Œlp =

8ï¼Œli = 4

52.8

ç±³ 72.9 90.2

Table

15: Hyperparameter analysis of

different adaptation approaches on

WikiSQL and MNLI.

Both

prefix-embedding tuning (PrefixEmbed) and

prefix-layer tuning (PrefixLayer) perform

worse as we increase

the number of trainable

parameters, while LoRAâ€™s performance

stabilizes.

Performance is measured

in validation accuracy.

è¡¨

15:WikiSQL å’Œ MNLI ä¸Šä¸

åŒé€‚åº”æ–¹æ³•

çš„è¶…å‚æ•°åˆ†

æã€‚å½“æˆ‘ä»¬å¢

åŠ å¯è®­ç»ƒå‚

æ•°çš„æ•°é‡æ—¶

ï¼Œ

å‰ç¼€åµŒå…¥è°ƒ

æ•´(PrefixEmbed)å’Œå‰ç¼€å±‚

è°ƒæ•´(PrefixLayer)çš„æ€§èƒ½

ä¼šæ›´å·®ï¼Œè€Œ LoRA çš„

æ€§èƒ½ä¼š

ç¨³å®š

ä¸‹æ¥ã€‚æ€§èƒ½ä»¥

éªŒè¯çš„å‡†ç¡®

æ€§æ¥è¡¡é‡ã€‚

Method MNLI(m)-100 MNLI(m)-1k MNLI(m)-10k

MNLI(m)-392K

GPT-3 (Fine-Tune) 60.2

85.8 88.9 89.5

GPT-3

(PrefixEmbed) 37.6 75.2 79.5

88.6

GPT-3 (PrefixLayer) 48.3

82.5 85.9 89.6

GPT-3

(LoRA) 63.8 85.6 89.2

91.7

æ–¹

æ³• æœ€ä½ç”Ÿæ´»

æ°´å¹³

(ç”·)-100

MNLI(m)-1k é”°é”‚

(ç™¾ä¸‡)-

10k

é”°é”‚(ç™¾

ä¸‡)-

392K

GPT-3(å¾®è°ƒ) 60.2 85.8

88.9 89.5

GPT-3(å‰ç½®

) 37.6

75.2 79.5 88.6

GPT-3(å‰ç½®å±‚)

48.3 82.5 85.9 89.6

GPT ä¸‰å·

63.8 85.6 89.2

91.7

Table 16: Validation

accuracy of different methods

on subsets of MNLI

using GPT-3 175B.

MNLI-

n describes a subset

with n training examples.

We evaluate with the

full validation set.

LoRA

performs exhibits favorable sample-efficiency

compared to other methods,

including fineï¿¾tuning.

è¡¨ 16:ä½¿ç”¨

GPT-3 175B å¯¹ MNLI

å­

é›†è¿›è¡Œä¸åŒ

æ–¹æ³•çš„éªŒè¯

å‡†ç¡®æ€§ã€‚MNLI- n æè¿°

äº†å…·æœ‰ n

ä¸ª

è®­

ç»ƒæ ·æœ¬çš„å­

é›†ã€‚æˆ‘ä»¬ä½¿ç”¨

å®Œæ•´çš„éªŒè¯

é›†è¿›è¡Œè¯„ä¼°

ã€‚ä¸åŒ…æ‹¬å¾®è°ƒ

åœ¨å†…çš„å…¶ä»–

æ–¹æ³•ç›¸

æ¯”ï¼ŒLoRA performs

è¡¨

ç°å‡ºè‰¯å¥½çš„

é‡‡æ ·æ•ˆç‡ã€‚

A B

A

B

6

A B

A B

To be

concrete, let the singular

values of Ui>Uj

to

be Ïƒ1, Ïƒ2, Â·

Â· Â· , Ïƒp

where p = min{i,

j}. We

å…·

ä½“æ¥è¯´ï¼Œè®¾ Ui>Uj

çš„

å¥‡å¼‚å€¼ä¸º Ïƒ1ï¼ŒÏƒ2ï¼Œï¼ŒÏƒp å…¶

ä¸­ p

= min{iï¼Œj}ã€‚æˆ‘ä»¬

know that

the Projection Metric Ham

& Lee (2008) is

defined as:

çŸ¥é“

æŠ•å½±åº¦é‡ Ham

& Lee(2008)å®š

ä¹‰ä¸º:

d(Ui

,

Uj

) =

v

u

t

p âˆ’

X

d(Uiï¼ŒUj)= vutp X

Ïƒ

2 âˆˆ [0,

Ïƒ2 âˆˆ [0,

p

p

âˆš

p]

âˆšp]

i

i

7

7

A B

A B

Hyperparameters Adaptation MNLI-100 MNLI-1k

MNLI-10K MNLI-392K

è¶…å‚æ•°

é€‚åº” é”°é”‚-100

MNLI-1k MNLI-10K é”°

é”‚-392K

Optimizer

- AdamW

Warmup Tokens

- 250,000

LR Schedule

- Linear

Batch Size

- 20 20 100

128

# Epoch -

40 40 4 2

ã€è®¡ç®—æœºã€‘ä¼˜

åŒ–

ç¨‹åº

- é˜¿è¾¾

å§†

çƒ­èº«ä»£å¸

- 250,000

LR è®¡åˆ’

- çº¿æ€§çš„

æ‰¹é‡ - 20

20 100 128

#çºªå…ƒ

- 40 40 å››

2

FineTune 5.00E-6

Learning Rate

PrefixEmbed

PrefixLayer

2.00E-04

5.00E-05

2.00E-04 4.00E-04

5.00E-05 5.00E-05

5.00E-04

1.00E-04

LoRA 2.00E-4

å¾®è°ƒ 5.00E-6

å­¦ä¹ ç‡

å‰ç¼€åµŒå…¥

å‰

ç½®å±‚

2.00E-04

5.00E-05

2.00E-04 2004

å¹´ 4

æœˆ

5.00E-05

5.00E-05

5.00E-04

1.00E-04

åŠ³

æ‹‰

2.00E-4

PrefixEmbed lp 16

32 64 256

Adaptation-

PrefixEmbed li 8

Specific

PrefixTune 

LoRA

lp

= li = 8

rq = rv =

8

å‰ç¼€åµŒå…¥

lp 16 32

64 256

é€‚åº”- å‰ç¼€åµŒ

å…¥æ

8

ç‰¹æ®Šçš„

å‰ç¼€åŠ³æ‹‰ lp =

li = 8

rq

= rv = 8

Table 17: The hyperparameters

used for different GPT-3

adaptation methods on MNLI(m)-n.

è¡¨

17:MNLI(m)-n ä¸Šä¸åŒ GPT-3 é€‚åº”

æ–¹æ³•ä½¿ç”¨çš„

è¶…å‚æ•°

where our similarity is

defined as:

å…¶ä¸­

æˆ‘ä»¬çš„ç›¸ä¼¼

æ€§å®šä¹‰ä¸º:

Ï†(A,

B, i, j) =

Ïˆ(Ui

 , Uj

) =

Ï†(Aï¼ŒBï¼ŒIï¼Œj) =

Ïˆ(Uiï¼ŒUj)= 1

p i=1

p i=1

p

p

7

A B

A

B

2

2

i

= 1 âˆ’ d(Ui

, Uj

)

2

I = 1d(Uiï¼ŒUj )2

This similarity satisfies that

if Ui

and Uj

share the same column

span, then Ï†(A, B,

i, j) = 1.

If

è¿™

ä¸ªç›¸ä¼¼æ€§æ»¡

è¶³:å¦‚æœ Ui å’Œ

Uj å…±

ç”¨åŒä¸€ä¸ªåˆ—

è·¨åº¦ï¼Œé‚£ä¹ˆ Ï†(Aï¼ŒBï¼ŒIï¼Œj) =

1ã€‚å¦‚

æœ

they are completely

orthogonal, then Ï†(A, B,

i, j) = 0.

Otherwise, Ï†(A, B, i,

j) âˆˆ (0, 1).

å®ƒä»¬æ˜¯å®Œ

å…¨æ­£äº¤çš„ï¼Œé‚£

ä¹ˆ Ï†(Aï¼ŒBï¼ŒIï¼Œj) = 0ã€‚å¦åˆ™ï¼ŒÏ†(Aï¼ŒBï¼ŒIï¼Œj)

âˆˆ (0ï¼Œ1)ã€‚

O ADDITIONAL

EXPERIMENTS ON LOW-RANK MATRICES

P å…³äº

ä½ç§©çŸ©é˜µçš„

é™„åŠ å®éªŒ

We present

additional results from our

investigation into the low-rank

update matrices.

æˆ‘

ä»¬æå‡ºäº†æˆ‘

ä»¬å¯¹ä½ç§©æ›´

æ–°çŸ©é˜µç ”ç©¶

çš„é™„åŠ ç»“æœ

ã€‚

P.1

CORRELATION BETWEEN LORA MODULES

P.2 LORA æ¨¡ä¹‹é—´çš„ç›¸

å…³æ€§

See

Figure 6 and Figure

7 for how the

results presented in Figure

3 and Figure 4

generalize to

other layers.

çœ‹è§ Figure 6 å’Œ

Figure

7 ç»“æœæ˜¯å¦‚ä½•

åœ¨ Figure 3

å’Œ Figure 4 æ¨å¹¿åˆ°

å…¶ä»–å›¾å±‚ã€‚

P.3 EFFECT OF r

ON GPT-2

P.4 r

å¯¹

GPT-2 çš„å½±å“

We repeat

our experiment on the

effect of r (Section

7.2) in GPT-2. Using

the E2E NLG

Challenge

dataset as an example,

we report the validation

loss and test metrics

achieved by

different choices

of r after training

for 26,000 steps. We

present our result in

Table 18. The

optimal

rank for GPT-2 Medium

is between 4 and

16 depending on the

metric used, which is

similar to that for

GPT-3 175B. Note that

the relationship between model

size and the optimal

rank for adaptation is

still an open question.

æˆ‘ä»¬

é‡å¤äº† r çš„å½±

å“å®éªŒ(Section 7.2)åœ¨

GPT-2ã€‚ä»¥

e2eÂ·NLG æŒ‘æˆ˜æ•°æ®é›†

ä¸ºä¾‹ï¼Œæˆ‘ä»¬æŠ¥

å‘Š

äº†åœ¨è®­ç»ƒ

26ï¼Œ000 æ­¥åï¼Œé€šè¿‡ä¸

åŒçš„

r é€‰æ‹©å®

ç°çš„éªŒè¯æŸ

å¤±å’Œæµ‹è¯•æŒ‡

æ ‡ã€‚æˆ‘ä»¬åœ¨ä¸­

å±•ç¤ºäº†æˆ‘

ä»¬

çš„ç»“æœ Table

18.æ ¹æ®

æ‰€ä½¿ç”¨çš„åº¦

é‡ï¼ŒGPT-2 ä»‹è´¨çš„æœ€

ä½³ç­‰çº§åœ¨ 4 å’Œ

16

ä¹‹é—´ï¼Œè¿™ç±»

ä¼¼

äº GPT-3 175B

çš„ç­‰çº§ã€‚æ³¨

æ„ï¼Œæ¨¡å‹å¤§å°

å’Œé€‚åº”çš„æœ€

ä½³ç­‰çº§ä¹‹é—´

çš„å…³ç³»ä»ç„¶

æ˜¯ä¸€

ä¸ªå…¬å¼€

çš„é—®é¢˜ã€‚

P.5 CORRELATION

BETWEEN W AND âˆ†W

P.6 W å’Œ W

ä¹‹

é—´çš„ç›¸å…³æ€§

See Figure 8 for

the normalized subspace similarity

between W and âˆ†W

with varying r.

çœ‹è§

Figure 8 å¯¹äºéš

r å˜åŒ–çš„

W å’Œ W ä¹‹

é—´çš„å½’ä¸€åŒ–

å­ç©ºé—´ç›¸ä¼¼

æ€§ã€‚

Note again that âˆ†W

does not contain the

top singular directions of

W , since the

similarity

between the top

4 directions in âˆ†W

and the top-10% of

those in W barely

exceeds 0.2. This gives

evidence that âˆ†W contains

those â€œtask-specificâ€ directions that

are otherwise not emphasized

in

W .

å†æ¬¡æ³¨æ„

ï¼ŒW

ä¸åŒ…å« W çš„é¡¶

éƒ¨å¥‡å¼‚æ–¹å‘

ï¼Œå› ä¸º W

ä¸­çš„é¡¶

éƒ¨ 4 ä¸ªæ–¹å‘ä¸

W ä¸­çš„é¡¶éƒ¨

10%æ–¹

å‘ä¹‹

é—´çš„ç›¸

ä¼¼æ€§å‡ ä¹ä¸

è¶…è¿‡ 0.2ã€‚è¿™è¯æ˜

äº† W

åŒ…å«äº†é‚£

äº›åœ¨ W ä¸­æ²¡æœ‰

å¼ºè°ƒçš„â€œç‰¹å®š

ä»»åŠ¡â€æ–¹å‘ã€‚

An

interesting next question to

answer, is how â€œstrongâ€

do we need to

amplify those task-specific

directions,

in order for the

model adaptation to work

well?

ä¸‹

ä¸€ä¸ªè¦å›ç­”

çš„æœ‰è¶£é—®é¢˜

æ˜¯ï¼Œä¸ºäº†è®©æ¨¡

å‹é€‚åº”è‰¯å¥½

åœ°å·¥ä½œï¼Œæˆ‘ä»¬

éœ€è¦å¤šâ€œå¼ºâ€åœ°

æ”¾å¤§é‚£äº›

ç‰¹

å®šäºä»»åŠ¡çš„

æ–¹å‘ï¼Ÿ

7

Wq Wv Wq Wv

Wq Wv Wq Wv

7

(Ar = 8,

Ar = 64, i,

j)

(Ar = 8ï¼ŒAr

= 64ï¼ŒIï¼Œj)

1 2

3 4 5 6

7 8

1 2

3 4 5 6

7 8

j j

j

j j

j

1 2 3 4

5

6 7 8

1 2 3 4

5 6 7 8

j

j

Laye

r

1

Layer

1

Layer

96

Layer

64

Layer

32

2 2

1

6

1

2

1

8

2

3

2

9

3

1

6

1

2

1

8

2

3

2

9

3

Layer

96

Layer

64

Layer

32

2

2

1

6

1

2

1

8

2

3

2

9

3

1

6

1

2

1

8

2

3

2

9

3

2

2

7

kU>WV

kU

> WV

1.0 1.0

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

0.0

Figure 6:

Normalized subspace similarity between

the column vectors of

Ar=8 and Ar=64 for

both

å›¾ 6:Ar =

8 å’Œ Ar=64 çš„

åˆ—å‘é‡ä¹‹é—´

çš„å½’ä¸€åŒ–å­

ç©ºé—´ç›¸ä¼¼æ€§

âˆ†Wq

and âˆ†Wv from the

1st, 32nd, 64th, and

96th layers in a

96-layer Transformer.

96 å±‚å˜å‹å™¨ä¸­

ç¬¬

1 å±‚ã€ç¬¬ 32 å±‚ã€ç¬¬

64

å±‚å’Œç¬¬ 96 å±‚çš„

Wq å’Œ

Wvã€‚

P.7 AMPLIFICATION FACTOR

P.8 æ”¾å¤§ç³»æ•°

One can naturally

consider a feature amplification

factor as the ratio

k

 

âˆ†

W 

k

F

, where U and

V

äººä»¬å¯ä»¥è‡ª

ç„¶åœ°è®¤ä¸ºç‰¹

å¾æ”¾å¤§å› å­

æ˜¯ kâˆW kF

çš„æ¯”å€¼ ï¼Œå…¶

ä¸­ U å’Œ

V

F

F

are

the left- and right-singular

matrices of the SVD

decomposition of âˆ†W .

(Recall UU >WV >V

æ˜¯ W çš„ SVD

åˆ†

è§£çš„å·¦å¥‡å¼‚

çŸ©é˜µå’Œå³å¥‡

å¼‚çŸ©é˜µ

gives the â€œprojectionâ€

of W onto the

subspace spanned by âˆ†W

.)

ç»™å‡º

W åˆ° W

æ‰€è·¨è¶Šçš„

å­ç©ºé—´ä¸Šçš„

â€œæŠ•å½±â€)

Intuitively, when âˆ†W

mostly contains task-specific directions,

this quantity measures how

much

of them are

amplified by âˆ†W .

As shown in Section

7.3, for r =

4, this amplification factor

is as

large as

20. In other words,

there are (generally speaking)

four feature directions in

each layer (out

of

the entire feature space

from the pre-trained model

W ), that need

to be amplified by

a very

large factor

20, in order to

achieve our reported accuracy

for the downstream specific

task. And,

one should

expect a very different

set of feature directions

to be amplified for

each different

downstream task.

ç›´è§‚åœ°

è¯´ï¼Œå½“ W ä¸»è¦åŒ…

å«ç‰¹å®šäºä»»

åŠ¡çš„æ–¹å‘æ—¶

ï¼Œè¿™ä¸ªé‡æµ‹é‡

å®ƒä»¬è¢« W

æ”¾å¤§

äº†å¤šå°‘ã€‚å¦‚æ‰€

ç¤º

Section 7.3,å¯¹äº r

= 4ï¼Œè¿™ä¸ª

æ”¾å¤§ç³»æ•°é«˜

è¾¾ 20ã€‚æ¢å¥è¯è¯´

ï¼Œåœ¨æ¯ä¸€å±‚ä¸­

(ä¸€èˆ¬æ¥è¯´)æœ‰

å››ä¸ª

ç‰¹å¾æ–¹

å‘(åœ¨æ¥è‡ªé¢„

è®­ç»ƒæ¨¡å‹

W çš„

æ•´ä¸ªç‰¹å¾ç©º

é—´ä¹‹å¤–)ï¼Œè¿™äº›

ç‰¹å¾æ–¹å‘éœ€

è¦è¢«æ”¾å¤§é

å¸¸å¤§çš„å› 

å­

20ï¼Œä»¥ä¾¿å®ç°æˆ‘

ä»¬æŠ¥å‘Šçš„ä¸‹

æ¸¸ç‰¹å®šä»»åŠ¡

çš„å‡†ç¡®åº¦ã€‚è€Œ

ä¸”ï¼Œäººä»¬åº”è¯¥

é¢„æ–™åˆ°ï¼Œå¯¹äº

æ¯ä¸ªä¸

åŒçš„

ä¸‹æ¸¸ä»»åŠ¡ï¼Œä¼š

æ”¾å¤§ä¸€ç»„é

å¸¸ä¸åŒçš„ç‰¹

å¾æ–¹å‘ã€‚

One may notice, however,

for r = 64,

this amplification factor is

only around 2, meaning

that

most directions learned

in âˆ†W with r

= 64 are not

being amplified by much.

This should not

be

surprising, and in fact

gives evidence (once again)

that the intrinsic rank

needed to represent

the

â€œtask-specific directionsâ€ (thus for

model adaptation) is low.

In contrast, those directions

in the

rank-4 version

of âˆ†W (corresponding to

r = 4) are

amplified by a much

larger factor 20.

ç„¶è€Œ

ï¼Œäººä»¬å¯èƒ½ä¼š

æ³¨æ„åˆ°ï¼Œå¯¹äº

r

= 64ï¼Œè¯¥æ”¾å¤§ç³»æ•°

ä»…ä¸º 2 å·¦å³ï¼Œè¿™

æ„å‘³ç€åœ¨

r = 64 çš„

W

ä¸­å­¦ä¹ çš„å¤§

å¤šæ•°æ–¹å‘æ²¡

æœ‰è¢«æ”¾å¤§å¤ª

å¤šã€‚è¿™å¹¶ä¸å¥‡

æ€ªï¼Œäº‹å®ä¸Š(å†

ä¸€æ¬¡)è¯æ˜äº†

ä»£è¡¨â€œç‰¹å®šäº

ä»»åŠ¡çš„æ–¹å‘

â€(å› æ­¤ç”¨äºæ¨¡

å‹é€‚åº”)æ‰€éœ€

çš„å†…åœ¨ç­‰çº§

å¾ˆä½ã€‚ç›¸æ¯”ä¹‹

ä¸‹ï¼ŒW çš„ç§© 4 ç‰ˆæœ¬

(å¯¹åº”äº

r = 4)ä¸­çš„

é‚£äº›æ–¹å‘è¢«

æ”¾å¤§äº† 20

å€ã€‚

W W W

W

7

1

ä¸€

7

ä¸ƒ

13

13

19

0.8

19 0.8

25

25

31 0.7

31

0.7

37

37

43

0.6

43 0.6

49

49

55 0.5

55

0.5

61

61

0.4

0.4

1

ä¸€

7

0.3

ä¸ƒ 0.3

13

13

19 0.2

19

0.2

25

25

31

0.1

31 0.1

37

37

43 0.0

43

0.0

49

49

55

55

61

61

j

j j j

j

j j j

Figure

7: Normalized subspace similarity

between the column vectors

of Ar=64 from two

randomly seeded runs, for

both âˆ†Wq and âˆ†Wv

from the 1st, 32nd,

64th, and 96th layers

in a 96-

layer

Trans- former.

å›¾ 7:åœ¨

96

å±‚å˜å‹å™¨ä¸­

ï¼Œå¯¹äºæ¥è‡ªç¬¬

1ã€32ã€64 å’Œ 96 å±‚çš„

Wq å’Œ Wvï¼Œæ¥

è‡ªä¸¤æ¬¡éšæœº

æ’­ç§è¿è¡Œ

çš„

Ar=64

çš„åˆ—å‘é‡ä¹‹

é—´çš„å½’ä¸€åŒ–

å­ç©ºé—´ç›¸ä¼¼

æ€§ã€‚

Rank r val

loss BLEU NIST METEOR

ROUGE L CIDEr

1

1.23 68.72 8.7215 0.4565

0.7052 2.4329

2 1.21

69.17 8.7413 0.4590 0.7052

2.4639

4 1.18 70.38

8.8439 0.4689 0.7186 2.5349

8 1.17 69.57 8.7457

0.4636 0.7196 2.5196

16

1.16 69.61 8.7483 0.4629

0.7177 2.4985

32 1.16

69.33 8.7736 0.4642 0.7105

2.5255

64 1.16 69.24

8.7174 0.4651 0.7180 2.5070

128 1.16 68.73 8.6718

0.4628 0.7127 2.5030

256

1.16 68.92 8.6982 0.4629

0.7128 2.5012

512 1.16

68.78 8.6857 0.4637 0.7128

2.5025

1024 1.17 69.37

8.7495 0.4659 0.7149 2.5090

æ’å r ä»·å€¼

æŸ

å¤±

è“è‰² ç¾

å›½å›½

å®¶æ ‡å‡†

æŠ€æœ¯ç ”

ç©¶æ‰€

(Natio

nal 

Instit

ute

of

Standa

æµæ˜Ÿ èƒ­è„‚

L è‹¹

æœ

é…’

Layer

Layer Layer Layer

Laye

Laye Layer Layer

1

6

1

1

1

6

2

1

2

6

1

6

1

1

1

6

2

1

2

6

1

6

1

1

1

6

2

1

2

6

1

6

1

1

1

6

2

1

2

6

1

6

1

1

1

6

2

1

2

6

1

6

1

1

1

6

2

1

2

6

1

6

1

1

1

6

2

1

2

6

1

6

1

1

1

6

2

1

2

6

W

W W W

7

(Wq, Ar = 4,

i, j) (Wq, Ar

= 8, i, j)

(Wq, Ar = 64,

i, j)

Random (Wq,

Arand, i, j)

(Wq,

Ar = 4, i,

j) (Wq, Ar =

8, i, j) (Wq,

Ar = 64, i,

j)

Random (Wq, Arand,

i, j)

rds

and 

Techno

logy)

ä¸€ 1.23 68.72 8.7215

0.4565 0.7052 2.432

9

2 1.21 69.17 8.7413

0.4590 0.7052 2.463

9

å›› 1.18 70.38 8.8439

0.4689 0.7186 2.534

9

8 1.17 69.57 8.7457

0.4636 0.7196 2.519

6

16 1.16 69.61 8.7483

0.4629 0.7177 2.498

5

32 1.16 69.33 8.7736

0.4642 0.7105 2.525

5

64 1.16 69.24 8.7174

0.4651 0.7180 2.507

0

128 1.16 68.73 8.6718

0.4628 0.7127 2.503

0

256 1.16 68.92 8.6982

0.4629 0.7128 2.501

2

512 1.16 68.78 8.6857

0.4637 0.7128 2.502

5

1024 1.17 69.37 8.7495

0.4659 0.7149 2.509

0

Table 18: Validation loss

and test set metrics

on E2E NLG Challenge

achieved by LoRA with

different rank r using

GPT-2 Medium. Unlike on

GPT-3 where r =

1 suffices for many

tasks, here

the performance

peaks at r =

16 for validation loss

and r = 4

for BLEU, suggesting the

GPT-2

Medium has a

similar intrinsic rank for

adaptation compared to GPT-3

175B. Note that some

of

our hyperparameters are

tuned on r =

4, which matches the

parameter count of another

baseline,

and thus might

not be optimal for

other choices of r.

è¡¨

18:ä½¿ç”¨ GPT-2 ä»‹è´¨ç”±

å…·æœ‰ä¸åŒç­‰

çº§ r

çš„ LoRA å®ç°çš„

E2E NLG

æŒ‘æˆ˜çš„éªŒè¯

æŸå¤±å’Œæµ‹è¯•

é›†

åº¦é‡ã€‚ä¸åƒ

åœ¨ GPT-3 ä¸Šï¼Œå…¶ä¸­

r = 1 è¶³

ä»¥ç”¨äºè®¸å¤š

ä»»åŠ¡ï¼Œè¿™é‡Œï¼Œå¯¹

äºéªŒè¯æŸå¤±

ï¼Œæ€§èƒ½åœ¨

r =

16 å¤„è¾¾

åˆ°å³°å€¼ï¼Œå¯¹äº

BLEUï¼Œæ€§èƒ½åœ¨

r = 4 å¤„è¾¾

åˆ°å³°å€¼ï¼Œè¿™è¡¨

æ˜

GPT-2 ä»‹è´¨ä¸ GPT-3 175B

ç›¸

æ¯”ï¼Œå…·æœ‰ç›¸ä¼¼

çš„å†…åœ¨é€‚åº”

ç­‰çº§ã€‚è¯·æ³¨æ„

ï¼Œæˆ‘ä»¬çš„ä¸€äº›

è¶…å‚æ•°æ˜¯åœ¨

r = 4 ä¸Šè°ƒæ•´çš„ï¼Œè¿™

ä¸å¦

ä¸€ä¸ªåŸº

çº¿çš„å‚æ•°è®¡

æ•°ç›¸åŒ¹é…ï¼Œå› 

æ­¤å¯¹äº r çš„å…¶

ä»–é€‰æ‹©å¯èƒ½

ä¸æ˜¯æœ€ä½³çš„

ã€‚

Wq

ä½“é‡å•†æ•°

451

451

555

555

658

658

762

762

865

865

969

969

1072

1072

1176

1176

i i

W

W W W

7

0

.

2

0

0

0

.

2

0

0

0

.175

0.175

0.150

0.150

0.125

0.125

0.100

0.100

j

j j j

j

j j j

Figure

8: Normalized subspace similarity

between the singular directions

of Wq and those

of âˆ†Wq

with varying

r and a random

baseline. âˆ†Wq amplifies directions

that are important but

not emphaï¿¾sized in W

. âˆ†W with a

larger r tends to

pick up more directions

that are already emphasized

in

W .

å›¾

8:Wq

å¥‡å¼‚æ–¹å‘å’Œ

Wq å¥‡å¼‚æ–¹å‘ä¹‹

é—´çš„æ ‡å‡†åŒ–

å­ç©ºé—´ç›¸ä¼¼

æ€§ï¼Œå…·æœ‰ä¸åŒ

çš„ r å’ŒéšæœºåŸº

çº¿ã€‚Wq

æ”¾å¤§äº†åœ¨

W ä¸­é‡è¦ä½†ä¸

å¼ºè°ƒçš„æ–¹å‘

ã€‚r è¶Šå¤§çš„ W

å€¾å‘

äºé€‰æ‹©æ›´å¤š

å·²ç»åœ¨ W ä¸­å¼º

è°ƒçš„æ–¹

å‘ã€‚
