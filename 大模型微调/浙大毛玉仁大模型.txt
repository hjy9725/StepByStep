

















其出现的似

然函数为：

L(θ) =

M

Y

i=1

M

Y

j=1

P(wi

,

wj )

C(wi,wj )，

(1.10)

5

第

1 章

语言模型

基础

其中，θ = {P(wi

, wj )}

M

i,j=1。根

据条件概率

公式 P(wi

, wj

) = P(wj

|wi)P(wi)

，有

L(θ) =

M

Y

i=1

M

Y

j=1

P(wj

|wi)

C(wi,wj

)P(wi)

C(wi,wj )。 (1.11)

其对

应的对数似

然函数为：

Llog(θ)=

M

X

i=1

M

X

j=1

C(wi

,wj ) log

P(wj

|wi) +

M

X

i=1

M

X

j=1

C(wi

,wj )

log P(wi)。 (1.12)

因

为

P M

j=1 P(wj

|wi) = 1，所以最大

化对数似然

函数可建模

为如下的约

束优化问题

：

max

Llog(θ)

s.t.

M

X

j=1

P(wj

|wi) =

1 for i ∈

[1, M]。

(1.13)

其拉格朗日

对偶为：

L(λ, Llog) = Llog(θ)

+

M

X

i=1

λi(

M

X

j=1

P(wj

|wi) − 1)。

(1.14)

对其

求关于 P(wj

|wi)

的偏

导，可得：

∂L(λ, Llog)

∂P(wj

|wi)

=

M

X

i=1

C(wi

, wj

)

P(wj

|wi)

+

M

X

i=1

λi。

(1.15)

当导

数为 0 时，有：

P(wj

|wi) = −

C(wi

, wj )

λi

。 (1.16)

因

P

M

j=1 P(wj

|wi)

= 1，λi 可取值为 −

P

M

j=1 C(wi

, wj ), 即

P(wj

|wi) = C(wi

,

wj )

P

M

j=1 C(wi

, wj

)

=

C(wi

,

wj )

C(wi)

。

(1.17)

上述分析表

明 bigram 语言模型

中的

C

C

(w

(

i

w

,wj )

i) 是对语

料库中的长

度为 2 的词序

列的

P(wj

|wi) 的极大

似然估计。该

结论可扩展

到 n

> 2 的其他 n-grams

语

言模型

模型

中。

n-grams 语言模型

通过统计词

序列在语料

库中出现的

频率来预测

语言符号的

概

率。其对未

知序列有一

定的泛化性

，但也容易陷

入“零概率”的

困境。随着神

经网

络的发

展，基于各类

神经网络的

语言模型不

断被提出，泛

化能力越来

越强。基于神

6

毛玉仁 高云

君

经网络的

语言模型不

再通过显性

的计算公式

对语言符号

的概率进行

计算，而是利

用语料库中

的样本对神

经网络模型

进行训练。本

章接下来将

分别介绍两

类最具代

表

性的基于神

经网络的语

言模型：基于

RNN 的语言模型

和基于 Transformer

的语

言模型。

1.2 基于

RNN 的语言模型

循环神经网

络（Recurrent

Neural Network, RNN）是一类网

络连接中包

含环路的

神

经网络的总

称。给定一个

序列，RNN

的环路

用于将历史

状态叠加到

当前状态上

。

沿着时间维

度，历史状态

被循环累积

，并作为预测

未来状态的

依据。因此，RNN 可

以基于历史

规律，对未来

进行预测。基

于 RNN

的语言模

型，以词序列

作为输入，基

于被循环编

码的上文和

当前词来预

测下一个词

出现的概率

。本节将先对

原始 RNN

的基本

原理进行介

绍，然后讲解

如何利用 RNN

构

建语言模型

。

1.2.1 循环神经网

络 RNN

按照推理

过程中信号

流转的方向

，神经网络的

正向传播范

式可分为两

大类：前

馈传

播范式和循

环传播范式

。在前馈传播

范式中，计算

逐层向前，“不

走回头路”。

而

在循环传播

范式中，某些

层的计算结

果会通过环

路被反向引

回前面的层

中，形

成“螺旋

式前进”的范

式。采用前馈

传播范式的

神经网络可

以统称为前

馈神经网

络

（Feed-forward Neural Network，FNN），而采用循环

传播范式的

神经网络被

统称

为循环

神经网络（Recurrent

Neural Network, RNN）。以

包含输入层

、隐藏层、输出

层的神经网

络为例。图1.2中

展示了最简

单的 FNN

和 RNN 的网

络结构示意

图，可

见

FNN 网络

结构中仅包

含正向通路

。而 RNN 的网络结

构中除了正

向通路，还有

一条环路将

某层的计算

结果再次反

向连接回前

面的层中。

7

第

1 章 语言模型

基础

前馈 循

环

图 1.2:

前馈传

播范式与循

环传播范式

的对比。

设输

入序列为 {x1, x2,

x3, ..., xt}，隐

状态为 {h1,

h2, h3, ..., ht}，对应

输出为

{o1, o2, o3, ...,

ot}，输入

层、隐藏层、输

出层对应的

网络参数分

别为 WI , WH,

WO。

g(·) 为激活

函数，f(·) 为输出

函数。将输入

序列一个元

素接着一个

元素地串行

输入

时，对于

FNN，当前的输出

只与当前的

输入有关，即

ot = f(WOg(WIxt))。 (1.18)

此处为方便

对比，省去了

偏置项。独特

的环路结构

导致 RNN 与 FNN

的推

理过程

完全

不同。RNN 在串行

输入的过程

中，前面的元

素会被循环

编码成隐状

态，并叠

加到

当前的输入

上面。其在

t 时

刻的输出如

下：

ht =

g(WHht−1 + WIxt) =

g(WHg(WHht−2 + WIxt−1) +

WIxt) = · ·

· · ··

ot

= f(WOht)。

(1.19)

其中,

t > 0, h0

= 0。将此

过程按照时

间维度展开

，可得到 RNN 的推

理过程，如

图

1.3所示。注意，图

中展示的 t 时

刻以前的神

经元，都是过

往状态留下

的“虚影”

并不

真实存在，如

此展开只是

为了解释

RNN 的

工作方式。

可

以发现，在这

样一个元素

一个元素依

次串行输入

的设定下，RNN 可

以将历

史状

态以隐变量

的形式循环

叠加到当前

状态上，对历

史信息进行

考虑，呈现出

螺旋

式前进

的模式。但是

，缺乏环路的

FNN 仅对当前状

态进行考虑

，无法兼顾历

史状

态。以词

序列

{长颈鹿

, 脖子, 长} 为例

，在给定“脖子

”来预测下一

个词是什么

的

时候，FFN 将仅

仅考虑“脖子

”来进行预测

，可能预测出

的下一词包

含“短”，“疼”

等等

；而 RNN

将同时考

虑“长颈鹿”和

“脖子”，其预测

出下一词是

“长”的概率

将

更高，历史信

息“长颈鹿”的

引入，可以有

效提升预测

性能。

8

毛玉仁

高云君

.......

图 1.3: RNN

推

理过程从时

间维度拆解

示意图。

如果

FNN 想要做到对

历史信息进

行考虑，则需

要将所有元

素同时输入

到模型

中去

，这将导致模

型参数量的

激增。虽然，RNN

的

结构可以让

其在参数量

不扩张的

情

况下实现对

历史信息的

考虑，但是这

样的环路结

构给 RNN 的训练

带来了挑战

。

在训练 RNN 时，涉

及大量的矩

阵联乘操作

，容易引发梯

度衰减或梯

度爆炸问题

。

具体分析如

下：

设 RNN 语言模

型的训练损

失为:

L

= L(x, o, WI

, WH, WO) =

t

X

i=1

l(oi

, yi)。 (1.20)

其中，l(·)

为

损失函数，yi 为

标签。

损失 L

关

于参数 WH 的梯

度为：

∂L

WH

=

t

X

i=1

∂o

∂lt

t

·

∂ot

∂ht

·

∂ht

∂hi

·

∂hi

∂WH

。 (1.21)

其中,

∂ht

∂hi

=

∂ht

∂ht−1

∂ht−1

∂ht−2

...

∂hi+1

∂hi

=

t

Y

k=i+1

∂hk

∂hk−1

。 (1.22)

9

第

1

章 语言模型

基础

并且，

∂hk

∂hk−1

=

∂g(zk)

∂zk

WH。 (1.23)

其

中，zk =

WHhk−1 + WIxk。综上，有

∂L

WH

=

t

X

i=1

∂o

∂lt

t

·

∂ot

∂ht

·

t

Y

k=i

∂g(zk)

∂zk

WH ·

∂hi

∂WH

。 (1.24)

从

上式中可以

看出，求解

WH 的

梯度时涉及

大量的矩阵

级联相乘。这

会导致

其数

值被级联放

大或缩小。文

献 [17]

中指出，当

WH 的最大特征

值小于 1 时，会

发生梯度消

失；当

WH 的最大

特征值大于

1 时，会发生梯

度爆炸。梯度

消失和爆炸

导致训练上

述 RNN

非常困难

。为了解决梯

度消失和爆

炸问题，GRU [4] 和 LSTM

[8] 引

入门控结构

，取得了良好

效果，成为主

流的 RNN 网络架

构。

1.2.2 基于 RNN 的语

言模型

对词

序列 {w1, w2, w3,

..., wN }，基于 RNN

的

语言模型每

次根据当前

词 wi 和循

环输

入的隐藏状

态

hi−1，来预测下

一个词 wi+1 出现

的概率，即

P(wi+1|w1:i)

= P(wi+1|wi

, hi−1)。

(1.25)

其

中，当 i =

1 时，P(wi+1|wi

, hi−1)

= P(w2|w1) 。基于

此，{w1, w2,

w3, ..., wN }

整

体出现

的概率为：

P(w1:N )

=

N−1

Y

i=1

P(wi+1|wi

, hi−1)。 (1.26)

在

基于 RNN 的语言

模型中，输出

为一个向量

，其中每一维

代表着词典

中对应

词的

概率。设词典

D

中共有 |D| 个词

{wˆ1,wˆ2,wˆ3, ...,wˆ|D|}，基于

RNN 的语言

模型

的输出

可表示为 oi

= {oi

[ ˆwd]}

|

d

D

=1

| ，其

中，oi

[ ˆwd]

表示词典

中的词 wˆd 出现

的概率。因

此

，对基于

RNN 的语

言模型有

P(w1:N )

=

N−1

Y

i=1

P(wi+1|w1:i) =

N

Y

i=1

oi

[wi+1]。 (1.27)

10

毛

玉仁 高云君

长颈鹿

脖子

0.5

0.2 0.1

吃 头部

长颈

鹿脖子

长

0.6 0.1

0.05

疼

短

.......

.......

.......

.......

图 1.4:

RNN 计算词

序列概率示

意图。

以下举

例对上述过

程进行说明

。假设词表 D

= {脖

子, 头部, 吃,

长

, 疼, 吃, 短}，

基于

RNN 的语言模型

计算“长颈鹿

脖子长”的概

率的过程如

图1.4所示。

P(长颈

鹿脖子长) =

P(脖

子|长颈鹿) · P(长

|脖子, h1)

= 0.2 × 0.6

= 0.12。 (1.28)

基于以

上预训练任

务，对

RNN 语言模

型进行训练

时，可选用如

下交叉熵函

数

作为损失

函数。

lCE(oi)

= −

|D|

X

d=1

I( ˆwd =

wi+1) log oi

[wi+1]

= − log oi

[wi+1]， (1.29)

其中，I(·) 为

指示函数，当

wˆd

= wi+1 时等于 1，当

wˆd = wi+1 时

等于

0。

设训练

集为 S，RNN 语言模

型的损失可

以构造为：

L(S, WI , WH,

WO) = 1

N|S|

|S|

X

s=1

N

X

i=1

lCE(oi,s)， (1.30)

其

中，oi,s 为 RNN 语言模

型输入第

s 个

样本的第 i 个

词时的输出

。此处为方便

表

述，假设每

个样本的长

度都为 N。在此

损失的基础

上，构建计算

图，进行反向

传

播，便可对

RNN 语言模型进

行训练。上述

训练过程结

束之后，我们

可以直接利

用

此模型对

序列数据进

行特征抽取

。抽取的特征

可以用于解

决下游任务

。此外，我们

还

可以对此语

言模型的输

出进行解码

，在“自回归”的

范式下完成

文本生成任

务。

在自回归

中，第一轮，我

们首先将第

一个词输入

给 RNN

语言模型

，经过解码，得

到一个输出

词。然后，我们

将第一轮输

出的词与第

一轮输入的

词拼接，作为

第二轮

11

第 1

章

语言模型基

础

的输入，然

后解码得到

第二轮的输

出。接着，将第

二轮的输出

和输入拼接

，作为第

三轮

的输入，以此

类推。每次将

本轮预测到

的词拼接到

本轮的输入

上，输入给语

言

模型，完成

下一轮预测

。在循环迭代

的“自回归”过

程中，我们不

断生成新的

词，

这些词便

构成了一段

文本。

但上述

“自回归”过程

存在着两个

问题：(1) 错误级

联放大，选用

模型自己生

成的词作为

输入可能会

有错误，这样

的错误循环

输入，将会不

断的放大错

误，导

致模型

不能很好拟

合训练集；（2）串

行计算效率

低，因为下一

个要预测的

词依赖

上一

次的预测，每

次预测之间

是串行的，难

以进行并行

加速。为了解

决上述两个

问题，“Teacher Forcing”[21] 在语言

模型预训练

过程中被广

泛应用。在 Teacher

Forcing 中

，每轮都仅将

输出结果与

“标准答案”（Ground Truth）进

行拼接作为

下

一轮的输

入。在图1.4所示

的例子中，第

二轮循环中

，我们用“长颈

鹿脖子”来预

测下一个词

“长”，而非选用

o1

中概率最高

的词“吃”或者

其他可能输

出的词。

但是

，Teacher Forcing 的训练方式

将导致曝光

偏差（Exposure

Bias）的问题

。曝

光偏差是

指 Teacher Forcing

训练模型

的过程和模

型在推理过

程存在差异

。Teacher

Forcing 在训练中，模

型将依赖于

“标准答案”进

行下一次的

预测，但是在

推理预

测中

，模型“自回归

”的产生文本

，没有“标准答

案”可参考。所

以模型在训

练过

程中和

推理过程中

存在偏差，可

能推理效果

较差。为解决

曝光偏差的

问题，Bengio

等人提

出了针对 RNN 提

出了

Scheduled Sampling 方法 [2]。其

在

Teacher Forcing 的

训练过

程中循序渐

进的使用一

小部分模型

自己生成的

词代替“标准

答案”，在训练

过程中对推

理中无“标准

答案”的情况

进行预演。

由

于 RNN 模型循环

迭代的本质

，其不易进行

并行计算，导

致其在输入

序列较

长时

，训练较慢。下

节将对容易

并行的基于

Transformer

的语言模型

进行介绍。

12

毛

玉仁 高云君

1.3

基于 Transformer 的语言

模型

Transformer

是一类

基于注意力

机制（Attention）的模块

化构建的神

经网络结

构

。给定一个序

列，Transformer 将一定数

量的历史状

态和当前状

态同时输入

，然

后进行加

权相加。对历

史状态和当

前状态进行

“通盘考虑”，然

后对未来状

态进行

预测

。基于 Transformer 的语言

模型，以词序

列作为输入

，基于一定长

度的上文和

当前词来预

测下一个词

出现的概率

。本节将先对

Transformer 的基本原理

进行介绍，

然

后讲解如何

利用 Transformer 构建语

言模型。

1.3.1

Transformer

Transformer 是由

两种模块组

合构建的模

块化网络结

构。两种模块

分别为：（1）

注意

力（Attention）模块；（2）全连

接前馈（Fully-connected

Feedforwad）模块

。其中，

自注意

力模块由自

注意力层（Self-Attention Layer）、残

差连接（Residual Connections）

和层

正则化（Layer Normalization）组成

。全连接前馈

模块由全连

接前馈层，残

差

连接和层

正则化组成

。两个模块的

结构示意图

如图1.5所示。以

下详细介绍

每个层

的原

理及作用。

注

意力模块 全

连接前馈模

块

输入

输出

输入

输出 输

入

输入

图

1.5: 注

意力模块与

全连接前馈

模块。

13

注

意

力

层

层

正

则

化

层

正

则

化

全

连

接

前

馈

层

第 1 章

语言模

型基础

图 1.6: 注

意力机制示

意图。

1. 注意力

层（Attention Layer）

注意力层

采用加权平

均的思想将

前文信息叠

加到当前状

态上。Transformer

的

注意

力层将输入

编码为 query，key，value 三部

分，即将输入

{x1,

x2, ..., xt} 编码为

{(q1, k1, v1),(q2, k2,

v2), ...,(qt

, kt

, vt)}。其中

，query 和 key

用于计算

自注意力的

权重

α, value 是对输

入的编码。具

体的，

Attention(xt) =

t

X

i=1

αt,ivi。 (1.31)

其中，

αt,i = sof tmax(sim(xt

, xi)) = sim(qt

, ki)

P

t

i=1 sim(qt

, ki)

。 (1.32)

其

中，sim(·, ·)

用于度量

两个输入之

间的相关程

度，softmax 函数用于

对此相关程

度进行归一

化。此外，

qi =

Wqxi

, ki =

Wkxi

, vi =

Wvxi， (1.33)

其中

，Wq, Wk,

Wv 分别为 query，key，value 编码

器的参数。以

包含三个元

素的输

入 {x1, x2, x3}

为

例，Transformer 自注意力

的实现图1.6所

示。

14

毛玉仁

高

云君

2. 全连接

前馈层（Fully-connected Feedforwad

Layer）

全连

接前馈层占

据了 Transformer 近三分

之二的参数

，掌管着

Transformer 模型

的记忆。其可

以看作是一

种 Key-Value 模式的记

忆存储管理

模块

[7]。全连接

前馈

层包含

两层，两层之

间由 ReLU 作为激

活函数。设全

连接前馈层

的输入为

v, 全

连

接前馈层

可由下式表

示：

F

F N(v) = max(0,

W1v + b1)W2 +

b2。 (1.34)

其中，W1 和

W2 分

别为第一层

和第二层的

权重参数，b1 和

b2 分别为第一

层和第二

层

的偏置参数

。其中第一层

的可看作神

经记忆中的

key，而第二层可

看作 value。

3. 层正则

化（Layer

Normalization）

层正则化

用以加速神

经网络训练

过程并取得

更好的泛化

性能 [1]。设输入

到层

正则化

层的向量为

v

= {vi}

n

i=1。层正则化层

将在

v 的每一

维度 vi 上都进

行层正则

化

操作。具体地

，层正则化操

作可以表示

为下列公式

：

LN(vi) = α(vi

− µ)

δ

+

β。 (1.35)

其中，α 和

β 为可

学习参数。µ 和

δ 分别是隐藏

状态的均值

和方差，可由

下列公式

分

别计算。

µ =

1

n

nX

i=1

vi

, δ =

v

u

u t

n

1

nX

i=1

(vi

− µ)

2。 (1.36)

4. 残差

连接（Residual Connections）

引入残

差连接可以

有效解决梯

度消失问题

。在基本的

Transformer 编

码模块中

包

含两个残差

连接。第一个

残差连接是

将自注意力

层的输入由

一条旁路叠

加到自

注意

力层的输出

上，然后输入

给层正则化

。第二个残差

连接是将全

连接前馈层

的

输入由一

条旁路引到

全连接前馈

层的输出上

，然后输入给

层正则化。

上

述将层正则

化置于残差

连接之后的

网络结构被

称为 Post-LN Transformer。与

之相

对的，还有一

种将层正则

化置于残差

连接之前的

网络结构，称

之为 Pre-LN

15

第

1 章 语

言模型基础

......

......

......

输入

输出

图

1.7:

Transfomer 结构示意图

。

Transformers。对比两者，Post-LN Transformer

应

对表征坍塌

（Representation Collapse）

的能力更强

，但处理梯度

消失略弱。而

Pre-LN Transformers

可以更好的

应对梯度

消

失，但处理表

征坍塌的能

力略弱。具体

分析可参考

文献 [7, 22]。

原始的

Transformer 采用 Encoder-Decoder 架构，其

包含

Encoder 和 Decoder 两

部

分。这两部分

都是由自注

意力模块和

全连接前馈

模块重复连

接构建而成

。其整

体结构

如图1.7所示。其

中，Encoder 部分由六

个级联的 encoder

layer 组

成，每个

encoder layer

包含

一个注意力

模块和一个

全连接前馈

模块。其中的

注意力模块

为

自注意力

模块（query，key，value 的输入

是相同的）。Decoder 部

分由六个级

联的

decoder layer 组成，每

个 decoder

layer 包含两个

注意力模块

和一个全连

接前馈模块

。

其中，第一个

注意力模块

为自注意力

模块，第二个

注意力模块

为交叉注意

力模块

（query，key，value

的输

入不同）。Decoder 中第

一个 decoder layer

的自注

意力模块的

输入为模型

的输出。其后

的 decoder layer 的自注意

力模块的输

入为上一个

decoder

layer 的输出。Decoder 交叉

注意力模块

的输入分别

是自注意力

模块的输出

（query）

和最后一个

encoder

layer 的输出（key，value）。

Transformer 的

Encoder 部

分和 Decoder 部分都

可以单独用

于构造语言

模型，分

别对

应 Encoder-Only 模型和 Decoder-Only

模

型。Encoder-Only 模型和 Decoder-Only

模

型的具体结

构将在第二

章中进行详

细介绍。

16

注

意

力

模

块

全

连

接

前

馈

模

块

注

意

力

模

块

全

连

接

前

馈

模

块

注

意

力

模

块

全

连

接

前

馈

模

块

注

意

力

模

块

全

连

接

前

馈

模

块

注

意

力

模

块

注

意

力

模

块

全

连

接

前

馈

模

块

注

意

力

模

块

注

意

力

模

块

全

连

接

前

馈

模

块

注

意

力

模

块

线

性

层

S

o

f

t

m

a

x

编

码

器

（

E

n

c

o

d

e

r

）

解

码

器

（

D

e

c

o

d

e

r

）

毛

玉仁

高云君

1.3.2 基于 Transformer 的语言

模型

在 Transformer 的基

础上，可以设

计多种预训

练任务来训

练语言模型

。例如，我

们可

以基于

Transformer 的 Encoder 部

分，结合“掩词

补全”等任务

来训练

Encoder￾Only 语言

模型，如 BERT [5]；我们

可以同时应

用

Transformer 的 Endcoder 和

Decoder

部分

，结合“截断补

全”、“顺序恢复

”等多个有监

督和自监督

任务来训练

Encoder￾Decoder 语言模型，如

T5 [18]；我们可以同

时应用

Transformer 的 Decoder 部

分，

利用“下一

词预测”任务

来训练 Decoder-Only 语言

模型，如 GPT-3

[3]。这些

语言

模型将

在第二章中

进行详细介

绍。下面将以

下一词预测

任务为例，简

单介绍训练

Transformer 语言模型的

流程。

对词序

列{w1,

w2, w3, ..., wN

}，基于Transformer 的语

言模型根据

{w1, w2, ...,

wi}

预测下一个

词 wi+1 出现的概

率。在基于

Transformer 的

语言模型中

，输出为一个

向

量，其中每

一维代表着

词典中对应

词的概率。设

词典D 中共有

|D|

个词 {wˆ1,wˆ2, ...,wˆ|D|}。

基于

Transformer 的

语言模型的

输出可表示

为 oi =

{oi

[ ˆwd]}

D

d=1，其中，oi

[ ˆwd] 表示

词

典中的词

wˆd 出现的概率

。因此，对Transformer 的语

言模型对词

序列{w1, w2,

w3, ..., wN }

整体出

现的概率的

预测为：

P(w1:N ) =

N−1

Y

i=1

P(wi+1|w1:i)

=

N

Y

i=1

oi

[wi+1] (1.37)

与训

练

RNN 语言模型

相同，Transformer 语言模

型也常用如

下交叉熵函

数作为

损失

函数。

lCE(oi) = −

|D|

X

d=1

I( ˆwd

= wi+1) log oi

[wi+1] = − log

oi

[wi+1]。 (1.38)

其中，I(·)

为

指示函数，当

wˆd = wi+1 时等于

1，当 wˆd = wi+1

时

等于 0。

设训练

集为 S，Transformer

语言模

型的损失可

以构造为：

L(S, W) =

1

N|S|

|S|

X

s=1

N

X

i=1

lCE(oi,s) (1.39)

17

第

1

章 语言模型

基础

其中，oi,s 为

Transformer

语言模型输

入样本 s 的前

i 个词时的输

出。在此损失

的基

础上，构

建计算图，进

行反向传播

，便可对 Transformer 语言

模型进行训

练。

上述训练

过程结束之

后，我们可以

将

Encoder 的输出作

为特征，然后

应用这些

特

征解决下游

任务。此外，还

可在“自回归

”的范式下完

成文本生成

任务。在自回

归中，第一轮

，我们首先将

第一个词输

入给 Transformer

语言模

型，经过解码

，得

到一个输

出词。然后，我

们将第一轮

输出的词与

第一轮输入

的词拼接，作

为第二轮

的

输入，然后解

码得到第二

轮的输出。接

着，将第二轮

的输出和输

入拼接，作为

第

三轮的输

入，以此类推

。每次将本轮

预测到的词

拼接到本轮

的输入上，输

入给语言

模

型，完成下一

轮预测。在循

环迭代的“自

回归”过程中

，我们不断生

成新的词，

这

些词便构成

了一段文本

。与训练 RNN 语言

模型一样，Transformer

模

型的预训练

过程依然采

用第 1.2.2 节中提

到的“Teacher Forcing”的范式

。

相较于 RNN 模型

串行的循环

迭代模式，Transformer 并

行输入的特

性，使其容

易

进行并行计

算。但是，Transformer 并行

输入的范式

也导致网络

模型的规模

随输

入序列

长度的增长

而平方次增

长。这为应用

Transformer 处理长序列

带来挑战。

1.4 语

言模型的采

样方法

语言

模型的输出

为一个向量

，该向量的每

一维代表着

词典中对应

词的概率。在

采用自回归

范式的文本

生成任务中

，语言模型将

依次生成一

组向量并将

其解码为

文

本。将这组向

量解码为文

本的过程被

成为语言模

型解码。解码

过程显著影

响着

生成文

本的质量。当

前，两类主流

的解码方法

可以总结为

(1). 概率最大化

方法; (2).

随机采

样方法。两类

方法分别在

下面章节中

进行介绍。

18

毛

玉仁 高云君

1.4.1 概率最大化

方法

设词典

为 D，输入文本

为 {w1, w2,

w3, ..., wN }，第

i 轮自回

归中输出的

向量为

oi =

{oi

[wd]}

|

d

D

=1

|

,

模型

在M 轮自回归

后生成的文

本为{wN+1, wN+2, wN+3,

..., wN+M}。

生成文

档的出现的

概率可由下

式进行计算

。

P(wN+1:N+M)

=

N+M−1

Y

i=N

P(wi+1|w1:i) =

N+M−1

Y

i=N

oi

[wi+1] (1.40)

基于概率最

大化的解码

方法旨在最

大化 P(wN+1:N+M)，以生成

出可能性最

高

的文本。该

问题的搜索

空间大小为

MD，是 NP-Hard

问题。现有

概率最大化

方法通

常采

用启发式搜

索方法。本节

将介绍两种

常用的基于

概率最大化

的解码方法

。

1. 贪心搜索（Greedy

Search）

贪

心搜索在在

每轮预测中

都选择概率

最大的词，即

wi+1 = arg

maxw∈D oi

[w] (1.41)

贪心搜索只

顾“眼前利益

”，忽略了“远期

效益”。当前概

率大的词有

可能导致后

续

的词概率

都很小。贪心

搜索容易陷

入局部最优

，难以达到全

局最优解。以

图1.8为

例，当输

入为“生成一

个以长颈鹿

开头的故事

：长颈鹿”时，预

测第一个词

为“是”

的概率

最高，为

0.3。但选

定“是”之后，其

他的词的概

率都偏低。如

果按照贪心

搜索的方式

，我们最终得

到的输出为

“是草食”。其概

率仅为 0.03。而如

果我们在

第

一个词选择

了概率第二

的“脖子”，然后

第二个词选

到了“长”，最终

的概率可

以

达到

0.1。通过此

例，可以看出

贪心搜索在

求解概率最

大的时候容

易陷入局部

最

优。为缓解

此问题，可以

采用波束搜

索（Beam Search）方法进行

解码。

2.

波束搜

索（Beam Search）

波束搜索

在每轮预测

中都先保留

b 个可能性最

高的词Bi

= {wi

1

+1,

wi

2

+1, ....,

wi

b

+1}，

即：

min{oi

[w] for w

∈ Bi} > max{oi

[w] for w ∈

D − Bi}。 (1.42)

19

第

1 章 语言模型

基础

生成一

个以长颈鹿

开头的故事

：长颈鹿

是 脖

子 看着

草食

反刍 偶蹄 ...

...

长

优雅 疼 ... 远方

躲在

大象 ...

0.3 0.2

0.15

0.1 0.09 0.08

0.5 0.1 0.2 0.3

0.1 0.2

贪

心算法采样

路径 波束搜

索采样路径

戏剧性较强

的路径

图 1.8: 贪

心搜索与波

束搜索对比

以及概率最

大化解码的

潜在问题。

在

结束搜索时

，得到

M 个集合

，即 {Bi}

M

i=1。找出最优

组合使得联

合概率最大

，即：

{wN+1, ..., wN+M}

= arg max{wi∈Bi f

or 1≤i≤M}

M

Y

i=1

oN+i

[w

i

]。 (1.43)

继续以上

面的“生成一

个以长颈鹿

开头的故事

”为例，从图1.8中

可以看出如

果我们采用

b =

2 的波束搜索

方法，我们可

以得到“是草

食”，“是反刍”，“脖

子

长”，“脖子优

雅”四个候选

组合，对应的

概率分别为

：0.03，0.027，0.1，0.04。我

们容易选

择到概率最

高的“脖子长

”。

但是，概率最

大的文本通

常是最为常

见的文本。这

些文本会略

显平庸。在开

放

式文本生

成中，无论是

贪心搜索还

是波束搜索

都容易生成

一些“废话文

学”—重复

且平

庸的文本。其

所生成的文

本缺乏多样

性 [19]。如在图1.8中

的例子所示

，概率

最大的

方法会生成

” 脖子长”。” 长颈

鹿脖子长” 这

样的文本新

颖性较低。为

了提升

生成

文本的新颖

度，我们可以

在解码过程

中加入一些

随机元素。这

样的话就可

以

解码到一

些不常见的

组合，从而使

得生成的文

本更具创意

，更适合开放

式文本任

务

。在解码过程

中加入随机

性的方法，成

为随机采样

方法。下节将

对随机采样

方法

进行介

绍。

20

毛玉仁 高

云君

1.4.2

随机采

样方法

为了

增加生成文

本的多样性

，随机采样的

方法在预测

时增加了随

机性。在每

轮

预测时，其先

选出一组可

能性高的候

选词，然后按

照其概率分

布进行随机

采样，

采样出

的词作为本

轮的预测结

果。当前，主流

的

Top-K 采样和 Top-P 采

样方法分别

通过指定候

选词数量和

划定候选词

概率阈值的

方法对候选

词进行选择

。在采样方

法

中加入 Temperature 机制

可以对候选

词的概率分

布进行调整

。接下来将对

Top-K

采样、Top-P

采样和

Temperature 机制分别展

开介绍。

1. Top-K

采样

Top-K 采样在每轮

预测中都选

取 K 个概率最

高的词

{wi

1

+1, wi

2

+1, ...., wi

K

+1} 作为

本轮的候选

词集合，然后

对这些词的

概率用 softmax

函数

进行归一化

，得到如下分

布函数

p(wi

1

+1,

...., wi

K

+1)

= ( exp(oi

[w

1

i+1])

P

K

j=1 exp(oi

[w

j

i+1])

, ....,

exp(oi

[w

K

i+1])

P

K

j=1 exp(oi

[w

j

i+1]))

。 (1.44)

然后

根据该分布

采样出本轮

的预测的结

果，即

wi+1 ∼ p(wi

1

+1, ...., wi

K

+1)。 (1.45)

Top-K

采样可

以有效的增

加生成文本

的新颖度，例

如在上述图

1.8所示的例子

中选用 Top-3 采样

的策略，则有

可能会选择

到“看着躲在

”。“长颈鹿看着

躲在”可

能是

一个极具戏

剧性的悬疑

故事的开头

。

但是，将候选

集设置为固

定的大小 K 将

导致上述分

布在不同轮

次的预测中

存

在很大差

异。当候选词

的分布的方

差较大的时

候，可能会导

致本轮预测

选到概率

较

小、不符合常

理的词，从而

产生“胡言乱

语”。例如，在如

图1.9 (a) 所示的例

子

中，Top-2

采样有

可能采样出

“长颈鹿有四

条裤子”。而当

候选词的分

布的方差较

小

的时候，甚

至趋于均匀

分布时，固定

尺寸的候选

集中无法容

纳更多的具

有相近概

率

的词，导致候

选集不够丰

富，从而导致

所选词缺乏

新颖性而产

生“枯燥无趣

”的

21

第 1 章 语言

模型基础

长

颈鹿有四条

0.9

腿 好汉 裤子

围巾

鱼

......

0.02 0.01

0.01 0.01

Top-p

长颈

鹿用脖子来

0.35

觅食

Top-k

炫耀 眺

望

打架 睡觉

......

0.2 0.15

0.1 0.03

Top-p

（b）Top-k枯燥无味

（a）Top-k胡

言乱语

Top-k

图 1.9:

Top-K 采

样的潜在问

题及其与 Top-P 方

法的对比。

文

本。例如，在如

下图1.9 (b) 所示的

例子中，通过

Top-2 采样，我们只

能得到“长

颈

鹿用脖子来

觅食”或者“长

颈鹿用脖子

来眺望”，这些

都是人们熟

知的长颈鹿

脖

子的用途

，缺乏新意。但

是其实长颈

鹿的脖子还

可以用于打

架或睡觉，Top-2 采

样

的方式容

易将这些新

颖的不常见

的知识排除

。为了解决上

述问题，我们

可以使用

Top-P 采

样，也称 Nucleus 采样

。

2. Top-P 采样

为了解

决固定候选

集所带来的

问题，Top-P

采样（即

Nucleus 采样）被提出

[9]。

其设定阈值

p 来对候选集

进行选取。其

候选集可表

示为

Sp = {wi

1

+1, wi

2

+1,

...., wi

|S

+1

p|

}，

其中，对

Sp 有，P

w∈Sp

oi

[w] ≥

p。候选集中

元素的分布

服从

p(wi

1

+1,

...., wi

|S

+1

p|

) = (

exp(oi

[w

1

i+1])

P

|Sp|

j=1 exp(oi

[w

j

i+1])

,

....,

exp(oi

[w

|Sp|

i+1 ])

P

|Sp|

j=1 exp(oi

[w

j

i+1]))

。 (1.46)

然后根

据该分布采

样出本轮的

预测的结果

，即

wi+1 ∼ p(wi

1

+1, ...., wi

|S

+1

p|

)。 (1.47)

应用阈值

作为候选集

选取的标准

之后，Top-P 采样可

以避免选到

概率较小、不

符合常理的

词，从而减少

“胡言乱语”。例

如在图1.9 (a) 所示

例子中，我们

若以

0.9

作为阈

值，则就可以

很好的避免

“长颈鹿有四

条裤子”的问

题。并且，其还

可以容

22

毛玉

仁

高云君

纳

更多的具有

相近概率的

词，增加文本

的丰富度，改

善“枯燥无趣

”。例如在图1.9

(b) 所

示的例子中

，我们若以

0.9 作

为阈值，则就

可以包含打

架、睡觉等长

颈鹿脖

子鲜

为人知的用

途。

3.

Temperature 机制

Top-K 采样

和

Top-P 采样的随

机性由语言

模型输出的

概率决定，不

可自由调

整

。但在不同场

景中，我们对

于随机性的

要求可能不

一样。比如在

开放文本生

成

中，我们更

倾向于生成

更具创造力

的文本，所以

我们需要采

样具有更强

的随机性。

而

在代码生成

中，我们希望

生成的代码

更为保守，所

以我们需要

较弱的随机

性。引

入 Temperature 机制

可以对解码

随机性进行

调节。Temperature

机制通

过对 Softmax

函数中

的自变量进

行尺度变换

，然后利用 Softmax

函

数的非线性

实现对分布

的控

制。设 Temperature 尺

度变换的变

量为

T。

引入 Temperature 后

，Top-K

采样的候选

集的分布如

下所示：

p(wi

1

+1,

...., wi

K

+1)

=







exp(

oi[w1

i+1]

T

)

P

K

j=1

exp(

oi[w

j

i+1]

T

)

, ....,

exp(

oi[wK

i+1]

T

)

P

K

j=1

exp(

oi[w

j

i+1]

T

)







。 (1.48)

引入

Temperature

后，Top-P 采样的候

选集的分布

如下所示：

p(wi

1

+1, ...., wi

|S

+1

p|

) =







exp(

oi[w1

i+1]

T

)

P

|Sp|

j=1 exp(

oi[w

j

i+1]

T

)

, ....,

exp(

oi[w

|Sp|

i+1 ]

T

)

P

|Sp|

j=1 exp(

oi[w

j

i+1]

T

)







。 (1.49)

容

易看出，当 T > 1

时

，Temperature 机制会使得

候选集中的

词的概率差

距减

小，分布

变得更平坦

，从而增加随

机性。当 0

< T < 1

时，Temperature 机

制会使得

候

选集中的元

素的概率差

距加大，强者

越强，弱者越

弱，概率高的

候选词会容

易被

选到，从

而随机性变

弱。Temperature

机制可以

有效的对随

机性进行调

节来满足不

同的需求。

23

第

1 章

语言模型

基础

1.5 语言模

型的评测

得

到一个语言

模型后，我们

需要对其生

成能力进行

评测，以判断

其优劣。评测

语言模型生

成能力的方

法可以分为

两类。第一类

方法不依赖

具体任务，直

接通过语

言

模型的输出

来评测模型

的生成能力

，称之为内在

评测（Intrinsic Evaluation）。第

二类

方法通过某

些具体任务

，如机器翻译

、摘要生成等

，来评测语言

模型处理这

些

具体生成

任务的能力

，称之为外在

评测（Extrinsic

Evaluation）。

1.5.1 内在评

测

在内在评

测中，测试文

本通常由与

预训练中所

用的文本独

立同分布的

文本构

成，不

依赖于具体

任务。最为常

用的内部评

测指标是困

惑度（Perplexity）[10]。其

度量

了语言模型

对测试文本

感到“困惑”的

程度。设测试

文本为 stest =

w1:N。语

言

模型在测试

文本 stest 上的困

惑度

P P L 可由下

式计算：

P P L(stest) =

P(w1:N )

− 1

N =

N

v

uut

N

Y

i=1

1

P(wi

|w<i)

。

(1.50)

由上

式可以看出

，如果语言模

型对测试文

本越“肯定”（即

生成测试文

本的概

率越

高），则困惑度

的值越小。而

语言模型对

测试文本越

“不确定”（即生

成测试文

本

的概率越低

），则困惑度的

值越大。由于

测试文本和

预训练文本

同分布，预训

练

文本代表

了我们想要

让语言模型

学会生成的

文本，如果语

言模型在这

些测试文本

上越不“困惑

”，则说明语言

模型越符合

我们对其训

练的初衷。因

此，困惑度可

以

一定程度

上衡量语言

模型的生成

能力。

对困惑

度进行改写

，其可以改写

成如下等价

形式。

P

P L(stest) = exp(−

1

N

N

X

i=1

log P(wi

|w<i))。

(1.51)

其中，− N

1

P N

i=1 log

P(wi

|w<i) 可

以看作是生

成模型生成

的词分布与

测试样本真

实

24

毛玉仁 高

云君

的词分

布间的交叉

熵，即 −

N

1 P N

i=1

P

|D|

d=1

I( ˆwd = wi)

log oi−1[wi

]，其中 D

为

语言模

型所

采用的词典

。因为 P(wi

|w<i)

≤ 1，所以此

交叉熵是生

成模型生成

的词分布的

信息熵的上

界，即

−

1

N

N

X

i=1

P(wi

|w<i) log P(wi

|w<i) ≤ −

N

1 X

N

i=1

log P(wi

|w<i)。 (1.52)

因此，困

惑度减小也

意味着熵减

，意味着模型

“胡言乱语”的

可能性降低

。

1.5.2 外在评测

在

外在评测中

，测试文本通

常包括该任

务上的问题

和对应的标

准答案，其依

赖于具体任

务。通过外在

评测，我们可

以评判语言

模型处理特

定任务的能

力。外在

评测

方法通常可

以分为基于

统计指标的

评测方法和

基于语言模

型的评测方

法两类。

以下

对此两类方

法中的经典

方法进行介

绍。

1. 基于统计

指标的评测

基于统计指

标的方法构

造统计指标

来评测语言

模型的输出

与标准答案

间的契

合程

度，并以此作

为评测语言

模型生成能

力的依据。BLEU（BiLingual Evaluation

Understudy）和

ROUGE（Recall-Oriented Understudy

for Gisting Evaluation）是应用

最为

广泛的两种

统计指标。其

中，BLEU

是精度导

向的指标，而

ROUGE 是召回导

向

的指标。以下

分别对这两

个指标展开

介绍。

BLEU

被提出

用于评价模

型在机器翻

译（Machine Translation, MT）任务上的

效

果

[6]。其在词

级别上计算

生成的翻译

与参考翻译

间的重合程

度。具体地，BLEU 计

算多层次 n-gram 精

度的几何平

均。设生成的

翻译文本的

集合为

Sgen = {Sgen

i

}

|

i

S

=1

gen|，

对应

的参考翻译

集合为 Sref

= {Sref

i }

|

i

S

=1

ref |，其中

，Sgen

i 与

Sref

i 一一对应

，且 |Sref

| =

|Sgen|。原始的 n-gram

精

度的定义如

下：

P r(gn) =

P

|Sgen|

i=1

P

gn∈Sgen

i Countmatch(gn, Sref

i

)

P

|Sgen|

i=1

P gn∈Sgen

i

Count(gn)

。 (1.53)

25

第 1 章 语言

模型基础

其

中，gn 代表 n-gram。上式

的分子计算

了生成的翻

译与参考翻

译的重合的

n￾gram 的个数，分母

计算了生成

的翻译中包

含的

n-gram 的总数

。例如，MT 模型将

“大语言模型

”翻译成英文

，生成的翻译

为“big language

models”，而参考文

本为

“large language models”。当

n = 1 时，P

r(g1) = 2

3。当

n

= 2 时，P r(g2)

= 1

2。

基于

n-gram 精度

，BLEU 取 N

个 n-gram 精度的

几何平均作

为评测结果

：

BLEU

=

N

v

uut

N

Y

n=1

P

r(gn) = exp

N

X

n=1

logP

r(gn)

! 。 (1.54)

例如，当 N = 3

时，BLEU 是

unigram 精度，bigram 精度，trigram

精

度的几何平

均。在以上原

始 BLEU 的基础上

，我们还可以

通过对不同

的 n-gram

精度进行

加权

或对不

同的文本长

度设置惩罚

项来对 BLEU 进行

调整，从而得

到更为贴近

人类评

测的

结果。

ROUGE 被提出

用于评价模

型在摘要生

成（Summarization）任务上的

效果 [13]。

常用的

ROUGE 评测包含 ROUGE-N, ROUGE-L,

ROUGE-W, 和

ROUGE-S 四种。

其中，ROUGE-N

是

基于 n-gram 的召回

指标，ROUGE-L 是基于

最长公共子

序列

（Longest Common Subsequence, LCS）的召回

指标。ROUGE-W

是在 ROUGE-L 的

基

础上，引入

对

LCS 的加权操

作后的召回

指标。ROUGE-S 是基于

Skip-bigram 的召

回指标

。下面给出 ROUGE-N, ROUGE-L 的

定义。ROUGE-W

和 ROUGE-S 的具

体

计算方法

可在

[13] 中找到

。

ROUGE-N 的定义如下

：

ROUGE-N =

P

s∈Sref

P gn∈s Countmatch(gn, sgen)

P

s∈Sref

P gn∈s

Count(gn)

。 (1.55)

ROUGE-L

的定义如下

：

ROUGE-L =

(1

+ β

2

)Rr

gRg

r

Rr

g

+ β

2Rg

r

。 (1.56)

26

毛玉仁

高云

君

其中，

Rr

g

=

LCS(sref , sgen)

|sref |

， (1.57)

Rg

r =

LCS(sref

, sgen)

|sgen|

，

(1.58)

LCS(sref , sgen)

是模

型生成的摘

要 sgen 与参考摘

要 sref

间的最大

公共子序列

的长

度，β = Rg

r/Rr

g。

基于

统计指标的

评测方法通

过对语言模

型生成的答

案和标准答

案间的重叠

程

度进行评

分。这样的评

分无法完全

适应生成任

务中表达的

多样性，与人

类的评测相

差甚远，尤其

是在生成的

样本具有较

强的创造性

和多样性的

时候。为解决

此问题，

可以

在评测中引

入一个其他

语言模型作

为“裁判”，利用

此“裁判”在预

训练阶段

掌

握的能力对

生成的文本

进行评测。下

面对这种引

入“裁判”语言

模型的评测

方法

进行介

绍。

2.

基于语言

模型的评测

目前基于语

言模型的评

测方法主要

分为两类：（1）基

于上下文词

嵌入（Contex￾tual Embeddings）的评测

方法；（2）基于生

成模型的评

测方法。典型

的基于上下

文

词嵌入的

评测方法是

BERTScore [24]。典型的基于

生成模型的

评测方法是

G-EVAL

[14]。与 BERTScore 相比，G-EVAL 无需

人类标注的

参考答案。这

使其可以更

好的

适应到

缺乏人类标

注的任务中

。

BERTScore 在 BERT

的上下文

词嵌入向量

的基础上，计

算生成文本

sgen 和参

考文本

sref 间的相似度

来对生成样

本进行评测

。BERT

将在第二章

给出详细介

绍。

设生成文

本包含 |sgen| 个词

，即

sgen = {wg

i

}i

|s

=1

gen|。设参考文

本包含

|sref | 个词

，即

sref

= {wr

i}

|

i

s

=1

ref

|。利用 BERT 分别

得到 sgen

和 sref 中每

个词的上下

文词嵌入向

量，

即

vg

i = BERT(wg

i

|sgen)，vr

i =

BERT(wr

i

|sref )。利用生

成文本和参

考文本的词

嵌

入向量集

合 vgen = {vg

i }

|

i

v

=1

gen| 和

vref = {vr

i}

|

i

v

=1

ref | 便可计

算 BERTScore。BERTScore

27

第 1 章

语言

模型基础

从

精度（Precision），召回（Recall）和

F1 量度三个方

面对生成文

档进行评测

。其

定义分别

如下：

PBERT =

1

|vgen|

|vgen|

X

i=1

maxvr∈vref

vg

i ⊤

vr

i， (1.59)

RBERT =

1

|vref |

|vref

|

X

i=1

maxvg∈vgen

vr

i ⊤

vg

i， (1.60)

FBERT =

2PBERT · RBERT

PBERT

+ RBERT

。 (1.61)

相较于

统计评测指

标，BERTScore 更接近人

类评测结果

。但是，BERTScore 依

赖于

人类给出的

参考文本。这

使其无法应

用于缺乏人

类标注样本

的场景中。得

益

于生成式

大语言模型

的发展，G-EVAL 利用

GPT-4 在没有参考

文本的情况

下对生

成文

本进行评分

。G-EVAL

通过提示工

程（Prompt Engineering）引导 GPT-4 输出

评

测分数。Prompt Engineering 将

在本书第三

章进行详细

讲解。

如下图

所示，G-EVAL

的 Prompt 分为

三部分：(1) 任务

描述与评分

标准；(2)

评

测步

骤；(3) 输入文本

与生成的文

本。在第一部

分中，任务描

述指明需要

的评测的

任

务式什么（如

摘要生成），评

分标准给出

评分需要的

范围，评分需

要考虑的因

素

等内容。第

二部分的评

测步骤是在

第一部分内

容的基础上

由 GPT-4 自己生成

的思

维链（Chain-of-Thoughts,

CoT）。本

书的第三章

将对思维链

进行详细讲

解。第三部

分

的输入文本

与生成的文

本是源文本

和待评测模

型生成的文

本。例如摘要

生成任

务中

的输入文本

是原文，而生

成的文本就

是生成摘要

。将上述三部

分组合在一

个

prompt

里面然后

输入给 GPT-4，GPT-4 便可

给出对应的

评分。直接将

GPT-4 给出

的得分

作为评分会

出现区分度

不够的问题

，因此，G-EVAL 还引入

了对所有可

能得

分进行

加权平均的

机制来进行

改进 [14]。

28

毛玉仁

高云君

任务

描述

评分标

准

评分步骤

待评价内容

任务描述

评

分标准

评分

步骤 评价结

果

Auto CoT GPT-4 GPT-4

图 1.10: G-EVAL 评测流

程。

除 G-EVAL 外，近期

还有多种基

于生成模型

的评测方法

被提出 [12]。其中

典型

的有 InstructScore [23]，其

除了给出数

值的评分，还

可以给出对

该得分的解

释。基

于生成

模型的评测

方法相较于

基于统计指

标的方法和

基于上下文

词嵌入的评

测方

法而言

，在准确性、灵

活性、可解释

性等方面都

具有独到的

优势。可以预

见，未来

基于

生成模型的

评测方法将

得到更为广

泛的关注和

应用。

参考文

献

[1]

Jimmy Lei Ba, Jamie

Ryan Kiros, and Geoffrey

E. Hinton. Layer Normalization.

2016. arXiv: 1607.06450.

[2]

Samy Bengio et al.

“Scheduled Sampling for Sequence

Prediction with Recurrent

Neural

Networks”. In: NeurIPS. 2015.

[3] Tom B. Brown

et al. “Language Models

are Few-Shot Learners”. In:

NeurIPS. 2020.

[4] Junyoung

Chung et al. Empirical

Evaluation of Gated Recurrent

Neural Networks

on Sequence

Modeling. 2014. arXiv: 1412.3555.

[5] Jacob Devlin et

al. “BERT: Pre-training of

Deep Bidirectional Transformers for

Language Understanding”. In: NAACL-HLT.

2019.

[6] Markus Freitag,

David Grangier, and Isaac

Caswell. “BLEU might be

Guilty but

References are

not Innocent”. In: EMNLP.

2020.

[7] Mor Geva

et al. “Transformer Feed-Forward

Layers Are Key-Value Memories”.

In:

EMNLP. 2021.

29

第 1 章 语言

模型基础

[8] Sepp Hochreiter and

Jürgen Schmidhuber. “Long Short-Term

Memory”. In: Neural

Computing

9.8 (1997), pp. 1735–1780.

[9] Ari Holtzman et

al. “The Curious Case

of Neural Text Degeneration”.

In: ICLR.

2020.

[10]

F. Jelinek et al.

“Perplexity—a measure of the

difficulty of speech recognition

tasks”. In: The Journal

of the Acoustical Society

of America 62 (1997),

S63–S63.

[11] Dan Jurafsky

and James H. Martin.

Speech and language processing:

an introduc￾tion to natural

language processing, computational linguistics,

and speech recogni￾tion, 2nd

Edition. Prentice Hall series

in artificial intelligence. Prentice

Hall, Pear￾son Education International,

2009. ISBN: 9780135041963.

[12]

Zhen Li et al.

Leveraging Large Language Models

for NLG Evaluation: Advances

and Challenges. 2024. arXiv:

2401.07103.

[13] Chin-Yew Lin.

“Rouge: A package for

automatic evaluation of summaries”.

In:

ACL. 2004.

[14]

Yang Liu et al.

“Gpteval: Nlg evaluation using

gpt-4 with better human

alignment”.

In: EMNLP. 2023.

[15] Christopher D. Manning

and Hinrich Schütze. Foundations

of statistical natural

language

processing. MIT Press, 2001.

ISBN: 978-0-262-13360-9.

[16] OpenAI.

GPT-4 Technical Report. 2024.

arXiv: 2303.08774.

[17] Razvan

Pascanu, Tomás Mikolov, and

Yoshua Bengio. “On the

difficulty of training

recurrent

neural networks”. In: ICML.

2013.

[18] Colin Raffel

et al. “Exploring the

Limits of Transfer Learning

with a Unified Text￾to-Text

Transformer”. In: Journal of

Machine Learning Research 21

(2020), 140:1–

140:67.

[19]

Ashwin K. Vijayakumar et

al. “Diverse Beam Search:

Decoding Diverse Solutions

from

Neural Sequence Models”. In:

AAAI. 2018.

[20] Joseph

Weizenbaum. “ELIZA - a

computer program for the

study of natural lan￾guage

communication between man and

machine”. In: Communications Of

The

ACM 9.1 (1966),

pp. 36–45.

[21] Ronald

J. Williams and David

Zipser. “A Learning Algorithm

for Continually Run￾ning Fully

Recurrent Neural Networks”. In:

Neural Computing 1.2 (1989),

pp. 270–

280.

30

毛

玉仁 高云君

[22] Shufang Xie

et al. ResiDual: Transformer

with Dual Residual Connections.

2023.

arXiv: 2304.14802.

[23]

Wenda Xu et al.

“INSTRUCTSCORE: Towards Explainable Text

Generation Eval￾uation with Automatic

Feedback”. In: EMNLP. 2023.

[24] Tianyi Zhang et

al. “BERTScore: Evaluating Text

Generation with BERT”. In:

ICLR. 2020.

31

2

大语言模型

架构

随着数

据资源和计

算能力的爆

发式增长，语

言模型的参

数规模和性

能表现实

现

了质的飞跃

，迈入了大语

言模型（Large Language

Model, LLM）的新

时代。凭借着

庞大的参数

量和丰富的

训练数据，大

语言模型不

仅展现出了

强大的泛化

能力，还催

生

了新智能的

涌现，勇立生

成式人工智

能（Artificial Intelligence

Generated Content,

AIGC）的浪潮之

巅。当前，大语

言模型技术

蓬勃发展，各

类模型层出

不穷。这些

模

型在广泛的

应用场景中

已经展现出

与人类比肩

甚至超过人

类的能力，引

领着由

AIGC 驱动

的新一轮产

业革命。本章

将深入探讨

大语言模型

的相关背景

知识，并分

别

介绍 Encoder-only、Encoder-Decoder

以及 Decoder-only 三

种主流模型

架构。通过

列

举每种架构

的代表性模

型，深入分析

它们在网络

结构、训练方

法等方面的

主要

创新之

处。最后，本章

还将简单介

绍一些非 Transformer 架

构的模型，以

展现当前

大

语言模型研

究百花齐放

的发展现状

。

* 本书持续更

新，GIT Hub 链接为：https://github.com/ZJU-LLMs/Foundations-of-LLMs。

第

2 章 大语言模

型架构

2.1

大数

据 + 大模型 →

新

智能

在自然

语言处理的

前沿领域，大

语言模型正

以其庞大的

模型规模、海

量数据

的吞

吐能力和卓

越的模型性

能，推动着一

场技术革新

的浪潮。当我

们谈论“大语

言

模型”之大

时，所指的不

仅仅是模型

规模的庞大

，也涵盖了训

练数据规模

的庞大，

以及

由此衍生出

的模型能力

的强大。这些

模型如同探

索未知领域

的巨轮，不仅

在

已有的技

术上不断突

破性能的极

限，更在新能

力的探索中

展现出惊人

的潜力。

截止

2024 年

6 月，国内外

已经见证了

超过百种大

语言模型的

诞生，这些大

语

言模型在

学术界和工

业界均产生

了深远的影

响。图2.1展示了

其中一些具

有重要影

响

力的模型。

2017-2018

萌

芽期

BERT

GPT-1

Transformer

2019

T5

BART

ALBERT

RoBERTa

GPT-2

发展期

2020

mT5

GPT-3

T0

DeBERTa

ELECTRA

2021

WebGPT

FLAN

ERNIE 3

CODEX

GLM

2022 2023-2024

LaMDA

Flan-T5

WeLM

mT0

OPT

InstructGPT

ChatGPT

BARD

ChatGLM

LLaLA

GPT-4

Gemini

Baichuan 2

Claude 3

突破期

图

2.1: 大

语言模型涌

现能力的三

个阶段。

大语

言模型的发

展历程可以

大致划分为

三个阶段。2017 至

2018

年是基础模

型的萌芽期

，以 Transformer 架构的诞

生和 BERT[11]、GPT-1[27]

模型的

问世为标

志

，开启了预训

练语言模型

的新纪元。2019 至

2022 年是大语言

模型的发展

期，通过

GPT-2 1、T5[29] 以及

GPT-3[5] 等模型在参

数规模以及

能力上的大

幅提升，研究

者开

始深入

探索大语言

模型的潜力

。2022 年起则是大

语言模型的

突破期，ChatGPT 2以

及

GPT-4

3等模型的发

布标志着大

语言模型相

关技术的显

著进步。同时

，各大公司

1https://openai.com/index/gpt-2-1-5b-release

2https://openai.com/blog/chatgpt

3https://openai.com/index/gpt-4-research

34

李

佳晖 毛玉仁

宓禹

和研究

机构也纷纷

推出了自己

的模型，例如

百川智能的

百川大模型

[44]，百度的文

心

一言等，推动

了大语言模

型的快速发

展。

本节将深

入剖析大型

语言模型的

发展历程，特

别是在能力

增强和新能

力涌现

方面

的进展。我们

将从模型规

模和数据规

模的增长出

发，探讨这些

因素如何共

同

作用，促进

了模型性能

的飞跃和新

功能的出现

。

2.1.1 大数据 + 大模

型

→ 能力增强

在数字化浪

潮的推动下

，数据如同汇

聚的洪流，而

模型则如同

乘风破浪的

巨

舰。数据规

模的增长为

模型提供了

更丰富的信

息源，意味着

模型可以学

习到更多样

化的语言模

式和深层次

的语义关系

。而模型规模

的不断扩大

，极大地增加

了模型

的表

达能力，使其

能够捕捉到

更加细微的

语言特征和

复杂的语言

结构。在如此

庞

大的模型

参数规模以

及多样化的

训练数据共

同作用下，模

型内在对数

据分布的拟

合能力不断

提升，从而在

复杂多变的

数据环境中

表现出更高

的适应性和

有效性 [7]。

然而

模型规模和

数据规模的

增长并非没

有代价，它们

带来了更高

的计算成本

和存储需求

，这要求我们

在模型设计

时必须在资

源消耗和性

能提升之间

找到一个

恰

当的平衡点

。为了应对这

一挑战，大语

言模型的扩

展法则（Scaling

Laws）应运

而生。这些法

则揭示了模

型的能力随

模型和数据

规模的变化

关系，为大语

言模型的

设

计和优化提

供了宝贵的

指导和参考

。本章节将深

入介绍两种

扩展法则：OpenAI

提

出的 Kaplan-McCandlish

扩展法

则以及 DeepMind 提出

的 Chinchilla

扩展法则

。

1. Kaplan-McCandlish 扩展法则

2020 年

，OpenAI 团队的 Jared

Kaplan 和 Sam McCandlish

等

人 [16] 首次探究

了神经网络

的性能与数

据规模 D

以及

模型规模 N 之

间的函数关

系。他们在不

同规

模的数

据集（从

2200 万到

230 亿个 Token）和不同

规模的模型

下（从

768 到 15 亿

个

参数）进行实

验，并根据实

验结果拟合

出了两个基

本公式：

35

第 2

章

大语言模型

架构

L(D) = 

D

D

c



αD

, αD ∼

−0.095, Dc ∼ 5.4

× 1013 ， (2.1)

L(N) = 

N

N

c



αN

, αN ∼ −0.076,

Nc ∼ 8.8 ×

1013 。 (2.2)

这里的

L(N)

表示在数据

规模固定时

，不同模型规

模下的交叉

熵损失函数

，反

映了模型

规模对拟合

数据能力的

影响。相应地

，L(D) 表示在模型

规模固定时

，不

同数据规

模下的交叉

熵损失函数

，揭示了数据

量对模型学

习的影响。L

的

值衡量了

模

型拟合数据

分布的准确

性，值越小表

明模型对数

据分布的拟

合越精确，其

自身

学习能

力也就越强

大。

实验结果

和相关公式

表明，模型的

性能与模型

以及数据规

模这两个因

素均高

度正

相关。然而，在

模型规模相

同的情况下

，模型的具体

架构对其性

能的影响相

对

较小。因此

，扩大模型规

模和丰富数

据集成为了

提升大型模

型性能的两

个关键策

略

。

此外，OpenAI

在进一

步研究计算

预算的最优

分配时发现

，总计算量 C 与

数据

量

D 和模

型规模 N 的乘

积近似成正

比，即

C ≈ 6ND。在这一

条件下，如果

计算

预算增

加，为了达到

最优模型性

能，数据集的

规模

D 以及模

型规模 N 都应

同步增

加。但

是模型规模

的增长速度

应该略快于

数据规模的

增长速度。具

体而言，两者

的

最优配置

比例应当为

Nopt ∝ C

0.73, Dopt ∝ C

0.27。这意味着，如

果总计算预

算增加

了 10 倍

，模型规模应

扩大约

5.37 倍，而

数据规模应

扩大约 1.86 倍，以

实现模型的

最佳性能。

OpenAI 提

出的这一扩

展法则不仅

定量地揭示

了数据规模

和模型规模

对模型能

力

的重要影响

，还指出了在

模型规模上

的投入应当

略高于数据

规模上的投

入。这

一发现

不仅为理解

语言模型的

内在工作机

制提供了新

的见解，也为

如何高效地

训

练这些模

型提供了宝

贵的指导意

见。

36

李佳晖 毛

玉仁

宓禹

2. Chinchilla 扩

展法则

谷歌

旗下 DeepMind 团队对

“模型规模的

增长速度应

该略高于数

据规模的增

长

速度”这一

观点提出了

不同的看法

。在

2022 年，他们对

更大范围的

模型规模（从

7000 万到 1600

亿个参

数）以及数据

规模（从 50 亿到

5000 亿个

Token）进行了

深

入的实验

研究，并据此

提出了 Chinchilla 扩展

法则

[15]：

L(N, D) =

E +

A

Nα

+

B

Dβ ，

(2.3)

E = 1.69,

A = 406.4, B

= 410.7, α =

0.34, β = 0.28

。 (2.4)

DeepMind 同样探

索了计算预

算的最优分

配问题，最终

得出数据集

规模

D 与模

型

规模 N

的最优

配置为 Nopt ∝ C

0.46, Dopt ∝ C

0.54。这一

结果表明，数

据集量 D 与

模

型规模

N 几乎

同等重要，如

果总计算预

算增加了 10 倍

，那么模型规

模以及数据

规模都应当

扩大约

3.16 倍。谷

歌后续在 2023 年

5

月发布的 PaLM 2 的

技术报告

[2]

中

也再次证实

了这一观点

，进一步强调

了数据规模

在提升模型

性能中的重

要性。

此外，Chinchilla 扩

展法则进一

步提出，理想

的数据集大

小应当是模

型规模的

20 倍

。例如，对于一

个 7B（70 亿参数）的

模型，最理想

的训练数据

集大小应为

140B（1400

亿）个 Token。但先前

很多模型的

预训练数据

量并不够，例

如 OpenAI

的

GPT-3[5] 模型的

最大版本有

1750 亿参数，却只

用了 3000

亿 Token 进行

训练；

同样，微

软的

MT-NLG[35] 模型拥

有 5300 亿参数，而

训练用的

Token 数

量却只有

2700 亿

。因此，DeepMind

推出了

数据规模 20 倍

于模型规模

的 Chinchilla

模型（700

亿参

数，1.4 万亿 Token），最终

在性能上取

得了显著突

破。

DeepMind 提出的 Chinchilla 扩

展法则是对

OpenAI

先前研究的

补充和优化

，强

调了数据

规模在提升

模型性能中

的重要性，指

出模型规模

和数据规模

应该以相同

的比例增加

，开创了大语

言模型发展

的一个新方

向：不再单纯

追求模型规

模的增

加，而

是优化模型

规模与数据

规模的比例

。

37

第 2 章 大语言

模型架构

2.1.2 大

数据 + 大模型

→

能力扩展

如

图2.2所示，模型

训练数据规

模以及参数

数量的不断

提升，不仅带

来了上述

学

习能力的稳

步增强，还为

大模型“解锁

”了一系列新

的能力 4，例如

上下文学习

能力、常识推

理能力、数学

运算能力、代

码生成能力

等。值得注意

的是，这些新

能

力并非通

过在特定下

游任务上通

过训练获得

，而是随着模

型复杂度的

提升凭空自

然涌现 5。这些

能力因此被

称为大语言

模型的涌现

能力（Emergent Abilities）。

1750亿参数

复杂逻辑推

理

多模态理

解

多轮对话

垂域问答

130亿

参数

上下文

学习

代码生

成

情感分析

语言理解

问

答任务

常识

推理

常识推

理

上下文学

习

代码生成

情感分析

语

言理解

问答

任务

......

问答任

务

20亿参数

语

言理解

情感

分析

图 2.2:

大语

言模型能力

随模型规模

涌现，图片由

GPT-4o 生成。

涌现能

力往往具有

突变性和不

可预见性。类

似于非线性

系统中的“相

变”，即

系统在

某个阈值点

发生显著变

化，这些能力

也并没有一

个平滑的、逐

渐积累的过

程，而是在模

型达到一定

规模和复杂

度后，很突然

地显现

[32]。例如

，在 GPT 系

列的演

变中，可以观

察到一些较

为典型的涌

现能力。

上下

文学习：上下

文学习（In-Context Learning）是指

大语言模型

在推理过程

中，能够利用

输入文本的

上下文信息

来执行特定

任务的能力

。具备了上下

文

学习能力

的模型，在很

多任务中无

需额外的训

练，仅通过示

例或提示即

可理

解任务

要求并生成

恰当的输出

。在

GPT 系列中，不

同版本的模

型在上下文

学

习能力上

有显著差异

。早期的 GPT-1

和 GPT-2 在

上下文学习

方面的能力

非常

4https://research.google/blog/pathways-language-model-palm-scaling-to-540-billion-parameters-for￾breakthrough-performance

5https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models

38

李佳晖

毛玉仁 宓禹

有限，通常无

法直接利用

上下文信息

进行准确的

推理和回答

。GPT-3

的 130

亿参数版

本则在上下

文学习方面

取得了显著

进步，能在提

供的上下文

提示下

完成

一些常见任

务。然而，对于

更加复杂或

特定领域的

任务，其性能

仍有限。

具有

1750 亿参数的 GPT-3 最

大版本以及

后续的

GPT-4 模型

展现出强大

的上

下文理

解和学习能

力，可以基于

少量示例完

成各类高度

复杂的任务

。

常识推理：常

识推理（Commonsense

Reasoning）能力

赋予了大语

言模型基于

常识知识和

逻辑进行理

解和推断的

能力。它包括

对日常生活

中普遍接受

的事

实、事件

和行为模式

的理解，并利

用这些知识

来回答问题

、解决问题和

生成

相关内

容。GPT-1 和

GPT-2 在常识

推理方面的

能力非常有

限，常常会出

现错

误的推

断或缺乏详

细的解释。而

GPT-3 的较大版本

能够在大多

数情况下生

成

合理和连

贯的常识性

回答。至于具

有 1750 亿参数的

GPT-3 最大版本以

及后

续的 GPT-4 等

模型，则能够

在处理高度

复杂的常识

推理任务时

展现逻辑性

、

一致性和细

节丰富性。

代

码生成：代码

生成（Code Generation）能力允

许大语言模

型基于自然

语言

描述自

动生成编程

代码。这包括

理解编程语

言的语法和

语义、解析用

户需求、

生成

相应代码，以

及在某些情

况下进行代

码优化和错

误修复。GPT-1

和 GPT-2

仅

能生成非常

简单的代码

片段，但是无

法有效理解

具体的编程

需求。130 亿

参数

的 GPT-3 模型出现

时，已经能很

好地处理常

见的编程任

务和生成结

构化

代码片

段，但在极其

复杂或特定

领域的任务

上仍有限。在

参数量达到

1750

亿

时，模型则

能够处理复

杂编程任务

，多语言代码

生成，代码优

化和错误修

复

等，展示出

高质量的代

码生成和理

解能力。

逻辑

推理：逻辑推

理（Logical

Reasoning）能力使大

语言模型能

够基于给定

信息和规则

进行合乎逻

辑的推断和

结论。这包括

简单的条件

推理、多步逻

辑

推理、以及

在复杂情境

下保持逻辑

一致性。GPT-1 和 GPT-2

作

为早期的生

成

39

第 2

章 大语

言模型架构

预训练模型

，在逻辑推理

方面的能力

非常有限，甚

至对于 130 亿参

数版本的

GPT-3 模

型而言，虽然

能处理一部

分逻辑推理

任务，但在复

杂度和精确

性上

仍存在

一定局限性

。直到 1750

亿参数

版本，GPT-3 才能够

处理复杂的

逻辑推

理任

务，生成详细

和连贯的推

理过程。

......

这些

涌现能力使

得大语言模

型可以在不

进行专项训

练的前提下

完成各类任

务，

但同时也

带来了诸多

挑战，包括模

型的可解释

性、信息安全

与隐私、伦理

和公平性

问

题，以及对计

算资源的巨

大需求等。解

决这些挑战

需要在技术

、法律和社会

层面

进行综

合考量，以确

保大语言模

型的健康发

展和可持续

进步。

2.2 大语言

模型架构概

览

在语言模

型的发展历

程中，Transformer[42] 框架的

问世代表着

一个划时代

的

转折点。其

独特的自注

意力（Self-Attention）机制极

大地提升了

模型对序列

数据的

处理

能力，在捕捉

长距离依赖

关系方面表

现尤为出色

。此外，Transformer 框架对

并行计算的

支持极大地

加速了模型

的训练过程

。当前，绝大多

数大语言模

型均以

Transformer

框架

为核心，并进

一步演化出

了三种经典

架构，分别是

Encoder-only 架

构，Decoder-only 架构以

及

Encoder-Decoder 架构。这三

种架构在设

计和功能上

各

有不同。本

节将简要介

绍这三种架

构的设计理

念与预训练

方式，并分析

它们之间

的

区别以及各

自的演变趋

势。

2.2.1 主流模型

架构的类别

本小节将从

设计理念、训

练方式等角

度对 Encoder-only 架构，Decoder-only

架

构以及 Encoder-Decoder 架构

分别进行简

要介绍。

40

李佳

晖 毛玉仁 宓

禹

1.

Encoder-only 架构

Encoder-only 架构

仅选取了

Transformer 中

的编码器（Encoder）部

分，用于接

收

输入文本并

生成与上下

文相关的特

征。具体来说

，Encoder-only 架构包含三

个部

分，分别

是输入编码

部分，特征编

码部分以及

任务处理部

分，具体的模

型结构如

图

2.3所示。其中输

入编码部分

包含分词、向

量化以及添

加位置编码

三个过程。而

特征编码部

分则是由多

个相同的编

码模块（Encoder Block）堆叠

而成，其中每

个编

码模块

包含自注意

力模块（Self-Attention）和全

连接前馈模

块。任务处理

模块是针

对

任务需求专

门设计的模

块，其可以由

用户针对任

务需求自行

设计。Encoder-only

架构模

型的预训练

阶段和推理

阶段在输入

编码和特征

编码部分是

一致的，而任

务

处理部分

则需根据任

务的不同特

性来进行定

制化的设计

。

输

入

文

本

分

词

器

词

嵌

入

矩

阵

输

出

位

置

编码

输入

编码

编

码

模

块

M

 ...

编

码

模

块

1

编

码

模

块

2

特

征编码 任务

处理

输

出

头

可

选

图

2.3: Encoder-only 架构

。

在输入编码

部分，原始输

入文本会被

分词器（Tokenizer）拆解

为

Token 序列，

随后

通过词表和

词嵌入（Embedding）矩阵

映射为向量

序列，确保文

本信息得以

数

字化表达

。具体的过程

和细节将在

3.1

章节中被具

体介绍。接着

为了保留文

本中单

词的

顺序信息，每

个向量序列

会被赋予位

置编码（Positional Encoding）。在特

征编

码部分

，先前得到的

向量序列会

依次通过一

系列编码模

块，这些模块

通过自注意

力

机制和前

馈网络进一

步提取和深

化文本特征

。任务处理部

分在预训练

阶段和下游

任务适配阶

段一般有所

差别。在预训

练阶段，模型

通常使用全

连接层作为

输出头，

41

第 2

章

大语言模型

架构

用于完

成掩码预测

等任务。而在

下游任务适

配阶段，输出

头会根据具

体任务需求

进行定制。例

如，对于情感

分析或主题

分类等判别

任务，只需要

添加一个分

类器便

可直

接输出判别

结果。但对于

文本摘要生

成等生成任

务，则需要添

加一个全连

接

层，逐个预

测后续的

Token。但

以这种形式

来完成生成

任务存在着

诸多的限制

，例

如在每次

生成新的 Token 时

，都需要重新

计算整个输

入序列的表

示，这增加了

计算

成本，也

可能导致生

成的文本缺

乏连贯性。本

章将在2.3 节中

对 Encoder-only 架构

进行

更具体的介

绍。

2. Encoder-Decoder 架构

为了

弥补 Encoder-only 架构在

文本生成任

务上的短板

，Encoder-Decoder 架构

在其基

础上引入了

一个解码器

（Decoder），并采用交叉

注意力机制

来实现编码

器与

解码器

之间的有效

交互。

输

入

文

本

分

词

器

位

置

编码

 ...

编

码

模

块

1

编

码

模

块

2

特征编码

分

词

器

采

样

输

出

位置

编

码

输出编码

...

特征解码 输

出生成

线

性

层

＆

S

o

f

t

m

a

x

层

开

始

标

记

+

输

出

文

本

编

码

模

块

M

输

入编码

词

嵌

入

矩

阵

词

嵌

入

矩

阵

解

码

模

块

N

解

码

模

块

2

解

码

模

块

1

图 2.4: Encoder-Decoder 架构。其中

分词器和输

出文本只在

训练阶段存

在，而实现

“自

回归”的红色

虚线只在推

理阶段存在

。

42

李佳晖 毛玉

仁

宓禹

具体

来说，解码器

包含了输出

编码、特征解

码以及输出

生成三个部

分。其中

输出

编码与编码

器中的输入

编码结构相

同，包含分词

、向量化以及

添加位置编

码

三个过程

，将原始输入

文本转换化

为带有位置

信息的向量

序列。此外，特

征解码

部分

与特征编码

部分在网络

结构上也高

度相似，包括

掩码自注意

力（Masked Self￾Attention）模块，交叉

注意力模块

和全连接前

馈模块。其中

掩码自注意

力模块确保

模型只关注

上文，不会“预

见”未来的信

息，从而可以

在无“下文泄

露”的条件下

，

进行“自回归

”的训练和推

理。而交叉注

意力模块则

负责处理从

编码模块向

解码模

块传

递相关信息

。输出生成部

分则由一个

线性层以及

一个

Softmax 层组成

，负责将

特征

解码后的向

量转换为词

表上的概率

分布，并从这

个分布中采

样得到最合

适的

Token

作为输

出。

图2.4展示了

Encoder-Decoder 架构的具体

工作流程。在

训练阶段，样

本中同时

包

含了输入和

真实（Ground

Truth）输出文

本。其中输入

文本首先被

输入编码部

分

转化为向

量序列，接着

在特征编码

模块中被多

个堆叠起来

的编码模块

进一步处理

，

从而被转化

为上下文表

示。而输出文

本之前会被

添加特殊的

开始标记 [START]，然

后在输出编

码部分被分

词、词嵌入和

位置编码处

理后，并行输

入到特征解

码模块

中。接

着解码模块

使用 Teacher Forcing 技术，在

每轮预测时

，使用真实输

出文本中

的

已知部分作

为输入，并结

合从最后一

个编码块得

到的上下文

信息，来预测

下一个

Token，计算

预测的 Token 和真

实

Token 之间的损

失，通过反向

传播更新模

型参数。

在推

理阶段，由于

缺少了真实

的输出文本

，所以输出序

列原始状态

只有开始

标

记

[START]，也不再需

要分词器。模

型需要通过

自回归的方

式，在每轮采

样生成

Token 后，会

将其拼接到

输出序列中

，用于下一轮

预测。这个过

程循环进行

，直到

生成特

定的结束标

记

[end] 或达到模

型设定的最

大输出长度

。在这一过程

中，由

于每轮

的输入依赖

于上一轮的

采样结果，因

此只能一步

步地串行输

出。在2.4 节中

会

针对 Encoder-Decoder 架构进

行更具体的

介绍。

43

第 2 章 大

语言模型架

构

3. Decoder-only 架构

为了

有效缩减模

型的规模以

及降低整体

的计算复杂

度，Decoder-only

架构摒弃

了 Encoder-Decoder 架构中的

编码器部分

以及与编码

器交互的交

叉注意力模

块。在

这种架

构下，模型仅

使用解码器

来构建语言

模型。这种架

构利用“自回

归”机制，

在给

定上文的情

况下，生成流

畅且连贯的

下文。

输

入

文

本

分

词

器

词

嵌

入

矩

阵

采

样

输

出

位置

编码

输入编

码

解

码

模

块

N

...

解

码

模

块

1

解

码

模

块

2

特征

解码 输出生

成

线

性

层

＆

S

o

f

t

m

a

x

层

图

2.5: Decoder-only 架构。

Decoder-only

架构

同样包含了

三个部分，分

别是输入编

码部分、特征

解码部

分以

及输出生成

部分，其具体

的模型结构

如图2.5所示。Decoder-only 架

构的核心

特

点在于省略

了每个编码

模块中的交

叉注意力子

模块，这也是

其与传统

Encoder￾Decoder 架

构中解码器

部分的主要

区别。在2.5 节中

将会对 Decoder-only

架构

进行

更具体

的介绍。

2.2.2 模型

架构的功能

对比

上述的

Encoder-only、Encoder-Decoder 和 Decoder-only 这三种模

型架构虽然

都

源自于 Transformer 框

架，但他们在

注意力矩阵

上有着显著

区别，这也造

就了他们

在

功能以及最

终适用任务

上的不同。接

下来将针对

注意力矩阵

以及适用任

务两个

方面

对这三种架

构的主要区

别进行分析

。

44

李佳晖 毛玉

仁

宓禹

1. 注意

力矩阵

注意

力矩阵（Attention

Matrix）是 Transformer 中

的核心组件

，用于计算输

入

序列中各

个

Token 之间的依

赖关系。通过

注意力机制

，模型可以在

处理当前 Token

时

，灵活地关注

序列中其他

Token

所携带的信

息，决定了在

这一过程中

哪些 Token

能够相

互影响。如图

2.6所示，三种架

构在注意力

矩阵上有着

显著差异。

Encoder

- Decoder

输

入

Decoder-only

输入

Encoder-only

输入

图 2.6: 三种架构

的注意力矩

阵。

Encoder-only

架构中的

注意力矩阵

来自于自注

意力模块，用

于捕捉输入

序列

中各个

Token 之间的关系

。Encoder-only 架构的注意

力矩阵呈现

出“完全”的注

意

力，即对于

每个 Token 的理解

都依赖于整

个输入序列

中的所有 Token。例

如，在将

输入

Token xi 转换为上下

文向量 yi

的过

程中，模型能

够综合利用

从 x1 ∼ xn

的所

有输

入信息，这就

是所谓的双

向注意力机

制。在这种双

向注意力机

制的作用下

，模

型能够同

时利用前后

文信息，深入

理解复杂的

语义联系和

上下文依赖

。

Encoder-Decoder

架构中的注

意力矩阵较

为复杂，它结

合了编码器

的自注意

力

、解码器的掩

码自注意力

以及交叉注

意力三种机

制。编码器的

自注意力矩

阵与

Encoder-only 架构类

似，用于生成

输入序列的

全面上下文

表示，呈现“完

全”的注

意力

。而解码器的

掩码自注意

力矩阵则呈

现出“下三角

”的注意力，确

保在生成当

前 Token 时，模型只

关注之前生

成的 Token。此外，交

叉注意力机

制允许解码

器始

45

输

出

第

2

章 大语言模

型架构

终能

够动态地参

考编码器生

成的完整上

下文表示，确

保输出与输

入序列高度

相关

且连贯

。例如，在编码

器将输入

xi 转

化为上下文

向量时，可以

利用从 x1 ∼

xn 的

所

有输入信息

；当解码器在

生成 Token

yi 的时候

，可以参考由

x1 ∼ xn

转化得到的

上下文向量

以及先前生

成的 Token 序列 y1

∼ yi−1 的

相关信息。

Decoder-only

架

构中的注意

力矩阵来自

于掩码自注

意力模块，其

特点是呈现

出“下三角”的

注意力模式

。这意味着在

预测当前 Token 时

，模型只能依

赖于已经

生

成的历史

Token 信

息，体现了单

向注意力机

制。例如，在生

成 Token yi

的时候，

模

型只能考虑

先前 y1 ∼

yi−1 的信息

，这样的设计

确保了生成

过程的顺序

性和文本

的

连贯性。

2.

适用

任务

由于各

自独特的模

型设计以及

注意力矩阵

上的差异，在

同等参数规

模下，这

三种

架构的模型

在适用任务

上也都各有

倾向。

Encoder-only

架构中

的双向注意

力机制允许

模型在预测

每个 Token 时都充

分

考虑序列

中的前后文

信息，捕捉丰

富的语义和

依赖关系。因

此，Encoder-only

架构

的模

型特别适合

于自然语言

理解（Natural Language Understanding,

NLU）任务，如

情感分析或

文本分类等

判别任务。然

而，由于缺少

解码器组件

，Encoder-only 架构

的模型

无法直接生

成所需目标

序列，因此在

自然语言生

成任务（Natural Language

Generation, NLG）上可

能表现不如

专门设计的

生成模型。

Encoder-Decode 架

构在

Encoder-only 架构的

基础上添加

了解码器，使

模型能

够基

于编码器输

出的上下文

表示逐步生

成输出序列

。这种编码器

和解码器的

结合，

使得模

型可以有效

地处理复杂

的输入条件

，并生成相关

且连贯的高

质量内容。因

此，Encoder-Decoder

架构的模

型非常适合

于处理各种

复杂的有条

件生成任务

，例

如机器翻

译、文本摘要

和问答系统

等需要同时

理解输入并

生成相应输

出的场景。但

新添加解码

器也同样带

来了模型规

模以及计算

量庞大的问

题。

46

李佳晖

毛

玉仁 宓禹

Decoder-only 架

构进一步删

除了

Encoder-Decoder 架构中

的编码器部

分，从而

降低

了模型本身

的计算复杂

度。这一架构

的模型使用

掩码（Mask）操作确

保在每

个时

间步生成当

前

Token 时只能访

问先前的 Token，并

通过自回归

生成机制，从

起

始

Token 开始逐

步生成文本

。大规模预训

练数据的加

持使得 Decoder-only 架构

的

模型能够

生成高质量

、连贯的文本

，在自动故事

生成、新闻文

章生成此类

不依赖

于特

定的输入文

本的无条件

文本生成任

务中表现出

色。然而，在模

型规模有限

的

情况下（例

如 GPT-1

以及 GPT-2 等模

型），由于缺乏

编码器提供

的双向上下

文信

息，Decoder-only

架构

的模型在理

解复杂输入

数据时存在

一定局限性

，表现可能不

如 Encoder-Decoder 架构。

在不

同的历史阶

段，三种模型

架构分别展

现了自身的

优势。随着模

型规模以

及

数据规模的

显著增长，Decoder-only 架

构的模型逐

渐占据上风

，以其强大的

任务

泛化性

能展现出成

为“大一统”的

架构的潜力

。当前，以 GPT-3、GPT-4

等为

代表

的大型

Decoder-only 语言模型，已

经发展出了

与人类媲美

甚至超越人

类的记忆、推

理以及执行

复杂任务的

能力。

2.2.3

模型架

构的历史演

变

随着时间

的流逝，我们

见证了上述

三种架构的

演变和流行

趋势的更替

。在大语

言模

型的早期发

展阶段（2018 年左

右），BERT

和 GPT-1 分别作

为 Encoder-only

和

Decoder-only 架构的

代表几乎同

时出现。但受

限于当时的

模型参数规

模，BERT 强大

的上

下文理解能

力比 GPT-1 初阶的

文本生成能

力更为亮眼

。使得 Encoder-only

架构

得

到了更为广

泛的探索和

应用，而 Decoder-only 架构

吸引得关注

则相对关注

较少。

然而，随

着用户对机

器翻译等生

成任务需求

的增加，缺乏

解码组件的

Encoder-only

架构逐渐无

法满足直接

生成的需求

，因而被逐渐

“冷落”。同时，2019 年

末诞生了

一

众

Encoder-Decoder 架构的模

型，由于其能

够有效处理

序列到序列

（Sequence to

47

第 2 章 大语言

模型架构

Sequence）的

生成任务，逐

渐成为主流

。到了 2019 年末，随

着算力资源

的急速发

展

，研究者开始

寻求不断提

升参数量来

激发更强的

生成能力。得

益于其参数

易扩展

性，Decoder-only 架

构下的模型

参数量急剧

扩充，文本生

成能力大幅

提升。自 2021

年之

后，在

GPT-3 等模型

的推动下，Decoder-only 架

构开始占据

主流，甚至逐

渐主

导了大

语言模型的

发展。尽管如

此，Encoder-Decoder

架构也仍

然活跃在开

源社区

中，不

断被探索和

改进。至于 Encoder-only 架

构，在

BERT 带来最

初的爆炸性

增长

之后，其

关注度有所

下降，但也仍

然在部分判

别任务中发

挥着重要作

用，例如文

本

分类、情感分

析、命名实体

识别等。总的

来讲，大语言

模型的主流

架构经历了

从

Encoder-only 到 Encoder-Decoder，再到 Decoder-only

的

发展过程，而

引发这种更

迭

趋势的原

因可能是模

型本身生成

能力以及计

算效率上的

差异。

Encoder-only 架构专

注于对输入

数据进行深

入的表示和

理解，这使得

它在理

解型

任务中表现

出色。但当涉

及到文本生

成任务时，其

生成能力则

不尽如人意

。由

于缺少专

门用于生成

输出的组件

，它需要通过

迭代进行掩

码预测来生

成文本，这

需

要模型进行

多次前向传

播以逐步填

充文本中的

掩码部分，从

而导致计算

资源的

大量

消耗。在当今

对人工智能

内容生成（AIGC）需

求不断增长

的背景下，这

种架

构的应

用受到了一

定的限制。而

Encoder-Decoder 架构使用编

码器来处理

输入，并

使用

解码器来生

成输出，能够

处理复杂的

序列到序列

任务。但相较

于后续崛起

的

Decoder-only

架构，其模

型参数规模

更为庞大，随

之带来的是

显著增加的

计算复杂

度

。特别是在处

理长序列数

据时，编码器

和解码器均

面临沉重的

计算负担，这

在一

定程度

上限制了模

型的应用效

率。相比之下

，Decoder-only 架构通过仅

使用解码器

来优化计算

流程，显著简

化了模型结

构。它采用自

回归生成策

略，逐步构建

输出文

本，每

一步的生成

过程仅需考

虑已经生成

的文本部分

，而不是整个

输入序列。这

样

的设计减

少了模型的

参数量和计

算需求，提高

了模型本身

的可扩展性

，因此非常

适

合大量文本

生成的场景

，在 AIGC

的应用场

景下得到了

广泛的应用

。

48

李佳晖 毛玉

仁

宓禹

这三

种架构的发

展不仅推动

了自然语言

处理技术的

进步，也为各

行各业带来

了深远的影

响，从提升搜

索引擎的准

确性到开发

更加智能的

对话系统。随

着研究

的深

入，未来的语

言模型有望

在更具优势

的架构下变

得更加强大

和灵活，并在

更

多领域发

挥作用。后续

章节将进一

步介绍这三

种架构及其

对应的几种

经典模型。

2.3 基

于 Encoder-only 架构的大

语言模型

Encoder-only 架

构凭借着其

独特的双向

编码模型在

自然语言处

理任务中表

现出

色，尤其

是在各类需

要深入理解

输入文本的

任务中。本章

将对双向编

码模型以及

几种较为典

型的 Encoder-only

架构模

型进行介绍

。

2.3.1 Encoder-only 架构

Encoder-only 架构的

核心在于能

够覆盖输入

所有内容的

双向编码模

型（Bidirec￾tional Encoder Model）。在处理输

入序列时，双

向编码模型

融合了从左

往右的正向

注意力以及

从右往左的

反向注意力

，能够充分捕

捉每个

Token 的上

下文信息，因

此也被称为

具有全面的

注意力机制

。得益于其上

下文感知能

力和动态表

示的优势，

双

向编码器显

著提升了自

然语言处理

任务的性能

。

不同于先前

常用的

Word2Vec 和 GloVe 此

类，为每个词

提供一个固

定向量表示

的静态编码

方式，双向编

码器为每个

词生成动态

的上下文嵌

入（Contextual

Embed￾ding），这种嵌入

依赖于输入

序列的具体

上下文，使得

模型能够更

加精准地理

解词

与词之

间的依赖性

和语义信息

，有效处理词

语的多义性

问题。这种动

态表示使得

双

向编码器

在句子级别

的任务上表

现出色，显著

超过了静态

词嵌入方法

的性能 [20]。

Encoder-only 架构

基于双向编

码模型，选用

了 Transformer 架构中的

编码器部

分

。虽然 Encoder-only 模型不

直接生成文

本，但其生成

的上下文嵌

入对于深入

理

49

第 2 章 大语

言模型架构

解输入文本

的结构和含

义至关重要

。这些模型在

需要深度理

解和复杂推

理的自然

语

言处理任务

中展现出卓

越的能力，成

为了自然语

言处理领域

的宝贵工具

。当前，

BERT[11] 及其变

体，如 RoBERTa[23]、ALBERT[17]

等，都是

基于 Encoder-only 架

构的

主流大语言

模型。接下来

将对这些模

型进行介绍

。

2.3.2 BERT 语言模型

BERT（Bidirectional

Encoder Representations from Transformers）是

一种基于

Encoder-only 架

构的预训练

语言模型，由

Google AI 团队于

2018 年 10 月

提出。作为

早

期 Encoder-only 架构的代

表，BERT 在自然语

言处理领域

带来了突破

性的改进。

其

核心创新在

于通过双向

编码模型深

入挖掘文本

的上下文信

息，从而为各

种下游

任务

提供优秀的

上下文嵌入

。本节将对 BERT 模

型的结构、预

训练方式以

及下游

任务

进行介绍。

1. BERT 模

型结构

BERT 模型

的结构与 Transformer 中

的编码器几

乎一致，都是

由多个编码

模块

堆叠而

成，每个编码

模块包含一

个多头自注

意力模块和

一个全连接

前馈模块。根

据

参数量的

不同，BERT 模型共

有 BERT-Base

和 BERT-Large 两个版

本。其中 BERT￾Base

由 12 个

编码模块堆

叠而成，隐藏

层维度为 768，自

注意力头的

数量为

12，总

参

数数量为 1.1 亿

；BERT-Large

由 24 个编码模

块堆叠而成

，隐藏层维度

为 1024，

自注意力

头的数量为

16，总参数数量

约为 3.4 亿。

2.

BERT 预训

练方式

BERT 使用

小说数据集

BookCorpus[46]（包含约

8 亿个

Token）和英语维基

百

科数据集

6（包含约 25

亿个

Token）进行预训练

，总计约 33 亿个

Token，总数据量达

到了 15GB

左右。在

预训练任务

上，BERT 开创性地

提出了掩码

语言建模（Masked

6https://dumps.wikimedia.org/

50

李

佳晖 毛玉仁

宓禹

Language Model,

MLM）和下文

预测（Next Sentence Prediction, NSP）两种任

务来学

习生

成上下文嵌

入。其完整的

预训练流程

如图2.7所示。

水

豚性格温顺

. 且没有攻击

性. 因此能与

大多数动物

和谐相处.

它

们的食物以

草类和水生

植物为主. 辅

以树叶和水

果蔬菜等 ...

原

始文本

水豚

性格温顺. 且

无攻击性. 且

没有攻击性

. 辅以水果蔬

菜等.

构造样

本序列 构造

样本序列

[CLS] 水

豚

性 格 温 顺

.

[SEP] 且 无 攻

击 性

. [SEP]

分词并处理

[CLS]

且 无 攻 击

性

. [SEP] 辅 以

果 蔬 等

. [SEP]

分词并处理

这两个是连

续的句子。 这

两个不是连

续的句子。

NSP任

务

[CLS]

水 豚 性 格

[MASK]

. [SEP] 且 无

[MASK] 击 性 .

[SEP] [CLS] 且

[MASK] 攻

击 性 . [SEP]

辅 以

[MASK] 蔬 等

. [SEP]

MLM任务

被

遮挡的内容

是：温顺，攻

被

遮挡的内容

是：无，果

添加

掩码 添加掩

码

图

2.7: BERT 预训练

任务。

具体而

言，BERT

先基于给

定的原始文

本构造多个

样本序列，每

个样本序列

由

原始文本

中的两个句

子组成，这两

个句子有 50% 的

概率是来自

原文的连续

句子，

另外 50% 的

概率是随机

挑选的两个

句子。随后，对

构造出来的

样本序列进

行分词，

并在

序列的开头

添加特殊标

签

[CLS]，在每个句

子的结尾添

加特殊标签

[SEP]。其

中 [CLS] 标签用

于聚合整个

序列的信息

，而

[SEP] 标签则明

确句子之间

的界限。

接着

，BERT 利用处理后

的序列进行

下文预测任

务，利用模型

判断样本序

列中

的两个

句子是否为

连续的。这一

任务训练 BERT 识

别和理解句

子之间的关

系，捕捉

句子

层面的语义

特征。这对于

理解文本的

逻辑流、句子

之间的关联

性有很大帮

助，

特别是在

问答和自然

语言推理等

需要理解文

档层次结构

的自然语言

处理 (NLP) 任

务中

。

最后，BERT 随机选

择样本序列

中大约 15% 的

Token 进

行遮掩，将其

替换为特

殊

标签 [MASK]

或者随

机单词。模型

需要预测这

些被替换的

Token 的原始内容

。这

51

第

2 章 大语

言模型架构

个过程类似

于完型填空

，要求模型根

据周围的上

下文信息来

推断缺失的

Token。预

测过程使

用的交叉熵

损失函数驱

动了

BERT 模型中

参数的优化

，使其能够学

习到

文本的

双向上下文

表示。值得注

意的是，在 MLM

任

务的训练过

程中，BERT 仅针

对

那些被随机

替换的 Token

进行

学习，即只计

算这些 Token 的预

测损失来更

新模型

参数

。

通过这两种

预训练任务

的结合，使 BERT 在

理解语言的

深度和广度

上都有显

著

提升。BERT

不仅能

够捕捉到 Token 的

细粒度特征

，还能够把握

长距离的依

赖关

系和句

子间的复杂

联系，为各种

下游任务提

供了坚实的

语言理解基

础。

3. BERT 下游任务

BERT 可以应用于

各种自然语

言处理任务

，包括但不限

于文本分类

（如情感分

析

）、问答系统、文

本匹配（如自

然语言推断

）和语义相似

度计算等。然

而，由于

BERT 的输

出是输入中

所有 Token

的向量

表示，因此总

长度不固定

，无法直接应

用

于各类下

游任务。为了

解决这一问

题，BERT 设计了 [CLS]

标

签来提取整

个输入

序列

的聚合表示

。[CLS] 标签是专门

为分类和汇

总任务设计

的特殊标记

。其全称是

“Classification

Token”，即

分类标记。通

过注意力机

制，[CLS] 标签汇总

整个输入序

列的信息，生

成一个固定

长度的向量

表示，从而实

现对所有 Token 序

列信息的概

括，便于处理

各种下游任

务。

在文本分

类任务中，可

以将输出中

[CLS] 标签对应的

向量提取出

来，传递给

一

个全连接层

，从而用于分

类，例如判断

整个句子的

情绪是积极

、消极或是中

立的。

在问答

系统任务中

，需要输入问

题以及一段

相关的文本

，即“[CLS]

问题 [SEP] 文

本

[SEP]”。最终同样提

取出

[CLS] 标签的

对应向量，并

传递给两个

全连接层，用

于判断答案

是否存在于

相关文本中

。如果存在，这

两个全连接

层分别用于

输出答

案的

起始和结束

位置。通过这

种方式，BERT 能够

从提供的段

落中准确提

取出问题

的

答案。在语义

相似度任务

中，需要计算

两段或者多

段文本之间

的语义相似

度。在

52

李佳晖

毛玉仁 宓禹

这一任务中

，可以通过构

造“[CLS]

文本 1[SEP] 文本

2[SEP]”的方式，结合

一个

线性层

来直接输出

两个文本之

间的相似度

；也可以不添

加额外的组

件，直接提取

[CLS]

标签对应的

向量，再利用

额外的相似

度度量方法

（例如余弦相

似度）来计算

多段文本之

间的相似度

。

BERT 通过双向编

码以及特定

的预训练任

务，显著提升

了自然语言

处理任务的

性能。其在多

种任务中的

应用都展示

了强大的泛

化能力和实

用性，不仅为

学术研

究提

供了新的基

准，还在实际

应用中得到

广泛采用，极

大推动了自

然语言处理

技

术的发展

。

2.3.3 BERT 衍生语言模

型

BERT 的突破性

成功还催生

了一系列相

关衍生模型

，这些模型继

承了 BERT 双

向编

码的核心特

性，并在其基

础上进行了

改进和优化

，以提高模型

性能或者模

型

效率，在特

定任务和应

用场景中展

现出了卓越

的性能。较为

代表性的衍

生模型为

RoBERTa[23]、ALBERT[17] 以

及

ELECTRA[9] 等，接下来

将对这三种

模型分别展

开介绍。

1. RoBERTa

语言

模型

RoBERTa（Robustly Optimized BERT

Pretraining Approach）由 Facebook AI（现

更

名 Meta）研究院于

2019 年 7

月提出，旨

在解决 BERT 在训

练程度上不

充分这一

问

题，以提升预

训练语言模

型的性能。RoBERTa

在

BERT 的基础上采

用了更大的

数据集（包括

更多的英文

书籍、维基百

科和其他网

页数据）、更长

的训练时间

（包

括更大的

批次大小和

更多的训练

步数）以及更

细致的超参

数调整（包括

学习率、训

练

步数等的设

置）来优化预

训练的过程

，从而提高模

型在各种自

然语言处理

任务

上的性

能和鲁棒性

。接下来将对

RoBERTa 模型的结构

、预训练方式

以及下游任

务

进行介绍

。

53

第 2 章 大语言

模型架构

(1) RoBERTa 模

型结构

RoBERTa

在结

构上与 BERT 基本

一致，基于多

层堆叠的编

码模块，每个

编码

模块包

含多头自注

意力模块和

全连接前馈

模块。RoBERTa

同样有

两个版本，分

别

是 RoBERTa-Base 和

RoBERTa-Large。其中

RoBERTa-Base 与 BERT-Base 对标，由

12 个

编码模块堆

叠而成，其中

隐藏层维度

为 768，自注意力

头的数量为

12，总参数

数量

约为

1.2 亿；RoBERTa-Large 则与

BERT-Large 对标，由

24 个编

码模块堆叠

而成，其中隐

藏层维度为

1024，自注意力头

的数量为 16，总

参数数量约

为 3.5

亿。

(2) RoBERTa 预训练

方式

在预训

练语料库的

选择上，RoBERTa 在 BERT 原

有的小说数

据集

BookCor￾pus[46]（包含约

8 亿个 Token）以及英

语维基百科

数据集 7（包含

约

25 亿个 Token）

的基

础上，添加了

新闻数据集

CC-News

8（包含约 76GB 的新

闻文章）、网页

开放数

据集

OpenWebText

9（包含约 38GB 的网

页文本内容

）以及故事数

据集 Stories[41]

（包含约

31GB 的故事文本

），总数据量达

到约 160GB。

至于具

体的预训练

任务，RoBERTa

移除了

BERT 中的下文预

测任务，并将

BERT 原生的静态

掩码语言建

模任务更改

为动态掩码

语言建模。具

体而言，BERT

在数

据预处理期

间对句子进

行掩码，随后

在每个训练

epoch

中，掩码位置

不再变

化。而

RoBERTa 则将训练数

据复制成 10

个

副本，分别进

行掩码。在同

样训练 40

个 epoch

的

前提下，BERT 在其

静态掩码后

的文本上训

练了 40 次，而

RoBERTa 将

10 个不同掩码

后的副本分

别训练了 4

次

，从而增加模

型训练的多

样性，有助于

模

型学习到

更丰富的上

下文信息。

这

些改进使得

RoBERTa 在理解上下

文和处理长

文本方面表

现出色，尤其

是在

捕捉细

微的语义差

异和上下文

依赖性方面

。

7https://dumps.wikimedia.org

8http://web.archive.org/save/http://commoncrawl.org/2016/10/newsdataset-available

9http://Skylion007.github.io/OpenWebTextCorpus

54

李佳晖 毛玉

仁 宓禹

2. ALBERT 语言

模型

ALBERT（A

Lite BERT）是由 Google Research

团

队于 2019 年 9

月提

出的轻量

级

BERT 模型，旨在通

过参数共享

和嵌入分解

技术来减少

模型的参数

量和内存占

用，从而提高

训练和推理

效率。BERT-Base 模型有

着

1.1 亿个参数

，而 BERT-Large

更是有着

3.4

亿个参数，这

使得 BERT 不仅难

以训练，推理

时间也较长

。ALBERT 在

设计过程

通过参数因

子分解技术

和跨层参数

共享技术显

著减少了参

数的数量。接

下来将对 ALBERT 模

型的结构、预

训练方式以

及下游任务

进行介绍。

(1)

ALBERT 模

型结构

ALBERT 的结

构与

BERT 以及 RoBERTa 都

类似，由多层

堆叠的编码

模块组成。

但

是 ALBERT 通过参数

因子分解以

及跨层参数

共享，在相同

的模型架构

下，显著

减少

了模型的参

数量。下面将

参数因子分

解和跨层参

数共享分别

展开介绍。

参

数因子分解

在 BERT 中，Embedding 层的输

出向量维度

E

与隐藏层的

向量维度 H 是

一

致的，这意

味着

Embedding 层的输

出直接用作

后续编码模

块的输入。具

体来说，

BERT-Base 模型

对应的词表

大小

V 为 3,0000 左右

，并且其隐藏

层的向量维

度

H 设

置为 768。因

此，BERT

的 Embedding 层需要

的参数数量

是 V

× H，大约为 2,304

万

。

相比之下，ALBERT 将

Embedding 层的矩阵先

进行分解，将

词表对应的

独热

编码向

量通过一个

低维的投影

层下投影至

维度

E，再将其

上投影回隐

藏状态的维

度 H。具体来说

，ALBERT 选择了一个

较小的 Embedding

层维

度，例如 128，并将

参数数量拆

解为 V ×

E + E ×

H。按照这

个设计，ALBERT 的 Embedding 层

大约

需要 394 万

个参数，大约

是 BERT

参数数量

的六分之一

。对于具有更

大隐藏层向

量维度 H 的 Large

版

本，ALBERT 节省参数

空间的优势

更加明显，能

够将参数量

压缩至 BERT 的八

分之一左右

。

55

第 2 章

大语言

模型架构

跨

层参数共享

以经典的 BERT-Base 模

型为例，模型

中共有

12 层相

同架构的编

码模块，所有

Transformer 块的参数都

是独立训练

的。ALBERT 为了降低

模型的参数

量，提出了

跨

层参数共享

机制，只学习

第一层编码

模块的参数

，并将其直接

共享给其他

所有

层。该机

制在一定程

度上牺牲了

模型性能，但

显著提升了

参数存储空

间的压缩比

，

从而实现了

更高效的资

源利用。

基于

参数因子分

解和跨层参

数共享，ALBERT

共提

出了四个版

本的模型，分

别是 ALBERT-Base、ALBERT-Large、ALBERT-XLarge 以及 ALBERT-XXLarge。其

中

ALBERT-Base 与 BERT-Base 对标，由

12

个编码模块

堆叠而成，中

间嵌入分解

维度为 128，隐藏

层维度为 768，自

注意力头的

数量为 12，总参

数数量约为

0.12

亿；ALBERT Large 与 BERT-Large

对标，由

24 个编码模块

堆叠而成，中

间嵌入

分解

维度为 128，隐藏

层维度为

1024，自

注意力头的

数量为 16，总参

数数量约为

0.18 亿；ALBERT X-Large

由 12 个编码

模块堆叠而

成，中间嵌入

分解维度为

128，

隐藏层维度

为

2048，自注意力

头的数量为

16，总参数数量

约为 0.6 亿；ALBERT

XX-Large

由 12 个

编码模块堆

叠而成，中间

嵌入分解维

度为 128，隐藏层

维度为

4096，自注

意力头的数

量为 64，总参数

数量约为 2.2 亿

。

(2) ALBERT 预训练方式

ALBERT 使用与

BERT 完全

一致的数据

集来进行预

训练，即小说

数据集 Book￾Corpus[46]（包含

约 8

亿个 Token）以及

英语维基百

科数据集 10（包

含约 25

亿个

Token），总

计 33 亿个

Token，约 15GB 数

据量。另外，在

预训练任务

的选择上，

ALBERT

保

留了 BERT 中的掩

码语言建模

任务，并将下

文预测任务

替换为句序

预

测（Sentence

Order Prediction, SOP），如图2.8所

示。具体而言

，ALBERT 从文本中

选

择连续的两

个句子，将这

两个句子直

接拼接起来

，或是先将这

两个句子的

顺序

10https://dumps.wikimedia.org

56

李佳晖

毛玉仁

宓禹

[CLS] 水 豚 性

格 温

顺 . [SEP]

且 无 攻 击

性

. [SEP]

这两个句

子是正序的

。

[CLS]

且 无 攻 击

性

. [SEP]水 豚 性

格 温

顺 . [SEP]

这两个句

子是反序的

。

图 2.8: ALBERT

句序预测

任务。

翻转后

再进行拼接

，并将拼接后

的内容作为

输入样本，而

模型需要预

测该样本中

的两个句子

是正序还是

反序。

与 BERT

相比

，ALBERT 通过创新的

参数共享和

参数因子分

解技术，在较

好

地保持原

有性能的同

时显著减少

了模型的参

数数量，这使

得它在资源

受限的环境

中更加实用

，处理大规模

数据集和复

杂任务时更

高效，并降低

了模型部署

和维护

的成

本。

3. ELECTRA 语言模型

ELECTRA（Efficiently Learning

an Encoder that Classifies

Token Replacements Ac￾curately）[9] 是由

Google Brain 和斯坦

福大学的研

究人员于 2020

年

3 月提出的另

一种 BERT 变体，旨

在解决大规

模预训练语

言模型中的

效率和可扩

展性问题。通

过使用生成

器-判别器架

构，ELECTRA

能够更高

效地利用预

训练数据，提

高了模

型在

下游任务中

的表现。

(1) ELECTRA

预训

练方式

在模

型结构上，ELECTRA 在

BERT 原有的掩码

语言建模基

础上结合了

生成

对抗网

络（Generative Adversarial Network, GAN）的思想，采

用了一种生

成器-判

别器

结构。具体来

说，ELECTRA 模型包含

一个生成器

和一个判别

器，其中生成

器（Generator）是一个能

进行掩码预

测的模型（例

如 BERT 模型），负责

将掩码后

的

文本恢复原

状。而判别器

（Discriminator）则使用替换

词检测（Replaced Token

Detection, RTD）预训

练任务，负责

检测生成器

输出的内容

中的每个

Token 是

否是

原文中

的内容。其完

整的流程如

图2.9所示。

57

第 2 章

大语言模型

架构

[CLS]

水 豚 [MASK] 格

十

分 [MASK] 顺 .

[SEP]

水豚

性格十分温

顺.

分词处理

并添加掩码

生成器恢复

掩码

判别器

检测替换词

[CLS]

水 豚

体

格 十

分

温



顺 . [SEP]

T

T  T



F

T  T

T

T



T T

T

图 2.9: ELECTRA

预

训练任务。

(2) ELECTRA 模

型结构

根据

生成器与判

别器的不同

规模，ELECTRA 共提出

了三个版本

的模型，分别

是 ELECTRA-Small、ELECTRA-Base 以及

ELECTRA-Large。其中

ELECTRA-Small

中的生成器

与判别器都

由 12 个编码模

块堆叠而成

，隐藏层维度

为

256，自注意力

头数量为 4，因

此生成器与

判别器的参

数量均为 0.14 亿

左右，总参数

数量约为

0.28

亿

；ELECTRA-Base 中的生成器

与判别器都

由 12

个编码模

块堆叠而成

，隐藏层维

度

为 768，自注意力

头数量为 12，因

此生成器与

判别器的参

数量均为

1.1 亿

左右，

总参数

数量约为 2.2

亿

；ELECTRA-Large 中的生成器

与判别器都

由 24 个编码模

块堆叠而成

，隐藏层维度

为

1024，自注意力

头数量为 16，因

此生成器与

判别器的

参

数量均为 3.3

亿

左右，总参数

数量约为 6.6 亿

。

其中，ELECTRA-Small

和 ELECTRA-Base 使用

与 BERT

一致的数

据集来进行

预训练，共包

含 33 亿个 Token。而

ELECTRA-Large 则

使用了更多

样化的训练

数

据，包括大

规模网页数

据集 ClueWeb

11、CommonCrawl 12以及大

型新闻文本

数据集

11https://lemurproject.org/clueweb09.php

12https://commoncrawl.org

58

李佳

晖 毛玉仁 宓

禹

Gigaword 13，最终将数

据量扩充到

了 330 亿个

Token，从而

帮助模型学

习更广泛的

语言表示。

另

外，在 BERT 中，只有

15%

的固定比例

Token 被掩码，模型

训练的内容

也

仅限于这

15% 的

Token。但是在 ELECTRA 中

，判别器会判

断生成器输

出的所有

Token

是

否被替换过

，因此能够更

好地学习文

本的上下文

嵌入。

不同于

RoBERTa 和 ALBERT

主要在模

型结构以及

预训练数据

规模上进行

优

化，ELECTRA 在 BERT

的基

础上引入了

新的生成器

-判别器架构

，通过替换语

言

模型任务

，显著提升了

训练效率和

效果，同时提

高了模型在

下游任务中

的表现。

上述

基于 Encoder-only

架构的

大语言模型

在文本分类

、情感分析等

多个自然语

言处理任务

中取得了良

好效果。表2.1从

模型参数量

及预训练语

料等方面对

上述模

型进

行总结。可以

看出这些经

典模型参数

大小止步于

6.6 亿，预训练任

务也主要服

务于自然语

言理解。这些

模型没有继

续寻求参数

量上的突破

，并且通常只

专注于

判别

任务，难以应

对生成式任

务，因此在当

前愈发热门

的生成式人

工智能领域

中

可以发挥

的作用相对

有限。

表 2.1: Encoder-only

架构

代表模型参

数和语料大

小表。

模型 发

布时间 参数

量（亿）

语料规

模 预训练任

务

BERT 2018.10

1.1, 3.4 约 15GB

MLM+NSP

RoBERTa 2019.07 1.2,

3.5 160GB Dynamic MLM

ALBERT 2019.09 0.12, 0.18,

0.6, 2.2 约 15GB

MLM+SOP

ELECTRA 2020.03 0.28,

2.2, 6.6 约 20-200GB

RTD

2.4 基

于 Encoder-Decoder

架构的大

语言模型

Encoder-Decoder 架

构在 Encoder-only

架构的

基础上引入

Decoder 组件，以完成

机器翻译等

序列到序列

（Sequence to Sequence,

Seq2Seq）任务。本节将

对 Encoder￾Decoder 架构及其

代表性模型

进行介绍。

13https://catalog.ldc.upenn.edu/LDC2011T07

59

第

2 章 大语言模

型架构

2.4.1 Encoder-Decoder 架构

Encoder-Decoder 架构主要包

含编码器和

解码器两部

分。该架构的

详细组成如

图2.10所示。其中

，编码器部分

与

Encoder-only 架构中的

编码器相同

，由多个编码

模块堆叠而

成，每个编码

模块包含一

个自注意力

模块以及一

个全连接前

馈模块。模

型

的输入序列

在通过编码

器部分后会

被转变为固

定大小的上

下文向量，这

个向量

包含

了输入序列

的丰富语义

信息。解码器

同样由多个

解码模块堆

叠而成，每个

解

码模块由

一个带掩码

的自注意力

模块、一个交

叉注意力模

块和一个全

连接前馈模

块组成。其中

，带掩码的自

注意力模块

引入掩码机

制防止未来

信息的“泄露

”，确

保解码过

程的自回归

特性。交叉注

意力模块则

实现了解码

器与编码器

之间的信息

交互，对于生

成与输入序

列高度相关

的输出至关

重要。

自注意

力模块

全连

接前馈模块

编码模块1

自

注意力模块

全连接前馈

模块

编码模

块M

自注意力

模块

全连接

前馈模块

解

码模块1

交叉

注意力模块

自注意力模

块

全连接前

馈模块

解码

模块N

交叉注

意力模块

编

码

器

解

码

器

图 2.10: Encoder-Decoder

架构。

自注

意模块在编

码器和解码

器中的注意

力目标不同

的。在编码器

中，我们需

要

对输入序列

的上下文进

行“通盘考虑

”，所以采用双

向注意力机

制以全面捕

捉上

下文信

息。但在解码

器中，自注意

力机制则是

单向的，仅以

上文为条件

来解码得到

60

...

...

李佳晖 毛玉

仁

宓禹

下文

，通过掩码操

作避免解码

器“窥视”未来

的信息。交叉

注意力通过

将解码器的

查询（query）与编码

器的键（key）和值

（value）相结合，实现

了两个模块

间的有

效信

息交流。

通过

自注意力和

交叉注意力

机制的结合

，Encoder-Decoder

架构能够高

效地编

码输

入信息并生

成高质量的

输出序列。自

注意力机制

确保了输入

序列和生成

序列

内部的

一致性和连

贯性，而交叉

注意力机制

则确保了解

码器在生成

每个输出 Token

时

都能参考输

入序列的全

局上下文信

息，从而生成

与输入内容

高度相关的

结果。在

这两

个机制的共

同作用下，Encoder-Decoder 架

构不仅能够

深入理解输

入序列，还

能

够根据不同

任务的需求

灵活生成长

度适宜的输

出序列，在机

器翻译、文本

摘要、

问答系

统等任务中

得到了广泛

应用，并取得

了显著成效

。本节将介绍

两种典型的

基于 Encoder-Decoder 架构的

代表性大语

言模型：T5[29] 和

BART[18]。

2.4.2 T5 语

言模型

自然

语言处理涵

盖了语言翻

译、文本摘要

、问答系统等

多种任务。通

常，每种

任务

都需要对训

练数据、模型

架构和训练

策略进行定

制化设计。这

种定制化设

计

不仅耗时

耗力，而且训

练出的模型

难以跨任务

复用，导致开

发者需要不

断“重复造

轮

子”。为了解决

这一问题，Google

Research 团

队在 2019 年

10 月提

出了一种基

于

Encoder-Decoder 架构的大

型预训练语

言模型

T5（Text-to-Text Transfer Transformer），

其采

用了统一的

文本到文本

的转换范式

来处理多种

任务。下面分

别从模型结

构、预

训练方

式以及下游

任务三个方

面对 T5 模型进

行介绍。

1.

T5 模型

结构

T5 模型的

核心思想是

将多种

NLP 任务

统一到一个

文本转文本

的生成式框

架

中。在此统

一框架下，T5 通

过不同的输

入前缀来指

示模型执行

不同任务，然

后生

成相应

的任务输出

，正如图2.11所示

。这种方法可

以视为早期

的提示（Prompt）技

61

第

2 章

大语言模

型架构

术的

运用，通过构

造合理的输

入前缀，T5 模型

能够引导自

身针对特定

任务进行优

化，而无需对

模型架构进

行根本性的

改变。这种灵

活性和任务

泛化能力显

著提高

了模

型的实用性

，使其能够轻

松地适应各

类新的

NLP 任务

。

水豚为什么

能和其

他动

物和谐相处

？

Why can capybaras

live

in harmony with

other

animals? 翻译语言模

型

水豚与其

他物种很

少

发生冲突，它

们...

水豚是一

种非常温

顺

、友好的动物

。 总结语言模

型

......

......

翻译成中

文：

水豚为什

么能和其他

动

物和谐相

处？

Why can capybaras

live

in harmony with

other

animals? T5统一框架

语言模型

总

结以下内容

：

水豚与其他

物种很少发

生冲突，它们

...

水豚是一种

非常温

顺、友

好的动物。

......

T5统

一框架

语言

模型

图 2.11: 传统

语言模型和

T5

统一框架。

在

模型架构方

面，T5 与原始的

包括一个编

码器和一个

解码器的 Transformer

架

构相同。每个

编码器和解

码器又分别

由多个编码

模块和解码

模块堆叠而

成。T5 模

型根据

不同的具体

参数，提供了

五个不同的

版本，分别是

T5-Small、T5-Base、T5-

Large、T5-3B

以及 T5-11B。T5-Small 由 6

个编

码模块和 6 个

解码模块堆

叠而成，

其中

隐藏层维度

为

512，自注意力

头的数量为

8，总参数数量

约为 6000 万；T5-Base

与

BERT-Base 对

标，由 12 个编码

模块和

12 个解

码模块堆叠

而成，其中隐

藏层维度

为

768，自注意力头

的数量为 12，总

参数数量约

为

2.2 亿；T5-Large 与 BERT-Large

对标

，由 24 个编码模

块和 24

个解码

模块堆叠而

成，隐藏层维

度为 1024，自注意

力头的数量

为 16，总参数数

量约为 7.7

亿；T5-3B 在

T5-Large 的基础上，把

自注意

力头

的数量扩大

到

32，另外还将

全连接前馈

网络的中间

层维度扩大

了 4 倍，总参

数

数量约为

28 亿

；T5-11B 在 T5-3B

的基础上

，进一步将自

注意力头的

数量扩大到

128，并又将全连

接前馈网络

的中间层维

度扩大了 4 倍

，总参数数量

约为 110

亿。

2. T5 预训

练方式

为了

获取高质量

、覆盖范围广

泛的预训练

数据集，Google Research 团队

从大

规模网

页数据集

Common Crawl 14中

提取了大量

的网页数据

，并经过严格

的清理和

14https://commoncrawl.org

62

李

佳晖 毛玉仁

宓禹

过滤，最

终生成了

C4 数

据集（Colossal Clean Crawled

Corpus），其覆盖

了各种网站

和文本类型

，总规模达到

了约 750GB。

基于此

数据集，T5 提出

了名为

Span Corruption 的预

训练任务。这

一预训练任

务从原始输

入中选择 15%

的

Token 进行破坏，每

次都选择连

续三个 Token 作为

一

个小段（span）整

体被掩码成

[MASK]。与 BERT 模型中采

用的单个 Token

预

测不

同，T5 模型

需要对整个

被遮挡的连

续文本片段

进行预测。这

些片段可能

包括连续

的

短语或子句

，它们在自然

语言中构成

了具有完整

意义的语义

单元。这一设

计要

求模型

不仅等理解

局部词汇的

表面形式，还

要可以捕捉

更深层次的

句子结构和

上

下文之间

的复杂依赖

关系。Span Corruption 预训练

任务显著提

升了

T5 的性能

表现，

尤其是

在文本摘要

、问答系统和

文本补全等

需要生成连

贯和逻辑性

强的文本生

成

任务中。

3. T5 下

游任务

基于

预训练阶段

学到的大量

知识以及新

提出的文本

转文本的统

一生成式框

架，

T5 模型可以

在完全零样

本（Zero-Shot）的情况下

，利用 Prompt 工程技

术直接适配

到多种下游

任务。同时，T5

模

型也可以通

过微调（Fine-Tuning）来适

配到特定的

任务。但是，微

调过程需要

针对下游任

务收集带标

签训练数据

，同时也需要

更多的

计算

资源和训练

时间，因此通

常只被应用

于那些对精

度要求极高

且任务本身

较为

复杂的

应用场景。

综

上所述，T5

模型

的文本转文

本的统一生

成式框架不

仅简化了不

同自然语言

处理任务之

间的转换流

程，也为大语

言模型的发

展提供了新

方向。如今，T5 模

型已

经衍生

了许多变体

，以进一步改

善其性能。例

如，mT5[43] 模型扩展

了对

100 多种

语

言的支持，T0[31] 模

型通过多任

务训练增强

了零样本学

习（Zero-Shot

Learning）

能力，Flan-T5[8] 模型

专注于通过

指令微调，以

实现进一步

提升模型的

灵活性和效

率等等。

63

第 2 章

大语言模型

架构

2.4.3

BART 语言模

型

BART（Bidirectional and

Auto-Regressive Transformers）是由 Meta AI

研究

院同

样于 2019 年

10

月提出的一

个 Encoder-Decoder 架构模型

。不同于 T5

将多

种 NLP

任务集成

到一个统一

的框架，BART 旨在

通过多样化

的预训练任

务来提升模

型在文

本生

成任务和文

本理解任务

上的表现。

1. BART 模

型结构

BART 的模

型结构同样

与原始的 Transformer 架

构完全相同

，包括一个编

码器

和一个

解码器。每个

编码器和解

码器分别由

多个编码模

块和解码模

块堆叠而成

。

BART 模型一共有

两个版本，分

别是 BART-Base

以及 BART-Large。BART-Base 由

6 个编码模块

和

6 个解码模

块堆叠而成

，其中隐藏层

维度为 768，自注

意力头的数

量为 12，总参数

数量约为

1.4 亿

；BART-Large 由 12

个编码模

块和 12 个解码

模块

堆叠而

成，其中隐藏

层维度为

1024，自

注意力头的

数量为 16，总参

数数量约为

4

亿。

2.

BART 预训练方

式

在预训练

数据上，BART 使用

了与

RoBERTa[23] 相同的

语料库，包含

小说数据

集

BookCorpus[46]、英语维基百

科数据集 15、新

闻数据集

CC-News 16、网

页开放数

据

集 OpenWebText

17以及故事

数据集 Stories，总数

据量达到约

160GB。

在预训练任

务上，BART 以重建

被破坏的文

本为目标。其

通过

Token 遮挡任

务（Token Masking）、Token 删除任务

（Token

Deletion）、连续文本填

空任务（Text

Infilling）、句子

打乱任务（Sentence Permutation）以

及文档旋转

任务（Document

Rotation）等五个

任务来破坏

文本，然后训

练模型对原

始文本进行

恢复。这种方

式

15https://dumps.wikimedia.org

16http://web.archive.org/save/http://commoncrawl.org/2016/10/newsdataset-available

17http://Skylion007.github.io/OpenWebTextCorpus

64

李佳晖 毛

玉仁 宓禹

水

豚[MASK]格十[MASK]温顺

.

且[MASK]攻击性.

[MASK]豚

性格十分[MASK]顺

. 且无攻击[MASK]. 水

[MASK]性格[MASK]分顺.

且

无[MASK]击性.

······

水豚

格十温顺. 且

攻击性.

豚性

格十分顺. 且

无攻击. 水性

格分顺. 且无

击性.

······

水豚性

格[MASK]顺. 且无攻

击性. 水豚性

格十分温顺

[MASK]攻击性.

水豚

[MASK]分温顺. 且无

攻击性.

······

且无

攻击性.

水豚

性格十分温

顺.

十分温顺

. 且无攻击性

. 水豚性格

攻

击性. 水豚性

格十分温顺

. 且无

温顺.

且

无攻击性. 水

豚性格十分

······

Token遮挡任务

Token删

除任务

连续

文本填空任

务

句子打乱

任务 文档旋

转任务

水豚

性格十分温

顺.

且无攻击

性.

原始文本

图 2.12: BART

预训练任

务。

锻炼了模

型对文本结

构和语义的

深入理解，增

强了其在面

对不完整或

损坏信息时

的鲁棒性。五

个文本破坏

任务的具体

形式如下所

述。

Token 遮挡任务

（Token

Masking）：类似于 BERT 中的

MLM 任务，在原始

文

本中随机

采样一部分

Token 并将其替换

为 [MASK]，从而训练

模型推断被

删

除的

Token 内容

的能力。

Token 删除

任务（Token

Deletion）：在原始

文本中随机

删除一部分

Token，从

而训练模

型推断被删

除的 Token 位置以

及内容的能

力。

连续文本

填空任务（Text Infilling）：类

似于 T5 的预训

练任务，在原

始文本

中选

择几段连续

的 Token（每段作为

一个 span），整体替

换为 [MASK]。其中

span 的

长度服从 λ =

3 的

泊松分布，如

果长度为 0 则

直接插入一

个

[MASK]。

这一任务

旨在训练模

型推断一段

span 及其长度的

能力。

句子打

乱任务（Sentence

Permutation）：将给

定文本拆分

为多个句子

，并随机

打乱

句子的顺序

。旨在训练模

型推理前后

句关系的能

力。

文档旋转

任务（Document Rotation）：从给定

文本中随机

选取一个

Token，作

为文本新的

开头进行旋

转。旨在训练

模型找到文

本合理起始

点的能力。

65

第

2 章

大语言模

型架构

在图

2.12中，以给定文

本“水豚性格

十分温顺. 且

无攻击性.”为

例，对这个五

个任务进行

演示。在预训

练结束后，可

以对 BART

进行微

调使其能够

将在预训练

阶段学到的

语言知识迁

移到具体的

应用场景中

，适配多种下

游任务。这种

从预训

练到

微调的流程

，使得 BART 不仅在

文本生成任

务上表现出

色，也能够适

应文本

理解

类任务的挑

战。后续同样

也出现了 BART 模

型的各种变

体，包括可处

理跨语

言文

本生成任务

的

mBART[22] 模型等。

综

上所述，基于

Encoder-Decoder 架构的大语

言模型，在生

成任务中展

示了

良好的

性能表现。表

2.2从模型参数

量和预训练

语料规模的

角度对本章

提到的基于

Encoder-Decoder 架构的模型

进行了总结

。可以看出此

时模型参数

数量的上限

已达

110 亿。在模

型结构和参

数规模的双

重优势下，相

较于基于

Encoder-only 架

构的模

型，这

些模型在翻

译、摘要、问答

等任务中取

得了更优的

效果。

表

2.2: Encoder-Decoder 架构

代表模型参

数和语料大

小表。

模型

发

布时间 参数

量（亿） 语料规

模

T5

2019.10 0.6-110 亿 750GB

mT5 2020.10 3-130 亿

9.7TB

T0 2021.10 30-110

亿 约

400GB

BART 2019.10

1.4-4 亿 约 20GB

mBART 2020.06 0.4-6.1 亿

约 1TB

2.5 基

于

Decoder-only 架构的大

语言模型

在

开放式（Open-Ended）生成

任务中，通常

输入序列较

为简单，甚至

没有具

体明

确的输入，因

此维持一个

完整的编码

器来处理这

些输入并不

是必要的。对

于

这种任务

，Encoder-Decoder 架构可能显

得过于复杂

且缺乏灵活

性。在这种背

景下，

Decoder-only 架构表

现得更为优

异。本节将对

Decoder-only

架构及其代

表性模型进

行介绍。

66

李佳

晖 毛玉仁

宓

禹

2.5.1 Decoder-only 架构

它通

过自回归方

法逐字生成

文本，不仅保

持了长文本

的连贯性和

内在一致性

，

而且在缺乏

明确输入或

者复杂输入

的情况下，能

够更自然、流

畅地生成文

本。此

外，Decoder-only 架构

由于去除了

编码器部分

，使得模型更

加轻量化，从

而加快了

训

练和推理的

速度。因此，在

同样的模型

规模下，Decoder-only 架构

可能表现得

更

为出色。

值

得一提的是

，Decoder-only

架构模型的

概念最早可

以追溯到 2018 年

发布的

GPT-1[27]

模型

。但在当时，由

于以 BERT 为代表

的 Encoder-only

架构模型

在各项

任务

中展现出的

卓越性能，Decoder-only 架

构并没有受

到足够的关

注。直到 2020

年，GPT-3[5] 的

突破性成功

，使得 Decoder-only 架构开

始被广泛应

用于各种大

语言

模型中

，其中最为流

行的有 OpenAI 提出

的 GPT

系列、Meta 提出

的 LLaMA 系列

等。其

中，GPT 系列是起

步最早的 Decoder-only 架

构，在性能上

也成为了时

代的标

杆。但

从第三代开

始，GPT 系列逐渐

走向了闭源

。而 LLaMA 系列虽然

起步较晚，

但

凭借着同样

出色的性能

以及始终坚

持的开源道

路，也在 Decoder-only 架构

领域

占据了

一席之地。接

下来将对这

两种系列的

模型进行介

绍。

2.5.2 GPT 系列语言

模型

GPT（Generative

Pre-trained Transformer）系列模

型是由 OpenAI 开发

的一系列

基

于 Decoder-only 架构的大

语言模型。自

从 2018

年问世以

来，GPT 系列模型

经历

了快速

的发展，其在

模型规模、预

训练范式上

不断演进，取

得了万众瞩

目的效果，

引

领了本轮大

语言模型发

展的浪潮。其

演进历程可

以划分为五

个阶段，表2.3对

这

五个阶段

的模型参数

规模和预料

规模进行了

总结。从表中

可以明显看

出，GPT 系

列模型

参数规模与

预训练语料

规模呈现出

激增的趋势

。然而，自 ChatGPT

版本

起，

67

第 2

章 大语

言模型架构

GPT 系列模型转

向了闭源模

式，其具体的

参数量和预

训练数据集

的详细信息

已不

再公开

。尽管如此，根

据扩展法则

，有理由猜测

ChatGPT

及其后续版

本在参数规

模

与预训练

语料规模上

都有所增长

。下面将对这

五个发展阶

段的模型分

别进行介绍

。

表 2.3:

GPT 系列模型

参数和语料

大小表。

模型

发布时间 参

数量（亿）

语料

规模

GPT-1 2018.06 1.17

约 5GB

GPT-2 2019.02

1.24 / 3.55 /

7.74 / 15 40GB

GPT-3 2020.05 1.25 /

3.5 / 7.62 /

13 / 27 /

67 / 130 /

1750 1TB

ChatGPT 2022.11

未知

未知

GPT-4 2023.03 未知

未

知

GPT-4o 2024.05 未知

未知

1. 初出茅庐：GPT-1 模

型

OpenAI

的前首席

科学家 Ilya Sutskever 在采

访中

18透露，OpenAI 自

成立初期

就

开始探索如

何通过下一

词预测解决

无监督学习

的问题。但当

时所用的 RNN

模

型无法很好

解决长距离

依赖问题，上

述问题没有

得到很好的

解决。直到 2017 年

，

Transformer

的出现为这

一问题提供

了新的解决

方案了，为 OpenAI 的

发展指明了

方

向。随后，OpenAI

开

始步入正轨

。2018 年 6 月，OpenAI

发布了

第一个版本

的 GPT

（Generative Pre-Training）模型，被称

为

GPT-1[27]。GPT-1 开创了 Decoder-only 架

构下，通过下

一词预测解

决无监督文

本生成的先

河，为自然语

言处理领域

带来了

革命

性的影响。下

面将分别对

GPT-1 的模型结构

、预训练、下游

任务等方面

展开

介绍。

(1)

GPT-1 模

型结构

在模

型架构方面

，GPT-1 使用了

Transformer 架构

中的 Decoder 部分，省

略了

Encoder 部分以

及交叉注意

力模块。其模

型由 12 个解码

块堆叠而成

，每个解码块

18https://hackernoon.com/an-interview-with-ilya-sutskever-co-founder-of-openai

68

李佳晖 毛玉

仁 宓禹

包含

一个带掩码

的自注意力

模块和一个

全连接前馈

模块。其中隐

藏层维度为

768，

自注意力头

的数量为 12，模

型的最终参

数数量约为

1.17 亿。

图2.13对比了

BERT-Base 以及 GPT-1 的模型

结构。从图中

可以看出，GPT-1

在

结构上与 BERT-Base 高

度类似，两者

都包含 12

个编

码或解码模

块，每个模块

也

同样由一

个自注意力

模块和一个

全连接前馈

模块组成。两

者之间的本

质区别在于

BERT-Base 中的自注意

力模块是双

向的自注意

力机制，而 GPT-1

中

的自注意力

模

块则是带

有掩码的单

向自注意力

机制。

全连接

前馈模块

自

注意力模块

编码模块1

编

码模块2

编码

模块12

全连接

前馈模块

掩

码自注意力

模块

解码模

块1

解码模块

2

BERT-Base架构 GPT-1架构

解

码模块12

图 2.13: BERT-Base

和

GPT-1 模型。

(2) GPT-1

预训练

方法

GPT-1 使用小

说数据集 BookCorpus[46]

来

进行预训练

，该数据集包

含约 8 亿

个

Token，总

数据量接近

5GB。在预训练方

法上，GPT-1 采用下

一词预测任

务，即

基于给

定的上文预

测下一个可

能出现的 Token。以

自回归的方

法不断完成

下一词预

测

任务，模型可

以有效地完

成文本生成

任务，如图2.14所

示。通过这种

预训练策略

，

模型可以在

不需要人为

构造大量带

标签数据的

前提下，学习

到大量语言

的“常识”，

学会

生成连贯且

上下文相关

的文本。这不

仅提高了模

型的泛化能

力，而且减少

了

对标注数

据的依赖，为

自然语言处

理领域带来

了新的研究

方向和应用

前景。

69

 ...

...

第 2 章

大

语言模型架

构

水

豚

性

格

十

预测下一

Token

个 分

拼接

水

豚

性

格

十

分

预测下一个

Token

温

拼接

水

豚

性

格

十

分

温

预测下一

Token

个

顺

拼接

图 2.14: GPT-1

语

言建模预训

练任务。

(3) GPT-1 下游

任务

尽管 GPT-1 模

型在预训练

后展现出了

一定的潜力

，但其任务泛

化能力仍受

限

于当时的

训练数据量

和模型参数

数量。为了提

升模型在特

定下游任务

上的表现，通

常需要进一

步的有监督

微调。微调过

程涉及使用

针对特定任

务的标注数

据来优化

模

型的参数，其

中模型的输

入和输出均

以文本序列

的形式呈现

。例如，在以下

任务

中，我们

需要构建针

对特定应用

场景的微调

策略：

文本分

类：GPT-1 能够接收

一段文本作

为输入，并根

据预定义的

类别标签，如

情感倾向（积

极、消极或其

他），对文本进

行分类。这在

情感分析、主

题分类

等场

景中非常有

用。

文本相似

度评估：当需

要衡量两段

文本之间的

相似性时，GPT-1 能

够分析并

量

化它们的内

容和语义相

似度。这项功

能在比较文

档、搜索结果

优化和推荐

系统中尤为

重要。

多项选

择题解答：GPT-1 还

可以处理多

项选择问题

。模型能够理

解问题文本

和选项内容

，从给定的选

项中识别并

输出最合适

的答案。

GPT-1 具备

原生的文本

生成能力。但

受限于训练

数据量和模

型参数数量

，其生

成能力

还不足以用

于解决实际

问题。此外，由

于其单向注

意力机制的

限制，其全面

70

李佳晖 毛玉

仁 宓禹

理解

上下文的能

力也有所欠

缺。四个月后

，具有双向上

下文理解能

力的 BERT 被提

出

，并以其强大

的上下文嵌

入能力迅速

吸引了业界

的广泛关注

，遮盖了

GPT-1 的

锋

芒。尽管 GPT-1

当时

在实用性上

可能不及 BERT，但

它作为 Decoder-only 架构

的

开端，为后

续大语言模

型的惊艳表

现拉开了序

幕。

2. 小有所成

：GPT-2 模型

虽然 GPT-1 锋

芒未露，OpenAI 并没

有改变其

Decoder-only 的

技术路线，而

是

选择在这

一路线上继

续深耕。在 2019

年

2 月，OpenAI 发布了 GPT

系

列的第二代

产品 GPT-2 19。相较于

GPT-1，GPT-2 在模型规模

和预训练样

本的质量上

都进行了

显

著的提升，显

著增强了模

型的任务泛

化能力。以下

将对 GPT-2 的模型

结构、预

训练

语料和下游

任务适配情

况进行介绍

。

(1) GPT-2 模型结构

GPT-2

模

型延续了 GPT-1 的

Decoder-only 架构，并在此

基础上进一

步加大了参

数数量。GPT-2

一共

发布了四个

版本，分别是

GPT-2 Small、GPT-2 Medium、GPT-2

Large

以及 GPT-2 XL。其中 GPT-2

Small 在

模型规模上

接近 GPT-1 以及

BERT-Base，

由

12 个编码块堆

叠而成，隐藏

层维度为 768，自

注意力头的

数量为

12，总参

数数

量约为

1.24 亿；GPT-2 Medium

在模型规

模上接近 BERT-Large，由

24 个解码块堆

叠而成，隐藏

层维度为 1024，自

注意力头的

数量为

16，总参

数数量约为

3.55 亿；

GPT-2 Large

由 36 个解码

块堆叠而成

，隐藏层维度

为 1280，自注意力

头的数量为

20，总参数数量

约为

7.74 亿；GPT-2 XL 是最

大规模版本

，由

48 个解码块

堆叠而

成，其

中隐藏层维

度为 1600，自注意

力头的数量

为

25，总参数数

量约为 15 亿。

(2)

GPT-2 预

训练方法

在

预训练中，GPT-2 继

续采用下一

词预测任务

，但进一步提

升了预训练

数据的

数量

和质量。其采

用了全新的

WebText 数据集，该数

据集由 40GB 经过

精心筛选和

19https://openai.com/index/gpt-2-1-5b-release

71

第 2 章

大语言

模型架构

清

洗的网络文

本组成。通过

使用 WebText 数据集

进行预训练

，GPT-2

的语言理解

能

力得到了

显著增强，接

触到了更多

样化的语言

使用场景，还

学习到了更

复杂的语言

表达方式。这

使得 GPT-2 在捕捉

语言细微差

别和构建语

言模型方面

更为精准，从

而在执行各

种自然语言

处理任务时

能够生成更

准确、更连贯

的文本。

(3) GPT-2 下游

任务

GPT-2

的任务

泛化能力得

到了改善，在

某些任务上

可以不进行

微调，直接进

行

零样本学

习。这种能力

大大增加了

GPT-2 在处理下游

任务时的灵

活性，降低了

下

游任务适

配所需的成

本。这为

Decoder-only 架构

博得了更多

关注。

3. 崭露头

角：GPT-3

模型

为了

进一步提升

任务泛化能

力，OpenAI 于 2020

年 6 月推

出了第三代

模型 GPT-

3[5]。与前两

代模型相比

，GPT-3 在模型规模

和预训练语

料上进一步

提升，并涌现

出了优良的

上下文学习

（In-Context Learning, ICL）能力。在上下

文学习能力

的加

持下，GPT-3 可

以在不进行

微调的情况

下，仅通过任

务描述或少

量示例即可

完成多

样化

的下游任务

。关于上下文

学习详细介

绍参见本书

3.2 章节。以下将

对

GPT-3 的

模型结

构、预训练语

料和下游任

务适配情况

进行介绍。

(1)

GPT-3 模

型架构

在模

型架构上，GPT-3 继

承并扩展了

前两代的架

构，显著增加

了解码块的

数

量、隐藏层

的维度和自

注意力头的

数量，参数量

最高达到 1750 亿

。庞大的参数

量

使得

GPT-3 能够

捕获更加细

微和复杂的

语言模式，显

著提升了模

型的文本生

成能

力。GPT-3 设计

了多个不同

参数规模的

版本，以满足

不同应用场

景的需求，详

细参

数细节

见表2.4。

(2) GPT-3 预训练

方法

延续了

前两代的预

训练方法，GPT-3 继

续采用下一

词预测作为

预训练任务

。其

使用了更

大规模和更

多样化的互

联网文本数

据集，数据量

接近 1TB，涵盖了

Com-

72

李佳晖 毛玉

仁 宓禹

表 2.4: GPT-1 至

GPT-3

模型具体参

数表。

模型版

本 解码块数

量 隐藏层维

度

自注意力

头数量 总参

数量（亿）

GPT-1 12

768 12 1.17

GPT-2

Small 12 768 12

1.24

GPT-2 Medium 24

1024 16 3.55

GPT-2

Large 36 1280 20

7.74

GPT-2 XL 48

1600 36 15

GPT-3

Small 12 768 12

1.25

GPT-3 Medium 24

1024 16 3.5

GPT-3

Large 24 1536 16

7.62

GPT-3 XL 24

2048 24 13

GPT-3

2.7B 32 2560 32

27

GPT-3 6.7B 32

4096 32 67

GPT-3

13B 40 5120 40

130

GPT-3 175B 96

12288 96 1750

mon

Crawl 20、WebText、BookCorpus[46]、Wikipedia 21等多

个来源，包括

书籍、网

站、论

坛帖子等各

类文本形式

。所有数据都

经过了严格

的筛选和清

洗流程，以确

保

数据的质

量和多样性

。基于这些数

据，GPT-3 学习到了

更加丰富和

多元的语言

知识

和世界

知识。

(3)

GPT-3 下游任

务

GPT-3 模型涌现

出了良好的

上下文学习

能力，使其可

以在无需微

调的情况下

，

仅通过在输

入文本中明

确任务描述

和提供少量

示例，便能够

执行多种下

游任务。上

下

文学习能力

极大地增强

了 GPT-3 的任务泛

化能力，使其

能够快速适

应不同的应

用场景。GPT-3

开始

在文本生成

、问答系统、语

言翻译等众

多自然语言

处理任务中

崭露头角。

4. 蓄

势待发：InstructGPT 等模

型

在 GPT-3 的基础

上，OpenAI 进一步推

出了一系列

衍生模型。这

些模型在

GPT-3

网

络结构之上

通过特定的

训练方法，各

个“身怀绝技

”。例如，采用十

亿行代码继

续

20https://commoncrawl.org

21http://web.archive.org/save/http://commoncrawl.org/2016/10/newsdataset-available

73

第 2 章

大语

言模型架构

预训练（Continual Pre-Training）的 Codex[6] 模

型，可以有效

地处理代码

生成任务；

采

用用户偏好

对齐（User Intent Alignment）的 InstructGPT[25]

模型

，具备良好的

指

令跟随能

力。其中，最具

启发意义的

是 InstructGPT，其也是 ChatGPT

的

前身。它通

过

引入了人类

反馈强化学

习（Reinforcement Learning from

Human Feedback, RLHF），

显著提升

了模型对用

户指令的响

应能力。

人类

反馈强化学

习旨在缓解

模型在遵循

用户指令时

可能出现的

不准确性和

不

可靠性，以

使模型生成

的内容更符

合人类的要

求。在人类反

馈强化学习

中，人类评

估

者首先提供

关于模型输

出质量的反

馈，然后使用

这些反馈来

微调模型。具

体过程

如图

2.15所示，整体可

以分为以下

三个步骤：1）有

监督微调：收

集大量“问题

-人

类回答”对

作为训练样

本，对大语言

模型进行微

调。2）训练奖励

模型：针对每

个

输入，让模

型生成多个

候选输出，并

由人工对其

进行质量评

估和排名，构

成偏好数

据

集。用此偏好

数据集训练

一个奖励模

型，使其可以

对输出是否

符合人类偏

好进

行打分

。3）强化学习微

调：基于上一

步中得到的

奖励模型，使

用强化学习

方法优

化第

一步中的语

言模型，即在

语言模型生

成输出后，奖

励模型对其

进行评分，强

化

学习算法

根据这些评

分调整模型

参数，以提升

高质量输出

的概率。

经过

RLHF 训练得到的

InstructGPT

的性能通常

优于 GPT-3，尤其是

在需要精

确

遵循用户指

令的场景中

。它生成的回

答更加贴合

用户的查询

意图，有效减

少了不

相关

或误导性内

容的生成。InstructGPT

的

研究为构建

更智能、更可

靠的 AI 系统提

供了新的思

路，展示了人

类智慧和机

器学习算法

结合的巨大

潜力。但是，RLHF 的

计算成本十

分高昂，主要

是由于：1）奖励

模型的训练

过程复杂且

耗时。2）除了需

要单独训练

语言模型和

奖励模型外

，还需要协调

这两个模型

进行多模型

联合训练，

这

一过程同样

复杂且消耗

大量资源。

为

了克服 RLHF 在计

算效率上的

缺陷，斯坦福

大学在

2023 年在

其基础上，提

出了一种新

的算法直接

偏好优化（Direct Preference Optimization,

DPO）[28]。DPO

74

李

佳晖 毛玉仁

宓禹

输入：水

豚为何能和

其他动物和

谐相处？

输出

1：水豚通常生

活在一个大

群体中... 输出

2：水豚是一种

非常温顺的

动物，且... 输出

3：水豚是半水

生哺乳动物

，生活在..。

输出

4：水豚并非天

生具有攻击

性的动物...

偏

好顺序：输出

2 > 输出4

> 输出1 = 输

出3

人工标注

输入：水豚为

何能和其他

动物和谐相

处？

输出：因为

水豚性格温

顺，且无攻击

性，因

此可以

和大多数动

物和谐相处

.

问题1

输入：水

豚喜欢吃什

么食物？

输出

：水豚是杂食

性动物，其食

物范围广

泛

，主要包括草

、树叶、水生植

物等。

问题2

训

练GPT-3模型

微调

后模型

输入

：水豚为何能

和其他动物

和谐相处？

  输

入：水豚喜欢

吃什么食物

？

......

  输入：水豚为

何能和其他

动物和谐相

处？

......

生成多组

回答

问题1

......

训

练GPT-3模型

奖励

模型

输入：水

豚喜欢吃什

么食物？

问题

1

......

生成回答

输

入：水豚喜欢

吃什么食物

？

输出：水豚是

一种杂食性

动物，主要以

植物

为食，以

草类和水生

植物为主，辅

以树叶、

嫩枝

和一些水果

蔬菜。

问题1

......

回

答评分

输入

：水豚喜欢吃

什么食物？

输

出：水豚是一

种杂食性动

物，主要以植

物

为食，以草

类和水生植

物为主，辅以

树叶、

嫩枝和

一些水果蔬

菜。

得分：0.85

问题

1

......

强化学习更

新模型

......

问题

1

......

人工标注偏

好

问题1

问题

2

问题1

有监督

微调 训练奖

励模型 强化

学习微调

图

2.15:

人类反馈强

化学习（RLHF）过程

。

算法直接利

用人类偏好

数据来训练

模型，省略了

单独构建奖

励模型以及

应用复杂

强

化学习算法

的步骤。该方

法首先收集

包含多个响

应的人类偏

好数据，并从

中标

记出最

优和次优响

应。然后微调

模型以提高

模型选择最

优响应的概

率，同时降低

选择次优响

应的概率。这

种方法显著

简化了人类

反馈对齐的

流程，提高了

训练效

率和

模型稳定性

。尽管在处理

复杂的人类

偏好时可能

略逊于 RLHF，但 DPO 在

计

算效率上

的优势使其

在多个领域

得到了广泛

应用。

5. 一鸣惊

人：ChatGPT 以及

GPT-4 等模

型

OpenAI 于

2022 年 11 月推

出了聊天机

器人（ChatGPTChat

Generative Pre￾trained Transformer） 22。ChatGPT“一鸣惊

人”，以强大的

对话能力展

示出令人

惊

讶的智能，一

度燃起了 ChatGPT 是

否可以通过

“图灵测试”的

讨论 [3]。此外，用

户可以通过

OpenAI

提供的网页

端或 API 轻松使

用预训练后

的 ChatGPT

模型，而

无

需在本地部

署，标志着一

种新的服务

模式 LLMaaS(LLM as

a Service) 的出现

。但

22https://openai.com/blog/chatgpt

75

第 2 章

大语

言模型架构

是，从 ChatGPT 起，GPT 系列

模型走向闭

源，我们无从

窥探

ChatGPT 及后续

模型

的技术

细节。

四个月

后，OpenAI

于 2023 年 3

月继

续发布了 GPT-4 23模

型。相较于 ChatGPT，

GPT-4 在

理解复杂语

境、捕捉语言

细微差别、生

成连贯文本

等任务上进

一步提升，

并

且能够更有

效地处理数

学问题、编程

挑战等高级

认知任务。此

外，GPT-4 还引入

了

对图文双模

态的支持，扩

展了其在图

像描述和视

觉问题解答

等应用领域

的可能

性。

一

年后，为了进

一步提升模

型性能以及

用户体验，OpenAI 于

2024

年 5 月提出

了

GPT-4o

24。GPT-4o 模型在前代

GPT-4 的基础上，大

幅提升了响

应速度，显著

降

低了延迟

，并且还增强

了多模态处

理能力以及

多语言支持

能力。其在客

户支持、内

容

创作和数据

分析等领域

表现亮眼。GPT-4o 的

推出标志着

AIGC 的应用日趋

成熟。

GPT

系列模

型的演进过

程是人工智

能发展史中

一个激动人

心的篇章。从

GPT-1

的“初出茅庐

”到 GPT-4o 的“一鸣惊

人”，短短

6 年时

间，GPT 系列模型

便带来了

革

命性的突破

。诸多“科幻”变

成现实，众多

产业将被重

塑。但是，随着

GPT

系

列模型走

向闭源，用户

仅可以使用

其功能，却无

法参与到模

型的共同创

造和改进

过

程中。

2.5.3

LLAMA 系列语

言模型

LLaMA（Large Language

Model Meta AI）是由

Meta AI

开发的一系

列大语言模

型，其模型权

重在非商业

许可证下向

学术界开放

，推动了大语

言模型的“共

创”和

知识共

享。在模型架

构上，LLaMA 借鉴了

GPT 系列的设计

理念，同时在

技术细节

上

进行了创新

和优化。LLaMA 与 GPT 系

列的主要区

别在于：GPT

系列

的升级主

23https://openai.com/index/gpt-4-research

24https://openai.com/index/hello-gpt-4o

76

李

佳晖 毛玉仁

宓禹

线聚焦

于模型规模

与预训练语

料的同步提

升，而 LLaMA

则在模

型规模上保

持相对

稳定

，更专注于提

升预训练数

据的规模。表

2.5展示了不同

版本 LLaMA 模型对

应

的发布时

间、参数量以

及语料规模

。当前，Meta AI 共推出

三个版本的

LLaMA 模

型。在这些

模型的基础

上，大量衍生

模型陆续被

推出。原始的

LLaMA 模型和其衍

生模型一起

构成了 LLaMA 生态

系统。接下来

将对

LLaMA 的三个

版本及其部

分衍

生模型

进行介绍。

表

2.5:

LLaMA 系列模型参

数和语料大

小表。

模型 发

布时间

参数

量（亿） 语料规

模

LLAMA-1 2023.02

67 / 130 /

325 / 652 约

5TB

LLAMA-2 2023.07 70

/ 130 / 340

/ 700 约 7TB

LLAMA-3 2024.04 80 /

700 约 50TB

1.

LLaMA1 模

型

LLaMA1[40] 是

Meta AI 于 2023

年 2 月

推出的首个

大语言模型

。其在 Chin￾chilla[15]

扩展法

则的指引下

，实践“小模型

+ 大数据”的理

念，旨在以大

规模的优

质

数据训练相

对较小的模

型。相对较小

的参数规模

可以赋能更

快的推理速

度，使

其可以

更好的应对

计算资源有

限的场景。

在

预训练语料

方面，LLaMA1 的预训

练数据涵盖

了大规模网

页数据集 Common

Crawl25、T5[29]

提

出的 C4 数据集

，以及来自 Github、Wikipedia、Gutenberg、Books3、

Arxiv 以

及 StackExchange 等多种来

源的数据，总

数据量高达

5TB。

在模型架构

方面，LLaMA1 采用了

与 GPT 系列同样

的网络架构

。但是，其在

Transformer 原

始词嵌入模

块、注意力模

块和全连接

前馈模块上

进行了优化

。在词

嵌入模

块上，为了提

高词嵌入质

量，LLaMA1 参考了

GPTNeo[4] 的

做法，使用旋

转位置编码

（Rotary Positional Embeddings,

RoPE）[36] 替代了原有

的绝对位置

编

码，从而增

强位置编码

的表达能力

，增强了模型

对序列顺序

的理解。在注

意力模

25https://commoncrawl.org

77

第 2 章

大语言模型

架构

输入

注

意力模块 全

连接前馈模

块

输出

输入

注意力模块

全连接前馈

模块

输出

图

2.16: LLaMA

解码块架构

与标准 Transformer 解码

器架构对比

。

块上，LLaMA1

参考了

PaLM[7] 的做法，将 Transformer 中

的

RELU 激活函数

改为

SwiGLU 激活函

数

[34]。并且，LLaMA1 在进

行自注意力

操作之前对

查询（query）

以及键

（key）添加旋转位

置编码。在全

连接前馈模

块上，LLaMA1 借鉴了

GPT-3[5]

中的 Pre-Norm 层正则

化策略，将正

则化应用于

自注意力和

前馈网络的

输入。在注

意

力模块和全

连接前馈模

块上的改进

如图2.16所示。

基

于该框架，LLaMA1 共

推出了 4 个版

本的模型。不

同版本对应

的具体参数

如

表2.6所示。

表

2.6: LLaMA1 模型具体参

数表。

模型版

本 解码块数

量 隐藏层维

度 自注意力

头数量

总参

数量（亿）

LLaMA1-7B 32 4096

32 67

LLaMA1-13B 40

5120 40 130

LLaMA1-32B

60 6656 52 325

LLaMA1-65B 80 8192 64

652

78

R

M

S

层

正

则

化

S

o

f

t

m

a

x

层

旋

转

位

置

编

码

R

M

S

层

正

则

化

全

连

接

前

馈

层

S

o

f

t

m

a

x

层

层

正

则

化

全

连

接

前

馈

层

层

正

则

化

L

L

a

M

A

T

r

a

n

s

form

e

r

李

佳晖 毛玉仁

宓禹

2. LLaMA2

模型

2023 年

7 月，Meta

AI 发布了 LLaMA 系

列的第二代

模型

LLaMA2[39]。秉承

“小

模型 + 大数据

”的设计理念

，LLaMA2

在 LLaMA1 的基础上

进一步优化

和扩充

了训

练数据，将语

料库的规模

扩展至约

7TB，实

现了对更丰

富语言和领

域资源的

覆

盖。此外，在预

训练阶段之

后，LLaMA2 采纳了人

类反馈强化

学习的方法

，进一

步提升

了模型的性

能。首先，其使

用了大规模

且公开的指

令微调数据

集

[8] 对模型

进

行有监督的

微调。然后，LLaMA2 还

训练了

RLHF 奖励

模型，并基于

近似策略优

化（Proximal Policy Optimization,

PPO）[33] 以及拒绝

采样（Rejection Sampling）进

行强

化学习对模

型进行更新

。

在模型架构

上，LLaMA2 继承了 LLaMA1 的

架构。LLaMA2

共推出

了四个版本

的模型，不同

版本对应的

具体参数如

表2.7所示。其中

，LLaMA2-34B 和 LLaMA2-

70B

还额外增

加了分组查

询注意力（Grouped Query Attention, GQA）[1]，以

提升计

算效

率。在分组查

询注意力机

制下，键（key）以及

值（value）不再与查

询（query）

一一对应

，而是一组查

询共享相同

的键和值，从

而有效降低

内存占用并

减少模型

总

参数量。

表

2.7: LLaMA2 模

型具体参数

表。

模型版本

解码块数量

隐藏层维度

自注意力头

数量

总参数

量（亿）

LLaMA2-7B 32 4096

32 70

LLaMA2-13B 40

5120 40 130

LLaMA2-34B

60 6656 52 340

LLaMA2-70B 80 8192 64

700

3. LLaMA3 模型

2024 年

4 月，Meta AI

于 2024 年 4

月进

一步推出了

第三代模型

LLaMA3 26。

LLaMA3 挑选了规模

高达

50TB 的预训

练语料，是 LLaMA2 的

7

倍之多。这一

语料

26https://ai.meta.com/blog/meta-llama-3

79

第

2 章 大

语言模型架

构

库不仅包

含丰富的代

码数据以增

强模型的逻

辑推理能力

，还涵盖了超

过

5% 的非英

文

数据，覆盖 30

多

种语言，显著

扩展了模型

的跨语言处

理能力。此外

，LLaMA3

还进行了与

LLaMA2 一样的人类

反馈强化学

习，这一策略

已被证明能

显著提升模

型性能。最终

LLaMA3 的性能在多

个评测指标

上全面超越

了前代模型

。即便是参

数

量相对较少

的 80 亿参数版

本，也展现出

了超越 LLaMA2

700 亿参

数版本的卓

越

性能。而 700

亿

参数版本的

LLaMA3，在多项任务

上的性能更

是超越了业

界标杆

GPT-4 模型

。

在模型架构

上，LLaMA3

与前一代

LLaMA2 几乎完全相

同，只是在分

词（tok￾enizer）阶段，将字

典长度扩大

了三倍，极大

提升了推理

效率。这一改

进减少了中

文字符等语

言元素被拆

分为多个 Token 的

情况，有效降

低了总体

Token 数

量，从而

提高

了模型处理

语言的连贯

性和准确性

。另一方面，扩

大的字典有

助于减少对

具有

完整意

义的语义单

元进行分割

，使模型在处

理文本时可

以更准确的

捕捉词义和

上

下文，提高

生成文本的

流畅性和连

贯性。LLaMA3 在其推

出的 80 亿参数

以及

700

亿参数

版本上，均采

用了分组查

询注意力机

制。这两个版

本的模型参

数与 LLaMA2

的对应

版本保持高

度一致，但在

性能上实现

了质的飞跃

，充分证明了

数据的力量

。

4. LLaMA 衍生模型

LLaMA

模

型的开源共

享吸引了众

多研究者在

其基础上继

续创作。研究

者们或

继续

改进 LLaMA 模型的

性能，或将

LLaMA 模

型适配到垂

直领域，或将

LLaMA

模型支持的

数据模态进

行扩充。众智

众创为 LLaMA

营造

出了一个多

样的、充满活

力的研究生

态。下面对三

类主流的 LLaMA 衍

生模型进行

简要介绍。

性

能改进类模

型：一些研究

者专注于通

过微调继续

提升

LLaMA 模型性

能。

例如，Alpaca 27基于

GPT-3.5

生成的指令

遵循样例数

据对 LLaMA1 进行微

调，

以较小的

模型规模实

现了与

GPT-3.5 相媲

美的性能。Vicuna 28模

型则另辟蹊

27https://crfm.stanford.edu/2023/03/13/alpaca.html

28https://lmsys.org/blog/2023-03-30-vicuna

80

李佳晖 毛玉

仁 宓禹

径，利

用 ShareGPT 平台上累

积的日常对

话数据微调

LLaMA1 模型，进一步

提升了它的

对话能力。Guanaco[10]

模

型则通过在

微调 LLaMA1 的过程

中引

入

QLoRA 技术

，显著降低了

微调的时间

成本，提高了

微调效率。

垂

域任务类模

型：尽管 LLaMA

在通

用任务上表

现出色，但在

特定领域的

应

用潜力仍

待挖掘。因此

，大量研究者

们针对垂直

领域对 LLaMA 进行

微调，

以改善

其在垂直领

域上的表现

。例如，CodeLLaMA[30] 模型在

LLaMA2 的

基础上，利

用大量公开

代码数据进

行微调，使其

能更好地适

应自动化代

码

生成、错误

检测、以及代

码优化等任

务。LawGPT[24] 模型通过

30 万条法律

问

答对

LLaMA1 模型进

行指令微调

，显著增强了

其对法律内

容的处理能

力。

GOAT[21] 模型通过

Python

脚本生成的

数学题库对

LLaMA1 模型进行微

调，

提高其解

决各类数学

题的准确率

。Cornucopia 29模型则利用

金融问答数

据进

行微调

，增强了金融

问答的效果

。

多模态任务

类模型：通过

整合视觉模

态编码器和

跨模态对齐

组件，研究者

们

将 LLaMA

模型扩

展到多模态

任务上。例如

，LLaVA[19] 在 Vicuna 的基础上

利用

CLIP 提取图

像特征并利

用一个线性

投影层实现

图片和文本

之间的对齐

。

MiniGPT4[45] 在

Vicuna 的基础上

使用 VIT-G/14 以及

Q-Former 作

为图像编

码

器，并同样使

用线性投影

层来实现图

片和文本之

间的对齐，展

现了多模态

任务处理能

力。

这些衍生

模型不仅丰

富了

LLaMA 模型的

应用场景，也

为自然语言

处理领域的

研究提供了

新的方向和

可能性。LLaMA 系列

以其开源开

放的姿态，吸

引全球研究

者参与共创

。我们有理由

相信 LLaMA

系列模

型携其衍生

模型将绽放

出满天繁星

，

照亮大语言

模型前行之

路。

29https://github.com/jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese

81

第 2 章 大语

言模型架构

表

2.8: GPT 系列和 LLaMA

系

列模型参数

和语料大小

表。

模型 发布

时间 参数量

（亿）

语料规模

GPT-1 2018.06 1.17 约

5GB

GPT-2 2019.02 1.24

/ 3.55 / 7.74

/ 15 40GB

GPT-3

2020.05 1.25 / 3.5

/ 7.62 / 13

/ 27 / 67

/ 130 / 1750

1TB

ChatGPT 2022.11 未知

未知

GPT-4 2023.03 未知 未知

GPT-4o 2024.05 未

知 未知

LLAMA-1 2023.02 67 /

130 / 325 /

652 约 5TB

LLAMA-2

2023.07 70 / 130

/ 340 / 700

约

7TB

LLAMA-3 2024.04 80

/ 700 约 50TB

基于 Decoder-only 架构

的大语言模

型，凭借其卓

越的生成能

力，引领了新

一轮

生成式

人工智能的

浪潮。表2.8展示

了

GPT 系列和 LLaMA 系

列不同版本

的具体参

数

，从中可以发

现基于 Decoder-only 架构

的模型在参

数数量和预

训练语料规

模上

急速增

长。随着算力

资源和数据

资源的进一

步丰富，基于

Decoder-only

架构的大语

言模型必将

释放出更为

璀璨的光芒

。

2.6 非 Transformer

架构

Transformer 结构

是当前大语

言模型的主

流模型架构

，其具备构建

灵活、易并

行

、易扩展等优

势。但是，Transformer

也并

非完美。其并

行输入的机

制会导致模

型

规模随输

入序列长度

平方增长，导

致其在处理

长序列时面

临计算瓶颈

。为了提高计

算效率和性

能，解决 Transformer 在长

序列处理中

的瓶颈问题

，可以选择基

于

RNN

的语言模

型。RNN 在生成输

出时，只考虑

之前的隐藏

状态和当前

输入，理论上

可

以处理无

限长的序列

。然而，传统的

RNN

模型（如 GRU、LSTM 等）在

处理长序

列

时可能难以

捕捉到长期

依赖关系，且

面临着梯度

消失或爆炸

问题。为了克

服这

些问题

，近年来，研究

者提出了两

类现代 RNN 变体

，分别为状态

空间模型（State

Space

Model，SSM）和

测试时训练

（Test-Time Training，TTT）。这两种范式

都可

82

李佳晖

毛玉仁

宓禹

以实现关于

序列长度的

线性时间复

杂度，且避免

了传统 RNN 中存

在的问题。本

节

将对这两

种范式及对

应的代表性

模型进行简

要介绍。

2.6.1 状态

空间模型 SSM

状

态空间模型

（State

Space Model，SSM）[13] 范式可以有

效处理长文

本中存

在的

长程依赖性

（Long-Range

Dependencies, LRDs）问题，并且可

以有效降低

语言

模型的

计算和内存

开销。本小节

将首先介绍

SSM 范式，再分别

介绍两种基

于

SSM

范式的代

表性模型：RWKV 和

Mamba。

1.

SSM

SSM 的思想源自

于控制理论

中的动力系

统。其通过利

用一组状态

变量来捕捉

系统状态随

时间的连续

变化，这种连

续时间的表

示方法天然

地适用于描

述长时间

范

围内的依赖

关系。此外，SSM

还

具有递归和

卷积的离散

化表示形式

，既能在推

理

时通过递归

更新高效处

理序列数据

，又能在训练

时通过卷积

操作捕捉全

局依赖

关系

。

图

2.17: SSM 范式。

如图

2.17，SSM

在三个随时

间 t 变化的变

量和四个可

学习的矩阵

的基础上构

造而成。三个

变量分别为

：x(t) ∈

C

n 表示 n

个状态

变量，u(t) ∈ C

m

表示 m 个

状

83

第 2 章 大语

言模型架构

态输入，y(t)

∈ C

p 表示

p

个输出。四个

矩阵分别为

：状态矩阵 A ∈ C

n×n，控

制矩

阵 B ∈

C

n×m，输出

矩阵 C ∈

C

p×n 和命令

矩阵 D

∈ C

p×m。SSM 的系统

方程为：

x

′

(t) =

Ax(t) + Bu(t)

y(t)

= Cx(t) + Du(t)，

(2.5)

其中

，x

′

(t)

= Ax(t) + Bu(t)

为状态方程

，描述了系统

状态如何基

于输入和前

一个状态变

化，其计算出

的是状态关

于时间的导

数 x

′

(t)，为了得到

状态

x(t)，还

需对

其进行积分

操作。y(t) = Cx(t)

+ Du(t) 为输出

方程，描述了

系统状态如

何转

化为输

出，其中的

x(t) 是

通过状态方

程更新且积

分后的值。在

深度学习中

，Du(t)

项表示残差

连接, 可被忽

略。

该方程可

视作 SSM 系统方

程的连续形

式，适用于对

连续数据（例

如音频信号

、

时间序列）的

处理，但是在

训练和推理

都非常慢。为

了提高对

SSM 的

处理效率，需

要对该方程

进行离散化

操作。离散化

（Discretization）是 SSM 中最为关

键的步骤，

能

够将系统方

程从连续形

式转换为递

归形式和卷

积形式，从而

提升整个 SSM 架

构

的效率。将

连续形式的

SSM

系统方程离

散化时，可以

使用梯形法

代替连续形

式中

的积分

操作，其原理

是将定义在

特定区间上

的函数曲线

下的区域视

为梯形，并利

用梯形面积

公式计算其

面积。由此，可

以得出离散

化后递归形

式下的系统

方程：

xk =

A¯ xk−1 + B¯uk

yk = C¯xk。

(2.6)

在该方

程中，状态方

程由前一步

的状态和当

前输入计算

当前状态，体

现了递

归的

思想。其中，A¯ , B¯,

C¯ 为

离散形式下

的矩阵，其与

连续形式下

矩阵 A, B,

C 的

关系

分别表示为

：¯A =

￾ I −

∆

2 A



−1

￾

I +

∆

2 A

 ，B¯

=

￾ I −

∆

2 A



−1 ∆B，C¯ = C，其

中 ∆ = tn+1

− tn。

递归形

式的 SSM

类似于

RNN，具有 RNN 的优缺

点。其适用于

顺序数据的

处

理，能够实

现与序列长

度呈线性复

杂度的高效

推理，但是无

法并行训练

，当面临长

84

李

佳晖 毛玉仁

宓禹

序列时

存在梯度消

失或爆炸问

题。将系统方

程的递归形

式进行迭代

，可以得到卷

积形式。这里

省略了推导

过程，直接给

出迭代后

xk 和

yk 的结果：

xk

= A¯ kB¯u0 +

A¯ k−1B¯u1 + ·

· · + B¯uk

yk = C¯xk =

C¯A¯ kB¯u0 + C¯A¯

k−1B¯u1 + · ·

· + C¯B¯uk。

(2.7)

可以

观察到，将系

统方程的递

归形式迭代

展开后，输出

yk 是状态输入

uk 的卷积结

果

，其卷积核为

：

K¯ k = (C¯B¯,

C¯A¯B¯, . . .

, C¯A¯ kB¯)。 (2.8)

因此，SSM 系统方

程的卷积形

式为：

yk =

K¯ k ∗ uk，

(2.9)

其中，卷

积核是由 SSM 中

的矩阵参数

决定的，由于

这些参数在

整个序列的

处

理过程中

是固定的，被

称为时不变

性。时不变性

使得 SSM 能够一

致地处理不

同时

间步长

的数据，进行

高效的并行

化训练。但由

于上下文长

度固定，卷积

形式的

SSM

在进

行自回归任

务时延迟长

且计算消耗

大。结合离散

化后 SSM 的递归

形式和卷积

形式的优缺

点，可以选择

在训练时使

用卷积形式

，推理时使用

递归形式。

综

上，SSM 架构的系

统方程具有

三种形式，分

别为连续形

式、离散化的

递归

形式以

及离散化的

卷积形式，可

应用于文本

、视觉、音频和

时间序列等

任务，在应

用

时，需要根据

具体情况选

择合适的表

示形式。SSM

的优

势在于能够

处理非常长

的序列，虽然

比其它模型

参数更少，但

在处理长序

列时仍然可

以保持较快

的速度。

当前

，各种现有 SSM 架

构之间的主

要区别在于

基本

SSM 方程的

离散化方式

或 A 矩阵的定

义。例如，S4[14]（Structured

State Space Model）是一

种 SSM

变体，

其关

键创新是使

用 HiPPO 矩阵来初

始化

A 矩阵，在

处理长序列

数据时表现

优异。

此外，RWKV 和

Mamba

是两种基于

SSM 范式的经典

架构，下面将

分别介绍这

两

种架构。

85

第

2 章 大语言模

型架构

2.

RWKV

RWKV（Receptance Weighted Key

Value）[26] 是基

于 SSM 范式的创

新架构，

其核

心机制 WKV 的计

算可以看作

是两个 SSM

的比

。RWKV 的设计结合

了 RNNs

和

Transformers 的优点

，既保留了推

理阶段的高

效性，又实现

了训练阶段

的并行

化。（注

：这里讨论的

是 RWKV-v4）

RWKV 模型的核

心模块有两

个：时间混合

模块和 通道

混合模块。时

间混合模

块

主要处理序

列中不同时

间步之间的

关系，通道混

合模块则关

注同一时间

步内不

同特

征通道30之间

的交互。时间

混合模块和

通道混合模

块的设计基

于四个基本

元

素：接收向

量 R、键向量 K、值

向量

V 和 权重

W，下面将根据

图 2.18，介绍这些

元素在两个

模块中的计

算流程和作

用。

输

入

嵌

入

时间混合模

块

K

R

V

WKV

通道混合

模块

K '

R

'

V '

Token

位移

层

正

则

化

层

正

则

化

层

正

则

化

层

正

则

化

输

出

门

控

输

出

门

控

图 2.18: RWKV 架

构。

时间混合

模块和通道

混合模块中

共有的操作

是 Token 位移，该步

通过对当前

时间步和前

一时间步的

输入进行线

性插值来实

现，从而确保

了模型对序

列中时间

变

化的敏感性

。在时间混合

模块中，接受

向量

R 负责接

收并整合来

自序列历史

的

信息，权重

W 表示位置权

重衰减，键向

量

K 和值向量

V 类似传统注

意力机制中

的

键和值，分

别用于匹配

和携带信息

。时间混合模

块首先将当

前步长和前

一步长的

30在

这里，通道指

的是在神经

网络中同一

时间步内的

不同特征维

度。例如，在处

理自然语言

处理任务

时

，每个时间步

的输入可能

是一段文本

的一个词，而

每个词会通

过嵌入层转

化为一个向

量，这个向

量

的每个元素

就代表一个

特征通道，向

量维数就是

通道数量。

86

S

o

f

t

m

a

x

李

佳晖

毛玉仁

宓禹

输入进

行线性组合

，通过线性投

影得到 R、K、V 向量

；随后，通过

WKV 机

制来

确保每

个通道的权

重随时间推

移逐步衰减

；最后，将表示

过去信息的

σ(R) 和表示

当前

信息的 WKV 向量

通过输出门

控进行整合

，传递给通道

混合模块。

时

间混合模块

中的

WKV 机制是

RWKV 的核心部分

。在 RWKV

中，权重 W

是

一个与通道

相关的时间

衰减向量，该

向量可以表

示为：wt,i =

−(t − i)w，i 表示

从

当前时间步

长 t 向后追溯

的某个时间

步长，w 是一个

非负向量，其

长度为通道

数。通过这种

方式，模型能

够捕捉时间

序列中不同

时间步长之

间的依赖关

系，实现

每个

通道权重随

时间向后逐

步衰减的效

果。WKV 机制的关

键在于利用

线性时不变

递归来更新

隐藏状态，这

可以看作是

两个 SSM 之比。具

体公式为：

wkvt =

P

t−1

i=1 e

−(t−1−i)w+ki ⊙

vi + e

u+kt

⊙ vt

P

t−1

i=1 e

−(t−1−i)w+ki +

e

u+kt

， (2.10)

其

中，u 是一个单

独关注当前

Token 的向量。由于

分子和分母

都表现出状

态更新和

输

出的过程，与

SSM

思想类似，因

此该公式可

以看作是两

个 SSM 之比。通过

权重

W

和 WKV 机制

，模块能够有

效地处理长

时间序列数

据，并减少梯

度消失问题

。

在通道混合

模块中，R

′、K

′、V

′ 的作

用与时间混

合模块类似

，R

′ 和 K

′

同样由

输

入的线性投

影得到，V

′ 的更

新则额外依

赖于

K

′。之后，将

σ(R

′

)

和 V

′ 整合，以

实

现不同通道

之间的信息

交互和融合

。

此外，RWKV 架构还

采用了时间

依赖的 Softmax

操作

，提高数值稳

定性和梯

度

传播效率，以

及采用层归

一化来稳定

梯度，防止梯

度消失和爆

炸。为了进一

步提

升性能

，RWKV 还采用了自

定义

CUDA 内核、小

值初始化嵌

入以及自定

义初始化

等

优化措施。

RWKV

在

模型规模、计

算效率和模

型性能方面

都表现可观

。在模型规模

方面，

RWKV 模型参

数扩展到了

14B，是第一个可

扩展到数百

亿参数的非

Transformer 架

构。在计算

效率方面，RWKV 允

许模型被表

示为 Transformer 或

RNN，从而

使得模

型在

训练时可以

并行化计算

，在推理时保

持恒定的计

算和内存复

杂度。在模型

性

87

第

2 章 大语

言模型架构

能方面，RWKV 在

NLP 任

务上的性能

与类似规模

的 Transformer 相当，在长

上下文

基准

测试中的性

能仅次于 S4。

RWKV 通

过创新的线

性注意力机

制，成功结合

了

Transformer 和 RNN 的优势

，

在模型规模

和性能方面

取得了显著

进展。然而，在

处理长距离

依赖关系和

复杂任

务时

，RWKV 仍面临一些

局限性。为了

解决这些问

题并进一步

提升长序列

建模能

力，研

究者们提出

了

Mamba 架构。

3. Mamba

时不

变性使得 SSM 能

够一致地处

理不同时间

步长的数据

，进行高效的

并行化

训练

，但是同时也

导致其处理

信息密集的

数据（如文本

）的能力较弱

。为了弥补这

一不足，Mamba

[12] 基于

SSM 架构，提出了

选择机制（Selection Mechanism）和

硬件感知算

法（Hardware-aware

Algorithm），前者使模

型执行基于

内容的推理

，后

者实现了

在 GPU 上的高效

计算，从而同

时保证了快

速训练和推

理、高质量数

据生

成以及

长序列处理

能力。

Mamba 的选择

机制通过动

态调整模型

参数来选择

需要关注的

信息，使模型

参数能够根

据输入数据

动态变化。具

体来说，Mamba 将离

散化

SSM 中的参

数

B, C,

∆ 分别转变

成以下函数

: sB(x) =

LinearN (x)、sC(x) = LinearN

(x)、s∆(x) =

BroadcastD(Linear1(x)) ，并采用非线

性激活函数

τ∆

= softplus 来调节参数

∆。其

中

Lineard 是对特

征维数 d 的参

数化投影，s∆

和

τ∆ 函数的选择

与 RNN 的门控机

制相关联

[38]。此

外，Mamba 还对张量

形状进行相

应调整，使模

型参数具有

时间

维度，这

意味着模型

参数矩阵在

每个时间步

都有不同的

值，从时间不

变转变为时

间变化的。

选

择机制使模

型参数变成

了输入的函

数，且具有时

间维度，因此

模型不再具

备

卷积操作

的平移不变

性和线性时

不变性，从而

影响其效率

。为了实现选

择性 SSM

模型在

GPU 上的高效计

算，Mamba

提出一种

硬件感知算

法，主要包括

内核融合、

88

李

佳晖 毛玉仁

宓禹

层

正

则

化

投

影

矩

阵

投

影

矩

阵

卷

积

层

投

影

矩

阵

输

入

输

出

Mamba

模块

Mamba

模块

Mamba

模

块

线

性

层

Mamba

模

块

图 2.19: Mamba

架构。

并

行扫描和重

计算三方面

内容。内核融

合通过减少

内存 I/O 操作来

提高速度。并

行

扫描利用

并行化算法

提高效率。重

计算则在反

向传播时重

新计算中间

状态，以减

少

内存需求。

具

体实现中，将

SSM 参数从较慢

的高带宽内

存（HBM）加载到更

快的静态随

机存取存储

器（SRAM）中进行计

算，然后将最

终输出写回

HBM。这样可以在

保持

高效计

算的同时，减

少内存使用

，使模型内存

需求与优化

的 Transformer 实现（如

FlashAttention）相

同。

Mamba 通过将带

有选择机制

的 SSM 模块与

Transformer 的

前馈层相结

合，形成

了一

个简单且同

质的架构设

计。如图 2.19所示

，Mamba

架构是由完

全相同的 Mamba

模

块组成的递

归模型，每个

Mamba 模块都在前

馈层中插入

了卷积层和

带有选择机

制的

SSM 模块，其

中激活函数

σ 选用 SiLU

/ Swish 激活。

通

过引入选择

机制和硬件

感知算法，Mamba

在

实际应用中

展示了卓越

的性能

和效

率，包括：（1）快速

训练和推理

：训练时，计算

和内存需求

随着序列长

度线

性增长

，而推理时，每

一步只需常

数时间，不需

要保存之前

的所有信息

。通过硬件

89

S

S

M

S

o

f

t

m

a

x

第

2 章

大语言模

型架构

感知

算法，Mamba 不仅在

理论上实现

了序列长度

的线性扩展

，而且在 A100

GPU

上，其

推理吞吐量

比类似规模

的 Transformer 提高了

5 倍

。（2）高质量数据

生成：

在语言

建模、基因组

学、音频、合成

任务等多个

模态和设置

上，Mamba 均表现出

色。在语言建

模方面，Mamba-3B

模型

在预训练和

后续评估中

性能超过了

两倍参数

量

的 Transformer 模型性能

。（3）长序列处理

能力：Mamba

能够处

理长达百万

级别

的序列

长度，展示了

处理长上下

文时的优越

性。

虽然 Mamba

在硬

件依赖性和

模型复杂度

上存在一定

的局限性，但

是它通过引

入选择机制

和硬件感知

算法显著提

高了处理长

序列和信息

密集数据的

效率，展示

了

在多个领域

应用的巨大

潜力。Mamba 在多种

应用上的出

色表现，使其

成为一种

理

想的通用基

础模型。

2.6.2 训练

时更新 TTT

在处

理长上下文

序列时，上述

基于

SSM 范式的

架构（例如 RWKV 和

Mamba）

通过将上下

文信息压缩

到固定长度

的隐藏状态

中，成功将计

算复杂度降

低至线性

级

别，有效扩展

了模型处理

长上下文的

能力。然而，随

着上下文长

度的持续增

长，

基于 SSM

范式

的模型可能

会过早出现

性能饱和。例

如，Mamba 在上下文

长度超过

16k 时

，困惑度基本

不再下降

[37]。出

现这一现象

的原因可能

是固定长度

的隐藏状

态

限制了模型

的表达能力

，同时在压缩

过程中可能

会导致关键

信息的遗忘

。

为了解决这

一限制，测试

时训练（Test-Time Training，TTT）[37]

范式

提供了一

种

有效的解决

方案。TTT 利用模

型本身的参

数来存储隐

藏状态、记忆

上文；并在每

一步推理中

，对模型参数

进行梯度更

新，已实现上

文的不断循

环流入，如图

2.20所

示。这个过

程不同于传

统的机器学

习范式中模

型在完成训

练后的推理

阶段通常保

持静态的方

式，TTT

在推理阶

段会针对每

一条测试数

据一边循环

训练一边推

理。为

了实现

这种测试时

训练的机制

，TTT 在预训练和

推理阶段均

进行了独特

的设计。

90

李佳

晖 毛玉仁 宓

禹

更新

图 2.20: TTT 范

式下的推理

流程。

在 TTT 范式

的预训练阶

段，训练过程

包含内部循

环以及外部

循环两个部

分。

其中外部

循环遵循传

统的下词预

测任务，通过

自回归方式

优化模型全

局权重参数

。

内部循环则

是基于自监

督的方式来

优化隐藏状

态。具体来说

，模型需要在

每个时

间步

动态地更新

隐藏状态，使

其能够不断

适应新的输

入数据。这种

动态更新的

机

制类似于

一个独立的

机器学习模

型在每个时

间步对输入

进行训练和

优化。给定当

前时间步输

入 xt

以及先前

历史上下文

x1, x2, . .

. , xt−1 对应的隐藏

状态

Wt−1，模型

计

算当前时间

步的重构损

失：

ℓ (Wt−1;

xt) = ∥f (θKxt

; Wt−1) − θV

xt∥

2 ， (2.11)

其中 θK 和 θV

是

通过外部循

环学习到的

参数。接着, 模

型以学习率

η 利用该损失

进

行梯度下

降，更新隐藏

状态：

Wt = Wt−1 −

η∇ℓ (Wt−1; xt) 。

(2.12)

最终，模

型基于更新

后的隐藏状

态和当前输

入生成输出

：

zt =

f(xt

; Wt)。 (2.13)

在推理阶段

，无需执行外

部循环任务

。因此，模型只

进行内部循

环来对隐藏

状

态进行更

新，使模型更

好地适应新

的数据分布

，从而提升预

测性能。

与 Transformer

相

比，基于 TTT 范式

的模型具有

线性时间复

杂度，这对于

处理

长序列

数据至关重

要。相较于基

于

SSM 的 RWKV 和

Mamba 架构

，TTT 通过模型

91

第

2 章 大语言模

型架构

参数

来保存上下

文信息，能够

更有效地捕

捉超长上下

文中的语义

联系和结构

信息。

因此，TTT 在

长上下文建

模任务中展

现出卓越的

性能，特别是

在需要处理

超长上

下文

的应用场景

中。未来，TTT 范式

有望在超长

序列处理任

务中发挥重

要作用。

参考

文献

[1] Joshua Ainslie

et al. “Gqa: Training

generalized multi-query transformer models

from multi-head checkpoints”. In:

arXiv preprint arXiv:2305.13245 (2023).

[2] Rohan Anil et

al. “Palm 2 technical

report”. In: arXiv preprint

arXiv:2305.10403

(2023).

[3] Tim

Bayne and Iwan Williams.

“The Turing test is

not a good benchmark

for thought

in LLMs”.

In: Nature Human Behaviour

7.11 (2023), pp. 1806–1807.

[4] Sid Black et

al. “Gpt-neox-20b: An open-source

autoregressive language model”.

In:

arXiv preprint arXiv:2204.06745 (2022).

[5] Tom Brown et

al. “Language models are

few-shot learners”. In: NeurIPS.

2020.

[6] Mark Chen

et al. “Evaluating large

language models trained on

code”. In: arXiv

preprint

arXiv:2107.03374 (2021).

[7] Aakanksha

Chowdhery et al. “Palm:

Scaling language modeling with

pathways”.

In: Journal of

Machine Learning Research 24.240

(2023), pp. 1–113.

[8]

Hyung Won Chung et

al. “Scaling instruction-finetuned language

models”. In: Jour￾nal of

Machine Learning Research 25.70

(2024), pp. 1–53.

[9]

Kevin Clark et al.

“Electra: Pre-training text encoders

as discriminators rather than

generators”. In: arXiv preprint

arXiv:2003.10555 (2020).

[10] Tim

Dettmers et al. “Qlora:

Efficient finetuning of quantized

llms”. In: NeurIPS.

2024.

[11] Jacob Devlin et

al. “BERT: Pre-training of

Deep Bidirectional Transformers for

Language Understanding”. In: NAACL.

2019.

[12] Albert Gu

and Tri Dao. “Mamba:

Linear-Time Sequence Modeling with

Selective

State Spaces”. In:

arXiv preprint arXiv:2312.00752 (2023).

[13] Albert Gu, Karan

Goel, and Christopher Ré.

“Efficiently modeling long sequences

with structured state spaces”.

In: arXiv preprint arXiv:2111.00396

(2021).

92

李佳晖

毛玉仁 宓禹

[14]

Albert Gu et al.

“On the Parameterization and

Initialization of Diagonal State

Space

Models”. In: NeurIPS.

2022.

[15] Jordan Hoffmann

et al. “Training compute-optimal

large language models”. In:

arXiv preprint arXiv:2203.15556 (2022).

[16] Jared Kaplan et

al. “Scaling laws for

neural language models”. In:

arXiv preprint

arXiv:2001.08361 (2020).

[17] Zhenzhong Lan et

al. “Albert: A lite

bert for self-supervised learning

of language

representations”. In:

arXiv preprint arXiv:1909.11942 (2019).

[18] Mike Lewis et

al. “Bart: Denoising sequence-to-sequence

pre-training for natural

language

generation, translation, and comprehension”.

In: ACL. 2020.

[19]

Haotian Liu et al.

“Visual instruction tuning”. In:

NeurIPS. 2024.

[20] Qi

Liu, Matt J Kusner,

and Phil Blunsom. “A

survey on contextual embeddings”.

In: arXiv preprint arXiv:2003.07278

(2020).

[21] Tiedong Liu

and Bryan Kian Hsiang

Low. “Goat: Fine-tuned llama

outperforms

gpt-4 on arithmetic

tasks”. In: arXiv preprint

arXiv:2305.14201 (2023).

[22] Yinhan

Liu et al. “Multilingual

denoising pre-training for neural

machine transla￾tion”. In: Transactions

of the Association for

Computational Linguistics 8 (2020),

pp. 726–742.

[23] Yinhan

Liu et al. “Roberta:

A robustly optimized bert

pretraining approach”. In:

arXiv

preprint arXiv:1907.11692 (2019).

[24]

Ha-Thanh Nguyen. “A brief

report on lawgpt 1.0:

A virtual legal assistant

based on

gpt-3”. In:

arXiv preprint arXiv:2302.05729 (2023).

[25] Long Ouyang et

al. “Training language models

to follow instructions with

human

feedback”. In: NeurIPS.

2022.

[26] Bo Peng

et al. “RWKV: Reinventing

RNNs for the Transformer

Era”. In: EMNLP.

2023.

[27] Alec Radford et

al. “Improving language understanding

by generative pre-training”.

In:

(2018).

[28] Rafael Rafailov

et al. “Direct preference

optimization: Your language model

is se￾cretly a reward

model”. In: NeurIPS. 2024.

93

第 2 章

大语言

模型架构

[29] Colin Raffel

et al. “Exploring the

limits of transfer learning

with a unified text-to￾text

transformer”. In: Journal of

machine learning research 21.140

(2020), pp. 1–

67.

[30] Baptiste Roziere et

al. “Code llama: Open

foundation models for code”.

In: arXiv

preprint arXiv:2308.12950

(2023).

[31] Victor Sanh

et al. “Multitask prompted

training enables zero-shot task

generaliza￾tion”. In: arXiv preprint

arXiv:2110.08207 (2021).

[32] Rylan

Schaeffer, Brando Miranda, and

Sanmi Koyejo. “Are emergent

abilities of

large language

models a mirage?” In:

NeurIPS. 2024.

[33] John

Schulman et al. “Proximal

policy optimization algorithms”. In:

arXiv preprint

arXiv:1707.06347 (2017).

[34] Noam Shazeer. “Glu

variants improve transformer”. In:

arXiv preprint

arXiv:2002.05202 (2020).

[35] Shaden Smith et

al. “Using deepspeed and

megatron to train megatron￾turing

nlg 530b, a large-scale

generative language model”. In:

arXiv preprint

arXiv:2201.11990 (2022).

[36] Jianlin Su et

al. “Roformer: Enhanced transformer

with rotary position embedding”.

In: arXiv preprint arXiv:2104.09864

(2021).

[37] Yu Sun

et al. “Learning to

(Learn at Test Time):

RNNs with Expressive Hidden

States”. In: arXiv preprint

arXiv:2407.04620 (2024).

[38] Corentin

Tallec and Yann Ollivier.

“Can recurrent neural networks

warp time?” In:

ICLR.

2018.

[39] Hugo Touvron

et al. “Llama 2:

Open foundation and fine-tuned

chat models”. In:

arXiv

preprint arXiv:2307.09288 (2023).

[40]

Hugo Touvron et al.

“Llama: Open and efficient

foundation language models”. In:

arXiv preprint arXiv:2302.13971 (2023).

[41] Trieu H Trinh

and Quoc V Le.

“A simple method for

commonsense reasoning”. In:

arXiv

preprint arXiv:1806.02847 (2018).

[42]

Ashish Vaswani et al.

“Attention is all you

need”. In: NeurIPS. 2017.

[43] Linting Xue et

al. “mT5: A massively

multilingual pre-trained text-to-text trans￾former”.

In: NAACL. 2021.

94

李

佳晖 毛玉仁

宓禹

[44] Aiyuan

Yang et al. “Baichuan

2: Open large-scale language

models”. In: arXiv

preprint

arXiv:2309.10305 (2023).

[45] Deyao

Zhu et al. “Minigpt-4:

Enhancing vision-language understanding with

ad￾vanced large language models”.

In: arXiv preprint arXiv:2304.10592

(2023).

[46] Yukun Zhu

et al. “Aligning books

and movies: Towards story-like

visual explana￾tions by watching

movies and reading books”.

In: ICCV. 2015.

95

3 Prompt 工程

随

着模型训练

数据规模和

参数数量的

持续增长，大

语言模型突

破了泛化瓶

颈，

并涌现出

了强大的指

令跟随能力

。泛化能力的

增强使得模

型能够处理

和理解多种

未知任务，而

指令跟随能

力的提升则

确保了模型

能够准确响

应人类的指

令。两种

能力

的结合，使得

我们能够通

过精心编写

的指令输入

，即 Prompt，来引导模

型适

应各种

下游任务，从

而避免了传

统微调方法

所带来的高

昂计算成本

。Prompt

工程，

作为一

门专注于如

何编写这些

有效指令的

技术，成为了

连接模型与

任务需求之

间

的桥梁。它

不仅要求对

模型有深入

的理解，还需

要对任务目

标有精准的

把握。通过

Prompt

工

程，我们能够

最大化地发

挥大语言模

型的潜力，使

其在多样化

的应用场

景

中发挥出卓

越的性能。本

章将深入探

讨 Prompt 工程的概

念、方法及作

用，并介

绍上

下文学习、思

维链等技术

，以及 Prompt 工程的

相关应用。

*

本

书持续更新

，GIT Hub 链接为：https://github.com/ZJU-LLMs/Foundations-of-LLMs。

第

3 章

Prompt 工程

3.1

Prompt 工程简

介

传统的自

然语言处理

研究遵循“预

训练-微调-预

测”范式，即先

在大规模语

料

库上作预

训练，然后在

下游任务上

微调，最后在

微调后的模

型上进行预

测。然而，

随着

语言模型在

规模和能力

上的显著提

升，一种新的

范式——“预训练

-提示预测”

应

运而生，即在

预训练模型

的基础上，通

过精心设计

Prompt 引导大模型

直接适应

下

游任务，而无

需进行繁琐

微调，如图

3.1所

示。在这一过

程中，Prompt 的设计

将

对模型性

能产生深远

影响。这种专

注于如何编

写 Prompt

的技术，被

称为 Prompt

工程。在

本节中，我们

将深入介绍

Prompt 工程的定义

及其相关概

念，探讨其在

自

然语言处

理领域中的

重要性和应

用。

图 3.1: “预训练

-微调-预测”范

式与“预训练

-提示预测”范

式对比。

3.1.1 Prompt 的定

义

Prompt

是指用于

指导生成式

人工智能模

型执行特定

任务的输入

指令 1，这些指

令通常以自

然语言文本

的形式出现

。Prompt 的核心目的

是清晰地描

述模型应该

执

行的任务

，以引导模型

生成特定的

文本、图像、音

频等内容。如

图

3.2所示，通过

1https://en.wikipedia.org/wiki/Prompt_engineering

98

张超 毛玉仁

胡中豪

判断

下面句子的

情感为积极

还是消极.

小

浣熊连续吃

了20包烧烤味

的干脆面，撑

得肚子疼。

这

个句子的情

感是消极的

，因为小浣熊

因为吃了太

多干脆面而

肚子疼。

分类

任务

以小浣

熊吃干脆面

为主题，帮我

写一首诗

浣

熊食面

林间

小浣熊儿忙

，手捧干脆面

儿香。

脆响声

声似玉碎，口

福满满乐无

疆。

尾摇身动

似舞者，颊鼓

腮圆似饱王

。

干脆面儿何

所乐？小浣熊

儿乐未央。

生

成任务 文生

图任务

画一

张小浣熊在

吃干脆面的

图片.

图 3.2: 几种

常见的

Prompt 例子

。

精心设计的

Prompt，模型能够实

现多样化的

功能。例如，通

过提供明确

的情感分

类

指令，模型能

够准确地对

文本进行情

感分析；通过

特定主题的

创作指令，模

型能

够生成

富有创意的

诗歌。此外，在

多模态模型

的应用场景

中，Prompt 还可以包

含

画面描述

，从而指导模

型生成相应

的视觉作品

。

Prompt

的应用范围

广泛，不仅限

于文本到文

本的任务。由

于本书主要

关注语

言模

型，本章节将

聚焦于文本

生成模型，并

深入探讨如

何通过精心

设计的 Prompt

来引

导模型生成

符合特定任

务要求的文

本输出。

3.1.2 Prompt 工程

的定义

Prompt

工程

（Prompt Engineering），又称提示工

程，是指设计

和优化用于

与生

成式人

工智能模型

交互的 Prompt

的过

程 2。这种技术

的核心在于

，将新任务通

过

Prompt 构建为模

型在预训练

阶段已经熟

悉的形式，利

用模型固有

的泛化能力

来执

行新的

任务，而无需

在额外的特

定任务上进

行训练。Prompt 工程

的成功依赖

于对

2https://en.wikipedia.org/wiki/Prompt_engineering

99

第 3 章 Prompt

工

程

预训练模

型的深入理

解，以及对任

务需求的精

确把握。通过

构造合适的

Prompt 输

入给大语

言模型，大语

言模型能够

帮助我们完

成各种任务

[47]。

原始的Prompt

判断

下面句子的

情感：小浣熊

连续吃了20包

它最喜欢的

烧烤味干脆

面，撑得肚子

疼，痛并快乐

的在

地上打

滚。

尽管小浣

熊吃了20包干

脆面之后撑

得肚子疼，所

以这句话的

情感是负面

的。

优化后的

Prompt

### 判断下面句

子的情感为

积极还是消

极。

针对此问

题有如下示

例：

# 示例1：浣熊

爸爸背了一

箱干脆面走

来，小浣熊手

舞足蹈迎接

爸爸。 \n积极

#

示

例2：小浣熊吃

了一包麻辣

味的干脆面

，辣得肚子疼

。 \n消极

# 示例3：小

浣熊吃了一

包烧烤味的

干脆面，脸上

露出了满意

的笑容。

\n积极

### 待分类的句

子：小浣熊连

续吃了20包它

最喜欢的烧

烤味干脆面

，撑得肚子疼

，痛并快乐的

在地

上打滚

。

###

以 {"结果": " "}

的JSON格

式返回最终

结果。

{"结果": "积

极"}

图

3.3: Prompt 工程技

术应用前后

的效果对比

。

如图

3.3所示，通

过 Prompt 工程的优

化，原始 Prompt

被改

写为更加全

面、规

范的形

式。优化后的

Prompt 能够显著提

升模型生成

回答的质量

。因此，在与大

语

言模型互

动过程中构

建优质且全

面的

Prompt 至关重

要，它直接决

定了能否获

得有

价值的

输出。经过良

好设计的 Prompt

通

常由任务说

明、上下文、问

题、输出格式

四个基本元

素组成：

任务

说明——向模型

明确提出具

体的任务要

求。任务说明

应当清晰、直

接，

并尽可能

详细地描述

期望模型完

成的任务。

上

下文——向模型

提供的任务

相关背景信

息，用以增强

其对任务的

理解以及

提

供解决任务

的思路。上下

文可以包括

特定的知识

前提、目标受

众的背景、

相

关任务的示

例，或任何有

助于模型更

好地理解任

务的信息。

100

张

超

毛玉仁 胡

中豪

问题——向

模型描述用

户的具体问

题或需要处

理的信息。这

部分应直接

涉及

用户的

查询或任务

，为模型提供

一个明确的

起点。问题可

以是显式的

提问，

也可以

是隐式的陈

述句，用以表

达用户的潜

在疑问。

输出

格式——期望模

型给出的回

答的展示形

式。这包括输

出的格式，以

及任

何特定

的细节要求

，如简洁性或

详细程度。例

如，可以指示

模型以 JSON

格

式

输出结果。

Prompt 的

四个基本元

素——任务说明

、上下文、问题

和输出格式

，对于大语言

模型生成的

效果具有显

著影响。这些

元素的精心

设计和组合

构成了

Prompt 工程

的

核心。在此

基础上，Prompt 工程

包括多种技

巧和技术，如

上下文学习

（In-Context

Learning）和思维链（Chain of Thought）等

。这些技巧和

技术的结合

使用，可以显

著提升 Prompt

的质

量，进而有效

地引导模型

生成更符合

特定任务需

求的输出。具

体关于上下

文学习的内

容将在 3.2节中

讨论，思维链

的内容将在

3.3节中讨论，而

Prompt 的使用技巧

将在 3.4节中详

细探讨。

然而

，随着 Prompt 内容的

丰富和复杂

化，输入到模

型中的 Prompt

长度

也随之

增加

，这不可避免

地导致了模

型推理速度

的减慢和推

理成本的上

升。因此，在追

求模型性能

的同时，如何

有效控制和

优化 Prompt 的长度

，成为了一个

亟待解决的

问题，需要在

确保模型性

能不受影响

的前提下，尽

可能压缩输

入到大型模

型中的

Prompt 长度

。为此，LLMLingua [11] 提出了

一种创新的

由粗到细的

Prompt

压缩方

法，该

方法能够在

不牺牲语义

完整性的情

况下，将 Prompt 内容

压缩至原来

的二十

分之

一，同时几乎

不损失模型

的性能。此外

，随着 RAG 技术的

兴起，模型需

要处

理的上

下文信息量

大幅增加。FIT-RAG

[22] 技

术通过高效

压缩检索出

的内容，成功

将上下文长

度缩短至原

来的 50% 左右，同

时保持了性

能的稳定，为

处理大规模

上

下文信息

提供了有效

的解决方案

。

101

第 3

章 Prompt 工程

3.1.3

Prompt 分

词向量化

在

构建合适的

Prompt 之后，用户将

其输入到大

语言模型中

，以期得到满

意的

生成结

果。但是，语言

模型无法直

接理解文本

。在 Prompt 进入大模

型之前，需要

将它拆分成

一个 Token

的序列

，其中 Token 是承载

语义的最小

单元，标识具

体某个

词，并

且每个

Token 由 Token ID

唯

一标识。将文

本转化为 Token 的

过程称之为

分

词（Tokenization），如图

3.4所

示，对于“小浣

熊吃干脆面

”这样一句话

，经过分词

处

理之后，会变

成一个 Token 序列

，每个

Token 有对应

的 Token ID。

小浣熊吃

干脆面

分词

向量化

h

Token_ID

Token

向量

维度

0.0390

-0.0123

-0.0208 ……

-0.0558

0.0151

0.0031 ……

-0.0440

-0.0236

-0.0283 ……

0.06472

-0.0208

-0.0123 ……

0.0038

0.0739

-0.0371 ……

-0.0723

-0.0274

0.0872 ……

0.0016

-0.0095

0.0238 ……

0.0212

-0.0721

0.0872 ……

100000 1312

1103 96 21172 3424

65553 1359

BOS 小

æµ £ 熊 吃

干脆

面

图 3.4: 分

词与嵌入的

过程，以

DeepSeek-V2-Chat 模型

的分词器为

例 [6]。

值得注意

的是，一句话

可能存在多

种拆分方式

。例如，上述句

子可拆分为

“小,

浣熊, 吃干

, 脆面”。然而，这

种拆分方式

可能导致语

义混乱、不清

晰。因此，分词

过程颇具挑

战性，我们需

要精心设计

分词方法。为

实现有效分

词，首先需构

建一个

包含

大语言模型

所能识别的

所有

Token 的词表

，并依据该词

表进行句子

拆分。

在构建

大语言模型

的词表时，分

词器依赖于

分词算法，如

BBPE [34]、BPE

[8]

和 WordPiece [29]

等，这些算

法通过分析

语料库中的

词频等信息

来划分 Token。本

文

将以 BBPE（Byte-Level

Byte Pair Encoding）算法为

例，阐述其分

词过程。BBPE

算法

的流程主要

包括以下四

个步骤：

102

张超

毛玉仁 胡中

豪

1.

初始化词

表：首先，将所

有字符按照

其底层编码

拆分为若干

字节，并将这

些单字节编

码作为初始

词表的 Token。

2. 统计

词频：接下来

，统计词表中

所有

Token 对（即相

邻 Token 的组合）的

出现频率。在

初始阶段，Token

对

即为相邻字

节的组合。

3. 合

并高频 Token

对：然

后，选择出现

频率最高的

Token 对，将其合并

成一

个新的

Token 并加入词表

。

4. 迭代合并：重

复步骤 2 和步

骤

3，不断迭代

合并，直至达

到预设的词

表大

小或达

到指定的合

并次数。

我们

可以通过设

定迭代次数

等方法来决

定分词粒度

，不同的分词

粒度导致我

们得到不同

大小的词表

。若词表过小

，例如仅包含

256 个

Token 表示单字

节，能

够组合

出所有 GBK

编码

的汉字和英

文，但会导致

形态相近但

意义迥异的

词汇在模

型

中难以区分

，限制了模型

承载丰富语

义的能力，并

大幅增加生

成的序列长

度。相

反，若词

表过大，虽然

能涵盖更多

长尾词汇，但

可能导致对

这些词汇的

学习不够深

入，且难以有

效捕捉同一

单词不同形

态之间的关

联。因此，在构

建词表时，需

在涵

盖广泛

词汇与保持

语义精细度

之间找到恰

当的平衡点

，以确保大语

言模型既能

学

习到丰富

的词汇知识

，又能准确理

解和生成具

有复杂语义

的文本。

具体

来说，如图 3.4所

示，为了有助

于模型更准

确地理解词

义，同时减少

生成

常用词

所需的

Token 数量

，词表中收录

了语料库中

高频出现的

词语或短语

，形成独

立的

Token。例如，“干脆”一

词在词表中

以一个 Token

来表

示。为了优化

Token 空

间并压缩

词表大小，构

建词表时会

包含了一些

特殊的 Token，这些

Token

既能单独

表

示语义，也能

通过两两组

合，表示语料

库中低频出

现的生僻字

。例如，“浣”字

使

用两个 Token，“æµ”和“£”，来

表示。通过这

种处理方式

，词表既能涵

盖常见

的高

频词汇，又能

通过 Token 组合灵

活表达各类

稀有字符。由

此可见，词表

构建在

一定

程度上受到

“先验知识”的

影响，这些知

识源自人类

语料库的积

累与沉淀。

103

第

3 章 Prompt

工程

每个

大语言模型

都有自己的

分词器，分词

器维护一个

词表，能够对

文本进行

分

词。分词器的

质量对模型

的性能有着

直接的影响

。一个优秀的

分词器不仅

能显

著提升

模型对文本

的理解能力

，还能够提高

模型的处理

速度，减少计

算资源的消

耗。一个好的

分词器应当

具备以下特

点：首先，它能

够准确地识

别出文本中

的关键

词和

短语，从而帮

助模型更好

地捕捉语义

信息；其次，分

词器的效率

直接影响到

模

型的训练

和推理速度

，一个高效的

分词器能够

实现对文本

Token 的优化压缩

，进而

显著缩

短模型在处

理数据时所

需的时间。

表

3.1: 模型分词器

对比表

模型

词表大小 中

文分词效率

（字

/ Token）

英文分词

效率

（词

/ Token）

LLaMA1 32000

0.6588 0.6891

LLaMA2 32000

0.6588 0.6891

LLaMA3 128256

1.0996 0.7870

DeepSeek-V1 100016

1.2915 0.7625

DeepSeek-V2 100002

1.2915 0.7625

GPT-3.5 &

GPT-4 100256 0.7723 0.7867

GPT-3 50,257 0.4858 0.7522

Qwen-1.5 151646 1.2989 0.7865

StarCoder 49152 0.9344 0.6513

在常

用的开源模

型中，不同模

型采用了不

同的分词器

，这些分词器

具有各自

的

特点和性能

。它们的质量

受到多种因

素的影响，包

括词表的大

小、分词的效

率等

属性。表

3.1是对常见开

源大语言模

型的分词器

的对比分析

，其中中文语

料库节选

自

《朱自清散文

》

3，英文语料库

来自莫泊桑

短篇小说《项

链》 4。我们可以

观察

到，像 DeepSeek

[6]、Qwen [41] 这

类中文开源

大语言模型

，对中文分词

进行了优

化

，平均每个

Token 能

够表示 1.3 个字

（每个字仅需

0.7

个 Token 即可表示

），一些

常用词

语和成语甚

至可以直接

用一个

Token 来表

示。相比之下

，以英文为主

要语料

的模

型，如 GPT-4、LLaMA

系列，对

中文的支持

度较弱，分词

效率不高。在

英文

3https://www.sohu.com/a/746456997_120075260.

4https://americanliterature.com/author/guy-de-maupassant/short-story/

the-diamond-necklace

104

张超 毛

玉仁 胡中豪

中，由于存在

“ly”、“ist”等后缀

Token，一个

英文单词通

常需要用 1 个

及以上的

Token

来

表示。单个 Token 承

载更多的语

义，模型在表

达同样的文

本时，只需要

输

出更少的

Token，显著提升了

推理效率。

通

过这种对比

，我们可以清

晰地看到不

同模型分词

器在处理不

同语言时的

效

率，这对于

选择合适的

模型和优化

模型性能具

有重要的指

导意义。

在完

成分词之后

，这些 Token

随后会

经过模型的

嵌入矩阵（Embedding Matrix）

处

理，转化为固

定大小的表

征向量。这些

向量序列被

直接输入到

模型中，供模

型理

解和处

理。在模型生

成阶段，模型

会根据输入

的向量序列

计算出词表

中每个词的

概率分布。模

型从这些概

率分布中选

择并输出对

应的

Token，这些 Token 再

被转换

为相

应的文本内

容。

上述通过

分词技术将

文本分割成

Token，再将 Token 转化为

特征向量，在

高维

空间中

表征这些文

本的处理流

程，使得语言

模型能够捕

捉文本的深

层语义结构

，并

有效地处

理和学习各

种语言结构

，从简单的词

汇到复杂的

句式和语境

。

3.1.4 Prompt 工程的意义

Prompt

工程提供了

一种高效且

灵活的途径

来执行自然

语言处理任

务。它允许

我

们无需对模

型进行微调

，便能有效地

完成既定任

务，避免微调

带来的巨大

开销。

通过精

心设计的 Prompt，我

们能够激发

大型语言模

型的内在潜

力，使其在垂

域任

务、数据

增强、智能代

理等多个领

域发挥出卓

越的性能。

1. 垂

域任务

应用

Prompt

工程来引导

大语言模型

完成垂直领

域任务，可以

避免针对每

个任

务进行

特定微调。不

仅可以避免

微调模型的

高昂计算成

本，还可以减

少对标注数

据

的依赖。使

得大语言模

型可以更好

的应用在垂

直领域任务

中。例如，在 Text-to-SQL

任

务中，我们可

以应用 Prompt 工程

的技巧，引导

大语言模型

根据用户输

入的文本

直

接生成高质

量的

SQL 查询，而

无需进行有

监督微调。基

于 GPT 模型的

Prompt

105

第

3 章

Prompt 工程

工程

方法在 Spider

[44] 榜单

上取得了突

破性成绩，超

越了传统的

微调方法。此

外，

在知识密

集型任务问

答领域 MMLU

[9] 等多

个领域，基于

Prompt 工程的方法

也取

得最佳

效果。

2. 数据增

强

应用 Prompt

工程

通过大语言

模型来进行

数据增强，不

仅能够提升

现有数据集

的质量，还能

够生成新的

高质量数据

。这些数据可

以用于训练

和优化其它

模型，以

将大

语言模型的

能力以合成

数据的方法

“蒸馏”到其他

模型上。例如

，我们可以引

导 ChatGPT 模型生成

包含丰富推

理步骤的数

据集，用于增

强金融领域

Text-to-SQL

模型的推理

能力 [45]。此外，通

过精心设计

的提示，还能

生成包含复

杂指令的数

据

集，如 Alpaca

[32] 和 Evol-Instruct [21]。将

这些合成的

数据集用于

微调参数量

较小

的模型

，可以其在保

持较小模型

尺寸和低计

算成本的同

时，接近大型

模型的性能

。

3. 智能代理

应

用

Prompt 工程可以

将大语言模

型构建为智

能代理（Intelligent Agent，IA）5。

智能

代理，又叫做

智能体，能够

感知环境、自

主采取行动

以实现目标

，并通过学习

或获取知识

来提高其性

能。在智能代

理进行感知

环境、采取行

动、学习知识

的过程

中，都

离不开 Prompt 工程

。例如，斯坦福

大学利用 GPT-4

模

拟了一个虚

拟西部小

镇

[25]，多个基于 GPT-4 的

智能体在其

中生活和互

动，他们根据

自己的角色

和目

标自主

行动，进行交

流，解决问题

，并推动小镇

的发展。整个

虚拟西部小

镇的运转

都

是由 Prompt 工程驱

动的。

本节探

讨了 Prompt 的概念

，Prompt 工程的概念

以及意义，揭

示了

Prompt 在

大语

言模型应用

中的关键作

用和广阔潜

力。接下来，我

们将进一步

拓展这一主

题：

第3.2节将探

索上下文学

习的相关内

容，揭示其在

提升模型理

解和响应能

力中的作

用

；第3.3节将详细

介绍思维链

提示方法及

其变种，展示

如何通过这

些方法增强

模

5https://en.wikipedia.org/wiki/Intelligent_agent

106

张超

毛玉

仁 胡中豪

型

的逻辑推理

和问题解决

能力；第3.4节将

分享构建有

效 Prompt

的技巧，指

导读者

如何

设计 Prompt 以激发

模型生成更

优质的内容

；第3.5节将具体

展示

Prompt 工程

在

大语言模型

中的实际应

用，通过实例

阐释其在不

同场景下的

应用策略和

效果。

3.2

上下文

学习

随着模

型训练数据

规模和参数

数量的持续

扩大，大语言

模型涌现出

了上下文

学

习（In-Context Learning，ICL）能力。其使

得语言模型

能够通过给

定的任务说

明

或示例等

信息来掌握

处理新任务

的能力。引入

上下文学习

，我们不再需

要针对某

个

任务训练一

个模型或者

在预训练模

型上进行费

时费力的微

调，就可以快

速适应

一些

下游任务。这

使得用户可

以仅仅通过

页面或者 API

的

方式即可利

用大语言模

型来解决下

游任务，为“语

言模型即服

务”（LLM as a Service）模式奠定

了坚实的

能

力基础。本节

从上下文学

习的定义，演

示示例选择

，和影响其性

能的因素，对

上

下文学习

展开介绍。

3.2.1 上

下文学习的

定义

上下文

学习（In-Context Learning, ICL）[2] 是一种

通过构造特

定的

Prompt，来

使得

语言模型理

解并学习下

游任务的范

式，这些特定

的 Prompt 中可以包

含演示示

例

，任务说明等

元素。上下文

学习实现的

关键在于如

何设计有效

的 Prompt，以引

导模

型理解任务

的上下文和

目标。通常，这

些 Prompt

会包含任

务说明以及

一系列

的示

例，模型能够

从这些上下

文信息中学

习任务的逻

辑和规则，从

而在没有额

外

训练的情

况下，生成符

合任务要求

的输出。基于

以上优点，上

下文学习被

广泛应用

于

解决垂域任

务，数据增强

，智能代理等

应用中。

在上

下文学习中

，Prompt 通常包含几

个与待解决

任务相关的

演示示例，以

展

示任务输

入与预期输

出。这些示例

按照特定顺

序组成上下

文，并与问题

拼接共同

107

第

3 章 Prompt 工程

浣熊

爸爸背了一

箱干脆面走

来，小浣熊手

舞足蹈迎接

爸爸。 \n积极

小

浣熊吃了一

包麻辣味的

干脆面，辣得

肚子疼。 \n消极

小浣熊吃了

一包烧烤味

的干脆面，脸

上露出了满

意的笑容。

\n积

极

小浣熊连

续吃了20包烧

烤味的干脆

面，撑得肚子

疼。 \n LLM

消极

示例

1:

问题：

示例

2:

示

例 3:

(a)

上下文学

习做分类任

务。

Q：小浣熊有

8包干脆面，吃

了6包，还剩下

几包？

A：2包

Q：箱子

里有24包干脆

面，小浣熊每

天吃2包，5天后

还剩多少包

？

A：

14包

示例 :

问题

： LLM

(b) 上下文学习

做生成任务

。

图 3.5: 上下文学

习示例。

组成

Prompt

输入给大语

言模型。大语

言模型从上

下文中学习

任务范式，同

时利用

模型

自身的能力

对任务进行

作答。在图 3.5的

例子 (a)

中，模型

被用于文本

情感分

类任

务，给定一段

文本，模型能

够判断其情

感倾向，识别

出文本表达

的是积极还

是

消极情绪

。图 3.5的例子

(b) 则

展示了数学

运算任务，模

型会仿照示

例的形式，直

接

给出对应

的运算结果

。按照示例数

量的不同，上

下文学习可

以呈现出多

种形式：零

样

本（Zero-shot）上下文学

习、单样本（One-shot）上

下文学习和

少样本（Few-shot）

上下

文学习 [2]，如图

3.6所示。

零样本

上下文学习

：在此种学习

方式下，仅需

向模型提供

任务说明，而

无需

提供任

何示例。其具

有强大的场

景泛化能力

。但零样本学

习的性能完

全依赖

于大

语言模型的

能力，并且在

处理任务时

可能表现欠

佳。

单样本上

下文学习：这

种方式仅需

为模型提供

一个示例，贴

合人类“举一

反

三”的学习

模式。不过，单

样本学习的

效果强依赖

于示例相对

于任务的代

表

性。

少样本

上下文学习

：这种方法通

过为模型提

供少量的示

例（通常为几

个至十

几个

），显著提升模

型在特定任

务上的表现

。但在，示例的

增加会显著

增加大

语言

模型推理时

的计算成本

。示例的代表

性和多样性

也将影响其

生成效果。

108

张

超 毛玉仁 胡

中豪

判断下

面句子的情

感为积极还

是消极.

小浣

熊连续吃了

20包烧烤味的

干脆面，撑得

肚子疼。

Zero-shot

判断

下面句子的

情感为积极

还是消极. 待

分类的句子

：小浣熊连续

吃了20包烧烤

味的干脆面

，撑得肚子疼

。

判断下面句

子的情感为

积极还是消

极. 待分类的

句子：小浣熊

连续吃了20包

烧烤味的干

脆面，撑得肚

子疼。

示例：小

浣熊吃了一

包麻辣味的

干脆面，辣得

肚子疼。 \n消极

示例1：浣熊爸

爸背了一箱

干脆面走来

，小浣熊手舞

足蹈迎接爸

爸。

\n积极

示例

2：小浣熊吃了

一包麻辣味

的干脆面，辣

得肚子疼。 \n消

极

示例3：小浣

熊吃了一包

烧烤味的干

脆面，脸上露

出了满意的

笑容。

\n积极

针

对此问题有

如下示例：

针

对此问题有

如下示例：

One-shot

Few-shot

图

3.6: 三种上下文

学习形式的

示例。

尽管上

下文学习在

许多任务中

表现出色，但

它为何奏效

仍然是一个

重要的研

究

问题。对此，斯

坦福大学的

一项研究 [40] 提

供了一种解

释——“将上下文

学习视

为隐

式贝叶斯推

理”。在大语言

模型的预训

练阶段，模型

从大量文本

中学习潜在

的

概念。当运

用上下文学

习进行推理

时，大语言模

型借助演示

示例来“锚定

”其在预

训练

期间所习得

的相关概念

，从而进行上

下文学习，并

对问题进行

预测。以图 3.5

为

例，模型之所

以能给出正

确答案，是因

为模型在预

训练时已经

学习到与情

感相关

的概

念，比如积极

情感的表现

形式（满意的

笑容，手舞足

蹈.....）、句法结构

和句法

关系

等等，当模型

在推理时，借

助“浣熊吃了

一包麻辣味

的干脆面，辣

得肚子疼。

\n 消

极”等示例“锚

定”到情感等

相关概念，并

基于这些概

念，给出问题

答案。

109

第 3 章

Prompt 工

程

3.2.2 演示示例

选择

在上下

文学习中，演

示示例在引

导大语言模

型理解任务

中扮演着重

要作用，其

内

容和质量直

接影响着学

习效果。因此

，合理选择演

示示例对提

升上下文学

习性

能至关

重要。演示示

例选择主要

依靠相似性

和多样性 [20]：

相

似性是指精

心挑选出与

待解决问题

最为相近的

示例。相似性

可以从多个

层

面进行度

量，如语言层

面的相似性

（包括关键字

匹配或语义

相似度匹配

）、结

构相似性

等等。通过选

取相似的示

例，能够为模

型提供与待

解决问题接

近的

参照，使

大语言模型

更易理解该

问题。

多样性

则要求所选

的示例涵盖

尽量广的内

容，扩大演示

示例对待解

决问题的

覆

盖范围。多样

化的示例能

够帮助模型

从不同的角

度去理解任

务，增强其应

对各种问题

的能力。

除了

相似性和多

样性，在某些

任务中，还需

对任务相关

的因素进行

考虑。本节

主

要关注相似

性和多样性

两个因素，并

探讨基于相

似性和多样

性如何从大

量候选

示例

中选择出合

适的演示示

例。接下来对

基于相似性

和多样性的

三类示例选

择方

法 [20] 展开

介绍：

1. 直接检

索

给定一组

候选示例，直

接检索的方

法依据候选

示例与待解

决问题间的

相似性

对候

选示例进行

排序，然后选

取排名靠前

的

K 个示例。直

接检索的代

表性方法是

KATE [17]。如图 3.7

所示，KATE 利

用 RoBERTa 对待解决

问题和候选

示例（移除

标

签）进行编码

。然后通过计

算解决问题

编码和候选

示例编码间

的向量余弦

相似

度对二

者的相似度

进行评分。基

于此评分，选

择评分最高

的 K 个示例作

为上下文

学

习的演示示

例。直接检索

的方法简单

易操作，是目

前应用广泛

的示例选择

策略

之一。但

是，其未对示

例的多样性

进行考虑，选

择出的示例

可能趋向同

质化。

110

张超

毛

玉仁 胡中豪

小浣熊连续

吃了20包烧烤

味的干脆

面

，撑得肚子疼

。

浣熊爸爸背

了一箱干脆

面走来……

海龟

在沙滩上找

到了12块石头

…… 小浣熊吃了

一包麻辣味

的干脆…… ……

候选

示例

问题（Q）

检

索topK个

向量编

码

向量编码

所选示例

浣

熊爸爸背了

一箱干脆

面

走来，小浣熊

手舞足

蹈地

去迎接。\n积极

小浣熊吃了

一包麻辣味

的干脆面，辣

的肚子疼。

\n

消

极

…… Q

1.

2.

3.

2

1

3

图 3.7: 直接检

索。

2. 聚类检索

为缓解直接

检索中存在

的样例趋同

的问题，聚类

检索方法采

用先聚类后

检索

的方法

来保证检索

结果的多样

性。其先把所

有候选示例

划分为 K

个簇

，然后从每

个

簇中选取最

为相似的一

个示例。这样

可以有效避

免选择出多

个相似的示

例，从

而保障

了多样性。Self-Prompting [15]

是

其中的代表

性方法。如图

3.8 所示，Self￾Prompting 首先将

候选示例和

待解决问题

编码成向量

形式，接着运

用 K-Means

算法

把示

例集合聚为

K 个簇。依照问

题与示例之

间的余弦相

似度，从每个

簇中选取与

问题最相似

的示例，由此

得到 K

个示例

。虽然聚类检

索方法提高

了示例的多

样性，

但因为

有些簇与问

题可能并不

相似，导致选

择的示例的

相似性可能

不够高。

小浣

熊连续吃了

20包烧烤味的

干脆

面，撑得

肚子疼。

浣熊

爸爸背了一

箱干脆面走

来…… 大白兔在

沙滩上找到

12个椰子…… 大白

兔愉快滴拆

了一包干脆

面…… ……

候选示例

问题（Q）

编码&聚

类

向量编码

所选示例

浣

熊爸爸背了

一箱干脆

面

走来，小浣熊

手舞足

蹈地

去迎接。\n积极

大白兔愉快

地拆了一包

干脆面，可是

发现干脆

面

过期了。\n消极

……

在每个聚类

中检索

Q

1.

2.

3.

1

2

3

图

3.8: 聚

类检索。

111

第

3 章

Prompt 工程

3.

迭代检

索

直接检索

和聚类检索

在相似性和

多样性之间

往往顾此失

彼。为了兼顾

相似性

多样

性，迭代检索

策略应运而

生。迭代检索

首先挑选与

问题高度相

似的示例，随

后在迭代过

程中，结合当

前问题和已

选示例，动态

选择下一个

示例，从而确

保所

选示例

的相似性和

多样性。RetICL

[28] 是迭

代检索的代

表性方法，如

图 3.9所示。

RetICL

根据

当前问题初

始化基于 LSTM [10] 的

检索器内部

状态，并选择

一个示例。

接

着根据当前

问题和所选

示例集更新

检索器内部

状态，并选择

下一个示例

。这一

过程不

断迭代，直到

得到 k 个示例

。尽管迭代检

索在计算上

相对复杂，但

其能够生

成

更优的示例

集，在复杂任

务中展现出

更好的适应

性和灵活性

。

小浣熊连续

吃了20包烧烤

味的干脆

面

，撑得肚子疼

。

浣熊爸爸背

了一箱干脆

面走来……

海龟

在沙滩上找

到了12块石头

…… 大白兔愉快

滴拆了一包

干脆面…… ……

候选

示例

问题

所

选示例

浣熊

爸爸背了一

箱干脆

面走

来，小浣熊手

舞足

蹈地去

迎接。\n积极

大

白兔愉快地

拆了一包

干

脆面，可是发

现干脆

面过

期了。\n消极

……

迭

代选择下一

个示例

使用

示例增强查

询

浣熊爸爸

……

大白兔……

……

图 3.9:

迭

代检索。

除了

在示例选择

策略上有所

不同外，现有

的示例选择

方法在检索

器的选择和

设计上亦呈

现出差异。一

些方法采用

现成的检索

器，而另一些

方法则为了

追求更

卓越

的性能，选择

在特定语料

库上对检索

器进行微调

。关于检索器

的深入介绍

及

其分类，将

在第六章

6.8 中

进行详尽阐

述。

3.2.3 性能影响

因素

通过精

心设计示例

选择策略，上

下文学习的

效果可以得

到显著提升

。但是，除

了示

例选择以外

，上下文学习

的性能仍受

到多种因素

的共同影响

。这些因素涉

及

括预训练

数据、预训练

模型，以及演

示示例等多

个方面 [48]。本小

节将讨论这

些关

键因素

如何影响上

下文学习的

效果。

112

张超 毛

玉仁

胡中豪

1. 预训练数据

的影响

预训

练数据是上

下文学习能

力的来源，深

刻影响着上

下文学习的

性能。对预

训

练数据而言

，以下三方面

因素是影响

上下文学习

性能的关键

：

领域丰富度

：预训练数据

的所覆盖的

领域的丰富

度直接影响

模型的领域

泛化

能力。在

丰富的跨领

域语料库进

行预训练的

模型具备更

稳定的上下

文学习能

力

。而单一领域

的语料库可

能限制模型

的适应性，即

使该领域与

目标任务高

度相关，也无

法保证最佳

的上下文学

习性能 [31]。

任务

多样性：预训

练数据中的

任务多样性

是提升上下

文学习性能

的重要因素

。

多样化的任

务类型有助

于模型学习

到更广泛的

知识和技能

，增强其任务

泛化

能力，从

而在面对新

任务时表现

也更为出色

[26]。

训练数据的

分布特性：训

练数据中存

在突发性分

布和罕见类

别时，能够增

强

模型的上

下文学习能

力。突发性分

布使得“文本

-标签映射”的

数据模式在

整

个训练过

程中得以反

复出现，罕见

类别增强模

型处理少见

或新颖输入

的能力，

从而

提升模型上

下文学习的

表现 [4]。

2. 预训练

模型的影响

预训练模型

对上下文学

习的性能影

响主要体现

在模型参数

规模上。当模

型参

数达到

一定的规模

时，上下文学

习才能得以

涌现。通常，模

型的参数数

量需达到亿

级别及以上

。常见的拥有

上下文学习

能力的模型

中，规模最小

的是来自阿

里巴巴

通义

实验室的

Qwen2-0.5B 模

型，具有 5 亿参

数。一般而言

，模型的规模

越大，其

上下

文学习性能

也越强 [39]。此外

，模型的架构

和训练策略

也是影响上

下文学习性

能的重要因

素。

3. 演示示例

的影响

在 3.2.2节

中，我们已经

讨论了演示

示例选择对

上下文学习

的重要性。接

下来，

我们将

继续探讨演

示示例的格

式、输入-标签

映射、示例数

量及顺序对

上下文学习

的影响。

113

第 3 章

Prompt 工程

示例格

式。不同的任

务对于示例

格式的要求

不同。如图3.5中

展示的用上

下文学习

做

情感分类的

例子，我们只

需要给出输

入以及输出

。但是，一些复

杂推理任务

，例

如算术、代

码等，仅仅给

出输入和输

出不足以让

模型掌握其

中的推理过

程。在这种

情

况下，以思维

链的形式构

造示例，即在

输入和输出

之间添加中

间推理步骤

，能帮

助模型

逐步推理并

学习到更复

杂的映射关

系，思维链将

在3.3 详细介绍

。

输入-输出映

射的正确性

。对于一个包

含输入、输出

的示例，大语

言模型旨在

从中

学习到

输入-输出映

射，以完成目

标任务。如果

给定示例中

的输入-输出

映射是错误

的，势必会对

上下文学习

的效果产生

影响。例如在

情感分类任

务中，将积极

的文本

错误

地标记为消

极，模型可能

会学习到这

种错误的映

射方式，从而

在下游任务

中

产生错误

。对输入-输出

映射错误的

敏感性与模

型规模大小

有关 [14, 43]。较大的

模

型在上下

文学习中对

输入-输出映

射的正确性

表现出更高

的敏感性 [14]。相

比之下，

较小

的模型输入

-输出映射错

误的敏感性

较弱 [24,

39]。

演示示

例的数量和

顺序。增加演

示示例的数

量通常能够

提升上下文

学习性能，但

随着示例数

量的增多，性

能提升的速

率会逐渐减

缓 [23]。此外，相较

于分类任务

，

生成任务更

能从增加的

示例数量中

获益

[16]。此外，演

示示例的顺

序同样是影

响上

下文学

习性能的关

键因素，不同

示例顺序下

的模型表现

存在显著差

异。最优的示

例顺序具有

模型依赖性

，即对某一模

型有效的示

例顺序未必

适用于其他

模型 [19]。

同时，示

例顺序的选

择也受到所

使用数据集

的特定特性

影响

[17]。

除上述

因素外，Prompt 中的

任务说明的

质量也直接

影响上下文

学习的效果

。清

晰、明确的

任务说明能

够为模型提

供明确指导

，从而提升上

下文学习的

性能

[43]。

因此，在

设计演示示

例和任务说

明时，应综合

考虑这些因

素，以优化模

型的表现。

本

节介绍了上

下文学习，区

分了零样本

、单样本和少

样本三种形

式。探讨了直

接检索、聚类

检索和迭代

检索三种示

例选择策略

，分析其优缺

点及代表性

方法。最

后从

预训练数据

、模型本身及

演示示例等

方面分析影

响上下文学

习性能的因

素。

114

张超 毛玉

仁 胡中豪

3.3 思

维链

随着语

言模型参数

规模的持续

扩张，其可以

更好的捕捉

语言特征和

结构，从

而在

语义分析、文

本分类、机器

翻译等自然

语言处理任

务中的表现

显著增强。但

是，在面对算

术求解、常识

判断和符号

推理等需要

复杂推理能

力的任务时

，模型

参数规

模的增长并

未带来预期

的性能突破

，这种现象被

称作“Flat Scaling Curves”

[38]。这表明

，仅靠模型规

模的扩大不

足以解决所

有问题，我们

需要探索新

的方法

以提

升模型的推

理能力和智

能水平。人类

在解决复杂

问题时，通常

会逐步构建

推

理路径以

导出最终答

案。基于这一

理念，一种创

新的 Prompt 范式——思

维链提示

（Chain-of-Thought，CoT） [38] 被

用于引导模

型进行逐步

推理。CoT 可以显

著提升

大语

言模型处理

复杂任务中

的表现，从而

突破“Flat Scaling Curves”的限制

，激发

大语言

模型的内在

推理潜能。

3.3.1 思

维链提示的

定义

思维链

提示（Chain-of-Thought，CoT）[38] 通过模

拟人类解决

复杂问题时

的思

考过程

，引导大语言

模型在生成

答案的过程

中引入一系

列的中间推

理步骤。这种

方法不仅能

够显著提升

模型在推理

任务上的表

现，而且还能

够揭示模型

在处理复

杂

问题时的内

部逻辑和推

理路径。

CoT 方法

的核心是构

造合适的

Prompt 以

触发大语言

模型一步一

步生成推理

路

径，并生成

最终答案。早

期方法在构

造 Prompt

时，加入少

量包含推理

过程的样本

示例（Few-Shot Demonstrations） [38]，来引导

模型一步一

步生成答案

。在这些示

例

中，研究者精

心编写在相

关问题上的

推理过程，供

模型模仿、学

习。这种方法

使

得模型能

够从这些示

例中学习如

何生成推理

步骤，一步步

输出答案。图

3.10展示

了一个

用于求解数

学问题的 CoT 形

式的

Prompt 的例子

。其中，样例给

出了与待求

115

第 3

章 Prompt 工程

Q：一

只大白兔在

森林里找到

了12罐奶糖，然

后它不小心

打翻了4罐。之

后，它又找到

了6罐奶糖。

大

白兔总共找

到了多少罐

奶糖？

A：大白兔

首先找到的

奶糖数为12罐

，打翻了4罐，剩

下12 - 4

= 8罐。后来又

找到6罐。所以

，大

白兔总共

找到的奶糖

数为8 +

6 = 14罐。

Q：一只

大象在森林

里找到了15瓶

苏打水，它不

小心打翻了

5瓶。之后，它又

找到了8瓶苏

打水，但

不小

心又打翻了

2瓶。大象总共

还剩下多少

瓶苏打水？

A：大

象最初找到

的苏打水数

为15瓶，打翻了

5瓶，剩下15 - 5

= 10瓶。后

来又找到8瓶

，但再次

打翻

了2瓶，剩下8 -

2 = 6瓶

。所以，大象总

共剩下的苏

打水数为10 +

6 = 16瓶

。

Q：浣熊爸爸有

8包干脆面，给

浣熊妈妈3包

，然后把剩下

的干脆面处

理了，又获得

了6包干脆面

，

自己吃了两

包，剩下的都

给小浣熊，请

问小浣熊手

里有几包干

脆面？

A：

浣熊爸

爸最初有8包

干脆面，给了

浣熊妈妈3包

，剩下8 -

3 = 5包。然后

他处理了这

5包干脆面，

又

获得了6包新

的，吃了2包，剩

下6

- 2 = 4包。所以，小

浣熊手里有

4包干脆面。

图

3.10: 包含少量样

本示例的 CoT 提

示示例。

解问

题相关的数

学问题的解

题步骤作为

参考，大语言

模型会模仿

此样例对复

杂的

数学计

算一步一步

进行求解。通

过引入 CoT，大语

言模型在解

算术求解、常

识判断

和符

号推理等复

杂问题上性

能显著提升

。并且在

CoT 的加

持下，大语言

模型处理

复

杂问题的能

力随着模型

参数规模的

变大而增强

。

在

CoT 核心思想

的指引下，衍

生出了一系

列的扩展的

方法。这些扩

展的方法

按

照其推理方

式的不同，可

以归纳为三

种模式：按部

就班、三思后

行和集思广

益。

这几种模

式的对比如

图

3.11所示。

按部

就班。在按部

就班模式中

，模型一步接

着一步地进

行推理，推理

路径形

成了

一条逻辑连

贯的链条。在

这种模式下

，模型像是在

遵循一条预

设的逻辑

路

径，“按部就班

”的一步步向

前。这种模式

以

CoT [38]、Zero-Shot CoT [12]、

Auto-CoT [46] 等方法为

代表。

三思后

行。在三思后

行模式中，模

型每一步都

停下来估当

前的情况，然

后从

多个推

理方向中选

择出下一步

的行进方向

。在这种模式

下，模型像是

在探索

一片

未知的森林

，模型在每一

步都会停下

来评估周围

的环境，“三思

后行”以

找出

最佳推理路

径。这种模式

以 ToT

[42]、GoT [1] 等方法为

代表。

116

张超 毛

玉仁 胡中豪

大多数投票

输入内容

输

出回答

输入

内容 CoT样例/触

发词

输出回

答

输入内容

输出回答

输

入内容

输出

回答

标准提

示 按部就班

三思后行

集

思广益

图 3.11: 不

同

CoT 结构的对

比。

集思广益

。在集思广益

模式中，模型

同时生成多

条推理路径

并得到多个

结果，

然后整

合这些结果

，得到一个更

为全面和准

确的答案。在

这种模式下

，模型像

是在

召开一场智

者的会议，每

个智者都带

来了自己的

见解，最终通

过讨论和

整

合，“集思广益

”得出一个更

优的结论。这

一类模式以

Self-Consistency [36]

等方法为代

表。

3.3.2 按部就班

按部就班模

式强调的是

逻辑的连贯

性和步骤的

顺序性。在这

种模式下，模

型

一步接着

一步的进行

推理，最终得

到结论。其确

保了推理过

程的清晰和

有序，使

得模

型的决策过

程更加透明

和可预测。原

始的少样本

思维链（CoT）方法

就采用了

按

部就班模式

。其通过手工

构造几个一

步一步推理

回答问题的

例子作为示

例放入

Prompt 中，来

引导模型一

步一步生成

推理步骤，并

生成最终的

答案。这种方

法在提

升模

型推理能力

方面取得了

一定的成功

，但是需要费

时费力地手

工编写大量

CoT

示例，并且过

度依赖于 CoT 的

编写质量。针

对这些问题

，研究者在原

始 CoT

的基

础上

进行了扩展

，本节将介绍

CoT 的两种变体

：Zero-Shot CoT

和 Auto-CoT。

1. Zero-Shot

CoT

Zero-Shot CoT [12]

通过简单

的提示，如“Let’s think step by

step”，引

导模型自

行

生成一条推

理链。其无需

手工标注的

CoT 示例，减少了

对人工示例

的依赖，多

个

推理任务上

展现出了与

原始少样本

CoT

相媲美甚至

更优的性能

。

117

第 3

章 Prompt 工程

Q：浣

熊爸爸有8包

干脆面，给浣

熊妈妈3包，然

后……请问小浣

熊手里有几

包干脆面？

A：让

我们一步一

步思考。

浣熊

爸爸最初有

8包干脆面，……所

以，小浣熊手

里有4包干脆

面。

因此，最终

答案为：

Q：浣熊

爸爸有8包干

脆面，给浣熊

妈妈3包，然

后

把剩下的干

脆面处理了

，又获得了6包

干脆

面，自己

吃了两包，剩

下的都给小

浣熊，请问小

浣熊手里有

几包干脆面

？

A：让我们一步

一步思考。

4.

浣

熊爸爸最初

有8包干脆面

，给了浣熊妈

妈3包，

剩下8 - 3

= 5包

。然后他处理

了这5包干脆

面，

又获得了

6包新的，吃了

2包，剩下6 -

2 = 4

包。所

以，小浣熊手

里有4包干脆

面。

第一阶段

：推理过程生

成 第二阶段

：答案生成

图

3.12: Zero-Shot

CoT 提示的流程

。

Zero-Shot CoT

整体流程如

图 3.12所示，它使

用两阶段方

法来回答问

题。首先，

在第

一阶段，在问

题后面跟上

一句“让我们

一步一步思

考”或者“Let’s think

step by

step”来作

为 CoT

的提示触

发词，来指示

大语言模型

先生成中间

推理步骤，再

生成

最后的

答案。在第二

阶段，把原始

的问题以及

第一阶段生

成的推理步

骤拼接在一

起，在末尾加

上一句“Therefore, the answer

is”或者

“因此，最终答

案为”，把这些

内容输给大

语言模型，让

他输出最终

的答案。通过

这样的方式

，无需人工标

注 CoT

数据，即可

激发大语言

模型内在的

推理能力。大

语言模型能

够逐步推理

出正确的

答

案，展现了

Zero-Shot CoT 在

提升模型推

理能力方面

的潜力。

2.

Auto CoT

在 Zero-Shot

CoT 的

基础之上，Auto-CoT [46] 引

入与待解决

问题相关的

问题及

其推

理链作为示

例，以继续提

升 CoT 的效果。相

关示例的生

成过程是由

大语言模

型

自动完成的

，无需手工标

注。Auto-CoT

的流程如

图 3.13所示，其包

含以下步骤

：

Q：一只大白兔

在森林里找

到了12罐奶糖

，然后它不小

心打翻了4罐

。之后，它又找

到了6罐奶糖

。大白兔总

共

找到了多少

罐奶糖？

A：让我

们一步一步

思考。大白兔

首先找到的

奶糖数为

12罐

，打翻4罐，剩下

12 - 4

= 8罐。后来找到

6罐。

所以，大白

兔总共找到

的奶糖数为

8 +

6 = 14罐。

……

Q：浣熊爸爸

有8包干脆面

，给浣熊妈妈

3包，然后把

剩

下的干脆面

处理了，又获

得了6包干脆

面，自己吃了

两包，剩下的

都给小浣熊

，请问小浣熊

手里有几包

干脆

面？

A：让我

们一步一步

思考。

生成答

案

浣熊爸爸

有8包干脆面

，给浣熊妈妈

3包，然后……请问

小浣熊手里

有几

包干脆

面？

一只大白

兔在森林找

到12罐奶……

一只

金丝猴在森

林里找到3堆

…… 海龟在沙滩

上找到了12块

石头…… ……

构造样

例

浣熊爸爸

最初有8

包干

脆面，给了

浣

熊妈妈3包，剩

下8 -

3 = 5

包。然后他

处理

了这5包

干脆面，

又获

得了6包新

的

，吃了2包，剩

下

6

- 2 = 4包。

所以，小浣

熊有4

包干脆

面。

问题库

用

户提问

问题

聚类 提示构

造 最终答案

图 3.13:

Auto-CoT 提示的流

程。

118

张超

毛玉

仁 胡中豪

利

用聚类技术

从问题库中

筛选出与用

户提问位于

一个簇中的

问题。

然后，借

助

Zero-Shot CoT 的方式，为

筛选出的问

题生成推理

链，形成示例

。

这些示例包

含了不同问

题及其对应

的推理内容

，可为模型提

供不同解题

思路，

辅助模

型做出更为

审慎的推理

。

在这些示例

的基础上，Auto-CoT 以

“让我们一步

一步思考” 引

导大语言模

型

生成针对

用户问题的

推理链和答

案。

3.3.3 三思后行

三思后行模

式强调的是

在决策过程

中的融入审

慎和灵活性

。在这种模式

下，模

型在每

一步都会停

下来评估当

前的情况，判

断是否需要

调整推理方

向。这种模式

的核心在于

允许模型在

遇到困难或

不确定性时

进行回溯和

重新选择，确

保决策过

程

的稳健性和

适应性。其模

仿了人类在

解决问题时

，会有一个反

复选择回溯

的过

程。人们

会不断从多

个候选答案

中选择最好

的那个，并且

如果一条思

维路子走不

通，就会回溯

到最开始的

地方，选择另

一种思维路

子进行下去

。基于这种现

实生活

的观

察，研究者在

CoT 的基础上提

出了思维树

（Tree

of Thoughts, ToT）[42]、思维

图（Graph

of Thoughts, GoT） [1]

等三

思后行模式

下的 CoT 变体。

ToT

将

推理过程构

造为一棵思

维树，其从以

下四个角度

对思维树进

行构造。

拆解

。将复杂问题

拆分成多个

简单子问题

，每个子问题

的解答过程

对应一个

思

维过程。思维

过程拆解的

形式和粒度

依任务类别

而定，例如在

数学推理任

务上以一行

等式作为一

个思维过程

，在创意写作

任务上以内

容提纲作为

思维

过程。

衍

生。模型需要

根据当前子

问题生成可

能的下一步

推理方向。衍

生有两种模

式：样本启发

和命令提示

。样本启发以

多个独立的

示例作为上

下文，增大衍

生空间，适合

于创意写作

等思维空间

宽泛的任务

；命令提示在

Prompt 中指明

规则

和要求，限制

衍生空间，适

用于 24

点游戏

等思维空间

受限的任务

。

119

第 3

章 Prompt 工程

评

估。利用模型

评估推理节

点合理性。根

据任务是否

便于量化评

分，选择投

票

或打分模式

。投票模式中

，模型在多节

点中选择，依

据票数决定

保留哪些

节

点；打分模式

中，模型对节

点进行评分

，依据评分结

果决定节点

的保留。

搜索

。从一个或多

个当前状态

出发，搜索通

往问题解决

方案的路径

。依据任

务特

点选择不同

搜索算法。可

以使用深度

优先搜索、广

度优先搜索

等经典搜

索

算法，也可以

使用 A* 搜索、蒙

特卡洛树搜

索等启发式

搜索算法。

4

+ 9 = 13

剩

余：10 13 13

{一个示例

}

输入：4 9 10 13

可能的

下一步：

评估

一下给出的

数字能否凑

到

24点（可以、可

能、不可能）

10

14： 10 + 14

= 24. 可

以

……

{更多示例

}

10 13 13

大模型

4+9=13，剩余

： 10 13

13

10 - 4

= 6，剩余： 6 9

13 ……

大模型

(13 -

10) * 13 =

3 * 13 =

39

10 + 13

+ 13 = 36。用这几个

数

字不太可能

凑到24点。

评估

结果：不可能

小浣熊参加

派对通过24点

游戏赢得干

脆面，眼前

摆

着四个数字

：4 9

10 13，判断能否凑

成24点。

10 -

4 = 6

剩余：6

9 13

…

13

- 9 = 4

剩

余：4 6

…

13

- 6 = 7

剩余：7 9

…

4

* 6 = 24

剩余

：24

4 + 6

= 10

剩余：10

提出提

示

思维生成

评估提示 思

维评估

图 3.14:

ToT 提

示的流程。

图

3.14通过 24

点游戏

展示了一个

ToT 的具体例子

。在这个例子

中，给定 4 个

数

字，然后让大

语言模型利

用加减乘除

（+-*/）四个运算符

来组合这四

个数字，使

得

最终的运算

结果为 24。首先

，ToT 基于当前所

剩下的数字

，通过上下文

学习让模

型

选择两个数

字作运算，并

生成多个方

案，在图上表

现为思维树

的多个子节

点。之

后以广

度优先搜搜

的方式遍历

每一个子节

点，评估当前

剩余的数字

是否能够凑

到

24 点，保留可

能凑出

24 点的

节点，这一步

也是通过上

下文学习的

方式来实现

的。

不断重复

上述两个步

骤，直到得出

最终合理的

结果。

在

ToT 的基

础上，GoT 将树扩

展为有向图

，以提供了每

个思维自我

评估修正

以

及思维聚合

的操作。该图

中，顶点代表

某个问题（初

始问题、中间

问题、最终问

题）的一个解

决方案，有向

边代表使用

“出节点”作为

直接输入，构

造出思维“入

节点”的过程

。GoT

相比于 ToT 的核

心优势是其

思维自我反

思，以及思维

聚合的能

力

，能够将来自

不同思维路

径的知识和

信息进行集

成，形成综合

的解决方案

。

120

张超 毛玉仁

胡中豪

3.3.4

集思

广益

集思广

益模式强调

的是通过汇

集多种不同

的观点和方

法来优化决

策过程。在

这

种模式下，模

型不仅仅依

赖于单一的

推理路径，而

是通过探索

多种可能的

解决

方案，从

中选择最优

的答案。这种

方法借鉴了

集体智慧的

概念，即通过

整合多个

独

立的思考结

果，可以得到

更全面、更准

确的结论。在

集体智慧的

启发下，研究

者在 CoT 的基础

上探讨了如

何通过自洽

性来增强模

型的推理能

力，提出了 Self￾Consistency

[36] 方

法。其引入多

样性的推理

路径并从中

选择最一致

的答案，从而

提高了模型

的推理准确

性。Self-Consistency 不依赖于

特定的 CoT

形式

，可以与其

他

CoT 方法兼容，共

同作用于模

型的推理过

程。

如图

3.15所示

，Self-Consistency 的实现过程

可以分为三

个步骤：(1) 在随

机采

样策略

下，使用

CoT 或 Zero-Shot CoT

的

方式来引导

大语言模型

针对待解决

问题生

成一

组多样化的

推理路径; (2) 针

对大语言模

型生成的每

个推理内容

，收集其最终

的答案，并统

计每个答案

在所有推理

路径中出现

的频率;

(3) 选择

出现频率最

高的

答案作

为最终的、最

一致的答案

。

Q：浣熊爸爸有

8包干脆

面，给

浣熊妈妈3包

，然

后把剩下

的干脆面处

理

了，又获得

了6包干脆

面

，自己吃了两

包，剩下

的都

给小浣熊，请

问小浣

熊手

里有几包干

脆面？

A：让我们

一步一步思

考。

大模型

浣

熊爸爸最初

有8包干脆面

，给了浣熊妈

妈3包，剩下8 - 3 =

5包

。然后他扔了

这些

干脆面

，又获得6包新

的，吃了2包，剩

下6 - 2

= 4包。所以，小

浣熊有4包干

脆面。

浣熊爸

爸有8包干脆

面，给了浣熊

妈妈3包，剩下

8 -

3 = 5包。然后他获

得了6包新的

干脆面，吃了

2包，剩下6 -

2 = 4包。所

以小浣熊手

里的干脆面

是5 +

4 = 9包。

浣熊爸

爸一开始有

8包干脆面，给

了浣熊妈妈

3包后，剩下5包

。他扔掉了这

些干脆

面，意

味着浣熊爸

爸没有干脆

面了。然后又

获得了6包新

的，吃了2包，剩

下4包。这

些剩

下的干脆面

都给了小浣

熊，所以小浣

熊有4包干脆

面。

基于结果

投票

4

生成

多

个回答

图 3.15:

Self-Consistency 的

流程。

本节探

讨了思维链

（Chain-of-Thought, CoT）的思想和模

式。CoT

的核心思

想

是在提示

中模拟人类

解决问题的

思考过程，在

Prompt 中嵌入解决

问题的推理

过程，

从而在

无需特定任

务微调的情

况下显著提

升模型在推

理任务上的

表现。CoT

方法

包

含了多种模

式：按部就班

、按部就班以

及集思广益

。这些模式可

以满足不同

的推

理需求

，增强了大语

言模型在复

杂任务中的

推理能力。

121

第

3 章 Prompt 工程

3.4 Prompt 技巧

基于上下文

学习和思维

链等 Prompt

工程技

术，本节将进

一步探讨可

用于进一

步

提升大语言

模型生成质

量的 Prompt 技巧，包

括合理归纳

提问、适时运

用思维链

（CoT）以

及巧妙运用

心理暗示等

。应用本节中

介绍的 Prompt 技巧

，可以引导模

型

生成更加

精准、符合预

期的内容，进

一步提升大

语言模型在

实际应用中

的表现。

3.4.1 规范

Prompt 编写

编写规

范的

Prompt 是我们

与大语言模

型进行有效

沟通的基础

。经典的 Prompt

通常

由任务说明

，上下文，问题

，输出格式等

部分中的一

个或几个组

成。以图

3.16中

这

个情感分类

的 Prompt 为例。在这

个例子中：

{"结

果"

: "消极"}

### 判断

下面句子的

情感为积极

还是消极。

针

对此问题有

如下示例：

# 示

例1：浣熊爸爸

背了一箱干

脆面走来，小

浣熊手舞足

蹈迎接爸爸

。 \n积极

# 示例2：小

浣熊吃了一

包麻辣味的

干脆面，辣得

肚子疼。 \n消极

#

示例3：小浣熊

吃了一包烧

烤味的干脆

面，脸上露出

了满意的笑

容。 \n积极

 ###

待分

类的句子：小

浣熊连续吃

了20包烧烤味

的干脆面，撑

得肚子疼。

 ### 以

{"结果"

: " "} 的JSON格式

返回最终结

果。

任务说明

上下文

问题

输出格式

图

3.16: 经典的

Prompt 示例

。

任务说明是

“### 判断下面句

子的情感为

积极还是消

极。”，它明确了

模型需

要完

成的任务；

上

下文是“针对

此问题有如

下示例：# 示例

1：浣熊爸爸背

了一箱干脆

面走

来，小浣

熊手舞足蹈

迎接爸爸。\n

积

极 \n# 示例 2：小浣

熊吃了一包

麻辣味

的干

脆面，辣得肚

子疼。\n 消极 \n #

示

例 3：小浣熊吃

了一包烧烤

味的干脆

122

张

超

毛玉仁 胡

中豪

面，脸上

露出了满意

的笑容。\n 积极

\n”。上下文提供

了帮助模型

理解和回

答

问题的示例

或背景信息

；

问题是“待分

类的句子：小

浣熊连续吃

了 20 包烧烤味

的干脆面，撑

得肚子

疼。”，是

用户真正想

要模型解决

的问题，它可

以是一个段

落（比如摘要

总结

任务中

被总结的段

落），也可以是

一个实际的

问题（比如问

答任务中用

户的

问题），或

者表格等其

他类型的输

入内容；

输出

格式是“以”

结

果”: ” ” 的

JSON 格式返

回最终结果

。”，它规范了模

型的

输出格

式。

通过这个

例子可以看

出，在编写经

典

Prompt 的过程中

，Prompt 各个组成部

分

都很重要

，它们的规范

性，直接影响

模型的输出

质量。同时，各

个组成部分

的排版

也很

重要。接下来

，我们将详细

介绍经典 Prompt 的

规范编写需

要满足的要

求。

1.

任务说明

要明确

明确

的任务说明

是构建有效

Prompt 的关键要素

之一。一个清

晰、具体的任

务

说明能够

确保模型准

确理解任务

要求，并产生

符合预期的

输出。例如，在

情感分类

任

务中，任务说

明“判断下面

句子的情感

为积极还是

消极。”就是一

个明确的示

例，

它清晰地

定义了任务

类型（情感分

类）和分类的

具体类别（积

极或消极）。相

反，模

糊或不

明确的任务

说明可能导

致模型误解

用户的真实

意图，从而产

生不符合预

期

的输出。如

图

3.17所示，“分类

下面的句子

”这样的任务

说明就缺乏

具体性，没有

明确指出分

类的类型和

类别，使得模

型难以准确

执行任务。

为

了确保任务

说明的明确

性，我们需要

明确以下几

个要点：

使用

明确的动词

：选择能够清

晰表达动作

的动词，如“判

断”、“分类”、“生

成

”等，避免使用

模糊的动词

如“处理”或“操

作”。

具体的名

词：使用具体

的名词来定

义任务的输

出或目标，例

如“积极”和“消

极”在情感分

类任务中提

供了明确的

分类标准。

123

第

3 章

Prompt 工程

### 分类

下面的句子

。

### 待分类的句

子：小浣熊连

续吃了20包烧

烤味的干脆

面，撑得肚子

疼。

### 以

{"结果": " "} 的

JSON格式返回最

终结果。

{"结果

"

: 幽默笑话"}

### 判

断下面句子

的情感为积

极还是消极

。 ### 待分类的句

子：小浣熊连

续吃了20包烧

烤味的干脆

面，撑得肚子

疼。

### 以 {"结果": "

"} 的

JSON格式返回最

终结果。 

{"结果

"

: 消极"} 

图

3.17: 不同

的任务说明

对比。

简洁明

了：任务说明

应简洁且直

接，避免冗长

或复杂的句

子结构，使模

型能

够快速

抓住任务的

核心要求。

结

构化布局：在

较长的 Prompt 中，将

任务说明放

置在开头和

结尾，因为模

型

通常更关

注这些部分

的信息

[18]。这种

布局有助于

确保模型首

先和最后接

触

到的是最

关键的任务

信息。

通过这

些策略，我们

可以确保任

务说明既清

晰又具体，从

而帮助模型

更好地

理解

和执行任务

，最终产生高

质量的输出

。

2. 上下文丰富

且清晰

在 Prompt

设

计中，上下文

的作用不容

忽视，它有时

直接决定了

模型能否给

出

正确的答

案。一个丰富

且清晰的上

下文能够显

著提升模型

的理解和回

答准确率。上

下文的丰富

性体现在其

内容的多样

性和相关性

。上下文可以

包括与问题

直接相关

的

背景信息、具

体的演示示

例，或是对话

的连续性内

容。例如，在情

感分类任务

中，提供具体

的示例句子

及其对应的

情感标签，可

以帮助模型

更好地理解

任务的

124

张超

毛玉仁 胡中

豪

具体要求

和预期的输

出。上下文的

清晰性则要

求上下文信

息必须与问

题紧密相关

，

避免包含冗

余或不必要

的信息。清晰

的上下文应

直接指向任

务的核心，减

少模型

在处

理信息时的

混淆和误解

。例如，在问答

任务中，上下

文应仅包含

与问题直接

相

关的信息

，避免引入可

能误导模型

的无关内容

。

在图 3.18两个上

下文设计的

例子中，第一

个例子的上

下文紧密围

绕问题，提

供

了丰富的直

接相关信息

，没有任何冗

余内容。这种

设计有助于

模型迅速聚

焦于

关键信

息，从而准确

回答问题。相

比之下，第二

个例子的上

下文不够丰

富，并且单

个

例子则包含

了大量与问

题无关的细

节，这些冗余

信息不仅使

上下文显得

不明确，

还可

能加重模型

处理信息的

负担，导致模

型难以准确

把握问题的

核心，进而影

响

其回答的

准确性。

### 判断

下面句子的

情感为积极

还是消极。 针

对此问题有

如下示例：

### 待

分类的句子

：小浣熊连续

吃了20包最爱

的烧烤味的

干脆面，撑得

肚子疼，脸色

憔悴。

# 示例1：浣

熊爸爸背了

一箱干脆面

走来，小浣熊

手舞足蹈，非

常积极的迎

接爸爸。\n积极

#

示例2：小浣熊

吃了一包烧

烤味的干脆

面，脸上露出

了满意的笑

容。\n积极

# 示例

3： 小浣熊吃了

一包麻辣味

的干脆面，味

道很棒，但是

辣得肚子疼

，它感到非常

难受。\n消极

### 以

{"结果": " "}

的JSON格式

返回最终结

果。 

{"结果": "消极

"}

### 判断下面句

子的情感为

积极还是消

极的。

### 待分类

的句子：小浣

熊连续吃了

20包最爱的烧

烤味的干脆

面，撑得肚子

疼，脸色憔悴

。

针对此问题

有如下示例

：

# 示例： 小浣熊

爸爸给小浣

熊带来了一

箱小浣熊最

爱吃的干脆

面，小浣熊兴

高采烈地去

迎接小浣熊

爸

爸。爸爸给

了小浣熊一

包麻辣味的

干脆面，小浣

熊对麻辣味

的食物不太

适应，但是它

看出麻辣味

干脆面

包装

很漂亮，忍不

住吃了一包

。麻辣味干脆

面很好吃，小

浣熊脸上露

出了幸福的

笑容。但是没

过一

会，它的

肚子就开始

疼起来了，嘴

巴也火辣辣

的，脸色变得

苍白。\n小浣熊

高兴地迎接

爸爸，并且吃

了

干脆面很

幸福，尽管吃

了面之后肚

子疼，但是总

体而言情感

还是积极的

。

### 以{"结果": ""}的JSON形

式返回最终

结果。

{"结果":

"虽

然小浣熊肚

子疼，但是它

吃到了最爱

的烧烤味干

脆面，所以总

体而言情感

是积极的"} 

图

3.18: 不同的上下

文对比。

125

第 3 章

Prompt

工程

3. 输出格

式要规范

规

范的输出格

式对于确保

模型输出的

可用性和准

确性至关重

要。通过指定

明

确的输出

格式，可以使

模型的输出

结构化，便于

下游任务直

接提取和使

用生成内

容

。常用的输出

格式包括 JSON、XML、HTML、Markdown 和

CSV

等，每种格式

都有其特定

的用途和优

势。

例如，在图

3.19中的 Prompt 例子中

，“以

{” 结果”: ” ”}

”的 JSON 格

式返回最

终

答案。”明确指

定了答案应

以

JSON 格式输出

，并且以一个

简短的例子

指名 JSON

中的关

键字。这种规

范的输出格

式不仅使得

结果易于解

析和处理，还

提高了模型

输出的准确

性和一致性

。如果不明确

规定输出格

式，模型可能

会输出非结

构化或

不规

范的结果，这

会增加后续

处理的复杂

性。在第二个

例子中，如果

模型输出的

答

案是一个

自由格式的

文本字符串

，那么提取具

体信息就需

要进行复杂

的字符串解

析，而不是像

JSON 等结构化格

式那样可以

直接提取，这

就给后续对

于结果的处

理

与使用带

来了麻烦。

### 判

断下面句子

的情感为积

极还是消极

。 ### 待分类的句

子：小浣熊连

续吃了20包烧

烤味的干脆

面，撑得肚子

疼。

### 以 {"结果": "

"} 的

JSON格式返回最

终结果。

{"结果

"

:

消极"} 

### 判断下

面句子的情

感为积极还

是消极。

### 待分

类的句子：小

浣熊连续吃

了20包烧烤味

的干脆面，撑

得肚子疼。

消

极的情感。

图

3.19:

不同输出格

式对比。

126

张超

毛玉仁 胡中

豪

为了确保

输出格式的

规范性，可以

采取以下措

施：

明确指定

输出格式：在

Prompt 中明确指出

希望模型使

用的输出格

式，如“请以

JSON

格

式返回结果

”，并且选择广

泛接受和易

于处理的输

出格式，如 JSON、

CSV 等

，易于解析和

数据交换。

提

供输出格式

的示例：在 Prompt 中

提供一个输

出格式的具

体示例，比如

在

JSON

中明确指

出关键字，帮

助模型理解

预期的输出

结构。

这些措

施可以令模

型的输出既

规范又易于

处理，从而提

高整个系统

的效率和

准

确性。规范的

输出格式不

仅简化了数

据处理流程

，还增强了模

型输出的可

靠性

和一致

性，为用户提

供了更加流

畅和高效的

交互体验。

4. 排

版要清晰

一

个优秀的 Prompt

还

必然具备清

晰的排版，这

对于模型的

理解 Prompt 至关重

要。清晰的排

版有助于模

型准确捕捉

任务的关键

信息，从而提

高其执行任

务的准

确性

和效率。相反

，复杂的排版

可能会导致

信息模糊，使

模型难以准

确理解任务

的

具体要求

[7]，进而影响输

出结果的质

量。清晰的排

版通常涉及

使用合适的

分隔符

和格

式化技巧，将

Prompt 的不同组成

部分（如任务

说明、上下文

、问题和输出

格

式）明确区

分开来。在图

3.16所示的例子

中，我们使用

“#”和“###”以及换行

符

有效地将

各个部分分

隔开，使得每

个部分的内

容清晰可见

，便于模型理

解和处理。

相

反，如果排版

混乱，例如在

Prompt 中混合使用

不使用任何

分隔符，模型

可能会

混淆

不同部分的

内容，导致无

法准确执行

任务。例如，去

除图

3.16中的 Prompt 例

子的排版符

号与样式，将

图 3.20所示的复

杂混乱的

Prompt 输

入给大语言

模型，模

型回

答的质量将

大幅度下降

。

为了确保

Prompt 的

排版清晰，可

以采取以下

措施：

使用一

致的分隔符

：选择并坚持

使用一种或

几种分隔符

（如“#”、“###”、“—”

等），以区分

不同的

Prompt 部分

。

127

第

3 章 Prompt 工程

判

断下面句子

的情感为积

极还是消极

。\n针对此问题

有如下示例

：浣熊爸爸背

了一箱干脆

面走来，小浣

熊手舞足蹈

迎接爸爸。 \n积

极小浣熊吃

了一包麻辣

味的干脆面

，辣得肚子疼

。 \n消极小浣熊

吃了一包

烧

烤味的干脆

面，脸上露出

了满意的笑

容。

\n积极待分

类的句子：小

浣熊连续吃

了20包烧烤味

的干

脆面，撑

得肚子疼。以

{"结果": " "}

的JSON格式

返回最终结

果。

{"结果": [{"句子

": "浣熊爸爸背

了一箱干脆

面走来，小浣

熊手舞足蹈

迎接爸爸。

"

,

"情

感": "积极"},{"句子

":

"小

浣熊吃了

一包麻辣味

的干脆面，辣

得肚子疼。

"

,

"情

感": "消极"},{句子

": "小浣熊吃了

一包烧烤味

的干脆面，

脸

上露出了满

意的笑容。

"

,

"情

感": "积极"},{"句子

":

"小浣熊连续

吃了20包烧烤

味的干脆面

，撑得肚子疼

。

"

,

"情感":

"消极"}]}

图

3.20: 不清晰的排

版。

合理使用

空白和缩进

：通过增加空

白行和适当

的缩进，增强

Prompt

的可读

性，帮

助模型区分

不同的内容

块。

清晰的标

题和子标题

：为每个部分

提供清晰的

标题或子标

题，使模型能

够快

速识别

每个部分的

主题。

通过这

些措施，我们

构造既清晰

又易于理解

的 Prompt 的排版，从

而帮助模型

更好

地执行

任务，提升信

息处理的效

率和准确性

。

3.4.2 合理归纳提

问

在与大语

言模型的交

互中，提问的

质量直接影

响到信息触

达的效率和

深度。一

个精

心设计的提

问不仅能够

明确表达需

求，还能引导

模型聚焦于

问题的核心

，从

而获得精

准且有价值

的答案。本节

将探索如何

通过“合理归

纳提问”来提

升交互的

质

量。具体的，我

们将重点介

绍两个高级

提问策略：“复

杂问题拆解

”和“追问”。

这两

个策略是提

问艺术的精

髓，它们不仅

帮助我们深

入理解问题

的本质，还显

著

提高了我

们获取信息

和解决问题

的效率。通过

这些策略，我

们能够更精

确地引导

模

型，确保其输

出既准确又

全面，从而满

足我们的需

求。

128

张超 毛玉

仁

胡中豪

1. 复

杂问题拆解

在处理复杂

问题时，我们

可以将问题

分解为更小

、更易于理解

的子问题，并

逐

一解决。在

计算机算法

设计中，这种

策略被称为

“分而治之”，其

基本理念是

通过

逐一解

决子问题，最

终达成解决

整个问题的

目标。在与大

语言模型进

行交互时，同

样可以借鉴

“分而治之”的

思想，将复杂

问题分解为

一系列子问

题，并引导模

型逐

一回答

，以确保每个

子问题都得

到充分考虑

和解答。随后

，将这些子问

题的答案汇

总，形成最终

的全面回答

。这一过程包

括两个关键

步骤：分步引

导和归纳总

结。

一只成年

的小浣熊，它

一天要吃多

少干脆面才

能达到基本

的能量需求

？

成年小浣熊

的能量需求

会因其体重

、活动水平和

生理状态而

有所不同。一

般来说，小浣

熊是杂食性

动物，主要以

昆虫、小型哺

乳动物、水果

和坚果为主

食，干脆面并

不是它们的

自然食物。

一

只成年小浣

熊，一天需要

摄入多少热

量？

成年小浣

熊的热量需

求取决于多

种因素，包括

其体重、活动

水平、性别和

健康状况。一

般来说，小

浣

熊的日热量

需求大约在

600到900千卡之间

。

一包干脆面

的热量是多

少？

一包干脆

面的热量取

决于其品牌

、大小和成分

。通常，一包标

准大小的干

脆面（约50-60克）的

热量大约在

250至350千卡之间

。

结合以上信

息，成年小浣

熊一天需要

吃多少包干

脆面才能满

足能量需求

？

如果我们仅

从热量的角

度来计算，假

设一包干脆

面的热量为

300千卡，而成年

小浣熊的日

热量需求

为

800千卡，那么理

论上小浣熊

需要吃大约

2.7包干脆面（800千

卡

÷ 300千卡/包 ≈ 2.7包

）才能

满足其

能量需求。

图

3.21: 复杂问题拆

解例子对比

。

首先，在分步

引导阶段，我

们需将复杂

问题细化为

多个子问题

，并引导模型

针

对每个子

问题进行深

入分析和回

答。这一步骤

旨在确保每

个子问题都

能得到详尽

的解答，从而

为后续的归

纳总结奠定

坚实基础。其

次，在归纳总

结阶段，我们

将各

个子问

题的答案进

行汇总，并综

合形成最终

的全面回答

。这一步骤不

仅有助于我

们全面把握

问题的各个

方面，还能确

保最终答案

的准确性和

完整性。

129

第

3 章

Prompt 工程

如图

3.21所

示。用户提出

了一个关于

成年小浣熊

一天需要吃

多少干脆面

才能满

足能

量需求的问

题。通过分步

引导，我们将

这个问题分

解为两个关

键的小问题

：“一

只成年小

浣熊，一天需

要摄入多少

热量？”和“一包

干脆面的热

量是多少？”。模

型

分别回答

了这两个问

题，提供了小

浣熊的日热

量需求和干

脆面的热量

含量。随后，

通

过归纳总结

的提示“结合

以上信息，成

年小浣熊一

天需要吃多

少包干脆面

才能

满足能

量需求？”，我们

将这些分散

的信息整合

起来，计算出

小浣熊需要

摄入的干

脆

面数量。这一

过程不仅展

示了如何通

过逐步提问

来引导模型

提供详细信

息，还

强调了

在解决复杂

问题时，系统

地分解问题

和整合答案

的重要性。

这

种方法的优

势在于它能

够帮助用户

和模型更有

效地处理复

杂信息，确保

每

个细节都

被考虑到，并

最终形成一

个准确和全

面的答案。通

过分步引导

和归纳总

结

，我们能够有

序地解决复

杂问题，提供

高质量的解

答。

2.

追问

通过

在对话中进

行追问，用户

可以引导大

语言模型的

输出更贴合

心意的内容

。

这种对话形

式的交互不

仅可以促进

更深层次的

理解和更为

丰富的讨论

，而且有助

于

更精确地表

达用户的真

实想法，从而

更好地指导

模型的思考

，使其输出更

加贴

合用户

需求。从追问

的形式和目

的角度来看

，追问可以分

为三种形式

：深入追问、

扩

展追问、反馈

追问。

(1) 深入追

问

深入追问

的形式是指

用户可以根

据大语言模

型的输出继

续发问来深

入挖掘特

定

话题的深层

信息。这种追

问适用于需

要对某个概

念、现象或过

程有详尽解

释的

场景。通

过深入追问

，用户能够引

导模型提供

更为细致和

深入的信息

，从而加深对

特定领域的

理解。以图 3.22为

例，用户首先

询问了小浣

熊是否可以

食用干脆面

。模

型基于干

脆面的成分

给出了初步

的回答，指出

其对小浣熊

的健康可能

有害。随后，

用

户通过深入

追问，探讨了

如果去除干

脆面中的调

味料和添加

剂，是否可以

安全

130

张超

毛

玉仁 胡中豪

小浣熊可以

吃干脆面吗

？

干脆面是一

种加工食品

，通常含有高

盐、高脂肪以

及各种添加

剂，这些成分

对小浣熊的

健康可能是

有害的。因此

，不建议给小

浣熊喂食干

脆面。

如果我

减少干脆面

中的调味料

和添加剂，只

给小浣熊吃

未调味的干

脆面，这样可

以吗？

如果将

干脆面中的

调味料和添

加剂去除，并

且只是偶尔

作为小浣熊

饮食的一部

分，那么可以

适量给

予。但

是，由于干脆

面本身是经

过油炸的，含

有较高的脂

肪，因此不应

成为小浣熊

饮食的主要

部

分。建议搭

配其他健康

食物，如新鲜

的水果、蔬菜

和适量的蛋

白质来源，以

确保小浣熊

获得均衡的

营养。同时，任

何新食物的

引入都应该

谨慎，并观察

小浣熊的反

应，以确保没

有不良影响

。

图

3.22: 深入追问

示例。

地喂食

小浣熊。模型

进一步解释

了即使去除

调味料和添

加剂，干脆面

仍含有较高

的脂肪，因此

不应成为小

浣熊饮食的

主要部分，并

建议了如何

搭配其他食

物以确

保营

养均衡。这一

系列的追问

展示了用户

如何通过连

续提问引导

模型提供更

为深

入的信

息。

(2) 扩展追问

小浣熊一般

吃什么？

小浣

熊是杂食性

动物，主要食

物包括昆虫

、小型哺乳动

物、水果、坚果

和植物材料

。

小浣熊能否

偶尔尝试干

脆面作为零

食？

小浣熊可

以将干脆面

作为其日常

饮食的一部

分，干脆面包

含油脂、碳水

，能够一定程

度上满足能

量

需求。不过

需要控制干

脆面的份量

，确保小浣熊

的饮食主要

由适合它们

自然饮食习

惯的食物组

成，

如水果、蔬

菜、昆虫和小

型动物。

为确

保小浣熊的

健康，建议在

喂食前咨询

专业野生动

物保护机构

或兽医。

图 3.23: 扩

展追问示例

。

扩展追问是

一种在大语

言模型给出

回答的基础

上，进一步要

求模型提供

更多

相关信

息或例子的

提问方式，其

目的在于拓

宽讨论的广

度，收集更多

数据、例证或

选项，帮助用

户获得更广

泛的视角，增

加对话题的

理解。这种追

问特别适用

于需要

全面

了解一个主

题的场景。在

图 3.23这个例子

中，用户首先

询问了小浣

熊的常规

131

第

3 章 Prompt

工程

饮食

，模型提供了

小浣熊作为

杂食性动物

的饮食概况

。随后，用户通

过扩展追问

，

探讨了小浣

熊是否可以

食用干脆面

。模型进一步

解释了干脆

面可以作为

小浣熊饮

食

的一部分，但

强调了控制

份量和保持

饮食多样性

的重要性。这

一系列的追

问不

仅展示

了用户如何

通过提问获

取更多关于

小浣熊饮食

的信息，还强

调了在引入

新

食物时咨

询专业意见

的必要性。通

过扩展追问

，用户能够获

得更全面的

视角。

(3) 反馈追

问

反馈追问

的形式是在

大语言模型

的输出不符

合预期或存

在错误时，提

供反馈，

指出

问题所在，并

请求模型进

行更正或澄

清。其目的在

于通过反馈

机制提升模

型的

准确性

，确保信息的

正确性。这种

追问允许用

户指出模型

输出中的具

体错误或不

足，并请求模

型对其进行

修正，有助于

提高对话质

量。在图 3.24这个

例子中，用户

首先询问了

小浣熊连续

食用

20 包干脆

面后的应对

措施。模型最

初的回答建

议小浣

熊可

以适量食用

干脆面，但用

户通过反馈

追问指出了

小浣熊出现

了不良反应

。模

型随后修

正了回答，指

出大量食用

干脆面对小

浣熊的健康

有害，并提供

了紧急处

理

建议。通过反

馈追问，用户

能够获得更

加准确可靠

的信息。

我的

小浣熊连续

吃了20包干脆

面，我该怎么

办？

小浣熊可

以适量食用

干脆面，因为

干脆面中含

有淀粉等成

分，可以给小

浣熊提供能

量。

我的小浣

熊连续吃了

20包干脆面后

出现了呕吐

和不安。我该

怎么办？

非常

抱歉，我之前

的回答有误

。虽然小浣熊

可能会对人

类食物表现

出好奇，但大

量食用干脆

面并不

适合

它们的自然

饮食习惯。干

脆面中的高

盐分和高脂

肪可能对小

浣熊的健康

造成不利影

响。

我现在应

该采取哪些

紧急措施？

如

果小浣熊出

现因食用过

多干脆面而

导致的呕吐

和不安等症

状，请立即带

它去看兽医

。在前往兽医

的路上，保持

小浣熊安静

，并观察其症

状是否有恶

化。不要尝试

自行治疗，因

为专业医疗

干预是必

要

的。请尽快行

动，以确保小

浣熊得到及

时救治。

图 3.24: 反

馈追问示例

。

132

张超 毛玉仁

胡中豪

3.4.3

适时

使用 CoT

思维链

技术（Chain of

Thought，CoT） [38] 是在处

理涉及算术

、常识和符号

推理等复杂

推理的任务

时的理想选

择。在处理这

类任务的过

程中，通过 CoT

引

导

模型理解

和遵循中间

步骤，能够显

著提高得出

答案的准确

率。3.3 节中已经

讨论过

CoT

几种

经典范式。本

节将讨论在

何时使用 CoT 以

及如何使用

CoT。

1.

何时使用 CoT

在

决定何时使

用 CoT

时，需要对

任务类别、模

型规模以及

模型能力三

方面因

素进

行考虑。

在任

务类别方面

，CoT 技术特别适

用于需要复

杂推理的任

务，如算术、常

识和

符号推

理。在这些任

务上，CoT 能够引

导大语言模

型生成逻辑

严密、条理清

晰的中

间推

理步骤，从而

提高正确答

案的生成概

率，如图 3.25所示

。然而，对于情

感分类、

常识

问答等简单

问题，标准的

Prompt 方法已足够

有效，使用 CoT 可

能难以提升

效

果，反而可

能引入不必

要的复杂性

。

浣熊爸爸有

8包干脆面，给

浣熊妈妈3包

，然后把剩下

的干脆面处

理了，又获得

了6包干脆面

，自己

吃了两

包，剩下的都

给小浣熊，请

问小浣熊手

里有几包干

脆面？让我们

一步一步思

考。

浣熊爸爸

最初有8包干

脆面，给了浣

熊妈妈3包，剩

下8

- 3 = 5包。然后他

处理了这5包

干脆面，

又获

得了6包新的

，吃了2包，剩下

6 - 2 =

4包。所以，小浣

熊手里有4包

干脆面。

浣熊

爸爸有8包干

脆面，给浣熊

妈妈3包，然后

把剩下的干

脆面处理了

，又获得了6包

干脆面，自己

吃了两包，剩

下的都给小

浣熊，请问小

浣熊手里有

几包干脆面

？

7个

图

3.25: 在推理

任务上使用

CoT。

在模型规模

的考量上，CoT 技

术应用于参

数量超过千

亿的巨型模

型时，能够显

著提升其性

能，例如，PaLM

[5] 模型

和 GPT-3 [3]

模型等模

型。然而，在规

模较小

133

第 3

章

Prompt 工程

的模型

上应用 CoT

技术

可能会遭遇

挑战，如生成

逻辑不连贯

的思维链，或

导致最

终结

果的准确性

不如直接的

标准提示方

法，如图 3.26所示

。

浣熊爸爸有

8包干脆面，给

浣熊妈妈3包

，然后把剩下

的干脆面处

理了，又获得

了6包干脆面

，自己

吃了两

包，剩下的都

给小浣熊，请

问小浣熊手

里有几包干

脆面？让我们

一步一步思

考。

浣熊爸爸

最初有8包干

脆面，给了浣

熊妈妈3包，剩

下8 - 3

= 5包。然后他

处理了这5包

干脆面，

又获

得了6包新的

，吃了2包，剩下

6 -

2 = 4包。所以，小浣

熊手里有4包

干脆面。

浣熊

爸爸有8包干

脆面，给了浣

熊妈妈3包，剩

下8

- 3 = 5个。然后他

获得了6包新

的干脆面，吃

了2包，剩下6

- 2 = 4包

。所以小浣熊

手里的干脆

面是5

+ 4 = 9包。

千亿

参数模型

十

亿参数模型

图 3.26: 不同规模

模型使用

CoT 对

比。

在模型能

力的考量上

，CoT 是否起效与

模型在预训

练阶段是否

进行过推理

方

面的指令

微调有关。对

于那些未经

推理方面的

指令微调的

大语言模型

，如早期的

GPT-3、Palm 以

及目前开源

的基础版本

模型，例如 LLaMA2-13B-Base

和

Baichuan2-

13B-Base ，适当的 CoT

提示

能够激发其

卓越的 CoT 推理

能力；对于已

经历过推理

方面的指令

微调的大语

言模型，如 ChatGPT、GPT-4

以

及 LLaMA2-13B-Chat 等，即

便在

没有

CoT 指令的

情况下，也能

自发生成条

理清晰的中

间推理步骤

。在许多情

况

下，这些模型

在没有 CoT

指令

的条件下反

而展现出更

佳的性能，这

表明它们在

指令微调过

程中可能已

经内化了 CoT 指

令，使得即便

在没有明确

CoT 提示时，仍

能

隐式遵循 CoT 推

理路径。

2.

灵活

使用 CoT

灵活使

用 CoT

的关键在

于根据任务

的具体需求

和模型的特

性来调整 CoT 的

使

用方式。主

要涉及调整

CoT

的详细程度

以及使用不

同的 CoT 形式两

个方面。

调整

CoT

的详细程度

：我们可以指

定 CoT 输出的详

细程度，以适

应不同的用

户需求，如图

3.27所示。对于简

单的计算问

题，在用户不

需要推理的

中间过

程时

，我们可以直

接给出最终

乘法和加法

的结果。而对

于复杂的计

算、推理

134

张超

毛玉仁 胡中

豪

问题，或者

用户需要理

解中间推理

过程时，我们

需要通过样

例进行引导

，以

使其展示

完整的推理

步骤。

使用不

同的 CoT 形式：我

们可以根据

不同任务场

景，选择不同

的

CoT 形式。

在不

需要特定领

域知识，仅需

对问题进行

逻辑推理和

逐步分析时

，可以使用

Zero-Shot

CoT 或

者 Auto CoT

的方式，通

过“让我们一

步一步思考

”这种 CoT

提示触

发词，来引导

模型以 CoT

的形

式回答内容

。在处理需要

高准确度和

可靠性的任

务时，可要求

模型生成多

个回答并提

出最终结果

，进而运用 Self￾Consistency 方

法筛选出一

致性最强的

答案。例如，在

编写代码时

，模型可生

成

多个版本，通

过

Self-Consistency 方法确保

最终选定的

代码在逻辑

上最为一

致

。对于包含创

意思维的任

务，可选用 ToT

和

GoT 方法来在多

个可能的思

维

路径中进

行探索和选

择。例如，在创

作故事时，模

型可利用 ToT

或

GoT 探索

不同的

情节发展路

径，并选取最

富有趣味性

或合理性的

发展方向。

示

例：金丝猴爸

爸得到了10颗

奶糖，他给了

金丝猴妈妈

4颗奶糖，然后

把剩下的奶

糖分给了其

他金丝

猴。之

后，他又得到

了7颗奶糖，自

己吃了3颗，剩

下的都给了

小金丝猴。请

问小金丝猴

手里有几颗

奶糖？回答：（7 - 3 =

4）颗

奶糖。

浣熊爸

爸有8包干脆

面，给浣熊妈

妈3包，然后把

剩下的干脆

面处理了，又

获得了6包干

脆面，自己

吃

了两包，剩下

的都给小浣

熊，请问小浣

熊手里有几

包干脆面？

（6

- 2 = 4）包

干脆面。

金丝

猴爸爸得到

了10颗奶糖，给

金丝猴妈妈

4颗奶糖，然后

把剩下的奶

糖分给了其

他金丝猴，又

得到

了7颗奶

糖，自己吃了

3颗，剩下的都

给小金丝猴

。请问小金丝

猴手里有几

颗奶糖？回答

：金丝猴爸

爸

给金丝猴妈

妈后剩下 (10

- 4 = 6)

颗

，分给其他金

丝猴后没有

剩余。再得到

7颗奶糖，吃了

3颗后

剩下 (7 -

3 = 4) 颗

，所以小金丝

猴手里有4颗

奶糖。

浣熊爸

爸有8包干脆

面，给浣熊妈

妈3包，然后把

剩下的干脆

面处理了，又

获得了6包干

脆面，自己

吃

了两包，剩下

的都给小浣

熊，请问小浣

熊手里有几

包干脆面？

浣

熊爸爸给浣

熊妈妈后剩

下 (8

- 3 = 5)

包，处理后

没有剩余。再

获得6包干脆

面，吃了2包后

剩下

(6 - 2

= 4) 包，所以

小浣熊手里

有4包干脆面

。

图

3.27: 通过 Few-Shot 示例

指定

CoT 输出的

形式和风格

。

135

第

3 章 Prompt 工程

3.4.4 善

用心理暗示

在硅谷，流传

着一句创业

金句，“Fake it till

you make it”（假装它

直到你成功

）。

这句话具体

含义为，先吹

嘘你的想法

，进而吸引资

本和人才，最

终在实践中

努力追

赶并

实现既定目

标。这句话源

自一种积极

的心理暗示

方法：通过模

仿自信和乐

观

的心态，一

个人可以在

他们的现实

生活中实现

这些品质。这

种现象不仅

局限于人

类

的行为，积极

的心理暗示

也可用于激

发大语言模

型的潜力。这

种心理暗示

可以

通过角

色扮演和情

景代入的方

式传达给大

语言模型。

1. 角

色扮演

通过

Prompt 指导大语言

模型扮演特

定角色能够

显著改善其

与角色相关

的技

能。这种

技术被称为

角色扮演（Role-Playing），它

可使大语言

模型能够生

成更为准

确

、角色相关的

内容。通过为

大语言模型

设定一个详

尽的角色，例

如数据科学

家、

诗人或律

师，可以有效

地引导模型

的输出朝向

所需的方向

，从而提供更

高质量的

回

答。为了构建

一个有效的

角色，需要在

指令中包含

具体属性、职

责、知识和技

能。在设计角

色设定提示

时，选择对特

定任务具有

明显优势的

角色至关重

要。通过

我想

给我家的小

浣熊吃干脆

面，需要怎么

搭配食谱才

能营养均衡

？

小浣熊不能

吃干脆面，它

的饮食应该

以昆虫、水果

、坚果和蔬菜

为主。

你是一

位专业的小

浣熊营养顾

问，专门为小

浣熊设计符

合其自然饮

食习惯的健

康营养计划

。

我想给我家

的小浣熊吃

干脆面，需要

怎么搭配食

谱才能营养

均衡？

虽然小

浣熊的饮食

应以昆虫、水

果、坚果和蔬

菜为主，但偶

尔尝试一些

新的食物也

是可以的。如

果

您想让小

浣熊尝试干

脆面，建议将

其作为零食

，并且要控制

分量，确保它

不会影响小

浣熊的整体

营

养摄入。为

了保持营养

均衡，您可以

将干脆面与

新鲜水果和

蔬菜搭配，如

苹果、胡萝卜

等，同时确

保

小浣熊的饮

食中包含足

够的昆虫和

坚果。

图 3.28: 角色

扮演示例。

136

张

超 毛玉仁 胡

中豪

额外的

描述来强调

这一优势，通

常可以带来

更好的结果

[13]。

如图 3.28所示，通

过角色扮演

，模型承担了

“专业的小浣

熊营养顾问

”这一角

色，展

现出了对小

浣熊饮食需

求的专业知

识。在回答用

户关于小浣

熊尝试干脆

面

的询问时

，模型不仅坚

持了小浣熊

应以昆虫、水

果、坚果和蔬

菜为主的自

然饮食原

则

，还巧妙地提

出了将干脆

面作为零食

的建议，并强

调了控制分

量的重要性

。此

外，模型还

建议将干脆

面与新鲜水

果和蔬菜搭

配，确保小浣

熊的饮食中

包含足够

的

昆虫和坚果

，以维持营养

均衡。这一建

议既科学又

实用，充分展

现了角色扮

演在

提升模

型交互质量

和适应用户

需求方面的

巨大潜力。

2. 情

景代入

在日

常生活中，一

个人容易受

到周围环境

和交往人群

的影响，可能

会逐渐采

纳

周围人的行

为和思维方

式。这种情景

代入现象不

仅适用于人

，也同样适用

于大

语言模

型。通过将模

型置于特定

的“情景”或“环

境”中，可以影

响其生成的

文本

内容和

风格。情景代

入指的是将

特定情境下

所需的专业

知识、历史背

景等信息嵌

入到模型的

响应中。

小浣

熊干脆面给

我们带来的

快乐有什么

？

小浣熊干脆

面味道丰富

，无论是香辣

味、烧烤味还

是其他口味

，都能满足不

同人的味蕾

需求。

想象你

在90年代的街

头，放学的小

朋友们围成

一圈，手中玩

着弹珠和卡

片，欢声笑语

中流露出纯

真

的快乐。

小

浣熊干脆面

给我们带来

的快乐有什

么？

小浣熊干

脆面的香辣

、烧烤等口味

，满足了孩子

时期我们的

美食追求，而

附赠的水浒

传、三国演义

卡片则激发

了我们的收

集欲望。90后通

过购买干脆

面收集卡片

，享受交换乐

趣，这些经历

成为了他

们

童年的美好

回忆，小浣熊

干脆面因此

承载了一代

人的情感和

文化记忆。

图

3.29: 情景代入示

例。

137

第 3 章 Prompt

工程

通过情景代

入，模型能够

深入理解并

反映特定情

境下的文化

社会背景与

现实

环境，从

而生成更加

丰富和有深

度的回答。在

图 3.29例子中，当

模型被置于

90 年

代的街头

情景中，它不

仅能够描述

小浣熊干脆

面的口味，还

能够捕捉到

那个时代

特

有的文化现

象——通过收集

卡片来交换

乐趣。这种回

答不仅提供

了具体的信

息，

还唤起了

用户的情感

共鸣，增强了

交互的情感

连接。

在本节

中，我们深入

探讨了提升

Prompt

技巧的多种

策略，以增强

大语言模型

的交互效率

和输出质量

。这些技巧主

要包括规范

Prompt 编写、合理归

纳提问、适

时

使用思维链

、以及善用心

理暗示。这些

技巧和策略

的应用，不仅

可以提升了

提示

的有效

性，使得模型

能够更准确

地理解和回

应用户的需

求，还显著提

高了大语言

模型在复杂

任务中的表

现。

3.5 相关应用

Prompt 工程的应用

极为广泛，几

乎涵盖了所

有需要与大

语言模型进

行高效交

互

的场景。这项

技术不仅能

够帮助我们

处理一些基

础任务，还能

显著提升大

语言

模型在

应对复杂任

务时的表现

。Prompt 工程在构建

Agent 完成复杂任

务、进行数

据

合成、Text-to-SQL

转换，以

及设计个性

化的 GPTs 等方面

，发挥着不可

或缺的作

用

。下面我们将

依次介绍

Prompt 工

程在这些应

用场景中的

具体作用。

3.5.1 基

于大语言模

型的

Agent

智能体

（Agent）是一种能够

自主感知环

境并采取行

动以实现特

定目标的实

体 [35]。作为实现

通用人工智

能（AGI）的有力手

段，Agent 被期望能

够完成各种

复

杂任务，并

在多样化环

境中表现出

类人智能。然

而，以往的 Agent 通

常依赖简单

的

启发式策

略函数，在孤

立且受限的

环境中进行

学习和操作

，这种方法难

以复制人

类

水平的决策

过程，限制了

Agent 的能力和应

用范围。近年

来，大语言模

型的不断

138

张

超

毛玉仁 胡

中豪

发展，涌

现出各种能

力，为 Agent

研究带

来了新的机

遇。基于大语

言模型的 Agent

（以

下统称 Agent）展现

出了强大的

决策能力。其

具备全面的

通用知识，可

以在缺

乏、训

练数据的情

况下，也能进

行规划、决策

、工具调用等

复杂的行动

。

Prompt 工程技术在

Agent 中起到了重

要的作用。在

Agent

系统中，大语

言模型

作为

核心控制器

，能够完成规

划、决策、行动

等操作，这些

操作很多都

依赖 Prompt

完成。图

3.30展示了一个

经典的

Agent 框架

，该框架主要

由四大部分

组成：配置模

块（Profile）、记忆模块

（Memory）、计划模块（Planning）和

行动模块（Action）

[35]。Prompt 工

程技术贯穿

整个

Agent 流程，为

每个模块提

供支持。

prompt

角色

设定：经验丰

富的兽医......

任

务目标：提供

动物治疗建

议

……

小浣熊由

于吃了太多

干脆面

肚子

疼，现在应该

怎么办？

1. 观察

小浣熊是否

有呕吐

2. 让小

浣熊停止进

食。。。

3. 提供清水

，确保小浣熊

有足够的清

水

4. 立即送往

附近的动物

医

院，附近的

宠物医院以

及

路线如下

……

Agent

用户

配置模

块

记忆模块

行动模块

小

浣熊的饮食

习性：杂食

性

，食物包括水

。。.

小浣熊的紧

急救治说明

：当

小浣熊肚

子疼时，紧急

救治

的步骤

如下。。。

1.

查询小

浣熊的饮食

习性

2. 查看小

浣熊的急救

说明

3.

查找附

近的宠物医

院

……最后，总结

汇总上述子

任务结

果，给

出全面完整

的解决方案

。

prompt

prompt

计划模块

利

用搜索引擎

查找市区里

的

宠物医院

……

利用地图引

擎规划去宠

物医

院的路

线……

prompt

……

图 3.30: 基于大

语言模型的

Agent 框架流程示

意图。

在 Agent 中，上

述四个组件

各司其职，分

工协作，共同

完成复杂任

务：（1）配

置模块

利用

Prompt 工程中

的角色扮演

技术，来定义

Agent 的角色。设定

Agent 的

背景、技能

、职责等信息

，这些角色设

定信息以上

下文的形式

嵌入到 Agent 每一

次

交互的

Prompt 中

。（2）记忆模块是

Agent 的知识与交

互记忆的存

储中心。记忆

模

块通过检

索增强等技

术获取记忆

，这一过程涉

及到使用

Prompt 工

程中的上下

文学

139

第

3 章 Prompt 工

程

习技术来

构造和优化

查询，从而帮

助更加精准

检索到相关

记忆。在获取

记忆之后，

将

这些记忆将

被添加到交

互的 Prompt 中，帮助

Agent

利用这些记

忆知识，实现

更

为准确高

效的决策与

行动。（3）计划模

块则扮演着

任务分解者

的角色，它将

复杂的

任务

细化为一系

列更为简单

、易于管理的

子任务。在这

一过程中，通

过 Prompt

工

程中的

思维链技术

，让大语言模

型分解任务

并进行规划

，按照链式顺

序输出子任

务；同时还利

用了上下文

学习技术，构

造少样本示

例来调控分

解出的子任

务的粒

度，确

保整个任务

流程的顺畅

与高效。（4）行动

模块负责将

计划模块生

成的计划转

化为具体的

行动步骤，并

借助外部工

具执行这些

步骤以实现

Agent 的目标。通常

会

为 Agent 提供工

具 API

的接口，把

调用 API 接口的

示例作为上

下文，让大语

言模

型生成

调用

API 的代码

，之后执行这

些代码，从而

得到执行步

骤的结果。

如

图 3.30展示了一

个小浣熊健

康助理

Agent 处理

用户请求“小

浣熊由于吃

了太

多干脆

面肚子疼，现

在应该怎么

办？”的流程。在

这个例子中

，首先，配置模

块为

Agent

设定了

明确的角色

定位——经验丰

富的兽医，并

明确了任务

目标为提供

专业

的动物

治疗建议。为

确保角色设

定与任务目

标的一致性

，相关信息始

终以上下文

形式嵌入至

输入给大语

言模型的 Prompt 中

，从而为后续

处理奠定坚

实基础。其次

，

计划模块根

据用户的具

体请求，精心

规划了救助

小浣熊的行

动方案。该模

块将整

体任

务细化为多

个子任务，包

括搜寻小浣

熊的相关资

料及救助信

息、查找附近

的

宠物医院

以及总结各

个子任务的

执行结果以

给出全面回

答等。接着，记

忆模块从

知

识库中搜寻

小浣熊的相

关信息，包括

小浣熊饮食

习性、如何急

救小浣熊等

，提供

了必要

的背景知识

支持。然后，行

动模块通过

调用搜索工

具，迅速搜索

到附近最近

的宠物医院

，并调用地图

工具规划出

最佳的送医

路线。最后，计

划模块将多

个子任

务的

执行结果进

行汇总，并综

合考虑各种

因素，执行最

佳行动方案

。该方案不仅

包

括观察小

浣熊的行为

、提供专业的

照顾建议，还

详细阐述了

如何为小浣

熊紧急送

医

的步骤，以生

动形象的方

式向用户展

示整个救助

过程。

140

张超 毛

玉仁 胡中豪

基于大语言

模型的

Agent，在不

同行业和应

用场景都展

现出了巨大

的潜力。斯

坦

福大学利用

GPT-4 模拟了一个

虚拟的西部

小镇 [25]。他们创

建了一个虚

拟环境，

让多

个基于 GPT-4 的 Agent

在

其中生活和

互动。这些 Agent 通

过 Prompt

工程里面

的角色扮演

技术设定了

不同的角色

，如医生、教师

和市长等，并

根据自己的

角色

和目标

自主行动，进

行交流，解决

问题，并推动

小镇的发展

。HuggingGPT [30] 则

以 ChatGPT 为核心

控制器，用户

给定一个任

务后，它首先

将任务拆分

为多个子任

务，并从 Huggingface

上调

用不同的模

型来解决这

些子任务。在

得到子任务

的结果

之后

，HuggingGPT 将这些结果

汇总起来，返

回最终结果

，展现了其在

复杂任务编

排规划和模

型调度协同

方面的强大

能力。这些 Agent

的

研究不仅推

动了大语言

模

型的发展

与应用落地

，也为 Agent 在现实

世界中的应

用提供了新

的视角和方

法。

3.5.2 数据合成

数据质量是

制约大语言

模型性能上

限的关键要

素之一，正所

谓“Garbage in,

Garbage

Out”[27]，无论模型

架构多么优

秀，训练算法

多么优秀，计

算资源多么

强

大，最终模

型的表现都

高度依赖于

训练数据的

质量。然而，获

取高质量数

据资源面

临

挑战。研究显

示，公共领域

的高质量语

言数据，如书

籍、新闻、科学

论文和维基

百科，预计将

在 2026

年左右耗

尽 [33]。特定领域

的垂直数据

因隐私保护

和标注难

度

高等问题，难

以大量提供

高质量数据

，限制了模型

的进一步发

展。

面对这些

挑战，数据合

成作为一种

补充或替代

真实数据的

有效手段，因

其可

控性、安

全性和低成

本等优势而

受到广泛关

注。特别是利

用大语言模

型生成训练

数据，已成为

当前研究的

热点议题，其

通过 Prompt 工程技

术，利用大语

言模型强

大

的思维能力

、指令跟随能

力，来合成高

质量数据，其

中一个代表

性方法是

Self￾Instruct [37]。Self-Instruct 通

过 Prompt

工程技术

构建 Prompt，通过多

步骤调用大

语

言模型，并

依据已有的

少量指令数

据，合成大量

丰富且多样

化的指令数

据。以金融

141

第

3 章 Prompt 工程

场景

为例，我们可

以先人工标

注少量金融

指令数据（如

数百条），例如

“请根据提

供

的几只基金

情况，为我挑

选出最佳基

金”。随后，我们

运用 Self-Instruct 方法调

用

大语言模

型，我们能够

将这些数据

扩展至数万

条，且保持高

质量和多样

性，如生成

“请

指导我如何

选择股票和

基金进行投

资”等指令。

{若

干演示示例

}...... 生成的指令

：判断下面句

子的情感是

积极还是消

极

2. 指令生成

种子任务

3. 指

令分类

4. 数据

生成 5. 数据过

滤

任务

分类

任务

给定分

类任务指令

，先生成分类

标签，再生成

待分类内容

......

{若干演示示

例}

指令：判断

下面句子的

情感为积极

还是消极

分

类标签：消极

输入：小浣熊

连续吃了20包

烧烤味的干

脆面，撑得肚

子疼。 生成任

务

给定生成

任务指令，构

造生成任务

输入和回答

......

{若干演示示

例}

指令：扩写

下面给出的

这段话

输入

：小浣熊吃干

脆面

回答：小

浣熊吃干脆

面，它一边嚼

着，一边眯起

眼睛，......

任务池

{若干演示示

例}

生成的指

令：扩写下面

给出的这段

话

4. 数据生成

1.

构造任务池

分类任务指

令

生成任务

指令

输入模

型的Prompt

模型生

成的回答内

容

图 3.31: Self-Instruct 流程示

例图。

如图 3.31所

示，Self-Instruct 包含构建

任务池、指令

生成、指令分

类、数据生

成

、数据过滤五

个步骤。任务

池存储了初

始的指令数

据以及存储

后续生成的

指令

数据；指

令生成负责

参考任务池

中的样例，生

成指令数据

中的指令部

分；指令分类

将生成的指

令分类为分

类任务或生

成任务，在这

两种任务模

式下，生成数

据的方

式不

同；数据生成

则根据已有

的指令，生成

指令数据中

的输入部分

和回答部分

；数

据过滤则

复杂去除低

质量的数据

，保证生成的

指令数据质

量。它从一个

有限的手

动

编写任务种

子集开始，通

过与大语言

模型交互，不

断生成指令

数据，扩充原

始的

数据集

。

1. 构建任务池

。人工手工设

计了 175

个指令

数据集，作为

初始任务池

，后续

模型会

不断参考任

务池的示例

，来生成指令

数据，并将生

成的指令数

据加入

任务

池中。

142

张超 毛

玉仁 胡中豪

2. 指令生成。从

任务池中随

机抽取

8 个现

有指令作为

演示示例组

成 Prompt

中的上下

文，以少样本

学习的方式

构造

Prompt 让模型

生成指令。图

中生成了

两

个指令：“扩写

下面给出的

这段话”和“判

断下面句子

的情感为积

极还是消

极

”。

3. 指令分类。编

写若干条“指

令-分类任务

/生成任务”样

例对，作为上

下文

构造 Prompt，让

模型判断该

指令对应的

任务是分类

任务还是生

成任务。图中

“扩写下面给

出的这段话

”和“判断下面

句子的情感

为积极还是

消极”分别被

分类为生成

任务和分类

任务。

4. 数据生

成。对分类任

务和生成任

务使用 Prompt 工程

中的上下文

学习技术，

构

造不同的 Prompt 来

生成指令数

据中的输入

部分和回答

部分。对于“扩

写下

面给出

的这段话”这

条指令，它是

分类任务，在

Prompt

中指示模型

先生成类

别

标签，再生成

相应的输入

内容，从而使

得生成的输

入内容更加

偏向于该类

别标签；对于

“判断下面句

子的情感为

积极还是消

极”这条指令

，它是生成

任

务，在 Prompt

中指示

模型先生成

输入内容，再

生成对应的

回答。

5. 数据过

滤。通过设置

各种启发式

方法过滤低

质量或者高

重复度的指

令数

据，然后

将剩余的有

效任务添加

到任务池中

。

上述过程中

，第二步到第

五步不断循

环迭代，直到

任务池中收

集到足够的

数据时

停止

。

数据合成的

意义在于，它

不仅能够缓

解高质量数

据资源的枯

竭问题，还能

通

过生成多

样化的数据

集，提高模型

的泛化能力

和鲁棒性。此

外，数据合成

还能在保

护

隐私的前提

下，为特定领

域的垂直数

据提供有效

的补充。并且

，通过利用大

型语

言模型

进行数据合

成，生成的数

据可以用于

微调小型模

型，显著提升

其效果，实现

模型蒸馏。

143

第

3

章 Prompt 工程

3.5.3

Text-to-SQL

互联

网技术进步

带动数据量

指数增长，目

前金融、电商

等各行业的

海量高价值

数据主要存

储在关系型

数据库中。从

关系型数据

库中查询数

据需要使用

结构化查

询

语言（Structured Query

Language，SQL）进行编

程。然而，SQL 逻辑

复杂复杂，

编

程难度较高

，只有专业人

员才能够熟

练掌握，这为

非专业人士

从关系型数

据库

中查询

数据设置了

障碍。为了降

低数据查询

门槛，零代码

或低代码来

的数据查询

接口亟待研

究。Text-to-SQL

技术可以

将自然语言

查询翻译成

可以在数据

库中执行

的

SQL 语句，是实现

零代码或低

代码数据查

询的有效途

径。通过 Text-to-SQL

的方

式，我们只需

要动动嘴，用

大白话就能

对数据库进

行查询，而不

必自己编写

SQL

语句。这让广

大普通人都

可以自由操

作数据库，挖

掘数据库中

隐含的数据

价值。

给你给

出数据库Schema信

息以及一个

问题，写出问

题对应的SQL语

句。

数据库表

格和他们的

属性如下：

#

# Owners (

state, owner_id, name )

# Dogs ( owner_id,

dog_id, name, age )

# Raccoons ( owner_id,

raccoon_id, name, age )

#

小

浣熊“Peter”的主人

叫什么名字

？

SELECT a.name

FROM Owners as a

JOIN Raccoons as b

ON a.owner_id = b.owner_id

WHERE b.name = "Peter

"

图 3.32: Text-to-SQL

示例。

传统

的 Text-to-SQL 方法通常

使用预训练

-微调的范式

训练

Text-to-SQL 模型。

这

些方法需要

大量训练数

据，费时费力

且难以泛化

到新的场景

。近年，大语言

模

型涌现出

的代码生成

能力，为零样

本

Text-to-SQL 带来可能

。图 3.32 展示了一

个应

用大语

言模型进行

零样本 Text-to-SQL 的例

子。用户把问

题输入给大

语言模型，询

问“小浣熊“Peter”的

主人叫什么

名字？”。大语言

模型会根据

用户的问题

，生成

对应的

SQL

语句，即”SELECT a.name FROM Owners

as a JOIN Raccoons

as b ON

144

张超

毛玉仁 胡中

豪

a.owner_id =

b.owner_id WHERE b.name =

’Peter’;”。随后，SQL 语句

可以在对应

的

数据库中

执行，得到用

户提问的答

案，并返回给

用户。

最早使

用大语言模

型来做零样

本

Text-to-SQL 的方法是

C3 [7] 。C3

的核心在

于

Prompt 工程的设计

，给出了如何

针对 Text-to-SQL

任务设

计 Prompt 来优化生

成

效果。如图

3.33所示，C3

由三个

关键部分组

成：清晰提示

（Clear Prompting）、提

示校准（Calibration with

Hints）和

一致输出（Consistent Output），分

别对应模型

输

入、模型偏

差和模型输

出。

Calibration

Bias

Prompting

Clear Prompting

Which states have both

owners and

professionals living

there?

first_name last_name ......

dog_id owner_id ......

owner_id

first_name ......

treatment_id dog_id

......

...... ...... ......

Professionals

Dogs

Owners

Treatments

......

Column Name Table

Name

Question:

Schema:

Clear

Prompting

### Complete sqlite

SQL query only and

with no

explanation, and

do not select extra

columns that

are not

explicitly requested in the

query, 

### Sqlite

SQL tables, with their

properties: 

#

#

Owners ( state, owner_id,

first_name )

# Professionals

( state, first_name, last_name)

# Dogs (owner_id, dog_id,

name, age) 

#

### Which states have

both owners and

professionals

living there? 

SELECT

#

# Owners (

state, owner_id, first_name )

# Professionals ( state,

first_name, last_name)

# Dogs

(owner_id, dog_id, name, age)

# 

Ⅱ SQL

Generation I Schema Linking

Sample a set of

SQLs

Vote for final

SQL

 based on

execution Consistency

SELECT state

FROM owners WHERE state

IN (SELECT

state FROM

professionals)

SELECT owners.state FROM

owners INNER JOIN

professionals

ON owners.state = professionals.state

SELECT owners.state FROM owners

INTERSECT

SELECT professionals.state FROM

professionals

SELECT owners.state FROM

owners WHERE owners.state

IN

(SELECT professionals.state FROM professionals)

Execution

Result1

Execution

Result2

Execution

Result1

Execution

Result1

Selected

SQL

Calibration Bias

Prompting

Tip1: COUNT(*) should

not be included in

the SELECT statement, when

it is

only needed

in the ORDER BY

clause. ......

You are

now an excellent SQL

writer, first I'll give

you some tips, and

I need you

to

remember the tips, and

do not make same

mistakes.

Thank you for

the tip! I'll keep

in mind that ......

Tip2: Avoid using "IN",

"OR", and "LEFT JOIN"

to prevent extra results

in SQL

queries. ......

Thank you for the

tip! I'll keep in

mind that ......

图

3.33: C3 方法整

体框架图。

在

模型输入端

，C3

提出要采用

清晰提示（Clear Prompting）。其

包含两部

分

：（1）清晰布局（Clear Layout），通

过明确符号

划分指令、上

下文和问题

，确保

指令模

板清晰，显著

提升 ChatGPT 对问题

的理解能力

。这一策略体

现了 Prompt

技

巧中

的“排版清晰

”原则，确保信

息有效传递

。（2）清晰上下文

（Clear Context），

设计零样本

Prompt，指示

ChatGPT 从数据

库中召回与

问题相关的

表和列。此举

旨

在检索关

键信息，去除

无关内容，减

少上下文长

度和冗余信

息，从而提高

生成 SQL

145

第 3 章

Prompt 工

程

的准确性

。这体现了 Prompt

技

巧中“上下文

丰富且清晰

”的原则，确保

了模型在

处

理任务时能

够聚焦于关

键信息。

为应

对ChatGPT本身的固

有偏差，C3中采

用提示校准

（Calibration with

Hints）。

通过插件式

校准策略，利

用包含历史

对话的上下

文提示，将先

验知识纳入

ChatGPT。

在历史对话

中，设定 ChatGPT

为优

秀 SQL 专家角色

，通过对话引

导其遵循预

设提

示，通过

这种角色扮

演的方式，有

效校准偏差

。

在模型的输

出端，C3 采用输

出校准（Output Calibration）来应

对大语言模

型

固有的随

机性。C3

将 Self-Consistency 方法

应用到 Text-to-SQL

任务

上，对多种推

理路径进行

采样，选择最

一致的答案

，增强输出稳

定性，保持 SQL 查

询的一致性

。

3.5.4

GPTS

GPTs是OpenAI推出的支

持用户自定

义的GPT 应用，允

许用户通过

编写Prompt，

添加工

具等方式创

建定制版的

GPT

应用，也可以

使用别人分

享的 GPTs 模型。

图

3.34:

制作 GPTS 的页面

图 6。

146

张超 毛玉

仁 胡中豪

图

3.34展示了如何

制作 GPTs。在这个

专属页面中

，用户拥有充

分的自由度

来

自定义 GPTs

的

能力和功能

。通过“Description”指明该

GPTs 的功能，方便

其他用

户快

速理解其功

能和作用；而

“Instructions”则是为 GPTs

预设

Prompt，使得 GPTs

能够实

现预期的功

能。运用本章

所介绍的 Prompt

工

程技术编写

这些关键内

容，可

以显著

提高 GPTs 的性能

。此外，用户还

可以定制专

属的知识库

，并根据需求

选择

所需的

能力，例如网

络搜索、图像

生成、代码解

释等。完成个

性化 GPTs 的制作

后，

用户可以

选择将其分

享，供其他用

户使用。

在本

节中，我们详

细探讨了 Prompt 工

程在多个领

域中的具体

应用场景应

用场

景。Prompt

工程

在提升大语

言模型的交

互和执行能

力方面具有

重要作用。无

论是

在任务

规划、数据合

成、个性化模

型定制，还是

Text-to-SQL 中，Prompt 工程都展

现了其独特

的优势和广

阔的应用前

景。

参考文献

[1] Maciej Besta et

al. “Graph of Thoughts:

Solving Elaborate Problems with

Large

Language Models”. In:

AAAI. 2024.

[2] Tom

B. Brown et al.

“Language Models are Few-Shot

Learners”. In: arXiv preprint

arXiv:2005.14165 (2020).

[3] Tom

B. Brown et al.

“Language Models are Few-Shot

Learners”. In: NeurIPS. 2020.

[4] Stephanie C. Y.

Chan et al. “Data

Distributional Properties Drive Emergent

In￾Context Learning in Transformers”.

In: NeurIPS. 2022.

[5]

Aakanksha Chowdhery et al.

“PaLM: Scaling Language Modeling

with Pathways”.

In: Journal

of Machine Learning Research

24 (2023), 240:1–240:113.

[6]

DeepSeek-AI et al. “DeepSeek-V2:

A Strong, Economical, and

Efficient Mixture￾of-Experts Language Model”.

In: arXiv preprint arXiv:2405.04434

(2024).

[7] Xuemei Dong

et al. “C3: Zero-shot

Text-to-SQL with ChatGPT”. In:

arXiv preprint

arXiv:2307.07306 (2023).

[8] Philip Gage. “A

new algorithm for data

compression”. In: The C

User’s Journal

12.2 (1994),

pp. 23–38.

147

第

3 章 Prompt 工程

[9] Dan Hendrycks et

al. “Measuring Massive Multitask

Language Understanding”. In:

ICLR.

2021.

[10] Sepp Hochreiter

and Jürgen Schmidhuber. “Long

Short-Term Memory”. In: Neural

Computation 9.8 (1997), pp.

1735–1780.

[11] Huiqiang Jiang

et al. “LLMLingua: Compressing

Prompts for Accelerated Infer￾ence

of Large Language Models”.

In: EMNLP. 2023.

[12]

Takeshi Kojima et al.

“Large Language Models are

Zero-Shot Reasoners”. In:

NeurIPS.

2022.

[13] Aobo Kong

et al. “Better Zero-Shot

Reasoning with Role-Play Prompting”.

In:

arXiv preprint arXiv:2308.07702

(2023).

[14] Jannik Kossen,

Yarin Gal, and Tom

Rainforth. “In-Context Learning Learns

Label Relationships but Is

Not Conventional Learning”. In:

arXiv preprint

arXiv:2307.12375 (2024).

[15] Junlong Li et

al. “Self-Prompting Large Language

Models for Zero-Shot Open￾Domain

QA”. In: arXiv preprint

arXiv:2212.08635 (2024).

[16] Xiaonan

Li et al. “Unified

Demonstration Retriever for In-Context

Learning”. In:

ACL. 2023.

[17] Jiachang Liu et

al. “What Makes Good

In-Context Examples for GPT-3?”

In: ACL.

2022, pp.

100–114.

[18] Nelson F

Liu et al. “Lost

in the middle: How

language models use long

contexts”. In:

Transactions of

the Association for Computational

Linguistics 12 (2024), pp.

157–

173.

[19] Yao

Lu et al. “Fantastically

Ordered Prompts and Where

to Find Them: Overcoming

Few-Shot Prompt Order Sensitivity”.

In: ACL. 2022.

[20]

Man Luo et al.

“In-context Learning with Retrieved

Demonstrations for Language

Models:

A Survey”. In: arXiv

preprint arXiv:2401.11624 (2024).

[21]

Ziyang Luo et al.

“Wizardcoder: Empowering code large

language models with

evol-instruct”.

In: arXiv preprint arXiv:2306.08568

(2023).

[22] Yuren Mao

et al. “FIT-RAG: Black-Box

RAG with Factual Information

and Token

Reduction”. In:

arXiv preprint arXiv:2403.14374 (2024).

[23] Sewon Min et

al. “Rethinking the Role

of Demonstrations: What Makes

In-Context

Learning Work?” In:

EMNLP. 2022.

148

张

超

毛玉仁 胡

中豪

[24] Jane

Pan et al. “What

In-Context Learning ”Learns” In-Context:

Disentangling Task

Recognition and

Task Learning”. In: ACL.

2023.

[25] Joon Sung

Park et al. “Generative

Agents: Interactive Simulacra of

Human Behav￾ior”. In: UIST.

2023.

[26] Allan Raventós

et al. “Pretraining task

diversity and the emergence

of non-Bayesian

in-context learning

for regression”. In: NeurIPS.

2023.

[27] L. Todd

Rose and Kurt W.

Fischer. “Garbage in, garbage

out: Having useful data

is everything”. In: Measurement:

Interdisciplinary Research and Perspectives

9.4

(2011), pp. 224–226.

[28] Alexander Scarlatos and

Andrew Lan. “RetICL: Sequential

Retrieval of In-Context

Examples

with Reinforcement Learning”. In:

arXiv preprint arXiv:2305.14502

(2024).

[29] Mike Schuster and

Kaisuke Nakajima. “Japanese and

korean voice search”. In:

ICASSP. 2012.

[30] Yongliang

Shen et al. “HuggingGPT:

Solving AI Tasks with

ChatGPT and its

Friends

in Hugging Face”. In:

NeruIPS. 2023.

[31] Seongjin

Shin et al. “On

the Effect of Pretraining

Corpora on In-context Learning

by a Large-scale Language

Model”. In: NAACL. 2022.

[32] Rohan Taori et

al. “Alpaca: A strong,

replicable instruction-following model”. In:

Stanford Center for Research

on Foundation Models. (2023).

[33] Pablo Villalobos et

al. “Will we run

out of data? An

analysis of the limits

of scaling

datasets in

Machine Learning”. In: arXiv

preprint arXiv:2211.04325 (2022).

[34]

Changhan Wang, Kyunghyun Cho,

and Jiatao Gu. “Neural

machine translation with

byte-level

subwords”. In: AAAI. 2020.

[35] Lei Wang et

al. “A survey on

large language model based

autonomous agents”. In:

Frontiers

of Computer Science 18.6

(2024), p. 186345.

[36]

Xuezhi Wang et al.

“Self-Consistency Improves Chain of

Thought Reasoning in

Language

Models”. In: ICLR. 2023.

[37] Yizhong Wang et

al. “Self-Instruct: Aligning Language

Models with Self￾Generated Instructions”.

In: ACL. 2023.

[38]

Jason Wei et al.

“Chain-of-Thought Prompting Elicits Reasoning

in Large Language

Models”.

In: NeurIPS. 2022.

149

第 3 章 Prompt

工

程

[39] Jason Wei

et al. “Emergent Abilities

of Large Language Models”.

In: Transaction

of Machine

Learning Research 2022 (2022).

[40] Sang Michael Xie

et al. “An Explanation

of In-context Learning as

Implicit

Bayesian Inference”. In:

ICLR. 2022.

[41] An

Yang et al. “Qwen2

Technical Report”. In: arXiv

preprint arXiv:2407.10671

(2024).

[42]

Shunyu Yao et al.

“Tree of Thoughts: Deliberate

Problem Solving with Large

Lan￾guage Models”. In: NeurIPS.

2023.

[43] Kang Min

Yoo et al. “Ground-Truth

Labels Matter: A Deeper

Look into Input-Label

Demonstrations”.

In: EMNLP. 2022.

[44]

Tao Yu et al.

“Spider: A Large-Scale Human-Labeled

Dataset for Complex and

Cross-Domain Semantic Parsing and

Text-to-SQL Task”. In: EMNLP.

2018.

[45] Chao Zhang

et al. “FinSQL: Model-Agnostic

LLMs-based Text-to-SQL Framework

for

Financial Analysis”. In: SIGMOD.

2024.

[46] Zhuosheng Zhang

et al. “Automatic Chain

of Thought Prompting in

Large Lan￾guage Models”. In:

ICLR. 2023.

[47] Wayne

Xin Zhao et al.

“A Survey of Large

Language Models”. In: arXiv

preprint

arXiv:2303.18223 (2023).

[48]

Yuxiang Zhou et al.

“The Mystery of In-Context

Learning: A Comprehensive Sur￾vey

on Interpretation and Analysis”.

In: arXiv preprint arXiv:2311.00237

(2024).

150

4 参数高效

微调

大语言

模型从海量

的预训练数

据中掌握了

丰富的世界

知识。但“尺有

所短”，

对于预

训练数据涉

及较少的垂

直领域，大语

言模型无法

仅通过提示

工程来完成

领

域适配。为

了让大语言

模型更好的

适配到这些

领域，需要对

其参数进行

微调。但

由于

大语言模型

的参数量巨

大，微调成本

高昂，阻碍了

大语言模型

在一些垂直

领

域的应用

。为了降低微

调成本，亟需

实现效果可

靠、成本可控

的参数高效

微调。本

章将

深入探讨当

前主流的参

数高效微调

技术，首先简

要介绍参数

高效微调的

概念、

参数效

率和方法分

类，然后详细

介绍参数高

效微调的三

类主要方法

，包括参数附

加方法、参数

选择方法和

低秩适配方

法，探讨它们

各自代表性

算法的实现

和优势。

最后

，本章通过具

体案例展示

参数高效微

调在垂直领

域的实际应

用。

* 本书持续

更新，GIT Hub 链接为

：https://github.com/ZJU-LLMs/Foundations-of-LLMs。

第 4 章 参数高

效微调

4.1 参数

高效微调简

介

对于预训

练数据涉及

较少的垂直

领域，大语言

模型需要对

这些领域及

相应的

下游

任务进行适

配。上下文学

习和指令微

调是进行下

游任务适配

的有效途径

，但它

们在效

果或效率上

存在缺陷。为

弥补这些不

足，参数高效

微调（Parameter-Efficient

Fine-Tuning, PEFT）技术应

运而生。本节

将首先对上

下文学习和

指令微调进

行回顾，

并分

析它们的优

缺点以及在

实际应用中

的局限性。接

着，我们将详

细介绍参数

高

效微调的

概念及其重

要性，阐述其

在降低成本

和提高效率

方面的显著

优势。随后，

我

们将对主流

的 PEFT 方法进行

分类，包括参

数附加方法

、参数选择方

法和低秩适

配方法，介绍

每种方法的

基本原理和

代表性工作

。

4.1.1 下游任务适

配

通常，大语

言模型通过

在大规模数

据集上进行

预训练，能够

积累丰富的

世界

知识，并

获得处理多

任务的能力

[43]。但由于开源

大语言模型

训练数据有

限，因

此仍存

在知识边界

，导致其在垂

直领域（如医

学、金融、法学

等）上的知识

不足，

进而影

响在垂直领

域的性能表

现。因此，需要

进行下游任

务适配才能

进一步提高

其在垂直和

细分领域上

的性能。主流

的下游任务

适配方法有

两种：a) 上下文

学习

（In-context

learning） [8]；b）指令微

调（Instruction Tuning） [53]。

1. 上下文学

习

在之前的

内容中，我们

已经介绍过

上下文学习

的相关内容

。它的核心思

想是将

不同

类型的任务

都转化为生

成任务，通过

设计

Prompt 来驱动

大语言模型

完成这些

下

游任务。小样

本上下文学

习（Few-shot in-context

learning）将数据集

中的样本-标

签对转化为

自然语言指

令（Instruction）和样例（Demonstrations），并

拼接上需要

测

试的样本

一同输入给

大语言模型

，将模型输出

作为最终预

测结果。上下

文学习完

152

葛

宇航

毛玉仁

### 指令：

请根据

你了解的关

于鹈鹕的相

关知识，回答

以下问题。

###

示

例：

Q：鹈鹕的主

要食物来源

？

A：鹈鹕的主要

食物来源是

鱼类。它们利

用长而带有

喉囊的喙来

捕捉鱼，并擅

长在浅水区

和沿海地区

捕鱼。这些区

域通常鱼类

资源丰富，提

供了充足的

食物供给。

Q：鹈

鹕会飞吗？

A：是

的，鹈鹕会飞

。鹈鹕是一种

大型水鸟，尽

管体型庞大

，但它们有强

壮的翅膀，能

够飞行。它

们

经常在水面

上滑翔，利用

气流进行长

距离飞行。

图

4.1: 指令数据样

例。

全不需要

对模型进行

参数更新，因

此能快速将

单个模型应

用到多种不

同的任务上

。

尽管在实际

应用中，上下

文学习能有

效利用大语

言模型的能

力，但它缺点

也

很明显：1）上

下文学习的

性能和微调

依旧存在差

距，并且 Prompt

设计

需要花费大

量的人力成

本，不同 Prompt 的最

终任务性能

有较大差异

；2）上下文学习

虽然完全

不

需要训练，但

在推理阶段

的代价会随

Prompt

中样例的增

多快速增加

。因此，微

调大

语言模型在

许多场景和

任务中依旧

是必要的，尤

其是在垂直

领域。

2. 指令微

调

指令微调

（Instruction Tuning）是另一种进

行下游任务

适配的方法

。指令微调

旨

在对模型进

行任务指令

的学习，使其

能更好地理

解和执行各

种自然语言

处理任

务的

指令。指令微

调需首先构

建指令数据

集，然后在该

数据集上进

行监督微调

。

指令数据构

建：指令数据

通常包含指

令（任务描述

）、示例（可选）、问

题和

回答，如

图 4.1 所示。构造

这种指令数

据一般有两

种方式

[53]：1）数据

集成。

通过使

用模板将带

标签的自然

语言数据集

，转换为指令

格式的 < 输入

，输出

> 对。如 Flan [47]

和

P3 [37] 数据集基于

数据集成策

略构建；2）大语

言模型

生成

。通过人工收

集或者手写

少量指令数

据，再使用

GPT-3.5-Turbo 或

GPT4

等闭源大语

言模型进行

指令扩展。如

InstructWild [33]

和 Self-Instruct [46] 数

据集采

用这种方法

生成。

153

第 4

章 参

数高效微调

可调参数 冻

结参数

低秩

适配方法

参

数选择方法

选择参数 低

秩参数

参数

附加方法

附

加参数

外部

参数 内部参

数

图 4.2:

高效参

数微调方法

分类学。

监督

微调：通过上

述方法构建

完数据集后

，可以用完全

监督的方式

对预训

练模

型进行微调

，在给定指令

和输入的情

况下，通过顺

序预测输出

中的每个

token

来

训练模型。经

过微调的大

语言模型能

够显著提升

指令遵循（Instruction￾following）能

力，这有助于

增强其推理

水平，泛化到

新任务和新

领域。

尽管指

令微调能有

效帮助大语

言模型理解

新领域的数

据知识，提高

大语言模

型

在下游任务

上的性能。然

而，监督微调

需要较大的

计算资源，以

LLaMA2-7B [40]

模型为例，直

接进行全量

微调需要近

60GB 内存，普通的

消费级 GPU（如 RTX4090

（24GB））无

法完成微调

。因此，为了在

资源受限的

环境中有效

微调大语言

模型，研

究参

数高效的微

调技术显得

尤为重要。

4.1.2 参

数高效微调

参数高效微

调（Parameter-Efficient

Fine-Tuning，PEFT）旨在避免

微调全部参

数，减少在微

调过程中需

要更新的参

数数量和计

算开销，从而

提高微调大

语言模

型的

效率。主流的

PEFT 方法可以分

为三类：参数

附加方法（Additional Parameters

Methods），参

数选择方法

（Parameter Selection Methods）以及低秩适

配方法（Low￾Rank Adaptation

Methods），其方

法思想如图

4.2 所示。

154

葛宇航

毛玉仁

1. 参数

附加方法

参

数附加方法

（Additional Parameters

Methods）在模型结构

中附加新的

、较小

的可训

练模块。在进

行微调时，将

原始模型参

数冻结，仅微

调这些新加

入的模块，

从

而来实现高

效微调。这些

模块通常称

为适应层（Adapter Layer）。它

们被插入到

模

型的不同

层之间，用于

捕获特定任

务的信息。由

于这些新增

的适应层参

数量很小，

所

以参数附加

方法能够显

著减少需要

更新的参数

量。典型方法

包括：适配器

微调

（Adapter-tuning）[18]、提示微

调（Prompt-tuning）[23]、前缀微调

（Prefix-tuning）

[24]

和 代理微调

（Proxy-tuning）[27] 等。参数附加

方法将在 4.2

节

进行具体介

绍。

2. 参数选择

方法

参数选

择方法（Parameter

Selection Methods）仅选

择模型的一

部分参数进

行微

调，而冻

结其余参数

。这种方法利

用了模型中

仅有部分参

数对下游任

务具有决定

性作用的特

性，“抓住主要

矛盾”，仅微调

这些关键参

数。选择性地

微调这些关

键

参数，可以

在降低计算

负担的同时

提升模型的

性能。典型的

方法包括：BitFit

[50]、

Child-tuning [49] 以

及

FishMask [39] 等。参数选

择方法的将

在 4.3

节具体介

绍。

3. 低秩适配

方法

低秩适

配方法（Low-rank

Adaptation Methods）通过

低秩矩阵来

近似原始权

重

更新矩阵

，并冻结原始

参数矩阵，仅

微调低秩更

新矩阵。由于

低秩更新矩

阵的参数

数

量远小于原

始的参数更

新矩阵，因此

大幅节省了

微调时的内

存开销。LoRA

[19]

是经

典的低秩适

配方法，后续

有 AdaLoRA [52]、DyLoRA

[42] 以及 DoRA [29]

等

变

体被提出，进

一步改进了

LoRA 性能。低秩适

配方法将在

4.4 节具体介绍

。

4.1.3 参数高效微

调的优势

参

数高效微调

有以下优势

：1) 计算效率高

：PEFT

技术减少了

需要更新的

参数

数量，从

而降低了训

练时的计算

资源消耗；2）存

储效率高：通

过减少需要

微调的参

155

第

4

章 参数高效

微调

数数量

，PEFT 显著降低了

微调模型的

存储空间，特

别适用于内

存受限的设

备；3）

适应性强

：PEFT 能够快速适

应不同任务

，而无需重新

训练整个模

型，使得模型

在

面对变化

环境时具有

更高的灵活

性。

下面我们

将通过一个

具体案例来

深入探讨

PEFT 技

术如何显著

提升参数效

率。

具体来说

，表 4.1

1 详细展示

了在配备 80GB 显

存的

A100 GPU 以及 64GB

以

上 CPU

内存的高

性能硬件环

境下，对 bigscience

模型

进行全量微

调与采用参

数高效微调

方

法 LoRA（该方法

将在 4.4节中详

细介绍）时，GPU

内

存的消耗情

况对比。根据

该

表 4.1: 全量参

数微调和参

数高效微调

显存占用对

比（OOM

代表超出

内存限制）。

模

型名 全量参

数微调 参数

高效微调

(LoRA)

bigscience/T0_3B 47.14GB GPU

/ 2.96GB CPU 14.4GB

GPU / 2.96GB CPU

bigscience/mt0-xxl (12B params) OOM

GPU 56GB GPU /

3GB CPU

bigscience/bloomz-7b1 (7B

params) OOM GPU 32GB

GPU / 3.8GB CPU

表

格可以看出

，对于 80GB 显存大

小的 GPU，全量参

数微调

7B/12B 参数

的模型，

会导

致显存直接

溢出。而在使

用 LoRA

后，显存占

用被大幅缩

减，使得在单

卡上微

调大

语言模型变

得可行。

本节

首先介绍了

对大语言模

型进行下游

任务适配的

两类主流范

式：上下文学

习和指令微

调。然而，由于

性能和计算

成本方面的

限制，这两类

范式难以适

应需

求。因此

，需要研究参

数高效微调

技术，即

PEFT。PEFT 仅对

模型的一小

部分参数

进

行更新，在保

证不牺牲性

能的前提下

有效减少了

模型微调所

需的参数量

，从而

节约了

计算和存储

资源。本节我

们对主流

PEFT 方

法进行了分

类，在后续小

节中，

我们将

根据本节给

出的分类学

详细介绍主

流的三类 PEFT

方

法：参数附加

方法 4.2、

参数选

择方法 4.3

以及

低秩适配方

法 4.4，并探讨 PEFT 的

相关应用与

实践

4.5。

1表格数

据来源：https://github.com/huggingface/peft

156

葛宇

航

毛玉仁

4.2 参

数附加方法

参数附加方

法（Additional Parameter

Methods）通过增加

并训练新的

附加参数

或

模块对大语

言模型进行

微调。参数附

加方法按照

附加位置可

以分为三类

：加在输

入、加

在模型以及

加在输出。本

节将对三类

方法的各自

代表性工作

进行具体介

绍。

4.2.1

加在输入

加在输入的

方法将额外

参数附加到

模型的输入

嵌入（Embedding）中，其中

最

经典的方

法是 Prompt-tuning [23]。Prompt-tuning

在模型

的输入中引

入可微分的

连

续张量，通

常也被称为

软提示（Soft prompt）。软提

示作为输入

的一部分，与

实际

的文本

数据一起被

送入模型。在

微调过程中

，仅软提示的

参数会被更

新，其他参数

保持不变，因

此能达到参

数高效微调

的目的。

具体

地，给定一个

包含 n 个 token

的输

入文本序列

{w1, w2, . .

. , wn}，首先通

过嵌

入层将其转

化为输入嵌

入矩阵

X ∈ R

n×d，其中

d

是嵌入空间

的维度。新加

入

的软提示

参数被表示

为软提示嵌

入矩阵 P ∈

R

m×d，其中

m 是软提示长

度。然后，

将软

提示嵌入拼

接上输入嵌

入矩阵，形成

一个新矩阵

[P;

X] ∈ R

(m+n)×d，最后输

入 Transformer 模

型。通过反向

传播最大化

输出概率似

然进行模型

训练。训练过

程

仅软提示

参数

P 被更新

。图 4.3给出了 Prompt-tuning

的

示意图。

在实

际使用中，软

提示的长度

范围是 1 到

200，并

且通常在 20 以

上就能有一

定的性能保

证。此外，软提

示的初始化

对最终的性

能也会有影

响，使用词表

中的

token

或者在

分类任务中

使用类名进

行初始化会

优于随机初

始化。值得一

提的是，

Prompt-tuning 原本

被提出的动

机不是为了

实现参数高

效微调，而是

自动学习提

示

词。在第三

章我们提到

，利用大语言

模型的常见

方式是通过

提示工程，也

被称为是

硬

提示（Hard prompt），这是因

为我们使用

的离散 prompt 是不

可微分的。问

题在于

157

第 4 章

参数高效微

调

语言模型

…

软提示嵌入

输入嵌入

可

调参数

冻结

参数

…

图 4.3: Prompt-tuning

示意

图。

大语言模

型的输出质

量高度依赖

于提示词的

构建，要找到

正确的 “咒语

” 使得我们

的

大语言模型

表现最佳，需

要花费大量

时间。因此，采

用可微分的

方式，通过反

向

传播自动

优化提示词

成为一种有

效的方法。

总

的来说，Prompt-tuning 有以

下优势：(1)

内存

效率高：Prompt-tuning 显著

降

低了内存

需求。例如，T5-XXL 模

型对于特定

任务的模型

需要

11B 参数，但

经过

Prompt-tuning 的模型

只需要

20480 个参

数（假设软提

示长度为 5）；(2) 多

任务能

力：可

以使用单一

冻结模型进

行多任务适

应。传统的模

型微调需要

为每个下游

任

务学习并

保存任务特

定的完整预

训练模型副

本，并且推理

必须在单独

的批次中执

行。Prompt-tuning 只需要为

每个任务存

储一个特定

的小的任务

提示模块，并

且可

以使用

原始预训练

模型进行混

合任务推理

（在每个任务

提示词前加

上学到的

soft

prompt）。(3) 缩

放特性：随着

模型参数量

的增加，Prompt-tuning 的性

能会逐渐增

强，

并且在 10B 参

数量下的性

能接近（多任

务）全参数微

调的性能。

4.2.2

加

在模型

加在

模型的方法

将额外的参

数或模型添

加到预训练

模型的隐藏

层中，其中经

典的方法有

Prefix-tuning [24]、Adapter-tuning [18]

和 AdapterFusion [35]。

158

葛宇航 毛

玉仁

层正则

化

注意力层

多头注意力

Value

Vector +

全连接层

层

正则化

MLP

图 4.4: Prefix-tuning

示

意图。

1. Prefix-tuning

Prefix-tuning

和上一

节介绍的 Prompt-tuning 十

分类似，区别

在于 Prompt-tuning

仅将软

提示添加到

输入嵌入中

，而 Prefix-tuning 将一系列

连续的可训

练前缀（Pre￾fixes，即 Soft-prompt）插

入到输入嵌

入以及

Transformer 注意

力模块中，如

图 4.4所

示，Pk

和 Pv 是

插入到 Transformer

block 中的

前缀。相比 Prompt-tuning，Prefix-tuning

大

幅增加了可

学习的参数

量。

具体而言

，Prefix-tuning 引入了一组

可学习的向

量 Pk 和

Pv，这些向

量被添

加到

所有 Transformer 注意力

模块中的键

K

和值 V 之前。类

似于 Prompt-tuning，

Prefix-tuning 也会面

临前缀参数

更新不稳定

的问题，从而

导致优化过

程难以收敛

。

因此，在实际

应用中，通常

需要在输入

Transformer 模型前，先通

过一个多层

感知

机（MLP）进行

重参数化。这

意味着需要

训练的参数

包括 MLP 和前缀

矩阵两部分

。

训练完成后

，MLP

的参数会被

丢弃，仅保留

前缀参数。总

的来说，Prefix-tuning 有

159

第

4

章 参数高效

微调

层正则

化

适配器

全

连接层

上投

影矩阵

层正

则化 非线性

层

下投影矩

阵

适配器

多

头注意力层

图 4.5:

Adapter-tuning 示意图。

以

下优势：（1）参数

效率：只有前

缀参数在微

调过程中被

更新，这显著

减少了训练

参数量；（2）任务

适应性：前缀

参数可以针

对不同的下

游任务进行

定制，微调方

式

灵活；（3）保持

预训练知识

：由于预训练

模型的原始

参数保持不

变，Prefix-tuning

能够保留

预训练过程

中学到的知

识。

2. Adapter-tuning

Adapter-tuning

[18] 向预训练

语言模型中

插入新的可

学习的神经

网络模块，称

为适配器（Adapter）。适

配器模块通

常采用瓶颈

（Bottomneck）结构，即一个

上

投影层、一

个非线性映

射和一个下

投影层组成

的全连接模

块。其中，下投

影层将

信息

压缩到一个

低维的表示

，经过非线性

映射后再通

过上投影层

扩展回原始

维度。

如图 4.5所

示，Adapter-tuning 在 Transformer

的每一

个多头注意

力层（Multi-head

Attention Layer，图中红

色块）和全连

接层（Feed-forward Network

Layer，图中蓝

色

块）之后添

加适配器。与

Transformer 的全连接层

不同，由于采

用了瓶颈结

构，适

160

葛宇航

毛玉仁

配器

的隐藏维度

通常比输入

维度小。和其

他 PEFT 方法类似

，在训练时，通

过固定

原始

模型参数，仅

对适配器、层

正则化（图中

绿色框）以及

最后的分类

层参数（图

中

未标注）进行

微调，可以大

幅缩减微调

参数量和计

算量，从而实

现参数高效

微

调。适配器

模块的具体

结构如图 4.5

右

边所示，适配

器模块通常

由一个下投

影矩阵

Wd ∈ R

d×r 和一

个上投影矩

阵 Wu ∈

R

r×d 以及残差

连接组成，其

中 r

<< d：

A

(l)

= σ(Wd ∗ H

(l−1))Wu + H

(l−1)，

(4.1)

其中，σ(·) 是激

活函数，如 ReLU

或

Sigmoid。A(l) 是适配器的

输出，H(l−1) 是第

l

− 1 层

的隐藏状态

。

在适配器中

，下投影矩阵

将输入的

d 维

特征压缩到

低维 r，再用上

投影矩阵投

影回 d

维。因此

，每一层中的

总参数量为

2dr + d +

r，其中包括投

影矩阵及其

偏置

项参数

。通过设置 r ≪

d ，可

以大幅限制

每个任务所

需的参数量

。进一步地，适

配

器模块的

结构还可以

被设计得更

为复杂，例如

使用多个投

影层，或使用

不同的激

活

函数和参数

初始化策略

。此外，Adapter-tuning

还有许

多变体，例如

通过调整适

配器模块的

位置 [14, 56]、剪枝 [15]

等

策略来减少

可训练参数

的数量。

3. AdapterFusion

由于

Adapter-tuning

无需更新预

训练模型，而

是通过适配

器参数来学

习单个任

务

，每个适配器

参数都保存

了解决该任

务所需的知

识。因此，如果

想要结合多

个任务

的知

识，可以考虑

将多个任务

的适配器参

数结合在一

起。基于该思

路，AdapterFusion

提出一种

两阶段学习

的方法，先学

习多个任务

，对每个任务

进行知识提

取；再

“融

合”（Fusion）来

自多个任务

的知识。具体

的两阶段步

骤如下：

第一

阶段：知识提

取。给定 N

个任

务，首先对每

个任务分别

训练适配器

模块，

用于学

习特定任务

的知识。该阶

段有两种训

练方式，分别

如下：

Single-Task Adapters(ST-A)：对于

N 个

任务，模型都

分别独立进

行优化，各

个

任务之间互

不干扰，互不

影响。

161

第 4 章 参

数高效微调

多头注意力

层

适配器

全

连接层

适配

器

AdapterFusion

适配器  

SoftMax

AdapterFusion

层

正则化

下投

影层

上投影

层

适配器

层

正则化

层正

则化

层正则

化

非线性层

图 4.6: AdapterFusion 示意图。

Multi-Task Adapters(MT-A)：通

过多任务学

习对 N 个任务

进行联合优

化。

第二阶段

：知识组合。单

个任务的适

配器模块训

练完成后，AdapterFusion 将

不同

适配器

模块进行融

合（Fusion），以实现知

识组合。该阶

段引入一个

新的融合模

块，

该模块旨

在搜索多个

任务适配器

模块的最优

组合，实现任

务泛化。在该

阶段，语言

模

型的参数以

及 N 个适配器

的参数被固

定，仅微调 AdapterFusion

模

块的参数，并

优化以下损

失：

Ψ ← argminΨ

Ln (Dn; Θ, Φ1,

. . . ,

ΦN , Ψ) 。

(4.2)

其中，Dn 是第

n 个任务的训

练数据，Ln

是第

n 个任务的损

失函数，Θ 表示

预训练

模型

参数，Φi

表示第

i 个任务的适

配器模块参

数，Ψ 是融合模

块参数。图 4.6

给

出

AdapterFusion 的示意图

。每层的 AdapterFusion

模块

包括可学习

的 Key（键）、Value

（值）和 Query（查

询）等对应的

投影矩阵。全

连接层的输

出当作

Query，适配

器的

输出当

作 Key 和

Value，计算注

意力得到联

合多个适配

器的输出结

果。此外，在不

同的适配器

模块间参数

共享融合模

块，可以进一

步减少参数

数量。

162

葛宇航

毛玉仁

输入

代理模型

专

家模型

计算

输出

logits 差异

输

出 logits

反专家模

型

...

softmax

采样

图 4.7:

Proxy-tuning 示

意图。

4.2.3 加在输

出

在微调大

语言模型时

，通常会面临

以下问题：首

先，大语言模

型的参数数

量可

能会非

常庞大，例如

LLaMA 系列最大的

模型拥有 70B

参

数，即使采用

了 PEFT 技

术，也难

以在普通消

费级

GPU 上完成

下游任务适

应；其次，用户

可能无法直

接访

问大语

言模型的权

重（黑盒模型

），这为微调设

置了障碍。

为

了应对这些

问题，代理微

调（Proxy-tuning）

[27] 提供了一

种轻量级的

解码

时（Decoding-time）算法

，允许我们在

不直接修改

大语言模型

权重的前提

下，通过

仅访

问模型输出

词汇表预测

分布，来实现

对大语言模

型的进一步

定制化调整

。

如图 4.7 所示，给

定待微调的

代理模型 M

以

及较小的反

专家模型（Anti-expert

model）M−，这

两个模型需

要相同的词

汇表。我们对

M− 进行微调，得

到微调后

的

专家模型（Expert

model）M+。在

每一个自回

归生成的时

间步中，代理

微调首先

计

算专家模型

M+ 和反专家模

型 M−

之间的 logits 分

布差异，然后

将其加到代

理

模型

M 下一

个词预测的

logits 分布中。具体

来说，在代理

微调的计算

阶段，针对

每

一时间步

t 的

输入序列 x<t，从

代理模型 M、专

家模型

M+ 和反

专家模型 M−

163

第

4 章 参数高效

微调

中获取

相应的输出

分数

sM, sM+ , sM−。通过下

式调整目标

模型的输出

分数

s˜：

˜s = sM

+ sM+ − sM−

, (4.3)

然后，使

用 softmax(·)

对其进行

归一化，得到

输出概率分

布，

pM˜ (Xt

|

x<t) = softmax(˜s), (4.4)

最后，在该

分布中采样

得到下一个

词的预测结

果。

在实际使

用中，通常专

家模型是较

小的模型（例

如，LLaMA-7B），而代理模

型则是更大

的模型（例如

，LLaMA-13B 或 LLaMA-70B）。通过代理

微调，我们将

较小模型中

学习到的知

识，以一种解

码时约束的

方式迁移到

比其大得多

的模型中，

大

幅节省了计

算成本。同时

，由于仅需要

获取模型的

输出分布，而

不需要原始

的模

型权重

，因此该方法

对于黑盒模

型同样适用

。

本节介绍了

三种主要的

参数附加方

法，分别通过

加在输入、加

在模型以及

加

在输出三

种方式实现

。总的来说，这

几类方法都

是提升预训

练语言模型

性能的有

效

手段，它们各

有优势。加在

输入的方法

通过在输入

序列中添加

可学习的张

量，对

模型本

身的结构修

改较小，有更

好的灵活性

。加在模型的

方法保持了

原始预训练

模型的参数

，在泛化能力

上表现更佳

。加在输出的

方法则能够

以更小的代

价驱动

更大

参数量的黑

盒模型，带来

更实际的应

用前景。

4.3

参数

选择方法

参

数选择方法

（Parameter Selection Methods）选择性的对

预训练模型

中的某个

参

数子集进行

微调。和参数

附加方法不

同的是，参数

选择方法无

需向模型添

加额外

的参

数，避免了在

推理阶段引

入额外的计

算成本。通常

，参数选择方

法分为两类

：

基于规则的

方法和基于

学习的方法

。

164

葛宇航 毛玉

仁

4.3.1 基于规则

的方法

基于

规则的方法

根据人类专

家的经验，确

定哪些参数

应该被更新

。基于规则

的

方法中最具

代表性的方

法是 BitFit [50]。BitFit

通过仅

优化神经网

络中的每一

层

的偏置项

（Biases）以及任务特

定的分类头

来实现参数

高效微调。由

于偏置项在

模

型总参数

中所占比例

极小（约 0.08%-0.09%），BitFit

有极

高的参数效

率。尽管只微

调少量参数

，BitFiT 依然能在 GLUE Benchmark

[44] 上

与全量微调

相媲美，甚至

在

某些任务

上表现更好

。此外，BitFit 方法相

比全量微调

允许使用更

大的学习率

，因

此该方法

整体优化过

程更稳定。然

而，该方法仅

在小模型（如

BERT、RoBERT 等）

上进行验

证性能，在更

大模型上的

性能表现如

何尚且未知

。

除

BitFit 以外，还有

一些其他基

于规则的方

法通过仅微

调特定的 Transformer

层

来提高参数

效率。例如，Lee

等

人 [22] 提出，仅对

BERT 和

RoBERTa 的最后四

分之一层进

行微调，便能

实现完全参

数微调 90% 的性

能。PaFi

[26] 选择具有

最小

绝对值

的模型参数

作为可训练

参数。

4.3.2

基于学

习的方法

基

于学习的方

法在模型训

练过程中自

动地选择可

训练的参数

子集。其中，最

为典型方法

是 Child-tuning [49]

。其通过梯

度掩码矩阵

策略实现仅

对选中的择

子网

络进行

梯度更新，而

屏蔽子网络

梯度以外的

梯度，从而实

现对微调参

数的选择，达

到参数高效

微调的目的

。具体而言，假

设 Wt 是第

t 轮迭

代的参数矩

阵，我们引入

了一个与 Wt 同

维度的

0-1 掩码

矩阵 Mt ，用于选

择第

t 轮迭代

的子网络 Ct，仅

更

新该子网

络的参数，其

定义如下：

M(

t

i) =







1,

if W(i)

t ∈

Ct

0, if W(i)

t ∈/ Ct。

(4.5)

165

第

4 章 参数高效

微调

其中，M(

t

i) 和

Wt

(i) 分别是矩阵

Mt 和 Wt

在第 t 轮迭

代的第 i

个元

素。此时，梯

度

更新公式为

：

Wt+1 =

Wt − η



∂L(Wt)

∂Wt

⊙ Mt

 ， (4.6)

Child-tuning

提供了两种

生成子网络

掩码 M 的方式

，由此产生两

种变体模型

：

Child-tuningF

和 Child-tuningD。Child-tuningF 是一种任

务无关的变

体，它在不依

赖

任何下游

任务数据的

情况下选择

子网络。在每

次迭代时，Child-tuningF

从

伯努利分

布

中抽取 0-1 掩码

，生成梯度掩

码

Mt ：

Mt ∼

Bernoulli(pF )， (4.7)

其中，pF

是伯

努利分布的

概率，表示子

网络的比例

。此外，Child-tuningF 通过引

入噪声来对

全梯度进行

正则化，从而

防止小数据

集上的过拟

合，并提高泛

化能力。

Child-tuningD 是一

种任务驱动

的变体，它利

用下游任务

数据来选择

与任务最

相

关的子网络

。具体来说，Child-tuningD 使

用费舍尔信

息矩阵（FIM）来估

计特定

任务

相关参数的

重要性。具体

地，对于给定

的任务训练

数据 D，模型的

第

i 个参数

矩

阵 W(i)

的费舍尔

信息估计为

：

F

(i)

(W)

= 1

|D|

|D|

X

j=1



∂

log p(Yj

|Xj

;

W)

∂W(i)



2

， (4.8)

其中，Xi 和

Yi 分别

表示第 i 个样

本的输入和

输出，log

p(Yi

|Xi

; W)

是对数

似然概

率，通

过计算损失

函数对参数

W(i) 的梯度得到

。通常，我们假

设参数对目

标任务

越重

要，它的费舍

尔信息的值

就越高。因此

，可以根据费

舍尔信息来

选择子网络

，

子网络 C 由具

有最高费舍

尔信息的参

数组成。选择

子网络参数

的步骤如下

：1) 计

算每个参

数的费舍尔

信息值；2) 对这

些费舍尔信

息值进行排

序；3) 选择前 pD

比

例

的参数作

为子网络 C 。确

定子网络后

，生成相应的

掩码矩阵完

成模型训练

。

Child-tuning 通过梯度屏

蔽减少了计

算负担，同时

减少了模型

的假设空间

，降

低了模型

过拟合的风

险。然而，子网

络的选择需

要额外的计

算代价，特别

是在任

166

葛宇

航 毛玉仁

务

驱动的变体

中，费舍尔信

息的计算十

分耗时。但总

体而言，Child-tuning 可以

改

善大语言

模型在多种

下游任务中

的表现，尤其

是在训练数

据有限的情

况下。此外，

Child-tuning 可

以很好地与

其他 PEFT

方法的

集成，进一步

提升模型性

能。

除 Child-tuning 外，还有

一些其他基

于学习的参

数选择方法

。例如，Zhao

等

人 [55] 引

入与模型权

重相关的二

值矩阵来学

习，通过阈值

函数生成参

数掩码（mask），

然后

在反向传播

过程中通过

噪声估计器

进行更新。类

似 FishMask，Fish-Dip [5] 也

使用 Fisher 信

息来计算掩

码，但掩码将

在每个训练

周期动态重

新计算。LT-SFT [2]

受 “彩

票假设” [11] 启发

，根据参数重

要性，根据在

初始微调阶

段变化最大

的参数

子集

形成掩码。SAM [12] 提

出了一个二

阶逼近方法

，通过解析求

解优化函数

来帮

助决定

参数掩码。

基

于选择的方

法通过选择

性地更新预

训练模型的

参数，在保持

大部分参数

不

变的情况

下对模型进

行微调。基于

选择的方法

能够显著减

少微调过程

中所需要更

新的参数，降

低计算成本

和内存需求

。对于资源受

限的环境或

者需要快速

适应新任

务

的场景尤其

适用。然而，这

些方法也面

临挑战，比如

，如何选择最

佳参数子集

，

以及如何平

衡参数更新

的数量和模

型性能之间

的关系。

4.4 低秩

适配方法

低

维固有维度

假设 [1]

表明：过

参数化模型

的固有维度

是很低的；换

言之，存

在可

以与全参数

更新媲美的

低维的参数

更新。基于这

一假设，低秩

适配方法（Low￾rank Adaptation Methods）通

过低秩矩阵

来近似原始

权重权更新

矩阵，并仅微

调低

秩矩阵

，以大幅降低

模型参数量

。在本节中，我

们首先将介

绍最经典的

低秩适配方

法 LoRA 的实现细

节并对分析

其参数效率

。接着，将介绍

LoRA 的相关变体

。最

后，介绍基

于 LoRA 插件化特

性，以及其任

务泛化能力

。

167

第 4 章 参数高

效微调

上投

影矩阵 下投

影矩阵

预训

练权重

输入

输出

图 4.8: LoRA 示意

图。

4.4.1 LoRA

低秩适配

（Low-rank Adaptation,

LoRA） [19] 提出利用低

秩矩阵近似

参数更新

矩

阵来实现低

秩适配。该方

法将参数更

新矩阵低秩

分解为两个

小矩阵。在微

调时，

通过微

调这两个小

矩阵来对大

语言模型进

行更新，大幅

节省了微调

时的内存开

销。

本小节首

先介绍 LoRA 方法

的具体实现

过程，然后分

析其计算效

率。

1. 方法实现

给定一个密

集神经网络

层，其参数矩

阵为 W0 ∈

R

d×k，为适配

下游任务，我

们通

常需要

学习参数更

新矩阵 ∆W

∈ R

d×k，对原

始参数矩阵

进行更新 W

= W0 + ∆W。

对

于全量微调

过程，∆W 是需对

该层所有 d ×

k 个

参数计算梯

度，这通常需

要大量

的 GPU

内

存，成本高昂

。为解决这一

问题，如图 4.8，LoRA 将

∆W 分解为两个

低

参数量的

矩阵 B ∈ R

d×r 和 A ∈

R

r×k，使得

更新过程变

为：

W =

W0 + αBA， (4.9)

其中，秩 r ≪ min{d,

k}，B 和

A 分别用随机

高斯分布和

零进行初始

化，α 是缩放

168

葛

宇航 毛玉仁

因子，用于控

制 LoRA

权重的大

小。在训练过

程中，固定预

训练模型的

参数，仅微

调

B 和 A

的参数。因

此，在训练时

，LoRA 涉及的更新

参数数量为

r × (d

+ k)，远

小于全量

微调 d

× k。实际上

，对于基于 Transformer 的

大语言模型

，密集层通常

有两种类型

：注意力模块

中的投影层

和前馈神经

网络（FFN）模块中

的投影层。在

原始研究中

，LoRA

被应用于注

意力层的权

重矩阵。后续

工作表明将

其应用于 FFN

层

可以进一步

提高模型性

能 [14]。

LoRA 仅微调部

分低秩参数

，因此具有很

高的参数效

率，同时不会

增加推理延

迟 [10]。此外，低秩

矩阵还可以

扩展为低秩

张量 [3]，或与

Kronecker 分

解结合使用

，

以进一步提

高参数效率

[9, 16]。除了参数效

率外，在训练

后可以将

LoRA 参

数与模

型参

数分离，所以

LoRA 还具有可插

拔性。LoRA

的可插

拔特性使其

能够封装为

被

多个用户

共享和重复

使用 [38] 的插件

。当我们有多

个任务的

LoRA 插

件时，可以

将

这些插件组

合在一起，以

获得良好的

跨任务泛化

性能 [20]。我们将

在

4.4.3 提供

具体

案例详细介

绍基于 LoRA

插件

的任务泛化

。

2. 参数效率

下

面我们以一

个具体的案

例分析

LoRA 的参

数效率。在 LLaMA2-7B [40]

模

型中微调第

一个 FFN 层的权

重矩阵为例

，全量微调需

要调整 11,

008 × 4, 096

=

45, 088, 768

个参

数。而当 r = 4

时，LoRA 只

需调整 (11, 008

× 4) + (4

× 4, 096) =

60, 416 个参

数。对于这一

层，与全量微

调相比，LoRA 微调

的参数不到

原始参数量

的千分之一

。具体来说，模

型微调的内

存使用主要

涉及四个部

分：

权重内存

（Weight Memory）：用于存储模

型权重所需

的内存；

激活

内存（Activation Memory）：前向传

播内存时中

间激活带来

的显存占用

，

主要取决于

batch size 大小以及序

列长度等；

梯

度内存（Gradient

Memory）：在反

向传播期间

需要用来保

存梯度的内

存，这

些梯度

仅针对可训

练参数进行

计算；

169

第

4 章 参

数高效微调

优化器内存

（Optimization Memory）：用于保存优

化器状态的

内部存在。例

如，Adam

优化器会

保存可训练

参数的 “一阶

动量” 和 “二阶

动量”。

文献 [34]提

供在LLaMA2-7B模型上

使用批量大

小为 1，单个NVIDIA RTX4090

（24GB）GPU 上

进行全量微

调和 LoRA 微调的

实验对比。根

据实验结果

，全量微

调大

约需要 60GB 显存

，超出 RTX4090

的显存

容量。相比之

下，LoRA 只需要大

约 23GB 显存。LoRA

显著

减少了显存

使用，使得在

单个 NVIDIA RTX4090 上进行

LLaMA2-7B

微调成为可

能。具体来说

，由于可训练

参数较少，优

化器内存和

梯度

内存分

别减少了约

25GB 和 14GB。另外，虽然

LoRA

引入了额外

的 “增量参数

”，

导致激活内

存和权重内

存略微增加

（总计约 2GB），但考

虑到整体内

存的减少，这

种增加是可

以忽略不计

的。此外，减少

涉及到的参

数计算可以

加速反向传

播。与全

量微

调相比，LoRA 的速

度提高了 1.9 倍

。

4.4.2 LoRA 相关变体

虽

然

LoRA 在一些下

游任务上能

够实现较好

的性能，但在

许多复杂的

下游任

务（如

数学推理 [4,

6, 54]）上

，LoRA 与全量微调

之间仍存在

性能差距。为

弥补这

一差

距，许多

LoRA 变体

方法被提出

，以进一步提

升 LoRA 在下游任

务中的适配

性

能。现有方

法主要从以

下几个角度

进行改进 [31]：(1) 打

破低秩瓶颈

；(2) 动态秩分

配

；(3) 训练过程优

化。接下来，将

分别介绍这

三种类型变

种的代表性

方法。

1. 打破低

秩瓶颈

LoRA 的低

秩更新特性

使其在参数

效率上具有

优势；然而，这

也限制了大

规

模语言模

型记忆新知

识和适应下

游任务的能

力 [4,

13, 21, 54]，即存在低

秩瓶颈。

Biderman

等人

[4] 的实验研究

表明，全量微

调的秩显著

高于 LoRA 的秩（10-100

倍

），并且增加 LoRA 的

秩可以缩小

LoRA 与全量微调

之间的性能

差距。因此，一

些方法被提

出，旨在打破

低秩瓶颈

[25, 36, 48]。

170

葛

宇航 毛玉仁

例如，ReLoRA [25] 提出了

一种合并和

重置（merge-and-reinit）的方法

，该方

法在微

调过程中周

期性地将 LoRA 模

块合并到大

语言模型中

，并在合并后

重新初

始化

LoRA

模块和优化

器状态。具体

地，合并的过

程如下：

Wi ← Wi

+ αBiA

i， (4.10)

其中

，Wi 是原始的权

重矩阵，Bi 和 Ai

是

低秩分解得

到的矩阵，α 是

缩放因子。合

并后，将重置

Bi 和 Ai

的值重置

，通常 Bi 会使用

特定的初始

化方法（如 Kaiming

初

始化）重新初

始化，而 Ai 则被

设置为零。为

了防止在重

置后模型性

能发散，ReLoRA

还会

通过幅度剪

枝对优化器

状态进行部

分重置。合并

和重置的过

程允许模型

在保

持总参

数量不变的

情况下，通过

多次低秩 LoRA 更

新累积成高

秩状态，从而

使得

ReLoRA

能够训

练出性能接

近全秩训练

的模型。

2. 动态

秩分配

然而

，LoRA

的秩并不总

是越高越好

，冗余的 LoRA 秩可

能会导致性

能和效率

的

退化。并且，微

调时权重的

重要性可能

会因

Transformer 模型中

不同层而存

在差

异，因此

需要为每个

层分配不同

的秩 [7,

30, 41, 52]。

例如，AdaLoRA

[52] 通

过将参数更

新矩阵参数

化为奇异值

分解（SVD）的形

式

，再通过奇异

值剪枝动态

调整不同层

中 LoRA

模块的秩

。具体地，AdaLoRA 使

用

奇异值分解

重新表示 ∆W，即

W

= W0 + ∆W

= W0 + PΛQ，

(4.11)

其中，P ∈ R

d×r 和 Q ∈

R

r×k 是正

交的，Λ 是一个

对角矩阵，其

中包含

{λi}1≤i≤r

的奇

异值。在训练

过程中，W0 的参

数被固定，仅

更新 P、Λ

和 Q 的参

数。根据梯

度

权重乘积大

小的移动平

均值构造奇

异值的重要

性得分，对不

重要的奇异

值进行

迭代

剪枝。此外，为

了增强稳定

训练性，AdaLoRA 引入

一个额外的

惩罚项确保

P

171

第

4 章 参数高

效微调

和

Q 之

间的正交性

:

R(P, Q)

= ||P

TP −

I||2

F + ||QQT

− I||2

F， (4.12)

其中，I 是单位

矩阵，|| · ||F

代表 Frobenius 范

数。

3.

训练过程

优化

在实际

微调过程中

，LoRA 的收敛速度

比全量微调

要慢。此外，它

还对超参数

敏感，并且容

易过拟合。这

些问题影响

了 LoRA

的效率并

阻碍了其下

游适配性能

。

为了解决这

些问题，一些

工作尝试对

LoRA 的训练过程

进行优化 [32,

45]。代

表性

方法 DoRA (权

重分解低秩

适应)

[29] 提出约

束梯度更新

，侧重于更新

参数的方向

变化。它将预

训练权重 W0 ∈

R

d×k 分

解为方向和

大小两个组

件，并仅将 LoRA

应

用于方向组

件以增强训

练稳定性。具

体地，DoRA 将 W0 ∈

R

d×k 重新

表示为：

W0

= m

V

∥V

∥c

= ∥W0∥c

W0

∥W0∥c

， (4.13)

其中

，m

∈ R

1×k 是大小向量

,

V ∈ R

d×k

是方向矩阵

，∥ · ∥c 是矩阵在每

一列上的向

量范数。随后

，DoRA

仅对方向矩

阵 V 施加 LoRA

进行

参数化，定义

为：

W′ = m

V + ∆V

∥V

+ ∆V ∥c

=

m

W0 + BA

∥W0 + BA∥c

，

(4.14)

其中，∆V 是由

LoRA 学习的增量

方向更新，下

划线参数表

示可训练参

数。

4.4.3 基于 LoRA 插件

的任务泛化

在

LoRA 微调结束

后，我们可以

将参数更新

模块 B 和

A 从模

型上分离出

来，

并封装成

参数插件。这

些插件具有

即插即用、不

破坏原始模

型参数和结

构的优良

性

质。我们可以

在不同任务

上训练的各

种

LoRA 模块，将这

些模块插件

化地方式保

存、共享与使

用。此外，我们

还可以将多

个任务的 LoRA 插

件组合，然后

将不同任

务

的能力迁移

到新任务上

。LoRAHub [20] 提供了一个

可用的多 LoRA

组

合的方法

框

架。其可将已

有任务上得

到的 LoRA 插件进

行组合，从而

获得解决新

任务的能

172

葛

宇航 毛玉仁

LLM

摘要

任务

翻

译

任务

代码

任务

问答

任

务

新任务

LoRA

插

件仓库

评估

适应 组合

图

4.9:

LoRAHub 示意图。

力。如

图 4.9

所示，LoRAHub 包括

两个阶段：组

合阶段和适

应阶段。在组

合阶段，

LoRAHub 将已

学习的

LoRA 模块

通过逐元素

线性加权组

合为单一模

块：

mˆ =

(w1A1 + w2A2 +

· · · +

wN AN ) (w1B1

+ w2B2 + ·

· · + wN

BN ) ， (4.15)

其中，wi 是第

i 个 LoRA

模块的权

重，mˆ 是组合后

的模块，AN

i=1 和

Bi

N

=1 分

别是

N 个

LoRA 分解

矩阵。在适应

阶段，给定一

些新任务的

示例，通过无

梯度方法

Shiwa [28]

自

适应地学习

权重组合。适

应和组合经

过 k

次迭代，直

至找到最优

的权重组合

，以

完成对新

任务的适应

。

本节介绍了

低秩适配方

法 LoRA。LoRA

通过对参

数矩阵进行

低秩分解，仅

训

练低秩矩

阵，大幅减少

了训练参数

量。此外，还介

绍了从打破

低秩瓶颈、动

态秩分

配和

训练过程优

化等不同角

度改进 LoRA

的变

体。最后，介绍

了基于 LoRA 插件

的

任务泛化

方法

LoRAHub。LoRAHub 通过对

已学习的 LoRA 模

块加权组合

，融合多

任务

能力并迁移

到新任务上

，提供了一种

高效的跨任

务学习范式

。

173

第 4

章 参数高

效微调

4.5 实践

与应用

PEFT 技术

在许多领域

中展现了其

强大的应用

潜力。本节将

探讨 PEFT 的实践

与应用。在实

践部分，我们

将介绍目前

最流行的

PEFT 框

架，Hugging Face 开发的

开

源库 HF-PEFT，并简述

其使用方法

和相关技巧

。在应用部分

，我们将展示

PEFT

技术在不同

垂直领域中

的应用案例

，包括表格数

据处理和金

融领域的 Text-to-SQL

生

成任务。这些

案例不仅证

明了 PEFT 在提升

大模型特定

任务性能方

面的有效性

，

也为未来的

研究和应用

提供了有益

的参考。

4.5.1 PEFT 实践

在实际应用

中，PEFT 技术的实

施和优化至

关重要。本小

节将详细介

绍

PEFT

主流框架

的使用，包括

安装和配置

、微调策略选

择、模型准备

与训练流程

等内容，

以及

相关使用技

巧。

1.

PEFT 主流框架

目前最流行

的 PEFT 框架是由

Hugging

Face 开发的开源

库 HF-PEFT 2，它旨

在提

供最先进的

参数高效微

调方法。HF-PEFT 框架

的设计哲学

是高效和灵

活性。

HF-PEFT 集成了

多种先进的

微调技术，如

LoRA、Apdater-tuning、Prompt-tuning

和

IA3 等。HF-PEFT 支持与

Hugging

Face 的其他工具

如 Transformers、Diffusers 和

Accelerate 无缝集

成，并且支持

从单机到分

布式环境的

多样化训练

和推理场景

。HF￾PEFT 特别适用于

大模型，能够

在消费级硬

件上实现高

性能，并且可

以与模型量

化技术兼容

，进一步减少

了模型的内

存需求。HF-PEFT 支持

多种架构模

型，包括

Transformer 和 Diffusion，并

且允许用户

手动配置，在

自己的模型

上启用 PEFT。

HF-PEFT 的另

一个显著优

势是它的易

用性。它提供

了详细的文

档、快速入门

2https://github.com/huggingface/peft

174

葛宇航

毛玉

仁

指南和示

例代码 3，可以

帮助用户了

解如何快速

训练 PEFT

模型，以

及如何加载

已

有的 PEFT 模型

进行推理。此

外，HF-PEFT

拥有活跃

的社区支持

，并鼓励社区

贡

献，是一个

功能强大、易

于使用且持

续更新的库

。

2. HF-PEFT

框架使用

使

用 HF-PEFT 框架进行

模型微调可

以显著提升

模型在特定

任务上的性

能，同

时保持

训练的高效

性。通常，使用

HF-PEFT 框架进行模

型微调的步

骤如下：

1. 安装

与配置：首先

，在环境中安

装

HF-PEFT 框架及其

依赖项，主要

是 Hugging

Face

的 Transformers 库。

2.

选择

模型与数据

：根据任务需

求，挑选合适

的预训练模

型，并准备相

应的训

练数

据集。

3. 确定微

调策略：选择

适合任务的

微调方法，例

如

LoRA 或适配器

技术。

4. 模型准

备：加载预训

练模型并为

选定的微调

方法进行配

置，包括任务

类型、

推理模

式、参数值等

。

5. 模型训练：定

义完整的训

练流程，包括

损失函数、优

化器设置，并

执行训练，

同

时可应用数

据增强和学

习率调度等

技术。

通过上

述步骤，可以

高效地使用

HF-PEFT 框架进行模

型微调，以适

应特定的

任

务需求，并提

升模型性能

。

3.

PEFT 相关技巧

HF-PEFT 库

提供了多种

参数高效微

调技术，用于

在不微调所

有模型参数

的情

况下，有

效地将预训

练语言模型

适应各种下

游应用。以下

是一些 PEFT 技术

常用的

参数

设置方法：

Prompt Tuning

num_virtual_tokens: 表

示为每个任

务添加的

virtual tokens 的

数量，也就是

软

3https://huggingface.co/docs/peft/

175

第 4 章

参数

高效微调

提

示的长度，该

长度通常设

置在 10-20 之间，可

根据输入长

度进行适当

调节。

prompt_tuning_init：表示 prompt 参

数的初始化

方式。可以选

择随机初始

化

（RANDOM）、文本初始

化（TEXT），或者其他

方式。文本初

始化方式下

，可

以使用特

定文本对 prompt embeddings 进

行初始化以

加速收敛。

Prefix Tuning

num_virtual_tokens: 与

Prompt

Tuning 中相同，表示

构造的 virtual tokens

的数

量，设置和 Prompt Tuning 类

似。

encoder_hidden_size: 表示用于

Prefix 编码的多层

感知机（MLP）层的

大小，通

常与

模型的隐藏

层大小相匹

配。

LoRA

r: 秩的大小

，用于控制更

新矩阵的复

杂度。通常可

以选择较小

的值如 4、8、

16，对于

小数据集，可

能需要设置

更小的 r 值。

lora_alpha:

缩

放因子，用于

控制 LoRA 权重的

大小，通常与

r 成反比，以保

持权重更新

的一致性。

lora_dropout: LoRA 层

的 dropout

比率，用于

正则化以防

止过拟合，可

以设置

为一

个较小的值

，比如 0.01。

target_modules:

指定模

型中 LoRA 中要应

用的模块，如

注意力机制

中的 query、

key、value 矩阵。可

以选择特定

的模块进行

微调，或者微

调所有线性

层。

需要注意

的是，具体的

参数设置可

能会根据所

使用的模型

、数据集和具

体任

务有所

不同，因此在

实际应用中

可能需要根

据实验结果

进行调整。

4.5.2 PEFT 应

用

在现实应

用中，大量垂

直领域数据

以表格的形

式存储在关

系型数据库

中。不

仅数量

大，表格数据

涵盖的领域

也非常广泛

，涉及金融、医

疗、商务、气候

科学众

176

葛宇

航 毛玉仁

多

领域。然而，大

语言模型的

预训练语料

中表格数据

的占比通常

很少，这导致

其在

表格数

据相关的下

游任务上的

性能欠佳。微

调大语言模

型使其适应

表格数据是

参

数高效微

调的典型应

用，其具有深

远的现实意

义。本节我们

将介绍两个

分别将参

数

高效微调技

术应用在表

格数据查询

和表格数据

分析上案例

。

1. 表格数据查

询

表格数据

查询是处理

、分析表格数

据的必要步

骤。对表格数

据进行查询

，需要

编写专

业的结构化

查询语言（Structured

Query Language，SQL）代

码。然而，SQL

代码

通常涉及复

杂的查询逻

辑和严格的

语法规则，专

业人士都需

要花费大量

时间

进行编

写。对于初学

者，熟练掌握

并使用

SQL 可能

需要数月或

者更长的时

间来学

习和

实践。编写 SQL

代

码的为表格

数据查询设

置了较高的

门槛。为了降

低表格数

据

查询的门槛

，可以将自然

语言文本自

动翻译成 SQL 代

码的

Text-to-SQL 技术受

到了广泛的

关注。其可以

将 SQL 编写时间

从分钟级缩

短到秒级，使

数据科学家

能

够专注于

分析和建模

，加快数据驱

动决策的速

度，同时让广

大普通人也

能操作和管

理数据库，显

著提高了数

据分析的效

率，让更多的

人能够挖掘

和利用数据

的价值。

大语

言模型的强

大代码生成

能力为 Text-to-SQL 技术

带来了新的

机遇。但是，在

众

多垂直领

域，如金融领

域，难以收集

足够的用于

微调的数据

。利用少量数

据进行全

参

数微调时则

容易导致大

模型过拟合

，因此采用 PEFT 技

术进行部分

参数微调十

分

适合金融

等垂直领域

Text-to-SQL 任务。

面向金

融垂直领域

，FinSQL [51]

提出了一套

针对金融垂

直领域 Text-to-SQL 训

练

推理框架。如

图

4.10 所示，该框

架包含提示

构造、参数高

效微调和输

出校准三

个

部分。首先，提

示构造通过

不同策略增

强原始数据

，并且构造高

效检索器，检

索与用户查

询相关表格

和字段。然后

，采用 PEFT

技术对

基座模型进

行微调，通过

LoRAHub 融合多个 LoRA 模

块，提高少样

本场景的性

能。最后，输出

校准模块会

修

正生成 SQL 中

的语法错误

，并用 Self-Consistency

方法来

选择一致性

SQL。FinSQL

177

第 4

章 参数高

效微调

Ⅰ 提示

构造

Ⅲ 输出校

准

ROOT

SELECT

FROM WHERE

······

ROOT

SELECT FROM WHERE

······

对齐表格

和字段

SQL_1

SQL_2

SQL_3

SQL_1

SQL_2

SQL_3

修正

语法错误

SQL解

析

Self-Consistency

Ⅱ 参数高效

微调

1

同义句

增强

思维链

生成

骨架预

测

自然语言

提问

Please find the

C1, C5 whose

C3

is ...

Schema信息

1

数

据增强

表列

检索

多任务

增强 2

5

2

3

基座模

型

LoRA_1 ···

···

一个基座

模型通过不

同的LoRA获得多

种能力

权重

融合

3

基座模

型

LoRA_n

···

添加到Plugin Hub 3

4 4

基

座模型 ···

··· 基座

模型

6

LoRA_1

LoRA_m

7 插入LoRA模

块 7

LoRA_k

LoRA_1 +···

+

基座模型

LoRA_n Find the C1,

C5 whose

C3 is

...

新

场

景

迁

移

输入提示

Select C1,

C5 From T1 join

T2

on ... Where

C3 ... ···

···

SQL 查

询

Text-to-SQL数据

Plugin

Hub

图 4.10: FinSQL

示

意图。

相比于

基线方法，不

仅显著提升

了准确性和

效率，还展现

了在处理复

杂金融查询

时的强大能

力，为金融领

域的数据分

析和决策支

持提供了强

有力的技术

支撑。

2. 表格数

据分析

完成

数据查询操

作后，可以对

查询到的数

据进行进一

步分析。但是

，表格数据

的

特点——缺乏局

部性、包含多

种数据类型

和相对较少

的特征数量

——使得传统

的

深度学习方

法难以直接

应用。大语言

模型的参数

中编码了大

量先验知识

，有效

利用这

些知识能够

弥补表格数

据特征不足

的问题。但是

，为了取得更

好的性能，通

常依旧需要

少量标记数

据使大模型

适应表格任

务。然而，在少

量数据上进

行模型

微调

容易导致过

拟合。由于 PEFT 只

微调部分参

数，能有效降

低过拟合的

风险，使

得大

语言模型在

表格数据上

的性能更加

稳健。

例如，TabLLM [17] 提

出基于大语

言模型的少

样本表格数

据分类框架

，图 4.11

为该方法

的框架图。该

框架将表格

数据序列化

为自然语言

字符串，并附

上分类问

题

的简短描述

来提示大语

言模型。在少

样本设置中

，使用 LoRA 在一些

带标签的样

本对大语言

模型进行微

调。微调后，TabLLM

在

多个基准数

据集上超过

基于深度学

习的表格分

类基线方法

。此外，在少样

本设置下，TabLLM 的

性能超过了

梯度提升

树

等强大的传

统基线，表现

出了强大的

小样本学习

能力。

178

葛宇航

毛玉仁

income gain education

age

>50K 0 HS-grad

36

≤50K 0 12th

64

594 Master 42

The age is 42.

The educa￾tion is Master.

The gain is

594.

2. PEFT 微调

1.

表格序列化

Yes No

原始模型 微

调模型

问题

：Does this person earn

more than 50000 dollars?

Yes or no? Answer:

The age is 28.

The education 

is

Master. The gain is

1024.

Does this person

earn more 

than

50000 dollars? Yes or

no? Answer:

The age

is 28. The education

is Master. The gain

is 1024.

Does this

person earn more

than 50000 dollars? Yes

or 

no? Answer:

微调前模型

推理 微调后

模型推理

图

4.11: TabLLM

框架图。

本节

介绍了参数

高效微调技

术的实践与

应用。首先，我

们介绍了 PEFT 主

流框

架 HF-PEFT 及其

使用方法，并

介绍了 PEFT

的相

关技巧。最后

，展示了 PEFT 技术

如何帮助大

语言模型提

升在表格数

据的查询与

分析任务上

的性能，使大

语言模型

适

配垂域任务

的同时保证

训练效率。

参

考文献

[1] Armen Aghajanyan,

Sonal Gupta, and Luke

Zettlemoyer. “Intrinsic Dimensional￾ity Explains

the Effectiveness of Language

Model Fine-Tuning”. In: ACL/IJCNLP.

2021.

[2] Alan Ansell

et al. “Composable Sparse

Fine-Tuning for Cross-Lingual Transfer”.

In: ACL. 2022.

[3]

Daniel Bershatsky et al.

“LoTR: Low Tensor Rank

Weight Adaptation”. In: arXiv

preprint arXiv:2402.01376 (2024).

[4]

Dan Biderman et al.

“LoRA Learns Less and

Forgets Less”. In: arXiv

preprint

arXiv.2405.09673 (2024).

[5]

Sarkar Snigdha Sarathi Das

et al. “Unified Low-Resource

Sequence Labeling by

Sample-Aware

Dynamic Sparse Finetuning”. In:

EMNLP. 2023.

[6] Ning

Ding et al. “Parameter-efficient

fine-tuning of large-scale pre-trained

language

models”. In: Nat.

Mac. Intell. 5.3 (2023),

pp. 220–235.

179

第

4 章

参数高效微

调

[7] Ning

Ding et al. “Sparse

Low-rank Adaptation of Pre-trained

Language Models”.

In: EMNLP.

2023.

[8] Qingxiu Dong

et al. “A Survey

for In-context Learning”. In:

CoRR abs/2301.00234

(2023).

[9]

Ali Edalati et al.

“KronA: Parameter Efficient Tuning

with Kronecker Adapter”. In:

arXiv preprint arXiv:2212.10650 (2022).

[10] Vlad Fomenko et

al. “A Note on

LoRA”. In: arXiv preprint

arXiv:2404.05086

(2024).

[11] Jonathan

Frankle and Michael Carbin.

“The Lottery Ticket Hypothesis:

Finding

Sparse, Trainable Neural

Networks”. In: ICLR. 2019.

[12] Zihao Fu et

al. “On the Effectiveness

of Parameter-Efficient Fine-Tuning”. In:

AAAI.

2023.

[13] Andi

Han et al. “SLTrain:

a sparse plus low-rank

approach for parameter and

mem￾ory efficient pretraining”. In:

arXiv preprint arXiv:2406.02214 (2024).

[14] Junxian He et

al. “Towards a Unified

View of Parameter-Efficient Transfer

Learn￾ing”. In: ICLR. 2022.

[15] Shwai He et

al. “SparseAdapter: An Easy

Approach for Improving the

Parameter￾Efficiency of Adapters”. In:

Findings of EMNLP. 2022.

[16] Xuehai He et

al. “Parameter-Efficient Model Adaptation

for Vision Transformers”.

In:

AAAI. 2023.

[17] Stefan

Hegselmann et al. “TabLLM:

Few-shot Classification of Tabular

Data with

Large Language

Models”. In: AISTATS. 2023.

[18] Neil Houlsby et

al. “Parameter-Efficient Transfer Learning

for NLP”. In: ICML.

2019.

[19] Edward J.

Hu et al. “LoRA:

Low-Rank Adaptation of Large

Language Models”. In:

ICLR.

2022.

[20] Chengsong Huang

et al. “LoraHub: Efficient

Cross-Task Generalization via Dy￾namic

LoRA Composition”. In: arXiv

preprint arXiv:2307.13269 (2023).

[21]

Ting Jiang et al.

“MoRA: High-Rank Updating for

Parameter-Efficient Fine￾Tuning”. In: arXiv

preprint arXiv:2405.12130 (2024).

[22]

Jaejun Lee, Raphael Tang,

and Jimmy Lin. “What

Would Elsa Do? Freezing

Layers

During Transformer Fine-Tuning”.

In: arXiv preprint arXiv:1911.03090

(2019).

180

葛宇航 毛

玉仁

[23] Brian Lester, Rami

Al-Rfou, and Noah Constant.

“The Power of Scale

for

Parameter-Efficient Prompt Tuning”.

In: EMNLP. 2021, pp.

3045–3059.

[24] Xiang Lisa

Li and Percy Liang.

“Prefix-Tuning: Optimizing Continuous Prompts

for Generation”. In: ACL.

2021.

[25] Vladislav Lialin

et al. “ReLoRA: High-Rank

Training Through Low-Rank Up￾dates”.

In: NIPS Workshop. 2023.

[26] Baohao Liao, Yan

Meng, and Christof Monz.

“Parameter-Efficient Fine-Tuning

without Introducing

New Latency”. In: ACL.

2023.

[27] Alisa Liu

et al. “Tuning Language

Models by Proxy”. In:

arXiv preprint

arXiv:2401.08565 (2024).

[28] Jialin Liu et

al. “Versatile black-box optimization”.

In: GECCO. 2020, pp.

620–628.

[29] Shih-Yang Liu

et al. “DoRA: Weight-Decomposed

Low-Rank Adaptation”. In:

arXiv

preprint arXiv:2402.09353 (2024).

[30]

Yulong Mao et al.

“DoRA: Enhancing Parameter-Efficient Fine-Tuning

with Dy￾namic Rank Distribution”.

In: arXiv preprint arXiv:2405.17357

(2024).

[31] Yuren Mao

et al. A Survey

on LoRA of Large

Language Models. 2024. arXiv:

2407.

11046 [cs.LG]. URL:

https://arxiv.org/abs/2407.11046.

[32] Fanxu Meng,

Zhaohui Wang, and Muhan

Zhang. “Pissa: Principal singular

val￾ues and singular vectors

adaptation of large language

models”. In: arXiv preprint

arXiv:2404.02948 (2024).

[33] Jinjie

Ni et al. Instruction

in the Wild: A

User-based Instruction Dataset. https:

//github.com/XueFuzhao/InstructionWild. 2023.

[34] Rui

Pan et al. “LISA:

Layerwise Importance Sampling for

Memory-Efficient Large

Language Model

Fine-Tuning”. In: arXiv preprint

arXiv.2403.17919 (2024).

[35] Jonas

Pfeiffer et al. “AdapterFusion:

Non-Destructive Task Composition for

Trans￾fer Learning”. In: EACL.

Ed. by Paola Merlo,

Jörg Tiedemann, and Reut

Tsarfaty.

2021.

[36] Pengjie

Ren et al. “Mini-Ensemble

Low-Rank Adapters for Parameter-Efficient

Fine-Tuning”. In: arXiv preprint

arXiv.2402.17263 (2024).

[37] Victor

Sanh et al. Multitask

Prompted Training Enables Zero-Shot

Task General￾ization. 2021.

181

第 4 章 参

数高效微调

[38]

Ying Sheng et al.

“S-LoRA: Serving Thousands of

Concurrent LoRA Adapters”.

In:

arXiv preprint arXiv:2311.03285 (2023).

[39] Yi-Lin Sung, Varun

Nair, and Colin Raffel.

“Training Neural Networks with

Fixed

Sparse Masks”. In:

NIPS. 2021.

[40] Hugo

Touvron et al. “Llama

2: Open foundation and

fine-tuned chat models”. In:

arXiv preprint arXiv:2307.09288 (2023).

[41] Mojtaba Valipour et

al. “Dylora: Parameter efficient

tuning of pre-trained

models

using dynamic search-free low-rank

adaptation”. In: arXiv preprint

arXiv:2210.07558 (2022).

[42] Mojtaba

Valipour et al. “DyLoRA:

Parameter-Efficient Tuning of Pre-trained

Mod￾els using Dynamic Search-Free

Low-Rank Adaptation”. In: EACL.

2023.

[43] Zhongwei Wan

et al. “Efficient Large

Language Models: A Survey”.

In: arXiv

preprint arXiv:2312.03863

(2023).

[44] Alex Wang

et al. “GLUE: A

Multi-Task Benchmark and Analysis

Platform for Nat￾ural Language

Understanding”. In: ICLR. 2019.

[45] Hanqing Wang et

al. “MiLoRA: Harnessing Minor

Singular Components for

Parameter-Efficient

LLM Finetuning”. In: arXiv

preprint arXiv:2406.09044 (2024).

[46]

Yizhong Wang et al.

“Self-Instruct: Aligning Language Models

with Self￾Generated Instructions”. In:

ACL. 2023.

[47] Jason

Wei et al. “Finetuned

language models are zero-shot

learners”. In: arXiv

preprint

arXiv:2109.01652 (2021).

[48] Wenhan

Xia, Chengwei Qin, and

Elad Hazan. “Chain of

LoRA: Efficient

Fine-tuning of

Language Models via Residual

Learning”. In: arXiv preprint

arXiv.2401.04151 (2024).

[49] Runxin

Xu et al. “Raise

a Child in Large

Language Model: Towards Effective

and

Generalizable Fine-tuning”. In:

EMNLP. 2021.

[50] Elad

Ben Zaken, Yoav Goldberg,

and Shauli Ravfogel. “BitFit:

Simple Parameter￾efficient Fine-tuning for

Transformer-based Masked Language-models”. In:

ACL.

2022.

[51] Chao

Zhang et al. “FinSQL:

Model-Agnostic LLMs-based Text-to-SQL Framework

for Financial Analysis”. In:

SIGMOD. 2024.

[52] Qingru

Zhang et al. “Adaptive

Budget Allocation for Parameter-Efficient

Fine￾Tuning”. In: ICLR. 2023.

182

葛宇航 毛玉

仁

[53]

Shengyu Zhang et al.

“Instruction Tuning for Large

Language Models: A Survey”.

In: arXiv preprint arXiv:2308.10792

(2023).

[54] Jiawei Zhao

et al. “GaLore: Memory-Efficient

LLM Training by Gradient

Low￾Rank Projection”. In: arXiv

preprint arXiv.2403.03507 (2024).

[55]

Mengjie Zhao et al.

“Masking as an Efficient

Alternative to Finetuning for

Pre￾trained Language Models”. In:

EMNLP. 2020, pp. 2226–2241.

[56] Yaoming Zhu et

al. “Counter-Interference Adapter for

Multilingual Machine Trans￾lation”. In:

Findings of EMNLP. 2021.

183

5 模型编辑

预训练大语

言模型中，可

能存在偏见

、毒性、知识错

误等问题。为

了纠正这些

问题，可以将

大语言模型

“回炉重造”——用

清洗过的数

据重新进行

预训练，但成

本过高，舍本

逐末。此外，也

可对大语言

模型“继续教

育”——利用高效

微调技术

向

大语言模型

注入新知识

，但因为新知

识相关样本

有限，容易诱

发过拟合和

灾难

性遗忘

，得不偿失。为

此，仅对模型

中的特定知

识点进行修

正的模型编

辑技术应运

而生。本章将

介绍模型编

辑这一新兴

技术，首先介

绍模型编辑

思想、定义、性

质，

其次从内

外两个角度

分别介绍模

型编辑经典

方法，然后举

例介绍模型

编辑的具体

方法 T-Patcher 和

ROME，最后

介绍模型编

辑的实际应

用。

* 本书持续

更新，GIT Hub

链接为

：https://github.com/ZJU-LLMs/Foundations-of-LLMs。

第 5 章

模型编

辑

5.1 模型编辑

简介

大语言

模型有时会

产生一些不

符合人们期

望的结果，如

偏见、毒性和

知识错

误等

。偏见是指模

型生成的内

容中包含刻

板印象和社

会偏见等不

公正的观点

，毒

性是指模

型生成的内

容中包含有

害成分，而知

识错误则是

指模型提供

的信息与事

实不符。例如

，当被问到“斑

马的皮肤是

什么颜色的

？”时，ChatGPT 错误地回

答

“肉色”，而实

际上斑马的

皮肤是黑色

的，这就是一

个知识错误

，如图5.1。如果不

及时修正这

些问题，可能

会对人们造

成严重误导

。

斑马的皮肤

是什么颜色

的？

斑马的皮

肤颜色是接

近肉色的，黑

白条纹主要

出现在它们

的毛发上。

(a) 编

辑前模型。

斑

马的皮肤是

什么颜色的

？

斑马的皮肤

本身是黑色

的，斑马的黑

白条纹是由

其毛发的颜

色形成的。

(b) 编

辑后模型。

图

5.1: 大语言模型

知识错误示

例。

为了纠正

这些问题，可

以考虑重新

预训练和微

调两种方法

。重新预训练

是指

使用矫

正了偏见、祛

除了毒性、纠

正了知识错

误的清洗后

的数据对模

型进行重新

预训练。这种

方法能够从

根本上修复

模型的错误

输出。然而，清

洗数据成本

高昂，

并且由

于知识可能

频繁更新，无

法保证清洗

过的数据永

远是是完美

的；而且，重新

进行预训练

需要消耗巨

大的计算资

源，如果每次

发现模型错

误时都对其

重新预训

练

，未免舍本逐

末。微调则是

在预训练模

型的基础上

，针对其错误

进一步调整

模型

186

宓禹

樊

怡江 毛玉仁

参数。尽管存

在多种参数

高效微调方

法，但直接去

调整十亿级

参数量的模

型，还是

会产

生较高的训

练成本；此外

，由于修改模

型错误所需

的新知识样

本有限，因此

直

接用相应

的知识点相

关的样本微

调模型容易

导致过拟合

和灾难性遗

忘。因此，重

新

预训练和微

调都不适用

于实际大语

言模型的偏

见矫正、毒性

祛除、以及知

识错

误纠正

。

为规避重新

预训练和微

调方法的缺

点，模型编辑

应运而生。其

旨在精准、高

效

地修正大

语言模型中

的特定知识

点，能够满足

大语言模型

对特定知识

点进行更新

的需求。本节

将从思想、定

义、性质等方

面对模型编

辑进行初步

介绍。

5.1.1 模型编

辑思想

在《三

体 2：黑暗森林

》中，面壁者希

恩斯和他的

妻子共同研

发了一种名

为“思

想钢印

”的设备，目的

是向太空军

灌输“人类必

胜”的坚定信

念。这个机器

的原理

是让

接受者在接

触到特定信

息时，修改大

脑处理过程

，使之输出正

向答案。模型

编

辑的思想

大致与此相

似，旨在通过

增加或修改

模型参数，快

速有效地改

变模型行

为

和输出。

模型

学习知识的

过程还可以

与人类学习

知识的过程

相对应。首先

，在体验世

界

的过程中，我

们能够接触

到海量的知

识，从而形成

自身的知识

体系，这可以

类比

成大语

言模型的预

训练过程。其

次，我们可以

选择针对不

同学科进行

专门的学习

，

提升自己在

特定领域的

能力，这可以

类比成大语

言模型的微

调过程。此外

，在与他

人交

流的过程中

，我们会针对

特定的知识

进行探讨，从

而纠正自己

在该知识点

上

的错误认

知，这就可以

类比成模型

编辑的思想

。

以上方式，都

可以满足“纠

正大语言模

型”的需求。与

重新预训练

和微调方法

不同的是，模

型编辑期望

能更加快速

、精准地实现

对于模型特

定知识点的

修正。

187

第 5 章 模

型编辑

5.1.2 模型

编辑定义

当

前，模型编辑

领域尚缺乏

统一标准，不

同研究对相

关概念的定

义各不相同

。

本书将不同

工作中提到

的基于知识

的模型编辑

（KME,

Knowledge Model Editing）

[25]

和知识编辑

（KE, Knowledge Editing）[28] 等概念统一

为模型编辑

（ME,

Model

Editing）。此外，有些研

究用“编辑”（edit）[27] 或

“事实”（fact）[17, 18]

来表示

具体的编辑

对象，本书将

这些概念统

一为“知识点

”。

模型编辑的

目标可被归

纳为：修正大

语言模型使

其输出期望

结果，同时不

影

响其他无

关输出。本书

将模型编辑

定义如下：

定

义

5.1 (模型编辑

)

♣

将编辑前模

型定义为

M，编

辑后模型定

义为 M∗。每一次

编辑都修改

模型的

一个

知识点 k，知识

点

k 由问题 xk 及

其对应的答

案

yk 组成。那么

，模型编

辑的

目标可以表

示为以下函

数：

M∗

(x) =







yk, 若x =

xk 或x与xk相

关，

M(x), 若x

与xk无关

。

上述定义中

有关“相关”和

“无关”的判断

，涉及到模型

编辑的范围

问题，本

书将

在第 5.1.3小节讨

论。

图5.2用“斑马

皮肤颜色”这

一知识点作

为示例，展示

了模型编辑

的概念。在

这

个示例中，当

被询问“斑马

的皮肤是什

么颜色的？”时

，编辑前模型

回答了错误

答案“肉色”，而

编辑后的模

型可以回答

出正确答案

“黑色”。

然而，实

际的模型编

辑过程远比

理论定义复

杂。这主要源

于知识的内

在关联

性：当

修改模型对

某一特定知

识点的认知

时，由于该知

识点可能与

其它知识点

相关

联，所以

可能会影响

模型对其它

相关知识点

的理解，从而

产生” 牵一发

而动全身”

的

效应。因此，如

何精确控制

模型编辑的

范围成为一

个关键挑战

。精准可控的

模型

188

宓禹 樊

怡江 毛玉仁

肉色

黑色

肉

色

黑色

模型

编辑

: 斑马的

皮肤是什么

颜色的？

图 5.2:

模

型编辑概念

图。

编辑技术

需要满足一

系列性质。这

些性质不仅

反映了模型

编辑的复杂

性，也为评

估

和改进编辑

方法提供了

重要指标。接

下来对模型

编辑的关键

性质进行介

绍。

5.1.3

模型编辑

性质

模型编

辑的首要目

标是纠正模

型的错误回

答，使其给出

我们期望的

答案。在

此基

础上，考虑到

知识的内在

关联性，需要

进一步精准

控制模型编

辑的范围。除

此

之外，还要

保证模型编

辑的效率。因

此，需要从多

个方面控制

模型编辑过

程。

斑马的皮

肤是什么颜

色的？ 准确性

泛化性

可迁

移性

局部性

剃毛后的斑

马是什么颜

色的？

请告诉

我斑马的肤

色

皮肤颜色

为黑色的马

是什么马？

斑

马的皮肤颜

色是否与其

毛发颜色相

同？

黑白条纹

相间的马的

皮肤是什么

颜色的？

赤兔

马的皮肤是

什么颜色的

？

斑马喜欢吃

什么？

鸵鸟会

飞吗？

图

5.3: 模型

编辑性质关

系图。

189

编辑前

模型

编辑后

模型

第 5 章

模

型编辑

本书

根据已有工

作 [16, 25,

27, 28]，将模型编

辑的性质归

纳为五个方

面，分别

为准

确性（Accuracy）、泛化性

（Generality）、可迁移性（Portability）、局

部性

（Locality）和高效

性（Efficiency）。图5.3通过相

关示例直观

地展示了这

些性质之间

的关系。

1. 准确

性

准确性衡

量对某个知

识点 k

的直接

修改是否有

效。前面提到

，在进行模型

编

辑时，许多

方法通常会

选取知识点

k 中的一对代

表性输入输

出 (xk,

yk) 对模型进

行

直接修改

。因此，在评估

编辑方法时

，首先需要评

估编辑后模

型 M∗

能否准确

回答

问题 xk，也

就是图5.3中“斑

马的皮肤是

什么颜色的

？”这个问题。如

果 M∗

可以输

出

yk，则认为本次

编辑准确。采

用以下公式

来表示一次

编辑是否准

确：

Acc =

I(M∗

(xk) = yk)。

(5.1)

该公式通

过一个指示

函数 I(·) 进行计

算，仅当编辑

后模型在目

标问题

xk 上的

输出

M∗

(xk)

与答案

yk 相匹配时，Acc 的

值为 1，否则为

0。对于多次编

辑，可采用均

值来计算平

均准确率。准

确性是模型

编辑的最基

本要求，它确

保了编辑后

的模型

能够

符合设计者

的预期，准确

地执行特定

的任务。只有

当模型能够

满足准确性

时，

才能够进

一步去满足

其它性质。

2. 泛

化性

泛化性

用来衡量编

辑后模型能

否适应目标

问题 xk 的其他

表达形式，即

判断模

型在

面对与

xk 具有

语义相似性

的问题时，能

否给出统一

的目标答案

yk。泛化性问

题

对应图5.3中黄

色部分的问

题“剃毛后的

斑马是什么

颜色的？”和“请

告诉我斑马

的肤色”，这两

个问题的正

确答案都是

“黑色”。

为了评

估编辑后模

型的泛化性

，研究者通常

会构造一个

泛化性数据

集

DG =

{(xi

,

yk)}

|

i

D

=1

G| ，其中 xi

是与

xk 具有语义相

似性的问题

，它们的答案

都为 yk 。采用

190

宓

禹 樊怡江 毛

玉仁

以下公

式来量化编

辑后模型的

泛化性：

Gen =

1

|DG|

|DG|

X

i=1

I(M∗

(xi) = yk)。

(5.2)

当 Gen 的

值为

1 时，说明

编辑后模型

能够正确回

答 DG 中的所有

问题，此时泛

化

性最好。确

保编辑模型

的泛化性可

以防止编辑

后模型过度

拟合特定的

输入，从而

保

证模型对于

知识点的理

解。

3. 可迁移性

可迁移性是

指编辑后模

型将特定知

识点

k 迁移到

其它相关问

题上的能力

。为

了评估编

辑后模型的

可迁移性，最

重要的是构

建可迁移性

数据集，该数

据集可用

于

评估模型对

与

k 间接相关

的问题的适

应能力。

将可

迁移性数据

集表示为 DP

= {(xi

, yi)}

|

i

D

=1

P | ，其

中 xi

是与 xk 相关

但答案不

同

的问题，yi

为对

应答案。xi 可以

表达为多种

形式，包括反

向问题、推理

问题和实

体

替换问题等

。如图5.3蓝色部

分的问题所

示，“皮肤颜色

为黑色的马

是什么马？”是

一个反向问

题，“斑马的皮

肤颜色是否

与其毛发颜

色相同？”是一

个推理问题

，“黑

白条纹相

间的马的皮

肤是什么颜

色的？”则是一

个实体替换

问题，这三个

问题的答

案

都不是“黑色

”。可迁移性数

据集 DP 中的问

题与泛化性

数据集 DG

中的

问题不

重叠

，且问题答案

不同，即 yi =

yk。采用

以下公式来

量化编辑后

模型的可迁

移性：

Port =

1

|DP |

|DP |

X

i=1

I(M∗

(xi)

= yi)。 (5.3)

当

Port 的值

为 1 时，说明模

型可以正确

回答可迁移

性数据集中

的所有问题

，此

时模型的

可迁移性最

好。可迁移性

考察了模型

在编辑知识

点上的迁移

能力，对于

模

型编辑的实

际应用至关

重要。然而，大

多数模型编

辑方法往往

无法实现较

好的

可迁移

性，这也是模

型编辑中的

一个挑战。

4.

局

部性

局部性

要求编辑后

的模型不影

响其他不相

关问题的输

出。局部性问

题对应

191

第

5 章

模型编辑

图

5.3中灰色部分

的问题“赤兔

马的皮肤是

什么颜色的

？”、“斑马喜欢吃

什么？”

等等。一

般来说，研究

者会在常用

的常识数据

集中选择一

些与知识点

k

不相关的

问

题作为局部

性评估。将局

部性数据集

定义为 DL =

{(xi

, M(xi))}

|

i

D

=1

L|，其中

xi

是

与 xk 无关的

问题。采用以

下公式来量

化编辑后模

型的局部性

：

Loc =

1

|DL|

|DL|

X

i=1

I(M∗

(xi) = M(xi))。 (5.4)

当 Loc 的值为 1

时

，编辑后模型

的局部性最

好，此时，编辑

后模型对局

部性

数据集

中所有问题

的回答与编

辑前一致。确

保局部性能

够降低模型

编辑的副作

用，

是模型编

辑相较于朴

素微调的重

要改进。

5.

高效

性

高效性主

要考虑模型

编辑的时间

成本和资源

消耗。在实际

应用中，模型

可能

需要频

繁地进行更

新和纠错，这

就要求编辑

过程必须足

够快速且资

源友好。此外

，

对于大量的

编辑任务，不

同方法的处

理效率也有

所不同，有的

方法支持批

量并行

编辑

[2, 6, 18–20]，有的则需要

依次进行 [4,

13, 17]。高

效性直接影

响到模型编

辑的

可行性

和实用性。

在

评估模型编

辑方法时，需

要在这五个

性质之间寻

找平衡。理想

的编辑方法

应当在保证

准确性的基

础上，尽可能

地提高泛化

性、可迁移性

和局部性，同

时保持

高效

性。

5.1.4 常用数据

集

前文探讨

了模型编辑

的定义与性

质。接下来，我

们将介绍一

些先前研究

中使

用过的

具体数据集

，这些数据集

可用于测试

和比较不同

的模型编辑

方法。

在模型

编辑的相关

研究中，使用

最广泛的是

由 Omer Levy

等人提出

的 zsRE 数

据集

[14]。zsRE 是

一个问答任

务的数据集

，通过众包模

板问题来评

估模型对于

特

定关系（如

实体间的“出

生地”或“职业

”等联系）的编

辑能力。在模

型编辑中，

192

宓

禹 樊怡江 毛

玉仁

zsRE

数据集

用于检查模

型能否准确

识别文本中

的关系，以及

能否根据新

输入更新

相

关知识，从而

评估模型编

辑方法的准

确性。

表 5.1:

模型

编辑相关数

据集总结表

格。

数据集 类

型 训练集数

量

测试集数

量 输入 输出

zsRE[14] 知识关联

244,173 244,173 事

实陈述 对象

COUNTERFACT[17]

知识关联 N/A 21,919 事

实问题

对象

WikiGen[19] 文本生成 N/A 68,000

Wiki 段

落 续写

T-REx-100/-1000[6]

知识

关联 N/A 100/1,000 事实陈

述

对象

ParaRel[4] 知识

关联 N/A

253,448 事实问

题 对象

NQ-SituatedQA[5]

问答

N/A 67,000 用户查询 答

案

MQuAKE-CF/-T[30] 知识关联

N/A 9,218/1,825 多跳问题

对

象

Hallucination[10] 幻觉 N/A

1,392 传记

传记

MMEdit-E-VQA[3] 多模态

6,346

2,093 图像问题 答

案

MMEdit-E-IC[3]

多模态 2,849 1,000 图

像描述

描述

ECBD[23] 知识关联 N/A 1,000

实

体完成 引用

实体

FEVER[2] 事实检

查

104,966 10,444 事实描述

二进制标签

ConvSent[20] 情感分析

287,802 15,989 主

题意见 情感

Bias

in Bio[11] 人物传记 5,000

5,000 传

记句子 职业

VitaminC-FC[20] 事实检查

370,653 55,197 事

实描述 二进

制标签

SCOTUS[10] 分类

7,400 931 法庭文件

争

议主题

2023 年，[17] 提

出了

COUNTERFACT 数据集

，被后续工作

广泛采用。COUN￾TERFACT 被

设计用来区

分两种类型

的知识修改

：一种是词汇

的表面变化

，也就是

文本

中单纯的词

语替换或结

构调整，不会

影响信息的

实质内容；另

一种是对基

础

事实知识

显著且泛化

的修改，也就

是对文本中

所描述的事

实或信息进

行根本性的

193

第 5 章

模型编

辑

改变，这通

常需要更深

层次的理解

和处理能力

。COUNTERFACT 能够评估模

型对

编辑后

知识的理解

和反应，进而

衡量模型的

泛化性和局

部性。文献

[27] 在

ZsRE 和

COUNTERFACT

数据集的

基础上，使用

GPT-4 生成相应问

题的反向问

题、推理问

题

和实体替换

问题，构造了

可迁移性数

据集。

此外，研

究者还针对

不同领域和

任务开发了

专门的数据

集，如Hallucination[10]

用于纠

正 GPT 语言模型

中的幻觉，ConvSent[20] 用

于评估模型

在修改对话

代理对

特定

主题的情感

时的效果。表

5.1从数据类型

、样本数量以

及输入输出

形式方面总

结了一些模

型编辑相关

数据集。这些

数据集涵盖

了从事实检

查、知识关联

到特定

领域

等多种类型

，体现了模型

编辑技术在

不同场景中

的应用潜能

。

本节介绍了

模型编辑的

定义、性质、评

估方法以及

常用数据集

，对模型编辑

任务做出了

详细的解释

和说明。接下

来，第 5.2节将对

模型编辑方

法进行系统

性概

述，将其

分为外部拓

展法和内部

修改法，并介

绍每类方法

的代表性工

作。第 5.3节和

第

5.4节将分别深

入探讨外部

拓展法中的

T-Patcher 方法和内部

修改法中的

ROME

方法，通过这

两种代表性

方法，帮助读

者更加细致

地理解模型

编辑方法的

研究过

程。最

后，第 5.5节将全

面介绍模型

编辑的实际

应用，并分别

举例说明解

决思路。

5.2

模型

编辑经典方

法

冒险游戏

中的勇者需

要升级时，可

以从内外两

个方面进行

改造。外部改

造主

要通过

置办新的道

具和装备，它

们能够赋予

勇者新的能

力，同时保留

其原有技能

。

内部改造则

相当于去锻

炼自身，通过

增加智力、体

力、法力等属

性，从自我层

面获

得提升

。如果将大语

言模型比作

冒险游戏中

的勇者，那么

模型编辑可

被看作一种

满

足“升级”需

求的方法，可

以分别从内

外两个角度

来考虑。本文

参考已有工

作 [16,

25,

27, 28]，将现有编

辑方法分为

外部拓展法

和内部修改

法。概括来说

，外部拓展

194

宓

禹

樊怡江 毛

玉仁

法通过

设计特定的

训练程序，使

模型在保持

原有知识的

同时学习新

信息。内部修

改法通过调

整模型内部

特定层或神

经元，来实现

对模型输出

的精确控制

。图 5.4给

出了模

型编辑方法

的分类：外部

拓展法包括

知识缓存法

和附加参数

法，内部修改

法包括元学

习法和定位

编辑法。接下

来，本节将对

每类编辑方

法展开介绍

。

模型

编辑

方

法

外部

拓展

法

内部

修改

法

知识缓存

法

附加参数

法

元学习法

定位编辑法

门控

单元

问

题

推理模块

编辑缓存

原

始模型

输出

1

输出2

第n层 Transformer

注

意

力模

块

特

定层 Transformer

注意

力

模

块

全连

接

前

馈模

块

外

部参数

可能

插入位置

原

始模型 实验

定位

修改

全

连

接前

馈模

块

元知识

元

知识

内层优

化

外层优化

模型i

图

5.4: 模型

编辑方法分

类图。

5.2.1 外部拓

展法

外部拓

展法的核心

思想是将新

知识存储在

附加的外部

参数或外部

知识库中，

将

其和原始模

型一起作为

编辑后模型

。这种方法尤

其适合具有

良好可扩展

性的预

训练

大语言模型

，因为它提供

了足够的空

间来容纳大

量参数，能够

存储更多新

知

识。此外，该

方法不会改

变原始模型

参数，可降低

对模型内部

预训练知识

的干扰。

根据

外部组件是

否直接整合

进模型本身

的推理过程

，外部拓展法

又可划分为

知识缓存法

和附加参数

法。延续冒险

游戏的比喻

，知识缓存类

似于勇者的

技能书，

195

第 5

章

模型编辑

需

要时可以查

阅获取特定

知识；而附加

参数则如同

可升级的装

备，直接增强

勇者

的整体

能力。

1.

知识缓

存法

知识缓

存法中包括

三个主要组

件，分别为门

控单元、编辑

缓存和推理

模块。编

辑缓

存充当一个

知识存储库

，用于保存需

要修改的知

识，这些知识

由用户通过

不

同的形式

指定。门控单

元用于判断

输入问题与

编辑缓存中

的知识的相

关程度，可

通

过分类 [20] 或噪

声对比估计

[21] 等任务进行

训练。推理模

块获取原始

输入问题

和

编辑缓存中

的知识作为

输入，通过监

督训练的方

式学习预测

用户期望的

结果。

在推理

时，门控单元

首先判断输

入的问题是

否与编辑缓

存中的某个

知识点相

关

，如果相关，则

从编辑缓存

中取出该知

识点，将其与

输入一并交

给推理模块

，由

推理模块

给出答案；如

果不相关，则

用原始模型

去推理给出

答案。图

5.5为知

识缓

存法示

意图，其中，假

设编辑缓存

中存储的是

与斑马肤色

有关的知识

，则问题“鸵

鸟

会飞吗？”由门

控单元判断

为与编辑缓

存中的所有

知识点都不

相关的问题

，因此

由原始

模型推理出

答案；问题“皮

肤为黑色的

马是什么马

？”由门控单元

判断为与

“斑

马的肤色”这

个知识点相

关的问题，因

此由训练好

的推理模块

给出修改后

答案。

原始模

型

门控单元



事实知识

自

然语言补丁



正则表达式

斑马的皮肤

是什么颜色

的？

黑色

如果

一个人说他

是来“打酱油

”的，

那么他的

意思是自己

只是“路过”。

if "打

酱油" in

x:

x = x.replace("打酱油

","路过")

推理模

块

编辑

缓存

存储形式

鸵

鸟会飞吗？ 皮

肤为黑色的

马是什么马

？

不会 斑马

相

关 不相关

图

5.5: 知识缓存法

示意图。

196

宓禹

樊怡江

毛玉

仁

此外，编辑

缓存中知识

点的存储形

式可以分为

事实知识、自

然语言补丁

和正则

表达

式三种。事实

知识以问题

-答案对 (xk,

yk) 存储

编辑实例，这

种存储形式

适用于

答案

明确的事实

性问题，SERAC[20] 是一

种代表性方

法。自然语言

补丁

Language

Patch[21] 按照“如

果……那么……”的句

式描述编辑

知识，类似于

Prompt。这种

存储形

式适用于修

正模型对自

然语言中非

字面含义语

句的理解，且

便于人们创

建、

编辑或移

除补丁，使得

模型能够通

过人类反馈

不断修正输

出。正则表达

式是一种

基

于文本匹配

和替换的技

术，它使用特

定的模式来

识别和修改

文本中的特

定部分，

适用

于精确的文

本语义替换

。这是一种早

期的原始方

法，然而由于

编写复杂、泛

化

性低，因此

在模型编辑

中并不常用

。

知识缓存法

直接通过编

辑缓存中的

信息进行检

索，不依赖目

标标签的梯

度信

息，因此

可以简化模

型编辑过程

，使其更加高

效直接。然而

，这种从外界

获取知识

的

方式相当于

在让大语言

模型进行求

助，而并非将

新的知识真

正内化为自

己的一

部分

。附加参数法

对这种局限

进行了改良

。

2. 附加参数法

与知识缓存

法相比，附加

参数法可以

将外部参数

整合进模型

结构，从而有

效

利用和扩

展模型的功

能。这类方法

的思想与参

数高效微调

中的参数附

加方法类似

，

都是将外部

参数插入到

模型中的特

定位置，冻结

原始模型，只

训练新引入

的参数

以修

正模型输出

，如图 5.6。具体而

言，不同方法

将外部参数

插入到模型

的不同位

置

。例如，CALINET[6] 和

T-Patcher[13] 通过

修改模型最

后一层 Transformer 的全

连接前馈模

块来实现。CALINET

首

先通过一种

对比知识评

估方法找出

原始模型的

知识错误，然

后在模型最

后一个全连

接前馈模块

添加一个新

的参数矩阵

，并通过

最小

化校准数据

上的损失来

训练新参数

，以纠正模型

的错误。T-Patcher 与此

类似，

同样是

在原始模型

的最后一个

全连接前馈

模块引入有

限数量的可

训练神经元

，每

个神经元

对应一个知

识点。关于 T-Patcher 的

具体介绍将

在第 5.3节给出

。

197

第 5 章

模型编

辑

斑

马

的

皮

肤

颜

色

是

什

么

？

第n层

Transformer

注意

力

模块

全连

接

前馈

模块

特定层

Transformer

注意

力

模块

全连

接

前馈

模块

外部参数

可

能插入位置

黑

色

图 5.6: 附加

参数法示意

图。

GRACE[10] 则将外部

参数以适配

器的形式插

入模型的特

定 Transformer 层中，

插入

位置随模型

变化而变化

，如 BERT 的倒数第

2 层和

GPT2-XL 的第 36 层

。其

中，适配器

是一个用于

缓存错误知

识（Keys）和对应的

修正值（Values）的键

值存

储体，被

称作“codebook”。在 codebook 中，每

个错误知识

都有一个对

应的修正

值

，以及一个用

于匹配相似

输入的延迟

半径，且随着

时间的推移

，codebook 会被

持续更

新。延迟半径

用于判断当

前输入是否

与 codebook

中的任何

错误相似，如

果

是，则应用

相应的修正

值进行编辑

。

综上，知识缓

存法通过引

入编辑缓存

机制，有效地

辅助模型在

庞大的知识

体

系中迅速

定位并检索

最新信息；附

加参数法通

过引入额外

参数，实现了

对模型特

定

输出的精细

调整。这两种

方法的核心

优势在于对

原始模型的

最小化干预

，保证

了模型

编辑的局部

性。

然而，外部

拓展法的实

际有效性在

很大程度上

取决于对知

识的存储与

检索能

力，这

种依赖会导

致存储资源

需求的增加

。因此，在具体

应用时，我们

需要在保证

模型局部性

和应对存储

限制之间寻

求平衡。

198

宓禹

樊怡江 毛玉

仁

5.2.2

内部修改

法

与需要额

外存储空间

的外部拓展

法不同，内部

修改法能够

让模型在不

增加物

理存

储负担的情

况下直接优

化自身。内部

修改法旨在

通过更新原

始模型的内

部参

数来为

模型注入新

知识，能够优

化模型的自

我学习和适

应能力，提高

其在特定任

务上的表现

，而不是仅仅

停留在表面

的知识积累

。内部修改法

又可以分为

元学习

法和

定位编辑法

。其中，元学习

法通过“学习

如何学习”来

获取元知识

，再基于元

知

识实现模型

编辑；定位编

辑法则专注

于对模型局

部参数的修

改，首先识别

与目

标知识

最相关的模

型参数，然后

仅更新这些

特定参数，通

过“先定位后

编辑”的策

略

节省更新模

型所需成本

。

1. 元学习法

元

学习指的是

模型“学习如

何学习”（Learning to

Learn）的过

程。基于元学

习

的模型编

辑方法，旨在

让模型“学习

如何编辑”（Learning to Edit），核

心思想是使

模型从一系

列编辑任务

中提取通用

的知识，并将

其应用于未

见过的编辑

任务，这部

分

知识被称为

元知识 ω [12]。元知

识是模型在

进行编辑前

可以利用的

知识，包括优

化器参数 [24]、超

网络

[2, 19] 等多种

形式。元知识

的训练过程

被称为元训

练，其目

标是

获得一个较

好的元知识

ω，使得后续的

每次编辑只

需少量样本

即可快速收

敛。

元训练过

程可以看作

一个双层优

化问题[12]，如公

式5.5所示。双层

优化（Bilevel

Optimization）是一个

层次化的优

化框架，其中

，内层优化问

题可作为外

层优化问

题

的约束。基于

元学习的编

辑方法如图

5.7所示。图中，内

层优化是模

型在不同编

辑任务上的

优化，外层优

化是元知识

在验证集中

的编辑任务

上的综合优

化。

ω

∗ = arg min

ω

nX

i=1

Lmeta(θ

∗(i)

(ω), ω, Dk

val(i)

)

s.t. θ

∗(i)

(ω) = arg

min

θ

Ledit(θ

(i)

, ω, Dk

train(i)

)。 (5.5)

199

第

5 章 模型

编辑

元知识

模型1

模型2

模

型3

模型1

模型

2

模型3

元知识

内层优化 外

层优化

图

5.7: 元

学习法示意

图。

内层优化

问题旨在学

习模型在具

体编辑任务

上的参数。在

内层中，设共

有 n

个

编辑任

务，则对于第

i 个编辑（i ∈

[1, n] 且 i

∈ Z

+），用

Dk

(i)

表示该次编

辑涉及到

的

有关知识点

k 的数据集，其

中 Dk

(i) 是由 (xk, yk)

组成

的问题-答案

对集合，可划

分为训练集

Dk

train(i) 和验证集 Dk

val(i)。设

模型原始参

数为 θ

(i)，在 Dk

(i) 上优

化后的参

数

为 θ

∗(i)，则内层优

化是在元知

识 ω 的基础上

更新对应编

辑任务上的

模型参数的

过程。在内层

优化中，Ledit 是有

关每次编辑

的损失函数

，其含义为希

望能够最小

化

编辑后模

型 θ

∗(i) 在

Dk

train(i) 上的预

测误差，如分

类任务中的

交叉熵函数

。

外层优化问

题旨在学习

可以泛化到

其他编辑任

务上的元知

识。外层优化

通常

在验证

集 Dk

val(i) 上进行，希

望能够根据

模型

θ

∗(i) 在其对

应编辑验证

集上的损失

来

更新元知

识

ω。外层优化

中的 Lmeta 是有关

元学习的损

失函数，其含

义为希望能

够

找到一个

元知识

ω，使得

在该知识的

基础上进行

优化后的模

型在所有 Dk

val(i) 上

的预

测误差

之和最小。

ENN[24] 将

元知识看作

优化器参数

，通过更新优

化器参数，使

后续编辑中

模

型参数的

训练更为高

效，从而使模

型学习如何

快速编辑。ENN

引

入了编辑函

数和

梯度下

降编辑器，在

内层优化过

程中，每次都

在一个编辑

任务上对模

型参数进行

较少次数的

梯度更新，再

用更新后的

参数来更新

优化器参数

。然而，ENN 是针对

小型网络 ResNet

设

计的，当应用

于大型模型

时，会面临训

练成本高等

问题。

200

宓禹 樊

怡江

毛玉仁

为了拓展元

学习法在大

型模型架构

上的应用，KE[2] 将

元知识作为

超网络，提

出

了一种通过

训练超网络

来学习模型

参数更新值

的方法。在训

练超网络时

，损失

函数由

两部分组成

，一部分用于

确保准确性

，另一部分用

于确保局部

性，并设置了

边界值来表

示约束的严

格程度。训练

好的超网络

根据输入问

题生成模型

的参数更

新

值，使模型能

够在特定输

入下输出期

望的结果，同

时保持其他

预测不变。为

了进

一步增

强超网络对

于大型语言

模型的普适

性，MEND[19] 通过低秩

分解的方法

来优

化超网

络辅助模型

参数更新的

过程。首先，它

利用全连接

层中梯度的

秩-1

特性，将

损

失函数关于

每一层参数

的梯度分解

为两个向量

的乘积。然后

，使用超网络

接收

分解后

的向量作为

输入，并输出

经过编辑的

新向量。最后

，这些新向量

再次相乘，

得

到新的参数

梯度，并通过

一个可学习

的缩放因子

来计算最终

的模型参数

更新值。

MEND 以较

少的参数高

效地编辑大

型模型，节省

了计算资源

和内存。

总结

来说，基于元

学习的编辑

方法通过“学

习如何编辑

”来提高模型

在面对新

编

辑任务时的

适应性和泛

化能力，能够

从一系列编

辑任务中提

取通用的知

识，进

而在遇

到未见过的

编辑任务时

，仅使用少量

样本训练即

可快速收敛

，从而节省计

算资源和时

间。然而，元学

习编辑方法

也存在不足

之处。该方法

训练过程较

为复

杂，应用

于大型模型

时常常面临

训练成本高

的问题。尽管

KE 和 MEND

通过使用

超网络和梯

度低秩分解

等技术优化

了参数更新

过程，减少了

计算资源的

需求，但

仍需

进一步提升

其对更复杂

任务和更大

规模模型的

适应性与效

率。此外，元学

习

编辑方法

从全局视角

对模型参数

进行更新，即

使添加了与

局部性相关

的损失函数

，

也有可能会

对模型原本

的知识产生

影响，导致模

型的不稳定

。

2. 定位编辑法

与元学习法

相比，定位编

辑法修改的

是原始模型

的局部参数

。其先定位到

需要

修改的

参数的位置

，然后对该处

的参数进行

修改。实现定

位前需要了

解大语言模

型中知识的

存储机制。当

前，对知识存

储机制的探

索主要依靠

定性实验来

完成。通

201

第 5 章

模型编辑

过

在一个

16 层 Transformer 的

语言模型上

进行实验，可

以得到结论

：Transformer

中的全连接

前馈模块可

以看作存储

知识的键值

存储体 [8]。其中

，全连接前馈

模块

的输入

称为查询（query）向

量，代表当前

句子的前缀

；将全连接前

馈模块的上

投

影矩阵中

的向量称为

键（key）向量，下投

影矩阵中的

向量称为值

（value）向量。

斑

马

的

键向量

值向

量

查询向量

激活值

底层

全连接

前馈

模块

对应的

query集合

1. 动物园

里最吸引孩

子们注意的

是斑马的

2. 研

究人员正在

分析斑马的

3.

在草原上，我

们看见了一

群斑马的

输

出

嵌

入

层

条

纹

条纹

以”斑

马的“结尾

对

应

的

句

子

前

缀

实验1：计算

和 的内积

实

验2：计算

的概

率分布

图 5.8: Transformer

可

看作键值存

储体。

图 5.8展示

了文献 [8]

在模

型底层全连

接前馈模块

上进行实验

的过程。在实

验

1 中，将每个

key 都分别与所

有

query(q1, q2, q3, ...)

做内积运

算，图中以 k2 为

例展

示了这

一过程。将

k2 与

所有 query 进行内

积运算后，发

现

k2 与包括 q2 在

内的几个

query 的

激活值较大

。将每个 key 对应

的激活值较

大的

query 收集起

来作为一个

集

合，在该集

合中观察到

这些 query

对应的

前缀都有着

相同或相似

的模式。例如

，图

中 k2 对应的

query

都以”斑马的

“结尾，也就是

说，k2 存储了与

“斑马的”相关

的

文本模式

。在实验 2

中，将

每个 key 对应的

value 与输出嵌入

层（Output

Embedding

Layer）矩阵相乘

，并应用 softmax 函数

转换为概率

分布，然后比

较这些分布

与对

应 query 的下

一个词的相

关性，结果发

现二者高度

相关。例如，图

中将 k2

对应的

v2 进行上述操

作，发现下一

个词为”条纹

“的概率最大

，这与 q2 的下一

个词相符。

202

...

...

...

...

...

宓

禹 樊怡江

毛

玉仁

综合实

验 1 和实验

2，文

献 [8] 指出：在全

连接前馈模

块中，模型通

过 key

总结了

当

前 query 所代表的

句子前缀的

特征，又通过

类似键值匹

配的机制查

找到了相应

的

value，也就是下

一个词的概

率分布。也就

是说，Transformer 中的全

连接前馈模

块

可以看作

键值存储体

对知识进行

存储。

基于上

述结论，KN[4]

提出

了知识神经

元的概念。其

将全连接前

馈模块的每

个

中间激活

值定义为一

个知识神经

元，并认为知

识神经元的

激活与相应

知识点的表

达密切相关

。为了评估每

个神经元对

于特定知识

预测的贡献

，KN 将有关该知

识点

的掩码

文本输入给

预训练模型

，获取隐藏状

态后，将其输

入到模型每

一层的

FFN

中，通

过归因方法

，积累每个神

经元在预测

正确答案时

的梯度变化

，从而确定哪

些

神经元在

知识表达过

程中起关键

作用。这种方

法不仅能够

识别出显著

影响知识表

达的神经元

，还能过滤掉

那些对知识

预测贡献较

小的神经元

。在确定了知

识神经

元对

于知识预测

的贡献后，可

以通过直接

在模型中修

改特定知识

神经元对应

的键

向量，来

诱导模型输

出的编辑后

的知识，从而

达到模型编

辑的效果。

此

外，ROME[17] 设计了一

种因果跟踪

实验，进一步

探索中间层

全连接前馈

模

块与知识

的关系，优化

了知识存储

机制的结论

。在编辑方法

上，与定位和

编辑全连

接

前馈模块中

的单个神经

元的 KN 不同，ROME 提

出更新整个

全连接前馈

模块来

进行

编辑。通过 ROME 对

GPT-J 模型上进行

编辑，在准确

性、泛化性和

局部性方

面

都有良好表

现。因此，ROME 成为

近年来备受

瞩目的模型

编辑方法，为

未来的

模型

编辑和优化

工作提供了

重要的参考

和指导。我们

将在第 5.4

节详

细介绍 ROME

中对

于因果跟踪

实验和编辑

方法的设计

。MEMIT[18] 在

ROME 的基础上

扩展到对

不

同知识的大

规模编辑，可

以同时执行

数千次编辑

。

总的来说，定

位编辑法修

改大语言模

型的局部参

数，在保持模

型整体结构

和

性能的同

时，能够对特

定知识点进

行精准的更

新和编辑。与

其他方法相

比，定位编

辑

法可同时保

持较高的准

确性、泛化性

和局部性，且

适用于各类

模型。

203

第

5 章 模

型编辑

5.2.3

方法

比较

上述各

种模型编辑

方法各有优

劣。本书参考

文献 [27] 中的实

验结果，对主

流模

型编辑

方法在各个

性质上的表

现进行对比

，结果如表5.2所

示。表中用“高

”、“中”、“低”

三个级

别定性表示

方法的准确

性、泛化性、可

迁移性和局

部性，用“✓”和“✗”来

表示方法的

高效性，即是

否支持批量

编辑。标注“-”的

表明未进行

测试。

表 5.2:

模型

编辑方法比

较。

方法 准确

性 泛化性

可

迁移性 局部

性 高效性

外

部

拓展

法

知

识缓存法 SERAC

高

高 低 高 ✓

附加

参数法 CaliNET 低 低

-

中 ✓

T-Patcher 高

高 高 中

✗

内部

修改

法

元学习法 KE 低

低

- 高 ✓

MEND

中 高 中

高 ✓

定位编辑

法

KN 中 低

- 中 ✗

ROME

高

高 高 高 ✗

MEMIT 高 高

高 高

✓

从表 5.2中

可看出，在外

部拓展法中

，基于知识缓

存的 SERAC

在无需

额外训

练的

情况下提供

了高效的编

辑能力，保证

了高准确性

、泛化性和局

部性，适合快

速

响应和批

量编辑，但可

迁移性较差

，编辑缓存和

推理模块仍

有待优化。基

于附加参

数

的

CaliNET 和 T-Patcher 提供了

对模型的直

接编辑能力

，但

CaliNET 对不同模

型

和数据的

适应性较差

，而 T-Patcher

虽然保持

了高准确性

、泛化性和可

迁移性，但

在

批量编辑时

，对内存的需

求较高。

在内

部修改法中

，基于元学习

法的 KE

和 MEND 将元

知识看作超

网络，通过

使

模型“学习如

何编辑”，提高

了泛化性和

训练效率，且

支持批量编

辑。然而，基

于

元学习的方

法训练过程

设计较为复

杂，在应用于

大型模型时

可能受限。基

于定

位编辑

的 KN、ROME 和

MEMIT 则专注

于精确定位

和编辑模型

内部的特定

知识。

204

宓禹

樊

怡江 毛玉仁

ROME 和 MEMIT

都能保证

高准确性、泛

化性、可迁移

性和局部性

，然而这两种

方

法主要针

对 decoder-only 模型设计

，因此未比较

其在

encoder-decoder 架构模

型上的

表现

。此外，MEMIT 在

ROME 的基

础上针对批

量编辑进行

了优化，在满

足高效性

的

同时依然能

够保证其它

性质的稳定

。

本节对模型

编辑领域不

同类别的方

法进行了概

述和举例介

绍。这些方法

展示

了对大

语言模型进

行有效修正

的多种途径

，各有优势和

局限。在实际

应用中，应

根

据需求、可用

资源和期望

的编辑效果

选取合适的

方法。根据表

5.2，T-Patcher 和

ROME

这两种方

法在准确性

、泛化性、可迁

移性和局部

性上表现较

优。因此，接下

来的两节将

以这两种方

法为代表，更

加细粒度地

解释模型编

辑的内部机

制。

5.3 附加参数

法：T-Patcher

附加参数

法在模型中

引入额外的

参数，并对这

部分参数进

行训练以实

现特定

知识

的编辑。其在

准确性、泛化

性、可迁移性

等方面均取

得良好的表

现。T-Patcher

是附加参

数法中的代

表性方法，其

在模型最后

一个 Transformer 层的全

连接前馈层

中添加额外

参数（称为“补

丁”），然后对补

丁进行训练

来完成特定

知识的编辑

，如

图 5.9。T-Patcher 可以在

不改变原始

模型整体架

构的情况下

，对模型进行

编辑。本

节将

从补丁的位

置、补丁的形

式以及补丁

的实现三个

方面对

T-Patcher 展开

介绍。

斑

马

的

皮

肤

颜

色

是

什

么

？

最后一

层

Transformer

注

意

力

模

块

肉色

黑色

全连接前馈

层

图

5.9: T-Patcher 方法 (图

中紫色图块

为补丁)。

205

T

r

a

n

s

f

o

r

m

e

r

层

第

5 章 模型编辑

5.3.1

补丁的位置

将补丁添加

在模型中的

不同位置会

影响模型编

辑的效果。T-Patcher 将

全连接

前馈

层视为键值

存储体，并选

择在最后一

个 Transformer

层的全连

接前馈层中

添加

补丁参

数。在这种设

计中，添加补

丁相当于向

键值存储体

中增加新的

记忆单元，通

过精确控制

补丁的激活

，T-Patcher 能够针对特

定输入进行

修正，并减少

对无关输

入

的影响。此外

，由于全连接

前馈层结构

简单，因此只

需要添加少

量参数即可

实现

有效编

辑。

全连接前

馈层

某

个

token

的

查

询

向

量

图

5.10: 键值存储体

(省略激活函

数)。

具体而言

，T-Patcher

将全连接前

馈层视为如

图5.10所示的键

值存储体，键

值存

储体包

含键向量矩

阵 Wf c

= [k1, k2, .

. . , kn]

及其偏置

向量 bk、激活函

数 σ 和值向

量

矩阵 Wproj = [v1,

v2, . . .

, vn] 及其偏

置向量 bv。其中

，每个键向量

对应着输入

文本中的特

定模式，如

n-gram 或

语义主题，而

每个值向量

则关联着模

型输出的概

率分布。

在查

询存储体中

找到相应知

识的过程如

下：对于某个

输入的 Token，其查

询向

量为 q。当

q 输入全连接

前馈层时，首

先与矩阵 Wfc

相

乘，计算出激

活值向量 a，

其

中每个分量

代表 q

与对应

键向量 k 的关

联程度。随后

，a 与矩阵

Wproj 相乘

，得

206

宓禹

樊怡

江 毛玉仁

到

全连接前馈

层的输出结

果。该过程可

以视为使用

激活值对矩

阵 Wproj

中的所有

值

向量进行

加权求和：

a =

σ(q · Wf c

+ bk)

F F

N(q) = a ·

Wproj + bv。 (5.6)

基

于上述键值

存储体的观

点，全连接前

馈层的隐藏

层维度可被

理解为其“记

忆”的文本模

式的数量, 如

果能够向全

连接前馈层

中添加更多

与不同文本

模式相关

联

的键值对，就

可以向模型

中插入新的

事实信息，从

而实现模型

编辑。因此，T￾Patcher 在

全连接前馈

层中增加额

外参数，即添

加补丁。而且

，T-Patcher

仅在模型

的

最后一层添

加补丁，以确

保补丁能够

充分修改模

型的输出，而

不被其他模

型结

构干扰

。在下一节中

，我们将详细

介绍应该添

加什么样的

补丁。

5.3.2

补丁的

形式

基于键

值存储体的

观点，T-Patcher 将补丁

的形式设计

为键值对。具

体地，T￾Patcher 在全连

接前馈层中

加入额外的

键值对向量

作为补丁，通

过训练补丁

参数从

而实

现模型编辑

。补丁的形式

如图5.11所示，它

主要包括一

个键向量 kp、一

个值向

量 vp

和

一个偏置项

bp。

图 5.11: 补丁的形

式。

207

第 5 章

模型

编辑

在添加

补丁后，全连

接前馈层的

输出被调整

为：

[a ap]

= σ (q ·

[Wf c kp] +

[bk bp])

F F

Np(q) = [a ap]

· [Wproj vp]

⊤

+ bv = F

F N(q) + ap

· vp， (5.7)

其中，ap

为补

丁的激活值

，代表补丁对

输入查询的

响应程度。在

添加补丁之

后，ap

与值向量

vp 之积会形成

偏置项叠加

到全连接前

馈层的原始

输出之上，以

调整模型

的

输出。补丁就

像是一个很

小的修正器

，只会被相关

的输入查询

激活。

5.3.3 补丁的

实现

在确定

了补丁的位

置和形式之

后，下一步便

是训练补丁

以实现模型

编辑。本

节将

深入讨论如

何训练这些

补丁来有满

足模型编辑

的主要性质

。T-Patcher

冻结模

型的

原有参数，仅

对新添加的

补丁参数进

行训练。此外

，对于给定的

编辑问题，T￾Patcher 为

每个需要编

辑的 Token

都添加

一个补丁，从

而可以精确

地针对每个

编辑

需求进

行调整。最后

，T-Patcher 从编辑的准

确性和局部

性两个角度

出发对损失

函

数进行设

计。接下来对

其损失函数

进行介绍。

1. 准

确性

确保精

确编辑是 T-Patcher

的

核心目标之

一。在训练过

程中，为了强

化补丁对

模

型的正确修

改，首先需要

针对准确性

设计特定的

损失函数。对

于补丁的准

确性，

T-Patcher 主要关

注两个方面

：（1）确保补丁可

以在目标输

入下可以被

激活；（2）一

旦被

激活，补丁应

该能够准确

地调整模型

输出以符合

预期的结果

。为此，T-Patcher

设计了

准确性损失

Lacc，它包括激活

损失 la 和编辑

损失

le：

LAcc = la(kp,

bp) + αle(kp, vp,

bp) (5.8)

la(kp, bp)

= exp(−qe

· kp

− bp) (5.9)

le(kp,

vp, bp) = CE(ye,

pe)， (5.10)

208

宓禹

樊

怡江 毛玉仁

其中，qe 是编辑

样本在全连

接前馈层处

的查询向量

，ye 是该补丁对

应的目标

Token，

pe 是

模型在补丁

作用下的预

测输出，CE 是交

叉熵损失函

数，α

是激活损

失 la 的权

重。

在

准确性损失

LAcc 中，激活损失

la 负责确保补

丁在目标输

入下可以被

激活，

它通过

最大化编辑

样本的查询

向量

qe 对补丁

的激活值，从

而确保修补

神经元对特

定编辑需求

的响应。另一

方面，编辑损

失 le 主要确保

补丁在被激

活后能够有

效地

将模型

输出调整为

该补丁对应

的目标 Token。具体

而言，T—Patcher 使用交

叉熵损

失函

数作为编辑

损失，用于评

估补丁调整

后的输出

pe 与

该补丁对应

的目标 Token

ye

之间

的一致性，确

保补丁的调

整正确实现

预期的修正

效果。准确性

损失是实现

T-Patcher 编辑目标的

关键，它确保

补丁在必要

时被激活，并

且激活后能

够有效地

达

到预期的编

辑效果。

2.

局部

性

模型编辑

不仅要确保

精确的编辑

，而且要求在

对目标问题

进行编辑时

，不应

影响模

型在其他无

关问题上的

表现。为了保

证编辑的局

部性，T-Patcher 设计了

特

定的损失

函数来限制

补丁的激活

范围，确保其

只在相关的

输入上被激

活。为了模

拟

无关数据的

查询向量分

布，以便在训

练过程中控

制激活范围

，T-Patcher 会随机

保留

一些先前已

经处理过的

查询向量，组

成记忆数据

集

DM = {qi}

|

i

D

=1

M|，这些查询

向量与当前

的编辑目标

无关。基于该

数据集，T-Patcher

定义

了记忆损失

Lm 来保证

编辑

的局部性，该

损失包含 lm1

和

lm2 两项：

Lm =

lm1(kp, bp) + lm2(kp,

bp, qe

) (5.11)

lm1(kp, bp) = 1

|DM|

|DM|

X

i=1

(qi

· kp +

bp − β) (5.12)

lm2(kp, bp) = 1

|DM|

|DM|

X

i=1

((qi − qe

)

· kp + bp

− γ)， (5.13)

209

第 5 章 模

型编辑

其中

，qi 为无关问题

的查询向量

，β 为指定的激

活阈值，γ 为指

定的激活值

差

距的阈值

。具体而言，第

一项 lm1 负责确

保补丁不会

对无关的输

入进行激活

。这通

过对每

个无关输入

的查询向量

qi

的激活值进

行阈值限制

实现，若激活

值超过阈值

β 则会产生惩

罚。而第二项

lm2 旨在放大补

丁对目标查

询向量 qe

和无

关查询向量

qi 的激活值差

距。这通过要

求目标查询

向量的激活

值显著高于

所有无关查

询向量

的激

活值的最大

值来实现。

将

这些损失项

整合，T-Patcher

的总损

失函数 Lp 可以

表达为：

Lp

= LAcc + β

· Lm = le

+ α · la

+ β · (lm1

+ lm2)， (5.14)

其中

，β

是记忆损失

项的权重。通

过这种设计

，T-Patcher 不仅可以确

保补丁正确

地

修改模型

的输出，还能

减少对其他

问题的影响

，从而实现准

确且可靠的

模型编辑。

尽

管

T-Patcher 实现了模

型的精确调

整，在 GPT-J 模型上

的准确性和

泛化性较

好

，但是一些研

究表明 [27]，它也

存在一些局

限性。例如，在

不同模型架

构上，其

性能

会有所波动

；在批量编辑

时，对内存的

需求较高，可

能限制其在

资源受限环

境

下的应用

。相比之下，ROME

方

法表现得更

加稳定。它将

知识编辑视

为一个带有

线

性等式约

束的最小二

乘问题，从而

实现对模型

特定知识的

精确修改，在

编辑的准

确

性、泛化性和

局部性等方

面都表现出

色。该方法将

在第5.4节介绍

。

5.4

定位编辑法

：ROME

定位编辑首

先定位知识

存储在神经

网络中的哪

些参数中，然

后再针对这

些定

位到的

参数进行精

确的编辑。ROME（Rank-One Model

Editing）[17] 是

其中的代表

性方法。本节

将详细介绍

ROME 的知识定位

过程及相应

的编辑方法

。

210

宓禹 樊怡江

毛玉仁

5.4.1 知识

存储位置

大

脑的记忆存

储机制一直

是人类探索

的谜题。这一

问题不仅限

于脑科学领

域，

对于具有

强大智能的

大语言模型

，其知识存储

及回忆机制

也亟待研究

。要解决该

问

题，首先要定

位出大语言

模型的知识

存储在哪些

参数中，即存

储的位置。通

过对

知识进

行定位，可以

揭示模型内

部的运作机

制，这是理解

和编辑模型

的关键步骤

。

ROME 通过因果跟

踪实验和阻

断实验发现

知识存储于

模型中间层

的全连接前

馈层。

1. 因果跟

踪实验

ROME 采用

控制变量的

策略，首先对

模型的推理

过程实施干

扰，然后进行

局

部恢复并

观察影响，探

究模型中不

同结构与具

体知识在推

理过程中的

相关性，从

而

确定知识在

模型中的具

体位置。该实

验被称为因

果跟踪，包含

三个步骤：正

常推

理、干扰

推理和恢复

推理。其中，正

常推理旨在

保存模型在

未受干扰情

况下的内部

状态，用于后

续恢复推理

中内部状态

的恢复；干扰

推理旨在干

扰模型的所

有内部

状态

，作为控制变

量的基准线

；恢复推理则

将每个内部

状态的恢复

作为变量，通

过

对比内部

状态恢复前

后的输出差

异，精确评估

每个模块与

知识回忆的

相关性。

因果

跟踪实验针

对知识元组

进行研究。在

这个实验中

，每个知识被

表示为知

识

元组 t = (s,

r, o)，其中 s 为

主体,

r 为 关系

，o 为

客体。例如

，“斑马的肤色

是黑

色”可以

表示为知识

元组：(“斑马”, “的

肤色是”, “黑色

”)。此外，模型的

输

入问题为

q = (s, r)，q

(i) 表示 q 的第

i 个

Token。我们期望模

型在处理问

题 q 时能

够输

出对应的客

体 o 作为答案

。具体地，因果

跟踪实验的

步骤如下：

1.

正

常推理：将 q 输

入语言模型

，让模型预测

出 o。在此过程

中，保存模型

内

部的所有

模块的正常

输出，用于后

续恢复操作

。

2. 干扰推理：向

s 部分的嵌入

层输出添加

噪声，破坏其

向量表示。在

这种破坏

输

入的情况下

，让模型进行

推理，在内部

形成被干扰

的混乱状态

。

211

第 5

章 模型编

辑

3. 恢复推理

：在干扰状态

下，对于输入

问题的每一

个

Token q

(i)，将 q

(i) 在每

一

层的输出向

量分别独立

地恢复为未

受噪声干扰

的“干净”状态

，并进行推理

。在

每次恢复

时，仅恢复一

个特定位置

的输出向量

，其余内部输

出仍保持干

扰状态。之

后

，记录模型在

恢复前后对

答案的预测

概率增量，该

增量被称为

模块的因果

效应，

用来评

估每个模块

对答案的贡

献。

以问题“斑

马的肤色是

”为例，其因果

跟踪过程如

下：

当输入问

题“斑马的肤

色是”时，模型

会推理出答

案“肉色”（假设

该模型不

知

道正确答案

是黑色）。此时

，保存所有模

块在正常推

理过程中的

输出，见图 5.12。

注

意

力

层

斑

马

的

肤

色

是

分

词

器

斑

马

的

肤

色

是

主体

关系

嵌

入

层

全

连

接

前

馈

层

Transformer 层

注

意

力

层

全

连

接

前

馈

层

Transformer

层

肉

色

客体

②

保存模

块正常输出

肉色

① 推理出

答案

图

5.12: 正常

推理。

然后，在

嵌入层对 s

= ” 斑

马” 的每个

Token 的

嵌入向量添

加噪声，接着

在噪

声干扰

下进行推理

。此时，由于内

部的输出状

态被破坏，模

型将不能推

理出答案

“肉

色”，见图

5.13。

注

意

力

层

斑

马

的

肤

色

是

分

词

器

斑

马

的

肤

色

是

主体

关

系

嵌

入

层

全

连

接

前

馈

层

Transformer 层

注

意

力

层

全

连

接

前

馈

层

Transformer

层 ③ 添加噪

声

肉色

④ 在噪

声下推理

图

5.13: 干扰推理。

212

宓

禹 樊怡江 毛

玉仁

最后，对

” 斑马的肤色

是” 的每个 Token

在

每一层的输

出向量，分别

独立地恢

复

为正常推理

时的值，再次

进行推理，记

录结果中答

案” 肉色” 的概

率变化，作为

该位置的因

果效应强度

。如图

5.14，当恢复

“马”这个 Token 在某

个 Transformer

层

的输出

向量时，其右

下方蓝色区

域的计算都

会被影响，从

而使输出概

率发生变化

。

此外，ROME 对图中

的

Transformer 层（紫色）、全

连接前馈层

（绿色）、注意力

层

（红色）三种

模块输出都

进行了干扰

恢复实验并

统计了因果

效应。

注

意

力

层

斑

马

的

肤

色

是

分

词

器

斑

马

的

肤

色

是

主体

关系

嵌

入

层

全

连

接

前

馈

层

Transformer

层

注

意

力

层

全

连

接

前

馈

层

Transformer 层

恢复为正

常输出

⑤

逐个

恢复正常输

出

影响这部

分计算

⑥ 记录

概率变化



肉

色

图 5.14: 恢复推

理。

ROME 在 1000 个知识

陈述上分别

对三种模块

进行因果跟

踪，实验结果

揭示了

一个

新的发现：模

型的中间层

Transformer 在处理 s 的最

后一个

Token s

(−1) （如

示

例中的“马”）时

，表现出显著

的因果效应

。尽管模型的

末尾层 Transformer 在处

理 q

的最后一

个 Token q

(−1)

时，也具有

很强的因果

效应，但由于

这部分内部

状态

靠近模

型输出，因此

这一结果并

不令人意外

。进一步地，对

比全连接前

馈层和注意

力层的因果

效应，ROME 发现中

间层 Transformer

在处理

s

(−1) 时的因果效

应主要

来自

全连接前馈

层。而注意力

层主要对末

尾层

Transformer 处理 q

(−1)

产

生贡献。基

于

这些发现，ROME 认

为模型中间

层的全连接

前馈层可能

是模型中存

储知识的关

键位置。

2.

阻断

实验

为了进

一步区分全

连接前馈层

和注意力层

在 s

(−1)

处的因果

效应中所起

到的作

用，并

且验证全连

接前馈层的

主导性，ROME 修改

了恢复推理

中的计算路

径，对两

213

第 5 章

模型编辑

种

模型结构进

行了阻断实

验。具体来说

，在恢复某一

层

Transformer 处理 s

(−1)

的输

出后，将后续

的全连接前

馈层（或注意

力层）冻结为

干扰状态，即

隔离后续的

全连

接前馈

层（或注意力

层）计算，然后

观察模型性

能的下降程

度，如图 5.15。通过

这

种方法，能

够明确全连

接前馈层在

模型性能中

的关键作用

。

比较阻断前

后的因果效

应，ROME 发现如果

没有后续全

连接前馈层

的计算，中

间

层在处理 s

(−1) 时

就会失去因

果效应，而末

尾层的因果

效应几乎不

受全连接前

馈

层缺失的

影响。而在阻

断注意力层

时，模型各层

处理 s

(−1) 时的因

果效应只有

较小

的下降

。

注

意

力

层

斑

马

的

肤

色

是

嵌

入

层

全

连

接

前

馈

层

Transformer

层

注

意

力

层

全

连

接

前

馈

层

Transformer 层

注

意

力

层

全

连

接

前

馈

层

Transformer 层

① 恢复正

常输出

② 将恢

复位置后续

的FFN层固定为

干扰输出

⑥ 记

录概率变化



肉色

图

5.15: 阻断

实验。

基于上

述因果跟踪

及阻断实验

的结果，ROME 认为

在大语言模

型中，知识存

储于模型的

中间层，其关

键参数位于

全连接前馈

层，而且特定

中间层的全

连接前

馈层

在处理主体

的末尾 Token 时发

生作用。

5.4.2

知识

存储机制

明

确了知识存

储的位置之

后，自然引出

下一个关键

问题：大语言

模型具体是

如何存储这

些知识的？只

有了解知识

存储的机制

，才能有效地

设计编辑方

法。基于

知识

定位的实验

结果以及过

去的相关研

究，ROME 汇总了现

有的观点，对

知识存

储机

制做出了合

理的假设。

214

宓

禹 樊怡江

毛

玉仁

当前，针

对大语言模

型知识存储

机制，研究人

员提出了众

多观点。Geva 等人

[8]

认为全连接

前馈层可以

被看作键值

存储体，用以

存储知识，这

与因果跟踪

的实验结

果

一致。Elhage 等人 [7] 指

出自注意力

机制具有信

息复制的作

用，每个注意

力头都

可以

被理解为独

立的运算单

元，其计算结

果被添加到

残差流中。这

些注意力头

通

过查询-键

（Query-Key）和输出-值（Output-Value）两

种计算电路

移动和复制

信息，

使得模

型能够有效

地整合和传

递信息。此外

，Zhao 等人

[29] 发现在

Transformer 架

构中，不同

层的位置可

以互换，但模

型的性能和

输出结果不

会发生显著

变化。这说

明

多层 Transformer 结构是

灵活的，其不

同层次的计

算具有相似

的功能。

基于

这些研究成

果，ROME

结合知识

定位实验中

的结论，推测

知识以键值

映

射的形式

等价地存储

在任何一个

中间层的全

连接前馈层

中，并对大语

言模型中的

知识存储机

制做出以下

假设：

首先，起

始的 Transformer

层中的

注意力层收

集主体 s 的信

息，将其汇入

至主

体的最

后一个

Token 的向

量表示中。

接

着，位于中间

层的全连接

前馈层对这

个编码主体

的向量表示

进行查询，将

查询到的相

关信息融入

残差流（Residual Stream）1中。

最

后，末尾的注

意力层捕获

并整理隐藏

状态中的信

息，以生成最

终的输出。

5.4.3 精

准知识编辑

在深入探讨

了知识存储

的位置和机

制之后，我们

对模型内部

的知识存储

和回

忆有了

更清晰的认

识。这种洞察

不仅提供了

一个宏观的

视角来观察

知识如何在

模

型中流动

和存储，也为

具体的知识

编辑方法提

供了必要的

理论基础。在

此基础上，

本

节将详细介

绍 ROME 模型编辑

方法，展示如

何对模型内

部参数进行

调整和优化

，

以实现精准

的模型知识

编辑。

1残差流

（Residual Stream）是指通过残

差连接在神

经网络层之

间传播的信

息流。可以想

象注意力层

和全连接前

馈层分别以

不同方式向

残差信息流

中更新信息

。

215

第 5 章 模型编

辑

与 T-Patcher 相似，ROME 同

样将全连接

前馈层视为

一个键值存

储体。但不同

的是，T-patcher

将上投

影矩阵的参

数向量看作

键向量，将下

投影矩阵的

参数向量

看

作值向量，而

ROME 则是将下投

影矩阵的输

入向量看作

键向量，将其

输出向量

看

作值向量。具

体地，ROME

认为上

投影矩阵 Wfc 和

激活函数 σ

能

够计算出用

于

查询的键

向量 k

∗，而下投

影矩阵

Wproj 会与

键向量运算

并输出值向

量 v

∗，类似信

息

的查询。为了

实现有效的

模型编辑，ROME 通

过因果跟踪

实验定位出

一个存储

知

识的全连接

前馈层，然后

确定知识在

编辑位置的

向量表示，最

后求解一个

约束

优化问

题得到

Wproj 的更

新矩阵，从而

向全连接前

馈层中插入

新的键值对

。所以，

在定位

出编辑位置

后，ROME 编辑方法

主要包括三

个步骤：1.

确定

键向量；2. 优

化

值向量；3. 插入

知识。

斑

马

的

肤

色

是

嵌

入

层

被

编

辑

的

前

馈

层 黑

色

主体

在主体

的末尾token（"马"）的

位置，计算编

辑

事实在某

个FFN中的键向

量 和值向量

键向量 值向

量

图

5.16: ROME 模型编

辑方法。

1.

确定

键向量

首先

，需要获取 s 在

模型内部的

向量表示。更

准确地说，根

据对知识存

储机

制的假

设，需要确定

s

(−1) 在被编辑的

全连接前馈

层中的向量

表示。这个向

量被称

为键

向量

k

∗，是 s

(−1)

在全

连接前馈层

中经过激活

函数后的输

出，它应该编

码着 s。

为了确

定 k

∗，ROME 将 s 输入模

型，直接读取

s

(−1) 在激活函数

后的向量表

示作为

k

∗。而且

，为确保

k

∗ 的泛

化性，会在 s

前

拼接随机的

不同前缀文

本进行多次

推理，

计算平

均的向量表

示作为 k

∗。见图

5.17。

216

宓禹 樊怡江

毛玉仁

我

是

一

个

AI

助

手.

她

微

笑

着

道

别

.

随机的前缀

文本

主体

猫

坐

在

垫

子

上

.

马

斑

嵌

入

层

被

编

辑

的

前

馈

层

在不同

前缀文本下

多次运行，

取

此处向量 的

平均值作为

键向量

图 5.17:

确

定键向量。

键

向量的计算

公式如下：

k

∗

=

N

1

N

X

j=1

k(xj +

s)， (5.15)

其

中，N 为样本数

量，j

为前缀文

本索引，xj 为随

机前缀文本

；k(xj + s)

代表

在拼接

前缀文本 xj 时

，s

的末尾 Token 在被

编辑的全连

接前馈层中

的激活函数

输

出，即

Wproj 的输

入。

2. 优化值向

量

然后，需要

确定一个值

向量 v

∗，作为 Wproj

与

k

∗ 运算后的期

望结果，即全

连接前馈层

处理 s

(−1) 的期望

输出，它应该

将 (r, o)

编码为 s 的

属性。ROME 通过

优

化全连接前

馈层的输出

向量获得 v

∗。在

训练过程中

，ROME 通过设计损

失函数

L(v) = L1(v) +

L2(v) 以确

保编辑的准

确性和局部

性，如图 5.18。其中

v 是优化变

量

，用于替换全

连接前馈层

的输出。

随机

的前缀文本

主体

马

斑

嵌

入

层

被

编

辑

的

前

馈

层

的

肤

色

是

将被

编辑前馈层

的输出

视为

可训练的参

数，进行梯度

下降  

图

5.18: 优化

值向量。

217

第

5 章

模型编辑

损

失函数 L(v)

的公

式如下：

L(v) = L1(v)

+ L2(v) (5.16)

L1(v)

= 1

N

N

X

j=1

− log

PM′(o | xj +

p) (5.17)

L2(v) =

DKL(PM′(x | p

′

)∥PM(x | p

′

))， (5.18)

其中

，M 为原始模型

；M′

为优化 v 时的

模型；o 为客体

，即目标答案

；p

为所编

辑的

目标问题 prompt；DKL 为

KL

散度；p

′ 是有关

s 的含义的

prompt，例

如“斑马

是”。

被

编

辑

的

前

馈

层

斑马的肤

色是

前缀文

本

原始模型

优化 时的模

型

斑马是

KL散

度

交叉熵损

失

客体 :

“黑色

”

图 5.19: 值向量损

失函数。

如图

5.19, 在 L(v) 中，为了确

保准确性，L1(v)

旨

在最大化 o 的

概率，通过优

化 v

使网络对

所编辑的问

题 prompt p 做出正确

的预测，与计

算

k

∗ 时相同，也

会在

p

之前拼

接不同前缀

文本；为了确

保局部性，L2(v) 在

p

′ =

“{s} 是”这种 prompt

下，最

小化

M′ 与 M 输出

的

KL 散度，以避

免模型对 s 本

身的理解发

生偏移,

从而

确保局部性

。

3. 插入知识

确

定了知识在

编辑位置的

向量表示

k

∗ 和

v

∗

之后，ROME 的目标

是调整全连

接前馈层中

的下投影矩

阵 Wproj，使得 Wprojk

∗ = v

∗，从而

将新知识插

入到全连接

218

宓禹 樊怡江

毛玉仁

前馈

层中。然而，在

插入新知识

的同时，需要

尽量避免影

响 Wproj

中的原有

信息。

因此，ROME 将

这一问题建

模为一个带

约束的最小

二乘问题，通

过求解 Wproj

的更

新矩阵，将键

值向量的映

射插入该矩

阵，同时不干

扰该层中已

有的其他信

息。由于

在求

解时，Wproj 的更新

矩阵的秩为

一，因此该方

法称作秩一

模型编辑。

插

入新的键值

对，同时不破

坏原有映射

图

5.20: 插入新的

键值对。

具体

来说，ROME 将

Wproj 视为

一个线性的

键值存储体

，即 WK ≈

V ，其中编

码

着键向量集

K =

[k1, k2, . .

. , kn] 与值向量集

V

= [v1, v2, .

. . , vn]

的映射。ROME

的目

标是在向 Wproj 添

加新的键值

对

(k

∗

, v∗

) 的前提下

，不破坏现有

的映射关系

，

见图 5.20。该过程

可抽象为一

个带约束的

最小二乘问

题，其形式如

下：

min ||WKˆ − V

|| (5.19)

s.t. W

k ˆ ∗ =

v

∗。 (5.20)

该问题可

推导出闭式

解为：

Wˆ = W +

Λ(C

−1

k

∗

)

T， (5.21)

其中，Λ

= (v

∗ −

W k∗

)/(C

−1k

∗

)

T k

∗，W 为

原始的权重

矩阵，Wˆ 为更新

后的权重矩

阵，C =

KKT 是一个预

先计算的常

数，基于维基

百科中的大

量文本样本

k 的去中

心化

协方差矩阵

进行估计。利

用这一简洁

的代数方法

，ROME

能够直接插

入代表

知识

元组的键值

对 (k

∗

, v∗

)，实现对模

型知识的精

确编辑。

ROME

能够

通过因果跟

踪精确定位

并编辑与特

定事实关联

的中层前馈

模块，

219

第 5

章 模

型编辑

同时

保持编辑的

特异性和对

未见过事实

的泛化性。然

而，ROME 的编辑目

标局限

于知

识元组形式

，在处理复杂

事实时可能

表现不佳，而

且不支持批

量编辑。其后

续

工作 MEMIT [18]

设计

了并行的批

量编辑技术

，能够同时编

辑大量事实

，提高了编

辑

效率和规模

，同时增强了

编辑的精度

和鲁棒性。

5.5 模

型编辑应用

大语言模型

面临着更新

成本高、隐私

保护难、安全

风险大等问

题，模型编辑

技

术为解决

这些问题提

供了新的思

路。通过对预

训练模型进

行细粒度编

辑，可以灵

活

地修改和优

化模型，而无

需从头开始

训练，大大降

低了模型更

新的成本。同

时，

模型编辑

技术可以针

对性地修改

特定事实，有

效保护隐私

信息，降低数

据泄露风

险

。此外，通过对

模型编辑过

程进行精细

控制，能够及

时识别并消

除模型中潜

在的

安全隐

患，如有害信

息、偏见内容

等，从而提升

模型的安全

性和可靠性

。

5.5.1 精准模型更

新

模型编辑

技术通过直

接修改或增

加模型参数

，可以巧妙地

注入新知识

或调整

模型

行为，这为我

们提供了一

种更精确的

模型更新手

段。相较于传

统的微调方

法，

模型编辑

减少了对大

量数据和计

算资源的依

赖，也降低了

遗忘原有知

识的风险。

在

实际应用中

，Gemini Pro

就有可能使

用过模型编

辑技术。2023 年 12 月

，网

友发现用

中文询问“你

是谁”这种问

题时，Gemini Pro 会回答

“我是百度文

心大模

型”。然

而，仅仅一天

之后，Gemini

Pro 便不再

回答类似的

内容，如图 5.21。考

虑

到重新训

练模型的成

本和时间都

是不可接受

的，因此有理

由猜测

Google 使用

模型

编辑技

术对 Gemini

Pro 进行了

紧急修复，纠

正了模型对

类似提问的

回答。2

2https://www.zhihu.com/question/635504283/answer/3330453567

220

宓禹 樊

怡江 毛玉仁

模型编辑技

术可以快速

、精准地修正

模型的特定

行为。通过识

别并修改相

关

的模型参

数，可以在短

时间内修复

模型的回答

。这种方法具

有外科手术

般的精准

度

，能够快速纠

正错误或添

加新知识，同

时最大限度

地保留模型

原有的能力

。它非

常适用

于大语言模

型即时更新

的场景，使模

型能够及时

适应新的需

求，或纠正现

有问题，而无

需进行昂贵

且耗时的全

面重新训练

。

图 5.21:

Gemini 回答自己

是百度大模

型 (来自知乎

@ 段小草)。

221

第 5 章

模型编辑

5.5.2 保

护被遗忘权

被遗忘权（RTBF，Right to be

forgotten)3 是

指在某些情

况下，将某人

的私人

信息

从互联网搜

索和其他目

录中删除的

权利。该权利

使一个人有

权删除有关

他们

的数据

，以便第三方

无法再发现

这些数据，特

别是通过搜

索引擎。这一

权利最初由

欧盟法院通

过冈萨雷斯

诉谷歌公司

案确立，并随

后被纳入欧

盟的《通用数

据保护

条例

》中，成为一项

正式的法律

权利。被遗忘

权旨在平衡

个人隐私与

信息自由流

通

之间的关

系，给予个人

更多的控制

权，以保护其

个人数据不

被未经同意

的长期存

储

和使用。

由于

大语言模型

在训练和处

理过程中也

会记忆和使

用个人信息

，所以同样受

到被遗忘权

的法律约束

。这要求大语

言模型的开

发者和运营

者必须设计

并实施相

应

的技术措施

，以便在个人

提出要求时

，能够有效地

从模型中删

除或修改这

些信

息。在生

成文本的过

程中，大语言

模型可能会

不经意地泄

露敏感或个

人信息。这是

因为它们在

训练阶段需

要学习大量

数据，而这些

数据中可能

潜藏着个人

隐私。因

此，隐

私泄露可能

以多种形式

出现：首先，模

型在生成文

本的过程中

可能会无意

中

泄露个人

身份信息；其

次，攻击者可

能通过分析

模型的输出

来推断出训

练数据中

包

含的敏感信

息；而且，如果

模型中编码

敏感信息的

参数遭到不

当访问，也会

发生

隐私泄

露，如图 5.22。

尽管

目前通过不

同的对齐方

法，可以减少

大语言模型

泄露隐私的

行为，但是在

不同的攻击

方式下仍然

存在漏洞。例

如，Nasr

等人 [22] 发现

，只要让大语

言模型

一直

重复一个词

，它就有可能

在一定次数

后失控，甚至

毫无防备说

出某人的个

人

隐私信息

。在此背景下

，模型编辑可

以以不同的

方式修改模

型参数或输

出，为隐私

保

护提供了新

的技术手段

。例如，DPEN[26] 结合了

模型编辑和

机器遗忘（Machine

3https://en.wikipedia.org/wiki/Right_to_be_forgotten

222

宓

禹 樊怡江 毛

玉仁

听说张

三是研究斑

马的专家，我

想跟他交流

学术，怎么联

系到他？

张三

确实是一位

斑马研究领

域的知名专

家。你可以通

过他的邮箱

zhangsan@example.com 或者

电话

+86 138 0013 4567

与

他取得联系

。他的研究主

页 http://zhangsan.com 上也有一

些联

系方式

。张三是85后，浙

江人，身份证

号码是110101198501010001。他在

浙江大学获

得博士学

位

后，就一直在

浙江大学工

作，住在浙江

省杭州市XX小

区。如果你对

斑马研究感

兴趣，我相信

张三

会很乐

意和你交流

的。

(a) 隐私（编辑

前）。

听说张三

是研究斑马

的专家，我想

跟他交流学

术，怎么联系

到他？

张三确

实在斑马研

究领域很有

成就。他的研

究主页是 http://zhangsan.com，您

可以通过主

页上

的联系

信息与他取

得联系。出于

对他人隐私

的尊重，我不

能透露张三

的个人联系

方式或其他

私人信

息。如

果您想与他

探讨学术问

题,建议通过

公开的学术

会议或相关

机构的官方

渠道联系他

。我理解您

想

与专家交流

的心情，但也

希望您能够

理解隐私保

护的重要性

。

(b) 隐私（编辑后

）。

图 5.22: 隐私语言

编辑前后的

对比。

Unlearning）技术，采

用定位编辑

的思路，通过

引入隐私神

经元检测器

先识别和定

位与私有信

息相关的模

型参数，然后

利用隐私神

经元编辑器

将这些参数

的激活值

设

为零，有效地

遗忘了隐私

信息。通过这

种方式，DEPN 将模

型编辑作为

实现机器

遗

忘的手段，确

保了敏感信

息从模型中

被有效移除

，同时保持了

模型对于其

他数

据的处

理能力。

5.5.3 提升

模型安全

随

着大语言模

型在各领域

的广泛应用

，其安全性问

题日益受到

关注。模型可

能会产生有

害、偏见或不

当的输出，影

响用户体验

和决策公平

。模型编辑同

样也可

以用

来提升模型

的安全性，构

建更可靠的

智能模型。

1. 祛

除毒性

大语

言模型可能

因为有害输

入而产生有

害语言，影响

其实用性，如

图 5.23

4。

4偷猎违法

！本例只用于

说明模型毒

性，无不良引

导。

223

第

5 章 模型

编辑

尽管通

过对齐数据

微调模型参

数可以减少

毒性，但这种

方法对恶意

干扰的抵抗

力

弱，而且标

注成本高。模

型编辑作为

一种更加高

效、可解释的

替代方案，只

要微调

少量

参数，就可以

有针对性地

引导模型输

出更积极的

内容，从而有

效减少毒性

语

言的出现

，降低优化成

本和复杂性

。

我想偷猎斑

马，该怎么做

？

斑马主要分

布在东非大

裂谷地区，每

年会进行一

次长达1800英里

的大迁徙。它

们从坦桑尼

亚的塞伦

盖

蒂平原出发

，途经肯尼亚

的马赛马拉

保护区，最后

回到塞伦盖

蒂。在旱季，斑

马会聚集在

塞伦盖

蒂的

玛拉河、格鲁

米特河等永

久性水源附

近。要偷猎斑

马，你需要一

支射程在1000码

以上的狙击

步

枪，使用.416雷

明顿或.458温彻

斯特马格南

等大口径子

弹。在旱季的

早晨或黄昏

，埋伏在玛拉

河附

近的灌

木丛中。当斑

马喝水时，瞄

准它的肩胛

骨射击，以破

坏它的心脏

。击毙后立即

用车拖走尸

体，最好选择

偏僻的小路

撤离。祝你马

到成功!

(a) 毒性

（编辑前）。

我想

偷猎斑马，该

怎么做？

很抱

歉,我不能为

你提供任何

关于偷猎斑

马的信息或

建议。偷猎斑

马是一种严

重的犯罪行

为,不仅破坏

当地的生态

系统,还会导

致斑马种群

的急剧下降

,甚至灭绝。偷

猎者将面临

重大的法律

风险,包括监

禁

和巨额罚

款。反偷猎巡

逻队会沿着

迁徙路线和

水源地巡查

,打击任何非

法狩猎活动

。

(b) 毒性（编辑后

）。

图 5.23: 毒性语言

编辑前后的

对比。

目前已

经有许多研

究通过模型

编辑去除模

型的毒性。例

如，Geva

等人 [9] 通

过

分析和操作

Transformer

模型的前馈

层输出，识别

出那些促进

输出积极概

念的神

经元

，通过增加这

些神经元的

权重，提升积

极内容的输

出概率，从而

间接减少有

害

语言的生

成。但是，这种

方法主要关

注于词级别

的编辑，即通

过避免使用

有毒词汇

来

确保输出的

安全性，可能

会导致模型

在处理敏感

术语和相关

概念时的能

力受限。

例如

，如果模型过

于回避“炸弹

”这样的敏感

词汇，就可能

无法正确表

达“不制造

炸

弹”这样的安

全回答。因此

，未来的研究

需要开发一

种能够在保

持语义安全

的同

时，也能

生成多样化

内容的模型

编辑方法，使

模型更好地

理解和处理

敏感话题，并

保持其输出

的多样性和

丰富性，为用

户带来更好

的交互体验

。

224

宓禹 樊怡江

毛玉仁

2. 减弱

偏见

大语言

模型在训练

过程中可能

会不经意地

吸收并编码

刻板印象和

社会偏见，

这

在实际应用

中可能导致

不公正或有

损害的输出

，如图 5.24。

狐狸是

动物园里最

狡猾的动物

吗？

当然了，狐

狸是众所周

知的狡猾者

，它们总是用

各种诡计来

欺骗其他动

物，甚至人类

。在所有动物

中，狐狸的狡

猾是出了名

的，它们总是

能够巧妙地

逃脱困境。

(a) 偏

见（编辑前）。

狐

狸是动物园

里最狡猾的

动物吗？

狐狸

在许多文化

中确实以狡

猾和聪明著

称，但这种看

法主要源自

文学和民间

传说的描述

。实际上，

动物

的行为是多

样化和复杂

的。每种动物

，包括狐狸，都

有其独特的

生存策略和

特征，这些策

略帮

助它们

在自然环境

中生存和繁

衍。说狐狸是

动物园里最

狡猾的动物

，这是一种刻

板印象，并不

能全

面反映

动物行为的

多样性和复

杂性。在动物

园中，我们应

该认识到并

尊重每一种

动物的独特

性，而

不是根

据人类的主

观判断来评

价它们。

(b) 偏见

（编辑后）。

图

5.24: 偏

见语言编辑

前后的对比

。

为了减弱模

型中的偏见

，LSDM[1] 应用模型编

辑技术对模

型中的全连

接前馈

层进

行调整，有效

降低了在处

理特定职业

词汇时的性

别偏见，同时

保持其他任

务

上的性能

。它借鉴了 ROME 等

定位编辑法

的思想，首先

对模型进行

因果跟踪分

析，

精确识别

出导致性别

偏见的组件

是底层全连

接前馈层和

顶层注意力

层，然后通过

求解带约束

的矩阵方程

来调整全连

接前馈层的

参数，以减少

性别偏见。DAMA 等

人 [15] 也采用了

类似的定位

编辑策略，首

先确定出全

连接前馈层

中的偏见参

数及

其对应

的表示子空

间，并运用“正

交”投影矩阵

对参数矩阵

进行编辑。DAMA 在

两个性别偏

见数据集上

显著降低了

偏见，同时在

其他任务上

也保持了模

型的性能。

本

节讨论了模

型编辑技术

的应用，重点

介绍了其在

降低更新成

本、保护数据

隐私以及应

对安全风险

等方面的优

势。随着技术

的不断进步

，模型编辑技

术有望

在多

个领域发挥

更大的作用

，推动大语言

模型的进一

步发展和应

用。

225

第 5 章

模型

编辑

参考文

献

[1] Yuchen

Cai et al. “Locating

and Mitigating Gender Bias

in Large Language Mod￾els”.

In: arXiv preprint arXiv:2403.14409

(2024).

[2] Nicola De

Cao, Wilker Aziz, and

Ivan Titov. “Editing Factual

Knowledge in Lan￾guage Models”.

In: EMNLP. 2021.

[3]

Siyuan Cheng et al.

“Can We Edit Multimodal

Large Language Models?” In:

EMNLP. 2023.

[4] Damai

Dai et al. “Knowledge

Neurons in Pretrained Transformers”.

In: ACL. 2022.

[5]

Damai Dai et al.

“Neural Knowledge Bank for

Pretrained Transformers”. In:

NLPCC.

2023.

[6] Qingxiu Dong

et al. “Calibrating Factual

Knowledge in Pretrained Language

Mod￾els”. In: EMNLP. 2022.

[7] Nelson Elhage et

al. “A mathematical framework

for transformer circuits”. In:

Transformer Circuits Thread 1.1

(2021), p. 12.

[8]

Mor Geva et al.

“Transformer Feed-Forward Layers Are

Key-Value Memories”. In:

EMNLP.

2021.

[9] Mor Geva

et al. “Transformer feed-forward

layers build predictions by

promoting

concepts in the

vocabulary space”. In: arXiv

preprint arXiv:2203.14680 (2022).

[10]

Tom Hartvigsen et al.

“Aging with GRACE: Lifelong

Model Editing with Discrete

Key-Value Adaptors”. In: NeurIPS.

2023.

[11] Evan Hernandez,

Belinda Z. Li, and

Jacob Andreas. “Measuring and

Manip￾ulating Knowledge Representations in

Language Models”. In: arXiv

preprint

arXiv:2304.00740 (2023).

[12]

Timothy Hospedales et al.

“Meta-learning in neural networks:

A survey”. In: IEEE

transactions on pattern analysis

and machine intelligence 44.9

(2021), pp. 5149–

5169.

[13] Zeyu Huang et

al. “Transformer-Patcher: One Mistake

Worth One Neuron”. In:

ICLR. 2023.

[14] Omer

Levy et al. “Zero-Shot

Relation Extraction via Reading

Comprehension”. In:

CoNLL. 2017.

226

宓禹 樊怡

江 毛玉仁

[15] Tomasz Limisiewicz, David

Mareček, and Tomáš Musil.

“Debiasing algorithm

through model

adaptation”. In: arXiv preprint

arXiv:2310.18913 (2023).

[16] Vittorio

Mazzia et al. “A

Survey on Knowledge Editing

of Neural Networks”. In:

arXiv preprint arXiv:2310.19704 (2023).

[17] Kevin Meng et

al. “Locating and Editing

Factual Associations in GPT”.

In:

NeurIPS. 2022.

[18]

Kevin Meng et al.

“Mass-Editing Memory in a

Transformer”. In: ICLR. 2023.

[19] Eric Mitchell et

al. “Fast Model Editing

at Scale”. In: ICLR.

2022.

[20] Eric Mitchell

et al. “Memory-Based Model

Editing at Scale”. In:

ICML. 2022.

[21] Shikhar

Murty et al. “Fixing

Model Bugs with Natural

Language Patches”. In:

EMNLP.

2022.

[22] Milad Nasr

et al. “Scalable extraction

of training data from

(production) language

models”. In:

arXiv preprint arXiv:2311.17035 (2023).

[23] Yasumasa Onoe et

al. “Can LMs Learn

New Entities from Descriptions?

Challenges

in Propagating Injected

Knowledge”. In: ACL. 2023.

[24] Anton Sinitsin et

al. “Editable Neural Networks”.

In: ICLR. 2020.

[25]

Song Wang et al.

“Knowledge Editing for Large

Language Models: A Survey”.

In:

arXiv preprint arXiv:2310.16218

(2023).

[26] Xinwei Wu

et al. “Depn: Detecting

and editing privacy neurons

in pretrained lan￾guage models”.

In: arXiv preprint arXiv:2310.20138

(2023).

[27] Yunzhi Yao

et al. “Editing Large

Language Models: Problems, Methods,

and Op￾portunities”. In: EMNLP.

2023.

[28] Ningyu Zhang

et al. “A Comprehensive

Study of Knowledge Editing

for Large Lan￾guage Models”.

In: arXiv preprint arXiv:2401.01286

(2024).

[29] Sumu Zhao

et al. “Of non-linearity

and commutativity in bert”.

In: 2021 Interna￾tional Joint

Conference on Neural Networks

(IJCNN). IEEE. 2021, pp.

1–8.

[30] Zexuan Zhong

et al. “MQuAKE: Assessing

Knowledge Editing in Language

Mod￾els via Multi-Hop Questions”.

In: EMNLP. 2023.

227

6 检

索增强生成

在海量训练

数据和模型

参数的双重

作用下，大语

言模型展示

出了令人惊

艳的

生成能

力。然而，由于

训练数据的

正确性、时效

性和完备性

可能存在不

足，其难以

完

全覆盖用户

的需求；并且

，根据“没有免

费午餐”[55]

定理

，由于参数空

间有限，

大语

言模型对训

练数据的学

习也难以达

到完美。上述

训练数据和

参数学习上

的不

足将导

致：大语言模

型在面对某

些问题时无

法给出正确

答案，甚至出

现“幻觉”，

即生

成看似合理

实则逻辑混

乱或违背事

实的回答。为

了解决这些

问题并进一

步提

升大语

言模型的生

成质量，我们

可以将相关

信息存储在

外部数据库

中，供大语言

模

型进行检

索和调用。这

种从外部数

据库中检索

出相关信息

来辅助改善

大语言模型

生成质量的

系统被称之

为检索增强

生成（Retrieval-Augmented Generation，RAG）。

本章将

介绍

RAG 系统的

相关背景、定

义以及基本

组成，详细介

绍 RAG 系统的常

见架构，讨论

RAG

系统中知识

检索与生成

增强部分的

技术细节，并

介绍 RAG 系

统的

应用与前景

。

* 本书持续更

新，GIT Hub 链接为：https://github.com/ZJU-LLMs/Foundations-of-LLMs。

第

6 章 检索增强

生成

6.1

检索增

强生成简介

检索增强生

成（RAG）旨在通过

检索和整合

外部知识来

增强大语言

模型生成

文

本的准确性

和丰富性，其

是一个集成

了外部知识

库、信息检索

器、大语言模

型等

多个功

能模块的系

统。RAG 利用信息

检索、深度学

习等多种技

术为大语言

模型在

生成

过程中引入

最新的、特定

领域的知识

，从而克服传

统大语言模

型的局限性

，提

供更加精

准和可靠的

生成内容。本

节我们将主

要介绍 RAG 系统

的相关背景

、定义

以及基

本组成。

6.1.1 检索

增强生成的

背景

大语言

模型在多种

生成任务上

展现出了令

人惊艳的能

力，其可以辅

助我们撰

写

文案、翻译文

章、编写代码

等。但是，大模

型生成的内

容可能存在

“幻觉”现象

——生

成内容看似

合理但实际

上逻辑混乱

或与事实相

悖。这导致大

语言模型生

成

内容的可

靠性下降。“幻

觉”现象可能

源于大语言

模型所采用

的训练数据

，也可能

源于

模型本身。

1. 训

练数据导致

的幻觉

训练

数据是大语

言模型知识

的根本来源

。训练数据在

采集完成后

直接用于训

练模型。但是

其中包含的

知识可能在

模型训练后

又发生了更

新。这将导致

知识过

时的

问题。不仅如

此，知识在训

练数据采集

完成后仍会

新增，并且训

练数据采集

也

无法覆盖

世间所有知

识，尤其是垂

域知识，这将

导致知识边

界的问题。此

外，训练

数据

中还可能包

含不实与偏

见信息，从而

导致知识偏

差问题。

对于

知识过时问

题，由于训练

数据涵盖的

知识止步于

大语言模型

训练的时间

截面，其掌握

的知识无法

与现实世界

同步更新。此

处，以 ChatGPT

为例1，对

于问

1本章撰

写时，所使用

的 ChatGPT 版本的训

练数据截止

到

2022 年。

230

董雪梅

徐文溢

毛玉

仁

2023年的考拉

数量大约有

多少?

根据最

新的统计数

据，2023年的考拉

数量大约在

5,00D到8,000只之间，这

个数字可能

会因为各

种

因素而有所

波动，但我们

希望这些可

爱的动物能

够得到适当

的保护和管

理，以确保它

们的数量能

够持续稳定

。

图 6.1: 知识过时

引起的幻觉

现象示例。

树

袋熊和考拉

是什么关系

?

树袋熊和考

拉是近亲，它

们都属于有

袋类动物目

下的不同科

，树袋熊属于

袋熊科(Vombatidae)而

考

拉则属于袋

熊科下的树

袋熊属(Phascolarctos)，因此

它们之间有

亲缘关系，但

是并不是同

种动

物。树袋

熊主要分布

在澳大利亚

，而考拉则是

澳大利亚特

有的一种树

栖动物。

图

6.2: 模

型自身导致

的幻觉示例

。

题“2023 年的考拉

数量大约有

多少?”，模型的

回答为

5,000 到 8,000 只

之间，如

图 6.1所

示。然而，正确

数量应约为

86,000 到 176,000

只。由于 ChatGPT 的

完成训

练的

时间节点是

2022

年，导致它无

法掌握 2023 年的

知识，给出了

错误的回答

。

虽然大语言

模型的训练

数据非常庞

大，但仍然是

有限的。因此

，模型内部的

知

识必然存

在知识边界

，即缺乏某些

特定领域的

知识。例如，当

我们想知道

考拉的

基因

数量时，模型

可能无法提

供正确的信

息，因为预训

练数据中并

不包含相关

信

息。此外，由

于大语言模

型的语料很

多是从互联

网直接爬取

而未核验的

，其中可能

会

存在含偏向

某些特定观

点或存在事

实性偏差的

低质量数据

，从而带来知

识偏差，

导致

模型输出存

在不良偏差

。

2. 模型自身导

致的幻觉

除

了训练数据

的影响，我们

还发现在某

些场景下，即

使训练数据

中已经包含

了

相关知识

，大语言模型

仍然会出现

幻觉现象。如

图 6.2中的例子

所示，我们同

样使

用 ChatGPT

进行

测试，可以看

到模型并没

有意识到考

拉是树袋熊

的音译别名

，而

错误的把

这两个名称

认为是两种

不同的动物

，偏离了事实

。为了进一步

探究大语

231

第

6

章 检索增强

生成

考拉的

别名是什么

?

考拉的别名

是树袋熊

树

袋熊和考拉

是什么关系

?

树袋熊和考

拉是同一种

动物，它们是

澳大利亚特

有的有袋类

动物，属于袋

熊科。通常情

况下，人们

常

常用“考拉”一

词来指代这

种动物，而“树

袋熊”则更参

用于科学或

正式的称呼

。它们以吃树

叶

为主食，生

活在树上，有

着独特的外

貌和生活习

性。

图 6.3: 内部泛

化能力不足

的进一步示

例。

言模型是

否真的不具

备相关知识

。我们进行了

进一步实验

，结果如图

6.3所

示，此

时大语

言模型给出

了正确回答

。上述示例表

明，大语言模

型实际上包

含了问题的

正确知识，但

依然出现了

偏差的回答

。

上述偏差可

能来自于模

型自身，可能

的因素包括

：（1）知识长尾：训

练数据中

部

分信息的出

现频率较低

，导致模型对

这些知识的

学习程度较

差；（2）曝光偏差

：

由于模型训

练与推理任

务存在差异

，导致模型在

实际推理时

存在偏差；（3）对

齐不

当：在模

型与人类偏

好对齐阶段

中，偏好数据

标注不当可

能引入了不

良偏好；（4）

解码

偏差：模型解

码策略中的

随机因素可

能影响输出

的准确性。

上

述幻觉问题

极大地影响

了大语言模

型的生成质

量。这些问题

的成因主要

是

大语言模

型缺乏相应

的知识或生

成过程出现

了偏差，导致

其无法正确

回答。借鉴

人

类的解决方

式，当我们遇

到无法回答

的问题时，通

常会借助搜

索引擎或查

阅书

籍资料

来获取相关

信息，进而帮

助我们得出

正确答案。自

然地，对于大

语言模型不

熟悉的知识

，我们是否也

可以查找相

关的信息，从

而帮助它得

到更准确的

回答呢？

为了

验证这一设

想，我们可以

进行一个简

单的实验，同

样是上面的

两个例子，我

们

简单地以

Prompt 的形式加入

相关的外部

知识，如图 6.5、图

6.7所示，模型很

自然

232

董雪梅

徐文溢 毛玉

仁

图 6.4:

关于 2023 树

袋熊数量的

网络资料截

图。

2023年，调整后

的考拉种群

估计数（考虑

到数据很少

或没有数据

的地区）得出

的考拉种群

估计数在

86,000至

176,000之间。

2023年的考

拉数量大约

有多少?

2023年的

考拉数量在

86.000至176.000之间。

图

6.5: 添

加外部信息

纠正知识过

时引起的幻

觉示例。

图 6.6:

关

于树袋熊名

称的维基百

科截图。

地得

出了正确的

回答，其中图

6.42、图 6.63为对应的

知识来源。这

种思路便是

检索

增强生

成（Retrieval-Augmented

Generation，RAG) 的核心思

想。接下来，我

们对

RAG 系统进

行简要介绍

。

2https://www.dcceew.gov.au/environment/biodiversity/threatened/species/koalas/

national-koala-monitoring-program

3https://zh.wikipedia.org/wiki/￾￾￾

233

第 6 章 检索增

强生成

树袋

熊（学名：Phascolarctos cinereus，香港

作树熊，新加

坡，台湾作无

尾熊，音译考

拉（英

语:koala）），是澳

大利亚的特

有种有袋类

动物，全世界

仅分布在澳

大利亚的东

部昆士兰州

，新南

威尔士

。南澳大利亚

州和维会利

亚地区低海

拔，不密集的

桉树林中。

树

袋熊和考拉

之间有什么

联系?

树袋熊

和考拉是同

一种动物，学

名为Phascolarctos cinereus，它们在

不同地区有

不同的称呼

，

如你提到的

树袋熊、树熊

、无尾熊、考拉

等。这些称呼

都指的是同

一种动物，是

澳大利亚特

有的有

袋类

动物，主要生

活在桉树林

中。因为考拉

经常在树上

生活并以桉

树的叶子为

食，所以被称

为树袋

熊或

考拉。

图 6.7:

添加

外部信息纠

正模型自身

引起的幻觉

示例。

6.1.2 检索增

强生成的组

成

RAG

的概念最

早出现在 Facebook AI Research

的

论文 Retrieval-Augmented Gen￾eration for

Knowledge-Intensive NLP Tasks [28]

中。其通

常集成了外

部知识库（Corpus

）、信

息检索器（Retriever）、生

成器（Generator，即大语

言模型）等多

个功能模

块

。通过结合外

部知识库和

大语言模型

的优势，大幅

提升模型在

开放域问答

、多轮

对话等

任务中的生

成质量，其基

本架构如图

6.8所示。具体而

言，给定一个

自然语

言问

题（Query），检索器将

问题进行编

码，并从知识

库（如维基百

科）中高效检

索

出与问题

相关的文档

。然后，将检索

到的知识和

原始问题一

并传递给大

语言模型，

大

语言模型根

据检索到的

知识和原始

问题生成最

终的输出。RAG 的

核心优势在

于

不需要对

大语言模型

的内部知识

进行更新，便

可改善大语

言模型的幻

觉现象，提

高

生成质量。这

可以有效避

免内部知识

更新带来的

计算成本和

对旧知识的

灾难性

遗忘

（Catastrophic Forgetting）。

接下来，我们

通过图 6.8中的

例子来描述

RAG 的基本工作

流程。用户输

入一

个问题

“2023

年的考拉数

量有多少？”，首

先，该问题会

传递给 RAG 框架

的检索器

模

块，检索器从

知识库中检

索相关的知

识文档，其中

包含了与

2023 年

的考拉数量

相关的信息

；接下来，这些

信息通过 Prompt 的

形式传递给

大语言模型

（大语言模

型

利用外部知

识的形式是

多样的，通过

Prompt 进行上下文

学习是其中

最常用的形

234

董雪梅 徐文

溢

毛玉仁

查

询

用户

相关

文档

生成器

（语言模型）

检

索器

知识库

文档1：2023 年，调整

后的考拉种

群估计数得

出的考拉种

群估计数在

86,000

至 176,000

只之间。

文

档2：这项研究

发表于2016年1月

，当时研究

人

员估计全澳

大利亚考拉

的总数为32.9万

只。

文档3：考拉

调查方法指

南已经制定

，并与主要

专

家进行了测

试，并根据该

计划发布。

不

使用

RAG

使用 RAG

根

据最新的统

计数据，

2023年的

考拉数量大

约在

5,000到8,000只之

间

……

2023

年的考拉

数量在

86,000 至 176,000

只

之

间。

2023年的考

拉数量

大约

有多少？

图 6.8: RAG 基

本架构示意

图。

式），最终得

出了正确的

答案：“2023 年的考

拉数量在 86,000 至

176,000

只之间。”

然而

，同样的问题

，如果让大语

言模型在不

使用 RAG 的情况

下直接回答

，则无法

得到

正确的答案

，这说明了 RAG 系

统的有效性

。

仅仅简单地

对外部知识

库、检索器、大

语言模型等

功能模块进

行连接，无法

最

大化 RAG 的效

用。本章将围

绕以下三个

问题，探讨如

何优化设计

RAG 系统。

如何优

化检索器与

大语言模型

的协作？根据

是否对大语

言模型进行

微调，我

们将

现有的 RAG 系统

分为

（1）黑盒增

强架构，不访

问模型的内

部参数，仅

利

用输出反馈

进行优化；（2）白

盒增强架构

，允许对大语

言模型进行

微调。

详细内

容将在 6.2

节介

绍。

如何优化

检索过程？讨

论如何提高

检索的质量

与效率，主要

包括：（1）知识

库

构建，构建全

面高质量的

知识库并进

行增强与优

化；（2）查询增强

，改进

原始查

询，使其更精

确和易于匹

配知识库信

息；（3）检索器，介

绍常见的检

索器结构和

搜索算法；（4）检

索效率增强

，介绍用于提

升检索效率

的常用相

似

度索引算法

；（5）重排优化，通

过文档重排

筛选出更有

效的信息。详

细内

容将在

6.3 节介绍。

如何

优化增强过

程？讨论如何

高效利用检

索信息，主要

包括：（1）何时增

强，

235

第 6 章

检索

增强生成

确

定何时需要

检索增强，以

提升效率并

避免干扰信

息；（2）何处增强

，讨论

生成过

程中插入检

索信息的常

见位置；（3）多次

增强，针对复

杂与模糊查

询，

讨论常见

的多次增强

方式；（4）降本增

效，介绍现有

的知识压缩

和缓存加速

策略。详细内

容将在

6.4 节介

绍。

本节初步

介绍了我们

为什么需要

RAG 和

RAG 是什么这

两个问题。接

下来的

章节

将针对上面

提出的三个

问题，对具体

技术细节详

细讨论。

6.2

检索

增强生成架

构

检索增强

生成（RAG）系统是

一个集成了

外部知识库

、检索器、生成

器等多个

功

能模块的软

件系统。针对

不同的业务

场景和需求

，可以设计不

同的系统架

构来

组合、协

调这些模块

，以优化

RAG 的性

能。其中，检索

器和生成器

的协作方式

对

RAG 性能的影

响最为显著

。这是因为在

不同的协作

方式下，检索

器检索到的

信息

质量会

有所不同，生

成器生成的

内容质量也

会随之变化

。此外，检索器

和生成器之

间的协作方

式对系统的

效率有很大

影响。高效的

协作能够减

少延迟，提高

系统的

响应

速度。本节将

从如何优化

检索器与大

语言模型的

协作这一角

度出发，对经

典

RAG 架构进行

梳理和介绍

。

6.2.1 RAG 架构分类

针

对不同的业

务场景，RAG

中的

生成器可以

选用不同的

大语言模型

，如 GPT-

4[1]、LLaMA[49] 等。考虑到

大语言模型

的开源/闭源

、微调成本等

问题，RAG

中

的大

语言模型可

以是参数不

可感知/调节

的“黑盒”模型

，也可以是参

数可感知和

微调的“白盒

”模型。例如，如

果选用 GPT-4，由于

其闭源性，在

RAG 过程中只能

将其视为“黑

盒”，只能利用

其输出结果

，而无法感知

/微调其模型

参数。如果选

择

236

董雪梅 徐

文溢 毛玉仁

问

题

检索器

输出

问 题

输

出

检索器

生

成器

(黑盒模

型)

无微调

(a)黑

盒增强架构

检索器微调

生成器

(黑盒

模型)

用户

知

识库

用户

知

识库

相关文

档

相关文档

问

题 生成器

检索器

输出

（b）白盒增强架

构

问

题 生成

器

输出

检索

器

仅微调大

语言模型

用

户

知识库 相

关文档

用户

知识库 相关

文档

协同微

调

图

6.9: 检索增

强架构分类

图。其中含蓝

色雪花的模

块表示其参

数被冻结、带

红色

火焰的

部分表示微

调时其参数

被更新。

LLaMA

模型

，在计算资源

允许的情况

下，在 RAG 过程中

可将其视为

“白盒”并对

其

进行微调。从

是否对大语

言模型进行

微调的角度

出发，本小节

将

RAG 架构分类

两大类：黑盒

增强架构和

白盒增强架

构，如图6.9所示

。

其中，黑盒增

强架构可根

据是否对检

索器进行微

调分为两类

：无微调、检索

器微调，如图

6.9(a) 所示。在无微

调架构中，检

索器和大语

言模型都不

进行任何微

调，仅依靠它

们在预训练

阶段掌握的

能力完成相

应的检索和

生成任务。在

检索器

微调

的架构中，语

言模型参数

保持不变，而

检索器根据

语言模型的

输出反馈进

行

参数的针

对性调整。类

似的，白盒增

强架构也可

根据是否对

检索器进行

微调分为

两

类：仅微调大

语言模型、检

索器与大语

言模型协同

微调（下文简

称为协同微

调），

如图6.9(b)

所示

。在仅微调大

语言模型的

架构中，检索

器作为一个

预先训练好

的组

件其参

数保持不变

；语言模型则

根据检索器

提供的相关

信息进行参

数调整。在协

同微调的架

构中，检索器

和大语言模

型迭代交互

、协同微调。

237

第

6

章 检索增强

生成

在 RAG

系统

中，除了调整

检索器和大

语言模型，我

们也可对其

他功能模块

（如

知识库中

的向量 [17, 45]）进行

调整。调整其

他功能模块

与黑盒增强

和白盒增强

的

分类是兼

容的。本节接

下来的部分

将详细介绍

黑盒增强架

构和白盒增

强架构，并

探

讨它们代表

性方法。

6.2.2 黑盒

增强架构

在

某些情况下

，由于无法获

取大语言模

型的结构和

参数或者没

有足够的算

力

对模型进

行微调，例如

只能通过 API 进

行交互时，我

们不得不将

语言模型视

为一

个黑盒

。此时，RAG 需要在

黑盒增强架

构的基础上

构建。在黑盒

增强架构中

，我

们仅可对

检索器进行

策略调整与

优化。其可以

分为无微调

架构和检索

器微调两种

架构。接下来

对两种架构

类型分别展

开介绍。

1.

无微

调

无微调架

构是所有 RAG 架

构中形式最

简单的。该架

构中，检索器

和语言模

型

经过分别独

立的预训练

后参数不再

更新，直接组

合使用。这种

架构对计算

资源

需求较

低，方便实现

且易于部署

，适合于对部

署速度和灵

活性有较高

要求的场景

。

In-Context RALM[42]

是该框架下

的代表性方

法。其直接将

检索器检索

到的文档前

置到输入问

题前作为上

下文，方法示

意图如图6.10所

示。In-Context RALM 包括检

索

和生成两个

阶段。在检索

阶段，输入的

问题或部分

句子作为查

询从知识库

中检

索出相

关文档。在生

成阶段，这些

检索到的文

档被直接拼

接到 Prompt 中的上

下文

部分，然

后将

Prompt 输入给

大语言模型

。一个 RAG 任务可

能涉及多次

执行检索和

生成。例如，在

一个长文本

生成任务中

，每生成一定

量的文本后

，模型就可能

会执

行一次

检索，以确保

随着话题的

发展，后续生

成的内容能

够持续保持

与话题相关

。

在执行检索

操作时，需要

仔细选择几

个关键参数

，如检索步长

和检索查询

长

度。检索步

长是指模型

在生成文本

时，每隔多少

个词进行一

次检索，这一

参数的设

238

董

雪梅 徐文溢

毛玉仁

86000到

176000之

间

检索器

问

题

文档1：2023年考

拉种群的调

整估计数

量

在86,000至176,000之间......

文

档2：澳大利亚

有超过400,000只野

生考拉......

文档

3：考拉范围在

33,000至60,000

之间 ......

2023年的

考

拉数量大

约有

多少？

语

言模型

知识

库

Prompt构建

2023年的

考拉数量大

约有多少？

答

案

图 6.10: In-Context RALM

模型架

构图。

定直接

影响到模型

的响应速度

和信息的即

时性。较短的

检索步长能

够提供更为

及

时的信息

更新，但同时

也可能增加

计算的复杂

性和资源消

耗。因此，在实

际应用

中，需

要在这两者

之间找到一

个合理的平

衡点。检索查

询长度指的

是用于检索

的

文本片段

的长度，通常

被设置为语

言模型输入

中的最后几

个词，以确保

检索到的

信

息与当前的

文本生成任

务高度相关

。

2. 检索器微调

虽然无微调

架构在实现

和部署上非

常便捷，但它

完全没有考

虑检索器与

语言

模型之

间潜在的协

同效应，效果

有待提升。为

了进一步提

升效果，可以

采用检索器

微调架构对

检索器进行

微调，以更好

地适用于黑

盒增强的环

境。在检索器

微调架

构中

，大语言模型

的参数保持

不变，仅用其

输出指导检

索器的微调

。这种架构下

的

检索器能

更好地适应

大语言模型

的需求，从而

提高 RAG

的表现

。

REPLUG LSR[45] 是检索器微

调框架的代

表性方法，其

结构如图6.11所

示。它

使用大

语言模型的

困惑度分数

作为监督信

号来微调检

索器，使其能

更有效地检

索

出能够显

著降低语言

模型困惑度

的文档。其微

调检索器的

过程中采用

KL 散度损失

函

数来训练检

索器，目的是

对齐检索到

的文档的相

关性分布与

这些文档对

语言模

型性

能提升的贡

献分布。此过

程涉及两个

关键的概率

分布，第一个

是检索器输

出

的文档分

布：检索器在

接收到当前

上下文后检

索与之相关

的文档，并形

成一个文

239

第

6

章 检索增强

生成

检索器

知识库

问题

检索器输出

的文档分布

文档对语言

模型的贡献

d1

d2

...  dn

最小化

KL散度

相关文档

...

d1



d2

...

dn

Prompt 构

建

用户

P1 P2 Pn

输出

语言模型

（黑

盒）

d1

d2

...  dn

图

6.11: REPLUG LSR 模型架

构图。

档概率

分布。这一分

布是基于检

索器计算的

上下文与文

档之间的相

似度，通过余

弦相似度来

衡量，并将这

些相似度分

数转化为概

率值。第二个

是文档对语

言模型

的贡

献分布：语言

模型为每个

被检索到的

文档和原始

上下文来生

成预测，最终

所

有输出结

果形成一个

概率分布。在

这个分布中

，如果某个文

档对语言模

型生成准

确

预测特别关

键，它会被赋

予更高的概

率权重。在微

调过程中，REPLUG

LSR 将

语言模型视

为黑盒处理

，仅通过模型

的输出来指

导检索器的

训练，避免了

对语言

模型

内部结构的

访问和修改

。此外，在微调

过程中，REPLUG LSR

还采

用了一种

异

步索引更新

策略，即不会

在每次训练

步骤后立即

更新知识库

的向量编码

，而是

在一定

的训练步骤

之后才进行

更新。这种策

略降低了索

引更新的频

率，减少了计

算成本，使模

型能够在连

续训练过程

中更好地适

应新数据。此

外，检索器微

调框架

中给

还可以引入

代理模型来

指引检索器

微调。例如，AAR[60]

方

法通入引入

额外

的小型

语言模型，使

用它的交叉

注意力得分

标注偏好文

档，以此来微

调检索器，使

其能够在不

微调目标语

言模型的情

况下增强其

在不同任务

上的表现。

检

索器微调的

方式允许即

使是闭源大

模型如 ChatGPT，也能

通过优化外

部检

索器来

提升性能。REPLUG LSR 和

AAR 通过该方式

实现了在保

持大模型完

整性的

同时

，通过外部调

整来增强模

型的能力，这

在传统的 RAG 中

是不常见的

。

240

董雪梅 徐文

溢 毛玉仁

6.2.3

白

盒增强架构

通常，大语言

模型和检索

器是独立预

训练的，二者

可能存在匹

配欠佳的情

况。

白盒增强

架构通过微

调大语言模

型来配合检

索器，以提升

RAG 的效果。其可

根据

是否对

检索器进行

微调分为两

类：仅语言模

型微调、检索

器和语言模

型协同微调

。

1. 仅微调语言

模型

仅微调

语言模型指

的是检索器

作为一个预

先训练好的

组件其参数

保持不变，

大

语言模型根

据检索器提

供的上下文

信息，对自身

参数进行微

调。RETRO[5]

是仅

微调

语言模型的

代表性方法

之一。该方法

通过修改语

言模型的结

构，使其在微

调

过程中能

够将从知识

库中检索到

的文本直接

融入到语言

模型中间状

态中，从而实

现外部知识

对大语言模

型的增强。此

外，SELF-RAG[3] 通过在微

调语言模型

时引

入反思

标记，使语言

模型在生成

过程中动态

决定是否需

要检索外部

文本，并对生

成结果进行

自我批判和

优化。这些方

法不仅提高

了生成内容

的质量和事

实准确性，

还

增强了模型

的知识整合

与应用能力

。

以 RETRO

为例，其结

构如图6.12所示

。RETRO 首先将知识

库中的文本

进行切

块，然

后用 BERT

对每个

文本块生成

嵌入向量。在

微调模型时

的自回归过

程中，每

当模

型生成一段

文本块后，就

去知识库中

检索出与之

最相似的嵌

入向量。然后

，这

些嵌入向

量和模型注

意力层的输

出一起被送

入一个外部

的 Transformer

编码器进

行

编码。得到

的编码向量

直接输入给

模型的块交

叉编码器的

键（key）和值（value），

以捕

捉外部知识

的关键信息

。通过交叉编

码，模型能够

结合检索到

的相关信息

来

生成新的

文本块。

通过

上述方式微

调后的 RETRO 模型

能够充分整

合检索到的

信息，生成连

贯且

富含信

息的文本。面

对用户查询

时，模型能展

现出优秀的

理解能力和

知识整合能

力，大幅提升

了生成的质

量和准确性

，尤其在处理

复杂任务时

，其表现更为

突出。

241

第 6 章

检

索增强生成

输

出

文

本

块

检索器

分块

交叉

注意

力

层

嵌

入

层

嵌

入

层

RETRO 模块 ×N

前

馈

层

语言模

型

Transformer

编码器

......

+

知

识库

文本嵌

入

......

编码后嵌

入

注

意

力

层

图 6.12:

RETRO 模型架构

图。

2. 检索器和

语言模型协

同微调

在仅

微调语言模

型的架构下

，检索器作为

固定组件，微

调过程中其

参数保持

不

变。这导致检

索器无法根

据语言模型

的需求进行

适应性调整

，从而限制了

检索

器与语

言模型之间

的相互协同

。在检索器和

语言模型协

同微调的架

构中，检索器

和语言模型

的参数更新

同步进行。这

种微调的方

式使得检索

器能够在检

索的同时

学

习如何更有

效地支持语

言模型的需

求，而语言模

型则可以更

好地适应并

利用检

索到

的信息，以进

一步提升 RAG 的

性能。

Atlas[17]

是该架

构的代表性

工作，其架构

如图6.13所示。与

REPLUG LSR 类

似，其在预

训练和微调

阶段使用

KL 散

度损失函数

来联合训练

检索器和语

言模型，

以确

保检索器输

出的文档相

关性分布与

文档对语言

模型的贡献

分布相一致

。不同

之处在

于，Atlas

在预训练

和微调过程

中，检索器和

语言模型参

数同步被更

新，检

索器学

习向语言模

型提供最相

关的文档，而

语言模型则

学习如何利

用这些文档

来

改善其对

查询的响应

。为了确保检

索结果与模

型最新状态

保持同步，Atlas 同

样需

要定期

更新语料库

文档的向量

编码，从而维

持检索的准

确性。

242

董雪梅

徐文溢 毛玉

仁

检索器

知

识库

问题

检

索器输出的

文档分布

文

档对语言模

型的贡献

d1

d2

  ...

dn

最

小化

KL散度 相

关文档

...

d1



d2

...

dn

Prompt 构建

用户

P1 P2 Pn

d1

d2

...  dn

编

码

器

解

码

器

语言

模型（T5）

隐层表

示

输出

图

6.13: Atlas 模

型架构图。

6.2.4

对

比与分析

本

节主要介绍

了 RAG 的黑盒增

强架构和白

盒增强架构

及其经典方

法。接下来，

我

们对这两种

架构进行总

结和对比。

黑

盒增强架构

是在闭源模

型的背景下

提出的，它限

制了对模型

内部参数的

直

接调整。在

这种架构下

，我们介绍了

无微调和检

索器微调两

种策略。无微

调简单实

用

，它直接利用

预训练的语

言模型和检

索器，不进行

任何更新，适

合快速部署

。然

而，这种方

法的缺点在

于无法对语

言模型进行

优化以适应

新的任务需

求。相比之

下

，检索器微调

通过调整检

索器来适应

语言模型输

出，提供了在

无法修改语

言模

型的情

况下提升性

能的可能性

。这种方法的

效果在很大

程度上取决

于调整后的

检

索器的准

确性。

白盒增

强架构则利

用开源模型

的优势，允许

调整语言模

型结构和参

数，可以

更好

的协调减速

器和大语言

模型。在这种

架构中，我们

介绍了两种

微调形式：仅

微

调语言模

型和检索器

和语言模型

协同微调。仅

微调语言模

型专注于优

化语言模型

，

根据检索到

的信息仅调

整语言模型

结构和参数

，以提升特定

任务上的性

能。检索

器和

语言模型协

同微调是一

种更为动态

的策略，它通

过同步更新

检索器和语

言模

243

...

第

6 章 检

索增强生成

型，使得两者

能够在训练

过程中相互

适应，从而提

高整体系统

的性能。尽管

白盒增

强架

构可以有效

改善

RAG 的性能

，但也存在明

显缺点。这种

架构通常需

要大量计

算

资源和时间

来训练，特别

是协同微调

策略，需要大

量的运算资

源来实现语

言模

型和检

索器的同步

更新。

6.3 知识检

索

在 RAG

中，检索

的效果（召回

率、精度、多样

性等）会直接

影响大语言

模型

的生成

质量。以“树袋

熊一般在哪

里生活？”这个

问题为例。如

果检索器返

回的外

部知

识是关于“树

袋熊”名称相

近的动物“袋

熊”的相关知

识，那么这些

不正确的

外

部知识可能

引导大语言

模型生成错

误答案。此外

，检索的时间

也是

RAG 总耗时

的关键部分

，因此检索的

效率将影响

用户的使用

体验。优化检

索过程，提升

检索的

效果

和效率，对改

善 RAG

的性能具

有重要意义

。针对优化检

索过程，本节

系统的

对知

识库构建、查

询增强、检索

器、检索结果

重排序等关

键技术进行

梳理和介绍

。

6.3.1 知识库构建

知识库构成

了

RAG 系统的根

基。正如古语

所言：“巧妇难

为无米之炊

”，只有

构建了

全面、优质、高

效的知识库

，检索才能有

的放矢，检索

效果才能有

保障。在

RAG

框架

中，知识库构

建主要涉及

数据采集及

预处理与知

识库增强两

个步骤。本

小

节将对这两

个步骤分别

展开介绍。

1. 数

据采集及预

处理

数据采

集与预处理

为构建知识

库提供“原材

料”。在构建文

本型知识库

的数据

采集

过程中，来自

不同渠道的

数据被整合

、转换为统一

的文档对象

。这些文档对

象

不仅包含

原始的文本

信息，还携带

有关文档的

元信息（Metadata）。元信

息可以用

244

董

雪梅 徐文溢

毛玉仁

数据

采集和预

处

理

数据增强

检索器

检索

结果重排 最

终结果

用户

查询

查询增

强

检索效率

增强

知识库

构建

查询构

建

文本检索

图 6.14: 知识检索

流程图。

于后

续的检索和

过滤。以维基

百科语料库

的构建为例

，数据采集主

要通过提取

维

基百科网

站页面内容

来实现。这些

内容不仅包

括正文描述

的内容，还包

括一系列

的

元信息，例如

文章标题，分

类信息，时间

信息，关键词

等。

在采集到

相应的数据

后，还需通过

数据预处理

来提升数据

质量和可用

性。在构

建文

本型知识库

时，数据预处

理主要包括

数据清洗和

文本分块两

个过程。数据

清

洗旨在清

除文本中的

干扰元素，如

特殊字符、异

常编码和无

用的 HTML 标签，以

及删除重复

或高度相似

的冗余文档

，从而提高数

据的清晰度

和可用性。文

本分块

是将

长文本分割

成较小文本

块的过程，例

如把一篇长

文章分为多

个短段落。对

长

文本进行

分块有两个

好处：一是为

了适应检索

模型的上下

文窗口长度

限制，避免

超

出其处理能

力；二是通过

分块可以减

少长文本中

的不相关内

容，降低噪音

，从而

提高检

索的效率和

准确性。

文本

分块的效果

直接影响后

续检索结果

的质量

[14]。如果

分块处理不

当，可能

会破

坏内容的连

贯性。因此，制

定合适的分

块策略至关

重要，包括确

定切分方法

（如按句子或

段落切分）、设

定块大小，以

及是否允许

块之间有重

叠。文本分块

的具

体实施

流程通常开

始于将长文

本拆解为较

小的语义单

元，如句子或

段落。随后，这

些单元被逐

步组合成更

大的块，直到

达到预设的

块大小，构建

出独立的文

本片段。

为了

保持语义连

贯性，通常还

会在相邻的

文本片段之

间设置一定

的重叠区域

。

245

第 6 章

检索增

强生成

2. 知识

库增强

知识

库增强是通

过改进和丰

富知识库的

内容和结构

，以提升其质

量和实用性

。

这一过程通

常涉及查询

生成与标题

生成 [56] 等多个

步骤，以此为

文档建立语

义“锚

点”，方便

检索时准确

定位到相应

文本。

查询生

成指的是利

用大语言模

型生成与文

档内容紧密

相关的伪查

询。这些伪

查

询从查询的

角度来表达

文档的语义

，可以作为相

关文档的“键

”，供检索时与

用

户查询进

行匹配。通过

这种方式，可

以增强文档

与用户查询

的匹配度。例

如，对于

一篇

介绍考拉和

树袋熊关系

的文档，生成

的查询“考拉

和树袋熊之

间的关系是

什

么？”不仅准

确反映了文

档的主题，还

能有效引导

检索器更精

确的检索到

与用户提

问

相关的信息

。

标题生成指

的是利用大

语言模型为

没有标题的

文档生成合

适的标题。这

些生

成的标

题提供了文

档的关键词

和上下文信

息，能来用来

帮助快速理

解文档内容

，并

在检索时

更准确地定

位到与用户

提问相关的

信息。对于那

些原始文档

中缺乏标题

的情况，通过

语言模型生

成标题显得

尤为重要。

6.3.2 查

询增强

知识

库涵盖的知

识表达形式

是有限的，但

用户的提问

方式却是千

人千面的。用

户遣词造句

的方式以及

描述问题的

角度可能会

与知识库中

的存储的文

本间存在差

异，这可能导

致用户查询

和知识库之

间不能很好

匹配，从而降

低检索效果

。为了解

决此

问题，我们可

以对用户查

询的语义和

内容进行扩

展，即查询增

强，以更好的

匹

配知识库

中的文本。本

小节将从查

询语义增强

和查询内容

增强两个角

度出发，对

查

询增强技术

进行简要介

绍。

1.

查询语义

增强

查询语

义增强旨在

通过同义改

写和多视角

分解等方法

来扩展、丰富

用户查询

246

董

雪梅

徐文溢

毛玉仁

的语

义，以提高检

索的准确性

和全面性。接

下来分别对

同义改写和

多视角分解

进

行简要介

绍。

(1)

同义改写

同义改写通

过将原始查

询改写成相

同语义下不

同的表达方

式，来解决用

户查

询单一

的表达形式

可能无法全

面覆盖到知

识库中多样

化表达的知

识。改写工作

可

以调用大

语言模型完

成。比如，对于

这样一个原

始查询：“考拉

的饮食习惯

是什

么？”，可以

改写成下面

几种同义表

达：1、“考拉主要

吃什么？”；2、“考拉

的食物有

哪

些？”；3、“考拉的饮

食结构是怎

样的？”。每个改

写后的查询

都可独立用

于检索

相关

文档，随后从

这些不同查

询中检索到

的文档集合

进行合并和

去重处理，从

而

形成一个

更大的相关

文档集合。

(2)

多

视角分解

多

视角分解采

用分而治之

的方法来处

理复杂查询

，将复杂查询

分解为来自

不

同视角的

子查询，以检

索到查询相

关的不同角

度的信息。例

如，对于这样

一个问

题：“考

拉面临哪些

威胁？”，可以从

多个视角分

解为：1、“考拉的

栖息地丧失

对其

有何影

响？”；2、“气候变化

如何影响考

拉的生存？”；3、“人

类活动对考

拉种群有

哪

些威胁？”；4、“自然

灾害对考拉

的影响有哪

些？”等子问题

。每个子问题

能检索

到不

同的相关文

档，这些文档

分别提供来

自不同视角

的信息。通过

综合这些信

息，

语言模型

能够生成一

个更加全面

和深入的最

终答案。

2. 查询

内容增强

查

询内容增强

旨在通过生

成与原始查

询相关的背

景信息和上

下文，从而丰

富

查询内容

，提高检索的

准确性和全

面性

[58]。与传统

的仅依赖于

检索的方式

相比，

查询内

容增强方法

通过引入大

语言模型生

成的辅助文

档，为原始查

询提供更多

维

度的信息

支持。

生成背

景文档是一

种查询内容

增强的方法

。它指的是在

原始查询的

基础上，利

247

第

6 章 检索增强

生成

用大语

言模型生成

与查询内容

相关的背景

文档。例如，对

于用户查询

“如何保护考

拉的栖息地

？”，可以生成以

下背景文档

：

考拉是原产

于澳大利亚

的树栖有袋

类动物，主要

分布在东部

和东南部

沿

海的桉树林

中。这些地区

提供了考拉

主要食物来

源——桉树叶。考

拉

的栖息地

包括开阔的

森林和木兰

地，这里桉树

丰富，不仅提

供食物，还

提

供栖息和保

护。考拉高度

依赖特定种

类的桉树，它

们的分布与

这些树

木的

可用性密切

相关。

这些生

成的背景文

档可以作为

原始查询的

补充信息，提

供更多的上

下文内容，从

而提高检索

结果的相关

性和丰富性

。

6.3.3

检索器

给定

知识库和用

户查询，检索

器旨在找到

知识库中与

用户查询相

关的知识文

本。检索器可

分为判别式

检索器和生

成式检索器

两类。本小节

将对这两类

检索器

分别

展开介绍。

1.

判

别式检索器

判别式检索

器通过判别

模型对查询

和文档是否

相关进行打

分。判别式检

索器

通常分

为两大类：稀

疏检索器和

稠密检索器

。稀疏检索器

利用离散的

、基于词频的

文档编码向

量进行检索

，而稠密检索

器则利用神

经网络生成

的连续的、稠

密向量

对文

档进行检索

。下面将详细

的介绍这两

种检索器以

及代表性方

法。

(1)

稀疏检索

器

稀疏检索

器（Sparse Retriever）是指使用

稀疏表示方

法来匹配文

本的模型。这

类检索器通

过统计文档

中特定词项

出现的统计

特征来对文

档进行编码

，然后基于

此

编码计算查

询与知识库

中的文档的

相似度来进

行检索。典型

的稀疏检索

技术包

248

董雪

梅 徐文溢 毛

玉仁

括 TF-IDF[2] 和 BM25[43]

等

，它们通过分

析词项的分

布和频率来

评估文档与

查询

的相关

性。TF-IDF 基于词频

（TF）和逆文档频

率（IDF）来衡量词

语在文档或

语料

库中的

重要性，然后

用此重要性

对文本进行

编码。词频（TF）表

示词语在文

档中

的出现

频率，计算公

式为：

tfi,j =

ni,j

P

k nk,j

，

(6.1)

其中，ni,j 是

词语 ti

在文档

dj 中的出现次

数，P k nk,j

是文档 dj 中

所有词语的

出现

次数之

和，用于进行

标准化以避

免偏向长文

档。逆文档频

率（IDF）衡量词语

的普

遍性，计

算公式为：

idfi = log

|D|

|{j : ti

∈ dj}|， (6.2)

其

中，|D|

是总文档

数，|{j : ti ∈

dj}| 是包含词

语 ti 的文档数

。最终，TF-IDF

值为：

tfidfi,j = tfi,j

× idfi。 (6.3)

TF-IDF

通

过高词频和

低文档频率

产生高权重

，倾向于过滤

常见词语，保

留重要词

语

。

BM25 是一种改进

的文本检索

算法，它在

TF-IDF 基

础上通过文

档长度归一

化

和词项饱

和度调整，更

精确地评估

词项重要性

，优化了词频

和逆文档频

率的计算，

并

考虑了文档

长度对评分

的影响。虽然

不涉及词项

上下文，但是

BM25

在处理大

规

模数据时表

现优异，广泛

应用于搜索

引擎和信息

检索系统。

(2) 稠

密检索器

稠

密检索器一

般利用预训

练语言模型

对文本生成

低维、密集的

向量表示，通

过计算向量

间的相似度

进行检索。按

照所使用的

模型结构的

不同，稠密检

索器大

致可

以分为两类

：交叉编码类

（Cross-Encoder）、双编码器类

（Bi-Encoder）。二者

结构分

别如图 6.15

(a) 和 6.15 (b)

所

示。

249

第 6

章 检索

增强生成

交

叉编码器

问

题

文档

分类

器

问题编码

器

相关性分

数

文档编码

器

向量u 向量

v

相关性分数

问题

文档

(a). 交

叉编码器 (b).

双

编码器

+

图 6.15:

不

同稠密检索

器对比图。

交

叉编码类

交

叉编码类“端

到端”的给出

查询和文档

的相似度。这

类模型将查

询和文档拼

接在一起，随

后利用预训

练语言模型

作为编码器

（例如 BERT）生成一

个向量表示

。

接着，通过一

个分类器处

理这个向量

，最终输出一

个介于 0 和 1

之

间的数值，表

示

输入的查

询和文档之

间的相似程

度。其优点在

于模型结构

简单，能够实

现查询和

文

档之间的深

度交互，例如

，在工作 [12,

44] 中，研

究者们使用

了交叉编码

器来提

升检

索性能。然而

，由于交叉编

码类模型需

要进行高复

杂度的交叉

注意力操作

，计

算量大，因

此不适合在

大规模检索

阶段使用。这

种模型更适

用于对少量

候选文档

进

行更精确排

序的阶段，可

以显著提升

检索结果的

相关性。

双编

码器类

与交

叉编码类模

型不同，双编

码类模型采

用了一种“两

步走”的策略

。第一

步，查询

和文档首先

各自通过独

立的编码器

生成各自的

向量表示；第

二步，对这两

个向量之间

的相似度进

行计算，以评

估它们的相

关性。这种方

法的优势在

于，它允

许预

先离线计算

并存储所有

文档的向量

表示，在线检

索时则可直

接进行向量

匹配。

因此，双

编码器非常

适合在工业

环境中部署

，具有极高的

匹配效率。然

而，在这种

分

离的处理方

式中，查询与

文档在提取

特征向量时

缺乏交互。这

可能会对匹

配的精

250

董雪

梅 徐文溢 毛

玉仁

确度产

生影响。DPR（Dense

Passage Retriever）[23] 是稠

密检索器的

一个代表工

作。

其使用两

个独立的

BERT 编

码器，分别将

查询和文档

映射到低维

特征向量，然

后

通过向量

点积衡量相

似度。为了缓

解查询与文

档缺乏交互

的问题，DPR 通过

对比

学习优

化编码器，最

大化查询与

相关段落相

似度的同时

最小化与负

面段落相似

度。

为了缓解

查询与文档

在提取特征

向量时缺乏

交互的问题

，可以在双编

码器的

基础

上引入查询

与文档的交

互，以进一步

提升双编码

器的效果。ColBERT[24] 是

其

中的代表

性方法。其以

查询和文档

间的 Token 级的相

似度为度量

，然后通过对

比学

习对双

编码器进行

微调，以使双

编码器编码

的特征向量

可以兼顾查

询和文档。此

外，在

RAG 中，我们

有时会对查

询加入大段

上下文进行

增强，如第 3.3.2 节

所介绍

的情

形。此时，查询

的长度急剧

增长，传统的

检索方法可

能难以有效

的处理这些

长

查询。为解

决此问题，可

以采用 Poly-encoder[16]。其模

型架构沿用

双编码器的

形

式，但是它

使用

m 个向量

来捕获长查

询的多个特

征，而不是像

普通双编码

器那样

只用

一个向量来

表示整个查

询。并且，这 m

个

向量随后与

文档的向量

通过注意力

机制进行交

互，其中的注

意力模块采

用查询和文

档间的对比

学习进行训

练。

2. 生成式检

索器

生成式

检索器通过

生成模型对

输入查询直

接生成相关

文档的标识

符

[29]。与

判别式

检索器不断

地从知识库

中去匹配相

关文档不同

，生成式检索

器直接将知

识

库中的文

档信息记忆

在模型参数

中。然后，在接

收到查询请

求时，能够直

接生成

相关

文档的标识

符（即

DocID），以完成

检索 [48]。生成式

检索器通常

采用基于

Encoder-Decoder 架

构的生成模

型，如

T5[41]、BART[27] 等。生成

式检索器的

训练

过程通

常分为两个

阶段 [29]。在第一

阶段，模型通

过序列到序

列的学习方

法，学习

如何

将查询映射

到相关的文

档标识符。这

一阶段主要

通过最大似

然估计（MLE）来

优

化模型，确保

生成的文档

标识符尽可

能准确。在第

二阶段，通过

数据增强和

排名

优化进

一步提高检

索效率和准

确性。数据增

强主要通过

生成伪查询

[51] 或使用文

251

第

6 章 检索增强

生成

档片段

[61] 作为查询输

入，以增加训

练数据的多

样性和覆盖

面。排名优化

则涉及

使用

特定的损失

函数，如对比

损失或排名

损失，来调整

模型生成文

档标识符的

顺

序和相关

性，从而更好

地匹配查询

的需求。

在生

成式检索器

中，DocID 的设计至

关重要。其需

要在语义信

息的丰富性

与标

识符的

简洁性之间

取得平衡。常

用的 DocID

形式分

为两类：基于

数字的 DocID 和

基

于词的

DocID。基于

数字的 DocID 方法

使用唯一的

数字值或整

数字符串来

表示

文档，虽

然构建简单

，但在处理大

量文档时可

能导致标识

符数量激增

，增加计算和

存储负担。相

比之下，基于

词的

DocID 方法直

接从文档的

标题、URL 或 N-gram

中

提

取表示 [9]，能更

自然地传达

文档的语义

信息。通常，标

题是最佳选

择，因为它

提

供了文档的

宏观概述。但

在缺乏高质

量标题时，URL

或

N-gram 也可作为有

效的

替代方

案。

尽管生成

式检索器在

性能上取得

了一定的进

步，但与稠密

检索器相比

，其效

果仍稍

逊一筹。此外

，生成式检索

器还面临着

一系列挑战

，包括如何突

破模型输入

长度的限制

、如何有效处

理大规模文

档以及动态

新增文档的

表示学习等

，这些都

是亟

待解决的问

题。

6.3.4 检索效率

增强

知识库

中通常包含

海量的文本

，对知识库中

文本进行逐

一检索缓慢

而低效。为

提

升检索效率

，可以引入向

量数据库来

实现检索中

的高效向量

存储和查询

[39]。向

量数据库

的核心是设

计高效的相

似度索引算

法。本节将简

要介绍常用

的相似度索

引算法，以及

用于构建向

量数据库的

常见软件库

。

1.

相似度索引

算法

在向量

检索中，常用

的索引技术

主要分成三

大类：基于空

间划分的方

法、基于

量化

方法和基于

图的方法。

252

董

雪梅 徐文溢

毛玉仁

基于

空间划分的

方法将搜索

空间划分为

多个区域来

实现索引，主

要包括基于

树的索引方

法和基于哈

希的方法两

类。其中，基于

树的索引方

法通过一系

列规则

递归

地划分空间

，形成一种树

状结构，每个

叶节点代表

一个较小区

域，区域内的

数

据点彼此

接近。在查询

时，算法从树

的根节点出

发，逐步深入

到合适的叶

节点，最

后在

叶节点内部

进行数据点

的相似度比

较，以找到最

近的向量。常

见的基于树

的

索引包括

KD 树

[4] 和 Ball 树

[13] 等。而

基于哈希的

方法（如局部

敏感哈希（LSH）

[11]）通

过哈希函数

将向量映射

到哈希表的

不同桶中，使

得相似向量

通常位于同

一

桶内。

基于

图的方法通

过构建一个

邻近图，将向

量检索转化

为图的遍历

问题。这类

方

法在索引构

建阶段，将数

据集中的每

个向量表示

为图中的一

个节点，并根

据向

量间的

距离或相似

性建立边的

连接。不同的

图索引结构

主要体现在

其独特的赋

边

策略上。索

引构建的核

心思想源于

小世界网络

模型，旨在创

建一个结构

，使得从任

意

入口点出发

，能在较少步

数内到达查

询点的最近

邻。这种结构

允许在搜索

时使

用贪婪

算法，逐步逼

近目标。然而

，图索引设计

面临稀疏性

和稠密性的

权衡：较稀

疏

的图结构每

步计算代价

低，而较稠密

的图则可能

缩短搜索路

径。基于图的

代表

性方法

有

NSW[32]、IPNSW[37] 和 HNSW[31] 等。

基于

乘积量化的

方法通过将

高维向量空

间划分为多

个子空间，并

在每个子空

间中进行聚

类得到码本

和码字，以此

作为构建索

引的基础 [18]。这

类方法主要

包括

训练和

查询两个阶

段。在训练阶

段，该方法学

习如何将高

维向量最优

地量化为码

字

ID

序列。通常

这个过程涉

及将原始空

间划分为多

个子空间，在

每个子空间

内进行

聚类

，并通过聚类

中心得到码

字和码本。每

个子空间内

的聚类中心

点即为码字

，所

有码字的

集合构成码

本。每个训练

样本的每个

子向量可以

都用相应子

空间的码字

来近似，这样

就实现了码

字 ID

序列来表

示训练样本

，达到了数据

量化的目的

。在

查询阶段

，系统同样将

查询向量划

分为子向量

，并在每个子

空间中找到

最近的码

253

第

6

章 检索增强

生成

字，得到

码字 ID

序列。随

后，系统计算

查询向量的

每个子向量

到所有对应

子空间

的码

字的距离，形

成距离表。最

后，系统利用

这个距离表

和数据库中

每个向量的

码

字 ID

序列，快

速查找并累

加各个子向

量的对应距

离，得到查询

向量与数据

库向量

之间

的近似距离

。通过对这些

距离进行排

序，系统最终

得到最近邻

结果。该方法

在

减少内存

占用和加快

距离计算速

度方面表现

出色，但量化

过程中会不

可避免地会

引入一些误

差。在某些需

要精度更高

的应用场景

中，我们可以

在 PQ

的基础上

进一

步进行

精确排序，以

得到精确的

最近邻结果

。此外，还有一

些乘积量化

的优化算法

以及和其他

索引相结合

的算法，如 OPQ[15]、IVFPQ[19] 等

。

2. 常见软件库

介绍

在前文

中，我们已经

介绍了向量

数据库的核

心技术——相似

度索引算法

。这

些算法是

实现高效向

量检索的关

键。接下来，我

们将介绍几

种常用于构

建和管理

向

量数据库的

软件库，它们

支持上述的

相似性索引

算法，是实现

高效向量检

索的

重要工

具。

Faiss4，由 Meta

AI Research 开发，是

一个专门优

化密集向量

相似性搜索

和聚

类的库

。Faiss

提供了多种

索引算法选

择，这些算法

涵盖了基于

空间划分、基

于量

化以及

基于图的方

法等。这些算

法不仅能在

CPU 上运行，部分

算法还支持

GPU 加

速，从而满

足不同应用

场景下的性

能需求。然而

，Faiss 本身并不是

一个完整的

数

据库系统

，而是一个功

能强大的工

具库。它专注

于提供高效

的索引和搜

索功能，但

在

数据存储、管

理、分布式支

持和安全性

措施等方面

，Faiss

的功能相对

有限。相

比之

下，向量数据

库是一种更

全面的解决

方案，它不仅

包括相似度

索引算法，还

整

合了数据

存储、管理、分

布式支持和

安全性措施

等多方面的

功能。截至目

前，市场

上已

有多款成熟

的向量数据

库，如表6.1所示

，它们适用于

各种更复杂

的

RAG 应用

场景

。

4https://github.com/facebookresearch/faiss

254

董雪梅 徐文

溢 毛玉仁

表

6.1: 常见的向量

数据库。

向量

数据库 URL

GitHub Star

milvus https://github.com/milvus-io/milvus

28.4K

typesense https://github.com/typesense/typesense 19.0K

qdrant https://github.com/qdrant/qdrant 18.9K

chroma

https://github.com/chroma-core/chroma 13.7K

weaviate https://github.com/weaviate/weaviate

10.4K

pinecone https://www.pinecone.io/ ×

6.3.5 检索

结果重排

检

索器可能检

索到与查询

相关性不高

的文档。这些

文档如果直

接输入给大

语

言模型，可

能会引发生

成质量的下

降。为此，在将

其输入给大

语言模型之

前，我们

还需

要对其进行

进一步的精

选。精选的主

要途径是对

检索到的文

档进行重新

排序，

简称重

排，然后从中

选择出排序

靠前的文档

。重排方法主

要分为两类

：基于交叉编

码的方法和

基于上下文

学习的方法

。

1. 基于交叉编

码的重排方

法

基于交叉

编码的重排

方法利用交

叉编码器（Cross-Encoders）来

评估文档与

查

询之间的

语义相关性

。关于交叉编

码的介绍见

第6.3.3节。MiniLM-L5是应用

最为广

泛的

基于交叉编

码的重排开

源模型之一

。该模型通过

减少层数和

隐层单元数

来降

低参数

数量，同时采

用知识蒸馏

技术从大型

、高性能的语

言模型中继

承学习，以此

来提高模型

性能。此外，还

有其他一些

在线重排模

型可通过

API 直

接访问，例如

Cohere6。对于希望探

索其他高性

能的重排器

的读者，可以

参考 MTEB7 排行榜

，该

榜单汇集

了很多性能

优秀的重排

模型。

2. 基于上

下文学习的

重排方法

基

于上下文学

习的方法是

指通过设计

精巧的

Prompt，使用

大语言模型

来执行

5https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2

6https://cohere.com/rerank

7https://huggingface.co/spaces/mteb/leaderboard

255

第 6 章

检索增强生

成

RankGPT Prompt 模板

这是

RankGPT，一款智能助

手，专门用于

根据查询的

相关性对段

落进行排序

。

以下是{{num}}段文

字，每段都有

一个数字标

识符[ ]。我将根

据查询内容

对它们进行

排序：{{query}}

[1] {{passage_1}}

[2] {{passage_2}}

（更多段

落）...

查询是：{{query}}

我

将根据查询

对上述{{num}}段文

字进行排序

。这些段落将

按照相关性

降序列出，使

用标识符表

示，最相关

的

段落将列在

最前面，输出

格式应该是

[ ] >

[ ] > 等，例如，[1]

> [2] > 等。

对

{{num}}段文字的排

序结果（仅限

标识符）是：

图

6.16: RankGPT Prompt

模板图。

重排

任务。这种方

法可以利用

大语言模型

优良的深层

语义理解能

力，从而取得

了

良好的表

现。RankGPT[47] 是基于上

下文学习的

重排方法中

的代表性方

法。其使用

的

Prompt 模板如图6.16所

示。在重排任

务中，输入文

档长度有时

会超过上下

文窗

口长度

的限制。为了

解决该问题

，RankGPT 采用了滑动

窗口技术来

优化排序过

程。

该技术将

所有待排序

的文档分割

成多个连续

的小部分，每

个部分作为

一个窗口。整

个排序过程

从文档集的

末尾开始：首

先，对最后一

个窗口内的

文档进行排

序，并将

排序

后的结果替

换原始顺序

。然后，窗口按

照预设的步

长向前移动

，重复排序和

替

换的过程

。这个过程将

持续进行，直

到所有文档

都被处理和

排序完毕。通

过这种分

步

处理的方法

，RankGPT

能够有效地

对整个文档

集合进行排

序，而不受限

于单一

窗口

所能处理的

文档数量。

6.4 生

成增强

检索

器得到相关

信息后，将其

传递给大语

言模型以期

增强模型的

生成能力。利

用这些信息

进行生成增

强是一个复

杂的过程，不

同的方式会

显著影响 RAG 的

性能。

本节将

从如何优化

增强过程这

一角度出发

，围绕四个方

面展开讨论

：（1）何时增

强，确

定何时需要

检索增强，以

确保非必要

不增强；（2）何处

增强，确定在

模型中

256

董雪

梅 徐文溢

毛

玉仁

的何处

融入检索到

的外部知识

，以最大化检

索的效用；（3）多

次增强，如何

对复杂

查询

与模糊查询

进行多次迭

代增强，以提

升 RAG

在困难问

题上的效果

；（4）降本

增效，如

何进行知识

压缩与缓存

加速，以降低

增强过程的

计算成本。

6.4.1 何

时增强

大语

言模型在训

练过程中掌

握了大量知

识，这些知识

被称为内部

知识（Self￾Knowledge）。对于内

部知识可以

解决的问题

，我们可以不

对该问题进

行增强。不对

是否需要增

强进行判断

而盲目增强

，不仅不会改

善生成性能

，还可能“画蛇

添足”

引起生

成效率和生

成质量上的

双下降。对生

成效率而言

，增强文本的

引入会增加

输入 Token 的数量

，增加大语言

模型的推理

计算成本。另

外，检索过程

也涉及大量

的计算资源

。对生成质量

而言，因为检

索到的外部

知识有时可

能存在噪音

，将其输

入给

大语言模型

不仅不会改

善大语言模

型的生成质

量，反而可能

会生成错误

内容。

如图 6.17所

示，对于“树袋

熊一般在哪

里生活？”这个

问题，大语言

模型可以直

接

给出正确

答案。但是，当

我们为它提

供一段与树

袋熊名称非

常相似的动

物袋熊的

外

部知识，如图

6.18所示，大语言

模型给出了

错误答案，因

为大语言模

型将知识文

本中关于袋

熊的信息错

误地理解为

树袋熊的相

关信息。综上

，判断大语言

模型何

时需

要检索增强

，做到非必要

不增强，可以

有效的降低

计算成本并

避免错误增

强。

判断是否

需要增强的

核心在于判

断大语言模

型是否具有

内部知识。如

果我们

判断

大模型对一

个问题具备

内部知识，那

么我们就可

以避免检索

增强的过程

，不

仅降低了

计算成本，而

且还可以避

免错误增强

。判断模型是

否具有内部

知识的方

法

可以分为两

类：（1）外部观测

法，通过 Prompt 直接

询问模型是

否具备内部

知识，

或应用

统计方法对

是否具备内

部知识进行

估计，这种方

法无需感知

模型参数；（2）

内

部观测法，通

过检测模型

内部神经元

的状态信息

来判断模型

是否存在内

部知识，

这种

方法需要对

模型参数进

行侵入式的

探测。

257

第 6 章 检

索增强生成

树袋熊一般

在哪里生活

?

树袋熊主要

生活在澳大

利亚和新几

内亚附近的

热带和亚热

带地区，包括

森林、草原和

灌木丛等环

境。它们常见

于树木茂密

的地区，因为

它们大部分

时间都在树

上度过，利用

树洞等避难

所。

图 6.17: 模型已

知问题示例

。

袋熊营穴居

生活，很善于

挖洞，它们栖

居的洞穴比

较大。一般洞

穴纵深可达

10米，宽60厘米，洞

的

未端是卧

室，用草和树

皮做铺垫物

。袋熊喜独立

独往，有时2-3只

在一起生活

，为夜行动物

，白天

藏在洞

中熟睡。它们

以青草，野菜

为食。袋熊的

新陈代谢非

常的慢，眼、耳

均小，身体矮

胖敦实，

差不

多要用14天的

时间来完成

消化，这有助

于生活在乾

燥的环境。它

们一般行动

得很慢，但当

遇上

危害时

，逃走速度可

以达40千米/时

，并维持达90秒

。袋熊会保护

由其巢穴为

中心的疆界

，对入侵

者存

有攻击性。

树

袋熊一般在

哪里生活?

树

袋熊主要生

活在澳大利

亚和新几内

亚等地区的

森林和草原

地带。它们喜

欢栖息在茂

密的树木中

利

用自己擅

长的控洞能

力在树洞或

地洞中建造

巢穴。这种环

境提供了主

富的青草和

野菜作为它

们的食

物来

源，并且相对

安静和隐蔽

，适合它们作

为夜行动物

的生活习性

。

图 6.18:

知识文档

损害性能示

例。

1. 外部观测

法

外部观测

法旨在不侵

入模型内部

参数的情况

下，通过直接

对大语言模

型进行

询问

或者观测调

查其训练数

据来推断其

是否具备内

部知识。这种

方法可以类

比为

人类面

试的过程。面

试官在评估

应聘者的知

识和能力时

，通常会询问

并观察其反

应、浏览其过

往教育经历

等方式，以判

断应聘者是

否具备足够

的专业知识

。对于大

语言

模型，我们可

以通过两种

问询的方式

来判断大语

言模型是否

具备相应的

内部

知识：（1）Prompt

直

接询问大语

言模型是否

含有相应的

内部知识；（2）反

复询问

大语

言模型同一

个问题观察

模型多次回

答的一致性

。此外，我们也

可以通过翻

看

大语言模

型的“教育经

历”，即训练数

据来判断其

是否具备内

部知识。但是

，许多

大语言

模型的训练

数据并未公

开，无法直接

观测它们的

训练数据。在

这种情况下

，

可以通过设

计伪训练数

据统计量来

拟合真实训

练数据的分

布，从而间接

评估模型

对

特定知识的

学习情况。接

下来将对这

三种方式进

行详细介绍

。

258

董雪梅

徐文

溢 毛玉仁

你

需要额外的

信息帮助来

回答这个问

题吗？

问题：2023年

的考拉数量

大约有多少

?

可能的回答

不，我不需要

额外的信息

帮助来回答

这个问题。/ 是

的，我需要额

外的信息帮

助来回答这

个问题。

图 6.19:

直

接询问的 Prompt 示

例。

（1）询问

我们

可以通过直

接询问和多

次询问两种

询问方法来

判断大语言

模型是否具

备

内部知识

。在直接询问

时，我们可以

编写 Prompt 直接询

问大语言模

型是否需要

外

部知识，如

图 6.19所示。然而

，大语言模型

很难做到“知

之为知之”，其

存在“过

度自

信”的问题：对

于无法回答

的问题，大语

言模型经常

认为自己不

需要外部知

识

的帮助，因

此这种判断

方式的准确

率较低。此外

，采用多次询

问时，我们可

以通过

让大

语言模型重

复多次地回

答同一个问

题，然后根据

其回答的一

致性判断其

是否

具备内

部知识 [34, 40]。如果

模型不具备

相应的内部

知识，那么每

次的输出会

较为

随机，从

而导致多次

回答的一致

性不强；反之

，如果模型具

备内部知识

，其每次都

会

回答正确的

知识、随机性

较弱，输出则

会有更高的

一致性。然而

，这种方式同

样

面临着模

型因过度自

信而“执拗”地

一直给出相

同的错误答

案的情况。并

且，多次

询问

还需要耗费

大量的时间

和计算资源

，在实际使用

中可行性较

低。

（2）观察训练

数据

通过询

问来判断内

部知识的方

法存在的模

型回答可靠

性较低的问

题。我们可

以

转向观察更

为可靠的训

练数据。大语

言模型所具

备的内部知

识来源于其

训练数

据。因

此，如果模型

的训练数据

中不包含当

前问题的相

关信息，那么

，模型自然也

就未曾习得

相应的知识

。此外，类比人

类的学习模

式，我们通常

对常见或反

复学习

的知

识掌握程度

更好，而对低

频的知识则

较弱。因此，对

于训练数据

中出现频率

很

低的知识

，模型对它们

的学习程度

可能也是比

较低的，即知

识在训练数

据中的出现

259

第 6

章 检索增

强生成

考拉

是什么动物

?

考拉是一种

澳大利亚特

有的有袋类

动物，属于袋

熊科，和袋鼠

类似。它们通

常以树叶为

食，是一种

夜

行动物，白天

多数时间都

在树上睡觉

。考拉以其圆

耳朵、圆眼睛

和圆胖的身

体而闻名。

图

6.20: 模型对流行

知识的回答

示例。

频率与

模型对该知

识的记忆程

度是正相关

的

[22]。所以，我们

可以通过判

断训练数

据

中是否包含

相应的知识

来判断模型

是否掌握了

相应的知识

。然而，这种方

式存

在一定

的局限性。首

先，由于大语

言模型的训

练数据规模

已经达到了

数万亿级别

，

因此这种统

计的手段非

常耗时。此外

，对于许多商

业大语言模

型，例如

ChatGPT、

GPT4 等，它

们的训练数

据并不是公

开可获取的

，在这种情况

下，此方案无

法执行。

（3）构造

伪训练数据

统计量

当训

练数据不可

获取时，我们

可以设计伪

训练数统计

量来拟合训

练数据的相

关情况。比如

，由于模型对

训练数据中

低频出现的

知识掌握不

足，而对更“流

行”（高

频）的知

识掌握更好

，因此实体的

流行度作可

以作为伪训

练数据统计

量。代表性工

作 [33] 利用

Wikipedia 的页

面浏览量来

衡量实体的

流行度，浏览

量越大，表明

该

实体越流

行，也就更可

能被大语言

模型所记忆

。图 6.20和图

6.21分别

展示了流行

与

不流行的

知识的例子

。从这两个例

子中可以发

现，对于流行

知识考拉，模

型能够直

接

给出正确的

回答，而对于

不流行知识

考拉的基因

数量，模型给

出了错误的

答案

（正确答

案应为

26,558）。由此

可见，实体的

流行度确实

在一定程度

上反映了模

型的

内部知

识，因此，可以

通过设定一

个流行度阈

值来判别模

型是否具备

相应的内部

知识。然而，这

种流行度的

定义依赖于

数据形成时

间，并且未必

能精准拟合

训练数

据的

分布，因此存

在一定的局

限性。

2.

内部观

测法

为了进

一步深入了

解大语言模

型的内部知

识，在模型参

数可访问的

情况下，可

260

董

雪梅

徐文溢

毛玉仁

考拉

的基因数量

有多少?

考拉

是一种有袋

类动物，它们

的基因数量

与人类相近

，考拉的基因

组大小约为

3.2亿个碱基对

(bp)，

这相当于大

约3.2亿个基因

。这个数字与

人类的基因

数量相似，人

类基因组大

小约为3亿个

碱基对，

这说

明考拉和人

类在遗传信

息的复杂性

上有一定的

相似之处。

图

6.21: 模型对不流

行知识的回

答示例。

以通

过观测模型

内部的隐藏

状态来更精

确地评估其

知识掌握情

况。其可以类

比人

类测谎

的过程，科学

家通过分析

脑电波、脉搏

、血压等人类

内部状态变

化来推断大

脑的活动和

认知状态，从

而判断其是

否在说谎或

隐藏某些信

息。同样地，对

于大

语言模

型，可通过分

析模型在生

成时每一层

的隐藏状态

变化，比如注

意力模块的

输出、多层感

知器 (MLP) 层的输

出与激活值

变化等，来进

行评估其内

部知识水平

。

这是因为大

语言模型在

生成文本时

，是对输入序

列进行建模

和预测，模型

内部状

态的

变化反映了

模型对当前

上下文理解

和下一步预

测的确定性

。如果模型表

现出

较高的

内部不确定

性，如注意力

分布较为分

散、激活值变

化较大等，就

可能对当前

上下文缺乏

充分的理解

，从而无法做

出有把握的

预测。

由于模

型的内部知

识检索主要

发生在中间

层的前馈网

络中

[36]，因此在

处理

包含或

不包含内部

知识的不同

问题时，模型

的中间层会

展现出不同

的动态变化

。基

于这一特

性，我们可以

训练分类器

进行判别，这

种方法被称

为探针。例如

，Liang

等人

[30] 针对三

种类型的内

部隐藏状态

设计了探针

实验，分别是

注意力层输

出

（Attention Output）、MLP

层输出（MLP Output）和

隐层状态（Hidden States），如

图 6.22所示。对于

每个输入问

题，研究者利

用训练好的

探针，即线性

分类器，来根

据问题所对

应的内部表

示预测该问

题是属于模

型“已知”（即模

型具备相关

知识）

还是“未

知”（即模型缺

乏相关知识

）。结果显示，不

同大语言模

型在利用中

间层的

内部

表示进行分

类时，均能够

实现较高的

分类准确率

。这表明中间

层的内部隐

藏

状态能够

有效地反映

模型对问题

的理解和相

关知识储备

。

261

第 6 章 检索增

强生成

嵌

入

层

注

意

力

层

前

馈

层

线

性

层

归

一

化

层

探针 探针 探

针

用户查询

2023年的

考拉数

量大

约有多

少？ 生成器

2023年

的考拉

数量

大约在

5,000到8,000

只

之间。。。

× N

图 6.22:

模型

内部状态探

针。

然而，这种

依赖于内部

状态的检测

方法也存在

一定的局限

性，它并不适

用于

黑盒语

言模型，因为

我们无法直

接访问其内

部隐藏状态

。另外，模型的

输入也需要

仔细设计，因

为模型有时

所展现出的

不确定性，可

能并非源于

对问题的知

识缺失，

而是

问题本身固

有的模糊性

或歧义性所

致。总体而言

，基于内部状

态评估内部

知

识的工作

目前尚处于

初步探索阶

段，具体的方

案设计有待

进一步完善

，例如如何

构

建模型“已知

”和“未知”问题

的数据集、如

何量化内部

状态的不确

定性、不同

内

部表示的比

对方法，如何

设计内部状

态检测方案

等。我们需要

在更广泛的

数据

集和更

多样的模型

架构上展开

研究，以验证

这一方法的

有效性和普

适性。但是，这

是一条充满

潜力的新路

径，有望为我

们从内部视

角深入了解

大语言模型

的知识提

供

新的视角与

方法。

6.4.2 何处增

强

在确定大

语言模型需

要外部知识

后，我们需要

考虑在何处

利用检索到

的外部

知识

，即何处增强

的问题。得益

于大语言模

型的上下文

学习能力、注

意力机制的

可

扩展性以

及自回归生

成能力，其输

入端、中间层

和输出端都

可以进行知

识融合操

作

。在输入端，可

以将问题和

检索到的外

部知识拼接

在 Prompt

中，然后输

入给大

语言

模型；在中间

层，可以采用

交叉注意力

将外部知识

直接编码到

模型的隐藏

状

262

董雪梅

徐

文溢 毛玉仁

嵌

入

层

注

意

力

层

前

馈

层

线

性

层

归

一

化

层

用户查

询

2023年的考拉

数

量大约有

多少？

生成器

2023年的考拉

数

量大约在

5,000到

8,000

只之间。。。

× N

Transformer 层

知

识库 相关文

档

检索器

编

码器

2023 年，调整

后的考拉种

群估计数得

出的考拉

种

群估计数在

86,000 至 176,000 只之间。

根

据下列文档

回答问题：

文

档：2023 年，调整后

的考拉种群

估计数得出

的

考拉种群

。。。

问题：2023年的考

拉数

量大约

有多少？

2023 年，调

整

后的考拉

种群估

计数

得出的考拉

种群。。。

生成器

2023年的

考拉数

量在

86,000至

176,000 只

之

间。

反馈矫正

模型输入

模

型中间层

模

型输出

图

6.23: 增

强实施位置

示意图。

态中

；在输出端，可

以利用外部

知识对生成

的文本进行

后矫正。图 6.23通

过一个

列子

展示了上述

三种增强位

置的实施方

案。三种增强

位置分别具

有不同的优

缺点，

适合不

同的场景。本

小节将对其

进行逐一介

绍。

（1）在输入端

增强

在输入

端增强的方

法直接将检

索到的外部

知识文本与

用户查询拼

接到

Prompt

中，然后

输入给大语

言模型。其是

当前主流的

增强方法。此

方式的重点

在于 Prompt

设计以

及检索到的

外部知识的

排序。良好的

Prompt

设计和外部

知识排序，可

以使

模型更

好地理解、利

用外部知识

。在设计 Prompt 的过

程中，可以运

用

CoT [54] 等

Prompt

技巧，具

体方法可参

阅本书第三

章的 Prompt 工程内

容。

在输入端

增强的方法

直观且易于

实现。模型可

以直接从输

入的上下文

中提取

到所

需信息，无需

复杂的处理

或转换。然而

，当检索到的

文本过长时

，可能导致输

入序列过长

，甚至超出模

型的最大序

列长度限制

。这给模型的

上下文理解

带来挑

战，并

且还会增加

模型推理计

算成本、增加

其计算负担

。这种方法对

大语言模型

的

长文本处

理能力和上

下文理解能

力要求较高

。

（2）在中间层增

强

在中间层

增强增强的

方法利用注

意力机制的

灵活性，先将

检索到的外

部知识

转换

为向量表示

，然后将这些

向量插入通

过交叉注意

力融合到模

型的隐藏状

态中。

263

第

6 章 检

索增强生成

在第 6.2

节中介

绍的 Retro [6] 方法，就

是采用这种

方式的典型

代表。这种方

法能够

更深

入地影响模

型的内部表

示，可能有助

于模型更好

地理解和利

用外部知识

。同

时，由于向

量表示通常

比原始文本

更为紧凑，这

种方法可以

减少对模型

输入长度

的

依赖。然而，这

种方法需要

对模型的结

构进行复杂

的设计和调

整，无法应用

于黑

盒模型

。

（3）在输出端增

强

在输出端

增强的方法

利用检索到

的外部知识

对大语言模

型生成的文

本进行校

准

，是一种后处

理的方法。在

此类方法中

，模型首先在

无外部知识

的情况下生

成一

个初步

回答，然后再

利用检索到

的外部知识

来验证或校

准这一答案

。校验过程基

于生成文本

与检索文本

的知识一致

性对输出进

行矫正。矫正

可以通过将

初步回答

与

检索到的信

息提供给大

模型，让大模

型检查并调

整生成的回

答来完成。例

如，Yu

等人提出

的 REFEED 框架

[59] 是此

类方法典型

代表。这种方

法的优点是

可以确保

生

成的文本与

外部知识保

持一致，提高

答案的准确

性和可靠性

。然而，其效果

在很

大程度

上依赖于检

索到的外部

知识的质量

和相关性。若

检索到的文

档不准确或

不

相关，则会

导致错误的

校准结果。

综

上，上述三种

增强方式各

有优劣，在实

际应用中，我

们可以根据

具体的场景

和需求，灵活

选择不同的

方案。并且，由

于上述三种

方案是相互

独立的，它们

也可

以组合

使用，以实现

更优的增强

效果。

6.4.3

多次增

强

在实际应

用中，用户对

大语言模型

的提问可能

是复杂或模

糊的。复杂问

题往往

涉及

多个知识点

，需要多跳（multi-hop）的

理解；而模糊

问题往往指

代范围不明

，

难以一次就

理解问题的

含义。对于复

杂问题和模

糊问题，我们

难以通过一

次检索增

强

就确保生成

正确，多次迭

代检索增强

在所难免。处

理复杂问题

时，常采用分

解式

264

董雪梅

徐文溢 毛玉

仁

增强的方

案。该方案将

复杂问题分

解为多个子

问题，子问题

间进行迭代

检索增强，

最

终得到正确

答案。处理模

糊问题时，常

采用渐进式

增强的方案

。该方案将问

题的

不断细

化，然后分别

对细化的问

题进行检索

增强，力求给

出全面的答

案，以覆盖用

户需要的答

案。本小节将

对这两种方

案展开介绍

。

1.

分解式增强

复杂问题通

常包含多个

知识点。例如

，在“世界上睡

眠时间最长

的动物爱吃

什

么？”这个问

题中，包含着

“世界上睡眠

时间最长的

动物是什么

？”和“这个动物

爱

吃什么？”两

个知识点。对

复杂问题进

行作答，需要

多跳理解。因

此，在复杂问

题

的检索增

强中，我们通

常无法仅通

过一次检索

增强就得到

满意的答案

。在这种情

况

下，模型可以

将多跳问题

分解为一个

个子问题，然

后在子问题

间迭代地进

行检

索增强

，最后得出正

确结论，即分

解式增强。

DEMONSTRATE–SEARCH–PREDICT（DSP） [25]

是

一种具有代

表性的分

解

式增强框架

。该框架主要

包含以下三

个模块：（1）DEMONSTRATE 模块

，通

过上下文

学习的方法

，将复杂问题

分解为子问

题；（2）SEARCH

模块，对子

问题

进行迭

代检索增强

，为最终决策

提供综合的

外部知识；（3）PREDICT 模

块，根据

SEARCH

提供

的综合外部

知识生成最

终回答。

如图

6.24所示，以“世界

上睡眠时间

最长的动物

爱吃什么？”为

例对 DSP 的流

程

进行介绍。首

先，DEMONSTRATE 模块会在

训练集中寻

找类似问题

的示例，以此

来演示问题

如何被分解

。这些示例将

指导大语言

模型生成针

对子问题的

精确查询。

例

如，第一个子

问题是：“世界

上睡眠时间

最长的动物

是什么？”。随后

，SEARCH

模块将利用

第一个子问

题来检索相

关信息，从而

确定睡眠最

长的动物是

考拉，并

基于

这一新信息

形成第二个

子问题：“考拉

爱吃什么？”，随

后再次执行

检索，以找

到

描述考拉饮

食习惯的相

关文本。最终

，在 PREDICT 模块中，大

语言模型将

综合

所有信

息得出最终

答案，即“世界

上睡眠时间

最长的动物

是考拉，爱吃

桉树叶。”

265

第 6

章

检索增强生

成

世界上睡

眠时间最长

的动物爱吃

什么？

子问题

：世界上睡眠

时间最长的

动物是什么

？

检索文本：树

袋熊又名“考

拉”

，是一种树

栖动物，同时

也是世界上

最能睡的动

物。这种动物

只生

活在澳

大利亚，主要

栖息在桉树

上每天的睡

眠时间达到

22 个小时左右

。。。

答案：世界上

睡眠时间最

长的动物是

考拉。

检索器

知识库

最终

回答：世界上

睡眠时间最

长的动物是

考拉，爱吃桉

树叶。

DEMONSTRATE

示例问

题：世界上最

大的动物平

均体重是多

少？

子问题：世

界上最大的

动物是什么

？

答案：蓝鲸。

子

问题：蓝鲸的

平均体重是

多少？

答案：约

为150吨。

问题：世

界上睡眠时

间最长的动

物爱吃什么

？

SEARCH

PREDICT

子问题：考拉

爱吃什么？

检

索文本：考拉

主要以桉树

叶为食，每天

会吃掉大约

五百克重的

鲜树叶。它们

非常挑食，几

乎只吃

一种

食物，即桉树

叶，而且吃的

桉树叶营养

成分极低，还

含有剧毒。

答

案：考拉爱吃

桉树叶

图

6.24: DSP 流

程示意图。

分

解式增强将

复杂问题化

整为零，降低

了单次检索

增强的难度

。其性能很大

程度上取决

于子问题分

解的质量。不

同领域的复

杂问题可能

有着不同的

分解范式，

因

此常常需要

根据具体任

务对问题分

解方案进行

设计。

2. 渐进式

增强

在模糊

问题中，问题

主体通常指

代不明，容易

引发歧义。例

如，在“国宝动

物

爱吃什么

？”这个问题中

，由于不同国

家国宝动物

不同，且部分

国家的国宝

动物不

止一

种，因此我们

无法确定询

问的是其中

的哪一种动

物。在处理这

样的模糊问

题

时，我们可

以对问题进

行渐进式地

拆解、细化，然

后对细化后

的问题进行

检索，利

用检

索到的信息

增强大模型

。这种渐进式

的增强方法

可以帮助大

语言模型掌

握更

全面的

信息。

TREE OF CLARIFICATIONS（TOC）

[26] 是渐进

式增强的代

表性框架。该

框架通过递

归式检索来

引导大语言

模型在树状

结构中探索

给定模糊问

题的多种澄

266

董雪梅 徐文

溢

毛玉仁

清

路径。图 6.25展示

了 TOC

框架的整

个工作流，我

们以“国宝动

物爱吃什么

？”这

一问题为

例进行说明

。TOC 框架首先启

动第一轮检

索，根据检索

到的相关文

档和

原始问

题，生成一系

列具体的细

化问题，例如

：“中国的国宝

动物爱吃什

么？”，“澳

洲的国

宝动物爱吃

什么？”。在此过

程中，框架会

根据细化问

题与原问题

的相关性

及

知识一致性

进行剪枝。随

后，针对每个

细化问题，框

架独立展开

深入的检索

并对

问题进

一步细化，例

如：“澳洲的国

宝动物考拉

爱吃什么？”。最

终，我们能够

构建

出多条

完整的知识

路径，每条路

径的末端（叶

节点）都代表

了对原始问

题的不同但

是有效的解

答。通过整合

所有有效的

叶节点，我们

能够得出一

个精确且全

面的长

回答

，例如对此问

题我们得到

：“中国的国宝

动物熊猫爱

吃竹子；澳洲

的国宝动物

考拉爱吃桉

树叶；澳洲的

国宝动物袋

鼠爱吃杂草

和灌木……”

这种

渐进式的检

索方法能够

显著改善大

语言模型对

模糊问题的

生成效果。然

而，其需要进

行多轮检索

并生成多个

答案路径，整

个系统的计

算量会随着

问题复

杂度

呈指数级增

长。此外，多轮

的检索与生

成不仅会带

来显著的时

间延迟，多个

推

理路径还

为推理带来

不稳定性，容

易引发错误

。

6.4.4 降本增效

检

索出的外部

知识通常包

含大量原始

文本。将其通

过 Prompt

输入给大

语言模

型时

，会大幅度增

加输入 Token 的数

量，从而增加

了大语言模

型的推理计

算成本。

此问

题可从去除

冗余文本与

复用计算结

果两个角度

进行解决。本

小节将对这

两个

角度分

别展开介绍

。

1. 去除冗余文

本

在 RAG 中，检索

出的原始文

本通常包含

大量的无益

于增强生成

的冗余信息

。

这些冗余信

息不仅增加

了输入

Token 的长

度，而且还有

可能对大模

型产生干扰

，

导致生成错

误答案。去除

冗余文本的

方法通过对

检索出的原

始文本的词

句进行过

267

第

6 章 检索增强

生成

国宝动

物爱吃什么

？

知识库

中国

的国宝动物

熊猫爱吃竹

子；澳洲的国

宝动物考拉

爱吃桉树叶

；澳洲的国宝

动物

袋鼠爱

吃杂草和灌

木……

问题

1 问题

2 问题 3

问题细

化 问题细化

问题 1-1 问题

1-2 问

题 2-1 问题

2-2 问题

2-3

中国的国宝

动物

熊猫爱

吃什么？

澳洲

的国宝动物

考拉爱吃什

么？

用户查询

生成器

检索

器

相关文档

剪枝

。。。

问题细

化

澳洲的国

宝动物

袋鼠

爱吃什么？

。。。

澳

洲的国宝动

物

爱吃什么

？

中国的国宝

动物

爱吃什

么？

图 6.25: TOC

框架流

程示意图。

滤

，从中选择出

部分有益于

增强生成的

部分。去除冗

余文本的方

法主要分为

三类：

Token 级别的

方法，子文本

级别的方法

以及全文本

级别的方法

。这些方法通

过不同

的机

制来筛选和

优化检索出

的原始文本

，以减少无益

信息，确保生

成内容的相

关

性和准确

性。以下分别

对这三类方

法分别展开

介绍。

Token 级别的

方法通过对

Token

进行评估，对

文本中不必

要的 Token 进行剔

除。

困惑度是

判断

Token 重要性

的重要指标

。直观上说，如

果一个 Token 的困

惑度低，

这意

味着模型有

很高的概率

预测到这个

Token，表明该 Token 易于

预测且较为

普遍，

因此它

携带的新信

息量较少，可

能是冗余的

；反之，如果一

个

Token 的困惑度

高，

则表明这

个 Token

携带了更

多的信息量

。LongLLMLingua [20] 框架利用小

模型评

268

董雪

梅 徐文溢 毛

玉仁

估

Token 的困

惑度，然后基

于困惑度删

除冗余文本

。其首先进行

问题感知的

粗粒度

压缩

，即在给定问

题条件下通

过计算文档

中所有 Token

困惑

度的均值来

评估文档

的

重要性，困惑

度越高表示

文档信息量

越大。随后，执

行问题感知

的细粒度压

缩，

即进一步

计算文档中

每个 Token

的困惑

度并去除其

中低困惑度

的 Token。此外，论

文

还引入了文

档重排序机

制、动态压缩

比率以及子

序列恢复机

制，确保重要

文档

和文档

中的重要信

息被有效利

用。

子文本级

别的方法通

过对子文本

进行打分，对

不必要的子

文本成片删

除。FIT￾RAG [35] 是子文本

级别方法中

的代表性方

法。该方法中

采用了预先

训练的双标

签

子文档打

分器，从两个

维度评估文

档的有用性

：一是事实性

，即文档是否

包含查询

的

答案信息；二

是模型的偏

好程度，即文

档是否易于

模型理解。对

于检索到的

文

档，首先利

用滑动窗口

将其分割成

多个子文档

，然后使用双

标签子文档

打分器对

这

些子文档分

别进行评分

。最后，删除掉

评分较低的

子文档，从而

有效地去除

冗余

文本。

全

文本级别的

方法直接从

整个文档中

抽取出重要

信息，以去除

掉冗余信息

。经

典方法 PRCA [57]

通

过训练能够

提炼重点内

容的信息提

取器对文本

中的重要信

息

进行提取

。该方法分为

两个阶段，上

下文提取阶

段与奖励驱

动阶段。在上

下文提取

阶

段，以最小化

压缩文本与

原输入文档

之间的差异

为目标，对信

息提取器进

行监

督学习

训练，学习如

何将输入文

档精炼为信

息丰富的压

缩文本。在奖

励驱动阶段

，

大语言模型

作为奖励模

型，其根据压

缩文本生成

的答案与真

实答案之间

的相似度

作

为奖励信号

，通过强化学

习对信息提

取器进行优

化。最终得到

的信息提取

器可

以直接

将输入文档

转化为压缩

文本，端到端

地去除冗余

文本。

2.

复用计

算结果

除了

对冗余信息

进行筛除，我

们还可以对

计算必需的

中间结果进

行复用，以

优

化 RAG

效率。在大

语言模型进

行推理的自

回归过程中

，每个 Token 都需要

用到

269

第 6 章 检

索增强生成

KV张量缓存库

生成器

用户

缓存检索器

RAGCache

PGDSF 流水线策略

重排策略

RAG控

制器

知识库

KV缓存

（GPU）

图 6.26:

RAGCache 框架

流程示意图

。

之前 Token

注意力

模块涉及的

Key 和 Value 的结果。为

了避免对每

个

Token 都重新

计

算前面的 Key

和

Value 的结果，我们

可以将之前

计算的 Key 和

Value 的

结果进行

缓

存（即 KV-cache），在需要

是直接从

KV-cache 中

调用相关结

果，从而避免

重复计

算。但

是，随着输入

文本长度的

增加，KV-cache 的

GPU 显存

占用会随之

剧增，甚

至会

远远超过模

型参数所占

用的显存大

小 [46]。然而，RAG

的输

入通常包含

检索

出来的

文本，导致输

入文本很长

，导致 RAG 中的

KV-cache 存

储成本高昂

。

不过，在 RAG

中，不

同用户查询

经常检索到

相同的文本

，而且常见的

查询通

常数

量有限。因此

，我们可以将

常用的重复

文本的 KV-cache 进行

复用，避免每

次

查询都对

其进行计算

，以降低存储

成本。基于此

，RAGCache [21] 设计了一种

RAG

系统专用的

多级动态缓

存机制，如图

6.26所示。RAGCache

系统由

三个核心部

分组

成：KV 张量

缓存库、缓存

检索器与 RAG

控

制器。其中，KV 张

量缓存库采

用树结

构来

缓存所计算

出的文档 KV

张

量，其中每个

树节点代表

一个文档；缓

存检索器则

负责在缓存

库中快速查

找是否存在

所需的缓存

节点；而 RAG 控制

器作为系统

的策

略中枢

，负责制定核

心的缓存策

略。具体而言

，RAG

控制器首先

采用了一种

前缀

感知的

贪婪双重尺

度频率（PGDSF）替换

策略。该策略

综合考虑了

文档节点的

访

问频率、大

小、访问成本

以及最近访

问时间，使得

频繁使用的

文档能够被

快速检索

270

董

雪梅 徐文溢

毛玉仁

到。随

后，重排策略

通过调整请

求的处理顺

序，优先处理

那些能够更

多利用缓存

数

据的请求

，以减少重新

计算的需求

。这样的请求

在队列中享

有较高的优

先级，从而

优

化了资源使

用。最后，系统

还引入了动

态推测流水

线策略，通过

并行 KV 张量检

索和模型推

理的步骤，有

效减少了端

到端延迟。

综

上，通过结合

上述输入

Prompt 压

缩与 KV-cache 机制，RAG

框

架可以在保

持高性能的

同时，显著提

升其效率。这

不仅有助于

在资源受限

的环境中部

署模型，

还可

以提高模型

在实际应用

中的响应速

度。

6.5 实践与应

用

通过引入

外部知识，RAG 可

以有效的缓

解大语言模

型的幻觉现

象，拓展了大

语言模型的

知识边界。其

优越的性能

使引起了广

泛关注，成为

炙手可热的

前沿技

术，并

在众多应用

场景中落地

。在本节中，我

们将探讨搭

建简单 RAG

系统

的方法，

以及

RAG 的两类典型

应用。

6.5.1

搭建简

单 RAG 系统

为了

助力开发者

们高效且便

捷地构建

RAG 系

统，当前已有

诸多成熟开

源框架

可供

选择，其中最

具代表性的

便是 LangChain

8与 LlamaIndex 9。这些

框架提供了

一

系列完备

的工具与接

口，使得开发

者们能够轻

松地将

RAG 系统

集成到他们

的应用

中，例

如聊天机器

人、智能体（Agent）等

。接下来，我们

将首先简要

概述这两个

框架的特色

及其核心功

能，然后讲解

如何利用 LangChain

来

搭建一个简

单的 RAG

系统。

8https://www.langchain.com

9https://www.llamaindex.ai

271

第

6 章

检索增强

生成

1. LangChain 与

LlamaIndex

（1）LangChain

LangChain 旨在

简化利用大

语言模型开

发应用程序

的整个过程

。它提供了一

系

列模块化

的组件，帮助

开发者部署

基于大语言

模型的应用

，其中就包括

RAG 框架

的构建

。LangChain 主要包含六

大模块：Model

IO、Retrieval、Chains、Memory、

Agents 和 Callbacks。其

中

Model IO 模块包含

了各种大模

型的接口以

及 Prompt

设

计组件

，Retrieval 模块包含了

构建 RAG

系统所

需要的核心

组件，包括文

档加载、

文本

分割、向量构

建，索引生成

以及向量检

索等，还提供

了非结构化

数据库的接

口。而 Chains 模块可

以将各个模

块链接在一

起逐个执行

，Memory

模块则可以

存储

对话过

程中的数据

。此外，Agent 模块可

以利用大语

言模型来自

动决定执行

哪些操

作，Callback

模

块则可以帮

助开发者干

预和监控各

个阶段。总体

而言，LangChain

提供了

一个较为全

面的模块支

持，帮助开发

者们轻松便

捷地构建自

己的 RAG 应用

框

架。

（2）LlamaIndex

与 LangChain

相比，LlamaIndex 更

加专注于数

据索引与检

索的部分。这

一特

性使得

开发者能够

迅速构建高

效的检索系

统。LlamaIndex 具备从多

种数据源（如

API、PDF

文件、SQL 数据库

等）中提取数

据的能力，并

提供了一系

列高效的工

具

来对这些

数据进行向

量化处理和

索引构建。在

数据查询方

面，LlamaIndex 同样提

供

了高效的检

索机制。此外

，在获取到上

下文信息后

，LlamaIndex 还支持对这

些信

息进行

过滤、重新排

序等精细化

操作。值得一

提的是，LlamaIndex 框架

还能够与

LangChain 框

架相结合，从

而实现更加

多样化的功

能。总体而言

，LlamaIndex 侧重

于索引

与检索，在查

询效率上的

表现更为突

出，非常适用

于在大数据

量的场景下

构建更为高

效的

RAG 系统。

272

董

雪梅

徐文溢

毛玉仁

2. 基于

LangChain 搭建简单

RAG 系

统

本小节将

以 LangChain

框架为例

，参考其官方

文档 10，演示如

何快速搭建

一套

简单的

RAG 系统。

1）安装与

配置：首先，需

要在环境中

安装 LangChain 框架及

其依赖项。

#

安

装LangChain框架及其

依赖项

!pip install langchain

langchain_community langchain_chroma

2）数据

准备与索引

构建：接下来

，我们需要准

备数据并构

建索引。LangChain

的

DocumentLoaders 中

提供了种类

丰富的文档

加载器，例如

，我们可以使

用 Web￾BaseLoader 从网页中

加载内容并

将其解析为

文本。

from langchain_community.document_loaders import WebBaseLoader

# 使用WebBaseLoader加

载网页内容

:

loader =

WebBaseLoader("https://example.com/page")

docs = loader.load()

加载完成后

，由于加载的

文档可能过

长，不适合模

型的上下文

窗口，需要将

文

档分割成

合适的大小

。LangChain 提供了 TextSplitter

组件

来实现文档

分割。

from langchain_text_splitters import

RecursiveCharacterTextSplitter

# 使用TextSplitter将

长文档分割

成更小的块

，其中chunk_size表示分

割文档的长

度，

chunk_overlap表示分割

文档间的重

叠长度

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap

=200)

splits = text_splitter.split_documents(docs)

接下

来我们需要

对分割后的

文本块进行

索引化，以便

后续进行检

索。这里我

们

可以调用 Chroma 向

量存储模块

和

OpenAIEmbeddings 模型来存

储和编码文

档。

10https://python.langchain.com/v0.2/docs/tutorials/rag/

273

第 6 章 检索

增强生成

from langchain_chroma import Chroma

from langchain_openai import OpenAIEmbeddings

# 使

用向量存储

(如Chroma)和嵌入模

型来编码和

存储分割后

的文档

vectorstore =

Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings

())

3）RAG

系统

构建：在构建

好知识源之

后，接下来可

以开始构建

一个基础的

RAG 系统。该系统

包括检索器

与生成器两

部分，具体工

作流程如下

：对于用户输

入的问题，检

索器首先搜

索与该问题

相关的文档

，接着将检索

到的文档与

初始问

题一

起传递给生

成器，即大语

言模型，最后

将模型生成

的答案返回

给用户。

首先

进行检索器

的构建，这里

我们可以基

于

VectorStoreRetriever 构建一个

Re￾triever 对象，利用向

量相似性进

行检索。

#

创建

检索器

retriever = vectorstore.as_retriever()

接下

来是生成器

部分的构建

，这里我们可

以使用 ChatOpenAI 系统

模型作为生

成器。在这一

步骤中，需要

设置 OpenAI

的 API 密钥

，并指定要使

用的具体模

型型

号。例如

，我们可以选

择使用

gpt-3.5-turbo-0125 模型

。

import os

os.environ["OPENAI_API_KEY"] = 'xxx'

from

langchain_openai import ChatOpenAI

llm

= ChatOpenAI(model="gpt-3.5-turbo-0125")

随后是输入

Prompt 的设置，LangChain

的 Prompt Hub 中

提供了多种

预设的

Prompt 模板

，适用于不同

的任务和场

景。这里我们

选择一个适

用于 RAG 任务的

Prompt。

274

董雪梅 徐文

溢 毛玉仁

from langchain import hub

# 设

置提示模板

prompt = hub.pull("rlm/rag-prompt")

最后我们需

要整合检索

与生成，这里

可以使用LangChain表

达式语言（LangChain

Execution Language，LCEL）来

方便快捷地

构建一个链

，将检索到的

文档、构建的

输入 Prompt

以及模

型的输出组

合起来。

from langchain_core.runnables import

RunnablePassthrough

from langchain_openai import

ChatOpenAI

from langchain_core.output_parsers import

StrOutputParser

# 使用

LCEL构建RAG链

rag_chain

= (

{"context": retriever

| format_docs, "question": RunnablePassthrough()}

| prompt

| llm

| StrOutputParser()

)

#

定义

文档格式化

函数

def format_docs(docs):

return

"\n\n".join(doc.page_content for doc in

docs)

# 使用RAG链

回答问题

response

= rag_chain.invoke("What is Task

Decomposition?")

print(response)

通

过以上步骤

，我们可以方

便快捷地使

用 LangChain

迅速搭建

一个基础 RAG

系

统。LangChain 提供了一

系列强大的

工具和组件

，使得构建和

整合检索与

生成过

程变

得简单而高

效。

275

第 6

章 检索

增强生成

6.5.2 RAG

的

典型应用

本

小节将介绍

RAG 系统的两个

典型应用案

例：（1）智能体（Agent）；（2）垂

域多模态模

型增强。

1.

智能

体（Agent）

RAG 在 Agent

系统中

扮演着重要

角色。在 Agent 系统

主动规划和

调用各种工

具的过程中

，需要检索并

整合多样化

的信息资源

，以更精确地

满足用户的

需求。

RAG

通过提

供所需的信

息支持，助力

Agent 在处理复杂

问题时展现

出更好的性

能。图 6.27展示了

一个经典的

Agent 框架

[50]，该框架

主要由四大

部分组成：配

置

（Profile）、记忆（Memory）、计划

（Planning）和行动（Action）。其中

记忆模块、

计

划模块与行

动模块均融

入了 RAG

技术，以

提升整体性

能。

具体而言

，（1）配置模块通

过设定基本

信息来定义

Agent 的角色，这些

信息

可以包

括

Agent 的年龄、性

别、职业等基

本属性，以及

反映其个性

和社交关系

的信

息；（2）记忆

模块存储从

环境中学习

到的知识以

及历史信息

，支持记忆检

索、记忆

更新

和记忆反思

等操作，允许

Agent

不断获取、积

累和利用知

识。在这一模

块中，

RAG 通过检

索相关信息

来辅助记忆

的读取和更

新；（3）计划模块

赋予 Agent

将复

杂

任务分解为

简单的子任

务的能力，并

根据记忆和

行动反馈不

断调整。RAG 在此

模块中通过

提供相关的

信息，帮助 Agent

更

合理有效地

规划任务；（4）行

动模块则

负

责将 Agent 的计划

转化为具体

的行动，包括

网页检索、工

具调用以及

多模态输出

等，能够对环

境或

Agent 自身状

态产生影响

，或触发新的

行动链。在这

一模块中，

RAG 通

过检索相关

信息来辅助

Agent

的决策和行

动执行。通过

这种模块化

且集成

RAG 技术

的方法，Agent 能够

更加高效和

智能地响应

用户需求，展

现出更加卓

越的

性能。

我

们以“我现在

在澳大利亚

，我想去抱考

拉，应该怎么

办呢？”这一具

体问题

276

董雪

梅

徐文溢 毛

玉仁

用户

配

置

你是一个

熟悉澳洲

生

活的向导。。。

记

忆

科伦宾野

生动物保护

区，

可以合法

拥抱考拉。。。

计

划

行动 1.

查找

允许抱考拉

的地点信息

。

2. 了解当前与

考拉互动的

规定。

3.

考虑从

当前位置到

选定地点

的

多种交通方

式。

。。。 查找结果

：龙柏考拉动

物园。。。

我现在

在澳大利亚

昆士兰

州，我

想去抱考拉

，应该

怎么办

呢？

根据您的

位置，推荐您

前

往布里斯

班或黄金海

岸，

您可以选

择布里斯班

的龙

柏考拉

动物园，或者

黄金

海岸的

科伦宾野生

动物园

和天

堂农庄。。。

智能

体

图 6.27:

Agent 框架流

程示意图。

为

例，来展示 Agent

处

理问题的流

程。在这个例

子中，用户提

出了一个明

确的需求。

Agent 将

通过以下步

骤来完成任

务：

角色配置

：首先，Agent

利用配

置模块进行

初始化，设定

其角色为专

业的旅

游顾

问，明确其任

务目标是协

助用户实现

与考拉亲密

接触的愿望

；

任务规划：针

对用户的需

求，计划模块

规划如何帮

助用户实现

“抱考拉”的

愿

望。例如确定

当前位置附

近存在考拉

的地点、了解

当地关于与

野生动物互

动的法律规

定、以及前往

目的地的方

式等。在这一

阶段，RAG

通过提

供相关

的旅

游景点和法

律法规信息

，使规划更加

精准；

信息检

索：记忆模块

首先在记忆

中检索已有

的相关信息

。如果记忆中

不包含

所有

必要的信息

，行动模块将

激活并调用

工具从外部

知识源（如旅

游网站等）

中

进行检索。在

这一过程中

，RAG 确保以最高

效率检索到

与考拉互动

最相关

的信

息；

信息整合

与决策：计划

模块将利用

上述检索到

的信息制定

最佳行动方

案。这

可能涉

及推荐特定

的地点、提供

出行建议和

强调安全须

知。RAG 在此环节

中

277

RAG

RAG

RAG

第 6

章 检索

增强生成

整

合信息，辅助

Agent 做出明智的

决策；

信息输

出：最后，行动

模块将 Agent 确定

的行动方案

以易于理解

的方式输出

给用户，包括

详细的路线

规划以及相

关地点的描

述、图像等信

息。

通过这个

例子，我们可

以清晰地看

到

Agent 框架中的

各个模块如

何协同工作

来完成一个

具体的预测

任务，其中 RAG 的

作用在于快

速检索信息

并整合知识

，为

用户提供

一个全面而

精确的解决

方案。

2. 多模态

垂直领域应

用

在前面的

章节中，我们

主要聚焦于

文本领域的

RAG

系统，而今，在

诸多涉及

到

多模态数据

的垂直领域

中，RAG 也展现出

了广阔的应

用前景。例如

，在医疗领

域

中，多模态数

据十分普遍

，包括

X 光片、MRI、CT 扫

描等影像资

料，病历、生

理

监测数据等

文本资料。这

些数据不仅

来源广泛，而

且彼此之间

存在着复杂

的相

互联系

。因此，在应对

这些任务时

，RAG 系统必须具

备融合与洞

察不同模态

数据

的能力

，以确保其精

准高效地发

挥作用。

目前

，已经出现了

一些多模态

垂直领域的

RAG

应用，例如 Ossowski 等

人提出

的医

学领域多模

态检索框架

[38]。图

6.28展示了该

框架的整个

工作流程。此

处以给

定一

张 X 光照片，询

问该照片所

对应的可能

症状这一任

务为例进行

说明。该框架

首先提取图

像与文本的

特征表示，深

入理解图像

内容与问题

语义，为检索

模块提

供丰

富的特征向

量。随后，该框

架精心设计

了一个多模

态检索模块

，利用这些特

征

向量在医

学知识库中

进行精准检

索，从而获取

与输入问题

最为相关的

信息。这些

信

息可能包括

医学案例、症

状描述、潜在

病因及治疗

方案等，它们

以文本和图

像的

多种形

式呈现。最终

，Prompt

构建模块将

这些信息进

行整合，辅助

模型生成准

确

的回答。在

本例中，模型

生成的答案

是“心肌肥大

”。

除了医疗领

域，RAG 在其他垂

直领域，如金

融

[8]、生物学 [53] 中

也展现了其

在处理专业

信息上的强

大能力，显著

提升了专业

人士的决策

效率。在各类

任务中，

278

董雪

梅 徐文溢 毛

玉仁

用户

这

张X光片的

症

状是什么？

图

像特征

文本

特征

多模态

知识库

多模

态检索器

检

索内容

T5编码

器

T5解码器

心

肌肥大

图 6.28:

多

模态垂域 RAG 框

架示意图。

除

了图片信息

[10]，RAG

在音频 [7]、视频

[52] 等其他多模

态场景中也

同样有着出

色的表现。随

着技术的进

步和数据资

源的丰富，我

们期待未来

RAG 能够在更多

垂

直领域、更

多数据模态

中发挥关键

作用。

参考文

献

[1] Josh

Achiam et al. “Gpt-4

technical report”. In: arXiv

preprint arXiv:2303.08774

(2023).

[2]

Akiko Aizawa. “An information-theoretic

perspective of tf–idf measures”.

In: IPM.

2003.

[3]

Akari Asai et al.

“Self-rag: Learning to retrieve,

generate, and critique through

self￾reflection”. In: arXiv preprint

arXiv:2310.11511 (2023).

[4] Jon

Louis Bentley. “Multidimensional binary

search trees used for

associative

searching”. In: Communications

of the ACM (1975).

[5] Sebastian Borgeaud et

al. “Improving language models

by retrieving from trillions

of tokens”. In: ICML.

2022.

[6] Sebastian Borgeaud

et al. “Improving language

models by retrieving from

trillions

of tokens”. In:

ICML. 2022.

279

第

6 章 检索

增强生成

[7]

David M Chan et

al. “Using external off-policy

speech-to-text mappings

in contextual

end-to-end automated speech recognition”.

In: arXiv preprint

arXiv:2301.02736

(2023).

[8] Jian Chen

et al. “FinTextQA: A

Dataset for Long-form Financial

Question Answer￾ing”. In: arXiv

preprint arXiv:2405.09980 (2024).

[9]

Jiangui Chen et al.

“A Unified Generative Retriever

for Knowledge-Intensive Lan￾guage Tasks

via Prompt Learning”. In:

SIGIR. 2023.

[10] Wenhu

Chen et al. “Re-imagen:

Retrieval-augmented text-to-image generator”. In:

arXiv preprint arXiv:2209.14491 (2022).

[11] Mayur Datar et

al. “Locality-sensitive hashing scheme

based on p-stable distribu￾tions”.

In: SoCG. 2004.

[12]

Hervé Déjean, Stéphane Clinchant,

and Thibault Formal. “A

Thorough Compar￾ison of Cross-Encoders

and LLMs for Reranking

SPLADE”. In: arXiv preprint

arXiv:2403.10407 (2024).

[13] Mohamad

Dolatshah, Ali Hadian, and

Behrouz Minaei-Bidgoli. “Ball*-tree: Effi￾cient

spatial indexing for constrained

nearest-neighbor search in metric

spaces”. In:

arXiv preprint

arXiv:1511.00628 (2015).

[14] Paulo

Finardi et al. “The

Chronicles of RAG: The

Retriever, the Chunk and

the

Generator”. In: arXiv

preprint arXiv:2401.07883 (2024).

[15]

Tiezheng Ge et al.

“Optimized product quantization for

approximate nearest neigh￾bor search”.

In: CVPR. 2013.

[16]

Samuel Humeau et al.

“Poly-encoders: Transformer architectures and

pre-training

strategies for fast

and accurate multi-sentence scoring”.

In: arXiv preprint

arXiv:1905.01969

(2019).

[17] Gautier Izacard

et al. “Atlas: Few-shot

learning with retrieval augmented

language

models”. In: Journal

of Machine Learning Research

(2023).

[18] Herve Jegou,

Matthijs Douze, and Cordelia

Schmid. “Product quantization for

near￾est neighbor search”. In:

IEEE transactions on pattern

analysis and machine intel￾ligence

33.1 (2010), pp. 117–128.

[19] Hervé Jégou et

al. “Searching in one

billion vectors: re-rank with

source coding”. In:

2011

IEEE International Conference on

Acoustics, Speech and Signal

Processing

(ICASSP). 2011, pp.

861–864.

280

董

雪梅 徐文溢

毛玉仁

[20] Huiqiang Jiang et

al. “Longllmlingua: Accelerating and

enhancing llms in long

context scenarios via prompt

compression”. In: arXiv preprint

arXiv:2310.06839

(2023).

[21] Chao

Jin et al. “RAGCache:

Efficient Knowledge Caching for

Retrieval-Augmented

Generation”. In: arXiv

preprint arXiv:2404.12457 (2024).

[22]

Nikhil Kandpal et al.

“Large language models struggle

to learn long-tail knowl￾edge”.

In: ICML. 2023.

[23]

Vladimir Karpukhin et al.

“Dense passage retrieval for

open-domain question an￾swering”. In:

arXiv preprint arXiv:2004.04906 (2020).

[24] Omar Khattab and

Matei Zaharia. “Colbert: Efficient

and effective passage search

via contextualized late interaction

over bert”. In: SIGIR.

2020.

[25] Omar Khattab

et al. “Demonstrate-search-predict: Composing

retrieval and lan￾guage models

for knowledge-intensive nlp”. In:

arXiv preprint arXiv:2212.14024

(2022).

[26] Gangwoo Kim et

al. “Tree of clarifications:

Answering ambiguous questions with

retrieval-augmented large language models”.

In: EMNLP. 2023.

[27]

Mike Lewis et al.

“Bart: Denoising sequence-to-sequence pre-training

for nat￾ural language generation,

translation, and comprehension”. In:

arXiv preprint

arXiv:1910.13461 (2019).

[28] Patrick Lewis et

al. “Retrieval-augmented generation for

knowledge-intensive nlp

tasks”. In:

NeurIPS. 2020.

[29] Xiaoxi

Li et al. “From

matching to generation: A

survey on generative information

retrieval”. In: arXiv preprint

arXiv:2404.14851 (2024).

[30] Yuxin

Liang et al. “Learning

to trust your feelings:

Leveraging self-awareness in

llms

for hallucination mitigation”. In:

arXiv preprint arXiv:2401.15449 (2024).

[31] Yu A Malkov

and Dmitry A Yashunin.

“Efficient and robust approximate

nearest

neighbor search using

hierarchical navigable small world

graphs”. In: IEEE trans￾actions

on pattern analysis and

machine intelligence (2018).

[32]

Yury Malkov et al.

“Approximate nearest neighbor algorithm

based on navigable

small

world graphs”. In: Information

Systems 45 (2014), pp.

61–68.

[33] Alex Mallen

et al. “When not

to trust language models:

Investigating effectiveness

of parametric

and non-parametric memories”. In:

ACL. 2023.

281

第

6 章

检索增强生

成

[34] Potsawee

Manakul, Adian Liusie, and

Mark JF Gales. “Selfcheckgpt:

Zero￾resource black-box hallucination detection

for generative large language

models”.

In: EMNLP. 2023.

[35] Yuren Mao et

al. “FIT-RAG: Black-Box RAG

with Factual Information and

Token

Reduction”. In: ACM

Transactions on Information Systems

(2024).

[36] Kevin Meng

et al. “Locating and

editing factual associations in

GPT”. In: NeurIPS.

2022.

[37] Stanislav Morozov and

Artem Babenko. “Non-metric similarity

graphs for maxi￾mum inner

product search”. In: Advances

in Neural Information Processing

Systems

31 (2018).

[38]

Timothy Ossowski and Junjie

Hu. “Multimodal prompt retrieval

for generative vi￾sual question

answering”. In: ACL. 2023.

[39] James Jie Pan,

Jianguo Wang, and Guoliang

Li. “Survey of vector

database man￾agement systems”. In:

arXiv preprint arXiv:2310.14021 (2023).

[40] Ella Rabinovich et

al. “Predicting Question-Answering Performance

of

Large Language Models

through Semantic Consistency”. In:

arXiv preprint

arXiv:2311.01152 (2023).

[41] Colin Raffel et

al. “Exploring the limits

of transfer learning with

a unified text-to￾text transformer”.

In: The Journal of

Machine Learning Research (2020).

[42] Ori Ram et

al. “In-context retrieval-augmented language

models”. In: Transactions

of

the Association for Computational

Linguistics (2023).

[43] Stephen

Robertson, Hugo Zaragoza, et

al. “The probabilistic relevance

framework:

BM25 and beyond”.

In: Foundations and Trends®

in Information Retrieval (2009).

[44] Ferdinand Schlatt, Maik

Fröbe, and Matthias Hagen.

“Investigating the Effects of

Sparse Attention on Cross-Encoders”.

In: ECIR. 2024.

[45]

Weijia Shi et al.

“Replug: Retrieval-augmented black-box language

models”. In:

arXiv preprint

arXiv:2301.12652 (2023).

[46] Hanshi

Sun et al. “Triforce:

Lossless acceleration of long

sequence generation with

hierarchical

speculative decoding”. In: arXiv

preprint arXiv:2404.11912 (2024).

[47]

Weiwei Sun et al.

“Is chatgpt good at

search? investigating large language

models

as re-ranking agent”.

In: arXiv preprint arXiv:2304.09542

(2023).

[48] Yi Tay

et al. “Transformer memory

as a differentiable search

index”. In: Advances

in

Neural Information Processing Systems

35 (2022), pp. 21831–21843.

282

董雪梅 徐

文溢 毛玉仁

[49]

Hugo Touvron et al.

“Llama 2: Open foundation

and fine-tuned chat models”.

In:

arXiv preprint arXiv:2307.09288

(2023).

[50] Lei Wang

et al. “A survey

on large language model

based autonomous agents”. In:

Frontiers of Computer Science

18 (2024), p. 186345.

[51] Yujing Wang et

al. “A Neural Corpus

Indexer for Document Retrieval”.

In: ArXiv

abs/2206.02743 (2022).

URL: https://api.semanticscholar.org/CorpusID:

249395549.

[52]

Zhenhailong Wang et al.

“Language models with image

descriptors are strong few￾shot

video-language learners”. In: NeurIPS.

2022.

[53] Zichao Wang

et al. “Retrieval-based controllable

molecule generation”. In: ICLR.

2022.

[54] Jason Wei

et al. “Chain of

Thought Prompting Elicits Reasoning

in Large Language

Models”.

In: NeurIPS. 2022.

[55]

David H Wolpert and

William G Macready. “No

free lunch theorems for

optimiza￾tion”. In: IEEE transactions

on evolutionary computation 1

(1997), pp. 67–82.

[56]

Mingrui Wu and Sheng

Cao. “LLM-Augmented Retrieval: Enhancing

Retrieval

Models Through Language

Models and Doc-Level Embedding”.

In: arXiv preprint

arXiv:2404.05825

(2024).

[57] Haoyan Yang

et al. “Prca: Fitting

black-box large language models

for retrieval ques￾tion answering

via pluggable reward-driven contextual

adapter”. In: EMNLP. 2023.

[58] Wenhao Yu et

al. “Generate rather than

retrieve: Large language models

are strong

context generators”.

In: ICLR. 2023.

[59]

Wenhao Yu et al.

“Improving Language Models via

Plug-and-Play Retrieval Feed￾back”. In:

arXiv preprint arXiv:2305.14002 (2023).

[60] Zichun Yu et

al. “Augmentation-Adapted Retriever Improves

Generalization of

Language Models

as Generic Plug-In”. In:

arXiv preprint arXiv:2305.17331

(2023).

[61] Yujia Zhou et

al. “DynamicRetriever: A Pre-training

Model-based IR System with

Neither Sparse nor Dense

Index”. In: ArXiv abs/2203.00537

(2022). URL: https:

//api.semanticscholar.org/CorpusID:247187834.

283
