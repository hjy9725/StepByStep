版权信息

C O P Y R

I G H T

书名：Transformer自然语言

处理实战：使用

Hugging

Face Transformers库构建NLP应

用

作者：【澳大利亚】路易斯

·汤斯顿 【瑞士】莱安德罗·冯

·韦

拉 【法】托马斯·沃尔夫

译

者：叶伟民；叶志远

出版社

：机械工业出版社

出版时

间：2023年12月

ISBN：9787111741923

字数：181千字

本书由

机械工业出版社有限公

司授权得到APP电子版制作

与发行

版权所有·侵权必

究

O'Reilly Media, Inc.介绍

O'Reilly以“分享创新知识

、改变世界”为己任。40多年来

我们一直

向企业、个人提

供成功所必需之技能及

思想，激励他们创新并做

得更

好。

O'Reilly业务的核心是独

特的专家及创新者网络

，众多专家及创新者

通过

我们分享知识。我们的在

线学习（Online Learning）平台提供

独家的

直播培训、互动学习、认证

体验、图书、视频，等等，使客

户

更容易获取业务成功

所需的专业知识。几十年

来O'Reilly图书一直被

视为学习

开创未来之技术的权威

资料。我们所做的一切是

为了帮助各

领域的专业

人士学习最佳实践，发现

并塑造科技行业未来的

新趋势。

我们的客户渴望

做出推动世界前进的创

新之举，我们希望能助他

们一

臂之力。

业界评论

“O'Reilly

Radar博

客有口皆碑。”

——Wired

“O'Reilly凭借一系列

非凡想法（真希望当初我

也想到了）建立了数

百万

美元的业务。”

——Business 2.0

“O'Reilly Conference是聚集关键

思想领袖的绝对典范。”

——CRN

“一

本O'Reilly的书就代表一个有用

、有前途、需要学习的主题

。”

——Irisb Times

“Tim是位特立独行的商人，他

不光放眼于最长远、最广

阔的领域，并

且切实地按

照Yogi Berra的建议去做了：‘如果你

在路上遇到岔路

口，那就

走小路。’回顾过去，Tim似乎每

一次都选择了小路，而且

有

几次都是一闪即逝的

机会，尽管大路也不错。”

——Linux

Journal

本

书赞誉

Transformer预训练语言模型

正在席卷整个NLP领域，而

Hugging Face Transformers库

则使其更易于使用。读者

可以跟随作

者的脚步，尽

情领略这一NLP领域最新突

破的奥妙。本书作者在NLP工

程与研究领域有深厚造

诣，通过本书，他们以通俗

易懂的方式巧妙地

将研

究成果与现实应用相结

合，提供了深刻见解。本书

是一本难得的

佳作，从多

语言到高效模型，从问答

系统到文本生成，全面介

绍了当

前NLP领域最重要的

方法与应用。本书每章都

以丰富的代码示例为基

础，提供细致讲解，并突出

最佳实践和实际考虑因

素，使读者能够轻

松地将

Transformer模型应用于现实世界。无

论你是NLP新手还是老

手，本

书都将增进你对NLP的理解

，并提升你开发和部署先

进模型的速

度。

——Sebastian Ruder，Google DeepMind

Transformer已经成为

NLP领域的新范式，而Hugging Face是将

Transformer应

用在产品和研究中的先

驱者。本书由来自

Hugging Face公司的

Lewis Tunstall、Leandro von Werra和

Thomas Wolf共同撰写，对Transformer提供了便

捷而实用的介绍。本

书介

绍了Transformer模型的基础概念，由

浅入深地讲解了

Transformer的实际

运用，还包括训练过程和

将Transformer应用于生

产等实际问

题。在阅读本书时，深入、丰

富的内容和清晰的示例

将使

你信心倍增，对任何

想要学习Transformer的人来说，本书

都是首选工

具书。

——Delip Rao，

Natural Language Processing

and Deep Learning with P

yTorch的作者

将复杂性变得简单！这是

一本介绍如何将Transformer应用于

NLP领

域，以及围绕它们不断

成长的技术生态系统Hugging Face的

珍贵书

籍。无论你对这些

词汇的理解是只停留在

概念上还是已经有了扎

实的

掌握，作者都会用幽

默、科学的严谨性和大量

代码示例来引导你深入

了解这个酷炫的技术领

域中最深层次的奥秘。从

“现成的预训练模

型”到“自

定义模型”，从性能到标注

缺失问题，本书内容几乎

涵盖

了每一个机器学习

工程师会在实际应用中

遇到的挑战，并提供了先

进

的解决方案，这本书极

有可能会在未来几年成

为NLP领域的标准工具

书。

——Luca Perrozzi，博

士，埃森哲公司数据科学

和机器学习副经

理

序

当

你读到这里时，一件神奇

的事情正在悄无声息地

发生：我在2021年

11月产生的这

些想法，通过黑色字迹经

由你的眼睛穿过你的大

脑皮

层，转换为文字、概念

和情感，成功地侵入了你

的大脑。很有可能它

们暂

时没有引起你的注意，但

仍在这个高度竞争的环

境中扎下了根，

很可能在

你与他人分享这些想法

时，它们就会“破土”而出。感

谢语

言的存在，让思想成

为经空气传播的高传染

性的“脑部病菌”，一旦

染上

就无药可救。

所幸，大多数

“脑部病菌”是无害的，并且

有一些对我们大有裨益

。

事实上，人类的“脑部病菌

”构成了我们最宝贵的两

个财富：知识与

文化。就像

肠道进行消化需要益生

菌一样，没有这些对我们

有益的

“脑部病菌”，我们就

很难进行思考。你的大部

分思想其实都不是你

自

身产生的：这些思想在“传

染”你之前，它们已经在其

他人的大脑

中产生、成长

、进化。所以，如果我们想造

出智能机器，就必须要找

到一种方法把人类的思

想“传染”给它们。

好消息是

，另一件神奇的事情在过

去几年也一直在发生着

：深度学习

的突破性进展

催生出了强大的语言模

型。在你阅读本书之前，你

可能

已经感受过语言模

型的奇妙，比如GPT-3，只需要输

入一段简短的提示

语，比

如“写一个青蛙遇到鳄鱼

的故事”，它就能写出完整

的故事。

尽管它与莎士比

亚写的作品还有明显的

差距，但读起来确实很难

让人

相信这是由人工神

经网络编写的。其实我在

行文时借助了GitHub的

Copilot，你能分

辨哪些内容是我写的吗

？

目前，这场人工智能革命

已不仅局限于文本生成

，它涵盖了自然语言

处理

（NLP）整个领域，从文本分类到

摘要、翻译、问答、聊天机器

人、自然语言理解（NLU）等。只要

有语言、语音或文字，就存

在NLP

的用武之地。在生活中

，我们已经可以向手机询

问明天的天气情况，

或通

过与虚拟助手对话来解

决问题，还可以通过搜索

引擎查到想要的

结果。但

这项技术是如此的新，最

好的可能还没有到来。

正

如大多数的科技进步，这

场NLP的革命是数百名无名

英雄默默无闻努

力工作

的结果，其中有三大关键

因素：

●Transformer是2017年Google发表的一篇名

为

“Attention Is

All You Need”

（https://arxiv.org/abs/1706.03762）的开创性论文中提出

的神经

网络架构。只用了

短短几年时间，Transformer就颠覆了

此前RNN的循

环结构与CNN的卷

积结构，占领了技术的制

高点。Transformer架构在

处理长序列

数据和大型数据集方面

表现得非常出色，以至于

它的用途

已不仅仅局限

于NLP领域，像图像处理等领

域也有大量的应用。

●在大

多数项目中，很难使用一

个大型数据集来从头开

始训练一个模

型。在实际

工作中，更常用的做法是

直接下载一个在通用数

据集上预

训练过的模型

，然后在自己的（更小的）数

据集上进行微调。自从

2010年

以来，使用预训练模型是

图像处理领域的主流方

式，但在NLP领

域，该方式仅限

于与上下文无关的词嵌

入（单个词汇的密集向量

表

示）。比如，“bear”这个词在“teddy bear”和“to bear”中

有

相同的预训练嵌入。不

过随即在2018年的几篇论文

中提出的语言模型

就解

决了这个问题，将预训练

与微调变得更加通用，这

完全改变了游

戏规则。

●Hugging Face提

供的模型仓库从某种意

义上来说也间接改变了

游戏

规则。早期，预训练模

型在训练完后并没有被

统一管理起来，因此想

要

获得一个可用的预训练

模型并不容易。墨菲定律

告诉我们，总会有

一些PyTorch用

户只能找到适用于TensorFlow而不

能用于PyTorch的模

型，反之亦然

。在获得一个预训练模型

后，找到对其做微调的方

式并

不是件容易的事。而

Hugging Face的Transformers库就肩负着这样的

使

命，它完全开源，并同时支

持PyTorch和TensorFlow，我们只需要从

Hugging Face

Hub下载

一个预训练模型，根据任

务进行配置、微

调，并进行

评估。此库的用户数正在

迅速增长，截至2021年第四季

度，已有5000多个组织使用，且

每个月使用p i p方式安装的

次数超

过400万。此外，Hugging Face

Transformers库的生

态系统正逐渐

蔓延到NLP领

域之外，也可以将其用于

图像处理。最后，还可以从

Hugging Face Hub下载数据集来训练或评

估微调的模型。

想了解更

多内容，请阅读本书。本书

由Hugging Face的开源开发者所

撰写

，作者包括了Hugging Face Transformers库的创建者

。本书具

备一定的广度和

深度，因此受众群体广泛

。它涵盖了Transformer架构

本身的知

识点，以及围绕它的整个

生态系统。读者可使用

Jupyter

notebook跟

进每个案例，一步一步地

构建起模型。本书作者

在

训练大型Transformer模型方面经验

丰富，书中提供了大量的

提示与

技巧，并尽可能地

让内容通俗易懂。

总之，如

果你对NLP领域具有浓厚兴

趣，想要获知目前最先进

的NLP产

品的原理以及训练

方式，那么本书一定值得

阅读。千言万语，尽在书

中

。

Aurélien Géron

2021年11月于新西兰奥克兰

前

言

自2017年推出以来，Transformer已成为

学术界和工业界处理各

种自然

语言处理（NLP）任务的

事实标准。你不知道的是

，你很可能已经与

Transformer有过了

互动：Google目前运用BERT模型来增

强搜索引擎，

帮助其更好

地理解用户的搜索内容

。与此同时，OpenAI推出的GPT系列

模

型因其能生成类人表达

的文本和图像，从而反复

登上主流媒体的头

版头

条。Transformer甚至正在为GitHub的Copilot（一种自

动编写代

码的AI程序）等应

用提供支持，如图P-1所示，它

可以将评论转换为源

代

码，自动构建神经网络！

图

P-1：来自GitHub Copilot的一个例子——给定一

个任务的简要描

述，随即

生成了整个类的细节建

议（class之后的所有内容均为

自动

生成的）

是什么让Transformer几

乎一夜之间改变了整个

AI领域？就像许多伟大

的科

学突破一样，它是在许多

先进的研究成果之上取

得的突破，比如

注意力模

型、迁移学习和可伸缩神

经网络。

尽管它异常强大

，但任何新方法想要在业

界获得广泛的认可与使

用，

都需要借助某种工具

来降低门槛。Hugging Face推出的Transformers

库（https://oreil.ly/Z79jF）响

应了这一号召，使从业者

能够轻松

地使用、训练和

分享Transformer模型。这加速促成了

Transformer应

用的百花齐放，目前该

库正在被5000多个组织使用

。本书内容将提供

训练和

优化Transformer模型的案例，并将其

应用到实际当中。

这本书

适合谁

本书适合AI领域的

数据科学家和机器学习

工程师，以及对Transformer

略有耳闻

但缺乏学习渠道，想将Transformer付

诸实践的群体阅读。本

书

不会介绍机器学习相关

基础知识，读者需要熟悉

Python编程，并且

了解常见的深

度学习框架，例如PyTorch（https://pytorch.org）和

TensorFlow（https://www.tensorflow.org），以及

有使用GPU训练模

型的实际

经验。本书会重点讲解Transformers库

的PyTorch API，第2

章还会介绍如何使

用TensorFlow来运行案例。

了解以下

相关资源将有助于你阅

读本书：

本书已由机械工

业出版社翻译出版，书名

为《机器学习实战：基于

Scikit-Learn、Keras和

TensorFlow（原书第2版）》（书号为978-7-

111-66597-7）。

●Hands-On Machine Learning

with Scikit￾Learn and TensorFlow （O'Reilly），作者Aurélien Géron

●Deep Learning for Coders with fastai

and PyTorch

（O'Reilly），作

者Jeremy Howard和Sylvain Gugger

●Natural

Language Processing with PyTorch（O'Reilly），

作者Delip Rao和Brian

McMahan

●The Hugging Face课程（https://oreil.ly/n3MaR），由

Hugging Face的开

源团队提供

你将学到什

么

本书的目标是让更多

开发者能够构建自己的

NLP应用程序。为此，书中

介绍

了大量实际的案例，并在

必要时穿插理论来讲解

。本书风格偏向

实战，建议

读者按照书中步骤运行

代码示例进行实验。

本书

涵盖Transformer在NLP领域的主要应用

，几乎每章（有少数例

外）都

会介绍一个实际任务，并

结合真实的用例和数据

集。此外，每

章还会介绍一

些前沿的概念。以下是每

章任务与主题的简单概

述：

●第1章将介绍Transformer模型和Hugging Face生

态系统。

●第2章将重点介绍

情感分析任务（一种常见

的文本分类问题）以及

Trainer API。

●第

3章将深入探讨Transformer架构，以为

接下来的章节做准备。

●第

4章将讲述在多语言中识

别文本中的实体（一种词

元分类问题）的

任务。

●第5章

将讲述Transformer模型生成文本的

能力，并介绍解码策略和

度量指标。

●第6章将深入挖

掘文本摘要这个复杂的

序列到序列的任务，并介

绍用

于此任务的度量指

标。

●第7章将聚焦于构建基

于评论的问答系统，并介

绍如何基于Haystack

进行信息检

索。

●第8章将聚焦于模型性

能。我们将研究意图识别

（一种序列分类问

题）的任

务，并探索知识蒸馏、量化

和剪枝等技术。

●第9章将探

讨在缺乏大量标注数据

的情况下提高模型性能

的方法。我

们将构建一个

针对GitHub

Issue的标注器，并探索零

样本分类技术和

数据增

强技术。

●第10章将展示如何

从头开始构建和训练用

于自动填充Python源代码

的模

型。我们将研究流式数据

集和大规模训练任务，并

构建自己的词

元分析器

。

●第11章将探讨Transformer面临的挑战

以及将这个模型应用于

其他领

域的一些新研究

。

Hugging Face Transformers库为使用和训练Transformer模型提

供

了多个抽象。本书将从

易于使用的pipeline开始，pipeline仅用短

短

几行代码就可以将文

本示例传到模型中，并进

行结果的预测。随后，

我们

将介绍词元分析器、模型

类和Trainer API，掌握这些之后就可

以为用例训练模型。紧接

着，我们将介绍如何使用

Hugging Face Accelerate库替换Trainer，以完全控制训练

循环，

并带领读者从头开

始训练大规模Transformer模型！尽管

每章内容都相

对独立，但

随着任务难度逐渐增加

，后续章节的难度也会增

加。因

此，我们建议先从第

1章和第2章开始，然后再选

择最感兴趣的章节进

行

阅读与实践。

除了Hugging Face Transformers库和Hugging Face

Accelerate

库

，书中还将广泛使用Hugging Face Datasets库，它

可以与其他库

无缝集成

。Datasets库提供了与Pandas相似的数据

处理功能，但是

Datasets在设计上

旨在处理大型数据集和

机器学习任务。

有了这些

工具，你就拥有了应对几

乎任何NLP挑战所需的一切

！

软件和硬件要求

由于本

书侧重实战，我们强烈建

议读者在阅读每章时运

行代码示例。

因此需要一

台配备NVIDIA GPU的PC来训练模型，此

外，以下几个免费

的在线

工具也可供学习时使用

：

●Google Colaboratory（https://oreil.ly/jyXgA）

●Kaggle Notebooks（https://oreil.ly/RnMP3）

●Paperspace Gradient

Notebooks（https://oreil.ly/mZEKy）

想要成功运行用例，读者

需要按照书中介绍的GitHub仓

库中提供的安

装指南进

行操作，本书所有代码与

指南托管在

https://github.com/nlp-with-transformers/notebooks。

本书大部分

章节使用NVIDIA Tesla

P100 GPU完成，其显存为

16GB。一些免费平台提供显存

较小的GPU，因此在训练模型

时要根据实

际情况缩减

训练规模。

排版约定

本书

中使用以下排版约定：

斜

体（Italic）

表示新的术语、URL、电子邮

件地址、文件名和文件扩

展名。

等宽字体（Constant width）

用于程序

清单，以及段落中的程序

元素，例如变量名、函数名

、数据

库、数据类型、环境变

量、语句以及关键字。

等宽

粗体（Constant

width bold）

表示应由用户直接

输入的命令或其他文本

。

等宽斜体（Constant width italic）

表示应由用户

提供的值或由上下文确

定的值替换的文本。

该图

示表示提示或建议。

该图

示表示一般性说明。

该图

示表示警告或注意。

示例

代码

可以从https://github.com/nlp-with-transformers/notebooks下载

补充材

料（示例代码、练习、勘误等

）。

这里的代码是为了帮助

你更好地理解本书的内

容。通常，可以在程序

或文

档中使用本书中的代码

，而不需要联系O'Reilly获得许可

，除非

需要大段地复制代

码。例如，使用本书中所提

供的几个代码片段来编

写一个程序不需要得到

我们的许可，但销售或发

布O'Reilly的示例代

码则需要获

得许可。引用本书的示例

代码来回答问题也不需

要许可，

将本书中的很大

一部分示例代码放到自

己的产品文档中则需要

获得许

可。

非常欢迎读者

使用本书中的代码，希望

（但不强制）注明出处。注明

出处时包含书名、作者、出

版社和ISBN，例如：

Natural Language Processing with

Transformers，作者

Lewis Tunstall、Leandro von Werra和Thomas Wolf，由

O'Reilly出

版，书号978-1-098-13679-6。

如果读者觉得对

示例代码的使用超出了

上面所给出的许可范围

，欢迎

通过permission@oreilly.com联系我们。

O'Reilly在线

学习平台（O'Reilly Online Learning）

40多年来，O'Reilly Media致力于

提供技术和商业培训、知

识和卓越

见解，来帮助众

多公司取得成功。

我们拥

有独一无二的专家和革

新者组成的庞大网络，他

们通过图书、

文章、会议和

我们的在线学习平台分

享他们的知识和经验。O'Reilly

的

在线学习平台允许你按

需访问现场培训课程、深

入的学习路径、交

互式编

程环境，以及O'Reilly和200多家其他

出版商提供的大量文本

和

视频资源。有关的更多

信息，请访问http://oreilly.com。

如何联系我

们

对于本书，如果有任何

意见或疑问，请按照以下

地址联系本书出版

商。

美

国：

O'Reilly Media, Inc.

1005 Gravenstein Highway

North

Sebastopol，CA 95472

中国：

北京市西城区西

直门南大街2号成铭大厦

C座807室（100035）

奥莱利技术咨询（北

京）有限公司

要询问技术

问题或对本书提出建议

，请发送电子邮件至

errata@oreilly.com.cn。

本书

配套网站https://oreil.ly/nlp-with-transformers上列出了勘

误

表、示例以及其他信息。

关

于书籍和课程的新闻和

信息，请访问我们的网站

http://oreilly.com。

我们在Facebook上的地址：http://facebook.com/oreilly

我们在

Twitter上的地址：http://twitter.com/oreillymedia

我们在YouTube上的地

址：http://www.youtube.com/oreillymedia

致谢

写一本关于机器

学习中发展最快的领域

之一的书，离不开很多人

的帮

助。首先要感谢出色

的O'Reilly团队，特别是Melissa Potter、

Rebecca Novack和Katherine Tozer，感谢他

们的支持和建议。当

然，这

本书也受益于许多审校

人员的帮助，他们花费了

大量的时间来

提供宝贵

的反馈。特别感谢Luca Perozzi、Hamel

Husain、

Shabie Iqbal、Umberto Lupo、Malte Pietsch、Timo Möller和

Aurélien Géron的详

细审校。感谢deepset

（https://www.deepset.ai）的Branden Chan帮助扩展

Haystack库，

以支持第7章的用例。本

书中优美的插图归功于

令人惊叹的

Christa

Lanz（https://christalanz.ch），是她让这本

书更具特

色。另外，本书还

有幸得到整个Hugging Face技术团队

的支持。非常

感谢Quentin Lhoest回答了

无数关于Datasets的问题、

Lysandre

Debut对Hugging Face Hub相关

事项的帮助，以及

Sylvain Gugger在Accelerate方面

的帮助，还有Joe Davison对于在

第9章

零样本学习方面的启发

。还要感谢Sidd Karamcheti和整个

Mistral团队（https://oreil.ly/aOYLt）为

GPT-2调整稳定性，使第

10章成为

可能。本书完全使用Jupyter notebook编写

，感谢

Jeremy

Howard和Sylvain Gugger创建了像fastdoc

（https://oreil.ly/yVCfT）这样的

出色工具，使这一切成为

可能。

Lewis：感谢Sofia一直以来对我

的支持和鼓励——否则，这本

书就不

会存在。经历了漫

长的写作阶段，我们终于

可以再次享受周末的快

乐

时光！

Leandro：感谢Janine，在这一年中

的许多深夜和繁忙的周

末，她的

耐心和支持给了

我很大的鼓励。

Thomas：首先我要

感谢Lewis和Leandro提出写这本书的

想法，并大力

推动以如此

美丽和易于理解的方式

编写本书并出版。我还要

感谢

Hugging Face团队的所有成员，感

谢他们相信AI的使命是一

项社区工

作，感谢整个NLP/AI社

区与我们一起建立和使

用我们在本书中描述的

程序和研究结果。

相对于

我们完成的工作，整个NLP/AI社

区所走过的旅程才是真

正重要

的，今天有幸与成

千上万的社区成员和像

你一样的读者一起走这

条道

路，我们从心底里感

谢你们所有人。

第1章

欢迎

来到Transformer的世界

A. Vaswani et al., “Attention Is

All You Need”

（https://arxiv.org/abs/1706.03762），（2017）.这篇论文的

标题

非常夸张，以至于不

下50篇后续论文（https://oreil.ly/wT8Ih）在

标题中

都包含了“all

you need”!

2017年，Google的研究人员

发表了一篇论文，提出了

一种用于序列建

模的新

型神经网络架构 。这种架

构称为Transformer，在机器翻译任

务

上，该架构在翻译质量和

训练成本方面都优于循

环神经网络

（RNN）。

J. Howard and S. Ruder，“Universal

Language Model Fine￾Tuning for Text Classification”

（https://arxiv.org/abs/1801.06146），（2018）.

同时，一种名

为ULMFiT的高效迁移学习方法

表明，在非常庞大且多样

化的语料库上训练长短

期记忆（LSTM）网络可以产生最

先进的文本分

类器，并且

只需要很少的标注数据

。

A. Radford et

al., “Improving Language Understanding by

Generative

Pre-Training”（https://openai.com/blog/language￾unsupervised），（2018）.

J. Devlin et al., “BERT:Pre-Training

of Deep Bidirectional

Transformers for Language

Understanding”

（https://arxiv.org/abs/1810.04805），（2018）.

这些研究催生了如今两

个最著名的Transformer模型类别：生

成预训练

Transformer（Generative Pretrained Transformer，GPT）

和基

于Transformer的双向

编码器表示

（Bidirectional Encoder Representations from

Transformers

，BERT） 。通过将Transformer架构

与无监督学习相结合，不

需要从

头开始训练这些

模型即可完成特定任务

，并打破了几乎所有NLP基准

。

自GPT和BERT发布以来，涌现了很

多Transformer模型，具体模型和时

间

线如图1-1所示。

要想更上一

层楼，我们不仅需要知其

然，还需要知其所以然。因

此我

们需要先解释一下

如下概念：

图1-1：Transformer大事记

●编码

器-解码器框架

●注意力机

制

●迁移学习

本章我们将

介绍通用于所有Transformer模型的

核心概念，讲述它们擅

长

的任务，最后介绍由对应

工具和库组成的Hugging Face生态系

统。

我们先从编码器-解码

器框架和Transformer兴起之前的架

构开始。

1.1

编码器-解码器框

架

在Transformer出现之前，NLP的最新技

术是LSTM等循环架构。这些架

构通过在神经网络连接

使用反馈循环，允许信息

从一步传播到另一

步，使

其成为对文本等序列数

据进行建模的理想选择

。如图1-2左侧所

示，RNN接收一些

输入（可以是单词或字符

），将其馈送给神经网络，

然

后输出一个称为隐藏状

态的向量。同时，模型通过

反馈循环将信息

反馈给

自身，然后在下一步中使

用。如果我们按照图1-2右侧

所示“展

开”循环，可以更清

楚地看到这一点：RNN将有关

其每一步的状态信息

传

给序列中的下一步操作

。这点令RNN可以跟踪前面步

骤中的信息，并

将其用于

输出预测。

图1-2：RNN架构展开

这

些架构曾经（并将继续）广

泛用于NLP任务、语音处理和

时间序列。

你可以在Andrej Karpathy的博

客

“The Unreasonable Effectiveness of Recurrent Neural

Ne

tworks”（https://oreil.ly/Q55o0）找到对它们能力的精

彩阐述。

I. Sutskever, O. Vinyals,

and Q.V. Le, “Sequence to Sequence

Learning with Neural Networks”

（https://arxiv.org/abs/1409.3215）, （2014）.

RNN发挥重要作用的

一个领域是机器翻译系

统，其目标是将一种语言

中

的单词序列映射到另

一种语言。此类任务通常

使用编码器-解码器或序

列到序列架构 来解决，这

些架构非常适合输入和

输出都是任意长度

序列

的情况。编码器将输入序

列的信息编码为通常称

为最后隐藏状态

的数字

表示。然后编码器将该状

态传给解码器，解码器生

成输出序

列。

通常，编码器

和解码器组件可以是能

够对序列进行建模的任

何类型的

神经网络架构

。图1-3中的成对RNN说明了这一

点，其中英语句子

“Transformers are great!”编码为

隐藏状态向量，然后解码

以产

生德语译文“Transformer

sind grossartig!”输入字

符通过编码

器按顺序馈

送，输出字符从上到下一

次生成一个。

图1-3：采用成对

RNN的编码器-解码器架构（具

体循环的层数通常会

比

此处显示的要多得多）

虽

然简单优雅，但这种架构

的一个弱点是编码器的

最终隐藏状态会产

生信

息瓶颈：它必须表示整个

输入序列的含义，因为解

码器在生成输

出时只能

靠它来读取全部内容。从

而很难处理长序列，因为

当序列过

长时，在将所有

内容压缩为单个固定表

示的过程中可能会丢失

序列开

头的信息。

D. Bahdanau,

K. Cho, and Y. Bengio, “Neural

Machine

Translation by Jointly Learning to

Align and Translate”

（https://arxiv.org/abs/1409.0473）, （2014）.

幸运的

是，有一种方法可以摆脱

这一瓶颈，就是允许解码

器访问编码

器的所有隐

藏状态。这种通用机制称

为注意力 。它是许多现代

神经

网络架构中的关键

组件。了解整合了注意力

机制的RNN能够帮助我们更

好地理解Transformer架构。接下来我

们深入了解一下注意力

机制。

1.2

注意力机制

注意力

机制的主要思想是，编码

器不再像图1-3那样对整个

输入序列只

生成一个状

态了，而是为每个表示都

生成一个状态，即解码器

可以访

问编码器所有隐

藏状态。但是，同时处理所

有状态会给解码器带来

巨

大的输入数量，因此需

要一些机制来按优先级

使用状态。这就是注意

力

的用武之地：它让解码器

在每个解码时间步为每

个编码器状态分配

不同

量的权重或“注意力”。此过

程如图1-4所示，其中展示了

注意力

在预测输出序列

中的词元sind中的作用。

图1-4：整

合了注意力机制的成对

RNN的编码器-解码器架构

当

涉及机器翻译时，对于一

组源语言单词和目标语

言单词之间的对应

关系

有时可能是非常明显和

直接的。例如，英文句子“The cat sat

on

the mat”翻

译成法语时，“le chat s'est assis sur

le

tapis”中的每个单

词都能够简单地对应于

英文句子中的一个单词

。然

而，在其他情况下，这种

对应关系可能并不是那

么直接或显而易见

的。在

这种情况下，可以使用注

意力机制来帮助模型学

习这种更复杂

的对应关

系，这些对应关系被称为

非平凡对应。这意味着在

生成翻译

时，每个目标语

言单词与源语言单词之

间的关系不能被简单地

表示为

一对一的对应关

系。相反，同一个目标单词

可能需要对应于多个源

单

词（或反之亦然），甚至可

能需要考虑整个源句子

才能确定最佳的对

应关

系。

通过关注每个时间步

最相关的输入标注，这些

基于注意力的模型能够

学习生成翻译中的单词

与源句子中的单词之间

的非平凡对应

（nontrivial alignment）

。例如，图1-5可

视化了英语到法语翻

译

模型的注意力权重，其中

每个像素表示一个权重

。图1-5展示了解码

器如何能

够正确对应单词“zone”和“Area”，它们

在两种语言中的

顺序不

同。

尽管注意力机制能够

带来更好的翻译，但在编

码器和解码器中使用循

环神经网络模型仍然存

在一个重大缺点：计算本

质上是顺序的，不能

跨输

入序列并行化。

Transformer引入了一

种新的建模范式：完全放

弃循环，改为使用一种

特

殊形式的注意力——自注意

力。我们将在第3章更详细

地介绍自注意

力，这里先

简单描述一下其基本思

想：允许注意力对神经网

络同一层

中的所有状态

进行操作。如图1-6所示，其中

编码器和解码器都有自

己

的自注意力机制，其输

出被馈送到前馈神经网

络（FF NN）。这种架

构的训练速度

比循环神经网络模型快

得多，从而为NLP许多最新突

破铺

平了道路。

▲图1-5：RNN编码器

-解码器对英语单词和生

成的法语翻译的对应

（由

Dzmitry Bahdanau提供）

图1-6：原始Transformer的编码器-解

码器架构

在最初的Transformer论文

中，翻译模型是在各种语

言的大型句子对语

料库

上从头开始训练的。然而

，在许多NLP实际应用中，我们

无法访问

大量的标注文

本数据来训练我们的模

型。因此我们引入了Transformer

革命

的最后一部分：迁移学习

。

1.3

NLP的迁移学习

权重是神经

网络的可学习参数。

如今

，计算机视觉的常见做法

是使用迁移学习，即在一

项任务上训练

像ResNet这样的

卷积神经网络，然后在新

任务上对其进行适配或

微

调。迁移学习允许网络

利用从原始任务中学到

的知识。在架构上，这

是指

将模型拆分为主体和头

，其中头是指针对任务的

网络。在训练期

间，主体学

习来源于领域的广泛特

征，并将学习到的权重用

于初始化

新任务的新模

型 。与传统的监督学习相

比，这种方法通常会产生

高

质量的模型，这些模型

在各种下游任务中效果

更佳，并且使用的标注

数

据更少。这两种方法的组

合如图1-7所示。

图1-7：传统监督

学习（左）和迁移学习（右）的

比较

在计算机视觉中，模

型首先在包含数百万张

图像的ImageNet

（https://image-net.org）等大规模数据集

上进行训练。这个过程称

为预训练，其主要目的是

向模型传授图像的基本

特征，例如边或颜

色。然后

，这些预训练模型可以在

下游任务上进行微调，例

如使用相

对较少的标注

示例（通常每个类几百个

）对花种进行分类。微调模

型

通常比在相同数量的

标注数据上从头开始训

练的监督模型具有更高

的

准确率。

尽管迁移学习

成为计算机视觉的标准

方法，但多年来，人们并不

清楚

NLP的类似预训练过程

是怎么样的。从而导致NLP应

用程序通常需要大

量的

标注数据才能实现高性

能。即便如此，这种性能也

无法与视觉领

域的成就

相提并论。

A. Radford, R.

Jozefowicz, and I. Sutskever, “Learning to

Generate Reviews and Discovering Sentiment”

（https://arxiv.org/abs/1704.01444）,

（2017）.

当时的一项相

关工作是ELMo（Embeddings from Language Models，来

自语言模型

的嵌入），它展示了预训练

LSTM如何为下游任务产生高

质

量的词嵌入。

在2017年和2018年

，几个研究小组提出了新

的方法，最终令迁移学习

也能成功应用到NLP领域。这

种方法始于OpenAI研究人员的

研究，他们

通过使用从无

监督预训练中汲取的特

征在情感分类任务上获

得了出色

的性能 。紧随其

后的是ULMFiT，它使用预训练LSTM模

型构建了一个

可以适用

于各种任务的通用框架

。

如图1-8所示，ULMFiT包括以下三个

主要步骤：

预训练

对于世

界上大多数语言，获得大

量数字化文本语料库可

能很困难，英

语更是如此

。寻找解决这一问题的方

法是NLP研究方向的一个活

跃领

域。

最初的训练目标

非常简单：根据前面的单

词预测下一个单词。这类

任

务称为语言建模，所生

成的模型称为语言模型

。这种方法的优雅之处

在

于不需要标注数据，并且

可以使用来自Wikipedia等来源的

大量可用

文本 。

领域适配

在大规模语料库上进行

预训练得出语言模型之

后，下一步就是将其适

配

于业务领域语料库（例如

，从Wikipedia迁移到电影评论的IMDb语

料

库，如图1-8所示）。这一阶段

仍然使用语言建模方法

，但现在模型必

须预测目

标语料库中的下一个单

词。

微调

这一步使用目标

任务的分类层对语言模

型进行微调（例如，对图1-8中

的电影评论的情感进行

分类）。

图1-8：ULMFiT工作流程（由Jeremy Howard提供

）

通过引入一个可行的NLP预

训练和迁移学习框架，ULMFiT填

补了令

Transformer起飞的缺失部分

。2018年，发布了两类将自注意

力与迁移

学习相结合的

Transformer模型：

GPT

Y. Zhu

et al., “Aligning Books and Movies:Towards

Story-Like

Visual Explanations by Watching Movies

and Reading Books”

（https://arxiv.org/abs/1506.06724），（2015）.

仅使用Transformer架构的解码

器部分，以及与ULMFiT相同的语

言建模

方法。GPT在BookCorpus1上进行预

训练，该语料库由7000本来自

冒

险、幻想和浪漫等各种

流派的图书组成。

BERT

仅使用

Transformer架构的编码器部分，以及

一种称为掩码语言建模

的

特殊形式的语言建模

。掩码语言建模的目的是

预测文本中随机掩码的

单词。如，给定一个句子，如

“I looked at

my[MASK]and saw that[MASK]was late.”，该

模型需要预测[MASK]所掩码

的单词最有可能的候选

者。BERT在

BookCorpus和英语Wikipedia上进行预训

练。

GPT和BERT在各种NLP基准测试中

创下新高，从而开创了Transformer时

代。

但是由于各个研究实

验室在不同的框架（PyTorch或TensorFlow）上

发

布模型，而这些模型无

法兼容于其他框架，NLP从业

者将这些模型移植

到他

们自己的应用程序中经

常会遇到困难。于是

Hugging FaceTransformers库（https://oreil.ly/Z79jF）这

个能够

跨50多个架构的统

一API应运而生。该库催化了

Transformer研究的爆

炸式增长，并迅

速渗透到NLP从业者中，从而

可以轻松地将

Transformer模型集成

到当今的许多实际应用

中。接下来我们看看这个

库吧！

1.4

Hugging Face

Transformers库：提供规范化接口

将新颖的机器学习架构

应用于新任务可能是一

项复杂的任务，通常涉

及

以下步骤：

1.将模型架构付

诸代码实现（通常基于PyTorch或

TensorFlow）。

2.从服务器加载预训练权

重（如果有的话）。

3.预处理输

入并传给模型，然后应用

一些针对具体任务的后

处理。

4.实现数据加载器并

定义损失函数和优化器

来训练模型。

其中每个步

骤都需要自定义每个模

型和任务的逻辑。传统上

（但并非

总是如此！），当研究

小组发表一篇新文章时

，他们也会发布代码以

及

模型权重。但是这类代码

很少是规范化的，并且通

常需要数天的改

造才能

适用于新的用例。

这就是

Hugging Face

Transformers库拯救NLP从业者的地方！它

为

各种Transformer模型提供了规范

化接口，从而令这些模型

可以适用于

新用例的代

码和工具。该库目前支持

三种主要的深度学习框

架

（PyTorch、TensorFlow和JAX），并能够在它们之间

轻松切换。此

外，它还提供

针对任务的头，因此你可

以轻松地微调下游任务

（如文

本分类、命名实体识

别和问答）的Transformer模型。这点令

训练和测

试模型所需的

时间从一周减少到一个

下午！

你将在1.5节亲眼见证

这一点，那里我们将展示

通过

Hugging Face Transformers库只需几行代码就

可以实现一些最常见

的

NLP应用程序。

1.5

Transformer应用概览

本节

所讲述的每个NLP任务都以

如下一段文本开头（以客

户对其订单的

反馈为例

）：

对于你的应用程序，以上

文本可能会是法律手册

、产品描述或完全不

同的

内容。在这个客户反馈的

例子中，你可能想知道反

馈是正面的还

是负面的

。这类任务称为情感分析

，是我们将在第2章探讨的

文本分类

这一更广泛主

题的一部分。这里我们只

看看使用

Hugging Face Transformers库从我们的文

本中提取情感需要做什

么。

1.5.1

文本分类

正如我们将

在后面章节所看到的，Hugging FaceTransformers库

具有

各种API，从而使你可以

在各种抽象级别与库进

行交互。在本章中，我

们将

从pipeline开始，pipeline把将原始文本转

换为微调模型的一组

预

测所需的所有步骤都抽

象出来。

我们可以通过调

用Hugging Face Transformers库的pipeline()函数

并提供我们

感兴趣的任务名称来实

例化pipeline：

当第一次运行以上

代码时，你会看到一些进

度条，因为pipeline会自

动从Hugging

Face Hub（https://oreil.ly/zLK11）下载

模型权

重。当第二次实例

化pipeline时，库会注意到你已经

下载了预训练模

型（缓存

），然后将改用缓存的版本

。默认情况下，text￾classification pipeline将使用专为

情感分析而设计的模型

，但它

也支持多类和多标

注分类。

现在我们有了pipeline，可

以生成一些预测了！pipeline将文

本字符

串（或字符串列表

）作为输入，然后返回预测

列表。每个预测结果都

是

一个Python字典，因此我们可以

使用Pandas将其很好地显示为

DataFrame：

本例的预测结果是模型

非常确信输入文本具有

负面情感，鉴于我们所

处

理的是一单愤怒的客户

投诉，这个预测结果是吻

合的！请注意，对

于情感分

析任务，pipeline仅返回其中一个

POSITIVE或NEGATIVE标

注，因为另一个可以

通过计算1-score来推断。

接下来

我们讲述另一个常见任

务，在文本中标识命名实

体。

1.5.2

命名实体识别

现在我

们能够预测客户反馈的

情感，但你经常还想知道

反馈是否与特

定项目或

服务有关。在NLP中，产品、地点

和人等现实世界的对象

称为

命名实体，从文本中

提取它们称为命名实体

识别（NER）。我们可以通

过加载

以下pipeline并将我们的客户评

论提供给它来应用NER：

你可

以看到pipeline检测出所有实体

，并且还为每个实体分配

了一个

类别，例如ORG（组织）、LOC（位

置）或PER（人）。在这里，我们使

用

aggregation strategy参数根据模型的预测对

单词进行分组。例

如，实体

“Optimus Prime”由两个单词组成，但被分

配到一个类

别：MISC（杂项）。score列告

诉我们模型对其识别的

实体的信心（概

率）。我们可

以看到，它对“Decepticons”和第一个“Megatron”最

没有信心（概率最低），两者

都未能作为一个实体分

在同一组。

看到上表word列中

那些奇怪的哈希符号（#）了

吗？这些符号是模型的

词

元分析器生成的，词元分

析器将单词划分成称为

词元的原子单元。

我们将

在第2章讲述词元分析器

的详细信息。

现在我们已

经把文本中的所有命名

实体提取出来了，但有时

我们想问

更有针对性的

问题。于是我们就需要问

答pipeline。

1.5.3

问答

我们通过下面的

context参数把问答的上下文（即

本节开头提到的文

本）提

供给模型，通过question参数把问

题提供给模型。模型将返

回

回答。现在我们看看当

询问客户反馈的相关问

题时，会得到什么回

答：

我

们可以看到，除了回答之

外，pipeline还返回回答在上下文

中的位

置，即start和end（就像NER标注

一样）。我们将在第7章研究

好几种

类型的问答，但本

节这种特殊的类型称为

提取式问答，因为答案是

直

接从文本提取出来的

。

通过这种方法，你可以通

过提问题从客户的反馈

中快速得到相关信

息。但

是，如果你收到堆积如山

的冗长投诉而你没有时

间阅读所有内

容，那该怎

么办？我们看看文本摘要

是否有帮助！

1.5.4

文本摘要

文

本摘要的目标是输入一

段长文本，然后生成包含

所有相关事实的简

短版

本。这是一项比前面所讲

任务复杂得多的任务，因

为它需要模型

生成连贯

的文本。我们通过以下熟

悉的模式实例化文本摘

要

pipeline：

得出的摘要还不错！尽

管其只是简单地复制粘

贴部分原始文本，但该

模

型能够捕捉到问题的根

源，并正确识别“Bumblebee”（出现在输

入

文本的末尾）是投诉者

。在以上代码中，你还可以

看到我们将一些关

键字

参数（如max_length和clean_up_tokenization_spaces）传给

pipeline。我们可以

通过这些参数调整输出

。

但是，当你收到用你不懂

的语言提供的反馈时，该

怎么办？你可以使

用Google翻译

，或者你可以使用你自己

的Transformer模型来翻译它！

1.5.5

翻译

与

摘要类似，翻译也是一项

文本生成任务。接下来我

们使用翻译

pipeline将英语文本

翻译成德语：

我们看到，模

型同样生成了一个非常

好的翻译，正确使用了德

语的代

词，如“Ihrem”和“Sie”。在以上示

例代码中，我们还展示了

如何

通过model参数指定模型

来替换默认模型，从而可

以为你的应用程序选

择

最佳模型，你可以在Hugging Face Hub上找

到数千种语言对模

型。接

下来我们看看最后一个

应用，然后再开始介绍Hugging Face生

态系统。

1.5.6

文本生成

假设你

希望通过自动完成功能

来撰写答复，从而更快地

回复客户。你

可以按如下

方式使用text-generation pipeline：

上面生成的内

容并不好，我们也许不想

用它来答复客户Bumblebee，但

你应

该明白了大致的用法。

现

在我们已经讲述了Transformer模型

一些很酷的应用，你可能

想知道

训练在哪里进行

。我们在本章使用的所有

模型都是公开可用的，并

且

已经针对以上任务微

调过了。一般来说，无论如

何，你都会想根据自

己的

数据微调模型，在后面的

章节中，你将学习如何做

到这一点。

但是，训练模型

只是任何NLP项目的一小部

分——能够有效地处理数

据

、与同事共享结果，以及使

你的工作可重复也是项

目的关键组成部

分。幸运

的是，围绕着Hugging Face Transformers库有一个由

一整

套工具组成的大型

生态系统，从而可以支持

大部分现代机器学习工

作

流程。我们一起看看这

个生态系统吧。

1.6

Hugging Face生态系统

以Hugging Face Transformers库为基础，Hugging Face已经迅速

发

展成一个完整的生态系

统，它由许多库和工具组

成，以加速你的NLP

和机器学

习项目。Hugging Face生态系统主要由

一系列库和Hub组

成，如图1-9所

示。库提供相关代码，而Hub提

供预训练的模型权重、

数

据集、度量指标脚本等。本

节我们将简要介绍各种

组件而跳过

Hugging Face

Transformers库，因为我们

已经讨论过它了，在后面

的章节我们还会看到Hugging Face Transformers库

的更多相关内

容。

图1-9：Hugging Face生态

系统概览

1.6.1

Hugging FaceHub

如前所述，迁移

学习是推动Transformer成功的关键

因素之一，因为它

使重用

预训练模型来完成新任

务成为可能。因此，能够快

速加载预训

练模型并进

行实验至关重要。

Hugging Face Hub拥有超

过20 000个免费提供的模型。图

1-10所示

的筛选器用以筛选

任务、框架、数据集等，从而

帮助你快速找到有前

途

的候选项。正如我们在pipeline所

看到的那样，在代码中加

载一个

有前途的模型实

际上只需一行代码。这使

得实验各种模型变得简

单，

从而允许你专注于项

目的领域特定部分。

图1-10：Hugging Face Hub的

模型页面，左侧显示筛选

器，右侧显

示模型列表

除

了预训练模型之外，Hub还托

管了用于度量指标的数

据集和脚本，使

你可以重

现已发布的结果或为应

用程序利用其他数据。

Hub还

提供Models（模型）和Datasets（数据集）卡片

，用于记录模型

和数据集

相关内容，以帮助你就它

们是否适合你做出明智

的决定。Hub

最酷的功能之一

是，你可以直接通过各种

特定于任务的交互式小

部件

试用任何模型，如图

1-11所示。

图1-11：Hugging Face Hub Model card示例：你可以通过

右侧

的inference小部件与模型进

行交互

接下来我们介绍

Hugging Face Tokenizers库。

PyTorch（https://oreil.ly/AyTYC）和TensorFlow

（https://oreil.ly/JOKgq）也提供了自己的Hub，如

果

Hugging

Face Hub上没有你所要的模型

或数据集，那么你可以试

试

PyTorch和TensorFlow的Hub。

1.6.2

Hugging Face

Tokenizers库

我们在本章看

到的每个pipeline示例背后都有

一个词元化

（tokenization）步骤，该步骤

将原始文本拆分为称为

词元的更小部

分。我们将

在第2章详细介绍这个过

程，但现在只需要知道词

元可以是

单词、单词的一

部分或只是标点符号等

字符就足够了。Transformer模

型是在

这些词元的数字表示上

训练的，因此正确执行这

一步对于整个

NLP项目非常

重要！

Rust（https://rust-lang.org）是一种高性能编程

语言。

Hugging Face Tokenizers库（https://oreil.ly/Z79jF）提供了许

多词元

化策略，并且因为其后端

使用Rust

，所以词元化速度特

别

快。它还负责所有预处

理和后处理步骤，例如规

范化输入并将模型输

出

转换为所需的格式。我们

可以像使用Hugging Face Transformers

库加载预训

练模型一样使用Hugging

Face Tokenizers库加载

Tokenizer。

我们还需要数据集和度

量指标来训练和评估模

型，我们先看一下数据

集

。

1.6.3

Hugging

Face Datasets库

加载、处理和存储数据

集可能是一个烦琐的过

程，尤其是当数据集变

得

太大而无法放入笔记本

电脑内存的时候。此外，你

通常需要实现各

种脚本

来下载数据并将其转换

为标准格式。

Hugging

Face Datasets库（https://oreil.ly/959YT）通过为可

在

Hub（https://oreil.ly/Rdhcu）上找到的数千个数据

集提供标准界面

来简化

这个过程。它还提供智能

缓存（因此你不需要每次

运行代码时

都重复预处

理工作），并通过利用称为

内存映射的特殊机制来

突破内

存限制，该机制将

文件的内容存储到虚拟

内存中，并使多个进程能

够

更有效地修改文件。该

库还可以与Pandas和NumPy等流行框

架进行互操

作，因此你不

必离开自己喜欢的数据

整理工具。

但是，如果你无

法可靠地度量性能，那么

良好的数据集和强大的

模型

就毫无价值。不幸的

是，经典的NLP度量指标带有

许多不同的实现，这

些实

现可能会略有不同并产

生欺骗性结果。Hugging Face

Datasets

库通过为

许多指标提供脚本，从而

有助于令实验更具可重

复性，结果

更可信。

现在借

助Hugging Face Transformers、Tokenizers和Datasets这些

库，我们拥有训

练自己的Transformer模型所需的一

切！然而，正如我

们将在第

10章所看到的，在某些情况

下，我们需要对训练循环

进行细

粒度的控制。这就

是生态系统的最后一个

库发挥作用的地方：

Hugging Face Accelerate库。

1.6.4

Hugging Face Accelerate库

如果你曾经不得不用PyTorch编

写自己的训练脚本，那么

在尝试将笔记

本电脑上

运行的代码移植到组织

集群上运行的代码时，你

可能会遇到

一些麻烦。Hugging

Face Accelerate库

（https://oreil.ly/iRfDe）为常规训练操作增加了

一个抽象层以负

责训练

基础设施所需的所有逻

辑。这可以通过在必要时

简化基础架构

的更改来

加速工作流。

至此，我们总

结了Hugging Face开源生态系统的核

心组件。但在结束

本章之

前，我们来看看在现实工

作中部署Transformer模型时遇到的

一

些主要挑战。

1.7

Transformer的主要挑

战

本章我们已经看到可

以用Transformer模型处理的各种NLP任

务。只看

媒体头条新闻，有

时会觉得Transformer模型能力无限

。然而，尽管

Transformer模型很有用，但

远未能包打天下。以下是

我们将在本书探

讨的一

些与之相关的挑战：

语言

NLP研究以英语为主。有一些

支持其他语言的模型，但

很难找到稀有或

资源少

的语言的预训练模型。我

们将在第4章探讨多语言

Transformer

及其执行零样本学习跨

语言迁移的能力。

数据可

用性

尽管我们可以通过

迁移学习来显著减少模

型所需的标注训练数据

量，

但与人类执行任务所

需的量相比，依然差很多

。我们将在第9章探讨如

何

处理几乎没有标注数据

可用的场景。

处理长文本

自注意力在段落长度的

文本上效果非常好，但是

在处理整个文档这样

长

度的文本时，将变得非常

昂贵。第11章将讨论缓解这

种情况的方

法。

不透明度

与其他深度学习模型一

样，Transformer在很大程度上是不透

明的。人

们很难或不可能

解开模型做出某种预测

的“原因”。当需要通过这些

模型来做出关键决策时

，这是一个特别艰巨的挑

战。我们将在第2章和

第4章

探讨一些探测Transformer模型误差

的方法。

偏见

Transformer模型主要基

于互联网的文本数据进

行预训练。这会将数据

中

存在的所有偏见印入模

型中。确保我们没有把种

族主义、性别歧视

或更糟

的偏见引入模型是一项

具有挑战性的任务。我们

将在第10章更

详细地讨论

相关问题。

尽管这些挑战

令人生畏，但是其中许多

挑战都是可以克服的。除

了以

上提到的章节外，我

们将在后面的几乎每一

章中触及它们。

1.8

本章小结

好了，看到这里，希望你很

高兴学习到如何开始训

练这些多功能模型

并将

其集成到自己的应用中

！在本章你已经看到，只需

几行代码，就

可以使用最

先进的模型进行分类、命

名实体识别、问答、翻译和

文本

摘要，但这些功能实

际上都只是“冰山一角”。

在

后续章节中，你将学习如

何使Transformer适配各种用例，例如

构建

文本分类器或用于

生产的轻量级模型，甚至

从头开始训练语言模型

。

我们将采用动手实操的

方法进行讲解，这意味着

对于所讲到的每个概

念

，都会有配套的代码，并且

你可以在Google Colab或你自己的GPU

机

器上运行这些代码。

现在

我们已经掌握了Transformer背后的

基本概念，是时候动手处

理我

们的第一个应用了

：文本分类。这也就是第2章

的主题！

第2章

文本分类

文

本分类是NLP中最常见的任

务之一，它的应用十分广

泛，例如将客户

反馈标注

为不同的类别或根据语

言分配给会这种语言的

客服人员。很

有可能，你的

电子邮件程序的垃圾邮

件过滤器正在使用文本

分类来保

护你的收件箱

，避免被大量的垃圾邮件

淹没！

另一种常见的文本

分类是情感分析，它（正如

我们在第1章中所看到

的

）旨在确定给定文本的极

性。例如，像特斯拉这样的

公司可能会分

析像图2-1中

的Twitter帖子（后文统称推文），以

确定人们是否喜欢

它的

新车顶。

图2-1：分析推文以从

客户那里获得有用的反

馈（由Aditya Veluri

提供）

V. Sanh et al., “DistilBERT，a Distilled

Version of

BERT:Smaller，Faster，Cheaper and Lighter”

（https://arxiv.org/abs/1910.01108），（2019）.

现在想象一下

，你是一名数据科学家，需

要构建一个系统，可以自

动

识别人们在Twitter上对你公

司产品表达的情感状态

，例如愤怒或喜

悦。在本章

中，我们将使用一种名为

DistilBERT 的BERT变体来解决

这个任务

。该模型的主要优点是，在

实现与BERT相当的性能的同

时，

体积更小、效率更高。这

使我们能够在几分钟内

训练一个分类器，如

果你

想训练一个更大的BERT模型

，则只需更改预训练模型

的

checkpoint。checkpoint对应于加载到给定Transformer架

构中的权重

集。

擎天柱是

著名动画片《变形金刚》中

汽车人的领袖。

这也将是

我们首次接触Hugging Face生态系统

中的三个核心库：

Datasets、Tokenizers和Transformers。如图

2-2所示，这些库令我们

能够

快速地将原始文本输入

微调后的模型，以用于推

理新的推文。因

此，现在我

们在擎天柱 的带领下，变

形出发！

图2-2：使用Datasets、Tokenizers和Transformers库进行

Transformer模型训练的典型流程

2.1

数

据集

E. Saravia et al., “CARER:

Contextualized Affect

Representations for Emotion Recognition，”Proceedings

of the

2018 Conference on Empirical

Methods in Natural Language

Processing（Oct-Nov 2018）:3687-3697，

http://dx.doi.org/10.18653/v1/D18-1404.

为了构建我们的情

感检测器，我们将使用一

篇论文 中提供的数据

集

，该论文探讨了英语推文

所表示的情感。与大多数

情感分析数据集

只涉及

“正面”和“负面”这两种极性

不同的是，这个数据集包

含六

种基本情感：anger（愤怒）、disgust（厌

恶）、fear（恐惧）、joy

（喜悦）、sadness（悲伤）和surprise（惊讶

）。我们的任务是训练

一个

模型，将给定推文按其中

一种情感进行分类。

2.1.1

初探

Hugging Face Datasets库

我们将使用Hugging Face Datasets库从Hugging Face Hub

（https://oreil.ly/959YT）下载

数据。我们可以使用

list_datasets()函数

查看Hub上有哪些可用数据

集。

我们可以看到每个数

据集都有一个名称，因此

让我们使用

load_dataset()函数加载情

感数据集：

emotions对象详情如下

：

我们可以看到它类似于

Python字典，每个键对应不同的

数据集分割。

我们可以使

用常用的字典语法来访

问某个数据集分割：

以上

代码返回一个Dataset类的实例

。Dataset对象是

Hugging Face Datasets库的核心数据结

构之一，在本书中我们将

探

索它的许多特性。首先

，它的行为类似于普通的

Python数组或列表，

因此我们可

以查询它的长度：

或者通

过索引访问某个样本：

在

这里我们可以看到，这行

数据将表示成这样一个

字典，其中键对应

着列名

：

值分别是推文和情感。这

反映了Hugging Face Datasets库是基于

Apache Arrow（https://arrow.apache.org）构建的

。

Apache Arrow定义了一种类型化的列

格式，比原生的Python更有效地

利用内存。我们可以通过

访问Dataset对象的features属性来查看

其背

后使用了哪些数据

类型。

在本例中，text列的数据

类型为字符串，而label列是一

个特殊的

ClassLabel对象，它包含有

关类名称及其映射到整

数的信息。我们还

可以使

用切片查看几行数据：

请

注意，这种情况下，字典的

值是列表而不是某个元

素。我们也可以

通过名称

获取整个列：

既然我们已

经看到如何使用Hugging Face

Datasets库加载

和检查数

据，那么让我们

对推文的内容进行一些

检查。

如果我的数据集不

在Hub上那该怎么办？

在本书

的大部分示例中，我们将

使用Hugging Face Hub库下载数据

集。但在

许多情况下，你会发现自

己处理的数据要么存储

在你的笔记

本电脑上，要

么存储在你的组织的远

程服务器上。Datasets提供了多

个

加载脚本来处理本地和

远程数据集。最常见数据

格式的示例参见表

2-1。

表2-1：如

何加载不同格式的数据

集

你可以看到，对于每种

数据格式，我们只需要将

相关的加载脚本参数

和

数据文件data_files参数传给load_dataset()函数

即可，其中

data_files参数指定一个

或多个文件的路径或URL。假

如情感数据集的

源文件

实际上托管在Dropbox上，那么可

以使用以下代码加载数

据集：

如果你想知道为什

么在前面的shell命令中会有

一个！符号，那是因为

我们

在Jupyter notebook中运行这些命令。如果

你想要在命令行终端

下

载和解压数据集，则只需

删除前缀。现在，我们查看

train.txt文件

的第一行：

我们可以

看到这里没有列标题，每

个推文和情感之间用分

号分隔。看

起来与CSV文件非

常相似，因此我们可以使

用csv脚本并将data_files

参数指向train.txt文

件来将数据集加载到本

地：

这里我们还指定了分

隔符类型（sep参数）和列的名

称（names参

数）。更简单的方法是

将data_files参数直接指向URL：

这个函

数会自动下载和缓存数

据集。正如你所看到的，

load_dataset()函

数非常灵活，有很多种用

法。所以我们建议查看

Datasets文

档（https://oreil.ly/Jodu4）以获得全面的概述。

2.1.2

从

Datasets到DataFrame

尽管Hugging Face Datasets库提供了许多底

层的功能供我们切分和

处理数据，但我们通常将

Dataset对象转换为Pandas DataFrame，这

样我们就

可以使用高级API来进行可

视化，这样做将非常方便

。

Hugging

Face Datasets库提供了set_format()方法，该方法允

许我

们更改数据集的输

出格式以进行转换。请注

意，它不会改变底层的数

据格式（Arrow表），并且你可以随

时切换到另一种格式。

你

可以看到，列标题被保留

，前几行与我们以前查看

的数据相匹配。

然而，标注

（label列）表示为整数，因此我们

需要使用int2str()方

法在我们的

DataFrame中创建一个包含相应标

注名称的新列

（label name列）：

在构建

分类器之前，我们仔细研

究一下数据集。正如

Andrej Karpathy在他

著名的博客文章

“A

Recipe for Training Neural Networks”

（https://oreil.ly/bNayo）中所指

出的那样，与数据“融为一

体”

是训练出优秀模型的

关键步骤！

2.1.3

查看类分布

对

于处理文本分类问题，检

查类的样本分布无论何

时都是一个好主

意。相对

于类平衡的数据集来说

，一个类分布不平衡的数

据集可能需

要在训练损

失和度量指标方面采取

不同的处理方法。

我们可

以使用Pandas和Matplotlib快速地可视化

类分布：

我们可以看到数

据集严重不平衡；joy和sadness类频

繁出现，大约是

love和surprise类的5～10倍

。处理不平衡数据的方法

包括：

●随机对少数类进行

过采样（oversample）。

●随机对多数类进

行欠采样（undersample）。

●收集更多来自

未被充分表示的类的标

注数据。

为了保持本章简

单，我们不使用以上的任

何方法，而将使用原始的

、

不平衡的类。如果你想了

解更多关于这些采样技

术的内容，我们建议

你查

看Imbalanced-learn库（https://oreil.ly/5XBhb）。需要注意

的是，在将

数据集分割成训练/测试

集之前不要应用采样方

法，否则会

在两者之间造

成大量泄漏！

现在我们已

经查看了这些类，接下来

我们看看这些推文本身

。

2.1.4

这些推文有多长

Transformer模型的

输入序列长度有一个最

大限制，称为最大上下文

大

小（maximum context size）。对于使用DistilBERT的应用程

序，

最大上下文大小为512个

词元，只有几段文本长。正

如我们将在2.2节

中看到的

，词元是指一段文本的原

子单元，这里为简单起见

我们将词

元视为一个单

词。我们可以通过查看每

个推文中单词的分布来

对每种

情感的推文长度

进行大致估计：

从图中可

以看出，对于每种情感，大

多数推文长度为15个单词

，最长

的推文远远低于DistilBERT的

最大上下文大小。超过模

型上下文大小

的文本需

要被截断，如果被截断的

文本包含关键信息，则可

能会导致

性能下降。就我

们的示例而言，应该不会

有这方面的问题。

接下来

我们将原始文本转换为

Hugging Face Transformers库支持的

格式，首先我们

需要重置数据集的输出

格式，因为我们不再需要

DataFrame格式了：

2.2

将文本转换成词

元

像DistilBERT这样的Transformer模型不能接

收原始字符串作为输入

。

它假定文本已经被词元

化并编码为数字向量。词

元化

（tokenization）是指将字符串分解

为给模型使用的原子单

元的步

骤。词元化的策略

有好几种，具体哪种最佳

通常需要从语料库中学

习。在讨论DistilBERT使用的Tokenizer之前，我

们先讨论两种极端情

况

：字符词元化和单词词元

化。

2.2.1

字符词元化

最简单的

词元化方案是按每个字

符单独馈送到模型中。在

Python中，

str对象实际上是一组数

据，这使我们可以用一行

代码快速实现字符词

元

化：

这是一个很好的开始

，但我们还没有完成任务

。我们的模型希望把每

个

字符转换为一个整数，有

时这个过程被称为数值

化

（numericalization）。一个简单的方法是用

一个唯一的整数来编码

每个唯一的词元（在这里

为字符）：

我们可以看到，我

们得到了一个包括了每

个字符到一个唯一性整

数的

映射，即词元分析器

的词表。我们现在可以使

用token2idx将词元化的

文本转换

成一个整数列表：

现在，每

个词元都已映射到唯一

的数字标识符（因此称为

input_ids）。最后一步是将input_ids转换为独

热向量（one￾hot vector）的二维张量。在机

器学习中，独热向量常常

用于编码分

类数据（包括

有序和无序数据）。例如，假

设我们想对《变形金刚》

中

的角色名称进行编码。一

种方法是将每个Name映射到

唯一的ID，如

下所示：

这种方

法的问题在于它会给Name这

一列的值引入虚假的顺

序关系，这

个缺陷在某些

情况下可能会导致神经

网络学习到错误的模式

和关系，

从而降低模型的

性能。因此，我们可以为每

个类别创建一个新列，在

该类别为true时分配1，否则分

配0。在Pandas中，可以使用

get_dummies()函数实

现这点：

以上DataFrame中的每行是

一个独热向量，一整行只

有一个1，其他都

是0。现在，看

看我们的input_ids，我们有类似的

问题：这些元素的

取值之

间引入了虚假的顺序关

系。因为这个关系是虚假

的，所以对两

个ID进行加减

是一个没意义的操作。

如

果我们将input_ids改成独热编码

，结果就很容易解释：“热”的

两

个条目表明是相同的

两个词元。在PyTorch中，我们可以

使用

one_hot()函数对input_ids进行独热编

码：

本例共有38个输入词元

，我们得到了一个20维的独

热向量，因为我们

的词表

包含了20个唯一字符。

在one_hot()函

数中，始终要设置num_classes参数，否

则独热向量可

能会比词

表长度短（需要手动用零

来填充）。在TensorFlow中，对应

的函数

是tf.one_hot()，对应num_classes的参数是depth。

通过输

出input_ids[0]的如下信息来检查第

一个向量，我们可以看到

有个位置出现了1：

从我们

这个简单的示例可以看

出，字符级别的词元化忽

略了文本中的

任何结构

，将整个字符串视为一串

字符流。虽然这有助于处

理拼写错

误和生僻词，但

主要缺点是语言结构（如

单词）需要从数据中学习

。

这需要大量的计算、内存

和数据。因此，字符词元化

在实践中很少使

用。如果

想保留文本的某些结构

，那么单词词元化是实现

这一目标的

一种简单直

接的方法，让我们来看看

它是如何工作的。

2.2.2

单词词

元化

与字符词元化相比

，单词词元化将文本细分

为单词，并将每个单词映

射到一个整数。单词词元

化使模型跳过从字符学

习单词的步骤，从而

降低

训练过程的复杂性。

有一

种简单的单词词元化方

法是使用空格来分割文

本。我们可以直接

在原始

文本上应用Python的split()函数（就像

我们统计推文字数那

样

）来实现这一点：

这里我们

可以采取相同的步骤，将

每个字符映射到ID。但是，我

们已

经可以看到这种词

元化方案中的一个潜在

问题：未考虑标点，因此将

NLP.视为一个单独词元。单词

词元化有一个缺点：鉴于

单词可以包括

变形、派生

或拼写错误，词表的大小

很容易增长到数百万！

有

些单词词元分析器支持

标点以及词干提取或词

形还原，因此它们可

以将

单词规范化成其词干（例

如将great、greater和greatest都变成

great），但这样会

丢失文本中一些信息。

GPT-2是

GPT的后继者，凭借其令人印

象深刻的生成逼真文本

的能力吸

引了公众的关

注。我们将在第6章中详细

探讨GPT-2。

词表太大是一个问

题，因为它导致了神经网

络需要大量的参数。举例

来说，假设词表中有100万个

唯一词项，并按照大多数

NLP架构中的标

准步骤将100万

维输入向量压缩到第一

层神经网络中的1000维向量

。这

样就导致了第一层的

权重矩阵将包含100万×1千=10亿

个权重。这已经

可以与最

大的GPT-2模型 看齐了，该模型

总计拥有大约15亿个参数

！

自然，我们希望避免在模

型参数上浪费过多，因为

模型训练成本高

昂，而且

规模较大的模型更难维

护。一种常见的方法是只

取语料库中

最常见的100 000个

单词并丢弃罕见的单词

来避免词表过大。词表之

外的单词统一归类为“unknown”（未

知，UNK），映射到一个共用的

UNK词

元。这意味着我们在单词

词元化过程中丢失了一

些可能很重要的

信息，因

为模型无法获得与UNK关联

的单词的信息。

那么有没

有这么一种方法：介于字

符词元化和单词词元化

之间，既可

以保留输入信

息又能保留文本结构？确

实有，这种方法叫子词词

元

化。

2.2.3

子词词元化

子词词

元化背后的基本思想是

将字符和单词词元化的

优点结合起来。

一方面，我

们希望将生僻单词拆分

成更小的单元，以使模型

能够处理

复杂单词和拼

写错误。另一方面，我们希

望将常见单词作为唯一

实体

保留下来，以便我们

将输入长度保持在可管

理的范围内。子词词元化

（以及单词词元化）是使用

统计规则和算法从预训

练语料库中学习

的。

M. Schuster

and K. Nakajima，“Japanese and Korean Voice

Search，”2012 IEEE InternationalConference on Acoustics，

Speech

and Signal Processing（2012）: 5149-5152，

https://doi.org/10.1109/ICASSP.2012.6289079.

在NLP中

常用的子词词元化算法

有几种，我们先从WordPiece

算法开

始，这是BERT和DistilBERT词元分析器使

用的算法。了解WordPiece如

何工作

最简单的方法是看它的

运行过程。

Hugging Face Transformers库提供了一个

很方便的AutoTokenizer

类，它能令你快

速加载与预训练模型相

关联的词元分析器——只需

要

提供模型在Hub上的ID或本

地文件路径，然后调用它

的

from_pretrained()方法即可。我们先加载

DistilBERT的词元分析器：

AutoTokenizer类是“auto”类的

一种（https://oreil.ly/h4YPz），

其任务是根据checkpoint的名

称自动检索模型的配置

、预训练权重或

词表。使用

以上代码的优点是可以

快速切换模型，但是你也

可以手动

加载特定类。例

如，我们可以按照下面的

方式加载

DistilBERTTokenizer：

当你第一次运

行AutoTokenizer.from_pretrained()方法时，你将看到

一个

进度条，显示从Hugging Face Hub加载的预

训练词元分析器的

参数

。当你第二次运行代码时

，它会从缓存（通常是

～/.cache/huggingface）中加

载词元分析器。

我们输入

“Tokenizing text is a core

task of NLP.”这一

简单样本来检验这

个词元分析器是如何工

作的：

和字符词元化一样

，我们可以看到，单词映射

成input_ids字段中的唯

一整数。我

们将在2.2.4节中讨论attention

mask字段的

作用。现在

我们有了input_ids，我们

可以通过使用词元分析

器的

convert_ids_to_tokens()方法将它们转换回

词元：

我们可以观察到三

件事情。首先，序列的开头

和末尾多了一些特殊的

词元：[CLS]和[SEP]。这些词元具体因

模型而异，它们的主要作

用是

指示序列的开始和

结束。其次，词元都小写了

，这是该checkpoint的

特性。最后，我们

可以看到tokenizing和NLP都被拆分为

两个词元，这

是有道理的

，因为它们不是常用的单

词。##前缀中的##izing和##p意

味着前

面的字符串不是空白符

，将带有这个前缀的词元

转换回字符串

时，应当将

其与前一个词元合并。AutoTokenizer类

有一个

convert_tokens_to_string()方法可以做到这

一点，所以让我们将它

应

用到我们的词元：

AutoTokenizer类还有

几个属性可以提供该词

元分析器的其他信息。例

如，我们可以检查词表的

大小：

还有模型的最大上

下文大小：

还有另一个有

趣的属性，模型在前向传

递中期望的字段名称：

现

在我们了解了处理单个

字符串的词元化过程，接

下来我们看看如何

对整

个数据集进行词元化！

在

使用预训练模型时，确保

使用与模型训练时相同

的词元分析器非常

重要

。从模型的角度来看，更换

词元分析器就像打乱词

表一样。如果

身边的每个

人都开始随机使用单词

，比如将“house”换成“cat”，

那么你会很

难理解发生了什么！

2.2.4

对整

个数据集进行词元化

我

们将使用DatasetDict对象的map()方法来

对整个语料库进行词元

化。在本书中，我们将多次

遇到这种方法，因为它提

供了一种方便的

方法，可

以将处理函数应用于数

据集中的每个元素。我们

很快就会看

到，map()方法还可

以用于创建新的行和列

。

我们要做的第一件事就

是编写一个将我们的样

本进行词元化的处理函

数：

这个函数将词元分析

器应用于一个批量样本

。padding=True表示以零

填充样本，以达

到批量中最长样本的长

度，truncation=True表示将样

本截断为模

型的最大上下文大小。为

了观察tokenize()具体做了什

么，现

在我们从训练集中取两

个批量样本传给tokenizer()函数：

这

里我们可以看到填充的

结果：input_ids的第一个元素比第

二个短，

因此向该元素填

充零以使两个元素具有

相同的长度。这些零在词

表中

具有对应的[PAD]词元，而

特殊词元集还包括我们

之前遇到的[CLS]和

[SEP]词元：

此外

，除了将编码后的推文返

回为input_ids外，词元分析器还返

回一

系列attention_mask数组。这是因为

我们不希望模型被额外

的填充词

元所困惑：注意

力掩码（attention mask）允许模型忽略输

入的填充

部分。图2-3提供了

输入ID和注意力掩码如何

填充的视觉解释。

图2-3：在每

个批量中，输入序列将填

充到批量中最大序列的

长度。

模型使用注意力掩

码来忽略输入张量中的

填充区域

在定义完处理

函数之后，我们可以通过

一行代码将该函数应用

到语料

库整个数据集：

map()方

法默认按单个样本操作

，因此将batched设置为True以按批量

对推文进行编码。由于我

们设置了batch_size=None，所以将把整个

数

据集作为一个批量应

用tokenize()函数。这可以确保全局

输入张量和

注意力掩码

具有相同的形状，我们可

以看到此操作已将新的

input ids和attention mask列添加到数据集中：

在

后面章节中，我们将看到

如何使用数据整理器来

动态地填充每个批

量中

的张量。在下一节中，我们

从整个语料库中提取特

征矩阵时，全

局填充将派

上用场。

2.3

训练文本分类器

如第1章所述，像DistilBERT这样的模

型被预训练用于预测文

本序列中

的掩码单词。然

而，这些语言模型不能直

接用于文本分类，我们需

要

稍微修改它们。为了理

解需要做哪些修改，我们

来看一下基于编码器

的

模型（如DistilBERT）的架构，如图2-4所示

。

图2-4：使用基于编码器的Transformer进

行序列分类的架构。它由

模

型的预训练主体和自

定义分类头组合而成

在

DistilBERT的情况下，它在猜测掩码

词元。

首先，文本会被词元

化并表示为称为词元编

码的独热向量。词元编码

的维度由词元分析器词

表的大小决定，通常包括

两万到二十万个唯一

性

词元。接下来，这些词元编

码会被转换为词元嵌入

，即存在于低维

空间中的

向量。然后，这些词元嵌入

会通过编码器块层传递

，以产生

每个输入词元的

隐藏状态。对于语言建模

的预训练目标 ，每个隐藏

状态都被馈送到一个层

，该层预测掩码输入词元

。对于分类任务，我

们将语

言建模层替换为分类层

。

实际上，PyTorch在实现中跳过了

为词元编码创建独热向

量的步骤，因

为将矩阵与

独热向量相乘等同于从

矩阵中选择一列。这可以

通过直接

从矩阵中获取

词元ID对应的列来完成。当

我们使用nn.Embedding类

时，我们将在

第3章中看到这一点。

我们

有以下两种选择来基于

Twitter数据集进行模型训练：

特

征提取

我们将隐藏状态

用作特征，只需训练分类

器，而无须修改预训练模

型。

微调

我们对整个模型

进行端到端的训练，这样

还会更新预训练模型的

参

数。

接下来我们将讲述

基于DistilBERT的以上两种选择，以

及这两种选择

的权衡取

舍。

2.3.1

使用Transformer作为特征提取器

使用Transformer作为特征提取器相

当简单。如图2-5所示，我们在

训

练期间冻结主体的权

重，并将隐藏状态用作分

类器的特征。这种方法

的

优点是，我们可以快速训

练一个小型或浅层模型

。这样的模型可以

是神经

分类层或不依赖于梯度

的方法，例如随机森林。这

种方法特别

适用于没有

GPU的场景，因为隐藏状态只

需要预计算一次。

图2-5：在基

于特征的方法中，DistilBERT模型是

冻结的，只提供用

于分类

器的特征

加载预训练模

型

我们将使用Hugging Face Transformers库中另一

个很方便的自动类

AutoModel。与AutoTokenizer类

似，AutoModel具有

from_pretrained()方法，可用于加载

预训练模型的权重。现在

我们使

用该方法来加载

DistilBERT checkpoint：

这里我们使用PyTorch来检查GPU是

否可用（即代码

torch.cuda.is available()），然后将PyTorch的

nn.Module.to()方

法与模型加载器链接

起来（即代码to（device））。这确保了如

果有

GPU，模型将在GPU上运行。如

果没有，模型将在CPU上运行

，不过这样

可能会慢很多

。

AutoModel类将词元编码转换为嵌

入向量，然后将它们馈送

到编码器栈

中以返回隐

藏状态。我们看一下如何

从语料库中提取这些状

态。

框架之间的互操作性

虽然本书中的代码大多

用PyTorch编写，但

Hugging Face Transformers库可以与TensorFlow和JAX紧

密协作。

这意味着你只需

要改变一些代码即可在

你最喜欢的深度学习框

架中加

载预训练模型！例

如，我们可以使用TFAutoModel类在TensorFlow中

加

载DistilBERT：

当模型仅在一个框

架中发布，而你想在另一

个框架中使用时，这种互

操作性特别有用。例如，在

第4章中我们会遇到XLM-RoBERTa模型

（https://oreil.ly/OUMvG），它只有PyTorch权重，因此如果你

尝试

像之前一样在TensorFlow中加

载它：

你将会得到一个错

误。在这种情况下，你可以

将from_pt=True参数传

给TfAutoModel.from pretrained()函数，库将自

动为你下载并转换

PyTorch权重

：

你可以看到，在Hugging Face Transformers库中切换

框架非常简

单！在大多数

情况下，你只需要在类名

前添加TF前缀即可获得相

应的

TensorFlow2.0类。同理，如果要加载

PyTorch的权重，你只需要将tf

替换

成pt字符串即可（例如在接

下来的部分中），pt是PyTorch的简

称

，就像tf代表TensorFlow一样。

提取最终

隐藏状态

作为预热，我们

检索一个字符串的最终

隐藏状态。我们需要做的

第一

件事是对字符串进

行编码并将词元转换为

PyTorch张量。可以通过向词

元分

析器提供return_tensors=”pt”参数来实现。具

体如下：

我们可以看到，生

成的张量形状为[batch

size，n_tokens]。现在我

们已经将编码作为张量

获取，最后一步是将它们

放置在与模型相同的

设

备上，并按以下方式传输

入：

这里我们使用了torch.no_grad()上下

文管理器来禁用梯度的

自动计

算。这对推理很有

用，因为它减少了计算的

内存占用。根据模型配

置

，输出可以包含多个对象

，例如隐藏状态、损失或注

意力，这些对

象以类似于

Python中的namedtuple的形式排列。在我们

的示例中，模

型输出是一

个BaseModelOutput实例，并且包含了其属

性名，我们可以

通过这些

属性名来获取其详情。我

们看到，我们的模型只有

一个属

性，即last_hidden_state（最终隐藏状

态），然后我们通过以下代

码

查看一下它的形状：

我

们可以看到，隐藏状态张

量的形状为[batch_size，n_tokens，

hidden_dim]。换句话说，对

于每个输入词元，都会返

回一个768维向

量。对于分类

任务，通常惯例是只使用

与[CLS]词元关联的隐藏状态

作

为输入特征。由于此词

元出现在每个序列的开

头，我们可以通过简单

地

索引outputs.last_hidden_state来提取它，如下所示

：

现在我们知道如何针对

单个字符串获取最终隐

藏状态。我们通过创建

一

个新的hidden_state列来对整个数据

集执行相同的操作，以存

储所

有这些向量。就像我

们在词元分析器中所做

的那样，我们将使用

DatasetDict的map()方

法一次性提取所有隐藏

状态。我们需要做的第

一

件事是将先前的步骤封

装在一个处理函数中：

这

个函数和我们之前的逻

辑的唯一不同在于最后

一步，即将最终的隐

藏状

态作为NumPy数组放回CPU。当我们

使用批量输入时，map()方法要

求处理函数返回Python或NumPy对象

。

由于我们的模型期望输

入张量，下一步需要将input_ids和

attention_mask列转换为torch格式，具体如下

：

然后我们可以一次性提

取所有分割的隐藏状态

：

请注意，这里我们没有设

置batch_size=None，这意味着使用了默认

的

batch_size=1000。正如预期的那样，应用

extract_hidden_states()

函数将一个新的hidden_state列添加

到我们的数据集中。

现在

我们已经得到了与每个

推文相关联的隐藏状态

，下一步是基于它

们训练

一个分类器。为了做到这

一点，我们需要一个特征

矩阵，我们

来看一下。

创建

特征矩阵

现在，经过预处

理的数据集包含了我们

需要训练分类器的所有

信息。

我们将使用隐藏状

态作为输入特征，标注作

为目标。我们可以很容易

地按照以下方式创建对

应的数组，以Scikit-learn格式为基础

：

在对隐藏状态进行模型

训练之前，进行快速检查

以确保它们提供了我

们

想要分类的情感的有用

表示是一个良好的实践

。接下来，我们将看

到可视

化特征提供了一种快速

的方法来实现这一点。

可

视化训练集

L. McInnes, J. Healy, and

J. Melville, “UMAP: Uniform

Manifold Approximation

and Projection for Dimension

Reduction”（https://arxiv.org/abs/1802.03426）, （2018）.

由于在768维度

中可视化隐藏状态是个

艰难的任务，因此我们将

使用强

大的UMAP算法将向量

投影到2D平面上 。由于UMAP在特

征缩放到[0，

1]区间内时效果

最佳，因此我们将首先应

用一个MinMaxScaler，然后

使用umap-learn库的UMAP实

现来缩放隐藏状态：

结果

是一个数组，该数组具有

相同的训练样本数量，但

只有2个特征，

而不是我们

最初使用的768个特征！我们

进一步探究压缩后的数

据，并

分别绘制每个类别

的点密度图：

这些只是投

影到较低维空间的结果

。某些类别重叠并不意味

着它们在

原始空间中不

能区分。相反，如果它们在

投影空间中是可区分的

，那

么它们在原始空间中

也将是可区分的。

从这个

图中，我们可以看到一些

明显的模式：负面情感，如

悲伤

（sadness）、愤怒（anger）和恐惧（fear），都占据

着类似的区

域，但分布略

有不同。另外，喜悦（joy）和爱情

（love）与负面情感

明显分开，并

且也共享一个相似的空

间。最后，惊奇（surprise）分

散在整个

图中。虽然我们可能希望

有些区分，但这并不是肯

定的，因

为该模型并没有

被训练去区分这些情感

。它只是通过猜测文本中

被掩

码的单词来隐式地

学习它们。

现在我们已经

对数据集的特征有了一

些了解，接下来我们来到

最后一

步，基于数据集训

练模型！

训练一个简单的

分类器

我们已经看到，不

同情感的隐藏状态是不

同的，尽管其中一些情感

并

没有明显的界限。现在

让我们使用这些隐藏状

态来训练一个逻辑回归

模型（使用Scikit-learn）。训练这样一个

简单的模型速度很快，而

且不需要GPU：

从准确率上看

，我们的模型似乎只比随

机模型稍微好一点，但由

于我

们处理的是一个不

平衡的多分类数据集，它

实际上会显著地表现更

好。我们可以通过将其与

简单基准进行比较来检

查我们的模型是否良

好

。在Scikit-learn中，有一个DummyClassifier可以用于构

建具有简

单启发式的分

类器，例如始终选择多数

类或始终选择随机类。在

这种

情况下，表现最佳的

启发式是始终选择最常

见的类，这会产生约35%的

准

确率：

因此，使用DistilBERT嵌入的简

单分类器明显优于我们

的基线。我们

可以通过查

看分类器的混淆矩阵来

进一步研究模型的性能

，该矩阵告

诉我们真实标

注和预测标注之间的关

系：

这里我们可以看到，anger和

fear最常与sadness混淆，这与我们可

视

化嵌入时所观察到的

一致。此外，love和surprise经常与joy混淆

。

接下来我们将探究微调

方法，这种方法可以带来

更好的分类效果。但

是，重

要的是要注意，微调需要

更多的计算资源，比如GPU，而

你的组

织可能没有GPU。在这

种情况下，基于特征的方

法可以是传统机器学习

和深度学习之间的一个

很好的折中方案。

2.3.2

微调Transformer模

型

现在我们探讨如何进

行端到端的Transformer模型微调。在

使用微调方

法时，我们不

使用隐藏状态作为固定

特征，而是如图2-6所示那样

进行

训练。这要求分类头

是可微的，这就是为什么

这种方法通常使用神经

网络进行分类。

图2-6：在使用

微调方法时，整个DistilBERT模型以

及分类头一起进

行训练

训练用作分类模型输入

的隐藏状态将有助于我

们避免使用可能不适合

分类任务的数据的问题

。相反，初始隐藏状态在训

练过程中适配，以

降低模

型损失并提高其性能。

我

们将使用Hugging Face Transformers库中的Trainer

API简化训

练循环。让我们看一下设

置它所需的步骤！

加载预

训练模型

我们要做的第

一件事是使用我们在基

于特征的方法中一样的

DistilBERT预训练模型。唯一的细微

修改是我们使用

AutoModelForSequenceClassification模型而

不是AutoModel。区别在

于AutoModelForSequenceClassification模型在预

训练模型输出的顶

部有

一个分类头，可以很容易

地与基础模型一起训练

。我们只需要指

定模型需

要预测的标注数量（在我

们的情况下为6个），因为这

决定了

分类头输出的数

量：

你会看到一个警告，说

明模型的某些部分是随

机初始化的。这是正常

的

，因为分类头还没有被训

练。接下来的步骤是定义

我们将用于评估

模型在

微调期间的性能的指标

。

定义性能指标

为了在训

练期间监控指标，我们需

要为Trainer定义一个

compute_metrics()函数。该函

数接收一个EvalPrediction对象（这是

一

个具有predictions和label_ids属性的命名元

组），并需要返回一

个将每

个指标名称映射到其值

的字典。对于我们的应用

，我们将计算

模型的F1分数

和准确率：

有了数据集和

度量指标后，在定义Trainer类之

前，我们只需要处理最

后

两件事情：

1.登录我们的Hugging Face Hub账

户。从而让我们能够将我

们的微

调模型推送到Hub上

，并与社区分享它。

2.定义训

练运行的所有超参数。

接

下来我们将解决这些步

骤。

训练模型

如果你使用

Jupyter notebook，你可以使用下面的辅助

函数来登录到

Hub：

然后会显

示一个小部件，你可以在

其中输入你的用户名和

密码，或具

有写入权限的

访问令牌。你可以在Hub文档

中找到有关如何创建访

问令

牌的详细信息（https://oreil.ly/IRkN1）。如果

你使用命令行终

端，则可

以通过运行以下命令登

录：

我们将使用TrainingArguments类来定义

训练参数。此类存储了大

量信

息，从而为训练和评

估提供细粒度的控制。最

重要的参数是

output_dir，它是存储

训练过程中所有工件的

位置。以下是

TrainingArguments的完整示例

：

这里我们还设置了批量

大小、学习率和迭代轮数

，并指定在训练运行

结束

时加载最佳模型。所有组

件都齐全了，我们可以使

用Trainer实例

化和微调我们的

模型：

我们可以看到我们

的模型在验证集上的F1分

数约为92%，这比基于特征

的

方法有了显著的提升！

我

们可以通过计算混淆矩

阵来更详细地查看训练

指标。为了可视化混

淆矩

阵，我们首先需要获取验

证集上的预测结果。Trainer类的

predict()方法返回了几个有用的

对象，我们可以用它们进

行评估：

predict()方法的输出是一

个PredictionOutput对象，它包含了

predictions和label_ids的数

组，以及我们传给训练器

的度量指标。

我们可以通

过以下方式访问验证集

上的度量指标：

它还包含

了每个类别的原始预测

值。我们可以使用np.argmax()进行贪

婪解码预测，然后会得到

预测标注，并且结果格式

与前面的基于特征

的方

法相同，以便我们进行比

较：

我们可以基于这个预

测结果再次绘制混淆矩

阵：

可见，与前面的基于特

征的方法相比，微调方法

的结果更接近于理想

的

对角线混淆矩阵。love类别仍

然经常与joy混淆，这点逻辑

上也讲得

过去。surprise也经常被

错误地识别为joy，或者与fear混

淆。总体而

言，模型的性能

似乎非常不错，但在我们

结束之前，让我们深入了

解

模型可能会犯的错误

的类型。

使用Keras进行微调

如

果你使用的是TensorFlow，那么还可

以使用Keras API微调模型。

其与PyTorch API的

主要区别在于，没有Trainer类，因

为Keras模型

已经提供了内置

的fit()方法。为了了解具体是

如何工作的，这里我们

将

加载DistilBERT模型的TensorFlow版本：

接下来

，我们将把数据集转换为

tf.data.Dataset格式。因为我们已经

填充

了词元化输入，所以我们

可以通过将to_tf_dataset()方法应用于

emotions_encoded轻松完成此转换：

在这里

，我们还对训练集进行了

随机化，定义了它和验证

集的批量大

小。最后要做

的是编译和训练模型：

误

差分析

在继续之前，我们

应该更深入地研究一下

模型的预测。一个简单而

又

强大的技巧是按模型

损失对验证样本进行排

序。当我们在前向传递期

间传递标注时，会自动计

算并返回损失。以下是返

回损失以及预测标

注的

函数：

我们可以再次使用

map()方法将此函数应用到所

有样本中以获得损失：

最

后，我们创建一个包含文

本、损失、预测标注、真实标

注的

DataFrame：

现在我们可以轻松

地根据损失升序或降序

对emotions_encoded进行排

序。此操作的目

的是检测以下内容之一

：

错误的标注

任何对数据

进行标注的过程都有可

能出错。数据标注者可能

会犯错误

或者存在分歧

，而从其他特征推断的标

注也有可能是错误的。如

果自

动标注数据很容易

，那么就不存在人工标注

数据这项工作了。因此，

有

些样本被错误标注是很

正常的。通过这种方法，我

们可以快速找到

并纠正

它们。

数据集的特性

在现

实世界中，数据集往往有

一定的杂乱。当输入为文

字时，输入中

的特殊字符

或字符串可能会对模型

的预测产生重大影响。检

查模型最

弱的预测可以

帮助识别这样的特征，清

理数据或注入类似的样

本可以

使模型更健壮。

让

我们先看一下损失最高

的数据样本：

我们可以清

楚地看到模型对某些标

注进行了错误的预测。另

外，似乎

有相当多的样本

没有明确的类，这可能是

被错误标注的或需要一

个新

类。特别是，joy似乎被多

次标注错误。通过这些信

息，我们可以改进

数据集

，这通常可以带来与增加

数据或使用更大的模型

一样大的（或

更大的）性能

提升！

当查看具有最低损

失的样本时，我们观察到

模型在预测sadness类时最

有信

心。深度学习模型非常擅

长找到和利用短路来进

行预测。因此，

值得花时间

查看模型最有信心的样

本，以便我们可以确信模

型不会错

误地利用文本

的某些特征。所以，让我们

也看一下损失最小的预

测：

▼（续）

通过上面操作，我们

可以看到joy有时会误标注

，而模型对预测

sadness标注最有

信心。通过这些信息，我们

可以有针对性地改进我

们

的数据集，并且还要关

注模型最有信心的类别

。

在使用训练好的模型之

前的最后一步是将其保

存以备后续使用。接下

来

我们将向你展示如何使

用Hugging

Face Transformers库来完成这

个任务。

储

存和共享模型

NLP社区通过

共享预训练和微调模型

获益匪浅，每个人都可以

通过

Hugging

Face Hub与他人共享自己的

模型。任何社区生成的模

型都

可以像我们下载DistilBERT模

型一样从Hub中下载。我们可

以通过使用

Trainer API非常简单地

保存和共享模型：

我们也

可以使用微调模型来对

新的推文进行预测。由于

我们已将模型

推到了Hub上

，因此现在我们可以通过

pipeline()函数来使用它，就像

在第

1章中所做的那样。首先，让

我们加载pipeline：

然后用一条样

本推文来测试pipeline：

最后，我们

可以用条形图绘制每个

类别的概率。很明显，模型

估计最

可能的类是joy，这对

于给定的推文似乎是合

理的：

2.4

本章小结

祝贺你，现

在你知道了如何训练一

个用于分类推文情感的

Transformer

模型！我们已经讨论了基

于特征和微调的两种互

补方法，并研究了它

们的

优势和劣势。

然而，这只是

使用Transformer模型构建实际应用

程序的第一步，我们

还有

很多工作要做。以下是在

NLP旅程中可能遇到的挑战

清单：

我的老板希望我的

模型昨天就上线了！

在大

多数应用程序中，你并不

希望你的模型闲置，你希

望将它用于预

测！当模型

被推送到Hub时，会自动创建

一个推理端点，可以使用

HTTP

请求调用它。如果你想了

解更多信息，建议查看推

理API的文档

（https://oreil.ly/XACF5）。

我的用户需要

更快的预测！

我们已经讨

论了解决此问题的一种

方法：使用DistilBERT。在第8章

中，我们

将深入研究知识蒸馏（DistilBERT创

建的过程）以及其他加

速

Transformer模型的技巧。

你的模型是

否也可以执行X任务？

正如

我们在本章中所提到的

，Transformer模型非常多才多艺。在本

书

的其余部分中，我们将

使用相同的基本架构探

索一系列任务，例如问

答

和命名实体识别。

我的文

本不是英语！

事实证明，Transformer模

型能够支持多语言，在第

4章中，我们将使

用它们同

时处理多种语言。

我没有

标注数据！

如果可用的标

注数据非常少，则可能不

能进行微调。在第9章中，我

们

将探讨一些应对这种

情况的技术。

现在我们已

经了解了如何训练和共

享Transforme。在第3章中，我们将

探索

如何从头开始实现我们

自己的Transformer模型。

第3章

Transformer架构剖

析

在第2章中，我们了解了

对于Transformer模型进行微调和评

估需要的

条件。现在我们

来看看它们里面是如何

工作的。在本章中，我们将

探

索Transformer模型的主要组成部

分，以及如何使用PyTorch实现它

们。我们还将提供关于如

何在TensorFlow实现相同内容的指

导。我们

首先专注于构建

注意力机制，然后添加必

要的部分来使Transformer编

码器起

作用。我们还会简要地探

讨编码器和解码器模块

之间的架构差

异。在本章

结束时，你将能够自己实

现一个简单的Transformer模型！

尽管

深入理解Transformer架构对于使用

Hugging

Face Transformers库并微调模型以适用于

你的用例通常不

是必要

的，但这有助于理解和应

对Transformer的局限性，并在新领域

中使用它们。

本章还将介

绍一种Transformer分类法，帮助你理

解近年来涌现的多种

模

型。在深入代码之前，我们

先了解一下推动Transformer革命的

最初

架构。

3.1

Transformer架构

正如我们

在第1章中看到的那样，原

始Transformer是基于编码器-解码

器

架构的，该架构广泛用于

机器翻译等任务中，即将

一个单词序列从

一种语

言翻译成另一种语言。该

架构由两个组件组成：

编

码器

将一个词元的输入

序列转化为一系列嵌入

向量，通常被称为隐藏状

态

或上下文。

解码器

利用

编码器的隐藏状态，逐步

生成一个词元的输出序

列，每次生成一

个词元。

而

编码器和解码器又由如

图3-1所示的几个构建块组

成。

图3-1：Transformer的编码器-解码器架

构，图中上半部分为编码

器，下半部分为解码器

我

们很快将详细讨论每个

组件，但我们已经可以从

图3-1中看到一些

Transformer架构的特

性：

●输入的文本会使用第

2章中所介绍的技术进行

词元化，并转换成词元

嵌

入。由于注意力机制不了

解词元之间的相对位置

，因此我们需要一

种方法

将词元位置的信息注入

输入，以便模拟文本的顺

序性质。也就

是说，词元嵌

入会与包含每个词元位

置信息的位置嵌入进行

组合。

●编码器由一系列编

码器层或“块”堆叠而成，类

似于计算机视觉中

叠加

卷积层。解码器也是如此

，由一系列解码器层堆叠

而成。

●编码器的输出被提

供给每个解码器层，然后

解码器生成一个对于序

列中下一个最可能的词

元的预测。该步骤的输出

随后被反馈回解码器

以

生成下一个词元，以此类

推，直到达到特殊的结束

序列（EOS）词

元。在图3-1的例子中

，假设解码器已经预测了

“Die”和“Zeit”。

现在它会把这两个作

为输入，并作为所有编码

器的输出，来预测下一

个

词元“fliegt”。在下一步中，解码器

将“fliegt”作为额外的输

入。我们

重复这个过程，直到解码

器预测出EOS词元或我们达

到了最大

长度。

Transformer架构最初

是为序列到序列的任务

（如机器翻译）而设计

的，但

编码器和解码器模块很

快就被抽出来单独形成

模型。虽然

Transformer模型已经有数

百种不同的变体，但其中

大部分属于以下三

种类

型之一：

纯编码器

这些模

型将文本输入序列转换

为富数字表示的形式，非

常适用于文本

分类或命

名实体识别等任务。BERT及其

变体，例如RoBERTa和

DistilBERT，属于这类架

构。此架构中为给定词元

计算的表示取决于

左侧

（词元之前）和右侧（词元之

后）上下文。这通常称为双

向注意

力。

纯解码器

针对

像“谢谢你的午餐，我有一

个……”这样的文本提示，这类

模型

将通过迭代预测最

可能的下一个词来自动

完成这个序列。GPT模型家族

属于这一类。在这种架构

中，对于给定词元计算出

来的表示仅依赖于

左侧

的上下文。这通常称为因

果或自回归注意力。

编码

器-解码器

这类模型用于

对一个文本序列到另一

个文本序列的复杂映射

进行建

模。它们适用于机

器翻译和摘要任务。除了

Transformer架构，它将编

码器和解码

器相结合，BART和T5模型也属于

这个类。

Y. Liu

and M. Lapata，“Text Summarization with Pretrained

Encoder”（https://arxiv.org/abs/1908.08345），（2019）.

实际上，纯解码器

和纯编码器架构的应用

之间的区别有些模糊不

清。

例如，像GPT系列中的纯解

码器模型可以被优化用

于传统上认为是序列

到

序列任务的翻译任务。同

样，BERT等纯编码器模型也可

以应用于通

常与编码器

-解码器或纯解码器模型

相关的文本摘要任务注

。

现在你已经对Transformer架构有了

高层次的理解，接下来我

们将更深

入地了解编码

器的内部工作原理。

3.2

编码

器

正如我们之前所看到

的，Transformer的编码器由许多编码

器层相互堆

叠而成。如图

3-2所示，每个编码器层接收

一系列嵌入，然后通过以

下

子层进行馈送处理：

●一

个多头自注意力层。

●一个

全连接前馈层，应用于每

个输入嵌入。

每个编码器

层的输出嵌入尺寸与输

入嵌入相同，我们很快就

会看到编

码器堆叠的主

要作用是“更新”输入嵌入

，以产生编码一些序列中

的

上下文信息的表示。例

如，如果单词“苹果”附近的

单词是“主题演

讲”或“电话

”，那么该单词将被更新为

更像“公司”的特性，而不

是

更像“水果”的特性。

图3-2：编码

器层放大图

这些子层同

样使用跳跃连接和层规

范化，这些是训练深度神

经网络的

常用技巧。但要

想真正理解Transformer的工作原理

，我们还需要更深

入地研

究。我们从最重要的构建

模块开始：自注意力层。

3.2.1

自

注意力机制

正如我们在

第1章中讨论的那样，注意

力机制是一种神经网络

为序列中

的每个元素分

配不同权重或“注意力”的

机制。对文本序列来说，元

素则为我们在第2章遇到

的词元嵌入（其中每个词

元映射为固定维度的

向

量）。例如，在BERT中，每个词元表

示为一个768维向量。自注意

力

中的“自”指的是这些权

重是针对同一组隐藏状

态计算的，例如编码

器的

所有隐藏状态。与自注意

力相对应的，与循环模型

相关的注意力

机制则计

算每个编码器隐藏状态

对于给定解码时间步的

解码器隐藏状

态的相关

性。

自注意力的主要思想

是，不是使用固定的嵌入

值来表示每个词元，而

是

使用整个序列来计算每

个嵌入值的加权平均值

。另一种表述方式是

说，给

定词元嵌入的序列x，…，x，自注

意力产生新的嵌入序列

，其

中每个是所有x的线性

组合：

1nj

M. E. Peters et al.,

“Deep Contextualized Word

Representations”（https://arxiv.org/abs/1802.05365），

（2017）.

左边的flies为飞的意思

，所以上下文嵌入与表示

飞的soars相近。右

边的flies为苍蝇

的意思，所以上下文嵌入

与表示昆虫的insect相近。

其中

的系数wji称为注意力权重

，其被规范化以使得∑jwji=1。如果

想

要了解为什么平均词

元嵌入可能是一个好主

意，那么可以这样思考，

当

你看到单词“flies”时会想到什

么。也许你会想到令人讨

厌的昆

虫，但是如果你得

到更多的上下文，比如

“time

flies like an arrow”，那

么你会意识到“flies”表示

的是

动词。同样地，我们可以通

过以不同的比例结合所

有词元嵌入来

创建“flies”的表

示形式，也许可以给“time”和“arrow”的

词元

嵌入分配较大的权

重wji。用这种方式生成的嵌

入称为上下文嵌入，早

在

Transformer发明之前就存在了，例如

ELMo语言模型 。图3-3展示

了这一

过程，我们通过自注意力

根据上下文生成了“flies”的两

种不

同表示 。

图3-3：自注意力

将原始的词元嵌入（顶部

）更新为上下文嵌入（底

部

），从而创建包含了整个序

列信息的表示

现在我们

看一下注意力权重是如

何计算的。

缩放点积注意

力

A. Vaswani

et al., “Attention Is All You

Need”

（https://arxiv.org/abs/1706.03762），（2017）.

实现自注意力层的方

法有好几种，但最常见的

是那篇著名的

Transformer架构论文

所介绍的缩放点积注意

力（scaled dot￾product attention）。要实现这种机制，需要

四个主要步骤：

1.将每个词

元嵌入投影到三个向量

中，分别称为query、key和value。

2.计算注意

力分数。我们使用相似度

函数确定query和key向量的相关

程度。顾名思义，缩放点积

注意力的相似度函数是

点积，并通过嵌入

的矩阵

乘法高效计算。相似的query和

key将具有较大的点积，而那

些

没有相似处的则几乎

没有重叠。这一步的输出

称为注意力分数，在一

个

有n个输入词元的序列中

，将对应着一个n×n的注意力

分数矩阵。

3.计算注意力权

重。点积在一般情况下有

可能会产生任意大的数

，这

可能会导致训练过程

不稳定。为了处理这个问

题，首先将注意力分数

乘

以一个缩放因子来规范

化它们的方差，然后再通

过softmax进行规范

化，以确保所

有列的值相加之和为1。结

果得到一个n×n的矩阵，该矩

阵包含了所有的注意力

权重wji。

4.更新词嵌入。计算完

注意力权重之后，我们将

它们与值向量v，…，

v相乘，最终

获得词嵌入表示。

1n

我们可

以使用一个很赞的库，Jupyter的

BertViz

（https://oreil.ly/eQK3I），来可视化以上的注意力

权重计算过

程。该库提供

了一些可用于可视化Transformer模

型的不同方面注意力

的

函数。如果想可视化注意

力权重，我们可以使用neuron_view模

块，

该模块跟踪权重计算

的过程，以显示如何将query向

量和key向量相结

合以产生

最终权重。由于BertViz需要访问

模型的注意力层，因此我

们

将使用BertViz中的模型类来

实例化我们的BERT checkpoint，然后使

用

show()函数为特定的编码器层

和注意力头生成交互式

可视化。请注

意，你需要单

击左侧的“+”才能激活注意

力可视化。

从以上可视化

图中，我们可以看到query向量

和key向量的值表示为一

条

条的条带，其中每个条带

的强度对应于其大小。连

线的权重是根据

词元之

间的注意力加权的，我们

可以看到，“flies”的query向量与

“arrow”的key向

量重叠最强。

揭开query、key和value的神

秘面纱

在你第一次接触

query、key和value向量的概念时，可能会

觉得这些概

念有点晦涩

难懂。这些概念受到信息

检索系统的启发，但我们

可以用

一个简单的类比

来解释它们的含义。你可

以这样想象，你正在超市

购

买晚餐所需的所有食

材。你有一份食谱，食谱里

面每个食材可以视为

一

个query。然后你会扫描货架，通

过货架上的标注（key），以检查

该商品是否与你列表中

的食材相匹配（相似度函

数）。如果匹配成

功，那么你

就从货架上取走这个商

品（value）。

在这个类比中，你只会

得到与食材匹配的商品

，而忽略掉其他不匹配

的

商品。自注意力是这个类

比更抽象和流畅的版本

：超市中的每个标

注都与

配料匹配，匹配的程度取

决于每个key与query的匹配程度

。因

此，如果你的清单包括

一打鸡蛋，那么你可能会

拿走10个鸡蛋、一个

煎蛋卷

和一个鸡翅。

缩放点积注

意力过程的更详细细节

可以参见图3-4。

图3-4：缩放点积

注意力中的操作

本章我

们将使用PyTorch实现Transformer架构，使用

TensorFlow实现

Transformer架构的步骤与之类

似。两个框架中最重要的

函数之间的映

射关系详

见表3-1。

表3-1：本章中使用的PyTorch和

TensorFlow（Keras）的类和方法

我们需要做

的第一件事是对文本进

行词元化，因此我们使用

词元分析

器提取输入ID：

正

如我们在第2章所看到的

那样，句子中的每个词元

都被映射到词元分

析器

的词表中的唯一ID。为了保

持简单，我们还通过设置

add_special_tokens=False来将[CLS]和[SEP]词元排除在外。接

下

来，我们需要创建一些

密集嵌入。这里的密集是

指嵌入中的每个条目

都

包含一个非零值。相反，我

们在第2章所看到的独热

编码是稀疏的，

因为除一

个之外的所有条目都是

零。在PyTorch中，我们可以通过使

用

torch.nn.Embedding层来实现这一点，该层

作为每个输入ID的查找

表

：

在这里，我们使用AutoConfig类加载

了与bert-base￾uncased

checkpoint相关联的config.json文件。在

Hugging Face Transformers库

中，每个checkpoint都被分配一个配

置文件，该文件指定了各

种超参数，例如vocab_size和hidden_size。

在我们

的示例中，每个输入ID将映

射到nn.Embedding中存储的30 522

个嵌入向

量之一，其中每个向量维

度为768。AutoConfig类还存储其他

元数

据，例如标注名称，用于格

式化模型的预测。

需要注

意的是，此时的词元嵌入

与它们的上下文是独立

的。这意味

着，同形异义词

（拼写相同但意义不同的

词），如前面例子中的

“flies”（“飞行

”或“苍蝇”），具有相同的表示

形式。后续的注

意力层的

作用是将这些词元嵌入

进行混合，以消除歧义，并

通过其上

下文的内容来

丰富每个词元的表示。

现

在我们有了查找表，通过

输入ID，我们可以生成嵌入

向量：

这给我们提供了一

个形状为[batch_size，seq len，hidden_dim]的

张量，就像我

们在第2章中看到的一样

。这里我们将推迟位置编

码，因

此下一步是创建query、key和

value向量，并使用点积作为相

似度函数

来计算注意力

分数：

这产生了一个5×5矩阵

，其中包含批量中每个样

本的注意力分数。稍

后我

们将看到，query、key和value向量是通过

将独立的权重矩阵WQ应

用

到嵌入中生成的，但这里

为简单起见，我们将它们

设为相等。在缩

放点积注

意力中，点积按照嵌入向

量的大小进行缩放，这样

我们在训

练过程中就不

会得到太多的大数，从而

可以避免下一步要应用

的

softmax饱和。

,K,V

torch.bmm()函数执行批量矩

阵乘积，简化了注意力分

数的计算过程，

其中query和key向

量的形状为[batch_size，seq_len，hidden_dim]。

如果我们忽

略批处理维度，那么我们

可以通过简单地转置key张

量以使

其形状为[hidden

dim，seq len]，然后使

用矩阵乘积来收集所有

在

[seq_len，seq_len]矩阵中的点积。由于我

们希望对批处理中的所

有

序列独立地执行此操

作，因此我们使用torch.bmm()，它接收

两个矩阵

批处理并将第

一个批处理中的每个矩

阵与第二个批处理中的

相应矩阵

相乘。

接下来我

们应用softmax：

最后将注意力权

重与值相乘：

这就是全部

了，我们已经完成了简化

形式的自注意力机制实

现的所有

步骤！请注意，整

个过程仅涉及两个矩阵

乘法和一个softmax，因此你

可以

将“自注意力”视为一种花

哨的平均形式。

我们把这

些步骤封装成一个函数

，以便以后我们可以重用

它：

我们的注意力机制在

query向量和key向量相等的情况

下，会给上下文

中相同的

单词分配非常高的分数

，特别是给当前单词本身

：query向量

与自身的点积总是

1。而实际上，一个单词的含

义将更好地受到上下文

中其他单词的影响，而不

是同一单词（甚至自身）。以

前面的句子为

例，通过结

合“time”和“arrow”的信息来定义“flies”的含

义，

比重复提及“flies”要更好。那

么我们如何实现这点？

我

们可以让模型使用三个

不同的线性投影将初始

词元向量投影到三个

不

同的空间中，从而允许模

型为query、key和value创建一个不同的

向

量集。

多头注意力

前面

提到，我们将query、key和value视为相等

来计算注意力分数和权

重。但在实践中，我们会使

用自注意力层对每个嵌

入应用三个独立的

线性

变换，以生成query、key和value向量。这些

变换对嵌入进行投

影，每

个投影都带有其自己的

可学习参数，这使得自注

意力层能够专

注于序列

的不同语义方面。

同时，拥

有多组线性变换通常也

是有益的，每组变换代表

一种所谓的

注意力头。多

头注意力层如图3-5所示。但

是，为什么我们需要多个

注

意力头？原因是一个注

意力头的softmax函数往往会集

中在相似度的某

一方面

。拥有多个头能够让模型

同时关注多个方面。例如

，一个头负

责关注主谓交

互，而另一个头负责找到

附近的形容词。显然，我们

没

有在模型中手工制作

这些关系，它们完全是从

数据中学习到的。如果

你

对计算机视觉模型熟悉

，你可能会发现其与卷积

神经网络中的滤波

器相

似，其中一个滤波器负责

检测人脸，而另一个滤波

器负责在图像

中找到汽

车的车轮。

图3-5：多头注意力

现在我们来编码实现，首

先编写一个单独的注意

力头的类：

这里我们初始

化了三个独立的线性层

，用于对嵌入向量执行矩

阵乘

法，以生成形状为[batch_size，seq_len，head_dim]的

张量，其中

head_dim是我们要投影

的维数数量。尽管head_dim不一定

比词元的嵌

入维数（embed_dim）小，但

在实践中，我们选择head_dim是

embed_dim的

倍数，以便跨每个头的计

算能够保持恒定。例如，BERT有

12个注意力头，因此每个头

的维数为768/12=64。

现在我们有了

一个单独的注意力头，因

此我们可以将每个注意

力头的

输出串联起来，来

实现完整的多头注意力

层：

请注意，注意力头连接

后的输出也通过最终的

线性层进行馈送，以生

成

形状为[batch_size，seq_len，hidden_dim]的输出张量，以适

用于

下游的前馈网络。为

了确认，我们看看多头注

意力层是否产生了我们

输入的预期形状。在初始

化MultiHeadAttention模块时，我们传递了

之

前从预训练的BERT模型中加

载的配置。这确保我们使

用与BERT相同

的设置：

这么做

是可行的！最后，我们再次

使用BertViz可视化单词“flies”

的两个

不同用法的注意力。这里

我们可以使用BertViz的head_view()

函数，通

过计算预训练checkpoint的注意力

并指示句子边界的位置

来

显示注意力：

这种可视

化展示了注意力权重，表

现为连接正在被更新嵌

入的词元

（左侧）与所有被

关注的单词（右侧）之间的

线条。线条的颜色深度

表

现了注意力权重的大小

，深色线条代表值接近于

1，淡色线条代表值

接近于

0。

在这个例子中，输入由两

个句子组成，[CLS]和[SEP]符号是我

们在第2

章中遇到的BERT的词

元分析器中的特殊符号

。从可视化结果中我们可

以看到注意力权重最大

的是属于同一句子的单

词，这表明BERT能够判

断出它

应该关注同一句子中的

单词。然而，对于单词“flies”，我们

可以看到BERT已经识别出在

第一句中“arrow”是重要的，在第

二句中

“fruit”和“banana”是重要的。这些

注意力权重使模型能够

根据它

所处的上下文来

区分“flies”到底应该为动词还

是名词！

至此我们已经讲

述完注意力机制了，我们

来看一下如何实现编码

器层

缺失的一部分：位置

编码前馈神经网络。

3.2.2

前馈

层

编码器和解码器中的

前馈子层仅是一个简单

的两层全连接神经网络

，

但有一点小小的不同：它

不会将整个嵌入序列处

理为单个向量，而是

独立

处理每个嵌入。因此，该层

通常称为位置编码前馈

神经网络。有

时候你还会

看到它又被称为内核大

小为1的1维卷积，这种叫法

通常来

自具有计算机视

觉背景的人（例如，OpenAI GPT代码库

就是这么叫

的）。论文中的

经验法则是第一层的隐

藏尺寸应为嵌入尺寸的

四倍，

并且最常用的激活

函数是GELU。这是大部分容量

和记忆发生的地方，

也是

扩展模型时最经常进行

缩放的部分。我们可以将

其实现为一个简

单的nn.Module，如

下所示：

需要注意的是，像

nn.Linear这样的前馈层通常应用

于形状为

（batch_size，input_dim）的张量上，它将

独立地作用于批量维度

中

的每个元素。这对于除

了最后一个维度之外的

任何维度都是正确的，

因

此当我们将形状为（batch_size，seq_len，hidden_dim）的张

量传

给该层时，该层将独

立地应用于批量和序列

中的所有词元嵌入，这正

是我们想要的。我们可以

通过传递注意力输出来

测试这一点：

现在我们已

经拥有了创建完整的Transformer编

码器层的所有要素！唯

一

剩下的部分是决定在哪

里放置跳跃连接和层规

范化。我们看看这会

如何

影响模型架构。

3.2.3

添加层规

范化

如前所述，Transformer架构使用

了层规范化和跳跃连接

。前者将批处

理中的每个

输入规范化为零均值和

单位方差。跳跃连接直接

将张量传

给模型的下一

层，而不做处理，只将其添

加到处理的张量中。在将

层

规范化放置在Transformer的编码

器或解码器层中时，论文

提供了两种

选项：

后置层

规范化

这是Transformer论文中使用

的一种结构，它把层规范

化置于跳跃连接

之后。这

种结构从头开始训练时

会比较棘手，因为梯度可

能会发散。

因此，在训练过

程中我们经常会看到一

个称为学习率预热的概

念，其

中学习率在训练期

间从一个小值逐渐增加

到某个最大值。

前置层规

范化

这是论文中最常见

的布局，它将层规范化置

于跳跃连接之前。这样做

往往在训练期间更加稳

定，并且通常不需要任何

学习率预热。

这两种方式

的区别如图3-6所示。

图3-6：Transformer编码

器层中层规范化的两种

方式

这里我们将使用第

二种方式，因此我们可以

简单地将我们的基本构

件

粘在一起，如下所示：

现

在使用我们的输入嵌入

来测试一下：

在更高层面

的术语中，自注意力层和

前馈层称为置换等变的

——如果

输入被置换，那么层

的相应输出将以完全相

同的方式置换。

我们已经

成功地从头开始实现了

我们的第一个Transformer编码器层

！

然而，我们设置编码器层

的方式存在一个问题：它

们对于词元的位置

是完

全不变的。由于多头注意

力层实际上是一种精致

的加权和，因此

词元位置

的信息将丢失 。

幸运的是

，有一种简单的技巧可以

使用位置嵌入来整合位

置信息。我

们来看看。

3.2.4

位置

嵌入

位置编码基于一个

简单但非常有效的想法

：用一个按向量排列的位

置

相关模式来增强词元

嵌入。如果该模式对于每

个位置都是特定的，那

么

每个栈中的注意力头和

前馈层可以学习将位置

信息融合到它们的转

换

中。

有几种实现这个目标

的方法，其中最流行的方

法之一是使用可学习的

模式，特别是在预训练数

据集足够大的情况下。这

与仅使用词元嵌入

的方

式完全相同，但是使用位

置索引作为输入，而不是

词元ID。通过

这种方法，在预

训练期间可以学习到一

种有效的编码词元位置

的方

式。

我们创建一个自

定义的Embeddings模块，它将输入的

input_ids投影到

密集的隐藏状态

上，并结合Position_ids的位置嵌入进

行投影。最终

的嵌入层是

两个嵌入层的简单求和

：

我们可以看到嵌入层现

在为每个词元创建了一

个密集的嵌入。

这种可学

习的位置嵌入易于实现

并广泛使用，除此之外，还

有其他一

些方法：

绝对位

置表示

Transformer模型可以使用由

调制正弦和余弦信号组

成的静态模式来编

码词

元的位置。当没有大量数

据可用时，这种方法尤其

有效。

相对位置表示

通过

结合绝对和相对位置表

示的想法，旋转位置嵌入

在许多任务上取

得了优

秀的结果。GPT-Neo是一个采用旋

转位置嵌入的模型的例

子。

尽管绝对位置很重要

，但有观点认为，在计算嵌

入时，周围的词元最

为重

要。相对位置表示遵循这

种直觉，对词元之间的相

对位置进行编

码。这不能

仅通过在开头引入新的

相对嵌入层来设置，因为

相对嵌入

针对每个词元

会因我们对序列的访问

位置的不同而不同。对此

，注意

力机制本身通过添

加额外项来考虑词元之

间的相对位置。像DeBERTa等

模型

就使用这种表示

。

现在我

们把所有内容整合起来

，通过将嵌入与编码器层

结合起来构建

完整的Transformer编

码器：

我们检查编码器的

输出形状：

我们可以看到

在每个批量中，我们为每

个词元获取了一个隐藏

状态。

这种输出格式使得

架构非常灵活，我们可以

很容易地适应各种应用

，

例如在掩码语言建模中

预测缺失的词元，或者在

问答中预测回答的起

始

和结束位置。在3.2.5节中，我们

将讲述如何构建一个类

似于我们在

第2章中使用

的分类器。

3.2.5

添加分类头

Transformer模

型通常分为与任务无关

的主体和与任务相关的

头。我们

将在第4章讲述Hugging Face Transformers库

的设计模式时会再次

提

到这种模式。到目前为止

，我们所构建的都是主体

部分的内容，如

果我们想

构建一个文本分类器，那

么我们还需要将分类头

附加到该主

体上。每个词

元都有一个隐藏状态，但

我们只需要做出一个预

测。有

几种方法可以解决

这个问题。一般来说，这种

模型通常使用第一个词

元来进行预测，我们可以

附加一个dropout和一个线性层

来进行分类预

测。下面的

类对现有的编码器进行

了扩展以用于序列分类

：

在初始化模型之前，我们

需要定义希望预测的类

数目：

这正是我们一直在

寻找的。对于批处理中的

每个样本，我们会得到输

出中每个类别的非规范

化logit值。这类似于我们在第

2章中使用的

BERT模型（用于检

测推文中的情感）。

至此我

们对编码器以及如何将

其与具体任务的头相组

合的部分就结束

了。现在

我们将注意力（双关语！）转

向解码器。

3.3

解码器

如图3-7所

示，解码器和编码器的主

要区别在于解码器有两

个注意力子

层：

掩码多头

自注意力层

确保我们在

每个时间步生成的词元

只基于过去的输出和当

前正在预测

的词元。如果

没有这样做，那么解码器

将能够在训练时通过简

单复制

目标翻译来欺骗

我们，导致训练失败。我们

需要对输入进行掩码，以

确保任务不是简单复制

目标翻译。

编码器-解码器

注意力层1

请注意，与自注

意力层不同，编码器-解码

器注意力中的key和query向

量可

能具有不同的长度。这是

因为编码器和解码器输

入通常涉及长度

不同的

序列。因此，此层中的注意

力得分矩阵是矩形的，而

不是正方

形的。

对编码器

栈的输出key和value向量执行多

头注意力，并以解码器的

中

间表示作为query 。在这种方

式中，编码器-解码器注意

力层学习如

何关联来自

两个不同序列（例如两种

不同语言）的词元。在每个

块

中，解码器都可以访问

编码器的key和value。

图3-7：Transformer解码器层

放大图

我们来看一下需

要进行哪些修改才能在

自注意力层中添加掩码

，然后

将编码器-解码器注

意力层的实现作为一道

作业题留给你。掩码自注

意

力的技巧是引入一个

掩码矩阵，该矩阵对角线

下方的元素为1，上方的

元

素为0：

这里我们使用了PyTorch的

tril()函数来创建下三角矩阵

。一旦我们有

了这个掩码

矩阵，我们可以使用Tensor.masked fill()将所

有的0替

换为负无穷来防

止每个注意力头查看后

面的词元：

∞

通过将矩阵对

角线上方的值设为负无

穷，可以保证当我们对分

数进行

softmax时，注意力权重都

为0，因为e-=0（回想一下softmax计算的

是

规范化指数）。我们只需

要对本章早先实现的缩

放点积注意力函数进

行

一点点修改，就能轻松地

包含这种掩码行为：

这里

的解码器层实现相当简

单。如果你想了解更多，我

们建议读者参

考Andrej Karpathy创作的

minGPT的优秀实现

（https://oreil.ly/kwsOP）。

至此我们讲

述了很多技术细节，希望

你现在应该对Transformer架构每

个

部分的工作原理有了很

好的理解。在开始构建比

文本分类更高级的

任务

模型之前，我们稍微退后

一步，看一看Transformer模型的各种

分

支，以及它们之间的关

系。

揭秘编码器-解码器注

意力机制

这里我们用一

个示例看看是否帮助你

解开编码器-解码器注意

力的神秘

面纱。想象一下

，你（解码器）正在班上，参加

一场考试。你的任务

是根

据前面的单词（解码器输

入）来预测下一个单词，听

起来很简

单，但实际上非

常难（你自己试试，预测本

书的某一段的下一个单

词）。幸运的是，你旁边的同

学（编码器）拥有整篇文章

。不幸的

是，他们是留学生

，文章是用他们的母语写

的。不过聪明如你，你还

是

想出了一种作弊的方式

。你画了一幅小漫画，描述

了你已经拥有的

文章内

容（query），交给了你的同学。然后

他们会尝试找出哪一段

文

章与那个描述匹配（key），并

画一幅漫画描述紧随该

段文章之后的单

词（value），然后

把这个答案传给你。有了

这种系统性的帮助，你轻

松地通过了考试。

3.4

认识Transformer

正

如你在本章中看到的那

样，Transformer模型有三种主要的架

构：编

码器、解码器和编码

器-解码器。早期Transformer模型的初

步成功触

发了模型开发

的寒武纪爆发，研究人员

在各种大小和性质的数

据集上

使用新的预训练

目标构建各种模型，并调

整架构以进一步提高性

能。

虽然模型的种类仍在

迅速增长，但它们仍然可

以分为三大类。

在本节中

，我们将简要介绍这三大

类以及每种类中比较重

要的模型。

我们先来看看

Transformer家族树。

3.4.1

Transformer的生命树

随着时

间的推移，三种主要的架

构都进行了各自的演进

。图3-8展示了

一些最著名的

模型及其后代。

Transformer模型总计

有超过50种不同的架构，因

此图3-8未能涵盖所

有架构

，它只列出了一些重要的

里程碑。在本章前面部分

，我们已经

详细介绍了Transformer模

型最初的架构，现在我们

着重研究一些比较

关键

的后代架构，我们先从编

码器分支开始。

3.4.2

编码器分

支

A. Wang

et al., “GLUE: A Multi-Task Benchmark

and Analysis

Platform for Natural Language

Understanding”

（https://arxiv.org/abs/1804.07461），（2018）.

基于Transformer架构的第一个纯

编码器模型是BERT。当初它发

布时，

在流行的GLUE基准测试

中 （该测试度量跨几个难

度级别的NLU任

务），它的表现

优于所有当时最先进的

模型。在此之后，BERT的预训

练

目标和架构持续进行适

配并进一步提高了性能

。纯编码器模型仍然

在NLU任

务（如文本分类、命名实体

识别和问答）的研究和工

业中占主

导地位。我们简

要地讲述一下BERT模型及其

变体：

图3-8：Transformer最突出的架构及

生命树

BERT

J.

Devlin et al., “BERT:Pre-Training of Deep

BidirectionalTransformersfor Language Understanding”

（https://arxiv.org/abs/1810.04805），（2018）.

BERT针对这两个目标

进行预训练：预测文本中

的掩码词元，确定一个

文

本段是否有可能跟随另

一个文本段

。前者称为掩

码语言建模

（MLM），后者称为下

一句预测（NSP）。

DistilBERT

V. Sanh et

al., “DistilBERT，a Distilled Version of

BERT:Smaller，Faster，Cheaper

and Lighter”

（https://arxiv.org/abs/1910.01108），（2019）.

虽然BERT取得了极

好的结果，但它太大了，使

其在需要低延迟的环境

中部署变得棘手。通过在

预训练期间使用一种称

为知识蒸馏的技术，

DistilBERT实现

了97%的BERT性能，同时使用的内

存量减少了40%，速

度提高了

60%

。有关知识蒸馏的更多详

细信息，请参见第8章。

RoBERTa

Y. Liu et al.,

“RoBERTa:A Robustly Optimized BERT

Pretraining Approach”（https://arxiv.org/abs/1907.11692），

（2019）.

在BERT发

布之后进行的一项研究

表明，通过修改预训练方

案，可以进

一步提高其性

能。RoBERTa采用更大的批量、更多

的训练数据进行更长

时

间的训练，并且放弃了NSP任

务 。这些改变与原始的BERT模

型相比

显著提高了性能

。

XLM

G. Lample, and A. Conneau,

“Cross-Lingual Language Model

Pretraining”（https://arxiv.org/abs/1901.07291）, （2019）.

跨语言语言模型（XLM）

探索了

几种用于构建多语言模

型的预训练目

标，包括来

自类GPT模型的自回归语言

建模和来自BERT的MLM。此外，

XLM预训

练论文的作者还介绍了

翻译语言建模（TLM），这是MLM对多

语

言输入的扩展。通过实

验这些预训练任务，它们

在几个多语言NLU基准

测试

以及翻译任务中取得了

最先进的结果。

XLM-RoBERTa

A. Conneau et al., “Unsupervised Cross-Lingual

Representation Learning at Scale”

（https://arxiv.org/abs/1911.02116），（2019）.

基于XLM和RoBERTa的

研究，XLM-RoBERTa或XLM-R模型通过大规模

扩展

训练数据将多语言

预训练推向了更高的水

平 。该模型的开发人员使

用Common Crawl语料库（https://commoncrawl.org）创建了一个包

含2.5TB文本的数据集，并在此

数据集上训练了一个编

码器MLM。由于

该数据集没有

平行文本（即译文），因此放

弃了XLM的TLM目标。这种

方法在

低资源语言方面大幅领

先于XLM和多语言BERT变体。

ALBERT

Z. Lan et al., “ALBERT:A Lite

BERT for Self-Supervised

Learning of Language

Representations”

（https://arxiv.org/abs/1909.11942），（2019）.

ALBERT模型

做了三处改进使得编码

器的架构更加高效 。首先

，它从

隐藏维度解耦了词

元嵌入的维度，从而能够

让嵌入维度更小，从而节

省参数，尤其是当词汇量

很大时。其次，所有层共享

相同的参数，从

而能够进

一步降低参数数量。最后

，将NSP目标替换为句子排序

预测：

模型预测两个连续

句子的顺序是否交换了

，而不是预测它们是否属

于

同一个文档或主题。这

些改变令使用更少的参

数训练更大的模型，并

在

NLU任务中达到更高的性能

成为可能。

ELECTRA

K. Clark

et al., “ELECTRA:Pre-Training Text Encoders as

Discriminators Rather Than Generators”

（https://arxiv.org/abs/2003.10555），（2020）.

标准MLM的预训练

目标有一个局限性，在每

个训练步骤中，只更新了

掩

码词元的表示，而没有

更新其他输入词元。为解

决这个问题，ELECTRA

采用了一种

双模型方法 ：第一个模型

（通常很小）像标准的掩码

语

言模型一样工作，预测

掩码的词元；然后，第二个

模型（鉴别器）预

测第一个

模型输出中的哪些词元

最初是被掩码的。换句话

说，鉴别器

需要对每个词

元进行二分类，这种方法

使训练效率提高了30倍。在

使

用ELECTRA模型执行下游任务

时，判别器将像标准BERT模型

一样进行微

调。

DeBERTa

P. He et

al., “DeBERTa:Decoding-Enhanced BERT with

Disentangled Attention”

（https://arxiv.org/abs/2006.03654），（2020）.

A. Wang et al., “SuperGLUE:A

Stickier Benchmark for General￾Purpose Language Understanding

Systems”

（https://arxiv.org/abs/1905.00537），（2019）.

DeBERTa模型做了

两个架构上的改进 。首先

，每个词元表示为两个向

量：一个表示内容，另一个

表示相对位置。通过将词

元的内容与相对

位置分

离，自注意力层可以更好

地建模相邻词元对的依

赖关系。另一

方面，单词的

绝对位置也很重要，特别

是对于解码。因此，在词元

解

码头的softmax层之前添加了

一个绝对位置嵌入。DeBERTa是第

一个

（作为集合）在SuperGLUE基准测

试 上击败人类基线的模

型

（SuperGLUE是GLUE的更难版本，由用于

度量NLU性能的几个子任务

组

成）。

至此我们讲述了一

些主要的纯编码器模型

，我们来看一下纯解码器

模

型。

3.4.3

解码器分支

Transformer解码器

模型的进展在很大程度

上是由OpenAI所推动的。这

些模

型在预测序列中下一个

单词方面表现出色，因此

主要用于文本生

成任务

（更多细节请参见第5章）。它

们的进展是通过使用更

大的数据

集和将语言模

型扩展到更大规模来推

动的。我们来看看这些迷

人的生

成模型的演变历

史：

GPT

A. Radford et

al., “Improving Language Understanding by

Generative

Pre-Training”（https://openai.com/blog/language￾unsupervised），OpenAI（2018）.

GPT将自然语言处理中的

两个关键思想融合在了

一起 ：新颖高效的

Transformer解码器

架构和迁移学习。在该架

构中，模型通过基于前面

的单词预测下一个单词

来预训练。该模型使用了

BookCorpus进行训

练，在分类等下游

任务上取得了优秀的结

果。

GPT-2

A. Radford et al., “Language Models

Are Unsupervised

Multitask Learners”（https://openai.com/blog/betterlanguage￾models），OpenAI（2019）.

受以上GPT简单且可扩展

的预训练方法成功的启

发，GPT-2对原始模型

和训练集

进行了升级

。GPT-2能够产生一

系列连贯的文本。由于担

心

可能被误用，因此GPT-2分阶

段发布，先发布较小的模

型，然后再发布

完整的模

型。

CTRL

N.S. Keskar

et al., “CTRL:A ConditionalTransformerLanguage

Model for

Controllable Generation”

（https://arxiv.org/abs/1909.05858），（2019）.

像GPT-2这样的模型可以根

据输入序列（即提示）生成

延续输出。然

而，用户对所

生成序列的风格控制较

弱。条件转换语言（CTRL）模型

通

过在序列开头添加“控制

词元”来解决这个问题

。这

样可以控制

所生成文本

的风格，实现多样化的生

成。

GPT-3

J. Kaplan et

al., “Scaling Laws for Neural Language

Models”

（https://arxiv.org/abs/2001.08361），（2020）.

T. Brown et al.,

“Language Models Are Few-Shot Learners”

（https://arxiv.org/abs/2005.14165），（2020）.

GPT在升级成GPT-2之后取得了

成功，OpenAI对不同规模的语言

模型的

行为进行了彻底

的分析，发现计算量、数据

集大小、模型大小和语言

模型的性能之间存在着

简单的幂律规律 。受到这

些分析的启发，

OpenAI对GPT-2放大100倍

，得到了拥有1750亿个参数的

GPT-3 。GPT-

3除了能够生成令人印象

深刻的逼真文本段落外

，还展现出少样本学习

的

能力：只需要提供少量的

几个任务样本（如将文本

翻译成代码），

GPT-3就能够在新

样本上完成新的任务。OpenAI没

有开源GPT-3，但提

供了API（https://oreil.ly/SEGRW）接口供

人们调用。

GPT-Neo/GPT-J-6B

S. Black

et al., “GPT-Neo:Large Scale Autoregressive

Language

Modeling with Mesh-TensorFlow”

（https://doi.org/10.5281/zenodo.5297715），（2021）； B.

Wang

and A. Komatsuzaki，“GPT-J-6B:A 6 Billion Parameter

Autoregressive Language Model”

（https://github.com/kingoflolz/mesh-transformer-jax），

（2021）.

GPT-Neo和GPT-J-6B类似于GPT，由EleutherAI

（https://eleuther.ai）训

练，EleutherAI是一个旨在重新创建

和发

布GPT-3同等规模模型的

研究人员组织 。GPT-Neo和GPT-J-6B是GPT-3

的1750亿

个参数完整版本的较小

变体，具有13亿、27亿和60亿个参

数，主要与OpenAI提供的GPT-3模型较

小版本相竞争。

Transformer生命树的

最后一个分支是编码器

-解码器模型。

3.4.4

编码器-解码

器分支

虽然目前业内通

常使用纯编码器或纯解

码器栈来构建模型，但是

Transformer架构有几种编码器-解码

器变体在自然语言理解

和生成领

域都具有创新

应用。

T5

C. Raffel

et al., “Exploring the Limits of

Transfer Learning

with a Unified Text-to-Text

Transformer”

（https://arxiv.org/abs/1910.10683），（2019）.

T5模型将所有的自然

语言理解和生成任务都

转化为文本到文本任务

（即序列到序列任务），统一

了它们的处理方式。既然

所有任务都被

定义为序

列到序列任务，因此就自

然而然采用了编码器-解

码器架构。

例如，对于文本

分类问题，编码器的输入

是文本，而解码器的输出

则

是文本而不是类（即将

预测标注生成为文本）。我

们将在第6章中更详

细地

讨论这个问题。T5模型使用

Transformer原始架构，数据使用C4数

据

集（一个超大规模的文本

语料库，爬取了各种来源

的网页文本数

据）。T5模型将

所有SuperGLUE任务转换为文本到

文本任务进行掩码语

言

建模预训练。其中110亿个参

数的最大版本在几个基

准测试中取得了

当时业

界最好的成绩。

BART

M. Lewis et al., “BART: Denoising

Sequence-to-Sequence Pre￾Training for Natural Language Generation,

Translation, and

Comprehension”（https://arxiv.org/abs/1910.13461）,

（2019）.

BART将BERT和GPT的预

训练流程整合进编码器

-解码器架构中 。BART

对输入序

列进行了多种变换，包括

从简单掩码到句子置换

、词元删除

和文档反转。这

些修改后的输入被传入

编码器中进行处理，然后

由解

码器重构为原始文

本。通过这种方式，BART模型具

有更强的灵活性，

既可以

用于NLU任务，也可以用于自

然语言生成（N L G）任务，并

且在

两方面都取得了最先进

的性能表现。

M2M-100

A. Fan et al.,

“Beyond English-Centric Multilingual Machine

Translation”（https://arxiv.org/abs/2010.11125），（2020）.

传统上，翻译

模型是针对一种语言对

和一个翻译方向构建的

。显然，

这无法扩展到众多

语言，而实际上有些知识

是可以在多种语言对之

间

共享的，这些知识可以

用于在罕见语言之间进

行翻译。M2M-100是第一

个可以在

任意100种语言之间进行翻

译的翻译模型 。这样就可

以对罕

见和少数民族语

言进行高质量的翻译。该

模型使用前缀词元（类似

于

[CLS]特殊词元）来表示源语

言和目标语言。

BigBird

M. Zaheer et al., “Big

Bird:Transformersfor Longer

Sequences”（https://arxiv.org/abs/2007.14062），（2020）.

Transformer模型的一

个主要局限是注意力机

制的二次存储需求，导致

最大上下文大小受到限

制。BigBird通过使用线性缩放的

稀疏注意力形

式来解决

这个问题 。这种方法令BigBird的

最大上下文大小从大多

数

BERT模型的512个词元扩展到

了4096个词元，从而能够容纳

更多的上下

文知识。这对

需要保存长依赖项的场

景特别有用，例如文本摘

要。

本章提到的所有模型

的预训练checkpoint都可以在

Hugging Face Hub（https://oreil.ly/EIOrN）上找

到，并可以像

第2章所描述

的那样使用Transformers进行微调以

适应你的用户场景。

3.5

本章

小结

本章我们从Transformer架构的

核心——自注意力机制的深

入研究开

始，随后逐步添

加了所有必要的组成部

分来构建Transformer编码器模

型。我

们添加了用于词元和位

置信息的嵌入层，构建了

一个前馈层以

补充注意

力头，最后，我们往模型主

体添加了一个分类头来

进行预

测。我们还研究了

Transformer架构的解码器部分，并在

本章末尾浏览

了Transformer最重要

的三种分支和模型架构

。

现在你已经对基本原理

有了更好的理解，让我们

超越第2章简单的分类

模

型，构建一个多语言的命

名实体识别模型吧。

第4章

多语言命名实体识别

到

目前为止，在本书中，我们

已经应用Transformer来解决英文文

本的

自然语言处理任务

。但是，如果文档是用希腊

语、斯瓦希里语或克林

贡

语写的呢？一种方法是在

Hugging Face Hub上寻找合适的预训练

语

言模型，然后对手头的任

务进行微调。然而，这些预

训练模型往往

只适用于

像德语、俄语或汉语这样

的“高资源”语言，因为这些

语言

有大量的网络文本

可用于预训练。当你使用

多语言语料库时，另一个

常见的挑战是对你和你

的工程团队来说，在生产

环境中维护多个单语

言

模型并不是一件有趣的

事。

幸运的是，有一类多语

言Transformer模型可以将你从这种

处境中拯救

出来。像BERT一样

，这些模型使用掩码语言

建模作为预训练目标，不

过不同的是，它们是在100多

种语言的文本上联合训

练的。通过在多种

语言的

庞大语料库上进行预训

练，这些多语言Transformer模型实现

了

零样本跨语言迁移。这

意味着在一种语言上微

调的模型无须进行任何

进一步的训练就可以在

其他语言上应用！这也使

得这些模型非常适合

于

“代码切换”，即在单个对话

的上下文中，说话者交替

使用两种或

更多语言或

方言。

A. Conneau et

al., “Unsupervised Cross-Lingual

Representation Learning at

Scale”

（https://arxiv.org/abs/1911.02116），（2019）.

在这一章中，我们将

讲述一种名为XLM-RoBERTa 的Transformer模型

（曾

在第3章介绍过），以及如何

对其进行微调以在多种

语言中进行

NER的。正如我们

在第1章看到的那样，NER是一

种常见的自然语言处理

（NLP）任务，该任务识别文本中

的人物、组织或地点等实

体。这些实

体可以用于各

种应用，例如从企业文档

中获取洞见、增强搜索引

擎的

质量，或者简单地从

语料库构建结构化数据

库。

本章我们假设要为一

个位于瑞士的客户进行

命名实体识别，因为瑞士

有四种官方语言（通常使

用英语作为它们之间的

桥梁）。我们第一步

是获取

一个适合此问题的多语

言语料库。

零样本迁移或

零样本学习通常指的是

在一个标注集上训练模

型，然后

在另一个标注集

上进行评估。不过在谈到

Transformer模型的时候，零

样本学习

也有可能是指在下游任

务上评估像GPT-3这样的语言

模型，即

使该模型并没有

经过微调。

4.1

数据集

J. Hu

et al., “XTREME: A Massively Multilingual

Multi-Task

Benchmark for Evaluating Cross-Lingual Generalization”

（https://arxiv.org/abs/2003.11080），（2020）； X. Pan et

al., “Cross-Lingual

Name Tagging and Linking for 282

Languages，”Proceedings of the 55th Annual Meeting

of the

Association for Computational Linguistics

1（July 2017）:

1946-1958，http://dx.doi.org/10.18653/v1/P17-1178.

本章我

们将使用跨语言传输多

语言编码器（XTREME）基准测试的

子

集，即WikiANN，又称PAN-X 。该数据集包

括多种语言的维基百科

文

章，其中包括瑞士使用

最广泛的四种语言：德语

（62.8%）、法语

（22.9%）、意大利语（8.4%）和英语（5.9%）。每

篇文章都用LOC

（位置）、PER（人物）和

ORG（组织）并以IOB2格式进行标注

（https://oreil.ly/yXMUn）。在IOB2这种格式中，B-前缀表示

实体

的开头，位于之后的

属于同一实体的连续词

元则赋予I-前缀。O标记表

示

该词元不属于任何实体

。以如下句子为例：

该句子

会以IOB2格式标注，如表4-1所示

。

表4-1：命名实体序列标注示

例

要在XTREME中加载PAN-X的一个子

集，我们需要知道要传给

load_dataset()函数的数据集配置。每当

要处理具有多个领域的

数据

集时，你可以使用get_dataset_config_names()函

数来查找可用的子

集。

有

183个配置！太多了！我们需要

缩小搜索范围，我们只寻

找以

“PAN”开头的配置：

好的，看

来我们已经明确了PAN-X子集

的语法规则：每个子集都

有一个

后缀，该后缀由两

个字母组成，看起来是一

个ISO 639-1语言代码

（https://oreil.ly/R8XNu）。这意味着，要

加载德语语料库，我们

需

要将de代码传给load dataset()的name参数，如

下所示：

为了创建一个真

实的瑞士语语料库，我们

将从PAN-X中按照前面所述的

口语比例提取德语（de）、法语

（fr）、意大利语（it）和英语

（en）语料库

。我们这么做将会造成语

言类别不平衡，这在现实

世界

的数据集中非常普

遍，其中由于缺乏熟练掌

握该语言的领域专家，获

取少数民族语言的标注

样本可能会很昂贵。这种

不平衡的数据集将能

够

模拟在多语言应用程序

中工作时的常见情况，我

们将看到如何构建

一个

可以处理所有语言的模

型。

为了追踪每种语言，我

们创建一个Python

defaultdict，将语言代码

作为key并将类型为DatasetDict的PAN-X语料

库作为value进行存储：

这里我

们使用shuffle()方法确保不会意

外地偏向某个数据集拆

分，而

select()方法允许我们根据

fracs中的值对每个语料库进

行下采样。然

后我们可以

通过访问Dataset.num_rows属性来查看训

练集中每种语言

的实例

数量：

按照前面的设计，我

们在德语方面拥有比其

他所有语言加起来都多

的

样本，所以我们将以德

语作为起点，向法语、意大

利语和英语进行零

样本

跨语言迁移。我们先从德

语语料库中抽一个样本

：

与我们之前遇到的Dataset对象

一样，我们样本的key对应于

Arrow表的

列名称，而value表示每个

列中的条目。值得一提的

是，我们看到

ner_tags列对应于每

个实体所映射的类别ID。人

类难以一下看懂这一

列

所代表的具体含义，所以

我们将创建一个人类能

够看懂的LOC、PER

和ORG标记的新列

。讲到这里，值得一提的是

，我们的Dataset对象有

一个features属性

，该属性指定了与每列相

关联的底层数据类型：

Sequence类

指定了该字段所包含的

特征列表，对于ner_tags来说，它

对

应于ClassLabel特征的列表。现在我

们从训练集中提取这个

特征列

表，具体方法如下

：

我们可以使用第2章提到

过的ClassLabel.int2str()方法，为训练集创

建

一个新列，该列包含每个

标记的类名。我们将使用

map()方法返回一

个字典（dict），其中

key对应新列名，value为类名列表

（list）：

现在我们已经将标记转

换成人类可读的格式，我

们看看在训练集的第

一

个样本中，词元和标记的

对齐结果：

我们可以看到

，上述结果中的LOC标记是有

用的，因为句子

“2000

Einwohnern an der Danziger Bucht in

der polnis

chen Woiwodschaft Pommern”在英语中

的意思是“波兰波美拉尼

亚

省的格但斯克湾有2000名

居民”，其中格但斯克湾是

波罗的海的一个

海湾，而

“voivodeship”则对应于波兰的一个省

。

接下来我们快速检查一

下，确保标记之间没有不

寻常的不平衡，我们

计算

每个拆分中每个实体的

频率：

这看起来很不错，PER、LOC和

ORG出现频率的分布在每个

拆分中大致相

同，因此验

证集和测试集应该能够

很好地度量我们的NER标注

器的泛化

能力。接下来，我

们介绍一下几个流行的

多语言Transformer以及如何

对它们

进行适配以解决我们的

NER任务。

4.2

多语言Transformer

多语言Transformer采用

与其单语言对应物相似

的架构和训练程序，不

同

之处在于用于预训练的

语料库包含多种语言的

文档。这种方法的一

个显

著特点是，尽管没有接收

任何明确的区分语言的

信息，但生成的

语言表示

能够在各种下游任务中

很好地进行跨语言泛化

。在某些情况

下，这种跨语

言迁移能力可以产生与

单语言模型类似的结果

，从而不

需要单独为每种

语言训练一个模型！

为了

度量NER的跨语言迁移进展

，通常使用CoNLL-2002

（https://oreil.ly/nYd0o）和CoNLL-2003

（https://oreil.ly/sVESv）数据集作为

英语、荷兰语、西班牙语和

德语的基准。这个基准数

据集由新闻文章组成，使

用与PAN-X相同的

LOC、PER和ORG类别进行

标注，但还包括一个用于

表示词元不属于前三

个

组的MISC（杂项）实体标注。多语

言Transformer模型通常以三种不

同

的方式进行评估：

en

在英语

训练数据上进行微调，然

后在每种语言的测试集

上进行评估。

each

针对每种语

言的测试数据进行微调

和评估，以度量每种语言

的性能。

all

在所有的训练数

据上进行微调，然后在每

种语言的测试数据集上

进行

评估。

我们将采用类

似的评估策略来评估我

们的实体识别任务，但首

先我们

需要选择一个要

评估的模型。最早的多语

言Transformer之一是

mBERT，它使用与BERT相同

的架构和预训练目标，但

将多种语言的维基

百科

文章添加到了预训练语

料库中。不过现在mBERT已被XLM-RoBERTa

（或

简称为XLM-R）所取代了，因此我

们在本章中将使用XLM-R模型

。

正如我们在第3章所看到

的那样，XLM-R仅使用MLM作为100种语

言的预

训练目标，但与其

先前的版本相比，其预训

练语料库的规模巨大：每

种语言都有维基百科转

储数据和2.5TB来自网络的Common Crawl数

据。该语料库比早期模型

使用的语料库大几个数

量级，并为像缅甸语

和斯

瓦希里语这样的低资源

语言提供了显著的信号

提升（这些语言只

有少量

的维基百科文章可用）。

Y. Liu et al.,

“RoBERTa: A Robustly Optimized BERT

Pretraining

Approach”（https://arxiv.org/abs/1907.11692），

（2019）.

T. Kudo and J.

Richardson，“SentencePiece:A Simple and

Language Independent Subword

Tokenizer and Detokenizer for

Neural Text

Processing”

（https://arxiv.org/abs/1808.06226），（2018）.

XLM-RoBERTa模

型名称中的RoBERTa部分是指其

预训练方法与RoBERTa单

语言模

型相同。RoBERTa的开发人员改进

了BERT的几个方面，特别是完

全删除了下一句预测任

务 。XLM-R也删除了XLM中使用的语

言嵌入，

并使用SentencePiece直接词元

化原始文本

。除了其多语

言特性外，

XLM-R和RoBERTa之间的一个

值得注意的区别是其各

自词表的大小：

XLM-R有250 000个词元

，而RoBERTa只有55 000个！

综上所述，XLM-R是进

行多语言自然语言理解

任务的绝佳选择。在接下

来的部分中，我们将探讨

如何在多语言中有效进

行词元化。

4.3

多语言词元化

技术

XLM-R使用一种名为SentencePiece的词

元分析器，而不是使用

WordPiece词

元分析器。SentencePiece词元分析器是

基于所有100种语

言的原始

文本进行训练的。为了了

解SentencePiece和WordPiece之间

的比较，现在我

们使用Hugging

Face Transformers库加载BERT和

XLM-R词元分

析器。

然后我们编码一个

小文本序列

“Jack Sparrow

loves New York!”，我们发现词

元分析器还可

以检索出

每个模型在预训练期间

所使用的特殊词元：

从以

上结果可以看到，XLM-R使用<s>和

</s>来表示序列的起始和结

束，而不是BERT用于句子分类

任务的[CLS]和[SEP]词元。这些词元

是

在词元化的最后阶段

添加的，接下来我们将讲

解这一步。

4.3.1

词元分析器pipeline

到

目前为止，我们将词元化

视为将字符串转换为可

以传给模型的整数

的单

个操作。这并不完全准确

，如果深究，那么我们可以

看到整个

pipeline通常由四个步

骤组成，具体如图4-1所示。

图

4-1：词元化pipeline中的步骤

现在我

们通过例句“Jack Sparrow loves New York!”更详细地

讲

解一下每个处理步骤：

规

范化

这一步对原始字符

串进行一系列操作（清理

）。常见的操作包括去除

空

格和移除重音符号。Unicode规范

化（https://oreil.ly/2cp3w）是

另一种常见的规范

化操作，许多词元分析器

都应用它来解决同一个

字

符存在多种写法的场

景。具体来说，同一抽象字

符序列可能会有两个

版

本的表示，而诸如NFC、NFD、NFKC和NFKD这样

的Unicode规范化方案

则将同一

字符的不同写法转换为

一种标准形式。规范化的

另一个例子

是将字符串

全部转为小写字母。因为

如果模型只需要处理小

写字符，

那么这种技术可

以用来减小所需的词表

大小。在规范化后，我们的

示

例字符串将会变成“jack sparrow loves

new york!”。

词

元化预处理

这一步将文

本拆分为较小的对象。可

以将词元化预处理器视

为将文本

拆分为“单词”的

工具，最终的词元将是这

些单词的一部分。对于英

语、德语、法语等印欧语言

而言，字符串通常可以根

据空格和标点符

号进行

拆分。以我们的示例为例

，这一步将得到

["jack"，"sparrow"，"loves"，"new"，"york"，"!"]。这样操作

之

后，这些单词后面可以

更简单地在pipeline的下一步中

使用字节对编

码（BPE）或Unigram算法

来拆分为子词。然而，将文

本拆分为“单

词”并非总是

一个简单和确定性的操

作，甚至可能不是合理的

操作。

例如，在中文、日文或

韩文等语言中，将符号组

合成语义单元（如印

欧语

言中的单词）可能是一个

具有多个同样有效组别

的非确定性操

作。在这种

情况下，最好使用特定于

语言的库进行词元化预

处理。

词元化模型

当输入

文本规范化和词元化预

处理完成之后，词元分析

器对单词应用

子词拆分

模型。这一步需要根据你

的语料库进行训练（如果

使用预训

练的词元分析

器，则已经完成了训练）。该

模型的作用是将单词拆

分

成更小的子词，以减小

词表的大小，并尝试减少

无法识别的词元数

量。常

见的子词拆分算法包括

BPE、Unigram和WordPiece等。例如，在

应用词元化

模型之后，我们的示例可

能被拆分为[jack，spa，rrow，

loves，new，york，!]。请注意，此时

我们拥有的不再是字符

串列

表，而是整数列表（即

输入ID）。为了更加生动形象

地描述这一过

程，我们省

略了引号。

后处理

这是整

个pipeline的最后一步，主要是对

词元列表进行一些额外

的转

换，例如，在输入的词

元索引序列的开头或结

尾添加特殊词元。例

如，BERT风

格的词元分析器将添加

分类和分隔符词元，于是

我们的示

例就变成了：[CLS，jack，spa，rrow，loves，new，york，!，

SEP]。至

此，这个序列（请记住，这将

是整数序列，而不是你在

这里

看到的字符串序列

）已经走完整个pipeline，可以输入

模型了。

回到前面我们对

XLM-R和BERT的比较，我们现在明白

了SentencePiece

是在后处理步骤中添

加了<s>和</s>，而不是[CLS]和[SEP]（方便起

见，我们将在图示中继续

使用[CLS]和[SEP]）。现在我们再次回

到

SentencePiece词元分析器，看看它还

有什么特殊之处。

4.3.2

SentencePiece词元分

析器

SentencePiece词元分析器基于一

种称为Unigram的子词分割类型

，并

将每个输入文本编码

为Unicode字符序列。这一特点对

于处理多语言语

料库尤

其有用，因为它能够忽略

重音符号、标点符号以及

许多语言

（如日语）中没有

空格字符的情况。此外，SentencePiece的

另一个特

别之处在于，它

使用Unicode符号U+2581或者__字符（又称

为下四分之

一块字符）来

表示空格。这使得SentencePiece能够无

歧义地反词元化

序列，也

不需要依赖特定于语言

的词元化预处理器。还是

以我们前面

的示例为例

，我们可以看到WordPiece丢失了“York”和

“!”之间的

空格信息。而SentencePiece则保

留了词元化后的文本中

的空格，因此

我们可以无

歧义地将其转换回原始

文本。这一特性尤其适用

于处理多

语言文本，因为

它可以保持原始文本的

完整性，而不会引入额外

的歧

义。

现在我们理解了

SentencePiece的工作原理，我们看看如

何将简单示例

编码成适

合NER的形式。第一件事是使

用带有词元分类头的预

训练模

型。但是，我们不会

直接从Hugging Face Transformers库中加载这

个头

，而是自己构建它！通过深

入研究Hugging Face

Transformers

库API，我们可以只用

几个步骤就完成这个过

程。

4.4

命名实体识别中的Transformers

在

第2章中，我们看到在文本

分类中，BERT使用特殊的[CLS]词元

开头

来表示整个文本序

列。然后，该表示经过一个

全连接或密集层输出所

有离散标注值的分布，如

图4-2所示。

图4-2：针对序列分类

任务，对纯编码器Transformer模型进

行微调

BERT和其他纯编码器

Transformer模型在命令实体识别方

面采用了与

NER相似的方法

，不同之处在于将每个输

入词元的表示馈送到相

同的全

连接层以输出词

元的实体（图4-2的序列分类

只输出一个标注）。因

此，NER通

常被框定为词元分类任

务。具体过程大致如图4-3所

示。

图4-3：针对命名实体识别

任务，对纯编码器Transformer模型进

行微

调

到目前为止，一切

都很好，但在词元分类任

务中，我们应该如何处理

子词呢？例如，图4-3中的名字

“Christa”被词元化为子词“Chr”和

“##ista”，那么

应该将哪一个或哪几个

子词分配为B-PER标注？

J. Devlin et

al., “BERT:Pre-Training of Deep

BidirectionalTransformersfor Language

Understanding”

（https://arxiv.org/abs/1810.04805），（2018）.

在BERT论文

中 ，作者将此标注分配给

第一个子词（在我们的示

例中

则为“Chr”），并忽略后续的

子词（“##ista”）。因此我们将遵循

该

惯例，并用IGN标注要忽略的

子词。这样在稍后的后处

理步骤中，我

们可以轻松

地将预测标注传给后续

的子词。我们也可以选择

包含

“##ista”子词的表示，即将其

分配为B-LOC标注的副本，但这

样做违

反了IOB2格式。

幸运的

是，由于XLM-R的架构基于RoBERTa，而RoBERTa与

BERT完全相

同，因此我们在BERT中

看到的所有架构方面都

可以用于XLM-R!接下

来，我们将

看到如何通过轻微修改

来支持Transformer模型类中的许多

其他任务。

4.5

自定义Hugging Face Transformers库模型

类

Hugging Face

Transformers库是根据任务来组织

和架构的。因此模

型类根

据不同的任务按照<Model Name>For<Task>的惯

例来命名，或

者当使用AutoModel类

时按照AutoModelFor<Task>命名。

然而，这种方

法无法包揽全部任务。假

设你有一个伟大的想法

，想用

Transformer模型解决一直困扰

你的NLP问题。所以，你安排了

一次会

议，通过出色的PPT演

示，向老板推销说如果你

能解决这个问题，就可

以

增加部门的收入。老板被

你出色的演示和对利润

增长的建议所打

动，慷慨

地同意给你一周时间来

构建一个概念验证（PoC）。看到

老板

这样，你十分兴奋，立

即开始工作。你启动GPU并打

开notebook开始编

码。可是当你执

行from transformers

import Bert ForTaskXY

（这里的TaskXY是你想解决的

假想NLP任务）后，当可怕的红

色报错布

满了你的屏幕

时，你脸上变色了：

ImportError:

cannot import nameBertForTaskXY。噢，目前

没有

适合你这个用例的

BERT模型！你只有一周时间，如

果你必须要自己实

现这

个模型，你应该如何开始

？

不要惊慌！Hugging

Face Transformers库的设计初衷

就是让你能够

轻松地扩

展现有模型以适应你的

特定用例。你可以从预训

练模型加载

权重，然后使

用特定于任务的辅助函

数。这样你就可以以极小

的成本

为你的特定目标

构建自定义模型。本节我

们将讲述如何实现自己

的自

定义模型。

4.5.1

主体和头

能令Hugging Face Transformers库如此通用的主要

思想是将架构分

为主体

和头（如我们在第1章中所

看到的）。我们已经看到，当

我们从

预训练任务转换

到下游任务时，我们需要

用适合该任务的层替换

模型

的最后一层。这个最

后一层被称为模型头，它

是与任务相关的部分。

模

型的其余部分称为主体

，包括词元嵌入和Transformer层，这些

层是

通用的、与任务无关

的。这种结构表现在具体

的代码实现类中，模型

主

体在BertModel或GPT2Model之类的类中实现

，这些类将返回最后一

层

隐藏状态。而BertForMaskedLM或

BertForSequence

Classification则为与任

务相关的模型类，它们基

于基础模型，然后在隐藏

状态之上添加必要的头

，具体如图4-4所示。

图4-4：BertModel类只包

含模型的主体部分，而BertFor<Task>类

将

主体部分与具体任务

的专用头结合起来

正如

接下来我们将看到的那

样，这种将主体和头分离

的方法使我们能

够为任

何任务构建一个自定义

头，然后将其安装到预训

练模型之上。

4.5.2

创建用于词

元分类的自定义模型

这

里我们通过建立一个适

用于XLM-R的自定义词元分类

头的练习来进行

学习。由

于XLM-R使用与RoBERTa相同的模型架

构，因此我们将使用

RoBERTa作为

基本模型，然后在此之上

增加适用于XLM-R的设置。需要

注意的是，本练习出于教

学目的，旨在向你展示如

何为自己的任务构

建自

定义模型。在实际工作中

，对于词元分类，

Hugging

Face Transformers库已经有

一个名为

XLMRobertaForTokenClassification的类可以使用

，你可以直接导入

该类。因

此如果需要的话，你可以

跳过本节，直接使用该类

。

在开始之前，我们需要一

个能够代表我们的XLM-R NER标注

器的数据

结构。我们需要

一个配置对象来初始化

模型，以及一个forward()函数

来生

成输出。我们按如下方式

构建用于词元分类的XLM-R类

。

这里config_class确保在初始化新模

型时使用标准的XLM-R设置。如

果

你想更改默认的参数

，则可以通过覆盖配置中

的默认设置来实现。使

用

super()方法调用RobertaPreTrainedModel类的初始化函

数。这个抽

象类处理预训

练权重的初始化或加载

。然后，我们加载我们的模

型主

体，即RobertaModel，并使用自己的

分类头进行扩展，其中包

括一个

dropout和一个标准前馈

层。请注意，我们设置

add_pooling_layer=False，以确

保所有隐藏状态都被返

回，而不仅仅

是与[CLS]词元相

关联的状态。最后，我们通

过调用从

RobertaPreTrainedModel继承的init weights()方法来

初始化所有权

重，该方法

将为模型主体加载预训

练权重，并随机初始化我

们的词元

分类头的权重

。

我们唯一需要做的是定

义模型如何在forward()方法中进

行前向传递。

在前向传递

期间，首先将数据通过模

型主体进行馈送。有许多

输入变

量，但我们现在所

需的只是input_ids和attention_mask。随后，将模

型

主体输出的隐藏状态馈

送到dropout和分类层中。如果我

们在前向传

递还提供了

标注，则可以直接计算损

失。如果存在注意力掩码

，则需

要做一些额外的工

作以确保我们仅计算未

掩码词元的损失。最后，我

们将所有输出包装在TokenClassifierOutput对

象中，从而允许我们通

过

前几章中熟悉的命名元

组来访问元素。

通过实现

一个简单类的两个函数

，我们可以构建自己的自

定义

Transformer模型。由于我们继承

自PreTrainedModel，因此能立即获

得Hugging

Face Transformers库所

有有用的Transformer工具，如

from_pretrained()！接下来

我们看看如何将预训练

的权重加载到我们

的自

定义模型中。

4.5.3

加载自定义

模型

现在我们准备加载

词元分类模型。除了模型

名称之外，我们还需要提

供一些额外的信息，包括

我们将用于词元每个实

体的标记以及每个标

记

与ID之间的映射和反向映

射。所有这些信息都可以

从我们的tags变

量中进行推

导，tags变量作为一个ClassLabel对象具

有一个names属

性，我们可以使

用它来推导映射：

我们将

把这些映射和tags.num classes属性存储

在我们在第3章遇到

的AutoConfig对

象中。向from pretrained()方法传关键字参

数将覆

盖默认值：

AutoConfig类包含

一个模型架构的蓝图。当

我们使用

AutoModel.from_pretrained（model_ckpt）载入一个模型

时，与该模

型相关联的配

置文件将被自动下载。然

而，如果我们想要修改像

类别

数或标注名称之类

的内容，那么我们可以先

载入配置文件，然后使用

我们想要自定义的参数

来进行修改。

现在，我们可

以使用带有附加config参数的

from_pretrained()函数像

往常一样加载模

型权重。请注意，我们的自

定义模型类中没有实现

加

载预训练权重，我们可

以通过继承RobertaPreTrainedModel来马上获

得

该功能。

然后我们要快速

检查一下，验证我们是否

正确初始化了词元分析

器和

模型，我们使用一个

已经知道实体标注的小

序列来预测结果以进行

测

试：

正如你所看到的，起

始词元<s>和结束词元</s>分别

被赋予ID为0和2。

最后，我们需

要将输入传给模型，并通

过获取argmax来提取预测结

果

，以获取每个词元最有可

能的类。

在这里，我们可以

看到logit的形状为[batch_size，num_tokens，

num_tags]，每个词元

都被赋予了7个可能的NER标

记中的一个。通过枚

举整

个序列，我们可以快速查

看预训练模型的预测结

果：

毫不意外，使用随机权

重的词元分类层存在许

多不足，我们需要使用

一

些标注数据进行微调以

使其更好！在微调之前，我

们将前面的步骤

封装成

一个辅助函数，以备后用

：

在训练模型之前，我们还

需要对输入进行词元化

并准备标注。接下来

我们

将进行词元化。

4.6

NER的词元化

现在我们已经确定了词

元分析器和模型可以对

单个样本进行编码，下

一

步是对整个数据集进行

词元化，以便我们可以将

其传给XLM-R模型进

行微调。正

如我们在第2章所看到的

那样，Hugging Face

Datasets

库提供了一种使用

map()操作快速对Dataset对象进行词

元化的方法。

为实现以上

方法，我们首先需要定义

一个具有最小签名的函

数：

其中，examples相当于Dataset的一个切

片，例如panx_de[‘train’]

[:10]。由于XLM-R词元分析器

返回模型输入的输入ID，因

此我们只需

要使用注意

力掩码和标注ID来增强该

信息，这些标注ID编码关于

哪个

词元与每个NER标记相

关联的信息。

按照Hugging Face Transformers库文档

（https://oreil.ly/lGPgh）所采用的方法，我们首先

将德语例句的

词元和NER标

记提取为普通列表：

接下

来，我们对每个单词进行

词元化，并使用is_split_into_words参

数告诉

词元分析器我们的输入

序列已经被分成了单词

。

在这个例子中，我们可以

看到词元分析器将“Einwohnern”分成

了两

个子词，即“__Einwohner”和“n”。因为我

们遵循的约定是仅将

“__Einwohner”与

B-LOC标注相关联，所以我们需

要一种方式在第一

个子

词之后掩码子词表示。幸

运的是，tokenized_input类包含了一个

word_ids()函

数，可以帮助我们实现这

一点。

在这里，我们可以看

到word ids将每个子词映射到相

应的words序列

索引，因此第一

个子词“__2.000”被分配索引0，而“__Einwohner”

和

“n”被分配索引1（因为“Einwohnern”是words中的

第二个单

词）。我们还可以

看到像<s>和</s>这样的特殊词

元被映射为None。我

们可以将

-100设置为这些特殊词元及

训练过程中要掩码的子

词的标

注：

为什么我们选

择把子词表示中的ID掩码

为-100呢？原因在于在PyTorch

中，交叉

熵损失类torch.nn.CrossEntropyLoss有一个称为

ignore_index的

属性，其值为-100。在训练过程

中，这个索引值会被

忽略

，因此我们可以通过掩码

为-100来忽略与连续子词相

关的词元。

这就是全部工

作了！我们可以清楚地看

到标注ID如何与词元对齐

，然

后我们将所有逻辑封

装进一个函数里面，并将

其应用于整个数据集：

我

们现在已经具备了编码

每个数据集分割所需的

所有元素，因此我们

编写

一个可以迭代的函数：

将

这个函数应用到DatasetDict对象上

，我们得到了每个数据集

分割编

码后的Dataset对象。我们

使用这个函数来编码我

们的德语语料库：

现在我

们已经有了一个模型和

数据集，我们还需要定义

一个性能度

量。

4.7

性能度量

评估命名实体识别模型

与评估文本分类模型类

似，通常会报告查准

率、召

回率和F1分数的结果。唯一

的复杂之处在于，为了使

预测被计

算为正确，实体

的所有单词都需要被正

确预测。幸运的是，有一个

名

为seqeval（https://oreil.ly/xbKOp）的实用库专门为这

类任务设

计。例如，给定一

些占位符NER标注和模型预

测，我们可以通过

seqeval的classification_report()函数

计算该指标。

正如我们所

看到的，seqeval期望将预测值和

标注作为列表的列表传

入，其中每个列表对应于

验证集或测试集中的单

个样本。为了在训练

过程

中集成这些度量指标，我

们需要一个能够接收模

型输出并将其转

换为seqeval所

期望的列表的函数。下面

的函数可以通过确保忽

略与后

续子词相关联的

标注ID来实现此目的：

在配

备了性能指标后，我们可

以继续训练模型。

4.8

微调XLM-RoBERTa

现

在我们已经有了微调模

型所需的所有条件！我们

将尝试第一种策

略：在PAN-X数

据集的德语子集上对我

们的基础模型进行微调

，然后评

估它在法语、意大

利语和英语上的零样本

跨语言性能。像往常一样

，

我们将使用Hugging Face Transformers库的Trainer来处理

训练循

环，因此首先我们

需要使用TrainingArguments类定义训练属

性：

这里我们在每轮结束

时评估模型对验证集的

预测，调整权重衰减，并

将

save_steps设置为一个较大的数字

以禁用checkpoint来加快训练速

度

。

首先我们需要登录Hugging Face Hub（如果

你使用命令行终端，则

可

以执行命令huggingface-cli login）。

我们还需要

告诉Trainer如何在验证集上计

算指标，因此在这里我们

可

以使用之前定义的align_predictions()函

数来提取预测和标注，以

seqeval所需的格式来计算F1分数

。

最后一步是定义一个数

据整理器，这样我们就可

以将每个输入序列填

充

到批处理中的最大序列

长度。Hugging Face Transformers库为词

元分类提供

了一个专用的数据整理

器，它将连同输入一起填

充标注：

填充标注是必要

的，因为与文本分类任务

不同，标注也是序列。这里

的一个重要细节是，标注

序列用值-100进行填充，如前

所述，这个值

在PyTorch损失函数

中会被忽略。

本章我们会

训练多个模型，因此我们

要通过创建一个model_init()方

法来

避免为每个Trainer初始化一个

新模型。这个方法加载一

个未训练

的模型，并在train()调

用开始时被调用：

我们现

在可以将所有这些信息

和编码好的数据集一起

传给Trainer：

然后按照以下方式

运行训练循环，并将最终

模型推送到Hub：

这些F1分数对

于命名实体识别模型来

说相当不错。为了确认我

们的模

型按预期工作，我

们在示例的德语译文上

测试它。

它表现不错！但我

们不应该根据单个示例

的表现过于自信。相反，我

们应该对模型的错误进

行适当和彻底的调查。在

4.9节中，我们将探索

如何为

NER任务执行此操作。

4.9

错误分

析

在我们深入探讨XLM-R的多

语言方面之前，我们花一

分钟来调查我们模

型的

错误。正如我们在第2章所

看到的那样，对模型进行

彻底的错误分

析是训练

和调试Transformer（以及机器学习模

型）最重要的方面之

一。有

几种故障模式会让你觉

得模型表现得很好，而实

际上它存在一

些严重的

缺陷。训练可能失败的示

例包括：

●我们可能不小心

掩码了太多的词元，也掩

码了一些标注，以获得极

具潜力的损失下降。

●compute_metrics()函数

可能存在bug，导致高估真实

表现。

●我们可以将零类或

0实体作为正常类包括在

N E R中，但这会严重

偏移准确

率和F1分数的结果，因为它

是在数量上占绝大多数

的类。

当模型表现远远低

于预期时，查看错误可以

提供有用的见解，并揭示

只查看代码难以发现的

错误。即使模型表现良好

且代码中没有错误，

在模

型部署到生产环境后，错

误分析仍然是了解模型

优势和劣势的有

用工具

。在模型部署到生产环境

后，我们需要始终牢记这

些方面。

为了进行分析，我

们将再次使用手头上最

强大的工具之一，即查看

拥

有最高损失的验证样

本。我们可以重复使用第

2章中构建的用于分析序

列分类模型的代码，但现

在我们需要计算样本序

列中每个词元的损

失。

我

们定义一个可以应用于

验证集的方法：

现在我们

可以使用map()函数将此函数

应用于整个验证集，并将

所有数

据加载到DataFrame中进行

进一步分析：

仍然使用ID编

码词元和标注，因此我们

将词元和标注映射回字

符串，

以便更容易地阅读

结果。对于标注为-100的填充

词元，我们分配一个

特殊

的标注IGN，这样我们可以稍

后过滤它们。我们还通过

将它们截断

到输入长度

来消除loss和predicted_label字段中的所有

填充。

每一列包含每个样

本的词元、标注、预测标注

等列表。我们可以通过

展

开这些列表来逐个查看

词元。pandas.Series.explode()函数允许我

们在一

行中创建原始行列表中

每个元素的行。由于一行

中的所有列表

都具有相

同的长度，因此我们可以

对所有列并行执行此操

作。我们还

删除了名为IGN的

填充词元，因为它们的损

失为零。最后，我们将仍然

是numpy.Array对象的损失转换为标

准float。

有了这种形状的数据

，我们现在可以按输入词

元分组，并使用计数、

平均

值和总和来聚合每个词

元的损失。最后，我们按损

失的总和对聚

合数据进

行排序，看看哪些词元在

验证集中累积了最多的

损失。

我们可以观察到这

个列表中的几种模式。

●“空

格”这个词元具有最高的

总损失，这并不奇怪，因为

它也是列

表中最常见的

词元。然而，它的平均损失

要比列表中的其他词元

低得

多。这意味着模型对

其进行分类并没有太多

的困难。

●像“in”“von”“der”和“und”这样的词在

文本中出现相对频

繁。它

们经常与命名实体一起

出现，有时也是命名实体

的一部分，这

解释了为什

么模型可能会混淆它们

。

●括号、斜杠和单词开头的

大写字母都比较少见，但

平均损失较高。

我们将进

一步调查它们。

我们还可

以将标注ID分组，并查看每

个类的损失：

我们发现B-ORG的

平均损失最高，这意味着

确定一个组织名称的开

始对

我们的模型提出了

挑战。

我们可以进一步分

解，通过绘制词元分类的

混淆矩阵来解决这个问

题，我们可以发现组织名

称的开始经常会被误认

为是后续的I-ORG词

元：

从图中

可以看出，我们的模型往

往最容易混淆B-ORG和I-ORG实体。另

外，它在分类其他实体方

面表现相当不错，这可以

通过混淆矩阵近乎

对角

线的特征看出。

现在我们

已经检查了词元级别上

的错误，我们继续查看那

些损失较高

的序列。为了

进行计算，我们将重新访

问我们的“未爆炸”

DataFrame，并通过

对每个词元的损失进行

求和来计算出总损失。为

此，我们首先编写一个函

数，以帮助我们显示带有

标注和损失的单词

序列

：

显然，这些样本的标注存

在问题。例如，联合国和中

非共和国都被标

注为人

！与此同时，在第一个例子

中，“8. Juli”被标注为组织。

事实证

明，PAN-X数据集的标注是通过

自动化过程生成的。这样

的标注

常常被称为“银标

准”（与人工生成标注的“金

标准”相对），在某

些情况下

，自动化方法无法产生明

智的标注也就不足为奇

了。实际

上，这种失败模式

不仅限于自动化方法，即

使人类仔细标注数据，在

标注者注意力衰减或者

他们对句子的理解出现

误解时也会出现错误。

我

们之前还注意到，括号和

斜杠的损失相对较高。我

们看一些带有左

括号的

序列的例子：

通常，我们不

会将括号及其内容作为

命名实体的一部分，但是

自动提

取标注文档的方

式似乎是这种方式。在其

他样本中，括号包含地理

规

范。虽然这也是一个位

置，但我们可能希望在批

注中将其与原始位置

分

离。该数据集包括不同语

言的维基百科文章，文章

标题通常包含括

号中的

某种说明。例如，在第一个

样本中，括号中的文本表

示Hama是

一个“Unternehmen”，即英语中的“公

司”。当我们推出模型时，这

些是需要知道的重要细

节，因为它们可能会对模

型的下游性能产生影

响

，整个pipeline是模型的一部分。

通

过相对简单的分析，我们

已经发现了模型和数据

集中的一些弱点。

在实际

应用中，我们会对这一步

进行迭代，清理数据集、重

新训练模

型、分析新的错

误，直到对性能满意为止

。

我们分析了单一语言上

的错误，但我们也对跨语

言性能感兴趣。在

4.10节中，我

们将进行一些实验，以了

解XLM-R中的跨语言迁移效果

如

何。

4.10

跨语言迁移

现在我

们已经对德语进行了XLM-R的

微调，我们可以通过Trainer的

predict()方

法评估它迁移到其他语

言上的能力。由于我们计

划评估多

种语言，因此我

们创建一个简单的函数

来实现这一功能：

我们可

以使用这个函数来检验

测试集的性能，并用dict记录

我们的分

数。

这个结果在

NER任务中是很不错的。我们

的指标在85%左右，我们可以

看到模型似乎最难处理

的是机构（ORG）实体，这可能是

因为这些在训

练数据中

最不常见，并且许多组织

名称在XLM-R的词表中是罕见

的。那

其他语言呢？下面看

看我们在德语上微调的

模型在法语上的表现如

何：

不错！虽然两种语言中

的名称和组织是相同的

，但是该模型成功地将

“Kalifornien”的

法语翻译成正确标注。接

下来，我们编写一个简单

的函数，对数据集进行编

码并生成分类报告，以量

化我们的德语模型

在整

个法语测试集上的表现

：

尽管我们在微平均指标

中看到了约15个百分点的

下降，但请记住我们

的模

型没有看到任何一个标

注的法语样本！通常情况

下，性能下降的

大小与语

言之间的距离有关。尽管

德语和法语被归为印欧

语系语言，

但它们实际上

属于不同的语系（分别是

日耳曼语系和罗曼语系

）。

下一步，我们来评估在意

大利语上的表现。由于意

大利语也是罗曼语

系语

言，我们预计得到的结果

与我们在法语上得到的

类似。

事实上，我们的期望

得到了F1分数的支持。最后

，我们来考察一下属

于日

耳曼语系的英语的性能

：

令人惊讶的是，我们的模

型在英语方面性能最差

，尽管我们可能直觉

地认

为德语与英语更相似而

不是法语。在对德语进行

微调并执行零样

本迁移

到法语和英语后，我们接

下来看看何时直接在目

标语言上进行

微调才有

意义。

4.10.1

零样本迁移何时有

意义

到目前为止，我们已

经看到，对德语语料库进

行XLM-R微调可以获得约

85%的F1分

数，而且在没有进行任何

额外的训练的情况下，该

模型可以

在我们语料库

中的其他语言上实现适

度的性能。问题是，这些结

果有

多好，它们与在单语

语料库上微调的XLM-R模型相

比如何？

在本节中，我们将

通过在规模不断增加的

训练集上对XLM-R进行微调，

来

探讨法语语料库的这个

问题。通过这种方式追踪

性能，我们可以确

定在哪

个点上进行零样本跨语

言迁移更优，实际上这一

点在指导是否

收集更多

标注数据方面是有用的

。

为简单起见，我们将保留

在德语语料库上进行微

调时得到的超参数，

除了

我们将调整Training Arguments的logging_steps参数以考

虑不

断变化的训练集大

小。我们可以将所有这些

封装在一个简单的函数

中，该函数接收与单语语

料库相对应的DatasetDict对象，将其

按

num_samples进行下采样，并对该样

本的XLM-R进行微调以返回最

佳时

期的指标。

与我们对

德语语料库进行的微调

一样，我们也需要将法语

语料库编码

为输入ID、注意

力掩码和标注ID：

接下来我

们通过在一个小的训练

集上运行我们的函数来

检查它是否正

常工作，该

训练集只包含250个样本。

我

们可以看到，仅用250个样本

，在法语上微调的表现明

显低于从德语

中进行零

样本迁移。现在，我们将训

练集大小增加到500、1000、2000

和4000个样

本，以了解性能是如何提

高的：

我们可以将在法语

样本上微调的结果与从

德语样本上进行零样本

跨语

言迁移的结果进行

比较，通过作图来观察随

着训练集大小的不断增

加，测试集上F1分数的变化

趋势。

从图中我们可以看

出，零样本迁移学习一直

保持竞争力，直到约750个

训

练样本之后，此时在法语

上的微调达到了类似于

我们在德语上微调

时得

到的性能水平。尽管如此

，这个结果也不容忽视！根

据我们的经

验，即使只让

领域专家标注几百个文

档都可能是昂贵的，尤其

是对于

NER这种需要细粒度

标注且耗时的任务。

我们

可以尝试用最后一种技

术来评估多语言学习：同

时在多种语言上

进行微

调！我们看看如何做到这

一点。

4.10.2

一次性对多种语言

进行微调

到目前为止，我

们已经看到从德语到法

语或意大利语的零样本

跨语言

迁移会导致约15个

百分点的性能下降。缓解

这种情况的一种方法是

同

时在多种语言上进行

微调。为了了解我们可以

获得什么类型的收益，

我

们首先使用Hugging Face Datasets库中的

concatenate datasets()函数

将德语和法语语料库合

并在一起：

我们将再次使

用与前面章节中相同的

超参数进行训练，因此我

们只需

在训练器中更新

日志记录步骤、模型和数

据集即可。

我们来看看该

模型在每种语言的测试

集上的表现：

它在法语数

据集上的表现比之前好

得多，与德语测试集上的

表现相匹

配。有趣的是，它

在意大利语和英语数据

集上的表现也提高了约

10个

百分点！因此，即使在另

一种语言的训练数据中

添加数据也可以提高

模

型对未知语言的表现。

我

们通过对比单独对每种

语言进行微调和对所有

语料库进行多语言学

习

来完成我们的分析。由于

我们已经在德语语料库

上进行了微调，因

此我们

可以使用train_on_subset()函数在剩余的

语言上进行微调，

num_samples等于训

练集中的样例数。

现在我

们已经在每种语言的语

料库上进行了微调，下一

步是将所有拆

分的语料

库连接在一起，创建一个

包含所有四种语言的多

语言语料

库。与先前的德

语和法语分析一样，我们

可以使用

concatenate_splits()函数，在我们上

一步生成的语料库列表

上执行

此步骤：

现在我们

有了多语言语料库，我们

将用训练器执行熟悉的

步骤：

最后一步是从训练

器生成对每种语言的测

试集的预测结果。这将为

我

们展示多语言学习的

效果。我们将在f1_scores字典中收

集F1分数，然

后创建一个DataFrame以

总结我们多语言实验的

主要结果：

从这些结果中

，我们可以得出一些普遍

的结论：

●多语言学习可以

带来显著的性能提升，特

别是如果跨语言迁移的

低

资源语言属于相似的

语系。在我们的实验中，我

们可以看到德语、法

语和

意大利语在all类别中实现

了类似的性能，这表明这

些语言彼此之

间比与英

语更相似。

●作为一种通用

策略，集中注意力进行语

言家族内的跨语言迁移

是一

个很好的想法，特别

是当处理像日语这样的

不同文本时。

4.11

用模型小部

件进行交互

在本章中，我

们将许多经过微调的模

型推送到了Hub。虽然我们可

以使

用pipeline()函数在本地机器

上与它们进行交互，但Hub提

供了适用于

这种工作流

的小部件。例如，图4-5展示了

我们的

transformersbook/xlm-roberta-base-finetuned-panx￾all checkpoint，你可以看到它已

经很好地识别了德语文

本中的所有

实体。

图4-5：Hugging Face

Hub上小

部件的示例

4.12

本章小结

J. Pfeiffer et

al., “MAD-X:An Adapter-Based Framework for

Multi-Task

Cross-Lingual Transfer”

（https://arxiv.org/abs/2005.00052），（2020）.

在

本章中，我们讨论了如何

使用在100种语言上预训练

的单一

Transformer（XLM-R）来处理多语言语

料库上的NLP任务。尽管我们

能

够表明从德语到法语

的跨语言迁移在只有少

量标注样本可用于微调

时

是具有竞争力的，但当

目标语言与基础模型进

行微调的语言显著不

同

，或者不是预训练过程中

使用的100种语言之一时，通

常不会出现好

的性能。最

近像MAD-X这样的方法就是专

门为这些低资源场景而

设计

的，而且由于MAD-X是建立

在Hugging Face Transformers库之上

的，因此你可以

轻松地修改本章的代码

来使用它 ！

到目前为止，我

们已经了解了两个任务

：序列分类和词元分类。它

们

都属于自然语言理解

领域，在该领域中，文本会

被合成为预测结果。

在第

5章中，我们将初探文本生

成，其中模型的输出不仅

包括输入文

本，还包括输

出文本。

第5章

文本生成

这

个例子来自OpenAI的GPT-2博客文章

（https://openai.com/blog/better-language-models）。

基于Transformer的语言模型有一种

非常神奇的特性，它们能

够生成几

乎与人类写作

的文本难以区分的文本

。一个著名的例子是OpenAI的

GPT-2，当

给定以下提示时

：

In a shocking finding, scientist

discovered a herd of

 unicorns

living in a remote, previously unexplored

v

alley, in the Andes Mountains.

Even more surprising t

o the

researchers was the fact that the

unicorns spo

ke perfect English.

能够生

成一篇引人入胜的关于

独角兽的新闻文章：

The scientist named the population, after

their distin

ctive horn, Ovid's Unicorn.

These four-horned, silver￾white unicorns were previously

unknown to science. Now

, after

almost two centuries, the mystery of

what sp

arked this odd phenomenon

is finally solved. Dr. Jorg

e

Pérez, an evolutionary biologist from the

University

 of La Paz, and

several companions, were exploring t

he

Andes Mountains when they found a

small valley, w

ith no other

animals or humans. Pérez noticed that

t

he valley had what appeared

to be a natural fountain

,

surrounded by two peaks of rock

and silver snow. 

Pérez and

the others then ventured further into

the 

valley.

“By the time

we reached the top of one

peak, the 

water looked blue,

with some crystals on top, ”

said Pérez. Pérez and his friends

were astonished to

 see the

unicorn herd. These creatures could be

seen

 from the air without

having to move too much to

s

ee them—

they were so

close they could touch their horns.

Whi

le examining these bizarre creatures

the scientists di

scovered that the

creatures also spoke some fairly re

gular English...

这个

例子如此引人注目的原

因在于它是在没有任何

明确监督的情况下

生成

的！通过简单地学习预测

数百万个网页文本中下

一个单词，像

GPT-2及其更强大

的后继者GPT-3这样的语言模

型能够获得广泛的技能

和模式识别能力，并可以

通过不同类型的输入提

示来激活这些能力。

图5-1展

示了语言模型有时会在

预训练期间接触到需要

根据上下文预测

以下词

元的任务序列，如加法、单

词拼写纠正和翻译。如果

模型足够

大，这使它们能

够在微调期间或在推理

时有效地迁移这些知识

。这些

任务并没有被预先

选择，而是在用于训练百

亿参数语言模型的大型

语

料库中自然发生的。

图

5-1：在预训练期间，语言模型

接触到可以在推理期间

进行调整的

任务序列（由

Tom

B. Brown提供）

然而，正如Delip Rao指出的那

样（https://oreil.ly/mOM3V），

Meena自己并不知道在讲冷

笑话。

Transformer模型生成逼真文本

的能力已经催生了各种

各样的应用，例

如InferKit（https://oreil.ly/I4adh）、Write WithTransformer

（https://oreil.ly/ipkap）、AI Dungeon

（https://oreil.ly/8ubC1），以及像

Google的Meena

（https://oreil.ly/gMegC）这样的对话代理，它们

甚至可以像图5-2

中展示的

那样讲些俗气的笑话 ！

在

本章中，我们将使用GPT-2来说

明语言模型的文本生成

原理，并探讨

不同的解码

策略对生成的文本所产

生的影响。

5.1

生成连贯文本

的挑战

到目前为止，本书

的重点是通过预训练和

监督微调的组合来处理

NLP任

务。正如我们所看到的

，对于像序列或词元分类

这样的特定任务，生

成预

测是相当简单的。模型产

生一些logit，我们要么取最大

值以获得

预测类，要么应

用softmax函数以获得每个类的

预测概率。相比之下，

将模

型的概率输出转换为文

本需要一种解码方法，这

在文本生成中引

入了一

些独特的挑战：

图5-2：左边是

Meena，正在对右边的一个人讲

一个俗气的笑话（由

Daniel Adiwardana和Thang Luong提

供）

●解码是迭代进行的，因

此涉及的计算量比仅通

过模型前向传递的一

次

传输入要大得多。

●生成的

文本的质量和多样性取

决于解码方法和相关的

超参数的选

择。

现在我们

从研究GPT-2是如何预训练的

以及随后如何应用于生

成文本来

开始理解这个

解码过程的工作原理。

像

其他自回归或因果语言

模型一样，GPT-2被预训练用于

在给定一些初

始提示或

上下文序列x=x，x，…，xk的情况下，估

计文本中出现词元

序列

y=y，y，…，yt的概率P（y|x），这个过程的核心

在于解码方

法，它决定了

每个时间步选择哪个词

元。由于获取足够的训练

数据以

直接估计P（y|x）是不切

实际的，因此通常使用概

率的链式规则将其

分解

为条件概率的乘积：

1212

其中

，y是序列y，...，yt的简写符号。我们

从这些条件概率中获得

了

这样的直觉，即自回归

语言模型等同于给定一

个句子中前面的单词预

测后面的单词。这正是上

述方程右侧的概率所描

述的。请注意，这种

预训练

目标与BERT的预训练目标非

常不同，BERT利用过去和未来

的上

下文来预测掩码词

元。

＜t1-1

现在你可能已经猜到

了我们如何将下一个词

元预测任务调整为生成

任

意长度的文本序列。如

图5-3所示，我们从像

“Transformers are the”这样的

提示开始，使用模型预测

下一个

词元。一旦我们确

定了下一个词元，我们将

其附加到提示上，然后使

用新的输入序列生成另

一个词元。如此循环，直到

达到特殊的序列结

尾词

元或预定义的最大长度

。

图5-3：通过在每个步骤中向

输入添加一个新单词来

生成文本序列

由于输出

序列取决于输入提示的

选择，因此这种类型的文

本生成通常

被称为条件

文本生成。

这个过程的核

心是决定在每个时间步

长选择哪个词元的解码

方法。由

于语言模型头在

每个步骤为词表中的每

个词元生成一个logit zt，我

们可

以通过使用softmax获得下一个

可能词元wi的概率分布：

,i

P（yt=wi|y，x）=softmax（zt）

＜t,i

大

多数解码方法的目标是

通过选择一个 来搜索概

率最大的、满足以

下条件

的整体序列：

直接找到 将

涉及使用语言模型评估

每个可能的序列。由于没

有一个

算法能够在合理

的时间内完成这个任务

，因此我们转而依赖近似

方

法。在本章中，我们将探

讨其中的一些近似方法

，并逐渐构建出更加

智能

和复杂的算法，以生成高

质量的文本。

5.2

贪婪搜索解

码

从模型的连续输出中

获取离散词元的最简单

解码方法是在每个时间

步

中贪婪地选择具有最

高概率的词元：

如果你的

机器内存不足，你可以通

过将model_name="gpt-xl"替换为

model_name="gpt"来加载一个

更小的GPT-2版本。

这里我们通

过15亿个参数的版本

的GPT-2来

了解贪婪搜索的工作原

理，我们先加载模型：

现在

让我们生成一些文本！虽

然Hugging Face Transformers库为像

GPT-2这样的自回归

模型提供了现成的generate()函数

，但为了了解底

层原理，我

们将自己实现这种解码

方法。下面我们将采用图

5-3所示的

相同迭代方法，使

用“Transformers are the”作为输入提示，在8

个时

间步内运行解码。在每个

时间步中，我们挑选出模

型在提示中最

后一个词

元的logit，并用softmax包装它们以获

得概率分布。然后我

们挑

选出具有最高概率的下

一个词元，将其添加到输

入序列中，并再

次运行该

过程。代码在每个时间步

中存储5个最有可能的词

元，以便我

们可以可视化

它们的选择，全部代码如

下：

使用这种简单的方法

，我们能够生成句子

“Transformers are the

most popular toy line in the

world”。有趣

的是，这表明GPT-2已经内化了

一些关于变形金刚媒体

特许经营权的知识：两家

玩具公司（Hasbro和Takara Tomy）创建了

变形

金刚这一品牌并拥有其

特许经营权。我们还可以

在每个时间步看

到其他

词元选项及其概率，这体

现了文本生成的迭代性

质。其他任务

（如序列分类

）的单个前向传递足以生

成预测，而文本生成则需

要逐

个解码输出词元。

可

见实现贪婪搜索并不太

难，接下来我们将使用

Hugging Face Transformers库

内置的generate()函数来探索更复

杂

的解码方法。为了重现

我们的简单示例，我们先

确保采样已关闭（除

非你

从checkpoint加载的特定模型配置

另有规定，否则默认情况

下已

关闭），并通过max_new_tokens来指定

新生成的词元数量：

现在

让我们尝试一些更有趣

的东西：我们能否重现本

章一开头的

OpenAI的独角兽故

事？和之前一样，我们将使

用词元分析器对提示进

行编码，并指定一个更大

的max_length值来生成更长的文本

序列：

前几句与本章一开

头的OpenAI例子有很大不同，发

现者是不同大学和

不同

的科学家！我们也可以看

到贪婪搜索解码的一个

主要缺点：它往

往会产生

重复的输出序列（最后两

段是重复的），在新闻文章

中这显

然是不可取的。这

是贪婪搜索算法的一个

常见问题，它们可能无法

给

出最优解。在解码的上

下文中，它们可能会错过

整体概率更高的词序

列

，只因为高概率的单词恰

好在低概率的单词之前

出现。

幸运的是，还有更好

的方法——束搜索解码，这也

是一种很流行的方

法。

N.S.

Keskar et al., “CTRL:A ConditionalTransformerLanguage

Model

for Controllable Generation”

（https://arxiv.org/abs/1909.05858），（2019）.

虽

然贪婪搜索解码很少用

于需要多样性的文本生

成任务，但对于生成

像算

术这样需要确定性和事

实正确输出的短序列时

，它可能很有

用。对于这些

任务，你可以通过用几个

行分隔符来对GPT-2进行条件

设

置，例如"5+8=>13 \n 7+2=>9 \n 1+0=>"。

5.3

束搜索解码

不

同于每次都选择概率最

高的词元，束搜索会跟踪

最有可能的下一个

top-b个词

元，其中b称为束的数量或

部分假设。下一个束是通

过考虑

现有集合的所有

可能的下一个词元扩展

并选择最有可能的b个扩

展而选

择的。该过程会一

直重复，直到达到最大长

度或遇到EOS词元，然后根

据

它们的对数概率对b个束

进行排名，选择最有可能

的序列。束搜索的

示例如

图5-4所示。

图5-4：两束的束搜索

为什么我们使用对数概

率而不是概率本身来评

分序列？其中一个原因

是

，计算序列P（y，y，...，yt|x）的整体概率需

要计算条件概率的

乘积

P（yt|y，x）而每个条件概率通常是

在[0，1]范围内的小的数

字，将

它们相乘可能会导致整

体概率很容易下溢。这意

味着计算机无

法精确表

示计算结果。例如，假设我

们有一个长度t=1024的词元序

列，并慷慨地假设每个词

元的概率为0.5。这个序列的

整体概率将会是

一个非

常小的数字：

12＜t

使用对数概

率进行计算是为了避免

数字不稳定性问题，因为

我们会遇

到下溢的情况

。我们可以通过计算相关

项——对数概率来避免这个

问

题。如果我们对联合概

率和条件概率取对数，然

后利用对数的乘法规

则

，那么我们可以得到：

换句

话说，我们之前提到的概

率乘积变成了对数概率

的总和，这样就

不太可能

遇到数值不稳定的情况

。例如，对于前面提到的相

同例子，

计算对数概率如

下：

这是一个我们可以轻

松处理的数字，这种方法

也适用于更小的数字。

由

于我们只想比较相对概

率，因此我们可以直接使

用对数概率进行比

较。

让

我们计算并比较贪婪搜

索和束搜索生成的文本

的对数概率，以查看

束搜

索是否可以提高总体概

率。由于Hugging Face Transformers库

返回给定输入

词元的下一个词元的非

规范化logit，因此我们首先需

要

规范化logit，以创建序列中

每个词元在整个词表的

概率分布。然后我

们需要

选择仅存在于序列中的

词元的概率。实现这些步

骤的具体函数

如下：

以上

函数给出了单个词元的

对数概率，如果要获得序

列的总对数概

率，我们只

需将每个词元的对数概

率相加。

请注意，我们忽略

了输入序列的对数概率

，因为它们不是由模型生

成

的。我们还可以看到，将

logit与标注对齐非常重要。由

于模型预测下

一个词元

，因此我们不会得到第一

个标注的logit，而且我们不需

要最

后一个logit，因为我们没

有与之对应的真实词元

。

我们首先使用这些函数

来计算对OpenAI提示使用贪婪

解码器的序列对

数概率

：

现在我们来比较一下使

用束搜索生成的序列。使

用generate()函数并

指定num_beams参数的数

量即可激活束搜索。我们

选择的束数越多，结

果就

可能越好。但是，生成过程

变得更慢，因为我们要为

每个束生成

并行序列：

我

们可以看到，使用束搜索

相较于简单的贪婪解码

，得到了更好的对

数概率

值（数值越高越好）。然而，我

们可以看到束搜索一样

存在重

复文本的问题。解

决这个问题的一种方式

是通过

no_repeat_ngram_size参数施加n-gram惩罚，该

参数会跟踪已经出现

的

n-gram并将下一个词元的概率

设置为零，从而避免产生

先前出现过

的n-gram：

现在结果

不错了！我们成功避免了

重复的文本，而且我们可

以看到，

尽管得分较低，但

文本仍然是连贯的。带有

n-gram惩罚的束搜索是一

种在

关注高概率词元（使用束

搜索）的同时减少重复（使

用n-gram惩

罚）之间获得平衡的

好方法，常用于需要确保

事实正确性的应用，如

文

本摘要或机器翻译。当事

实正确性不如生成输出

的多样性重要时，

例如在

开放域的闲聊或故事生

成中，另一种减少重复并

提高多样性的

选择是使

用采样。现在我们探讨一

些最常用的采样方法来

完成我们对

文本生成的

探索。

5.4

采样方法

最简单的

采样方法是在每个时间

步从模型输出的概率分

布中随机采

样，采样的范

围为整个词表：

其中|V|表示

词表的基数。我们可以通

过添加温度参数T来控制

输出的

多样性，该参数在

进行softmax之前重新缩放logit。

如果

你了解一些物理知识，你

可能会发现它与玻尔兹

曼分布

（https://oreil.ly/ZsMmx）有惊人的相似之

处。

通过调整T，我们可以控

制概率分布的形状 。当T≪1时

，分布会在原

点附近峰值

化，罕见的词元会被压制

。另一方面，当T≫1时，分布变

得

平坦，每个词元变得同等

可能。图5-5展示了温度对词

元概率的影

响。

为了展示

如何使用温度参数来影

响生成的文本，让我们通

过在

generate()函数中设置温度参

数为2来进行采样（我们将

在5.5节解释

top k参数的含义）：

▲图

5-5：三种选定温度下随机生

成的词元概率分布

我们

可以清晰地看到，高温度

导致大部分无意义的语

句。通过强调稀

有的词元

，我们让模型创建了奇怪

的语法和许多虚构的单

词！我们看

看如果降低温

度会发生什么：

这样生成

的文本明显更加连贯，甚

至包括了另一个被认为

发现了这个

结论的大学

的引用！我们可以从温度

中得到的主要教训是，它

允许我

们控制样本的质

量，但在连贯性（低温度）和

多样性（高温度）之间

总是

存在一个权衡，需要根据

具体应用场景进行调整

。

另一种调整连贯性和多

样性之间权衡的方法是

截断词汇的分布。这允

许

我们自由地使用温度来

调整多样性，但在一个更

有限的范围内排除

在上

下文中过于奇怪的词汇

（即低概率词）。有两种主要

方法：top-k

和核（或top-p）采样。让我们

看一下。

5.5

top-k和核采样

top-k和核（top-p）采

样是使用温度的两种流

行的替代或扩展方法。

在

这两种情况下，基本思想

是限制每个时间步可以

采样的可能词元数

量。为

了了解其工作原理，让我

们先在图5-6中查看T=1时模型

输出的

累积概率分布。

让

我们分解一下这些图，因

为它们包含了很多信息

。在图5-6的上图

中，我们可以

看到一个词元概率的直

方图。它在10-8左右有一个峰

值，

其次是在10-4左右有一个

较小的峰值，然后急剧下

降，只有少量词元的

概率

在10-2到10-1之间。从这张图中可

以看出，选择具有最高概

率的词

元的概率（在10-1处的

独立条）是1/10。

在图5-6的下图中

，我们按降序对词元进行

了排序，并计算了前

10 000个词

元的累积总和（在GPT-2的词表

中总共有50

257个词

元）。曲线表

示选择任何前面词元的

概率。例如，从具有最高概

率的

1000个词元中选择任何

一个的概率大约为96%。我们

可以看到概率迅速

上升

到90%以上，但只有在几千个

词元之后才饱和接近100%。该

图表显

示，有1/100的概率不会

选择不在前2000个词元中的

任何词元。

尽管这些数字

一开始可能看起来很小

，但它们变得重要，因为我

们在

生成文本时每个词

元只采样一次。因此，即使

只有百分之一或千分之

一的概率，如果我们采样

数百次，那么在某个时刻

挑选一个不太可能

的词

元的机会是相当大的。在

采样时选择这些词元会

严重影响生成文

本的质

量，因此我们通常希望避

免这些非常不太可能的

词元。这就是

top-k和top-p采样发挥

作用的地方。

top-k采样的思想

是通过仅从具有最高概

率的k个词元中进行采样

来避

免低概率选择。这对

分布的长尾部分施加了

固定的截断，并确保我们

只从可能的选择中进行

采样。回到图5-6，top-k采样等价于

定义一条

竖线，然后从竖

线左侧的词元中进行采

样。同样，generate()函数提

供了一个

使用top k参数轻松实现这一

目的的方法：

▲图5-6：下一个词

元预测的概率分布（上图

）和降序词元概率的累

积

分布（下图）

这可能是目前

为止我们生成的最像人

类语言的文本。但是我们

如何选

择k呢？k的值是手动

选择的，并且在序列中的

每个选择中都是相同

的

，与实际的输出分布无关

。我们可以通过查看一些

文本质量指标来

找到一

个好的k值，我们将在第6章

中探讨这些指标，但是这

个固定的

截止值可能不

能非常令人满意。

一种替

代方法是使用动态截断

。在核（top-p）采样中，我们不选择

固

定的截断值，而是设定

一个当达到一定概率质

量时的截断条件。假设

我

们将该值设定为95%。然后，我

们按概率降序排序所有

词元，并从列

表顶部逐个

添加词元，直到所选词元

的概率之和达到95%。回到图

5-

6，p的值定义了概率累积总

和图上的水平线，我们仅

从线下词元中进

行采样

。根据输出分布的不同，可

能只有一个（非常可能）词

元或一

百个（等可能）词元

。讲到这里，generate()函数还提供了

一个激活

top-p采样的参数。让

我们试一下：

由上可见，top-p采

样方法也产生了一个连

贯的故事，这次的新变化

是

这些独角兽从澳大利

亚迁徙到南美洲。你甚至

可以结合这两种采样方

法，以兼顾两者的优点。设

置top_k=50和top_p=0.9，表示从最多50个

词元

中选择概率质量为90%的词

元。

当我们使用采样时，也

可以应用束搜索。不同于

贪婪地选择下一个候

选

词汇批量，我们可以对它

们进行采样，然后以相同

的方式构建出

束。

5.6

哪种解

码方法最好

不幸的是，目

前没有一种通用的最佳

解码方法。最好的方法将

取决于

你生成文本的任

务性质。如果你想让你的

模型执行像算术或提供

特定

问题答案这样的精

确任务，那么你应该降低

温度或使用确定性方法

，

如将贪婪搜索与束搜索

相结合，以确保获得最可

能的答案。如果你想

让模

型生成更长的文本，甚至

有点创造性，那么你应该

切换采样方

法，增加温度

或使用top-k和核采样的混合

方法。

5.7

本章小结

在本章中

，我们探讨了文本生成，这

是与我们之前遇到的NLU任

务非常

不同的任务。生成

文本至少需要每个生成

的词元进行一次前向传

递，

如果使用束搜索则需

要更多。这使得文本生成

在计算上非常耗费，需

要

适当的基础设施才能以

规模运行文本生成模型

。此外，一个好的解

码策略

可以将模型的输出概率

转化为离散的词元，从而

提高文本的质

量。找到最

佳的解码策略需要一些

实验和对生成的文本进

行主观评

估。

然而在实践

中，仅凭直觉做出这些决

策是不可取的！就像其他

NLP任务

一样，我们应该选择

一个反映我们想要解决

问题的模型性能度量指

标。毫不奇怪，有很多选择

，在第6章中我们将遇到最

常见的选择，我

们将介绍

如何训练和评估文本摘

要模型。或者，如果你迫不

及待地想

学习如何从头

开始训练GPT类型的模型，你

可以直接跳到第10章，在那

里我们将收集大量代码

数据集，然后在其之上训

练自回归语言模型。

第6章

文本摘要

你可能曾经需

要总结一份文件，包括研

究文章、财务收益报告、一

系

列电子邮件。如果你仔

细思考，这需要一系列的

能力，包括理解长篇

内容

、推理内容、然后产生一段

流畅的、包括原始文档主

要主题的文

本。此外，准确

地总结新闻文章与总结

法律合同非常不同，因此

需要

复杂的领域泛化能

力。出于这些原因，总结文

本（专业术语为文本摘

要

）对于神经语言模型，包括

Transformer模型来说是一项困难的

任

务。尽管面临这些挑战

，文本摘要因为能够显著

加速领域专家的工作

流

程，企业可以通过文本摘

要压缩内部知识、总结合

同、自动生成社

交媒体发

布内容等。因此文本摘要

NLP任务很有价值。

为了帮助

你理解相关的挑战，本章

将探讨如何利用Transformer预训练

模型来进行文本摘要。摘

要是一种经典的序列到

序列（seq2seq）任

务，需要输入文本

和目标文本。正如我们在

第1章中看到的那样，

Transformer模型

是一个出色的编码器-解

码器架构。

在本章中，我们

将建立自己的编码器-解

码器模型，将多人对话压

缩成

简明的摘要。但在此

之前，我们先来看看摘要

领域中一个经典数据

集

：CNN/DailyMail语料库。

6.1

CNN/DailyMail数据集

CNN/DailyMail数据集包

含大约30万对新闻文章及

其对应的摘要，这些

摘要

由CNN和DailyMail附加到其文章的要

点组成。这个数据集的一

个

要点是摘要是抽象出

来的而不是提取出来的

，这意味着摘要是使用新

的句子组成的，而不是简

单的对现有句子的摘录

。该数据集可在Hub上

获得（https://oreil.ly/jcRmb）。我

们将使用3.0.0版本，这是一个

为摘要设置的非匿名版

本。我们可以像第4章中看

到的那样，使用

version参数指定

版本。我们深入了解一下

它：

数据集有三列：article列包含

新闻文章；highlights列包含摘要；id

列

是每篇文章的唯一标识

。我们来看其中一篇文章

的摘录：

我们可以看到，文

章比目标摘要长很多，就

本例而言，差距是17倍。

长文

章对大多数Transformer模型都构成

了挑战，因为上下文大小

通常

限制在1000个词元左右

，只相当于几段文字。对于

摘要来说，处理这

个问题

的标准但粗糙的方法是

简单地截断超出模型上

下文大小的文

本。显然，在

文本的末尾可能存在用

于摘要的重要信息，但目

前我们

只能接受模型架

构的这种局限性。

6.2

文本摘

要pipeline

我们来看一下几种最

流行的Transformer模型在前面例子

中的表现如

何。虽然我们

将要探索的模型架构有

不同的最大输入尺寸，但

是我们

将输入文本限制

在2000个字符以使所有模型

具有相同的输入，从而使

输出更具可比性：

摘要中

的一项惯例是通过换行

符将摘要句子分开。我们

可以在每个句

号后添加

一个换行符词元，但这个

简单的启发式方法无法

应对像

“U.S.”或“U.N.”这样的字符串

。NLTK

（Natural Language Toolkit）包含了一个更复杂、可以

区分句子

末尾和缩写中

出现的标点符号的算法

：

在接下来的章节中，我们

将加载多个大模型。如果

你的内存不足，你

可以将

这些大模型替换为较小

的checkpoint（例如“gpt”，“t5-

small”），或者跳过本节，直

接前往后面的6.5节。

6.2.1

摘要基

准

一种常见的新闻文章

摘要基准是简单地取文

章的前三句话。使用NLTK

的句

子词元分析器，我们可以

轻松实现这样的基准：

6.2.2

GPT-2

A. Radford et al., “Language

Models Are Unsupervised

Multitask Learners”（https://openai.com/blog/better￾language-models），OpenAI（2019）.

在

第5章中，我们已经看到了

GPT-2如何根据一些提示生成

文本。该模

型令人惊讶的

特点之一是，我们也可以

使用它来生成摘要，只需

在输

入文本末尾附加“TL；DR”。“TL；DR”（“太

长了；没看”的简

写）通常用

于表示一个长帖子的简

短版本（例如Reddit等平台）。我

们

将通过使用Hugging Face Transformers库中的pipeline()函数

重

新创建原始论文的过

程来开始我们的摘要实

验 。我们将创建一个文

本

生成pipeline并加载GPT-2模型的大型

版本（gpt2-xl）：

这里我们通过对输

入的查询进行切片，将生

成的文本摘要存储在一

个

Python字典中，以便后面进行

比较。

6.2.3

T5

接下来我们尝试T5 Transformer模

型。正如我们在第3章中所

看到的

那样，这个模型的

开发者们对NLP中的迁移学

习进行了全面的研究，发

现可以通过将所有任务

都构建成文本到文本任

务来创建一个通用的

Transformer模

型架构。T5 checkpoint是混合无监督数

据（用于重建

掩码单词）和

多个任务（包括摘要）的监

督数据进行训练的。因此

，

这些checkpoint可以直接使用与预

训练中相同的提示来执

行摘要，而

无须微调。在这

个框架中，用于让模型对

文档进行摘要的输入格

式

为"summarize: <ARTICLE>"，而用于翻译的格式

则

为"translate

English to German: <TEXT>"。如图6-1所示，这

使得T5非

常灵活，能够使用单个模

型解决许多任务。

图6-1：T5的文

本到文本框架图（由Colin

Raffel提供

）。除了翻译

和摘要之外，还

展示了CoLA（语言可接受性）和

STSB（语义相似度）

任务

我们可

以直接使用pipeline()函数加载T5模

型来进行摘要生成，该函

数还会将输入格式化为

文本对文本格式，因此我

们无须在输入前添

加"summarize"：

6.2.4

BART

M. Lewis et al., “BART:

Denoising Sequence-to-Sequence Pre￾training for Natural Language

Generation, Translation, and

Comprehension”（https://arxiv.org/abs/1910.13461）,

（2019）.

B

A RT也

采用了编码器-解码器架

构，并被训练用于重构损

坏的输

入。它是一个结合

了BERT和GPT-2的预训练方案 。我们

将使用

facebook/bart-large-ccn checkpoint，该checkpoint专门使用了

CNN/DailyMail数

据集进行微调：

6.2.5

PEGASUS

J. Zhang et

al., “PEGASUS: Pre-Training with Extracted Gap￾Sentences

for Abstractive Summarization”

（https://arxiv.org/abs/1912.08777），（2019）.

PEGASUS与BART一样，也

是一个编码器-解码器Transformer模

型 。如

图6-2所示，它的预训练

目标是预测多句文本中

的掩码句子。作者认

为，预

训练目标越接近下游任

务，它就越有效。为了找到

一个更接近

摘要而不是

一般语言建模的预训练

目标，他们自动识别了一

个非常大

的语料库中包

含其周围段落大部分内

容的句子（使用摘要度量

指标作

为内容重叠的启

发式），并对PEGASUS模型进行预训

练以重构这些句

子，从而

获得了一个用于文本摘

要的最先进模型。

图6-2：PEGASUS架构

（由Jingqing Zhang等人提供）

这个模型有

专门的换行符词元，所以

我们不需要使用

sent tokenize()函数：

6.3

比

较不同的摘要

现在我们

已经用四个不同的模型

生成了摘要，我们来比较

一下它们的

结果。请记住

，其中一个模型根本没有

在数据集上进行训练（GPT-

2），一

个模型在执行其他任务

的同时进行了微调（T5），而另

外两个

模型则专门针对

这个任务进行了微调（BART和

PEGASUS）。我们来看看

这些模型生

成的摘要：

我们在查看模

型输出时首先注意到的

一件事是，由GPT-2生成的摘要

与

其他摘要非常不同。它

不是给出文本的摘要，而

是把人物摘要出来。

由于

GPT-2没有明确训练生成真实

的摘要，它经常会“幻想”或

虚构事

实。例如，在撰写本

文时，Nesta并不是世界上最快

的人，而是排名第

九。将其

他三个模型的摘要与基

准摘要进行比较，我们发

现它们有着

显著的重叠

，其中PEGASUS的输出与基准摘要

最相似。

现在我们已经检

查了几个模型，我们要决

定在生产环境中使用哪

一

个。所有四个模型似乎

都提供了合理的质量结

果，我们可以生成更多

的

例子来帮助我们做出决

定。但是，这并不是确定最

佳模型的系统性

方法！理

想情况下，我们将定义一

个指标，在一些基准数据

集上为所

有模型进行度

量，并选择性能最佳的那

一个。但是，如何为文本生

成

定义一个指标呢？我们

所看到的标准指标，如准

确率、查准率和召回

率，都

不易用于此任务。对于每

个由人类撰写的“黄金标

准”摘要，

可能有数十个可

接受的摘要（通过同义词

、释义或稍微不同的表达

方

式）。

接下来我们将探讨

一些常见的、用来度量生

成文本的质量的指标。

6.4

度

量生成文本的质量

好的

度量指标非常重要，因为

我们不但在训练模型时

需要靠它们来度

量模型

的性能，而且在模型投入

使用后也需要它们。如果

我们的指标

不好，那么在

模型投入使用后，我们可

能会对模型退化失去警

觉，如

果这些指标与业务

目标不一致，那么我们可

能无法创造任何价值。

在

文本生成任务上度量性

能并不像情感分析或命

名实体识别等标准分

类

任务那么容易。以翻译为

例，对于像英语中的“I

love dogs!”

这样

的句子，翻译成西班牙语

可能有多种有效的可能

性，比如

“¡Me encantan los

perros!”或

“¡Me gustan los perros!”。仅仅通过检查

输出翻译与参考翻译

是

否精确匹配是不理想的

，即使是人类也不一定能

够做到这点，因为

我们每

个人的文本写作风格略

有不同（甚至自己与自己

都不同，取决

于具体日期

甚至年份！）。幸运的是，有一

些替代方案。

两个最常用

的用于评估生成文本的

度量指标是BLEU和ROUGE。我们看看

它们的定义。

6.4.1

BLEU

K.

Papineni et al., “BLEU:A Method for

Automatic Evaluation

of Machine Translation，”Proceedingsof the

40th Annual

Meeting of the Association

for Computational Linguistics

（July 2002）: 311-318，

http://dx.doi.org/10.3115/1073083.1073135.

BLEU的思想很简

单 ：与其看生成文本中有

多少个词元与参考文本

的

词元完全对齐，不如看

单词或n-gram。BLEU是基于查准率的

度量指

标，这意味着当我

们比较两个文本时，我们

计算生成文本中出现在

参

考文本中的单词数，并

将其除以生成文本的长

度。

然而，这种普通的查准

率存在一个问题。假设生

成文本只是一遍又一

遍

地重复同一个单词，并且

这个单词也出现在参考

文本中。如果它重

复了与

参考文本长度相同的次

数，那么我们就得到了完

美的查准率！

因此，BLEU论文的

作者引入了一个轻微的

修改：只计算一个单词在

参

考文本中出现的次数

。这里举一个例子，假设我

们的参考文本为

“the

cat is on the mat”，生成文

本为

“the

the the the the the”。

从这个简单的例子

中，我们可以按如下方式

计算查准率：

我们可以看

到，简单的校正已经产生

了一个更合理的值。现在

我们通

过不仅考虑单个

单词，而且考虑n-gram来扩展这

个概念。假设我们有

一个

生成的句子snt，我们想要将

其与参考句子snt'进行比较

。我们提

取所有可能的n-gram，进

行统计以获取查准率Pn：

为

了避免重复生成同一个

单词，分子中的计数被截

断（clip）。这意

味着n-gram的出现计数

被限制在它在参考句子

中出现的次数。还要注

意

，这个公式中对于一个句

子的定义并不非常严格

，所以如果你的生

成文本

包含多个句子，则它们会

被视为一个句子。

通常在

测试集中我们有多个样

本需要评估，因此我们需

要稍微扩展方

程式，对语

料库C中所有样本进行求

和：

我们快实现我们的目

标了。由于我们不关注召

回率，因此相比于更长

的

句子，所有短而准确的生

成序列都有优势。因此，查

准率评分更有

利于短的

生成序列。为了补偿这一

点，BLEU的作者引入了一个额

外的

项，即短句惩罚（brevity penalty，在下

面公式中简写为B R）：

通过取

最小值，我们确保这个惩

罚项永远不会超过1，并且

指数项在生

成文本长度

l小于参考文本长度l时，指

数项将呈指数级下降。你

可能

会问，为什么我们不

使用像F1分数这样的东西

来考虑召回率呢？答案

是

，通常在翻译数据集中，会

有多个参考句子而不是

只有一个。因

此，如果我们

同时度量召回率，就会激

励翻译使用所有参考句

子中的

所有单词。因此，更

好的选择是寻求译文中

的高查准率，并确保译文

和参考具有相似的长度

。

genref

最终，我们可以将所有内

容整合在一起，得出BLEU分数

的公式：

最后一个术语是

修改后的n-gram N的查准率的几

何平均值。在实践

中，通常

为BLEU-4分数。然而，你可能已经

看到这个指标有许多局

限

性，例如，它没有考虑到

同义词，并且推导过程中

的许多步骤似乎是

不通

用且相当脆弱的启发式

方法。你可以在Rachel Tatman的博客文

章

“Evaluating Text Output in NLP: BLEU

at Your Own Ri

sk”（在NLP中评估文本输出：自

己承担BLEU的风险）

（https://oreil.ly/nMXRh）中找到对

BLEU的缺陷的精彩阐述。

总的

来说，文本生成领域仍在

寻找更好的度量指标，克

服BLEU等指标

的局限性是当

前研究的一个活跃领域

。BLEU指标的另一个缺点是它

期

望文本已经进行了词

元化。如果没有使用完全

相同的文本词元化方

法

，则可能会导致不同的结

果。SacreBLEU指标通过内置词元化

步骤来

解决这个问题。因

此，它是基准测试的首选

指标。

理论部分我们已经

学习完了，接下来需要通

过代码计算生成文本的

分

数。我们是否需要写Python代

码实现所有这些逻辑？不

用担心，

Hugging Face Datasets库已经提供了现

成的指标！加载这些指标

的

方式与加载数据集的

方式相同：

bleu

metric对象是Metric类的一

个实例，它的工作方式类

似于聚合

器：你可以使用

add()添加单个实例，也可以通

过add batch()添加整

个批量。在添加

完需要评估的所有样本

之后，调用compute()即可计算

指标

。然后会返回一个包含多

个值的字典，包括每个n-gram的

查准

率、长度惩罚以及最

终的BLEU分数。现在我们将bleu

metric对

象应

用于之前的示例：

BLEU分

数也适用于存在多个参

考译文的情况。这就是为

什么reference

以列表形式传的原

因。为了使n-gram中的零计数对

度量结果更平滑，

BLEU集成了

多个修改查准率计算的

方法。一种方法是向分子

添加一个

常数。这样，缺失

的n-gram不会导致分数自动降

为零。只不过在本例

中为

了解释这些值，我们将smooth value设

置为0关闭了该方法。

我们

可以看到1-gram的查准率确实

是2/6，而2/3/4-gram的查准率都是

0[关于

个别指标如计数和bp的更

多信息，请参见SacreBLEU仓库

（https://oreil.ly/kiZPl）]。这意

味着几何平均值为零，同

样BLEU

分数也为零。我们再看

看前面提到的另一个几

乎正确的例子：

我们注意

到查准率分数要好得多

。预测中的所有1-gram都匹配，然

而

我们从查准率分数中

也发现一些问题。对于4-gram，只

有两个候选项

["the"，"cat"，"is"，"on"]和["cat"，"is"，"on"，"mat"]，其中

后

者不匹配，因此查准率为

0.5。

BLEU分数广泛用于评估文本

，尤其是在机器翻译中，因

为精确的翻译

通常比包

含所有可能和合适的单

词的翻译更受青睐。

BLEU分数

也同样应用于其他领域

，例如文本摘要，只不过情

况有些不

同。在文本摘要

中，我们希望生成文本能

够包含所有重要信息，因

此

我们倾向于高召回率

。这点导致通常会使用ROUGE分

数。

6.4.2

ROUGE

C-Y.

Lin，“ROUGE: A Package for Automatic Evaluation

of

Summaries，”Text SummarizationBranches Out（July 2004），

https://aclanthology.org/W04-1013.pdf.

ROUGE分数是专门针对文本

摘要等高召回率比查准

率更重要的应用场景

开

发的 。这种方法与BLEU分数非

常相似，我们观察不同的

n-gram，

并比较它们在生成文本

和参考文本中的出现次

数。不同之处在于，对

于ROUGE，我

们检查参考文本中有多

少个n-gram也出现在生成文本

中。

对于BLEU，我们观察生成文

本中有多少个n-gram出现在参

考文本中，

因此我们可以

使用查准率公式，只需进

行轻微修改，即在分母中

计算

生成文本中参考n-gram的

（未截断）出现次数：

以上是

ROUGE最初的版本。随后，研究人

员发现完全删除查准率

会产生

强烈的负面影响

。回到没有截断计数的BLEU公

式，我们可以同时度量

查

准率和召回率，然后将两

者的ROUGE分数组合在调和平

均数中，得到

F1分数。这个分

数就是ROUGE现在常用的版本

。

ROUGE还有一个版本是度量最

长公共子串（LCS），称为ROUGE-L。LCS

可以计

算任意两个字符串之间

的最长公共部分。例如，abab和

abc的

LCS是ab，它的长度为2。如果我

们想比较两个样本之间

的这个值，我

们需要对其

进行规范化，否则较长的

文本将处于优势地位。为

了实现

这一点，ROUGE的发明者

提出了一个类似F分数的

方案，其中LCS与参考

文本和

生成文本的长度进行规

范化，然后两个规范化分

数被混合在一

起：

这样可

以正确地对LCS分数进行规

范化，并可以在样本之间

进行比较。

Hugging Face Datasets库包含了两种

ROUGE的变体：一种计算每个

句

子的分数并对摘要进行

平均（ROUGE-L），另一种直接计算整

个摘要

的分数（ROUGE-Lsum）。

我们可以

按照以下方式加载度量

指标：

前面我们已经用GPT-2和

其他模型生成了一组摘

要，现在我们有了可以

系

统比较这些摘要的度量

方法。让我们对模型生成

的所有摘要应用

ROUGE分数：

Hugging

Face Datasets库

的ROUGE度量指标还会计算置

信区间（默

认为第5个和第

95个百分位数）。平均值存储

在mid属性中，区间可以

通过

low和high检索。

这些结果显然不

太可靠，因为我们只看了

一个样本，但是我们可以

比

较这个例子的摘要质

量。结果表格证实了我们

的观察结果，在我们的

模

型中，GPT-2表现最差，这点并不

令人惊讶，因为它是这些

模型中唯

一没有专门针

对文本摘要进行训练的

模型。然而，令人惊讶的是

，仅

使用前三个句子的简

单的基准模型（baseline）与其他具

有数十亿参

数的Transformer模型相

比表现也不错！PEGASUS和BART是整体

最好的

模型（ROUGE分数越高越

好），但在ROUGE-1和LCS分数方面，T5略好

一

些。依据这些结果，T5和PEGASUS为

最佳模型，但是再次强调

，我们需

要谨慎看待这些

结果，因为我们仅在一个

例子上评估了这些模型

。基

于PEGASUS论文中的结果，我们

预计PEGASUS在CNN/DailyMail数据集上

表现可

能会优于T5。

我们看看是否

能够用PEGASUS复现那些结果。

6.5

在

CNN/DailyMail数据集上评估PEGASUS

现在充分

评估模型的条件都齐全

了：我们拥有CNN/DailyMail测试集数

据

集、评估用的ROUGE指标，以及一

个摘要模型。我们只需要

把这些部

分组合起来。首

先，我们评估三句话基准

模型的性能：

然后我们把

该函数应用于数据的一

个子集。由于CNN/DailyMail数据集

的测

试部分包含大约10 000个样本

，生成所有这些文章的摘

要需要很

多时间。回顾第

5章，每个生成的词元都需

要通过模型进行前向传

递。

为每个样本生成100个词

元将需要100万次前向传递

，如果我们使用束

搜索，则

此数字还需要乘以束的

数量。为了让计算更快一

些，我们将

对测试集进行

子采样，最终使用1000个样本

进行评估。这样我们使用

单个GPU上不到一小时就能

完成PEGASUS模型的评估，而且得

到稳定的

分数估计：

分数

大多数比上一个示例差

，但仍然比GPT-2实现的分数要

好！现在我

们依样画葫芦

来评估PEGASUS模型：

我们来详细

解释一下这段评估代码

。首先，我们将数据集分成

较小的

批量，以便可以同

时处理。然后对于每个批

量，我们对输入文章进行

词元化，然后将它们提供

给generate()函数，使用束搜索生成

摘要。

我们使用论文中的

相同生成参数。惩罚参数

新的长度确保模型不会

生

成过长的序列。最后，我

们解码生成文本，替换<n>词

元，并将解码的

文本与参

考文本一起添加到度量

中。最后，我们计算并返回

ROUGE分

数。现在，我们再次使用

用于seq2seq生成任务的

AutoModelForSeq2SeqLM类来加

载模型，并对其进行评估

：

这些数字非常接近论文

中的结果。这里需要注意

的是，损失和每个词

元的

准确率在某种程度上与

ROUGE分数解耦。损失与解码策

略无关，而

ROUGE分数则强耦合

。

由于ROUGE和BLEU比人工评估的损

失或准确率更好，因此在

构建文本生

成模型时应

重点关注它们，并仔细探

索和选择解码策略。然而

，这些

指标远非完美，因此

应始终考虑人工评估。

现

在我们已经有了评估函

数，可以训练我们自己的

摘要模型了。

6.6

训练摘要模

型

至此，我们已经仔细研

究了文本摘要和评估的

许多细节，现在我们使

用

这些知识来训练一个自

定义的文本摘要模型！对

于我们这个自定义

应用

，我们将使用三星开发的

SAMSum数据集

（https://oreil.ly/n1ggq），该数据集包含了

一系列对话以及简短

的

摘要。这些对话可以代表

客户与客服中心之间的

互动，并以此生成

准确的

摘要以帮助改善客户服

务，并检测客户请求中的

常见模式。我

们先加载数

据集并查看一个样本：

对

话看起来就像你通过短

信或WhatsApp聊天一样，包括了表

情符号和

为GIF准备的占位

符。dialogue字段包含了完整的文

本，而summary字

段则是对话的摘

要。在CNN/DailyMail数据集上进行微调

的模型能够处

理这个数

据集吗？我们来看看！

6.6.1

评估

PEGASUS在SAMSum上的性能

首先，我们将

使用PEGASUS运行相同的摘要生

成流程，以查看输出结

果

。我们可以重用CNN/DailyMail摘要生成

的代码：

我们可以看到，该

模型主要尝试通过提取

对话中的关键句子来进

行摘

要。这在CNN/DailyMail数据集上可

能效果相对较好，但是在

SAMSum

中，摘要更加抽象，效果不

一定好。我们可以通过在

测试集上运行完

整的ROUGE评

估来确认这一点：

虽然结

果并不太好，但这并不出

乎意料，因为远离了CNN/DailyMail数

据

分布。尽管如此，在训练之

前设置评估流程有两个

优点：我们可以

直接使用

度量指标来度量训练的

成功，而且我们有一个很

好的基准。

在我们的数据

集上对模型进行微调应

该会立即改善ROUGE度量指标

，如

果没有改善，那么我们

就知道我们的训练循环

出了问题。

6.6.2

微调PEGASUS

在我们对

数据进行训练之前，我们

快速查看输入和输出的

长度分布：

我们可以看到

，大多数对话比CNN/DailyMail的文章要

短得多，每个对

话有大约

100～200个词元。同样地，摘要也要

短得多，大约有20～40

个词元（与

推文的平均长度相同）。

我

们先记住这些结果，后面

会用到。首先，我们需要对

数据集进行词

元化。我们

将对话和摘要的最大长

度分别设置为1024和128：

在词元

化步骤中有一个新事物

：tokenizer.as_target_tokenizer()上

下文。某些模型需要在

解码器输入中使用特殊

词元，因此将编码器和

解

码器输入的词元化步骤

分开非常重要。在with语句中

（称为上下文

管理器），词元

分析器知道它正在为解

码器进行词元化处理。

现

在，我们需要创建数据整

理器。在大多数情况下，我

们可以使用默

认的整理

器，它收集批量中的所有

张量并将它们简单地堆

叠起来。对

于摘要任务，我

们不仅需要堆叠输入，还

需要在解码器侧准备目

标。

PEGASUS是一种编码器-解码器

Transformer，因此具有经典的seq2seq

架构。在

seq2seq设置中，一种常见的方法

是在解码器中应用

teacher forcing。使用

此策略时，解码器接收输

入词元（与仅包含

解码器

的模型相同，如GPT-2），这些词元

由标注向右移动一个位

置，

除此之外还有编码器

输出。因此，在预测下一个

词元时，解码器将获

得向

右移动一个位置的真实

值作为输入，如下表所示

：

我们将它向右移动一个

位置，这样解码器只会看

到前一个正确的标

注，而

不是当前或未来的标注

。仅进行移位就足够了，因

为解码器有

一个掩码自

注意力机制，它会掩码当

前和未来的所有输入。

因

此，在准备批量时，我们通

过将标注向右移动一个

位置来设置解码

器的输

入。之后，我们通过将标注

中的填充词元设置为-100来

确保忽

略损失函数中的

填充词元。实际上，我们不

必手动执行这些步骤，因

为DataCollatorForSeq2Seq会帮我们完成所有这

些步骤：

然后，和往常一样

，我们为训练设置了一个

TrainingArguments：

与以往设置不同的是，这

次有了一个新的参数

gradient_accumulation_steps。由

于模型非常大，因此我们

不得不将

批量大小设置

为1。然而，批量大小太小会

影响收敛。为了解决这个

问

题，我们可以使用一种

称为梯度累积的巧妙技

巧。顾名思义，我们不

是一

次性计算整个批量的梯

度，而是分批计算并聚合

梯度。当我们聚

合足够的

梯度时，我们运行优化步

骤。这比一次性完成自然

会慢一

些，但它可以节省

我们大量的GPU内存。

现在，我

们登录到Hugging

Face，这样我们就可

以在训练后将模型推

送

到Hub上：

现在我们已经拥有

初始化训练器所需的一

切，包括模型、词元分析

器

、训练参数、数据整理器，以

及训练和评估数据集：

我

们已经准备好进行训练

了。训练完成后，我们可以

直接在测试集上

运行评

估函数，以查看模型的表

现如何：

我们可以看到，ROUGE分

数比没有进行微调的模

型有了显著的提高，因

此

尽管之前的模型也是用

于摘要生成训练的，但它

并没有很好地适应

新的

领域。我们把我们的模型

推送到Hub上吧：

接下来我们

将使用这个模型为我们

生成一些摘要。

你也可以

将生成的结果作为训练

循环的一部分进行评估

：使用名为

Seq2SeqTrainingArguments的TrainingArguments扩展，并指定

predict_with_generate=True。将其传给名为Seq2SeqTrainer的专用

Trainer，该

Trainer使用generate()函数而不是模型的

前向传递来创

建用于评

估的预测。你动手试一试

吧！

6.6.3

生成对话摘要

从损失

和ROUGE分数来看，该模型似乎

比仅在CNN/DailyMail上训练的

原始模

型表现出显著的改进。从

测试集中的一个样本生

成的摘要如下

所示：

这与

参考摘要十分相似。看起

来模型已经学会了将对

话综合成摘要而

不仅仅

是提取段落。现在进行最

终测试：模型在自定义输

入上的表现

如何？

生成的

自定义对话摘要很有意

义。它很好地总结了讨论

中所有人都想

一起写书

的内容，而不仅仅是提取

单个句子。例如，它将第3行

和第4

行合成为一个逻辑

组合。

6.7

本章小结

文本摘要

相较于其他可视为分类

任务的任务，如情感分析

、命名实体

识别或问答等

，具有一些独特的挑战。传

统的度量指标，如准确率

，

并不能反映所生成文本

的质量。正如我们所见，BLEU和

ROUGE这些度量

指标能够更好

地评估所生成文本。然而

，人工评估仍然是最好的

度量

指标。

J. Wu et al.,

“Recursively Summarizing Books with Human

Feedback”（https://arxiv.org/abs/2109.10862），（2021）.

在处理摘要模

型时，一个常见的问题是

如何对文本超过模型上

下文长

度的文档进行总

结。不幸的是，目前没有解

决这个问题的单一策略

，

这仍然是一个开放而活

跃的研究问题。例如，OpenAI最近

的工作展示

了如何通过

将其递归应用于长文档

并在循环中使用人类反

馈来扩展摘

要 。

在第7章中

，我们将探讨问答系统，这

是基于文本段落提供答

案的任

务。与摘要不同的

是，对于这个任务，存在处

理长篇或多篇文档的良

好策略，我们将向你展示

如何将问答系统扩展到

数千个文档。

第7章

构建问

答系统

无论你是研究人

员、分析师还是数据科学

家，都很有可能需要在浩

如

烟海的文档中跋山涉

水才能找到你所需要的

信息。最让人感到崩溃的

是，在使用Google或者Bing搜索引擎

的时候，它们还不断提醒

你，还

有更好的搜索方法

。例如，使用Google搜索：玛丽·居里

什么时候获

得她的第一

个诺贝尔奖？可以立即得

到正确答案：1903，如图7-1所

示。

图

7-1：Google搜索&查询与相应的答案

片段示例

虽然在这种情

况下，每个人都知道DropC是最

好的吉他调音方式。

在这

个例子中，Google首先检索出了

大约319

000个与查询信息相关

的文档，然后执行了另一

个处理步骤，即从这些文

档中提取出带有相

应段

落和网页的答案片段。所

以，搜索引擎的每条搜索

结果看起来似

乎对你都

很有用。再比如，使用Google搜索

一个稍微棘手的问题：

“哪

种吉他调音最好？”这次并

没有直接显示出答案片

段，而是需要

点击搜索引

擎推荐的网页链接，跳转

到各个网站中才能找到

我们想要

的答案

。

这项技

术背后的方法被称为问

答系统，问答系统有各种

各样的类型，

但最为常见

的是提取式问答系统，它

将所涉问题的答案识别

为文档中

的一小段文本

，这里的文档可以是网页

、法律合同或新闻文章。这

种

先查到相关文档，然后

再从中提取答案的两阶

段处理方式，是许多现

代

问答系统的理论基础，像

语义搜索引擎、智能助手

或者自动信息提

取器，都

是基于这种理论来构建

的。在本章中，我们将使用

这种处理

方式来解决电

商网站所面临的一个常

见问题：帮助消费者解答

特定问

题，帮助其了解一

个商品。在这个场景中，把

用户的评论当作问答系

统的文本数据源，在此过

程中，我们将了解到Transformer模型

如何作

为强大的阅读理

解工具，来从文本中提取

有价值的信息。

本章着重

介绍提取式问答，不同场

景适用的问答形式也不

同。比如，

技术社区的问答

系统收集的是用户在Stack

Overflow

（https://stackoverflow.com）等

技术论坛上的问答对，然

后使用语

义相似度搜索

来找到与新问题最匹配

的答案。还有开放域长格

式

（long-form）问答，旨在为诸如“为什

么天空是蓝色的？”之类的

开

放性问题生成复杂的

长文本答案。另外还可以

针对表格，像TAPAS

（https://oreil.ly/vVPWO）这种Transformer模型能

为表格生成聚合

操作语

句，来获取相关信息。

7.1

构建

基于评论的问答系统

如

果你在电商网站买过商

品，那你很有可能参考过

其他人对该商品的

评论

，来帮助你做出是否下单

的决定。这里的评论是指

回答“这把吉

他有背带吗

？”或者“这台相机可以在晚

上使用吗？”这类的具体问

题，不是那种对商品的描

述性评论，仅从描述性评

论很难获取这种具

体问

题的答案。因为一般的热

门商品都有成千上万条

描述性评论，所

以要从中

找到与某个确切问题相

关的评论是一件很难的

事。有一种替

代方法倒是

可以直接获取答案，那就

是在Amazon这种电商网站提供

的

社交问答平台上发布

问题，不过这种方法的时

效性很难保证，一般要

在

几天后才能得到答案，甚

至更久。那么有什么方法

能像图7-1中

Google搜索示例一样

，又快又准确地获取答案

呢？下面就让我们来看

看

Transformer是如何做到的。

7.1.1

准备数据

集

J. Bjerva et

al., “SubjQA:A Dataset for Subjectivity and

Review Comprehension”（https://arxiv.org/abs/2004.14283），

（2020）.

不久之后我们会看到

，会有一些根本无法回答

的问题出现，旨在生成

更

健壮的模型。

本书使用SubjQA数

据集

来构建问答系统，该

数据集包含10 000多条

关于商

品和服务的英文用户评

论，涉及六个领域：旅行社

、餐厅、电

影、书籍、电子产品

和杂货店。如图7-2所示，每条

数据都包含一个问

题和

一个评论，评论里面会有

一个或多个词条可以准

确回答该问题

。

图7-2：一个商

品的问题和相应评论示

例（答案部分带有下划线

）

SubjQA数据集的有趣之处在于

，它其中的大多数问题和

答案都是偏向

主观的，也

就是说，它们取决于用户

的个人体验。从图7-2中可以

看

出，回答这种主观性的

问题，要比回答“英国的货

币是什么？”这种

事实类问

题要难得多。首先，“品质低

劣”（poor quality）是一个

主观性的词汇

，完全取决于用户自身对

于品质的定义；其次，可用

于

检索的关键词也没有

出现在评论中，这样就无

法使用关键词搜索来获

取答案了。而图7-2中的内容

完全有可能在现实世界

里遇到，因此这个

数据集

是比较贴近现实情况的

。由于这个特性，就可以将

SubjQA数据

集作为一个反映了

客观世界真实情况的测

试集来对我们的问答模

型进

行基准测试，这样得

出的结果也更具备说服

力。

问答系统通常根据它

们在响应查询时可以访

问的数据域进行分类，封

闭域问答系统（Closed-Domain

QA，CDQA）处理窄域

问题（例如，单

个商品类别

），而开放域问答系统（Open-Domain QA，ODQA）几乎

可

以处理所有问题（例如

，Amazon电商网站的整个商品目

录），并且能

够仅仅依赖通

用知识本体和世界知识

。封闭域问答系统涉及搜

索的文

档数量一般少于

开放域问答系统。

首先，我

们从Hugging Face Hub（https://oreil.ly/iO0s5）下载

数据集，像在第

4章中那样操作，使用

get dataset

config names()函数

来从下载的多域数据集

中找出可

用的数据子集

：

本次示例将专注为电子

领域（上面的electronics）构建问答系

统。在

确定了领域之后，便

要开始加载electronics数据子集，我

们将该值传

给load_dataset()函数的name参

数即可：

与Hugging Face Hub上的其他问答

类数据集一样，SubjQA数据集将

每个问题与对应的答案

存储为嵌套字典结构。比

如我们查看answers列

中的其中

一行：

我们可以看到答案

存储在text字段中，answer_start字段则提

供答案

字符的起始索引

。为了更加直观地查看数

据集，可以使用flatten()方

法展平

这些嵌套列，并将每个拆

分单元转换为Pandas的DataFrame实

例：

D. Hendrycks et al.,

“CUAD:An Expert-AnnotatedNLPDataset for

Legal Contract Review”（https://arxiv.org/abs/2103.06268），

（2021）.

从

结果可以看出，这个electronics数据

子集相对较小，只有1908个样

本。这其实也反映这个领

域的现实情况，因为让领

域专家来标注提取

式问

答数据集将会花费不菲

。例如，用于法律合同领域

提取问答对的

CUAD数据集价

值大约200万美元，因为标注

其中的13 000个案例 需

要非常

专业的法律知识才能完

成。

SubjQA数据集中有许多的列

，但最有趣的不是这些数

据本身，而是使

用它们构

建问答系统，如表7-1所示：

表

7-1：SubjQA数据集中的列名及其描

述

下面我们来看一些训

练样本，使用sample()方法来选择

一个随机样

本：

从样本中

可以看出一些特点，首先

，样本中的问题question在语法上

有些问题，这在电商网站

的FAQ中比较常见的，因为都

是真人写的；其

次，如果answers.text为

空，表示在评论中无法找

到答案，当前问题

对当前

评论而言是没有答案的

；最后，可以使用答案片段

的起始索引

和长度来从

评论中切分出答案所对

应的文本范围：

接下来，我

们通过统计几个以常见

词汇开头的问题的数量

，来了解训

练中不同问题

类型的分布情况：

从以上

运行结果可以看到，以“How”“What”和

“Is”开头的问题是

最为常见

的，尤其是以“How”开头的问题

，远远多于其他类型的问

题，我们再来看一些实际

的问题例子：

斯坦福问答

数据集

P. Rajpurkar et

al., “SQuAD:100，000+Questions for Machine

Comprehension of

Text”（https://arxiv.org/abs/1606.05250），

（2016）.

P. Rajpurkar, R. Jia,

and P. Liang, “Know What You

Don't

Know: Unanswerable Questions for SQuAD”

（https://arxiv.org/abs/1806.03822）, （2018）.

SubjQA的（question，review，[answer sentences]）格式在提取式

问答数据集中非常常见

，它在斯坦福问答数据集

（SQuAD） 中被首度

应用。SQuAD数据集知

名度很高，常被用来测试

模型在理解一段文本

后

，回答相关问题的能力。该

数据集基于维基百科数

百篇英文文章，

每篇文章

被切分成段落，然后让众

包标注人员为每个段落

标注一系列

问题和答案

。在SQuAD数据集的第一个版本

中，每个问题的答案都保

证

存在于相应的段落中

，但没过多久，人们发现使

用序列模型

（Sequence Model）也开始可以

胜任此工作，甚至比人类

的标注效果

更好。为了让

模型获得更佳的泛化能

力，SQuAD 2.0在SQuAD 1.1的

基础上，增加了与

给定段落相关，但不能仅

从文本中找到答案的对

立

问题，来使标注难度加

大 。本书写作时的最新成

果如图7-3所示，事

实上，自2019年

以来，大多数的此类模型

都超越了人类的表现。

T. Kwiatkowski et al., “Natural

Questions: A Benchmark for

Question Answering

Research，”Transactions of the

Association for Computational

Linguistics 7（March

2019）:452-466，http://dx.doi.org/10.1162/tacl_a_00276.

然

而，这种超乎常人的表现

似乎并不能反映出真实

的阅读理解能力，

因为那

种“无法回答”的问题可以

通过段落中的某种匹配

模式来解决

（如查找反义

词）。为了解决这种问题，Google发

布了自然问答

（Natural Question，NQ）数据集 ，该

数据集包含了30万个自然

产

生的问题和对应的回

答标注，每个回答都是人

工从维基百科找到的答

案。NQ数据集中的答案比SQuAD数

据集中的答案长得多，并

且提出了更

具挑战性的

基准。

图7-3：SQuAD

2.0基准测试的进展

（图片来自

Papers with Code）

现在我们已经

对数据集进行了一些探

索，下面让我们深入了解

Transformer如何从文本中提取答案

。

7.1.2

从文本中提取答案

问答

系统需要做的第一件事

，是找到一种方法将用户

评论中的潜在答

案文本

段识别出来。例如，有一个

“Is it waterproof?”（它防水

吗？）的问题，评论是

“This

watch is waterproof at 30m depth”（这个手表在水

下30米深都

能防水），模型正确的输出

该是“waterproof at 30m”

（防水30米）。要从文本中

准确提取答案，要搞清楚

以下三个问题：

●如何将问

题转化为监督学习问题

。

●如何针对问答任务做输

入处理和编码。

●如何处理

超过模型最大上下文限

制的长文本问题。

下面我

们来看看如何理解和解

决这些问题。

片段分类

从

文本中提取答案最常用

的方法是将问题转化成

一个监督的片段分类

（span classification）任

务，也就是预测答案片段

的起始词元和

终止词元

。这个过程如图7-4所示：

由于

SubjQA数据集中与电子产品相

关的数据子集相对较小

，只有1295

个训练样本，因此最

好直接使用已经在大型

问答数据集（如SQuAD）上

进行过

微调的语言模型。一般来

说，这种语言模型已经具

有了较强的

文本阅读理

解能力，可以作为构建更

加精准模型的基础模型

来使用。

这与前几章采用

的方式不同，在前几章中

，通常是从预训练模型开

始，然后对特定任务头进

行微调。例如，在第2章中，我

们必须对分类

头进行微

调，因为分类的数量是与

数据集相关联的。对提取

式问答来

说，可以直接使

用微调过的模型，因为标

注结构在不同数据集当

中是

保持一致的。

图7-4：问答

任务的片段分类头

可以

访问Hugging Face

Hub（https://oreil.ly/dzCsC）网站的顶

部的“Models”tab页，输

入“squad”，再点击左侧的

“Question Answering”选项卡

来查找提取式问答模型

，如图7-5所

示。

图7-5：Hugging

Face Hub上搜索提取

式问答模型的方式

在撰

写本书时，按照图7-5这样来

操作，可以发现已经有350多

个问答

模型可供选择，如

此多的模型，我们应该选

择哪个呢？这需要考虑多

种因素，比如根据语料库

是单语言还是多语言的

，以及运行环境对于

模型

的限制条件，等等。表7-2列出

了几种模型，可以帮助我

们在选择

的时候做一下

参考。

表7-2：在SQuAD 2.0数据集上经过

微调处理的Transformer基准模型

W. Wang et al.,

“MINILM: Deep Self-Attention Distillation

for Task-Agnostic

Compression of Pre-Trained Transformers”

（https://arxiv.org/abs/2002.10957），（2020）.

出

于对本章内容的考虑，这

里选用经过微调处理的

MiniLM模型，因为

它在训练阶段

速度很快，能够满足快速

迭代的需求 。我们在使用

它

的时候，需要一个词元

分析器来对文本进行编

码操作，下面来看一下

具

体过程。

文本词元化

首先

需要从Hugging

Face Hub（https://oreil.ly/df5Cu）加载

MiniLM模型的checkpoint，来对

文本进行编码操作：

为了

查看这个模型的效果如

何，我们首先尝试从一段

短文本中提取答

案。在提

取式问答任务中，我们一

般将问题和上下文成对

（question，context）传给词元分析器：

以上代

码返回Pytorch

Tensor对象，用它们来运

行模型的前向传递。

如果

我们将词元化的输入看

作一个表：

注意，并非所有

的Transformer模型都存在token_type_ids，在类似

BERT的

模型中，比如MiniLM，token_type_ids在训练期间

也被用来合

并下一个语

句的预测任务。

从表格里

面可以看到熟悉的input

ids与attention mask张

量，而另

一个token_type_ids张量表示的

是哪部分输入内容和问

题与上下文相

对应（0代表

问题的词元，1代表上下文

的词元） 。

为了直观了解词

元分析器如何格式化问

答任务的输入内容，这里

对

inputs_ids张量进行解码：

可以看

出，每一个问答任务，其输

入内容都保持如下格式

：

第一个[SEP]词元的位置由token_type_ids决

定。现在文本已经被词元

化了，接下来只需要使用

一个问答头来实例化模

型，并通过前向传递

（forward pass）运行

输入内容：

有关如何提取

这些隐藏状态的详细信

息，请参阅第2章。

可以看出

，问答头输出了一个QuestionAnsweringModelOutput对象

。

如图7-4所示，问答头对应一

个线性层，该层从编码器

获取隐藏状态，

并计算开

始和结束片段的logit ，也就是

将问答视为词元分类的

一种

形式，类似于第4章中

介绍的命名实体识别的

情况。下一步是将输出转

换为答案片段，需要先获

取开始和结束词元的logit：

如

果将这些logit形状与输入ID进

行比较：

可以看出，每个输

入词元有两个相关的logit（开

始和结束）。如图7-

6所示，较大

的正logit对应于更有可能的

开始和结束词元。在这个

示

例中，可以看到模型将

最高起始词元的logit分配给

数字“1”和

“6000”，这是合理的，因为

原始问题就是一个关于

数量的问题。同

样地，具有

最高logit的结束词元则是“minute”和

“hours”。

图7-6：开始和结束词元的logit预

测结果，最高分数的词元

使用灰色

标记

为了得到

最终的答案，我们可以在

开始和结束词元的logit之上

计算

argmax，然后从输入内容中

切分出片段。以下代码运

行这些步骤并且

将结果

进行解码，然后输出结果

：

在Hugging Face

Transformers库中，所有的预处理和

后处理步骤都

被封装在

使用起来非常方便的专

用pipeline中。我们可以传入词元

分

析器和经过微调的模

型来实例化pipeline，如下所示：

pipeline返

回的结果里面除了答案

之外，还在分数（score）字段中给

出了模型概率估计值（通

过对logit做softmax获得）。当通过设置

topk参数来让模型预测返回

多个结果的时候，该字段

在单个上下文中

对比多

个答案时是很有用的。有

时我们还会碰到那种无

法回答的问

题，就像前文

提到的SubjQA数据集中的answers.answer_start空值

情

况。当出现这种情况的

时候，模型会为[CLS]词元分配

一个较高的开始

和结束

分数，pipeline会将此输出映射成

一个空字符串。

在上面的

简单示例中，我们通过获

取相应logit的argmax来获得开始和

结束索引。然而，这种启发

式方法也可以通过选择

属于问题而不是上

下文

的词元来产生超出范围

的答案。在实际应用中，pipeline会

根据

各种约束条件来计

算出最佳的开始和结束

索引组合，比如必须要在

一

定范围内，或开始索引

必须要在结束索引之前

等约束条件。

处理长文本

段落

在阅读理解场景有

一个比较常见的问题，文

本段落的长度经常会超

出

模型限制的最大输入

长度（一般最多只有几百

个词元）。如图7-7所

示，SubjQA训练集

中有相当一部分文本段

落长度超出了MiniLM模型限

制

的512个词元数量。

图7-7：SubjQA训练集

中每个问答-上下文对的

词元数量分布情况

对于

文本分类等其他场景，最

常用的方法是将超出长

度的文本直接截

断并丢

弃，因为即使缺失一部分

文档，也能得出正确的分

类预测结

果。但在问答场

景，这种做法是有问题的

，因为问题的答案很可能

位

于上下文的末尾附近

。如图7-8所示，处理这种问题

的标准方法是在输

入上

加一个滑动窗口，将原始

长文本处理成多个短文

本，其中每个窗

口都包含

完全适配模型上下文的

词元数量。

Hugging Face Transformers库提供了相关

的API，可以在词元分析

器中

设置return_overflowing_tokens=True来启用滑动窗口功

能，滑

动窗口的大小由max_seq_length参

数控制，步幅大小则由doc stride

参

数控制。下面从训练集中

选取一组数据，并定义一

个滑动窗口来演

示它是

如何使用的：

▲图7-8：滑动窗口

如何为长文本创建多个

问答-上下文对——第一段

对

应问题，第二段是每个窗

口截取的上下文

在这个

案例中，每个滑动窗口都

获取了一个input_ids数组，下面来

查

看每个滑动窗口中的

词元数量：

最后，我们通过

解码input_ids来查看两个滑动窗

口重叠的地方：

到目前为

止，我们对问答模型如何

从文本中提取答案已经

有了一些认

知，下面我们

来看看如何使用其他组

件来构建一个端到端的

问答

pipeline。

7.1.3

用Haystack构建问答pipeline

在本章

前面的示例中，我们为模

型传入问题和上下文，就

能得到答

案。但在实际业

务场景中，用户只会提出

关于商品的问题，因此需

要

找到某种方式来从语

料库中的所有评论中选

出相关的文本段。一种方

式是将给定商品的所有

评论拼接在一起，再将拼

接好的长文本提供给

模

型。这种方式看似简单，但

却有明显的缺点，那就是

会使上下文变

得特别长

，从而影响处理效率，带来

很高的延迟。例如，假设平

均每

个商品有30个评论，每

条评论的处理时间是100ms，如

果使用这种方式

来处理

并获取答案，则会使每次

查询操作都不会少于3s，这

种体验对

于电商网站来

说是非常糟糕的。

为了解

决这个问题，现在的问答

系统通常都基于检索器

-阅读器

（Retriever-Reader）架构，从名称就可

以看出，这种架构有两个

主

要组件：

检索器

如果向

量的大部分元素为0，则称

该向量是稀疏向量。

检索

器（Retriever）旨在为给定查询操作

检索相关文档，目前的检

索

器通常分为三类：稀疏

检索器（Sparse Retriever）、密集检索器

（Dense Retriever）和迭

代检索器（Iterative

Retriever）。稀

疏检索器使

用词频将每个文档和查

询表示为一个稀疏向量

（sparse vector） ，然后通过计算向量内积

来确定查询和文档的

相

关性，但稀疏检索不能解

决术语不匹配问题，在问

题与文档相似但

不存在

重复术语的情况下，稀疏

检索效果较差。随着深度

学习的逐渐

成熟，发展出

了密集检索器，密集检索

器使用类似Transformer的编码

器将

查询和文档表示为上下

文嵌入（密集向量）。这些嵌

入将语义编

码，通过理解

查询内容来提高搜索准

确率。迭代检索器则是通

过多次

迭代从大集合从

检索相关文档。

阅读器

阅

读器（Reader）旨在从检索器输出

的文档中提取答案。阅读

器通常

是一个阅读理解

模型，在本章末尾我们将

见到可以生成具有自由

格式

答案的模型样例。

如

图7-9所示，还有其他组件能

对检索器获取的文档或

阅读器提取的答

案做后

处理。例如，检索出来的文

档可能需要以重新排序

的方式，来

消除噪声或那

些可能让使用者无法理

解的文档。同样，当正确答

案来

自长文档不同段落

时，通常需要对答案进行

后处理。

我们将使用Haystack库（https://haystack.deepset.ai）来

构建问答

系统，它是一家

专注于NLP领域的德国公司

deepset

（https://deepset.ai）所开发的。Haystack基于检索器-阅

读器架

构，它将构建问答

系统的大部分复杂性抽

象出来，并与

Hugging Face

Transformers库紧密集成

。

图7-9：现代问答系统的检索

器-阅读器架构

除了检索

器和阅读器之外，在使用

Haystack构建问答pipeline时还需

要另外

两个组件：

Document Store

文档存储器，用

于存储在检索时提供给

检索器的文档和元数据

。

Pipeline

流程控制器，封装了问答

系统所有流程组件，用以

编写自定义检索流

程或

者合并多个检索器处理

后的文档等。

在本节中，我

们将了解如何使用这些

组件构建一个问答pipeline的原

型系统，之后的内容将研

究如何提升它的性能。

本

章内容全部基于Haystack

0.9.0版本库

编写，在0.10.0版本库

（https://oreil.ly/qbqgv）中，pipeline API和用于

评估的API均

已被重构，目的

是更易于探查检索器或

阅读器是否影响了整体

性能。

如果想获知本章代

码使用新版API如何编写，可

以查看相关GitHub仓库

（https://github.com/nlp-with-Transformers/notebooks）。

初始化

文档存储

在Haystack中，有多种文

档存储可供选择，每一种

都能与一组专用的

检索

器组合配对。如表7-3所示，其

中展示了稀疏检索器（TF-IDF和

BM25）和密集检索器（Embedding和DPR）与所有

可选文档存储器的兼

容

关系，我们将在本章后面

内容解释这些缩写的含

义。

表7-3：Haystack中的检索器和文档

存储器的兼容性

由于我

们在本章中会使用稀疏

检索器和密集检索器，因

此这里选用

Elasticsearch作为文档存

储器，因为它与两种类型

的检索器都兼容。

Elasticsearch是一种

搜索引擎，能够处理多种

数据类型，包括文本、

数字

、地理空间、结构化数据和

非结构化数据。它能够存

储大量数据

并使用全文

搜索功能快速过滤数据

，因此也特别适合用于开

发问答系

统。Elasticsearch目前基本上

已经成为基础设施分析

行业的一个标

准，应用范

围非常广，因此你的公司

很有可能已经拥有了可

以直接使

用的Elasticsearch集群。

该使

用手册还提供了MacOS和Windows的安

装说明。

要初始化文档存

储，需要下载安装Elasticsearch，按照

Elasticsearch的

使用手册（https://oreil.ly/bgmKq） ，使用wget

命令下载

压缩包，并用tar命令解压：

下

面我们来启动Elasticsearch服务器，由

于本书完全是在

Jupyter notebook中运行

所有代码，因此我们需要

使用Python的

Popen()函数来开启一个

新进程，并且使用chown命令在

后台运行这个

子进程：

在

Popen()函数中，args参数需要指定希

望运行的程序，stdout=PIPE

参数表示

为标准输出创建一个新

管道，stderr=STDOUT参数收集该管道

的

错误信息，preexec_fn参数表示指定

该程序运行的ID。

Elasticsearch默认监听

9200端口，可以通过它来发送

HTTP请求到

localhost，验证是否启动成

功：

显示上面的内容就表

示Elasticsearch已经启动成功了，接下

来要做的

就是实例化文

档存储对象：

默认情况下

，ElasticsearchDocumentStore实例化之后会在

Elasticsearch创建两

个索引，一个叫作document，用于存

储文档，另

一个叫作label，用于

存储带标注的答案片段

。接下来将SubjQA数据集

的评论

设置为文档的索引，Haystack的文

档存储需要一个包含带

文本

和元键的字典，字段

名称为text和meta，如下所示：

meta字段

中的信息可以提供给检

索器作为过滤条件使用

。对于本书介

绍的这个场

景，我们提取SubjQA数据集的item_id和

q review_id列，

这样就可以按商品和

问题ID结合相应的训练进

行过滤。然后遍历每个

DataFrame，使

用write_documents()方法将它们添加到索

引中，如下

所示：

执行上述

操作，就将所有评论信息

加载到了索引中。如何检

索这些索

引呢？这时就需

要用到检索器了，下面来

看看如何为Elasticsearch初

始化一个

检索器。

初始化检索器

想

更深入了解TF-IDF和BM25，请参阅由

D. Jurafsky与J. H.

Martin

（Prentice Hall）撰写的Speechand Language Processing第3版的第

23章。

Elasticsearch兼

容Haystack提供的所有检索器，下

面使用稀疏检索器

BM25（“Best Match 25”的缩

写）来进行讲解。BM25是经典的

TF￾IDF（Term Frequency-Inverse Document

Frequency）算法的改进

版本，可以将

问题和上下文转化为可

以在Elasticsearch中进行快速检

索的

稀疏向量。BM25分数可以用以

度量匹配到的文本与检

索的相关程

度，在TF-IDF基础上

通过快速饱和TF值和规范

化文档长度来获得更好

的效果，所以更加倾向于

用在短文本检索领域 。

在

Haystack中，ElasticsearchRetriever默认使用BM25检索器，下面

是它的初始化方式：

接下

来我们看看如何查询训

练集中的某个电子产品

。对于像本章中这

种基于

评论的问答系统来说，将

查询范围限制到某一类

别非常重要，

否则检索器

将去检索与用户查询无

关的商品评论。例如，查询

“这个

相机质量好吗？”，如果

没有商品过滤器，则可能

会返回有关于手机

的评

论信息，而用户实际上想

知道某款笔记本电脑摄

像头的质量怎么

样。数据

集中的item_id是Amazon的ASIN编号，它是Amazon商

品的一个

特殊的编码标

识，可以登录Amazon ASIN查询网站（https://amazon￾asin.com）来

查看具体的商品信息。下

面代码段中的ASIN编号对应

于

Amazon的一款Fire品牌的平板电

脑，我们使用retrieve()方法来检索

“它是否适用于阅读？”的答

案：

在以上代码片段中，我

们使用top_k参数指定返回的

文档数量，并对包

含在meta字

段中的item_id和split键都使用了过

滤器。

retrieved_docs中的每一个元素都

是一个Haystack的文档对象，其中

包括具体的文档信息，以

及检索器本次查询的分

数和其他元数据。下

面是

一个retrieved_docs信息示例：

以上除了

检索出的文档结果之外

，我们还可以看到Elasticsearch计算

出

的查询分数（分数越高，匹

配度越高）。Elasticsearch底层使用

Lucene（https://lucene.apache.org）进行

索引和搜索，所以

Elasticsearch默认使

用Lucene的评分函数。如果想深

入了解，可以在

Elasticsearch文档（https://oreil.ly/b1Seu）中找

到评分函数的细

节。简而

言之，它首先使用布尔测

试（文档与查询内容是否

匹配）来

对待选文档进行

过滤，然后应用基于将文

档和查询表示为向量的

相似

度度量方式来进行

评分。

到目前为止，我们了

解了一种检索相关文档

的方法，接下来讲解一种

从文档中提取答案的方

法，以及如何在Haystack中加载MiniLM模

型。

初始化阅读器

在Haystack中，有

两种类型的阅读器可以

用来从给定的上下文中

提取

答案。

FARMReader

基于deepset公司研发

的FARM框架（https://farm.deepset.ai），用

来对Transformer进行微调

操作和部署操作，它完全

兼容经

Hugging Face

Transformers库训练出的模型

，也可以直接加载

Hugging Face Hub上的模

型。

TransformersReader

基于Hugging

Face Transformers库的问答pipeline，仅用于

推理。

尽管两个阅读器都

以相同的方式处理模型

的权重，但它们在将预测

结

果转换成答案的方式

上存在一些差别：

●在Hugging Face

Transformers库中

，问答pipeline在每个文本段

中使

用softmax对开始和结束的logit进行

规范化处理，也就是说，只

有在分数之和为1的情况

下，在同一段文本中提取

的答案的分数才有相

互

比较的意义。一段文本的

答案分数为0.9，不一定比另

一段分数为

0.8的文本答案

效果好。在FARM中，logit也没有规范

化，因此也只能

比较同一

个文本段的答案。

●TransformersReader有时会

两次预测出相同的答案

，但分数却不一

样，这是因

为窗口将答案截断，两个

窗口中都有答案片段，在

FA R M中，这些重复项会被删除

。

由于本章后续内容包括

对Reader进行微调操作，我们会

用到

FARMReader。与Hugging Face

Transformers库一样，需要在

Hugging Face Hub上

指定MiniLM的checkpoint和一些问答特定

的参

数来加载模型。

也可

以直接在Hugging

Face Transformers库中微调阅读

理解模型，

然后将其加载

到TransformersReader中进行推理，关于如何

进行微调

的详细信息，请

参阅文档（https://oreil.ly/VkhIQ）。

在FARMReader中，滑动窗口

的行为由词元分析器中

的max_seq_length

和doc_stride参数控制，这里我们

直接使用MiniLM论文中的值，下

面

使用一个之前的例子

来测试Reader的效果：

可以看出

，Reader的效果满足预期，到这里

，所有的子步骤已经完

成

，接下来使用Haystack Pipeline将所有组件

打包成一个完整的

pipeline。

问答

pipeline组装

Haystack提供了Pipeline抽象模块，用

来将检索器、阅读器和其

他组

件以图的形式集成

在一起，按需定制pipeline。另外还

有一些类似

Hugging Face Transformers库中那样可

以预定义的pipeline，专门

为问答

系统设计。这里我们使用

它制作一个用于答案提

取的

pipeline，会用到ExtractiveQAPipeline，它需要用一

对检索器-阅读

器作为其

参数：

每个Pipeline都有一个run()方法

来执行整个pipeline，只需要设置

一

些参数。对于ExtractiveQAPipeline来说，需要

设置query参数，使用

top_k retriever指定提取

的文档数量，以及使用top_k_reader指

定

从这些文档中提取的

答案数量，还需要像之前

那样设置filters参数。

下面再次

使用关于Amazon Fire平板电脑的那

个问题来获取答案：

pipeline按照

预期返回了答案数组，一

个端到端用于Amazon商品评论

的问答系统就完成了。但

是我们从结果中可以发

现，似乎第二个答案

和第

三个答案更接近问题的

实际要求。为了优化这一

点，需要一些指

标来量化

检索器和阅读器的性能

，我们将在本章接下来的

内容中详细

介绍。

7.2

评估并

改进问答pipeline

尽管在本书撰

写之际，业界对于问答系

统的研究大部分都聚焦

在改进

阅读理解模型上

，但是在实际应用场景中

，如果检索器一开始就检

索

不到相关文档，那么即

使拥有再好的阅读器也

无济于事。实质上，检

索器

的性能决定了整个问答

系统的性能上限，因此检

索器使用是否得

当就显

得很重要。考虑到这一点

，我们来看看用以评估检

索器的一些

常用指标，对

比稀疏检索器和密集检

索器的性能差异。

7.2.1

评估检

索器

评估检索器的一个

常用指标是召回率，它表

示检索出的相关文档数

与

所有的相关文档数的

比率，在这种情况下，“相关

”仅仅表示答案是

否存在

于一段文本中。所以如果

给定一组问题，可以通过

计算一个答

案出现在检

索器返回的前k个文档中

的次数来计算召回率。

在

Haystack中，有两种评估检索器的

方法：

●使用检索器内置的

eval()方法。该方法可用于开放

域和封闭域的问

答，但不

能用于像SubjQA这样的数据集

，因为每个文档都与单个

商品

相关联，每个问题都

需按商品维度进行过滤

。

●构建一个将检索器和EvalRetriever类

相结合的自定义Pipeline，这

种方

式支持定制评估函数和

检索流程。

召回率的一个

补充指标是平均查准率

（mean Average Precision，

mAP），它可以让那种检索文档

更加精准的检索器获得

正向收益。

由于需要评估

每个商品的召回率，然后

进行聚合，所以这里更倾

向于

使用第二种方法。Pipeline是

以图的形式组织的，图中

的每个节点表

示一个类

，该类有输入和输出，通过

run()函数接收前一个节点的

输出

作为其输入：

以上代

码段的kwargs参数接收图中前

一个节点的输出，在run()方法

中

做一些处理以后将元

组连同传出边（outgoing edge）名称输出

给下

一个节点，另外，PipelineNode还包

含一个outgoing_edgs参数，表示

该节点

输出的边数（在大多数情

况下outgoing_edgs=1，只有在

pipeline中还存在其

他分支节点才需要），给它

正确赋值即可。

在这个案

例中，需要用一个节点来

评估检索器，这里会使用

到

EvalRetriever类，它的run()函数会追踪那

些与ground truth集合匹

配的文档。使

用该类，就可以在检索器

节点之后添加评估节点

来构建

Pipeline：

以上代码段中会

为每个节点设置名称和

输入信息inputs。在大多数情

况

下，每个节点都有一个出

边，所以只需要在inputs中设置

前一个节

点的名称即可

。

至此，我们制作了包含评

估节点的pipeline，现在只需要将

问题和对

应的答案传给

该pipeline用于评估。为此，我们需

要将答案添加到文

档存

储的label索引中。Haystack提供了一个

Label对象，它将答案片

段和元

数据以规范化的方式进

行封装。我们通过迭代测

试集中的每个

问题，同时

提取匹配的答案和其他

元数据来创建Label对象数组

：

我们看看封装后的Label对象

中都有什么内容：

从中我

们可以看到问答对，以及

包含问题的唯一ID的origin字段

，这

样就能按问题过滤文

档存储内容。此外，我们还

将item_id添加到了

meta字段中，以便

可以按商品过滤label，得到label之

后，再将它们

添加到Elasticsearch的label索

引，如下所示：

接下来，我们

需要将问题ID和相应的答

案之间建立一个映射关

系，之

后传给pipeline。为了获取所

有label，我们可以使用文档存

储中的

get_all_labels_aggregated()方法，该方法会聚

合与唯一ID关联的所

有问

答对，这个方法会返回MultiLabel对

象数组，但是在我们的例

子

中只返回了一个元素

，那是因为我们是按问题

ID来进行过滤的。下面

是建

立聚合label的示例：

通过查看

其中一个label，我们可以看到

与给定问题相关的所有

答案都

被聚合在multiple_answers字段中

：

现在我们已经了解了评

估检索器的所有关键步

骤，下面我们就定义一

个

函数，将与每个商品关联

的问答对都发送到评估

pipeline，并在

pipe对象中追踪正确的

检索结果：

以上代码执行

后成功计算出了召回率

，这里为top_k_retriever设置了

一个比较

特殊的值来指定需要检

索的文档数量。一般来说

，增大这个

值会提高召回

率，但代价是会向阅读器

输出更多文档，并且会降

低端

到端pipeline的处理速度。为

了设置一个恰当的k值，我

们编写了一个

函数，依次

计算数组中每个k值在测

试集的召回率：

为了能够

直观地看到随着k值的增

加，召回率如何变化，下面

来绘制曲

线图：

从图中可

以看出，在k=5附近有一个明

显的拐点，到k=10的时候，召回

率基本不再增加。是否存

在方法，能在更小的k值上

取得相似的效果

呢？目前

使用的检索器是BM25，它使用

稀疏向量，稀疏向量的问

题在

于如果文档和问题

没有匹配的项就不会被

召回。这时密集向量就有

了

用武之地，我们可以为

问题和文档分别生成密

集向量，来获取语义层

面

的表示。下面让我们看看

如何使用密集向量技术

来检索文档。

密集文档检

索

V.

Karpukhin et al., “Dense Passage Retrieval

for Open￾Domain Question Answering”

（https://arxiv.org/abs/2004.04906），（2020）.

密集文档检索（Dense

Passage Retrieve，DPR）主要解

决开放域问

答中的检索

问题。从上一个例子可以

看出，当k=10时，召回率已经非

常接近于理想的状态，我

们不禁会产生遐想，能否

使用较小的k值得到

近似

的效果呢？因为这样做的

一个最直观的收益是可

以把更少的文档

传给阅

读器，减少处理步骤，从而

让问答pipeline整体的时延降低

。

类似BM25这样的稀疏检索器

有一个众所周知的局限

性，如果查询内容

中有评

论内容不完全匹配的术

语，则可能无法提取相关

的文档。一种

有望解决此

问题的方案是使用密集

嵌入来表示问题和文档

，这种当前

最前沿的技术

叫作密集文档检索 。DPR的主

要思想是采用两个BERT模

型

作为问题和文本段的编

码器。如图7-10所示，这些编码

器将输入的

文本映射为

[CLS]词元的d维向量表示。

Haystack为DPR初

始化检索器的方式与BM25相

似。除了设置文档存储之

外，我们还需要为问题和

段落挑选BERT编码器。这些编

码器是通过负

样本（问题

与不相关的文本段）和正

样本（问题与相关的文本

段）来

进行训练的，目的是

学习具有更高相似度的

问题-段落对。这里的示例

使用已经在NQ语料库上微

调过的编码器：

图7-10：用于计

算文档和查询的相关性

的DPR双编码器架构

代码中

设置了embed_title=False，因为在过滤了商

品之后，简单连接

文档的

标题（即item

id）并不会提供更多

的信息。一旦将密集检索

器初始化，下一个步骤就

是遍历Elasticsearch所有索引文档，并

使用

编码器来更新嵌入

，可以通过以下方式完成

：

准备好上述步骤后，下面

来用与BM25相同的方式来评

估密集检索器，

比较它们

的查全率：

从图中可以看

出，使用DPR并没有获得比BM25更

高的召回率，在k=3的

时候接

近饱和。

使用Facebook的FAISS库（https://oreil.ly/1E8Z0）作为文

档存储可

以提升嵌入的

相似度搜索性能。同样地

，提升DPR检索器的性能也可

以

通过在目标域做微调

操作来完成。如果想要了

解怎样对DPR做微调操

作，请

查阅Haystack文档（https://oreil.ly/eXyro）。

到这里我们已

经完成了对评估检索器

的探究，下面来看看如何

评估阅

读器。

7.2.2

评估阅读器

在提取式问答场景中，主

要有两个指标用于评估

阅读器：

精准匹配（Exact Match，EM）

如果预

测结果与事实答案中的

字符完全匹配，则用EM=1表示

，否则

EM=0，如果不存在预期的

答案，模型预测任何文本

都用EM=0来表示。

F1 分数（F1-score）

F1分数是

统计学中用来度量二分

类模型查准率的一种指

标，同时兼顾

了分类模型

的查准率和召回率，是查

准率和召回率的调和平

均数，最

大值是1，最小值是

0。

下面我们从FARM中导入一些

辅助函数来建立一个简

单示例，观察这两

个指标

：

在函数底层实现中，我们

首先通过删除标点符号

、修复空格和将字母

转化

为小写等操作来将答案

进行规范化，然后将规范

化的字符串词元

化处理

成词袋（bag-of-word），最后在词元层面

来计算指标。从上面

例子

可以看出，EM是一个比F1分数

要严格很多的指标：多一

个或少一

个词元都会使

EM=0，而F1分数可能无法捕捉到

真正错误的答案。例如

预

测的答案片段是“about 6000 dollars”，将会得

到以下结果：

所以，仅仅依

靠F1分数来评估阅读器可

能会产生一些误差，需要

结合

EM来做权衡。

一般来说

，每个问题都可能会有多

个合理的答案，因此会为

数据集中

每个用于评估

的问答对分别计算这两

个指标，然后选择最佳分

数的答

案。最后对每个问

答对的EM和F1分数求平均数

，得到的就是模型总体

的

EM和F1分数。

为了评估阅读器

，下面我们将创建一个具

有两个节点的新pipeline：

一个阅

读器节点，一个用于评估

阅读器的节点。我们将会

使用到

EvalReader类，该类从阅读器

获取预测结果并计算相

应的EM和F1分

数，为了与SQuAD评估

结果进行比较，我们将使

用存储在EvalAnswers

中的top_1_em和top_1_f1指标为

每个查询获取最佳答案

：

请注意，以上代码设置了

skip_incorrect_retrieval=False，作用是

可以确保检索器

始终会将上下文传给阅

读器（在SQuAD评估中也是一

样

）。现在我们已经通过阅读

器运行了每个问题，下面

来输出分数：

经过微调的

模型在SubjQA上的效果似乎要

比在SQuAD

2.0上的效果要

差得多

，其中MiniLM的EM和F1分数分别是76.1和

79.5。造成性能下降

的一个原

因是用户对产品的真实

评论和SQuAD的维基百科文章

有很大的

差异，而且用户

评论的语法是偏口语化

的。另一个原因可能是数

据集

语料具备固有的主

观性，这些问答对与维基

百科中的科普信息相比

显

得不着边际。下面我们

来看看如何在数据集上

对模型进行微调操作，

来

获得更好的领域自适应

结果。

7.2.3

领域自适应

D. Yogatama et

al., “Learning and Evaluating General

Linguistic

Intelligence”

（https://arXiv.org/abs/1901.11373），（2019）.

尽管在

SQuAD上微调的模型可以很好

地泛化到其他领域，但对

于SubjQA

来说，模型的EM和F1分数要

比SQuAD差得多。在其他提取式

问答数据集

中也存在这

种泛化失效的情况，这有

可能是因为Transformer模型在

SQuAD上容

易产生过拟合

。改善阅读

器的最直接方法是在SubjQA训

练

集上进一步微调MiniLM模型

。FARMReader中有一个专门为此设计

的

train()方法，输入数据采用SQuAD JSON格

式，其中所有问答对按照

商品维度分别组合在一

起，如图7-11所示。

图7-11：SQuAD JSON数据结构

展示

SQuAD JSON是一个比较复杂的

数据格式，需要借助一些

方法和Pandas

库来辅助操作。首

先来创建一个函数，该函

数可以创建与每个商品

ID

相关联的paragraphs数组，数组的每

个元素都包含一个上下

文（即评

论）和一个问答对

的qas数组，如下所示：

有了paragraphs数

组的创建方法之后，传入

任意单个商品ID关联的

DataFrame就

可以获得SQuAD格式的数据：

最

后将此函数应用于每个

被拆分的DataFrame中的每个商品

ID，下面的

convert_to_squad()函数将执行此操

作，并将结果保存在

electronics-{split}.json文件

中：

现在我们知道了如何

正确地拆分这种格式的

数据，下面通过指定训练

和拆分的位置以及保存

微调之后模型的位置，来

对阅读器进行微调操

作

：

对阅读器经过微调操作

之后，下面来比较它与基

线模型的性能差异：

从结

果可以看出，领域自适应

使EM分数提升到原来的6倍

！F1分数也提

升到原来的1倍

左右！可能有人会问，为什

么不直接在SubjQA训练集上

微

调预训练的语言模型，原

因之一是在SubjQA中只有1295个训

练语

料，而SQuAD有超过100 000个，我们

很可能会遇到过拟合的

问题。不

过，可以看看如果

这样做会产生什么结果

，为了能进行公平的比较

，

我们将使用用于微调SQuAD基

线相同的语言模型。和之

前一样，使用

FARMReader加载模型：

然

后使用一轮（n epochs=1）来进行微调

操作：

结合对测试集的评

估结果，可以得到：

可以看

出，直接在SubjQA上微调语言模

型比在SQuAD+SubjQA上性能要

差得多

。

在处理小型数据集时，在

评估Transformer模型时最好使用交

叉校验，

因为在小型数据

集上非常容易过拟合。可

以在FARM仓库

（https://oreil.ly/K3nK8）中找到如何使

用SQuAD格式的数据集执行

交

叉验证的例子。

7.2.4

评估整体

问答pipeline

目前我们已经知道

了如何评估检索器和阅

读器，本节将它们整合到

一

起，评估pipeline的整体性能，要

完成这一工作，只需要在

检索器

pipeline中添加阅读器节

点。此前我们验证了检索

器在k=10的时候能

够获取不

错的召回率，在加入阅读

器后，最终还需要再微调

这个值，

以评估它对阅读

器性能的影响（与此前SQuAD类

似的评估方式相比，现

在

的情况是每次查询操作

，阅读器都会接收多个上

下文）：

我们通过比较模型

的top 1的EM和F1分数，来预测图7-12中

检索器返

回的文档中的

答案。

图7-12：阅读器的EM和F1分数

与整个问答pipeline的比较

从图

7-12可以看出检索器对整个

pipeline性能的影响，因为多了检

索

器，整体问答pipeline性能比单

独评估阅读器要低一些

，这主要是因

为检索器会

限制查到的文档数，这个

问题可以通过调整检索

器查到的

文档数来解决

。

到目前为止，我们只从文

档中提取了答案片段，在

实际情况中，答案

很可能

零散地分布在整个文档

中，我们当然希望模型能

将这些片段综

合成一个

连贯的答案。下面我们看

看生成式问答如何解决

这个问题。

7.3

生成式问答

P. Lewis et

al., “Retrieval-Augmented Generation for

Knowledge-IntensiveNLPTasks”

（https://arxiv.org/abs/2005.11401），（2020）.

有

一种十分有趣的方案可

以替代将答案提取为文

本片段这种方案。该

方案

使用预训练语言模型来

直接生成答案，通常被称

为抽象式问答

（Abstractive QA）或生成式

问答（Generative QA），并且有能力

生成具

备更好措辞的答案，从而

解决答案分散的问题。虽

然目前这种

技术方案还

不如提取式问答成熟，但

它发展的速度很快，很可

能目前

已经有工业级应

用案例了。本节将会介绍

目前最前沿的技术：检索

增

强生成（Retrieval-Augmented Generation，RAG） 。

RAG扩展了本章中

介绍的经典检索器-阅读

器架构，将阅读器替换为

生

成器，并使用DPR作为检索

器来搭配使用。生成器是

一个预训练的序列

到序

列（常用Seq2Seq称呼）的Transformer模型，类似

T5和BART模

型，首先从DPR获取文档

的隐式向量，然后根据查

询内容和文档内容迭

代

生成答案。由于DPR和生成器

是可区分的，因此整个过

程也可以进行

端到端的

微调处理，如图7-13所示。

图7-13：端

到端微调检索器和生成

器的RAG架构（来自

Ethan Perez）

下面我们

来看看RAG的一个简单示例

，需要用到之前使用的

DPRetriever，另

外再实例化一个生成器

，RAG有两种类型可供选择：

RAG-Sequence

使

用被检索出的文档来生

成完整的答案，检索器中

前k个被传到生成器

的文

档，会被当成额外的文本

信息，通过边缘化的方式

融合到生成

器，最后为每

个文档输出序列，以获取

最佳答案。简单来说，就是

使

用单一文档生成整个

序列，然后使用检索器对

该文档的检索概率加权

求和。

RAG-Token

使用不同文档来生

成答案中的每个词元，每

个词元最终的概率分布

是

检索器对该文档的检

索概率乘基于该文档生

成词元的概率，最后把所

有词元的概率相乘得到

最终序列的概率。

由于RAG-Token模

型往往比RAG-Sequence模型的效果更

好，我们将使用

在NQ上微调

的模型作为生成器。在Haystack中

，实例化生成器类似于

实

例化阅读器，但不会涉及

滑动窗口的设置，比如不

用设置

max_seq_length和doc_stride参数，而是指定

控制文本生成的超参

数

：

我们使用num_beams参数指定了在

束搜索中的束数（在本书

第5章有详

细介绍），就像在

DPR检索器所做的那样，不需

要引入文档标题，语料

库

是按商品ID过滤的。

接下来

要做的是使用Haystack的GenerativeQAPipeline将检索

器和生

成器组合在一起

：

在RAG中，查询编码器和生成

器都是经过端到端训练

的，而上下文编码

器并不

会启用。在Haystack中，Generative

QAPipeline使用

RAGenerator的查询

编码器和DensePassageRetriever的上下文编码

器。

下面试试给RAG输入一些

之前的Amazon Fire平板电脑的查询

信息，来

看看效果。为了简

化查询，这里编写了一个

简单的函数来获取查询

结

果并输出最佳答案：

我

们来使用此函数做个测

试：

这些结果看起来并不

是我们想要的，但也不是

那么糟糕，这种主观性

问

题确实会使生成器“感到

困惑”，我们换一种事实陈

述性问题来试

试：

可以看

出，事实陈述性的问题获

得了不错的答案。为了获

取更好的结

果，我们可以

在SubjQA上对RAG进行端到端的微

调，这可以作为本书的

一

个实践练习题，如果你有

兴趣，Hugging Face Transformers库

（https://oreil.ly/oZz4S）中的脚本可以帮

助到你。

7.4

本章小结

本章讲

解了问答系统的两种技

术（提取式和生成式），研究

了两种不

同的检索算法

（BM25和DPR）。在本章中，我们看到，虽

然领域自适应

是一种简

单的技术，但它却可以显

著提升问答系统的性能

，随后我们

研究了一些用

于评估此类系统的常见

指标。尽管本章关注的是

封闭域

问答（电子产品的

单个域），但本章中的技术

可以很容易地推广到开

放域问答案例。建议读者

阅读Cloudera的Fast Forward问答系列

（https://oreil.ly/Fd6lc）文章。

从

头开始构建问答系统是

一项有挑战的工作，有个

可取的经验是首先

为终

端用户提供搜索功能，然

后才是其他组件的部署

，比如提取组

件。除了按需

为用户响应查询之外，阅

读器还可以提供一些比

较新颖

的功能。例如，Grid Dynamics（https://oreil.ly/CGLh1）的研

究

人员能够使用他们的

阅读器自动提取用户目

录中每种商品的一组优

缺

点。另外，还可以通过构

造诸如“这是什么类型的

相机？”之类的查

询问题，以

零样本的方式提取命名

实体。考虑到其还在学术

初期，我

们建议在其他两

种方式不能很好地解决

问题之后才开始研究生

成式问

答。借用马斯洛需

求层次理论，问答领域的

需求层次可以用图7-14表

示

。

图7-14：问答领域需求层次金

字塔

A. Talmor et al., “MultiModalQA:

Complex Question Answering

over Text，Tables and

Images”

（https://arxiv.org/abs/2104.06039），（2021）.

P. Lewis et al.,

“PAQ: 65 Million Probably-Asked Questions

and

What You Can Do with Them”

（https://arxiv.org/abs/2102.07033），（2021）；A. Riabi et

al., “Synthetic Data

Augmentation for Zero-Shot Cross￾Lingual Question Answering”

（https://arxiv.org/abs/2010.12643），（2020）.

展望一下未来，一个

令人振奋的研究领域是

多模态问答

（Multimodal QA），它涉及文本

、表格和图像等多种模态

。如

MultimodalQA的基准测试 所述，这样

的问答系统可以回答更

加复杂

的问题，整合不同

模态的信息，比如

“When was the famous painting

with two touching fing

ers completed?”（那幅两

只手指触碰的名画是什

么时候完成的？）

这样的问

题。另一个具有实际业务

价值的应用场景是知识

图谱的问

答，图谱节点对

应于现实世界的实体，他

们之间的关系由边（edge）

来定

义。通过将仿真的描述编

码为（主语、谓语、宾语）三元

组，可

以使用图谱来回答

有关缺失元素的问题。关

于将Transformer和知识图

谱结合的

示例，请参阅Haystack教程（https://oreil.ly/n7lZb）。

一个有

前景的研究方向是自动

问题生成

（Automatic Question Generation），它是一种使用

未标注数据或

使用数据

增强的无监督/弱监督训

练方法，最近有两篇关于

它的论文，

一篇关于PAQ的基

准测试

（Probably

Answered Questions benchmark），另一篇关于跨语

言环境的合成数据增强

。

本章探讨了如何将问答

模型用于实际场景，以及

要实现这个目标需要

做

的工作，比如实现快速检

索pipeline来达到近实时的预测

效果。虽

然理论上是近实

时的，但是在生产环境中

将问答模型应用于少数

预先

选定的文档却可能

需要几秒钟的时间来处

理。虽然几秒钟看起来并

没

有多久，但不妨试想一

下，在使用Google搜索的时候，秒

出结果和等

待几秒才出

结果的体验是完全不同

的。这几秒钟也可能决定

底层

Transformer模型的命运，多几秒

钟它可能就被否决了。第

8章将介绍

几种模型加速

的方法。

第8章

Transformer模型调优

在

前面的章节中，你已经看

到如何对Transformer进行微调，从而

在各

种任务上产生出色

的结果。然而，在许多情况

下，准确率（或你正在

优化

的任何指标）并不足够。如

果你的最新模型太慢或

太大而无法满

足应用程

序的商业要求，那么它就

不会很有用。一个显而易

见的替代

方法是训练一

个更快、更紧凑的模型，但

模型容量的减少通常伴

随着

性能的下降。当你需

要快速、紧凑且高度准确

的模型时，你有什么技

术

可以选择？

在本章中，我们

将探讨四种互补技术，可

用于加速你的Transformer模

型的预

测并减少内存使用：知识

蒸馏、量化、剪枝和使用

Open Neural

Network Exchange（ONNX）格

式和ONNX Runtime

（ORT）进行图优化。我们还

将看到如何将一些技术

组合起来以产生显

著的

性能提升。例如，这是Roblox工程

团队在他们的文章

“How

We Scaled Bert to Serve 1+Billion

Daily Request

s on CPUs”（https://oreil.ly/QdNIk）中采

取的方法。如图8-1

所示，他们

发现将知识蒸馏和量化

相结合，可以使他们的BERT分

类器

的延迟和吞吐量提

高30倍以上！

为了阐明每种

技术所带来的利弊，我们

将以意图识别为案例研

究。这

是基于文本的助手

的重要组成部分，低延时

对于实时维持对话至关

重

要。在学习过程中，你将

学习如何创建自定义训

练器，进行高效的超

参数

搜索，并了解如何通过Hugging Face

Transformers库

实现尖端

研究所需的要

素。我们开始吧！

8.1

以意图识

别为例

假设我们正在尝

试为公司的呼叫中心构

建一个基于文本的问答

机器

人，以便客户无须与

人类交谈即可查询其账

户余额或进行预订。为了

理解客户的目标，我们的

助手需要能够将各种自

然语言文本分类为一

组

预定义的动作或意图。例

如，客户可能会发送以下

有关即将到来的

旅行的

消息：

图8-1：Roblox使用知识蒸馏、动

态填充和权重量化扩展

了BERT（照

片由Roblox员工Quoc N. Le和Kip

Kaehler提供）

Hey，

I'd like to rent

a vehicle from Nov 1st to

Nov 15t

h in Paris and

I need a 15 passenger van

我

们的意图分类器可以自

动将其归类为汽车租赁

意图，然后触发一个

操作

和响应。为了在生产环境

中具有稳健性（robust，又称鲁棒

性），我们的分类器还需要

能够处理超出范围的查

询，即客户进行的

查询不

在任何预定义意图之内

，系统应该产生正确的响

应。例如，在

图8-2中展示的第

二种情况中，客户提出了

一个关于体育的问题（超

出

范围），文本助手错误地

将其分类为已知的范围

内意图之一，并返回

发薪

日的响应。在第三种情况

下，文本助手被训练可以

检测超出范围

的查询（通

常标记为单独的类），并告

知客户它可以回答哪些

主题的

问题。

S. Larson et al.,

“An Evaluation Dataset for Intent

Classification

and Out-of-Scope Prediction”

（https://arxiv.org/abs/1909.02027），（2019）.

作为基准，我

们对BERT-base模型进行了微调，在

CLINC150数据集上实

现了大约94%的

准确率

。这个数据集包括

来自银行和旅行等10个领

域

中150个意图的22 500个范围内

查询，还包括属于oos意图分

类的1200

个范围外查询。实际

上，我们也会收集我们自

己的内部数据集，但使

用

公共数据集是快速迭代

和产生初步结果的好方

法。

我们首先从Hugging

Face Hub下载我们

微调过的模型，并将其封

装

成一个文本分类pipeline：

▲图8-2：人

类（右侧）与面向个人财务

的基于文本的助手（左侧

）

之间的三次交互（由Stefan Larson等人

提供）

现在我们有了一个

pipeline，我们可以传递一个查询

来从模型中获取

预测意

图和信心评分。

太好了！对

租车（car_rental）意图分类正确。现在

我们来创建一个

基准，用

来评估我们的基线模型

的性能。

8.2

创建性能基准

如

Emmanuel Ameisen在Building Machine Learning Powered

Applications（O'Reilly）一书中所描述的，业务

或产品指标是最重

要的

考虑因素。毕竟，如果模型

不能解决你的业务关心

的问题，那么

它的准确率

就不重要了。在本章中，我

们将假设你已经定义了

对应用

程序有意义的指

标，然后再集中优化模型

指标。

与其他机器学习模

型一样，将Transformer模型部署到生

产环境中涉及

多个限制

因素之间的权衡，最常见

的限制因素包括 ：

模型性

能

我们的模型在反映实

际生产数据的精心制作

的测试集上表现如何？当

错误的代价很高（最好通

过人工干预来降低），或者

当我们需要在数

百万个

样本上运行推理且对模

型指标进行小的改进可

以转化为大的总

体收益

时，这一点尤为重要。

延迟

我们的模型能多快地提

供预测？通常我们关心的

是实时环境中的延

迟，例

如像Stack

Overflow这样需要分类器快

速检测网站上不受欢迎

的评论（https://oreil.ly/cf7QX）。

内存

我们如何部

署类似GPT-2或T5这样需要千兆

字节的磁盘存储和内存

的百

亿参数模型？在移动

设备或边缘设备中，内存

尤其重要，因为模型必

须

在不能访问强大的云服

务器的情况下生成预测

。

忽略这些限制将对你的

应用程序用户体验产生

负面影响。更常见的情

况

是，因为考虑不周，购买了

过多的、不必要的云服务

器，会导致成

本的增加。为

了探索如何使用各种压

缩技术优化每个约束条

件，我们

从创建一个简单

的基准测试开始，该测试

度量给定pipeline和测试集

的每

个数量。下面是我们需要

的框架：

我们已经定义了

一个optim_type参数，用于跟踪本章

中涵盖的不同优

化技术

。我们将使用run_benchmark()方法来收集

所有的指标，并将其

保存

在一个字典中，key由optim_type给出。

现

在，我们通过计算测试集

上的模型准确率来给这

个类添加一些具体

内容

。首先，我们需要一些数据

进行测试，因此我们下载

用于微调基

线模型的CLINC150数

据集。我们可以使用Hugging Face Datasets库

从

Hub获取数据集，如下所示：

其

中，plus配置是指包含超出训

练范围的样本子集。CLINC150数据

集

中的每个样本都由文

本列中的查询和其对应

的意图组成。我们将使用

测试集来对我们的模型

进行基准测试，因此我们

来看一下数据集中的

一

个样本：

意图以ID的形式提

供，但我们可以通过访问

数据集的features属性轻

松获取

到它们与字符串之间的

映射（反之亦然）。

现在我们

已经基本了解了CLINC150数据集

的内容，我们来实现

PerformanceBenchmark类的

compute_accuracy()方法。由于数据集在

意图

类上平衡，我们将使用准

确率作为我们的度量指

标。我们可以通

过Hugging Face Datasets库加载

此度量指标，方法如下：

准

确率指标要求预测和参

照（即基准标注）为整数。我

们可以使用

pipeline从text字段提取

预测，然后使用意图对象

的str2int()方法将

每个预测映射

到其相应的标识符。以下

代码在返回数据集上的

准确率

之前将所有预测

和标注收集到列表中。我

们也将其添加到我们的

PerformanceBenchmark类中：

接下来，我们通过使

用PyTorch的torch.save()函数将模型序列化

到磁

盘中来计算模型的

大小。在内部，torch.save()使用Python的pickle

模块

，并且可以用于保存从模

型到张量到普通的Python对象

的任何内

容。在PyTorch中，保存模

型的推荐方式是使用它

的state_dict，它是

一个Python字典，将模型

中的每个层映射到其可

学习的参数（即权重

和偏

差）。我们看看基线模型的

state_dict中存储了什么：

我们可以

清晰地看到每个key-value对对应

于BERT中特定的层和张量。

因

此，如果我们使用以下代

码保存我们的模型：

我们

可以使用Python的pathlib模块中的Path.stat()函

数来获取关于

底层文件

的信息。特别地，Path（"model.pt"）.stat().st_size会给

出模

型的字节数。我们把这些

放在一起写成compute_size()函数，并

将

其添加到PerformanceBenchmark中：

最后，我们实

现time_pipeline()函数，以便我们可以度

量每个查询的

平均延迟

。对于这个应用程序，延迟

是指将文本查询提供给

pipeline

并从模型返回预测的意

图所需的时间。在幕后，pipeline还

会对文本

进行词元化处

理，但这比生成预测要快

一千倍，因此对总体延迟

的贡

献可以忽略不计。度

量代码片段执行时间的

一种简单方法是使用

Python的

time模块中的perf_counter()函数。该函数的

时间分辨率比

time.time()函数更好

，非常适合获取精确的结

果。

我们可以使用perf_counter()函数来

计时我们的pipeline，通过传递

测

试查询并计算开始和结

束之间的毫秒级时间差

来完成：

这些结果展示出

延迟时间有相当大的差

异，并且暗示通过pipeline计

时的

结果在每次运行时可能

会产生非常不同的结果

。所以我们将收集

多次运

行的延迟时间，然后使用

得到的分布计算均值和

标准差，以便

给我们一个

关于数值差异的概念。以

下代码执行我们需要的

操作，并

包括一个预热CPU的

阶段，然后进行实际的计

时运行：

为了保持简单，我

们将使用相同的查询值

来对比所有的模型。一般

来

说，延迟取决于查询的

长度，一个好的实践是使

用模型在生产环境中

可

能遇到的查询来进行测

试。

现在我们的PerformanceBenchmark类已经完

成，我们从基准测试BERT

开始

。对于基线模型，我们只需

要传递pipeline和我们希望进行

基准

测试的数据集。我们

将收集结果到perf_metrics字典中以

跟踪每个模

型的性能。

现

在我们有了一个参考点

，我们来看一下我们的第

一个压缩技术：知

识蒸馏

。

平均延迟值会根据你使

用的硬件类型而有所不

同。例如，通常可以通

过在

GPU上运行推理来获得更好

的性能，因为它可以进行

批处理。对于

本章的目的

，重要的是模型之间延迟

的相对差异。一旦确定了

性能最

佳的模型，我们就

可以探索不同的后端，以

确保必要时能够降低绝

对

延迟。

8.3

通过知识蒸馏减

小模型大小

C. Buciluǎ

et al., “Model Compression，”Proceedings of the

12th ACM SIGKDD International Conference on

Knowledge

Discovery and Data Mining（August 2006）:

535-541，

https://doi.org/10.1145/1150402.1150464.

G. Hinton, O. Vinyals,

and J. Dean, “Distilling the

Knowledge

in a Neural Network”

（https://arxiv.org/abs/1503.02531）, （2015）.

知识蒸馏是

一种通用的方法，用于训

练一个较小的学生模型

来模仿一

个更慢但表现

更好的较大的教师模型

的行为。这种方法最初在

2016年

集成模型的背景下引

入 ，后来在一篇著名的2015年

的论文中得到推

广。其被

推广到深度神经网络，并

应用于图像分类和自动

语音识别

。

W. Fedus, B. Zoph, and N.

Shazeer, “Switch

Transformers:Scaling to Trillion Parameter

Models with Simple

and Efficient Sparsity”（https://arxiv.org/abs/2101.03961）,

（2021）.

鉴于最近自然

语言处理中越来越流行

使用具有越来越多参数

数量的预

训练语言模型

（目前最大的模型参数数

量已经达到一万亿个） ，知

识蒸馏也成为一种流行

的策略，可以压缩这些巨

大模型的大小，使其

更适

合于构建实际应用程序

。

8.3.1

微调知识蒸馏

Geoff Hinton在一次演

讲中（https://oreil.ly/OkHGp）创造了这个

词，指的

是对软化的概率的观察

揭示了教师的隐藏知识

。

那么在训练过程中，知识

是如何从教师模型传到

学生模型的呢？对于

类似

于微调这样的监督任务

，主要思想是通过教师模

型提供的“软概

率”分布来

增加基准标注，从而提供

一些学生模型需要学习

的互补信

息。例如，如果我

们的BERT-base分类器对多个意图

赋予了高概率，那

么这可

能意味着这些意图在特

征空间中非常接近。通过

训练学生模型

来模仿这

些概率，目标是提取一些

教师模型已经学习到但

仅仅依靠标

注无法获取

的“暗知识” 。

从数学角度来

看，这个过程的工作原理

如下。假设我们将输入序

列x提

供给教师模型，以生

成一个logit向量z（x）=[z（x），…，zN

（x）]。我们可以通

过应用softmax函数将这些logit转换

为概率：

1

在第5章中，我们在

文本生成的上下文中也

遇到了温度。

但这不完全

符合我们的需求，因为在

许多情况下，教师模型会

给一个

类别分配高概率

，而其他类别的概率接近

于零。当出现这种情况时

，

教师模型除了提供基准

标注外，并没有提供太多

附加信息，所以我们

在应

用softmax前，会使用一个超参数

温度T对logit进行缩放，以使概

率变得“更软” ：

如图8-3所示，T值

越高，类上的概率分布越

平缓，能够揭示出教师模

型为每个训练例子所学

习到的决策边界的更多

信息。当T=1时，我们可

以得到

原始的softmax分布。

图8-3：一个硬标

注被独热编码（左）、softmax概率（中

）、以及软

分类概率（右）的比

较

由于学生模型也会生

成自己的软概率qi（x），我们可

以使用

Kullback-Leibler（KL）（https://oreil.ly/8nKQG）散度来度量两

个

概率分布之间的差异：

使

用KL散度，我们可以计算当

我们用学生模型的概率

分布来近似教师

模型的

概率分布时的损失。这使

我们能够定义知识蒸馏

损失：

2

L=TD

KDKL

22

其中T是一种规范化

因子，它考虑到软标注产

生的梯度大小与1/T成比

例

的事实。对于分类任务，学

生模型损失则是蒸馏损

失与一个常规的

基于交

叉熵的基准标注损失L的

加权平均。

CE

L=αL+（1-α）L

studentCEKD

其中α是一个超

参数，它控制每个损失的

相对强度。整个过程的示

意

图如图8-4所示，在推断时

间，温度设置为1，以恢复标

准softmax概

率。

图8-4：知识蒸馏过程

8.3.2

基于知识蒸馏的预训练

技术

V. Sanh

et al., “DistilBERT，a Distilled Version of

BERT:Smaller，Faster，Cheaper and Lighter”

（https://arxiv.org/abs/1910.01108），（2019）.

知识蒸馏还可以在

预训练期间使用，我们可

以创建一个通用的学生

模

型，随后可对下游任务

进行微调。在这种情况下

，教师模型是一个预

训练

语言模型，例如BERT，它将其关

于掩码语言建模的知识

迁移给学

生模型。例如，在

DistilBERT论文中 ，掩码语言建模损

失L由知识蒸

馏术语和余

弦嵌入损失L=1-cos（hs，ht）扩展，以调整

教师模型和学

生模型之

间的隐藏状态向量方向

：

mlmcos

L=αL+βL+γL

DistilBERTmlmKDcos

由于我们已经有了经过

微调的BERT-base模型，我们看看如

何使用知识

蒸馏来微调

更小、更快的模型。为了实

现这一点，我们需要一种

将交

叉熵损失与LKD项相结

合的方法。幸运的是，我们

可以通过创建自己的

训

练器来做到这一点！

8.3.3

创建

知识蒸馏训练器

为实现

知识蒸馏，我们需要向Trainer基

类添加几个东西：

●新的超

参数α和T，控制了蒸馏损失

的相对权重以及标注概

率分布应

平滑化的程度

。

●微调的教师模型，在我们

的例子中是BERT-base。

●一种新的损

失函数，将交叉熵损失与

知识蒸馏损失结合起来

。

添加新的超参数非常简

单，我们只需要继承TrainingArguments类并

将

它们作为新属性包含

进去：

对于训练器本身，我

们需要一个新的损失函

数。实现这一点的方法是

通过子类化Trainer并覆盖compute_loss()方法

，包括知识蒸馏损失项

L：

KD

我

们逐步解释一下这段代

码。当我们实例化DistillationTrainer时，

我们

传了一个已经在我们的

任务上进行了微调的教

师模型作为

teacher_model参数。接下来

，在compute_loss()方法中，我们从学生

模

型和教师模型中提取logit，将

它们按温度进行缩放，并

通过

softmax进行规范化之后，传

给PyTorch的nn.KLDivLoss()函数计算KL

散度。nn.KLDivLoss()的一

个怪癖是，它期望以对数

概率形式输入，

并将标注

作为普通概率。这就是为

什么我们使用F.log_softmax()函数

来规

范化学生模型的logit，而将教

师模型的logit转换为标准softmax

概

率的原因。nn.KLDivLoss()中的reduction=batchmean参数指定

我们

在批处理维度上对

损失进行平均。

你还可以

使用Hugging Face

Transformers库的Keras API进行知识

蒸馏

。为此，你需要实现一个自

定义的Distiller类，覆盖

tf.keras.Model()的train_step()、test_step()和compile()方法

。

请查看Keras文档（https://oreil.ly/6qp0F）了解如何实

现。

8.3.4

选择一个好的学生模

型来初始化

Y. Kim and H. Awadalla，“FastFormers:

Highly

EfficientTransformerModels for Natural Language

Understanding”（https://arxiv.org/abs/2010.13382），

（2020）.

现在我们有

了自定义的训练器，你可

能会问的第一个问题是

应该选择

哪个预训练语

言模型作为学生模型？一

般来说，我们应该选择一

个更

小的模型来降低延

迟和内存占用。从文献上

来看，一个好的经验法则

是当教师模型和学生模

型为同一模型类型时，知

识蒸馏效果最好 。

这种情

况的一个可能原因是不

同的模型类型，比如BERT和RoBERTa，可

以具有不同的输出嵌入

空间，这会阻碍学生模型

模仿教师模型的能

力。在

我们的案例研究中，教师

模型是BERT，因此DistilBERT是一个

很自

然的备选项，因为它的参

数数量少了40%，并且已经被

证明在下游

任务上取得

了强大的结果。

首先，我们

需要对查询进行词元化

和编码，因此我们从DistilBERT实

例

化词元分析器，并创建一

个简单的tokenize_text()函数来处理预

处

理：

默认情况下，Trainer在对分

类任务进行微调时会查

找一个名为labels

的列。也可以

通过指定TrainingArguments的label name参数来覆盖

此

行为。

在这里，我们已经

删除了文本（text）列，因为我们

不再需要它，同

时我们也

将意图（intent）列重命名为标注

（labels），以便于训练

器自动检测

。

现在我们已经处理了文

本，接下来需要做的是为

我们的

DistillationTrainer定义超参数和compute_metrics()函

数。我们还

将把所有的模

型推送到Hugging Face Hub，所以我们开始

登录我们

的账户：

接下来

，我们将定义训练过程中

需要跟踪的指标。与性能

基准测试一

样，我们将使

用准确率作为主要指标

。这意味着我们可以在

compute_metrics()函

数中重用accuracy_score()函数，并将其包

含在

DistillationTrainer中。

在这个函数中，序

列建模头的预测以logit的形

式呈现，因此我们使用

np.argmax()函

数找到最有信心的类别

预测，并将其与基准标注

进行比

较。

这种微调通用

的、精简的语言模型的方

法有时被称为“任务无关

”的

精简。

接下来，我们需要

定义训练参数。首先，我们

将设置α=1，以了解

DistilBERT在没有任

何来自教师模型的信号

的情况下表现如何

。然

后

，我们将推送我们微调过

的模型到一个名为distilbert-base￾uncased-finetuned-clinc的新

存储库中，因此我们只需

要在

DistillationTrainingArguments的output_dir参数中指定即可

。

我们还调整了一些默认

的超参数值，比如轮次数

、权重衰减和学习

率。下一

步要做的是初始化一个

学生模型。由于我们将在

训练器中进

行多次运行

，我们将创建一个student_init()函数来

初始化每个新运

行的模

型。当我们将此函数传给

DistillationTrainer时，这将确保每

次调用train()方

法时我们都初始化一个

新模型。

我们需要做的另

一件事是为学生模型提

供每个意图和标注ID之间

的映

射。这些映射可以从

我们在pipeline中下载的BERT-base模型中

获得：

有了这些映射，我们

现在可以使用第3章和第

4章遇到的AutoConfig类

创建自定义

模型配置。我们使用这个

配置来为我们的学生模

型创建一

个包含有关标

注映射信息的配置：

在这

里，我们还指定了模型应

该期望的类数。然后，我们

可以将这个

配置提供给

AutoMo delForSequenceClassification类的

from pretrained()函数，如下所示：

我们

现在已经拥有所有需要

制作我们的蒸馏模型的

成分，因此我们加

载模型

并进行微调：

我们可以看

到，与BERT基础模型达到的94%的

准确率相比，知识蒸馏之

后，在验证集上的准确率

还能达到92%，看起来相当不

错。现在我们已

经对DistilBERT进行

了微调，我们将模型推到

Hub上，以便以后重复使

用：

我

们现在将模型安全地存

储在平台上，可以立即在

性能基准测试中使

用它

。

我们可以将该pipeline传给我们

的PerformanceBenchmark类来计算与

该模型相

关的指标：

为了将这些结

果与我们的基线进行比

较，我们创建一个散点图

，将准

确率与延迟进行比

较，每个点的半径对应于

磁盘上模型的大小。以下

函数可以满足我们的需

求，将当前优化类型标记

为虚线圆以便于与以

前

结果进行比较：

从图中可

以看出，通过使用一个较

小的模型，我们显著降低

了平均延

迟。这一切只需

要付出降低略超过1%的准

确率的代价！我们看看能

否

通过包含教师模型的

蒸馏损失并找到好的参

数值来弥补最后的差距

。

8.3.5

使用Optuna找到优秀的超参数

T. Akiba

et al., “Optuna:A Next-Generation Hyperparameter

Optimization

Framework”

（https://arxiv.org/abs/1907.10902），（2019）.

为了找到适合α和T的最佳

值，我们可以在二维参数

空间上进行网格搜

索。但

更好的选择是使用Optuna ，这是

一个专门为这种任务设

计的

优化框架。Optuna通过多次

实验来优化目标函数，将

搜索问题表述为

一个目

标函数。例如，假设我们希

望最小化Rosenbrock的“香蕉函

数”（https://oreil.ly/hPk8h）。

2

f（x，y）=（1-x）2+100（y-x）2

这

是一个优化框架的著名

测试案例。如图8-5所示，该函

数因其曲线轮

廓而得名

，在（x，y）=（1，1）处有全局最小值。找到

这个山谷是一

个简单的

优化问题，但收敛到全局

最小值并不容易。

图8-5：两个

变量的Rosenbrock函数绘图

在Optuna中，我

们可以通过定义一个objective()函

数，该函数返回f

（x，y）的值，从而

找到f（x，y）的最小值。

trial.sugges_float对象指定

了要均匀采样的参数范

围；Optuna还提

供suggest_int和suggest_categorical函数，分别用

于整数和分类参

数。Optuna将多

个实验收集为一项研究

，因此我们只需将objective()

函数传

给study.optimize()以创建研究，如下所示

：

学习完成后，我们得到如

下最佳参数：

我们可以看

到，通过1000次实验，Optuna已经成功

找到了与全局最小

值相

当接近的x和y值。要在Hugging Face

Transformers中使

用

Optuna，我们首先需定义将要

优化的超参数空间。除了

α和T之外，我

们还将包括训

练时期的数量：

使用Trainer运行

超参数搜索非常简单，我

们只需要指定要运行的

实验

数量和要优化的方

向。因为我们希望获得最

佳的准确率，所以我们在

训练器的hyperparameter_search()方法中指定

direction="maximize"，并

将超参数搜索空间按如

下传递：

hyperparameter search()方法返回一个BestRun对

象，该对象包含所

最大化

的目标的值（默认为所有

指标的总和）和它用于该

运行的超参

数：

这个α值告

诉我们，大部分的训练信

号都来自知识蒸馏项。让

我们使

用这些值更新我

们的训练参数，并运行最

后的训练：

非常惊人的是

，虽然学生模型的参数数

量几乎是教师模型的一

半，但

我们已经成功地训

练出学生模型，使其准确

率与教师模型相当！我们

把这个模型推到库中供

未来使用：

8.3.6

基准测试蒸馏

模型

现在我们有了一个

准确的学生模型，让我们

创建一个pipeline，重新

进行基准

测试，看看它在测试集上

的表现如何：

为了将这些

结果放入上下文中，我们

使用plot_metrics()函数可视化

它们：

正

如预期的那样，与DistilBERT基准相

比，模型的大小和延迟基

本保

持不变，但准确率得

到了改善，甚至超过了教

师模型！这个结果出人

意

料，很有可能是因为教师

模型没有像学生模型那

样系统地进行微

调。这很

棒，但实际上我们还可以

使用一种称为量化的技

术进一步压

缩我们的蒸

馏模型。

8.4

利用量化技术使

模型运算更快

我们现在

看到，通过知识蒸馏，我们

可以将来自教师模型的

信息迁移

到较小的学生

模型中，从而降低运行推

理所需的计算和内存成

本。量

化采用了一种不同

的方法，它并不是减少计

算量，而是通过使用低精

度数据类型[例如8位整数

（INT8）]来表示权重和激活，而不

是通常的

32位浮点数（FP32），从而

使计算更有效率。减少位

数意味着结果模

型需要

更少的内存存储，并且像

矩阵乘法这样的操作可

以使用整数算

术更快地

执行。值得注意的是，这些

性能提升可以在几乎不

损失准确

率的情况下实

现！

浮点数和定点数基础

介绍

目前大多数Transformer模型都

是使用浮点数（通常是FP32或

FP16与

FP32的组合）进行预训练和

微调的，因为它们提供了

适合非常不同范

围的权

重、激活和梯度的精度。像

FP32这样的浮点数表示为32位

的序

列，这些位以符号、指

数和有效数字的形式组

成。符号确定数字是正

的

还是负的，而有效数字则

对应于数量级，通过某个

固定基数（通常

是二进制

或十进制）中的指数进行

缩放。

例如，数字137.035可以通过

以下算术运算表达为一

个十进制浮点数：

137.035=（-1）0×1.370 35×102

其中1.37035是

尾数，10的指数是2。通过指数

，我们可以表示广泛的

实

数，并且小数或二进制点

可以相对于有效数字放

置在任何位置（因

此称为

“浮点数”）。

然而，当模型训练

完成之后，我们只需要运

行前向传递来进行推理

，

因此我们可以降低数据

类型的精度，而不会对准

确率产生太大影响。

对于

神经网络，我们通常使用

定点格式表示低精度数

据类型，其中实

数表示为

B位整数，它们由相同类型

的所有变量共同缩放。例

如，

137.035可以表示为整数137 035，该整

数缩放了1/1000。我们可以通

过

调整缩放因子来控制定

点数的范围和查准率。

量

化的基本思想是将每个

张量中的浮点值f“离散化

”，通过从范围

[f，f]映射到一个

更小的范围[q，q]，然后在该范

围线性分布所有

值。从数

学上讲，这种映射可以用

以下方程式描述：

maxminmaxmin

仿射映

射只是神经网络的线性

层中你熟悉的y=Ax+b映射的高

级叫法。

其中缩放因子S是

一个正浮点数，常数Z与q类

型相同，并称为零点，因

为

它对应于浮点值f=0的量化

值。请注意，映射需要是仿

射的

（affine），这样当我们将定点

解量化为浮点时，就可以

得到浮点数

。转换过程参

见图8-6。

图8-6：将浮点数量化为

无符号8位整数（由Manas Sahni提供）

现

在，Transformer（更普遍的包括深度神

经网络）主要使用量化调

优

的一个主要原因是权

重和激活函数通常取值

于相对较小的范围内。这

意味着我们不需要将所

有可能的FP32数字的范围压

缩到INT8表示的

2

8=256个数字的范

围内。为了说明这一点，我

们从蒸馏模型中选出一

个注意力权重矩阵，然后

绘制其值的频率分布：

正

如我们所看到的，权重的

值在接近于零的较小区

间[-0.1，0.1]内分

布。假设我们要将

此张量量化为有符号的

8位整数。在这种情况下，我

们整数的可能值范围是

[q，q]=[-128，127]。零点与FP32的零点重

合，并根

据先前的公式计算比例

因子：

maxmin

为了获得量化张量

，我们只需反转映射q=f/S+Z，将值

夹紧，将它们四

舍五入到

最近的整数，并使用Tensor.char()函数

将结果表示为

torch.int8数据类型

：

我们刚刚量化了第一个

张量。在PyTorch中，我们可以使用

quantize_per_tensor()函数和一个用于优化整

数算术操作的量化数据

类型torch.qint来简化转换过程：

图

8-7非常清楚地表明了通过

仅将某些权重值精确映

射并舍入其余部分

所引

发的离散化。

图8-7：量化对Transformer权

重的影响

现在为了完善

我们的分析，我们比较一

下使用FP32和INT8值计算两个

权

重张量的乘积的时间。对

于FP32张量，我们可以使用PyTorch的

简便

@操作符进行乘法计

算：

对于量化张量，我们需

要使用QFunctional包装器类，以便我

们可以使

用特殊的torch.qint8数据

类型执行操作：

这个类支

持各种基本的操作，比如

加法，在我们的例子中，我

们可以

通过以下方式对

我们量化张量的乘法进

行计时：

与我们的FP32计算相

比，使用INT8张量的速度快了

近100倍！通过使用

专用后端

有效地运行量化运算符

，可以获得更大的收益。截

至本书撰

写时，PyTorch支持：

●需要

支持AVX2或更高版本的x86 CPU。

●ARM CPU（通常

用于移动设备/嵌入式设

备）

由于INT8数字位数是FP32数字

位数的四分之一，量化还

将内存存储要

求降低为

FP32的四分之一。在我们的简

单示例中，我们可以通过

使用

Tensor.storage()函数和Python的sys模块中的

getsizeof()函数比较

权重张量及其

量化版本的底层存储大

小来验证这一点：

对于一

个完整的Transformer模型，在实际压

缩比方面，取决于哪些层

被量化（正如我们将在8.5节

中看到的，通常只有线性

层被量化）。

那么，量化会存

在什么问题？将我们模型

中所有计算的精度进行

更改

会在模型的计算图

中的每个点引入小的扰

动，这些扰动可能会被累

积

并影响模型的性能。有

几种方法可以对模型进

行量化，它们都有各自

的

优点和缺点。对于深度神

经网络，通常有三种主要

的量化方法：

动态量化

当

使用动态量化时，在训练

期间不会发生任何更改

，只有在推理过程

中才进

行调整。与我们将讨论的

所有量化方法一样，在推

理时间之

前，模型的权重

被转换为INT8。除了权重之外

，模型的激活还被量

化。这

种方法是动态的，因为量

化是即时进行的。这意味

着所有矩阵

乘法都可以

使用高度优化的INT8函数计

算。在所有讨论的量化方

法

中，动态量化是最简单

的方法。但是，在使用动态

量化时，激活会以

浮点格

式写入和读取到内存中

。整数和浮点数之间的转

换可能成为性

能瓶颈。

静

态量化

与实时计算激活

的量化不同，我们可以通

过预先计算量化方案来

避免

将其转换为浮点数

。静态量化通过在推理时

间之前观察代表性数据

样

本上的激活模式来实

现这一点。我们先计算好

理想的量化方案，然后

保

存它。这使我们能够跳过

INT8和FP32值之间的转换，以加速

计算。

但是，它需要访问良

好的数据样本，并在整个

流程中引入额外的步

骤

，因为现在我们需要在执

行推理之前训练并确定

量化方案。此外，

静态量化

并未能解决这样一个方

面：训练和推理期间查准

率之间的差

异，这会导致

模型的指标（例如准确率

）下降。

量化感知训练

在训

练期间，通过对FP32值进行“伪

”量化，可以有效地模拟量

化的

影响。在训练过程中

，不使用INT8值，而是将FP32值舍入

，以模仿量

化的效果。这是

在前向和后向传递期间

完成的，并且在模型指标

方面

的性能优于静态量

化和动态量化。

使用Transformer模型

进行推理的主要瓶颈是

这些模型中巨大数量的

权

重相关的计算量和内

存带宽。因此，动态量化目

前是自然语言处理中

基

于Transformer的模型的最佳方法。在

较小的计算机视觉模型

中，限

制因素是激活的内

存带宽，这就是为什么通

常使用静态量化（或在性

能下降太显著的情况下

使用量化感知训练）。

在PyTorch中

实现动态量化非常简单

，只需要一行代码即可完

成：

在这里，我们将完整精

度的模型传给quantize_dynamic()，并指定我

们要对其中量化的PyTorch层类

集。dtype参数指定目标精度，可

以是

fp16或qint8。一个好的做法是

选择你可以容忍的最低

精度，以实现评

估指标。在

本章中，我们将使用INT8，并且

很快就会看到它对模型

的

准确性几乎没有影响

。

8.5

基准测试量化模型

现在

我们的模型已经完成了

量化，让我们将其传递到

基准测试中并可

视化结

果：

不错，量化模型几乎是

蒸馏模型的一半大小，并

且甚至获得了轻微的

准

确率提升！我们看看能否

利用一个强大的框架——ONNX Runtime将

我们的优化推到极限。

8.6

使

用ONNX和ONNX

Runtime进行推理优化

有一

个名为ONNX-ML的专门标准，旨在

为传统的机器学习模型

（例如随

机森林）和框架（例

如Scikit-learn）提供支持。

ONNX（https://onnx.ai）是一种开放

标准，定义了一组共同的

运算符

和共同的文件格

式，以在各种框架中表示

深度学习模型，包括PyTorch

和TensorFlow

。当

将模型导出为ONNX格式时，这

些运算符用于构建

计算

图（通常称为中间表示），表

示数据通过神经网络的

流程。图8-8

是一个BERT-base模型的示

意图，其中每个节点接收

一些输入，应用像

Add或Squeeze这样

的操作，然后将输出馈送

给下一组节点。

图8-8：BERT-base模型ONNX图

的一部分（通过Netron可视化）

通

过使用标准化的运算符

和数据类型公开图形，ONNX使

得在不同框架

之间进行

切换变得容易。例如，可以

将在PyTorch中训练的模型导出

为

ONNX格式，然后在TensorFlow中导入（反

之亦然）。

其他流行的加速

器包括NVIDIA的TensorRT

（https://oreil.ly/HnNZx）和Apache TVM

（https://oreil.ly/7KUyt）。

融合操作是

指将一个运算符（通常是

激活函数）合并到另一个

运算符

中，以便它们可以

一起执行。例如，假设我们

想要对矩阵积A×B应用

激活

函数f。通常需要将积的结

果写回GPU内存，然后再计算

激活函

数。运算符融合允

许我们在单个步骤中计

算f（A×B）。常量折叠指的

是在编

译时评估常量表达式，而

不是在运行时。

ONNX的真正优

势在于与专用加速器（如

ONNX

Runtime或简称ORT）的

结合使用 。ORT通过

诸如运算符融合和常量

折叠等技术提供了优化

ONNX图形的工具 ，并定义了执

行提供程序的接口，使你

能够在不同

类型的硬件

上运行模型。这是一个强

大的抽象。图8-9展示了ONNX和

ORT生

态系统的高级架构。

图8-9：ONNX和

ONNX Runtime生态系统的架构（由ONNX Runtime团

队

提供）

要看到ORT的实际效果

，我们需要将我们的蒸馏

模型转换为ONNX格式。

Hugging

Face Transformers库内置

一个名为

convert_graph_to_onnx.convert()的函数，它通过

以下步骤简化了该

过程

：

1.将模型初始化为Pipeline。

2.通过管

道运行占位符输入，以便

ONNX可以记录计算图。

3.定义动

态轴以处理动态序列长

度。

4.使用网络参数保存图

形。

要使用这个功能，我们

首先需要为ONNX设置一些OpenMP

（https://openmp.org）环

境变量：

OpenMP是一个为开发高

度并行化应用程序而设

计的API。

OMP

NUM THREADS环境变量设置了在

ONNX Runtime中用于并行计算

的线程

数，而OMP_WAIT_POLICY=ACTIVE指定等待线程应处

于活动状态

（即使用CPU处理

器周期）。

接下来，我们将蒸

馏模型转换为ONNX格式。这里

，我们需要指定

convert()函数的参

数pipeline_name="text-classification"，以及

model_ckpt参数和tokenizer参数来初

始化pipeline。

这里的参数opset=12用于指

定ONNX运算符集的版本（ONNX使用

运算符

集来将不可变运

算符规范分组）。

现在我们

已经保存了模型，我们需

要创建一个InferenceSession实例

来将输

入输送进模型中：

现在当

我们调用onnx model.run()方法时，我们可

以从ONNX模型中获

取类logit。我们

用测试集中的一个样本

来测试一下这个方法。由

于

convert()方法的输出告诉我们

ONNX模型只需要输入input_ids和

attention_mask，我们

需要从样本中删除label列：

在

我们有了logit之后，我们可以

通过取最大值来轻松地

获得预测标

注：

这确实与

基准标注相符：

ONNX模型与text-classification pipeline不

兼容，因此我们将创建

自

己的类，模拟其核心行为

：

我们可以用这个方法测

试我们的简单查询，看看

我们是否正确识别了

car_rental的

意图：

我们的pipeline按照预期运

作。下一步是为ONNX模型创建

性能基准。

在这里，我们可

以重用PerformanceBenchmark类的工作，只需要

重写

compute_size()方法并保留compute_accuracy()和time_pipeline()方

法

。我们需要重写compute_size()方法的原

因是我们不能依赖于

state_dict和

torch.save()来度量模型的大小，因为

onnx_model技术

上是一个ONNX InferenceSession对象，没有

访问

PyTorch nn.Module属性的权限。无论如

何，其逻辑很简单，具体实

现如下：

有了我们的新基

准测试，让我们看看将蒸

馏模型转换为ONNX格式后的

性能如何：

令人惊讶的是

，将蒸馏模型转换为ONNX格式

并使用ONNX

Runtime使蒸

馏模型（上图

中的“Distillation”圆）的延迟得到了提

升！让我们

看看是否可以

通过添加量化来获得更

多性能。

与PyTorch类似，ORT提供了三

种量化模型的方法：动态

、静态和量化

感知训练。就

像我们在PyTorch中所做的那样

，我们将对我们的蒸馏模

型应用动态量化。在ORT中，量

化是通过quantize_dynamic()函数应用

的，该

函数需要量化ONNX模型的一

个路径、一个保存量化模

型的目标

路径，以及将权

重减少的数据类型：

现在

模型已经量化了，我们将

其传递到基准测试中：

与

从PyTorch量化获得的模型（上图

中的

“distillation+quantization”阴影圆）相比，ORT量化将

模型大小

和延迟都减少

了约30%。其中一个原因是PyTorch仅

优化nn.Linear模

块，而ONNX还量化了嵌

入层。从图中我们还可以

看到，将ORT量化应用

于我们

的蒸馏模型与我们的BERT基

线相比，提供了近三倍的

增益！

至此我们对Transformer模型推

理进行加速技术的分析

就结束了。我们

已经看到

，可以通过量化等方法来

降低表示的精度来减小

模型大小。

还有一种减小

大小的策略是完全删除

某些权重。这种技术称为

权重剪

枝，这就是8.7节的重

点。

8.7

使用权重剪枝使模型

更稀疏

到目前为止，我们

已经看到知识蒸馏和权

重量化非常有效，可以生

成

更快的推理模型，但在

某些情况下可能还有对

模型内存占用的严格限

制。例如，如果我们的产品

经理突然决定将我们的

聊天机器人部署到

移动

设备上，那么我们需要尽

可能地减少意图分类器

所占的存储空

间。我们看

看如何通过识别和删除

神经网络中最不重要的

权重来减少

模型参数的

数量。

8.7.1

深度神经网络中的

稀疏性

如图8-10所示，剪枝的

主要思想是在训练过程

中逐渐删除权重连接

（可

能还包括神经元），使得模

型逐渐变得更加稀疏。由

此得到的剪

枝模型具有

更少的非零参数，可以以

紧凑的稀疏矩阵格式存

储。剪枝

也可以与量化结

合使用以获得进一步的

压缩效果。

8.7.2

权重剪枝方法

从数学上讲，大多数权重

剪枝方法的工作方式是

计算一个重要性分数

矩

阵S，然后根据重要性选择

前k%的权重：

图8-10：剪枝前后的

权重和神经元（由Song Han提供）

实

际上，k是一个新的超参数

，用于控制模型中稀疏性

的程度，即零值

权重的比

例。k值越低，对应的矩阵越

稀疏。我们可以根据这些

分数定

义一个掩码矩阵

M，在前向传递过程中对某

些输入xi进行Wij权重掩码，

从

而有效地创建激活ai的稀

疏网络：

B. Hassibi and

D. Stork，“Second Order Derivatives for

Network

Pruning:Optimal Brain Surgeon，”Proceedings of the

5th

International Conference on Neural Information Processing

Systems（November 1992）: 164-171，

https://papers.nips.cc/paper/1992/hash/303ed4c69846ab36c2904d

3ba8573050-Abstract.html.

正如“Optimal

Brain Surgeon”论文 中所讨

论的那样，每种剪枝

方法

都有一系列需要考虑的

问题：

●哪些权重应该被消

除？

●剩余的权重应该如何

调整以获得最佳性能？

●如

何以计算效率高的方式

进行网络剪枝？

这些问题

的答案决定了得分矩阵

S的计算方式，因此让我们

首先看一下

最早和最流

行的剪枝方法之一：幅值

剪枝。

幅值剪枝

S. Han

et al., “Learning Both Weights and

Connections for

Efficient Neural Networks”

（https://arxiv.org/abs/1506.02626），（2015）.

正如其名

称所示，幅值剪枝（magnitude pruning）根据权

重幅度计

算分数，S=（|W|）1，然后从

M=Topk（S）得出掩码。在文献中，通常

先训练模型学习哪些连

接是重要的，然后剪枝最

不重要的权重 ，最

后重新

训练稀疏模型并重复该

过程直到达到所需的稀

疏度。

ij≤j,j≤n

这种方法的一个缺

点是计算成本高：在每个

剪枝步骤中，我们需要将

模型训练到收敛。因此，通

常最好逐步增加初始稀

疏度si（通常为

零）到某个步

数N后的最终值sf：

M. Zhu and S.

Gupta, “To Prune, or Not to

Prune: Exploring

the Efficacy of Pruning

for Model Compression”

（https://arxiv.org/abs/1710.01878）, （2017）.

我们这里

的思路是每隔Δt步更新二

进制掩码M，以允许掩码权

重在训

练过程中重新激

活并恢复可能由剪枝过

程引入的准确率损失。如

图8-

11所示，立方因子意味着

在早期阶段（冗余权重数

量较多时）权重剪

枝率最

高，并逐渐减少。

图8-11：用于剪

枝的立方稀疏度调度器

V. Sanh, T.

Wolf, and A.M. Rush, “Movement Pruning:Adaptive

Sparsity by Fine-Tuning”

（https://arxiv.org/abs/2005.07683）, （2020）.

其中一个使用幅度剪枝

的问题是，它真正是为纯

监督学习设计的，其

中每

个权重的重要性与手头

的任务直接相关。相比之

下，在迁移学习

中，权重的

重要性主要由预训练阶

段决定，因此幅度剪枝可

能会删除

对微调任务很

重要的连接。最近，Hugging Face研究人

员提出了一种

自适应方

法，称为运动剪枝，我们来

看看 。

运动剪枝

运动剪枝

（movement pruning）的基本思想是在微调过

程中逐渐移除

权重，使得

模型变得更加稀疏。关键

的新颖之处是模型在微

调过程中

同时学习了权

重和分数。因此，不像幅度

剪枝那样直接从权重中

派生

分数，运动剪枝中的

分数是任意的，并且可以

通过梯度下降学习，就

像

神经网络中的其他任何

参数一样。这意味着在反

向传递过程中，我

们也会

跟踪损失函数L相对于分

数Sij的梯度。

还有一个“软”版

本的运动剪枝，它不是选

择权重的前k%，而是使用

全

局阈值τ定义二进制掩码

：M=（S＞τ）。

一旦得到分数，使用M=Topk（S）二进

制掩码生成就相对简单

了 。

运动剪枝的直觉是，最

重要的是保留那些从头

开始变化最多的权重。

换

句话说，在微调过程中正

权重增加（负权重减少），这

相当于说，

随着权重远离

零，分数增加。如图8-12所示，这

种行为与幅值剪枝不

同

，后者选择距离零最远的

权重作为最重要的权重

。

图8-12：剪枝技术所移除权重

的比较（左：幅值剪枝，右：运

动剪

枝）

这两种剪枝方法

之间的差异在剩余权重

的分布中也是明显的。如

图8-

13所示，大小剪枝产生了

两个权重簇，而移动剪枝

产生了一个更平滑

的分

布。

在本书编写时，Hugging Face Transformers库还没

有开箱即用的剪

枝方法

。幸运的是，有一个名为Neural Networks Block Movement

（https://oreil.ly/aHEvD）的

很不错的库实现了本书

许多这些思

想，所以在你

的场景里面，如果有内存

方面的限制，我们建议你

看看

这个库。

图8-13：稀疏化剩

余权重的分布情况，包括

幅值剪枝（MaP）和运动

剪枝（MvP）

8.8

本

章小结

我们已经看到，将

Transformer模型优化为在生产环境

中部署涉及沿着

两个维

度进行压缩：延迟和内存

占用。从微调模型开始，我

们应用蒸

馏、量化和通过

ORT进行优化，显著减少了这

两个方面的占用。特别

是

，我们发现ORT中的量化和转

换在最小的工作量下获

得了最大的收

益。

尽管剪

枝是减小Transformer模型存储大小

的有效策略，但当前的硬

件

并未针对稀疏矩阵操

作进行优化，这限制了这

种技术的实用性。然

而，这

是一个活跃的研究领域

，当本书出版时，许多这方

面的局限性

可能已经得

到解决。

那么接下来要做

什么呢？本章介绍的所有

技术都可以应用于其他

任

务，比如问答、命名实体

识别或语言建模。如果你

发现自己在满足延

迟要

求或模型消耗计算资源

方面遇到困难，我们建议

尝试其中之一。

在第9章中

，我们将告别性能优化话

题，探讨每个数据科学家

最担心的

场景：标注数据

不足。

第9章

零样本学习和

少样本学习

在每一个算

法专家的脑海中都有一

个根深蒂固的观念，那就

是在每个

新项目开始的

时候都会面临一个问题

：有多少标注数据？大多数

时候

面临的情况是“没有

”或者是“很少”，但是需求方

可不关心这个，

模型必须

具备符合预期的效果。而

现实是，在小型数据集上

训练出的

模型通常不会

有很好的效果，最有成效

的解决方案是标注更多

的数据

提供给模型进行

训练。然而，数据标注的过

程需要耗费很多的人力

物

力，尤其是那种需要具

备专业知识才能进行标

注的数据。

幸运的是，对于

这种标注数据短缺的情

况，业界已经有了一些解

决方

案。你可能已经对其

中的某些方法有所耳闻

，比如零样本学习（zero￾shot

learning）或少样

本学习（few-shot learning），而GPT-3模

型甚至可以

仅用几十个样本就能处

理各种不同的任务，让人

感到非常

惊奇。

一般来说

，模型的最优效果取决于

任务、可用数据，以及可用

数据被

标注的比例。图9-1所

示的结构能一定程度上

帮助我们选择最恰当的

方

法。

按步骤对图中结构

做如下说明：

1.是否有标注

数据？

我们需要明白，即使

拥有少量的标注数据也

可以为模型带来正向收

益。如果根本没有标注数

据，则可以用零样本学习

方法，这通常会设

置一个

较高的基线指标。

2.有多少

标注数据？

如果拥有标注

数据，那么决定模型性能

的因素就是标注数据所

占的比

例。如果有大量的

标注数据用于模型训练

，就可以使用第2章介绍的

标

准微调方法来进行处

理。

3.是否有未标注的原始

数据？

Q. Xie

et al., “Unsupervised Data Augmentation for

Consistency Training”（https://arxiv.org/abs/1904.12848），

（2019）； S. Mukherjee and

A.H. Awadallah，“Uncertainty-

Aware Self-Training for Few-Shot

Text Classification”

（https://arxiv.org/abs/2006.15315），（2020）.

如果只有少量的标

注数据，但是还有大量未

标注的原始数据，则这对

于模型训练也是很有帮

助的。假如能获得这样的

未标注数据，就能在

训练

分类器（Classfier）之前用它来微调

模型，或者使用更复杂的

方

法，如无监督数据增强

（Unsupervised

Data Augmentation，UDA）

或不确定性自我训练（Uncertainty-aware Self-Training，UST）

。如

果没有这样的未标注数

据，也就无法去标注更多

的数据，在这种

情况下，就

需要使用少样本学习技

术，或者使用预训练语言

模型的嵌

入，通过最近邻

搜索（nearest neighbor search），来对目标进行

分类

。

本章将基于图9-1的思路来

帮助我们在使用Jira

（https://oreil.ly/TVqZQ）或GitHub（https://oreil.ly/e0Bd1）

的时

候，根据issue的描述自动为其

打上标注。这些标注包括

issue类

型、导致issue的组件名称，或

者负责issue的团队。将这种打

标注的

任务进行自动化

处理，会对生产力产生很

大的影响，因为这样就可

以

让项目的维护团队能

够专注于解决用户提出

的问题，而不是将时间浪

费在对问题的分类上面

。本章以Hugging Face在GitHub上的

Transformers代码仓库

为例，带领大家分析此代

码仓库中的issue，学

习如何构

建此类任务，以及如何获

取数据。

图9-1：在缺少大量标

注数据的情况下，可用于

提高模型性能的几种

技

术

本章介绍的方法适用

于文本分类场景，但在处

理命名实体识别任务、

问

答任务或文本摘要生成

任务这些更复杂的任务

时，则可能需要其他

技术

的加持，比如数据增强。

9.1

构

建GitHub issue标记任务

进入Transformers代码仓

库的issue模块

（https://oreil.ly/StdH3），点击其中一个

issue，就会得到如图9-

2所示的页

面，该页面包含一个标题

、一段描述和一组标注集

合。因

此，该任务可以看作

给定标题和描述，预测一

个或多个标注，是一个

典

型的多标注文本分类任

务。这比第2章中遇到的多

分类问题更具有挑

战性

，因为在第2章中，每条推文

只会被标注一种情感。

图

9-2：Hugging Face Transformers代码仓库中某个

GitHub issue的详细

展示页面

在了解了GitHub issue的常

见形式后，下面我们看看

如何下载它们来

构建数

据集。

9.1.1

获取数据

为了获取

代码仓库中的所有issue信息

，我们将使用GitHub提供的

REST API（https://oreil.ly/q605k）来轮

询issues端点

（https://oreil.ly/qXdWV）。这个端点会返回

一个JSON对象列表，

每个对象

都包含大量关于当前issue的

字段，包括该issue的状态（打

开

或关闭）、issue的发起者，以及在

图9-2中可以看到的标题、正

文

和标注。

由于获取所有

issue信息需要耗费一些时间

，本书的GitHub代码仓库

（https://oreil.ly/if2dm）中提供

了一个github-issues￾transformers.jsonl文件，以及一个fetch_issues()函

数，你可以自

行下载它们

。

GitHub

REST API会将pull请求也加入issue当中，因

此我们的数据

集里面混

合了原始issue和pull请求issue。为了不

让任务变得复杂，

我们将

为这两种类型的issue开发分

类器。其实在实践中，我们

也很可

能会构建两个分

类器，因为这样方便对模

型的性能进行更精细的

控

制。

现在我们知道了如

何获取目标数据，下面来

看看如何处理这些数据

。

9.1.2

准备数据

当我们下载好

了所有的issue，就可以使用Pandas来

加载它们：

结果显示，在数

据集中有近10 000个issue，查看单行

数据，我们可

以看到其中

包含的许多字段，如URL、ID、日期

、用户、标题、正文以

及标注

：

其中的labels列就是标注数据

，它包含了一个JSON对象列表

，示例如

下：

每个JSON对象都包

含一个标注的信息，这里

我们需要的信息是标注

的

名称，也就是其中的name字

段，下面将标注名称提取

出来覆盖labels

列的内容：

现在

，labels列中的每行都是GitHub的标注

名称列表，这样就能得出

issue的标注数量分布情况：

可

以看出，大多数issue都有0或1个

标注，有1个以上标注的issue则

少

得多。下面我们来看看

数据集中最频繁出现的

10个标注。在Pandas

中，可以通过explode()函

数来展开Labels列，这样列表中

的每个标注

会成为行，然

后简单计算每个标注出

现的次数：

从结果可以看

出，数据集中有65种标注，这

些标注数量差异很大，分

布非常不均匀。其中“wontfix”和“model card”是

最频繁出现的

标注。有些

标注很难通过标题来推

测，比如“Good First Issue”

或“Help

Wanted”；有些标注可以

基于规则来判断，比如

“model card”，就

可以根据仓库是否添加

模型卡片来确定。所以，

能

够用于预测的标注只是

标注集的一个子集，要把

不需要预测的标注

去除

掉。

以下代码段对数据集

进行过滤，以获得我们要

处理的标注子集，同时

对

标注名称进行规范化处

理，使其更易阅读：

现在我

们来看看新标注的分布

情况：

在本章后面的内容

中，我们会发现，未打标注

的issue在训练过程中可

以当

作单独的分片来处理。所

以这里我们创建一个新

的列，来表示该

issue是否打了

标注：

下面来看一个例子

：

在该例子中，我们提出了

一种新的模型架构，因此

new model的添加

对于该模型是有

意义的。还可以看出，title包含

了对分类器有用的信

息

，所以可以把它和body字段中

的issue描述拼接起来：

在查看

其他数据之前，先检查一

下数据中是否有重复的

地方，如果

有，则使用drop_duplicates()方法

将它们去重：

从去重结果

中可以获知，在我们的数

据集中有一些重复的issue，但

只

占很小的比例（1.88%）。下面我

们先查看文本的单词数

量，再按照模

型的上下文

大小将其截断，看看是否

会丢失信息：

以上分布结

果符合大多数文本数据

集的长尾特征，因为大多

数issue都

较短，很少有超过500个

单词的issue。有超过500个单词的

长issue也

是很常见的，特别是

当错误消息和代码片段

合并到一起发布成为issue

时

。鉴于大多数Transformer模型的上下

文大小为512个词元或更多

，

截断少数的长issue也不会对

整体性能有什么大的影

响。现在我们已经

探索和

清洗了我们的数据集，在

这之后要做的是创建训

练集和验证

集，以便为我

们的分类器设定基准指

标。下面来看看如何实现

。

9.1.3

创建训练集

对于多标注

任务来说，创建训练集和

验证集相对麻烦，因为无

法保证

所有标注在两个

数据集分布情况一致。我

们可以做一些近似操作

，使

用Scikit-multilearn库（http://scikit.ml）的

MultiLabelBinarizer类将标注转换

为独热编码形式。先传入

一个标注

名称列表，并创

建一个向量，其中的0代表

没有的标注，1代表有的标

注。下面我们将all_labels传给MultiLabelBinarizer进行

拟合，来看

看标注名称与

ID的映射关系，如下所示：

在

这个简单例子中，我们可

以看到第一行有两个1分

别对应于

tokenization和new model的标注，而第

二行只有一个1对应于

pytorch。

然

后使用Scikit-multilearn的iterative_train_test_split()函数将

数据拆

分为训练集和测试集。由

于我们采用迭代式生成

训练样本和测

试样本，因

此这个函数可以保证生

成的训练集和测试集中

的标注分布

是一致的。我

们把它封装成一个可以

应用于DataFrames的函数，由于

该函

数期望有一个二维特征

矩阵，我们需要在进行拆

分之前给可能的

索引增

加一个维度：

定义好了balanced_split()函

数，我们可以把数据拆分

成监督和无监

督部分组

成的数据集，然后为监督

部分创建标注分布一致

的训练、验

证和测试集：

接

着，将它们转为DatasetDict格式，这样

就能轻松对数据集进行

词元

化，并与Trainer整合，方便训

练。这里，我们将使用from_pandas()

方法

，直接从相应的Pandas DataFrame中加载每

个拆分部分：

最后，创建一

些训练切片，以便评估每

个分类器的性能与训练

集大小

的关系。

9.1.4

创建训练

切片

该数据集具有两个

我们在本章要研究的特

性：稀疏标注数据和多标

注

分类。训练集中只有220个

可供训练的样本，即使是

迁移学习，这也是

一个挑

战。为了深入研究模型在

小标注数据量上的效果

，我们还将会

创建样本更

少的训练数据切片。然后

将样本的数量与性能做

比较，研

究模型在不同数

据量下的效果。我们将从

每个标记只有8个样本开

始，

使用iterative_train_test_split()函数创建有不同

样本的数据集，

直到覆盖

全部训练集：

注意，这种迭

代方法只是将样本近似

拆分成所需大小，因为如

果严格

指定大小，并不一

定能找到标注分布一致

的数据集分片：

我们将使

用特定的数据集分片大

小作为后文图表的刻度

。到这里，我

们准备好了用

于训练的数据集分片，接

下来看看如何训练一个

强大的

基线模型。

9.2

基线模

型

——朴素贝叶斯

每当开启

一个新的NLP项目时，创建一

个强大的基线模型是很

有必要

的，主要有两个原

因：

1.如果能够使用正则表

达式，或借助一个非常简

单的模型就能解决实

际

问题，那么就没有必要使

用更复杂的模型，因为其

带来的提升也会

非常有

限，而且像Transformer这样的模型的

部署和维护通常也比较

复

杂。

2.基线模型可以给复

杂模型提供快速对比的

参考依据。例如，假设你

训

练了一个BERT-large模型，并在验证

集仅获得了80%的准确率，你

很

可能会认为这是验证

集而不是模型的问题。在

这之后，当你知道像逻

辑

回归这样的简单分类器

也能得到95%的准确率时，你

就会转变思路，

认为验证

集是没有问题的，而是模

型出了问题，然后你就可

能会去一

遍遍地调试你

的模型。

因此，训练一个不

错的基线模型是很有必

要的。对于文本分类这样

的

任务来说，朴素贝叶斯

分类器（Naive Bayes classifier）是最基

础的分类

模型之一，它非常简单，能

够快速训练，并有一定的

稳健

性。朴素贝叶斯的Scikit-learn实

现并不具备开箱即用的

多标注分类

能力，不过我

们可以使用Scikit-multilearn库将多标注

分类转换为对

每个标注

的二分类问题，为L标注训

练L个二进制分类器。首先

使用

MultiLabelBinarizer在我们的训练集中

创建一个新的label_ids列，

再使用

map()函数来一次性解决所有

处理步骤：

为了评估分类

器的性能，这里使用微观

和宏观的F1分数，其中前者

跟

踪出现较频繁的标注

上的性能，后者跟踪不考

虑频率的所有标注上的

性能。由于我们将在不同

大小的训练分片中评估

每个模型，因此我们

将创

建一个defaultdict，用一个列表来保

存每个训练分片的分数

：

到这一步，训练基线模型

的准备工作已经就绪，下

面是训练基线模型

的代

码，在训练集规模持续增

加的情况下评估分类器

性能：

上面是一段较长的

代码片段，这其中进行了

许多操作，我们来一探究

竟。首先，我们获取训练切

片并对标注进行编码。然

后，我们使用

CountVectorizer对文本进行

编码，简单地创建一个与

词表大小相关的

向量，其

中每个条目对应于文本

中某一个词元出现的频

率。这种方式

被称为词袋

（bag-of-words），因为所有词汇的顺序信

息都会丢失。

最后，我们训

练分类器，并在测试集上

使用预测结果，通过分类

报告

获得微观和宏观的

F1分数。

使用下面的辅助函

数，可以绘制这个实验的

结果：

注意，这里将样本的

数量绘制在对数坐标轴

刻度之上。从结果图中可

以看出，随着训练样本数

量的增加，微观和宏观F1分

数都有所升高。

但可用于

训练的样本太少，结果包

含许多噪声，因为每个切

片都可能

有不同类别的

分布。尽管如此，我们只需

要得到这个结果的趋势

即

可。下面我们看看这些

结果与基于Transformer的模型相比

效果如何。

9.3

零样本学习

这

里我们第一个考虑的技

术是零样本分类技术，它

完全适合没有标注

数据

的场景。无标注数据在业

界非常普遍，可能是因为

历史数据无标

注，也可能

是因为获取数据的标注

很困难。在本节中，我们可

能欺骗

模型，因为我们仍

然会使用测试数据来度

量性能，但是我们不会使

用

任何数据来训练模型

（否则与以下介绍的方法

相比较会很困难）。

零样本

分类的目标是使用预训

练模型，不需要对你的特

定任务的语料

做附加的

微调操作。为了更好地理

解这一点，回想一下，BERT这样

的

语言模型也是经过预

训练的，用以预测数千本

书和维基百科大型转储

文本中的掩码词元。为了

成功预测一个缺失词元

，该模型需要意识到

上下

文中的主题。可以尝试通

过提供下面的这样的句

子来欺骗模型为

我们做

文档分类：

感谢Joe Davison（https://joeddav.github.io）为我们介

绍了这个

方法。

模型会为

该文档的主题给出一个

合理的建议，因为这是一

个在数据集

中出现的自

然文本 。

下面用一个关于

生活中常见的问题来进

一步说明。假设你有两个

孩

子，一个喜欢有汽车的

电影，而另一个更喜欢有

动物的电影。不幸的

是，他

们已经看过了你知道的

所有电影，现在你想创建

一个函数来告

诉你他们

想看的新电影是关于什

么主题的。你会很自然地

借助

Transformer来完成这项任务。首

先要做的事情是将BERT-base加载

到

fill-mask pipeline中，该pipeline使用掩码语言模

型来预测掩码词

元的内

容：

接下来，创建电影的描

述，并在其中为掩码词元

添加一个提示。这个

提示

的目的是引导模型来为

我们做分类操作。fill-mask

pipeline会

返回

最可能的词元来填充在

掩码词的地方：

很显然，该

模型只预测了与动物有

关的词元。我们也可以调

转一下思

路，向pipeline查询几个

给定词元的概率，而不是

获得最可能的词

元。对于

这个任务，我们可能会选

择汽车（cars）和动物

（animals），所以我们

将它们作为目标传给pipeline：

结

果不出所料，对汽车词元

的预测概率要比动物词

元的预测概率小得

多。让

我们看看这是否也适用

于更接近汽车的描述：

这

非常奏效！以上仅是一个

非常简单的例子，如果我

们想要它运行稳

定，就需

要对它做更加详尽的测

试，但它揭示了本章所探

讨的许多方

法的关键思

想：找到一种方法，使一个

预训练模型去适应其他

任务，

而不是重新训练一

个模型。在这个理论前提

下，我们为掩码词元设置

了提示，这样就可以直接

使用掩码语言模型来进

行分类。下面来看看

是否

可以通过调整一个已在

接近文本分类任务上做

过微调的模型来做

得更

好：自然语言推理（Natural Language Inference，NLI）。

A. Williams,

N. Nangia, and S.R. Bowman, “A

Broad-Coverage

Challenge Corpus for Sentence Understanding

Through

Inference”（https://arxiv.org/abs/1704.05426）, （2018）；

A. Conneau et

al., “XNLI: Evaluating Cross Lingual Sentence

Representations”（https://arxiv.org/abs/1809.05053）,

（2018）.

使用掩

码语言模型来做分类任

务是一个好技巧，但我们

还可以通过使

用一个在

更接近分类的任务上训

练出来的模型来做得更

好，有一个叫

文本蕴含任

务的技术符合这个路线

。在文本蕴含任务中，模型

需要确

定两个文本段落

是否有可能相互蕴含或

相互矛盾。这样的模型常

被训

练来检测MNLI语料库（Multi-Genre NLI Corpus）或

XNLI语料库

（Cross-Lingual NLI Corpus）等数据集

的蕴含

和矛盾。

这两个数据集中

的每个样本都由三部分

组成：一个前提，一个假设

和

一个标注，标注可以是

蕴含（entailment）、中性（neutral）或矛盾

（contradiction）的。当假

设在前提下必为真时，就

会被归类为蕴含

标注；当

假设在前提下必然是假

或不合适时，就会被归类

为矛盾标

注；如果两种情

况都不满足，就归类为中

性标注。这几种情况的例

子

如表9-1所示。

表9-1：MNLI数据集中

的三类情况

现在，我们可

以劫持一个在MNLI数据集上

训练的模型来创建一个

分类

器，而且根本不需要

任何标注！这其中最关键

的想法是将我们希望分

类的文本视为前提，然后

将假设表示为：

其中，我们

插入了标注的名称，而蕴

含分数则会告诉我们该

前提和该

主题相关的可

能性大小，可以对任意数

量的类依次运行这个方

法。这

种方法的缺点是，需

要对每个类执行一个前

向传递，这会使得它的运

行效率低于标准分类器

。另一个稍显棘手的问题

是，标注名称的选择

会对

准确率产生很大的影响

，因此选择本身具备语义

的标注通常是最

好的方

法。例如，如果标注是简单

的Class 1，那么模型就无法提示

这是什么意思，以及是否

构成蕴含或矛盾的关系

。

Hugging Face

Transformers有一个内置的MNLI模型用于

零样本分类

的创建，我们

可以通过一个pipeline来初始化

它，如下：

设置devide=0来确保模型

工作在GPU上，而不是工作在

默认的CPU上，

用以加快推理

速度。要对一段文本进行

分类，我们只需要将它和

标注

名称传给pipeline。此外，我们

还可以设置multi_label=True来确保

得到

所有的分数，而不是只得

到单个标注分类的最大

分数：

由于我们使用的是

子词词元分析器，我们甚

至能把代码传给模型。整

体的词元化效率可能不

是很高，因为只有一小部

分零样本pipeline的

预训练数据

集是由代码片段组成的

，但代码也是由一些自然

词汇组成

的，这不是一个

很大的问题。此外，代码块

可能也包含重要的信息

，

如一些常用框架（PyTorch或TensorFlow）。

可以

看出，该模型对这段文本

关乎一个新模型显得非

常有信心，但它

对其他模

型也产生出相对较高的

分数。零样本分类的一个

重要方面关

乎我们要处

理的领域。我们在这里要

处理的文本是非常贴近

技术的，

且大部分都与代

码编写有关，所以它们与

MNLI数据集中的原始文本分

布有很大的差异。因此，这

对模型来说是一项有挑

战的任务也就不足

为奇

了。它在某些领域的效果

可能比其他领域的效果

要好得多，这要

取决于它

们与训练数据的近似程

度。

下面来写一个函数，往

零样本pipeline中传入一个样本

，通过map()的

运行将其扩展到

整个验证集：

到这一步，我

们有了分数，下一步是确

定把哪组标注分配给所

有样

本，有两种选项可供

实验：

●定义一个阈值，并选

择所有高于阈值的标注

。

●选取分数最高的k个标注

。

为了帮助确定用哪种方

法最好，我们下面写一个

get_preds函数，并用

其中一种方法

来检索预测结果：

下面来

编写第二个函数，叫作get_clf_report()，用

于从数据集中返

回带有

预测标注的Scikit-learn分类报告：

在

配备好这两个函数后，我

们从top-k方法开始逐步增加

几个k值，绘

制验证集的微

观和宏观F1分数：

从曲线图

表中可以看出，通过选择

每个样本中得分top 1的标注

，就

可以获得最佳结果。也

许你并不会感到惊讶，因

为在我们的数据集中

大

多数样本都只有一个标

注。我们下面与设置阈值

进行比较，这样就

能预测

每个样本有一个以上标

注的情况：

虽然这种方法

的效果要比top 1的结果要差

一点，但是我们可以从图

表中清晰地看到查准率

和召回率的折中。如果阈

值设置得太低，就会

产生

太多的预测，导致获得低

查准率；如果把阈值设置

得太高，就几

乎不能做出

预测，导致获得低召回率

。图表中显示阈值在0.8左右

能获

得两者的最佳折中

点。

由于top 1方法表现最好，我

们用它来比较零样本分

类和测试集上的

朴素贝

叶斯：

对比零样本pipeline和基线

模型，可以得出两个结论

：

1.如果我们有少于50个标注

的样本数据，那么零样本

pipeline的性能

就会大大超过基

线模型。

2.即使超过50个标注

，在考虑微观和宏观F1分数

时，零样本pipeline

的性能也很优

秀。微观F1分数的结果告诉

我们，基线模型在频繁出

现

的类上表现良好，而零

样本pipeline在上述案例中表现

优异，因为它

不需要任何

样本来学习。

你可能也注

意到了本节的一个矛盾

点：我们明明讨论的是处

理无标注

的问题，却仍然

使用了验证集和测试集

。其实我们只是用它们来

展示

不同的技术，并让它

们的结果具备可比性。即

便在一个真实的用例

中

，收集少量有标注的例子

来进行快速评估也是有

意义的。最重要的

一点是

，我们并没有使用数据来

给模型调整参数，相反，我

们只是调

整了一些超参

数。

如果你发现在自己的

数据集上很难得到好的

结果，下面有几点可以关

注，以改善零样本pipeline：

●你的pipeline的

工作方式可能对标注的

名称非常敏感。如果这些

标

注名称本身没有什么

意义，或是很难与文本内

容联系起来，那么

pipeline很可能

会表现不佳。解决方式是

，要么使用不同的标注名

，

要么并行使用标注名，再

在一个额外步骤中整合

他们。

●另一个可以改进的

是假设的形式。默认情况

下它是

hypothesis="This is example is about {}"，但你可以根据你

的用例来向pipeline传入其他形

式的文本，这样可能会提

升性能。

下面我们看看如

何使用少量标注样本来

训练模型。

9.4

少样本学习

在

大多数NLP项目中，你一般也

会接触到有少量标注的

场景。这些标注

可能直接

来源于客户或跨公司团

队，或者你决定自己做下

来标注几条

数据。即使是

用之前的方法，我们也需

要用一些有标注的例子

来评估

零样本方法的效

果。在本节中，我们将会看

到如何最大化利用之前

标

注过的例子。我们首先

介绍一种数据增强的技

术，使用它可以成倍地

增

加我们的少量标注数据

。

9.4.1

数据增强

在小规模数据

集上提高文本分类器性

能的一个简单而有效的

方法是使

用数据增强技

术，它可以运用现有的数

据产生出新的训练实例

。这种

方法常用于计算机

视觉领域，即在不改变数

据本意的情况下对图像

进

行无序扰动（例如将一

只猫的图像旋转90度，它仍

然是一只猫）。然

而对文本

数据来说，数据增强略显

棘手，因为扰动单个词汇

或者字符

会完全改变其

本意。例如，将“大象比老鼠

重吗？”扰动成“老鼠比

大象

重吗？”，虽然只有两个词的

位置互换，答案却相反。但

是，如

果文本由几个句子

组成（就像GitHub的issue列表一样），这

些类型的

转换所引入的

噪声一般不会影响标注

。在实际场景中，有两类数

据增

强技术是常用的：

回

译（back translation）

将原始文本中的语言

使用机器翻译成一种或

多种语言，然后再将其翻

译回原语言。回译一般对

资源丰富语言（High-Resource

Language，

HRL）或不包含

太多特定专有名词的语

料库效果最好。

词元扰动

J. Wei and K.

Zou，“EDA: Easy Data Augmentation Techniques

for

Boosting Performance on Text Classification Tasks”

（https://arxiv.org/abs/1901.11196），（2019）.

从训练集中给定一个文

本，随机选择单词并进行

简单的转换，比如随

机同

义词替换、随机插词、交换

或删除等操作 。

这些转换

的方式如表9-2所示。其他关

于NLP的数据增强技术详细

介

绍，建议参阅Amit

Chaudhary的博文

“A Visual Survey of Data

Augmentation in NLP”

（https://oreil.ly/j6euX）。

表

9-2：不同类型的文本数据增

强技术

你可以使用M2M100（https://oreil.ly/gfJCq）这样

的机器翻译模型

来实现

回译，而NlpAug（https://oreil.ly/UVRci）和TextAttack

（https://oreil.ly/NMtYi）这样的库则提

供了多种词元扰动方法

。

本节我们将重点探讨使

用同义词进行替换，因为

其实现起来较简单，

并能

直观体现出数据增强背

后的主要思想。

下面我们

使用来自NlpAug的ContextualWordEmbsAug增强器来将

DistilBERT的上下文词向量替换同

义词。从一个简单示例开

始：

从上述结果可以看到

，ContextualWordEmbsAug增强器将“are”替换

成了单引

号，下面用一个简单的函

数来封装这个增强过程

：

现在，我们将这个函数传

给map()方法，就可以用

transformations_per_example参数生

成任意数量的新数据。当

然，我

们也可以在代码中

引入这个函数来训练朴

素贝叶斯分类器，只需要

在

选择切片操作后添加

一行代码即可：

重新运行

分析，会生成如下图表：

从

图表中可以看出，运用少

量的数据增强就能使朴

素贝叶斯分类器的

F1分数

提高5分左右，而且一旦有

了170个左右的训练样本，它

的宏观

分数就会超越零

样本pipeline。下面我们来看看基

于大型语言模型嵌

入的

方法。

9.4.2

使用嵌入作为查找

表

像GPT-3这样的大型语言模

型，已经被证明在解决数

据短缺的任务方面

表现

出色。原因是这些大型语

言模型已经学习了大量

有用的文本特

征，这些特

征将很多维度的信息进

行编码，如情感、主题、文本

结构

等。所以，大型语言模

型的嵌入可用于开发语

义搜索引擎，检索相似

的

文件或评论，甚至做文本

分类。

在本节中，我们将构

建一个仿照OpenAI

API分类接口的

文本分类器

（https://oreil.ly/aMgIr）。这个想法按

照三步来执行：

1.使用语言

模型来产生所有标注文

本的向量。

2.对存储的向量

进行最近邻搜索。

3.聚合最

近邻标注来获得预测结

果。

这个过程如图9-3所示。图

9-3展示了有标注数据是如

何被模型向量化

并与标

注一起存储的。当一个新

的文本需要被分类时，它

也被向量化

处理，并根据

最近邻标注给出结果。校

准要搜索的近邻数量是

很重要

的，因为太少可能

会有噪声，而太多则可能

会混入相邻的群体中。

图

9-3：近邻嵌入查找

这种方法

的优势在于，它不需要对

模型进行微调来利用少

数可用的标

注数据点。相

反，使这种方法发挥作用

的决定性因素是选择一

个适当

的模型，它最好是

在与你的数据集类似的

领域预训练的。

由于GPT-3只能

通过OpenAI的API来使用，这里我们

使用GPT-2来测试上

面的案例

。特别说明，我们使用的是

GPT-2的一个变体模型，该变体

模

型是使用Python代码训练的

，这有望于捕捉到GitHub issue的一些

上

下文。

下面我们写一个

辅助函数，接收传入的文

本列表，并使用模型为每

个

文本创建一个单向量

表示方式。有个问题必须

要处理，像GPT-2这样的

Transformer模型，实

际上返回的是每个词元

的一个嵌入向量。例如，

给

定一个句子“I took my

dog for a walk”，会产生好几

个

嵌入向量，每个词元一

个。但是我们真正想要的

是整个句子的单个嵌

入

向量。为了处理这个问题

，可以使用一种叫作汇聚

（pooling，又称

池化）的技术。最简单

的汇聚方法之一是对词

元嵌入进行均分，这种

方

法被称为平均汇聚（mean pooling）。使用

平均汇聚，唯一需要注

意

的一点是，在每份中不包

含填充词元，可以使用注

意力掩码来解

决。

为了让

大家看清它是如何工作

的，下面我们加载一个GPT-2的

词元分析

器和模型，定义

平均汇聚操作，且将整个

过程封装在embed_text()函

数中：

请注

意，GPT风格的模型没有填充

词元，因此需要手动添加

一个，然后

才能像之前那

样分批地获得嵌入。为此

，我们回收字符串末尾的

词

元：

J.

Johnson, M. Douze, and H. Jégou,

“Billion-Scale

Similarity Search with GPUs”

（https://arxiv.org/abs/1702.08734）,

（2017）.

现在我们已经有了

所有的嵌入，需要建设一

个系统来查询它们。也可

以写一个相关函数，例如

，我们要查询一个新的嵌

入与训练集中现有

的嵌

入之间的余弦相似度。另

外，我们也可以使用

Hugging Face Dataset的一

个内置结构——FAISS索引

，我们已

经

在第7章中见到过FAISS。你可

以把它当作嵌入的搜索

引擎，稍后我们

会介绍它

是如何工作的。可以通过

add_faiss_index()来使用数据集的

一个现

有字段来创建一个FAISS索引

，或者可以通过

add_faiss_index_from_external_arrays()将新的嵌

入数据加载到数

据集。下

面我们使用之前的一个

函数将嵌入添加到数据

集中，如下所

示：

以上代码

创建了一个叫作“嵌入”的

FAISS索引。我们可以通过调用

get_nearest_examples()函数来做近邻搜索操作

。它返回近邻以及每

个近

邻匹配的分数。我们需要

指定要查询的嵌入和要

检索的近邻数

量。让我们

看看与一个案例最匹配

的文档：

以上结果正是我

们所需要的：我们通过嵌

入找到的三个文档都有

相同

的标注，从标题中也

可以看出它们的意思非

常接近。查询和检索到的

文档都有赖于增加新的

、高效的Transformer模型。然而，问题依

旧存

在，k的最佳值是什么

？同样地，我们应该如何聚

合检索到的文档的标

注

？例如，我们是否应该检索

三个文档，并分配所有至

少出现过两次

的标注？或

者应该检索20个文档，使用

至少出现5次的标注？我们

来系

统性地研究一下这

个问题：尝试使用几个k值

，然后用辅助函数改变标

注分配的阈值，使m＜k，然后记

录下每个k值对应的宏观

和微观性能，

这样就可以

得到最佳结果。我们可以

给函数

get_nearest_examples_batch()传入一批查询，而

不是在验证集中的

每个

样本上循环：

下面我们检

查一下所有训练样本的

最佳值是多少，并将所有

配置的k值

和m值的分数可

视化展示：

从图中可以看

出一个模式：对于给定的

k值，m值过大或者过小都会

产

生次优结果。当选择符

合m/k=1/3的比例时，我们可以得

到最佳的性

能。下面我们

看看是哪个k与m可以产生

最优结果：

当选择k=15与m=5时，或

者换句话说，当我们检索

15个最近邻，然后分

配至少

出现5次的标注时，效果最

优。现在我们得到了一个

好办法来得

出嵌入查找

的最优解，可以玩一个和

贝叶斯分类器一样的游

戏，即通

过训练集的切片

来评估性能。在对数据集

进行切片之前，首先需要

删

除索引，因为我们不能

像对数据集那样对FAISS索引

做切片。代码中循

环的其

余部分保持不变，只增加

使用验证集获取最佳k值

和m值的逻

辑：

嵌入查找法

在微观分数上与以前的

方式效果相差不大，同时

只有两个

“可学习”的参数

，即m与k，但在宏观分数上的

表现略差。

我们需要对这

些结果保持严谨的态度

，哪种方法最有效很大程

度上取

决于需求领域。零

样本pipeline的训练数据与本章

使用的

GitHub

issue数据集区别较大

，后者包含了以前的模型

没有遇到过的

大量代码

片段。对于一些常见的任

务，例如情感分析，该pipeline可

能

会获得较好结果。同样地

，嵌入的质量也取决于模

型以及它所训练

的数据

。我们尝试了好几种模型

，比如sentence-transformers/stsb￾roberta-large模型，它被训练来提

供高质量的语句嵌入，还

有如

microsoft/codebert-base和dbernsohn/roberta-python模型，它们被

应用

于代码与文档类训练任

务。对于本节这个特定的

案例，在Python

代码上训练的GPT-2效

果最优。

因为除了替换模

型的checkpoint名称来测试另一个

模型之外，你并不

需要修

改你的代码。一旦建立了

用于评估的pipeline，就可以快速

试

用一些模型。

下面我们

把这个简单的嵌入技巧

结合有限的数据来微调

一个

Transformer模型用以做比较。

用

FAISS做高效的相似度搜索

我

们在本书中首次接触FAISS是

在第7章，当时我们用它通

过DPR嵌入来

检索文档。这里

我们会简单介绍下FAISS库是

如何工作的，以及它为什

么会是ML领域的一个强大

的工具。

我们在日常早已

习惯了在巨大的数据集

上进行查询操作，比如使

用维

基百科或者互联网

搜索引擎，如Google等。当我们把

文本转换为嵌入

时，当然

也希望保持不错的性能

。然而，使文本查询加速的

方法并不

适用于嵌入。

业

界为了快速检索文本，通

常采用倒排索引的方式

来进行，使用属性

映射文

档。倒排索引的工作方式

类似书籍末尾的索引：将

关键词或其

他内容映射

到具体的页码（或者这里

的文档）。当需要执行查询

操作

的时候，我们可以快

速查找关键词出现在哪

些文档中。这种方法对于

那种离散的对象（例如单

词）很有效，但是对于连续

的对象（例如向

量）则作用

不大。每个文档可能都有

一个独有的向量，因此索

引永远

不会与新的向量

匹配。大多数时候，我们并

不需要那种精确的匹配

，

近似足矣。

当我们想从数

据库中找到与目标向量

最相似的向量时，理论上

需要将

目标向量与数据

库中的每个向量进行比

较。对于本章中的小型数

据库

是没有问题的，但是

如果将范围扩大到上百

万条向量查询，所带来的

延迟就无法预估了，通常

需要等待相当长的一段

时间才能找到结果。

FAISS通过

一些技巧来解决这个问

题，其主要的思想是对数

据集进行分

区。如果只需

要将被查询向量与整个

向量数据库的一个子集

进行比

较，速度就能大大

提升。但是，如果只是随机

对数据集进行分区，那

么

如何来确定应该搜索哪

个分区呢？以及如何保证

找到的向量是最相

似的

呢？万幸的是，FAISS有一个不错

的解决方案：对数据集使

用k均

值聚类算法（k-means clustering），效果是

可以根据相似度将嵌入

分组。此外，对于每个分组

，我们将得到一个质心向

量

（centroid vector），它是该组所有成员的

平均值，如图9-4所示。

图9-4：FAISS索引

结构：灰色小点表示添加

到索引中的数据点，黑色

大点表示通过k均值聚类

算法找到的聚类中心，各

区域表示属于某聚

类中

心的区域

基于这样的分

组思想，在n个向量中执行

搜索操作就容易多了：首

先在

k个质心向量中搜索

与query向量最相似的那个质

心向量，然后在该质

心向

量所在的组中进行搜索

。这样就把需要搜索的向

量从n个减少到了

k+n/k个。但看

这个表达式，可能你会提

出一个问题：如何确定最

佳的

k值？如果k值太小，那么

在进行组内查找的时候

，仍然会有很多个向

量需

要去做比较；而如果k值太

大，那么需要与query向量做比

较的质

心向量又太多。这

个问题可以看作寻找函

数f（k）=k+n/k的k的最小值

问题，简单

做一下数学运算，。于是就

可以用下面的函数坐标

曲线来

直观地解答这个

问题，n=220。

图中可以清晰看出

搜索中要做的比较次数

随着聚类数量的变化趋

势，

我们期望做最少的比

较次数，即求这个函数的

最小值，最小值在=1024

处。

除了

用分区的思想来加快查

询速度，FAISS还可以使用GPU来进

一步加

快查询速度。如果

在查询过程中，内存成为

瓶颈，则FAISS还提供几种

业界

前沿的量化方案来压缩

向量。如果你想在你的项

目中使用FAISS，

它的仓库有个

简单的指南（https://oreil.ly/QmvzR），你可以根据

你的用例选择正确的方

式。

业界基于FAISS构建的最大

的项目之一是Facebook的CCMatrix语料库

（https://oreil.ly/ennlr），该项目作者使用多语言

嵌入来寻找不

同语言的

排比句，这个巨大的语料

库随后被用来训练M2M100

（https://oreil.ly/XzSH9）模型

，该模型是一个大型的机

器翻译模

型，能够进行100种

语言的直接翻译。

9.4.3

对Transformer做微

调

如果有机会获得有标

注数据，我们也可以尝试

做一些显而易见的事

情

：简单地微调一个Transformer预训练

模型。在本节中，我们将使

用

标准的BERT checkpoint作为起点，随后

，大家将看到对语言模型

做

微调是怎样影响性能

的。

对许多应用场景来说

，从预训练的BERT模型开始构

建目标模型是一个

好想

法。然而，如果你的语料库

所属领域与预训练模型

的原始语料库

（通常是基

于维基百科的语料库）差

异比较大，那么你应该在

Hugging Face Hub上查找更适合你的预训

练模型，很可能有人已经

在你的领域分享了预训

练模型。

下面从加载预训

练模型的词元分析器开

始，来对我们的数据集进

行词

元化，并删掉在训练

和评估当中并不需要的

列：

通常多标注损失函数

希望标注是浮点类型，因

为它也支持类概率

（class probabilities），而不

是离散的标注，因此，我们

需要更

改label_ids列的类型。由于

更改列元素的格式与Arrow的

类型格式不

匹配，因此这

里我们会做一个小小变

通。首先，创建一个带有标

注的

新列，该列的格式是

由第一个元素推断出来

的。然后，删除原来的

列，将

新列重命名为原列名：

由

于训练数据的规模有限

，因此很可能会快速发生

过拟合，所以这里

设置load_best_model_at_end=True，再

根据微观F1分数选择最佳

模

型：

由于我们使用F1分数

来选择最佳模型，因此需

要确保在模型评估期间

就要将其计算出来。因为

模型返回的是logit，首先需要

使用sigmoid

函数对预测结果进

行规范化，然后设置一个

阈值再将它们转化为二

进

制形式。随后从分类报

告中获取F1分数：

到这里，准

备工作已经就绪。对于每

个训练集分片，我们从头

开始训

练分类器，在循环

结束时加载最佳模型，并

将结果存储在测试集上

：

从结果中可以看出，当案

例数量达到大约64个时，在

数据集上简单地

微调一

个vanilla BERT模型就能获得有竞争

力的结果（灰色实线）。

此外

，还能看出在案例数量少

于64个时，模型效果就不太

稳定，因为

在小样本上训

练模型容易过拟合，语料

中的标注可能个体差异

性较

大。在使用数据集的

无标注部分之前，让我们

看看另一种具备前景的

方法，即在少样本领域中

使用语言模型。

9.4.4

基于提示

的上下文学习和少样本

学习

本章前段内容介绍

过，可以使用像BERT或GPT-2这样的

语言模型，通过

提示与解

析模型的词元预测来使

其适应监督任务。这与添

加一个特定

任务头，并为

任务调整模型参数的经

典方法不同。从好的方面

来说，

这种方法不需要任

何训练数据；但从坏的方

面来说，如果能够获得标

注数据，则无法利用它们

。但存在一个折中方法，即

上下文学习（in￾context learning）或少样本学

习（few-shot

learning）。

为了厘清这个概念，我

们考虑使用一个把英语

翻译成法语的案例来讲

解。在零样本的范式下，我

们将构建一个提示，像如

下这样：

T. Brown et al.,

“Language Models Are Few-Shot Learners”

（https://arxiv.org/abs/2005.14165），（2020）.

这有望提示模型

预测出“merci”这个词的词元。我

们在第6章使用

GPT-2进行总结

时已经知道，在文本中加

入“TL；DR”会促使模型生成

一个

总结，并不需要做明确的

训练工作。在GPT-3的论文中提

到一个有

趣的事情，大型

模型能从提示中进行有

效的学习——因此，前面的翻

译案例可以使用英译德

的例子来增强，这将使模

型在这种任务中表现

得

更好 。

此外，笔者还发现，模

型的规模越大，就越善于

应用上下文中的例

子，这

促使性能的大幅提升。虽

然GPT-3模型的规模在实际落

地中具备

一定挑战性，但

这也是个已有许多很酷

的应用的新兴研究领域

。例如

一个关于自然语言

处理的shell项目，它使用常规

描述语言输入，并由

GPT-3解析

为shell命令，这将为那些shell初学

者带来福音。

D.

Tam et al., “Improving and Simplifying

Pattern Exploiting

Training”（https://arxiv.org/abs/2103.11955），（2021）.

T. Le Scao

and A.M. Rush，“How Many Data Points

Is a Prompt

Worth?”（https://arxiv.org/abs/2103.08493），（2021）.

使用标注数

据的另一种方法是创建

提示和将被预测的例子

，并在这些

例子上持续训

练语言模型。一种叫ADAPET的方

法就使用了这种思想，

它

在各方面都优于GPT-3 ，它使用

自动生成的提示来调整

模型。

Hugging Face的最新研究结果表

明，这样的方法比微调一

个自定义的

头更具数据

效率（data-efficient） 。

在本节中，我们简单

介绍了各种能有效利用

少数标注数据的方法。在

很多时候，除了标注数据

之外，我们还可以通过其

他方式获得大量未

标注

数据。在9.5节，我们将讨论如

何使这些数据物尽其用

。

9.5

利用无标注数据

尽管训

练分类器的最佳方式是

依靠大量的标注数据，但

是这并不意味

着无标注

数据就是毫无价值的。回

想一下我们知道的大多

数模型的预

训练：即使它

们几乎是基于互联网的

不相关数据来训练的，我

们也可

以利用预训练权

重来用在其他各种文本

任务，这就是NLP领域中迁移

学

习的核心思想。自然地

，如果下游任务的文本结

构与预训练的文本相

似

，那么迁移的效果会更好

。所以如果我们能使预训

练任务更接近下

游任务

，就有可能提高模型迁移

的整体效果。

本节我们将

借助具体的案例来思考

这个问题：BERT已在BookCorpus和

English Wikipedia上进行

了预训练，而包含代码的

GitHub issue文

本只是一个小众数据

集。如果从头开始预训练

BERT，则可以在抓取

GitHub的所有issue时

就开始进行。但是，这种方

法是昂贵的，而且

BERT学到的

关于语言的特征针对GitHub

issue有

效。那么在重新训练

模型

和使用现成的模型之间

有没有一个折中方案呢

？答案是有的，这

种方案叫

作领域自适应（我们在第

7章中的问答领域介绍过

）。与其从

头开始重新训练

语言模型，不如基于其领

域数据继续训练它。我们

使

用本章之前介绍过的

预测掩码词元的语言模

型，这也就意味着不需要

任何标注数据。之后，我们

可以将适应后的模型加

载为分类器，并对

其微调

，以此来利用未标注的数

据。

与使用标注数据相比

，领域自适应的好处是即

使使用未标注数据，其

也

是大量可用的。此外，适应

过后的模型也可以在其

他用例中重复使

用。试想

一下，你想构建一个电子

邮件分类器，并对你的所

有历史邮

件使用领域自

适应，之后就可以将此模

型用于NER或另一个分类任

务，

比如情感分析，因为该

方法对于下游任务是不

可知的。

下面我们将微调

一个预训练的语言模型

。

9.5.1

语言模型的微调

在本节

中，我们将在数据集的未

标注部分用掩码语言建

模来微调经过

预训练的

BERT模型。为了做到这一点，我

们需要了解两个新概念

：在

对数据进行词元化时

的一个额外步骤；一个特

殊的数据整理器。下面

我

们从词元化开始讲解。

除

了文本中的普通词元外

，词元分析器还将特殊词

元添加到序列中，

比如用

于分类和下句预测的[CLS]词

元和[SEP]词元。当我们进行掩

码

语言建模时，需要确保

训练的模型不会用来预

测这些词元。出于这个

原

因，我们需要将它们从损

失函数中掩码掉，通过设

置

return_special_tokens_mask=True即可。下面用这个参数

对文本进行

重新词元化

：

在进行掩码语言建模的

时候，缺的是掩码输入序

列中的词元并在输出

中

包含目标词元的机制。我

们可以采取的一种方法

是，引入一个可以

掩码随

机词元的函数，并为序列

创建标注。但这会使数据

集的大小增

加一倍，因为

我们需要在数据集中存

储目标序列，所以这也意

味着我

们将在每轮（epoch）都使

用相同的序列掩码。

有一

个比较优雅的解决方案

，即使用数据整理器。需要

记住，数据整

理器是在数

据集和模型调用之间建

立桥梁的函数。从数据集

中采样一

个批量的数据

，数据整理器准备批量中

的元素以将其提供给模

型。在

我们遇到的最简单

的例子中，它只是将每个

元素的张量拼接成单个

张

量。在本节的案例中，我

们可以使用它来动态地

进行掩码和标注生

成。这

样我们就不需要存储标

注，而且每次采样都会得

到新的掩码。

这个任务的

数据整理器叫作DataCollatorForLanguageModeling，我们

可

以使用模型的词元分析

器和通过mlm_probability参数掩码的词

元来

初始化它。下面我们

将使用这个整理器来掩

码15%的词元，这与BERT论

文中描

述的一致：

我们快速看一

下数据整理器的运行情

况，看看它到底做了什么

操作。

为了在DataFrame中快速显示

出结果，我们将词元分析

器和数据整理器

的返回

格式切换为NumPy：

从结果可以

看到，对应于感叹号的词

元已经被替换成了一个

掩码词

元。另外，数据整理

器返回了一个标注数组

，其中原始词元为-100，

被掩码

的词元则为词元的ID。我们

还可以明显看出，在计算

损失时，

包含-100的条目则被

忽略掉。下面我们把数据

整理器的格式换回

PyTorch：

有了

词元分析器和数据整理

器，我们就可以对掩码语

言模型进行微调

了。我们

照常设置TrainingArguments和Trainer：

我们可以访

问trainer的日志记录，来查看模

型的训练集损失和验证

集

损失。所有日志都存储

在trainer.state.log_history中，它是一个字

典表，可

以很容易被加载到Pandas DataFrame中。由

于训练集损失和

验证集

损失是在不同的步骤中

被记录的，所以在DataFrame中存在

缺失

值。出于这个原因，我

们在绘制指标之前，先把

缺失的值删除：

从结果看

来，训练集损失和验证集

损失都大大降低了。所以

我们来检

验一下，当基于

这个模型对分类器进行

微调时，能否获得效果提

升。

9.5.2

分类器的微调

现在我

们来重复微调操作，但有

些许不同的是，我们将加

载自定义的

checkpoint：

对比基于vanilla BERT模

型的微调结果，我们可以

看出这里具备了一

个优

势，特别是在低数据域。在

有更多标注数据的情况

下，F1分数获

得了几个百分

点的提升：

结果突出表明

了领域自适应可以通过

未标注数据和少量的操

作为模型

带来一些性能

提升。自然地，未标注的数

据越多，标记的数据越少

，

使用此方法的带来影响

就越大。在本章结束之前

，我们将介绍使用无

标注

数据的更多技巧。

9.5.3

高级方

法

在调整分类头之前对

语言模型进行微调是一

个简单而可靠的方法，可

以显著提高性能。其实，还

有一些巧妙而复杂的方

法可以进一步利用

未标

注的数据。我们在此总结

了其中一些方法，可以帮

助你的模型发

挥出极致

的性能，具体请看下文。

无

监督数据增强

无监督数

据增强的核心思想是：一

个模型对于无标注数据

和失真数据

的预测结果

应该是一致的。这种失真

是通过标准的数据增强

策略引入

的，例如词元替

换或者回译，通过最小化

原始数据和失真数据的

预测

结果之间的KL离散度

来加强一致性。此过程如

图9-5所示，一致性要求

是通

过增加交叉熵损失函数

和未标注数据的附加项

来实现的。这就意

味着我

们使用标准监督方法在

标注数据上训练出一个

模型，再限制该

模型对无

标注数据做出一致的预

测。

图9-5：使用UDA训练M模型（图由

Qizhe Xie提供）

这种方法表现出的

性能令人印象深刻：基于

少量有标注数据，使用UDA

方

法训练出的BERT模型和使用

大量数据训练出的模型

性能十分接近。

但缺点是

，我们需要构建一个数据

增强pipeline，而且需要更多的训

练时间，因为需要多个前

向传递来生成对未标注

数据和增强数据的概

率

分布。

不确定性感知自训

练

另一种有前景的利用

无标注数据的方法是不

确定性感知自训练

（Uncertainty-aware Self-Training，UST）。该方

法的思想是在有

标注的

数据上训练出一个教师

模型，然后用这个模型在

未标注数据上

创建伪标

注，再在新的伪标注数据

上训练一个学生模型，这

个学生模

型又作为下一

次迭代训练的教师模型

。

这种方法有趣的一点是

生成伪标注的方法：为了

获得模型预测结果的

不

确定性度量，在开启蒙特

卡罗dropout的情况下，将相同的

输入内容

多次传给模型

。然后，预测的方差代表了

特定样本上模型的确定

性。

有了这个不确定性的

度量，伪标注就可以用一

种叫作“基于分歧的贝

叶

斯主动学习”

（Bayesian Active

Learning by Disagreement，BALD）方法进

行采

样。图9-6展示了整个流程。

S. Mukherjee

and A.H. Awadallah，“Uncertainty-Aware Self￾Training for Few-Shot

Text Classification”

（https://arxiv.org/abs/2006.15315），（2020）.

图

9-6：UST方法是由一个生成伪标

注的教师模型和一个接

收这些标注

用于训练的

学生模型组成。学生模型

经过训练之后会成为教

师模型，

在实际应用中重

复这个步骤即可（图由Subhabrata

Mukherjee提

供）

通过不断迭代，教师模

型在创建伪标注方面不

断变得更好，从而带来

整

个模型性能的提升。最终

，这种方法在模型中并不

会用得太多，它

在多个数

据集上的效果完胜UDA。

现在

我们已经了解了两种高

级方法，最后我们来总结

一下本章中的内

容。

9.6

本章

小结

在本章中可以看到

，即使没有标注数据或是

只有少量的标注数据，我

们也可以完成一些任务

。我们可以使用在其他数

据集上预训练过的模

型

，比如使用在Python代码上预训

练的BERT语言模型或GPT-2，来完成

GitHub issue的分类任务。此外，我们还

可以使用领域自适应，即

使

使用普通分类头也能

获得额外的性能提升。

本

章所介绍的方法中哪种

在实战当中效果最好，取

决于多个方面：标

注数据

的量、数据包含的噪声、数

据与预训练语料的接近

程度等。为

了找出效果最

好的方法，构建一个用于

评估的pipeline并进行迭代是

一

个不错的途径。Hugging Face Transformer具备非常

灵活的API，

它让我们可以快

速加载几个模型来进行

比较，并且这个过程并不

需要

修改任何代码。在Hugging Face Hub上

有超过10 000个模型，可能

已经

有人做过你想做的事，我

们要善于发现并利用它

们。

本章还介绍了一些超

出本书范围的内容，例如

研究UDA或UST这种前沿

的复杂

方法，以及花时间去获得

更多的数据。我们要想评

估模型，就

免不了要准备

测试集和验证集。标注几

百条数据需要几小时或

几天的

时间，我们可以借

助一些工具来辅助标注

。有时候我们花一些时间

来

创建一个小型的、高质

量的数据集，胜过用这些

时间来研究一个更加

复

杂的解决方案。本章所述

内容也是为了确保你能

够合理利用标注数

据。

本

章我们探讨的是如何使

用少量数据来使模型发

挥更强的效能，第10

章正好

相反，我们会介绍如何利

用大规模数据和算力。我

们将从头训

练一个大型

的Transformer模型来帮助我们自动

补全代码。

第10章

从零训练

Transformer模型

本书开篇提到了一

个叫作GitHub Copilot的复杂应用程序

，它使用类

似GPT的Transformer模型来实

现代码自动补全，这样的

特性在学习和

使用一门

新的编程语言或框架完

成编程任务，或自动生成

模板代码时

特别有用。像

TabNine（https://tabnine.com）和Kite

（https://kite.com）也基于AI模型来做类似

的事情。在本书第5章，

我们

近距离了解了如何使用

GPT模型来生成高质量的文

本。在本章中，

我们将沿用

这套机制来闭环训练类

似GPT的模型来生成Python源代码

，

我们将最终的模型称为

CodeParrot模型。

到目前为止，我们都

是在有数据约束的情况

下进行研究，能使用的标

注数据是很有限的。在这

些情况下，得益于迁移学

习的帮助，我们才

构建出

了高性能的模型。在第9章

中，我们将迁移学习使用

到了极致，

几乎没有使用

任何训练数据就完成了

任务。

在本章中，我们将带

领大家走向另一个极端

，也就是当需要的数据应

有尽有时，可以完成哪些

事情。我们将探索预训练

的步骤，并学习如

何从头

开始训练一个Transformer模型。在解

决这个问题的过程中，我

们还将研究一些之前没

有考虑过的与训练相关

的问题，比如下面这

些：

●收

集并处理一个庞大的数

据集。

●为数据集创建一个

自定义词元分析器。

●在多

GPU上完成大规模训练任务

。

为了更有效地训练具有

数十亿参数的大型模型

，我们需要使用专有工

具

来进行分布式训练。虽然

Hugging Face Transformer的Trainer也

支持分布式训练，但

我们想借此机会让你了

解一个叫作

Hugging

Face Accelerate的PyTorch库。最终我

们会接触到一些目

前业

界使用的较大型的NLP模型

，但在此之前，我们需要找

到一个足够

大的数据集

。下面我们从如何找到这

样的数据集开始介绍。

本

章代码与其他章节不同

（在单GPU上使用Jupyter notebook即可运

行），训

练代码被设计成需要在

多GPU上运行。如果你想训练

出自己的

CodeParrot版本，建议使用

Hugging Face的Transformer代码仓库

（https://oreil.ly/ZyPPR）中的脚本。

10.1

如

何寻找大型数据集

在很

多领域，你手头可能真的

有大量的数据，从法律文

件到生物医学

数据集，再

到编程代码库。大多数情

况下，这些数据集是无标

注的，

如此庞大的规模也

意味着只能使用启发式

方法，或者使用在收集过

程

中附带的元数据来标

注它们。

其实，一个非常庞

大的语料库即使没有标

注或只有启发式标注，也

是

有用的。在第9章中介绍

过这样一个例子，我们为

了领域自适应而使用

数

据集中的未标注部分微

调了一个语言模型。在数

据有限的情况下，

这种方

法往往可以带来性能上

的增益。如何判定从头开

始训练一个模

型或者对

现有模型进行微调，是由

用于微调的语料库大小

，以及可用

的预训练模型

和语料库之间的领域差

异来决定的。

如果你使用

预训练模型，那就必须使

用与之对应的词元分析

器，但使

用这样的在另一

个领域的语料库上训练

过的词元分析器往往是

次优

的。比如，在法律文件

、其他语言、甚至完全不同

的序列（如音符或

DNA序列）上

使用GPT的预训练词元分析

器会导致词元混乱（后面

我们

很快会介绍这种情

况）。

随着你能获得的训练

数据量越来越接近用于

预训练的数据量，在资源

和预算允许的情况下，考

虑从头开始训练模型和

词元分析器是很有必

要

的。在我们进一步讨论不

同的预训练目标之前，我

们首先需要构建

一个适

合预训练的大型语料库

。构建这样的语料库也有

其一系列挑

战。

10.1.1

构建大规

模语料库的挑战

预训练

模型的质量很大程度上

可以反映出预训练语料

库的质量，预训

练语料库

中的任何缺陷都会被继

承到预训练模型中。所以

，在构建预

训练语料库之

前，最好先了解一些与构

建大型语料库相关的常

见问题

与挑战。

随着数据

集的规模不断变大，我们

对其中的内容就会渐渐

失去掌控

力。一个非常庞

大的数据集很可能不是

由某个人一次性构建出

来的，

因为需要考虑到整

条生产pipeline和模型被应用的

场景，大型数据集

更有可

能是通过收集其他系统

的数据，以自动或者半自

动的方式来构

建的。比如

，来自一个公司存储的所

有文件（合同、采购订单等

）、

用户操作日志或者来自

互联网的数据。

Y. Zhu et al., “Aligning

Books and Movies: Towards Story￾Like Visual

Explanations by Watching Movies and Reading

Books”（https://arxiv.org/abs/1506.06724），（2015）；J.

Dodge et al., “Documenting the

English Colossal Clean

Crawled Corpus”（https://arxiv.org/abs/2104.08758），

（2021）.

大规模数

据集几乎都是在高度自

动化的流程中被构建出

来的，因此我

们对它的内

容和构建方式能做的干

预都很有限。更进一步，使

用这种

存在误差的低质

量数据来训练模型就会

增加风险。最近对两个著

名的

大规模数据集（BookCorpus和C4，分

别用来训练BERT和T5）的调研发

现它们有以下这些特点

：

●C4语料库的大部分语料是

机翻的，不是人工翻译的

。

●C4中对非裔英语中的停用

词（stopword）进行了不同程度的删

除，

导致此类语料的表现

力不足。

●在大型文本语料

库中，很难找到关于性与

性别内容保留或删除的

折

中点。例如出现“性”这样

的词，它有很多意思，既有

中性的，也有

违规的。这个

词对于在C4上训练的词元

分析器来说完全是未知

的，因

为这个词在语料库

中完全没有。

J.

Bandy and N. Vincent，“Addressing Documentation Debt

in

Machine Learning Research: A Retrospective

Datasheet for

BookCorpus”（https://arxiv.org/abs/2105.05241），（2021）.

●BookCorpus中有很多侵

犯版权的情况，这些情况

在其他大规模数据

集中

可能也存在 。

●BookCorpus数据集语料

的体裁风格倾向于言情

小说。

也许这些特点与训

练出来的模型的应用场

景并不冲突。例如，由于

BookCorpus中

的言情小说的比例较高

，经它训练出的模型如果

被用于

言情小说自动写

作工具或开发游戏，都是

可以接受的。

下面我们通

过比较GPT和GPT-2的文本生成，来

介绍模型被数据所偏斜

的概念。GPT是基于BookCorpus训练的，而

GPT-2是基于网页、博客和

Reddit上的

新闻训练出来的。我们将

基于同一个提示来比较

大小相似

的两个模型版

本，因此最主要的区别还

是预训练数据集，我们将

使用

text-generation pipeline来研究模型的输出

：

下一步我们创建一个简

单的函数来分别计算两

个模型中的参数数量：

从

结果可以看出，原始的GPT模

型和GPT-2模型的大小相近。我

们给它

们输入相同的提

示，尝试使用它们分别生

成三段不同的补充句：

观

察两个模型输出的内容

，可以看出GPT模型明显向言

情方向偏斜，内

容非常像

是两个恋爱中的男女之

间的对话。而GPT-2一部分是在

Reddit

中链接的文章与网络文

本上进行训练的，其中的

“他们”一般是中性

词，而内

容则包含“博客式”与冒险

相关的元素。

B. Hutchinson

et al., “Towards Accountability for Machine

Learning Datasets:Practices from Software Engineering and

Infrastructure”（https://arxiv.org/abs/2010.13561），

（2020）.

一般来说，任

何经过文本数据集训练

的模型都会继承其训练

数据中的

语言偏见，以及

对人群和事件的过度表

达或表达不足。对于与模

型互

动的目标受众来说

，模型中的这些偏见是需

要被考虑的。Google有一

篇论文

对此事进行了详尽描述

，该论文还包含了一个用

于数据集开发

的框架 。

以

上我们介绍了在构建大

型文本数据集时会面临

的一个典型挑战。有

了这

个意识，下面我们来构建

自己的数据集。

10.1.2

构建自定

义代码数据集

通过比较

，GitHub Copilot支持十几种编程语言。

为

了简化操作，本节我们将

致力于为Python语言构建一个

代码生成模

型 。为了达到

这个目的，首先我们需要

一个由Python源代码组成的

大

型预训练语料库。如何找

到这样的语料库呢？幸运

的是，GitHub为

我们提供了这样

的天然资源，几乎每个软

件工程师都能想到。这个

著

名的代码共享网站拥

有海量的代码仓库，并且

这些代码仓库很多是公

开的，根据不同的license可以下

载作不同的用途。在本书

写作时，

GitHub已经托管了超过

2000万个代码仓库，许多代码

仓库是用户为了

学习、研

究业余项目或测试而创

建的小型仓库。

访问GitHub仓库

主要通过两种方式：

●通过

GitHub的REST

API（https://oreil.ly/brhxw）：像第9章获

取issue那样的操

作，直接通过REST API下载。

●通过公

开数据集目录，如Google BigQuery

（https://oreil.ly/dYsVT）。

由于GitHub给

REST API限制了下载速度，而我们

的预训练语料库又需

要

庞大的数据量，所以我们

使用Google BigQuery来获取Python代码

仓库。Google BigQuery的

bigquery-public￾data.github_repos.contents表包含了所有小于10MB的仓

库副本，其

中的项目满足

GitHub License API，且必须开源。

Google BigQuery的数据集中

不包含项目的star信息或fork信

息，出

于这个原因，我们可

以使用GitHub的REST

API或Libraries.io

（https://libraries.io）来获取更多

的仓库信息。最近GitHub官方

发

布了一个叫作CodeSearchNet（https://oreil.ly/daE43）的数据

集

，它利用Libraries.io过滤了一些被fork的

代码仓库。

下面我们看看

如何使用Google BigQuery来构建Python代码数

据集。

用Google BigQuery构建数据集

M.-A. Lachaux et al.,

“Unsupervised Translation of

Programming Languages”（https://arxiv.org/abs/2006.03511），

（2020）.

首先

，我们从Google BigQuery快照中提取GitHub公共

仓库中所有的

Python文件，为了

后面能够重现这些步骤

，也为了防止未来

Google BigQuery的免费

政策发生改变，此数据集

还将在

Hugging

Face Hub上传并分享。导出

这些文件的步骤是从

TransCoder的

实现（https://oreil.ly/vih2m）修改而来的，如下所

示 ：

1.创建一个Google Cloud账户（使用免

费功能即可）。

2.在账户下创

建一个Google BigQuery项目。

3.在此项目下

创建一个数据集。

4.在数据

集中创建一个表，执行SQL的

结果将存储到表中。

5.在github repos上

执行下面的SQL（如果要保存

结果，选择“More

＞Query Options”，勾选

“Set a destination table

for query results”复选框，并

指定表名）。

这条SQL底层处理

了大约2.6TB的数据，提取了2680万

个Python代码文

件，形成了一个

包含了压缩JSON文件的大约

50GB的数据集。在此过程

中过

滤掉了空文件和较小文

件，比如常见的init.py文件，因为

它们包

含的信息用处不

大。其次还过滤了大于1MB的

文件，且下载了所有文件

的license，以方便使用的时候能

根据license来过滤训练数据。

下

一步，我们将构建的数据

集下载到本地机器。如果

你在家尝试这样

的操作

，请确保有足够的带宽和

不少于50GB的磁盘空间。使用

下列两

个步骤下载数据

集：

1.将结果导出到Google Cloud：

a.在Google Cloud Storage（GCS）创建

一个bucket和文件目录。

b.选择“Export > Export

to GCS”将

表导出到bucket中，导出

格式为

JSON，并使用gzip压缩。

2.借助gsutil库（https://oreil.ly/JzgRk），将bucket下

载到本地

机器：

a.使用pip

install gsutil下载

gsutil库。

b.将Google账户配置到gsutil:gsutil config。

c.将bucket复制

到本地机器。

如果你觉得

上面的步骤略显麻烦，也

可以直接下载我们放在

Hugging

Face Hub上的公开数据集：

是否过

滤噪声

因为GitHub的使用门槛

很低，人人都可以创建代

码仓库，所以项目的

质量

存在较大的差异。如果我

们想让模型训练出来后

能以一个理想的

方式运

行，就需要对仓库做一些

主观上的选择。在训练数

据集中加入

一些噪声会

使我们的模型在推理时

显得更有稳健性，但同时

也增加了

预测的不确定

性。我们需要根据模型的

应用场景，选择设置合适

的噪

声数据，并增加相应

的预过滤和后过滤操作

。

出于本章的演示目的，并

保持数据准备部分的代

码简洁性，我们将不

会根

据项目star和用途来做进一

步的过滤，仅获取GitHub BigQuery

数据集

中的Python文件。然而，数据准备

是一个很关键的步骤，应

该

尽量确保数据集的纯

粹性。在本节的案例中需

要考虑的是：是否需要

平

衡数据集中的编程语言

；过滤低质量的数据（比如

，根据star数量

或fork标记）；删除重

复的代码文件；考虑版权

信息；探查文档或评

论等

字符串中的使用的语言

；删除个人标识，如密码或

key信息。

处理50GB的数据集是一

个不小的挑战，需要足够

大的磁盘空间与内

存。10.1.3节

将介绍如何在小型机器

上处理大型数据集。

10.1.3

处理

大型数据集

加载一个非

常大的数据集是具有挑

战性的，特别是当数据集

大于机器

的内存的时候

。对于一个大规模预训练

数据集来说，这其实是一

个很

常见的情况。在我们

的例子中，有50GB的压缩数据

和大约200GB的未压

缩数据，使

用常规尺寸的笔记本电

脑或台式计算机的内存

是很难完成

加载任务的

。

值得庆幸的是，Hugging Face Datasets库针对此

问题做了相关设

计，它具

有两个特殊的功能，得以

让开发者摆脱内存和磁

盘空间的限

制：内存映射

和流式加载。

内存映射

为

了克服内存的制约，Hugging Face Datasets库使

用了一种默认开

启的零

拷贝和零开销的内存映

射机制。数据集以文件形

式存储于磁盘

上，但不是

直接加载到内存中，Hugging Face Datasets使用

一个只

读指针来操作该

文件，这样就既保证了读

取效率，又不会使内存承

担

过大的压力。

下面我们

将直接加载存储在本地

的codeparrot资源库中的50GB压缩

JSON文件

。因为JSON文件是压缩的，所以

先要对其进行解压，

Hugging Face Datasets库可

以解决这个问题。不过需

要注意，这个

过程需要大

概180GB的磁盘空间，几乎不会

使用内存。另外在下载数

据

集的时候配置delete

extracted=True，可以帮

助我们及时删除不再

需

要的文件：

Hugging Face Datasets库底层通过在

一个优化过的缓存文件

中加载

所有压缩的JSON文件

，然后进行读取操作。我们

来看看这个数据集加

载

后有多大：

上面的183.68GB要比一

般的PC机内存大很多，使用

Hugging Face Datasets库提供的内存映射的方

法可以轻松解决这个

问

题，整个过程使用的内存

只有4GB多一点。

到这里，可能

许多人会提出一个问题

，上面的这种操作是否会

使训练

过程中有I/O瓶颈。在

实践当中，与其他领域相

比，NLP领域加载的数

据是非

常轻量的，因此这很难成

为一个问题。此外，底层使

用了

Apache Arrow实现，零拷贝的方式

使得访问任何数据非常

高效。只要

你的磁盘速度

不是特别差，基本也可以

达到GB/s的速度来读取数据

集。但是，有一个问题是无

法避免的，那就是没有足

够的磁盘空间。

这个问题

很多人都会遇到，因为有

时候确实无法腾出那么

多资源出

来。不过不用担

心，Hugging Face Datasets库提供了流式加载功

能，这样就不需要将整个

数据集存储到本地磁盘

上了。

流式加载

有些更加

庞大的数据集（≥1TB）使用一整

个标准硬盘也很难容纳

。遇

到这种情况的时候，除

了单纯地扩存储资源外

，还可以将数据集进行

流

式处理。Hugging Face Datasets库能逐行读取一

些压缩或未压缩

的文件

格式，比如JSON、CSV、文本（原始文本

，或经zip、gzip、

Zstd压缩过的文本）。下面

我们使用它直接从压缩

的JSON文件流式加

载数据集

，这个过程并不会产生额

外的文件：

实际操作的时

候可以发现，加载数据集

在一瞬间就可以完成。在

流式

加载模式下，压缩的

JSON文件被飞速加载成为一

个IterableDataset对

象，看此对象名称可

以知道，只能顺序读取，不

能随机访问。所以只

能使

用next（iter（streamed dataset））来读取内容，而不是像

读

取数组内容那样使用

streamed

dataset[1264]。此外，这里也可以使

用Python的

洗牌算法shuffle()，通过建立一个

缓冲区（大小可调）来

对内

容进行随机排序后再迭

代。

与内存映射读取的内

容相比，它们其实是一样

的：

使用流式读取数据集

的最大好处是，它不会在

磁盘上创建额外的（缓

存

）文件，也不需要大量的内

存，使用这种方式可以节

约大量的存储

和内存资

源（从180GB减少到50GB）。我们还可以

做得更好，不必下载

数据

集，而是直接引用Hugging Face Hub上的数

据集，再用流式加

载数据

集：

这种方式处理数据集

与传统方式效果完全一

样，有了这个技术，就可

以

在一个小型机器上使用

任意大的数据集。下面我

们将数据集与训练

和验

证过程推送到Hugging Face Hub上，再通过

流式加载访问它

们。

10.1.4

推送

数据集到Hugging Face Hub

将数据集推送

到Hugging Face Hub后，我们能够完成下面

这些事：

●在任何机器上都

能轻松访问它。

●获知流式

加载数据集的时候是如

何与Hugging Face Hub上的数据

集无缝衔

接的。

●与技术社区分享你

的成果。

在上传数据集之

前，需要先登录Hugging Face账户，在终

端运行下面

的命令，并输

入你的用户名与密码：

在

之前的章节中，相同的操

作在Jupyter notebook环境中使用

notebook_login()辅助函

数来登录。登录完成之后

，就可以在

Hugging Face Hub创建一个新的

数据集，并上传压缩后的

JSON文

件。为了简化说明，这里

创建两个仓库：一个用于

训练集，另一个用

于验证

集。可以使用huggingface-cli的repo create命令来完

成此事

项，如下所示：

接下

来，需要指定仓库类型为

数据集类型（与存储权重

的模型仓库不

同），以及选

定项目组织。如果是在个

人账户下，则可不设定。然

后，将创建的仓库克隆到

本地，再把JSON文件复制到仓

库目录中，再

将仓库变更

推送到Hugging Face Hub上即可（和GitHub使用方

式如

出一辙）：

将184个JSON压缩的

JSON文件的最后一个当成验

证集（约占整个数据集

的

0.5%），去掉最后一个文件，将其

余文件作为训练集，执行

下面的

命令完成：

提交并

推送到Hugging Face

Hub：

对验证集重复这

一过程：

git后台会计算每个

文件的hash值，所以在“git add.”这一步

可能

会需要较多时间，由

于文件较大，最后在推送

的时候也需要较多时

间

。需要注意，验证集添加了

“_validation”后缀。

到这里，分割出的训

练集和验证集，以及完整

数据集都已经在

Hugging Face Hub上准备

完成了，链接如下：

●https://huggingface.co/datasets/transformersbook/codeparrot

●https://huggingface.co/datasets/transformersbook/codeparrot

-train

●https://huggingface.co/datasets/transformersbook/codeparrot

-valid

建议在

仓库中添加README.md文件，并尽可

能地介绍数据集的构建

过程

与其他有用的信息

。一个文档完善的数据集

对自己以及他人都会起

到

帮助作用。可以参考Hugging

Face Datasets库

的README.md文件

（https://oreil.ly/Tv9bq），了解如何写好一

个README.md。后续也

可以在网页上

直接修改你的README.md文件。

10.2

构建

词元分析器

现在我们已

经了解了如何构建和加

载大型数据集，下面来看

看如何有

效地处理数据

，并馈送到模型。本书前面

的章节中介绍和使用了

与模

型配套的词元分析

器。在当时的场景下，这是

有意义的。因为那是预

训

练模型，我们不得不使用

它的原始词元分析器，以

保持与预训练模

型一致

的预处理设计，否则就会

引起一些问题。

然而，当我

们要训练一个新模型时

，使用为其他数据集准备

的词元分

析器并不是最

优方案。下面是使用这类

词元分析器可能会面临

的问

题：

●T5词元分析器是在

C4语料库（https://oreil.ly/wsYIC）上训练

的，其中使

用了大量的停用词过滤

步骤。因此，T5词元分析器连

常见

的英文单词都不能

识别，比如“sex”。

●CamemBERT词元分析器也

是在一个非常庞大的语

料库上训练的，但只

包含

法语文本[OSCAR语料库的法语

子集

（https://oreil.ly/hgO5J）]。因此，它完全不能识

别英文单词，比

如“being”。

在实践

当中，测试这些词元分析

器的特性是比较容易的

：

在很多情况下，将这种短

小且很常见的词再进行

拆分是比较低效的，

因为

这会增加模型的输入序

列长度（上下文大小有限

）。因此，有必

要了解清楚用

于训练词元分析器的数

据集所属领域与预处理

情况。词

元分析器和模型

可以对数据集中对模型

下游行为有影响的偏置

项进行

编码。为了给数据

集构建一个最佳的词元

分析器，只能通过自训练

来

完成，下面我们来看看

如何操作。

训练一个模型

需要从一组给定的权重

开始，并使用来自误差信

号的反

向传递，在设计目

标上使模型的损失最小

化，并为模型找到一组最

佳

的权重来完成训练目

标所定义的任务。事实上

，训练词元分析器并不

需

要反向传递或权重，它只

是一种构建文本字符串

到id列表的最佳映

射的方

法。在当今的词元分析器

中，从字符串到id的最优转

换涉及一

个由原子字符

串列表组成的词表，以及

转换、规范化、切分，或将文

本字符串映射到有该词

表的索引列表的方法。然

后将该索引列表作为

神

经网络的输入。

10.2.1

常见的词

元分析器模型

我们在第

4章中介绍过，词元分析器

是一个由四个步骤组成

的

pipeline：规范化、预词元化、词元

分析器模型和后处理。其

中可在

数据上进行训练

的是词元分析器模型。本

书第2章介绍过几种针对

子词

的词元化算法，如BPE，WordPiece和

Unigram。

BPE算法从单个词表的基本

单元开始，通过创建新的

词元的过程来构建

词表

，这些新的词元是由高频

出现的基本单元拼接起

来再添加进词表

中。不断

重复这个过程，直到达到

期望的词表大小。

Unigram算法则

另辟蹊径，它将语料库中

的所有词汇和潜在的子

词初始

化为基础词表。然

后，逐步删除或拆分那些

用处不大的词元，最终获

得符合要求的小批量词

表。而WordPiece是Unigram的前身，尚未被

Google开

源。

这些算法对下游性能

的影响因任务类型而异

，因此很难说清孰优孰

劣

。总的来说，BPE和Unigram算法在大多

数时候都表现出较合理

的性

能，下面我们看看在

评估其性能时需要考量

的一些点。

10.2.2

度量词元分析

器性能

在实践当中，词元

分析器的性能和优化点

是很难被度量的。这里有

一

些可能视作度量指标

的点：

●子词产生率（subword fertility）：计算每

个被词元化的词产生

的

子词平均数量。

●延续词的

比例（proportion of continued

words）：语料库中

至少分成

两个子词的被词元化的

词的比例。

●覆盖率指标（coverage metric）：一

个被词元化的语料库中

的未

知词汇或生僻词汇

使用的词元比例。

此外，专

注于拼写错误或噪声的

稳健性，以及模型应用于

外域的性能

表现也是时

常被提及的，因为这些实

际上很大程度取决于词

元化过程

的性能。

以上这

些指标从其他角度来度

量词元分析器的性能，但

它们往往忽略

了词元分

析器与模型的交互问题

。比如，子词产生率可以通

过词表中

所有可能的词

来最小化，但这样做的结

果也会为模型产生一个

巨大的

词表。

所以，词元分

析器性能的最好通过模

型的下游性能来评估。例

如，我

们说早期BPE算法的性

能优良，那是因为使用词

元分析器和词表的模型

性能略高于基于字符或

单词的词元化训练出的

模型性能。

下面我们来看

看如何构建针对Python代码而

优化的词元分析器。

10.2.3

用于

Python代码的词元分析器

这里

将自定义一个词元分析

器来对Python代码做词元化操

作。在处理

编程语言的时

候，预词元化的问题值得

讨论。如果我们在空白处

拆分

并删除它们，则将失

去所有的缩进信息，但这

在Python语言中是很重

要的语

法组成部分（比如while循环或

者if-then-else语句，没有缩进

将很难

阅读）。另外，换行是没有任

何意义的，可以在不影响

语义的

情况下考虑增删

。类似地，在标点符号上进

行拆分也不是很好的做

法，比如下划线，有时候下

划线是用来组成变量的

，它和其他领域的

下划线

意义差别很大。因此，直接

使用基于自然语言的预

词元化分析

器并不是最

佳选择。

让我们看看在Hub上

是否提供了对我们有用

的词元分析器。这里需要

一

个能保留空格的词元

分析器，所以我们的目标

是找到一个处理字节级

别的词元分析器，比如GPT-2的

那个。下面加载此词元分

析器来尝试进

行词元化

操作：

Python有一个内置的tokenize模块

，可以将Python代码拆分成一些

有

意义的单元（代码、注释

、缩进等）。使用这个方法的

一个问题是，

这种预词元

化分析器是基于Python的，因此

会很慢，而且会受到

Python全局

解释器锁（Global Interpreter Lock，GIL）的约束。

另一方

面，Hugging Face

Transformers库中的大部分词元分

析器是

由Tokenizers库提供的，且是

使用Rust编写的。基于Rust的词元

分析

器在训练中和实际

应用中的速度要比Python领先

多个数量级。

以上代码的

输出相当奇怪，我们可以

通过运行词元分析器pipeline的

各个子模块来了解它的

底层发生了什么。首先，查

看词元分析器中运

用了

什么规范化处理：

结果显

示，在GPT-2中并没有运用规范

化操作。它直接处理输入

的原始

Unicode字符，并无任何规

范化步骤。下面我们来看

看预词元化的情

况：

从结

果中我们可以发现很多

的“Ġ”符号，它是什么意思？伴

随词元的

数字又是什么

意思？我们这里对其作出

解释，目的是让大家更好

地理

解这个词元分析器

的工作原理。

先解释词元

中的数字。Hugging

Face Tokenizers库有一个很实

用的

功能，用于在字符串

和词元之间切换，它叫作

偏移量追踪，词元分析

器

对输入的字符串的所有

操作都会被其追踪，如此

就能确切获知词元

化后

第一个词元对应于输入

字符串的哪个部分。所以

这些数字表示每

个词元

在原始字符串中的位置

信息。比如，单词"hello"对应于原

始输

入字符串的第8～13个字

符。如果在规范化步骤中

删除了一些字符，则

我们

仍能找到每个词元在原

始字符串中的位置。

被词

元化的文本中的“Ċ”、“Ġ”符号看

起来很奇怪，这是因为词

元

分析器工作在字节级

别，而不是处理的Unicode字符（每

个Unicode字

符由1～4个字节组成）。这

里使用字节是因为字节

码表中仅有256个元

素，而Unicode字

符却多达143

859个，每个Unicode字符又

可以通过

字节序列表示

。这样一来，就可以将所有

UTF-8编码的字符串用256个

元素

编码表达，而模型也只需

要处理256个元素，并不需要

直接处理

Unicode字符，降低了复

杂性。下面我们看看一些

常见字符用这种方式

是

如何表达的：

到这里，可能

你还是不明白，为什么需

要模型工作在字节级别

？回想

一下在第2章中关于

字符和词元的讨论，基于

143 859个Unicode字符

来建立词表其实

没有任何问题，但是这样

会使得模型的嵌入层变

得非

常大，因为它需要包

含每个词汇词元的向量

。

L. Xue

et al., “ByT5:Towards a Token-Free Future

with Pre￾Trained Byte-to-Byte Models”

（https://arxiv.org/abs/2105.13626），（2021）.

而如果只使用256个字节作

为词表，那么输入的序列

就会被分割成许多

小单

元（由字节构成的Unicode字符），因

此模型就不得不处理较

长的

输入内容，并增加一

些开销在使用字节重建

Unicode字符上，再使用

Unicode重建内容

。关于这种开销的更详细

研究，请参阅ByT5模型的论

文

。

有一个介于它们之间的

解决方案，即通过最常见

的字节组合来扩充256

个字

节，构建出一个中等规模

的词表。这其实就是BPE算法

所使用的方

法。其思路是

通过迭代合并词表中最

频繁出现的词元对，来创

建新的

词汇词元，从而逐

步构建一个预期规模的

词表。例如，如果t和h频繁

地

一起出现（英文中有很多

），就可以在词表中添加一

个th词元来模

拟这对词元

组合，而不是将它们分开

。t和h的词元也被保留在词

表

中，以便在它们不同时

出现时进行词元化。使用

这些包含基本单元的

词

表，我们就可以高效地对

任意字符串进行建模。

P. Gage，“A New Algorithm for Data

Compression，”The C

Users Journal 12，no. 2（1994）:

23-38，

https://dx.doi.org/10.14569/IJACSA.2012.030803.

需

要注意，不要将BPE（Byte-Pair Encoding）中的“byte”与

“byte-level”中

的“byte”混为一谈。BPE来自Philip Gage在1994

年提

出的一种数据压缩技术

，最初是操作字节 ，但目前

的标准BPE算

法却是操作Unicode字

符串（尽管有一种新的BPE算

法也专注于字节操

作，叫

作字节级BPE）。如果需要将Unicode字

符串读取为字节来处

理

，那么我们可以重新使用

一个简单的BPE子词切分算

法。

在NLP领域中使用典型的

BPE算法有一个问题需要注

意。这些算法通常

被设计

为使用纯粹的Unicode字符串作

为输入，而不是字节内容

，并且

要求在输入中使用

常规的ASCII字符，没有空格或

控制字符。但是在对

应于

256个初始字节的Unicode字符中，也

存在许多控制字符（换行

符、制表符、转译符，以及其

他不可打印的字符）。为了

克服这个问

题，GPT-2的词元分

析器首先将256个输入字节

映射为Unicode字符串，

这样这些

字符串就很容易被标准

的BPE算法处理了，也就是说

，将256

个基本元素映射为Unicode字

符串，都对应于可打印的

标准Unicode字

符。

不管这些Unicode字符

使用多少个字节来编码

，这都不重要，重要的是

最

后有256个单个值来形成基

础词表，且都能被BPE算法兼

容。下面我

们看看GPT-2的词元

分析器与这种映射关系

的例子，可以使用以下方

式

来访问所有的映射：

我

们可以在表10-1中查看一些

常见的字节值和映射的

Unicode字符。

表10-1：BPE中的字符映射示

例

此外，我们还可以使用

更加易懂的映射方式，比

如将换行符直接映射

为

NEWLINE字符串，但BPE算法通常是基

于字符设计的。因此，让每

个

字节字符持有一个Unicode字

符，使用BPE算法就会更加方

便。现在我

们了解了Unicode编码

的技巧，就可以更好地理

解词元化转换过程了：

从

上面的结果中，我们可以

看出换行符，因为换行符

被映射为了

“Ċ”，而空格被映

射为了“Ġ”。我们还可以看到

：

●连续的空格是被保留的

（例如'ĊĠĠĠ'，里面有三个空格）。

●连

续的空格会被认为是一

个词。

●每个词前面的空格

被附加在后面的那个词

上，并被认为是后面词的

一部分（例如'Ġsay'）。

下面我们使

用BPE算法来做一个实验。在

实验之前，回顾一下之前

提到

的，BPE模型会将单词拆

分为子单元，直到所有的

子单元能在预定义的

词

表中找到。

比如，GPT-2的词元分

析器的词表包含50257个词：

●带

有256个字节值的基础词表

。

●通过反复合并最常出现

的词元创建的50 000个额外词

元。

●还加入了一个特殊字

符，来表示文件的边界。

可

以通过查看词元分析器

的长度来获得词表的大

小：

最后运行完整的pipeline代码

，会得到下列输出：

从结果

可以看出，BPE的词元分析器

保留了大部分单词，但是

会将缩进

分割为几个连

续的空格。出现这种情况

的原因是，它的词元分析

器并

不是在代码上进行

训练的，而原始语料是连

续空格很少的文本。因

此

，BPE模型中没有为缩进单独

表示的词元。这就是一个

词元分析器与

数据集不

匹配的情况。解决方案是

在目标语料库上重新训

练词元分析

器，下面我们

看看如何操作。

10.2.4

训练词元

分析器

我们使用语料库

的部分数据来重新训练

字节级的BPE词元分析器，来

让

它提升对Python代码的泛化

能力。重新训练

Hugging Face Transformers库提供的

词元分析器非常简单，只

需要

做以下操作：

●指定目

标词表大小。

●准备一个迭

代器来提供输入字符串

列表，以训练词元分析器

模型。

●调用train_new_from_iterator()方法。

传统的深

度学习模型通常需要从

训练语料库中记忆许多

细节，与之不

同的是，词元

分析器实际上被训练来

提取主要的统计类数据

。简而言

之，词元分析器被

训练来找到哪些字母组

合在语料库中出现得最

频

繁。

因此，要达到这个目

的，就不一定要在大型语

料库上进行训练，需要

语

料库具有足够的代表性

，并且要足够大，让词元分

析器获取到具有

统计意

义的特征。但是，由于词表

大小和语料库的一些原

因，词元分

析器可能会存

储一些意料之外的词。例

如，查看GPT-2的词元分析器中

最长的词，可以看到：

这些

词元看起来很像是论坛

上的分隔线。这其实是合

理的，因为GPT-2

是在以Reddit为核心

的语料库上训练的。下面

看看词表中最不频繁出

现的词：

第一个词元，<|endoftext|>，是用

来表示文本序列结束的

特殊词元，

它是在BPE词表构

建完成后添加的。对于这

里每一个词元，模型都需

要

去学习一个相关的词

嵌入，而不希望嵌入矩阵

中包含太多的噪声词。

请

注意，在我们的建模方法

中，一些具有时间和空间

特征的世界知识

（例如，像

Hitman和Commission这样的专有名词）会以

非常低的级别

做嵌入操

作，这是通过在词表中使

用相关向量为这些词分

配独有的词

元来实现的

。BPE的词元分析器创建这种

特有的词元，可以说明目

标词

表太大，或者语料库

本身包含具有特异性的

词元。

下面我们使用语料

库训练一个新的词元分

析器，并查看它的词表。由

于这里只需要一个能够

合理代表数据集统计规

律的语料库，所以从语

料

库中选择1～2GB的数据（或者大

概100 000个文档）即可：

这里需要

研究一下BPE算法创建的第

一个和最后一个词，来看

看词表的

关联性。直接跳

过前面256个字节的词元，观

察其后添加的词元：

从中

我们可以看出有非常多

的缩进和空格词元，以及

Python语言的关

键字，如self、or和in。有这

样的结果就表明BPE算法是

符合预期的。

下面来看看

最后一个词：

这里出现了

一些常见的词汇，例如recv

（https://oreil.ly/tliPP），以

及一些可能来自代码注

释的噪声词

汇。

下面使用

词元分析器对Python代码进行

词元化：

尽管这其中许多

不是Python的关键字，但词元分

析器将World和say这

样的词还是

做了拆分，而其实这样的

词在语料库中经常出现

。下面检

查一下Python的所有关

键字是否都在词表中：

上

面的结果显示，Python中有些经

常使用的关键字却不在

词表中，比

如finally。可以尝试使

用更大的数据集样本来

构建一个更大的词表。

例

如，构建一个具备32 768个词的

词表（8的倍数对于一些GPU/TPU兼

容性更好），并在两倍于它

的语料上训练词元分析

器：

我们并不想看到使用

了更多的语料之后，那些

问题还会出现，来看看

使

用这种方式产生的词元

情况：

以上结果中并没有

出现任何Python的关键字，这可

能是我们想要的效

果，让

我们用这个词元分析器

来对示例代码进行词元

化：

效果的确好了很多，缩

进也能正确地表示了，Hello、World和

say这样

的常见单词也不会

被拆分了，而是成为了单

个词元。我们再来查看一

下Python的所有关键字是否都

在词表中：

结果显示，关键

字nonlocal（https://oreil.ly/IHAMu）仍然不在词

表中，但其

实它在实际编程当中也

很少使用，它会让语法变

得复杂，

所以它不在词表

中也似乎是合理的。在检

查之后我们发现，目前的

词

元分析器已经非常接

近我们的目标了，但如果

不测试模型整体的性

能

，单独评估词元分析器的

性能是一件很有挑战性

的事。下面我们将

在这个

词元分析器的基础上继

续训练一个模型，查看它

的实际效果。

通过比较代

码示例词元化后的序列

长度，可以得出这个新的

词元分析

器比标准GPT-2的词

元分析器的性能高一倍

左右。新的词元分析器使

用

的词元数量大约只有

其一半，这样就能得到两

倍有效的模型上下文。

现

在使用新的词元分析器

在1024的上下文窗口上训练

新模型，相当于

用之前的

词元分析器在2048的上下文

窗口训练同一个模型，并

且新方

法速度更快，内存

使用效率更高。

10.2.5

保存自定

义词元分析器

现在词元

分析器已经训练完毕，如

何进行保存呢？最简单的

方法是将

其推送到Hugging

Face Hub进行

托管，便于以后维护与使

用，后文

在介绍使用训练

服务器的时候会再次用

到它。

使用词元分析器的

push_to_hub()方法可以帮助我们创建

一个私有模型

仓库，并将

词元分析器保存到其中

。因为目前已经使用huggingface￾clilogin完成

了登录，所以可以直接推

送词元分析器到仓库中

，如下

所示：

当然如果你不

想推送到某个组织，则可

以忽略掉organization这个参

数。该操

作会在你的命名空间中

创建一个名为codeparrot的资源仓

库，之后就可以跟其他人

分享了：

现在就可以像之

前那样从Hub（https://oreil.ly/vcLeo）上直接加载

词

元分析器了，并且也可以

研究它的文件和词表，这

里也将小的词元

分析器

推送到Hub：

后面我们会针对

一个用例构建词元分析

器，并展开深入研究。接下

来

就让我们见证一个模

型的诞生历程吧。

10.3

从零训

练一个模型

到这里本章

的正题就开始了：模型训

练。我们将为此项任务设

计最合

适的架构，初始化

一个没有预训练权重的

模型，编写一个自定义数

据

加载类，最后构建训练

循环。在本节的最后，我们

将分别使用1.11亿

和15亿个参

数来训练小型与大型的

GPT-2模型。在此之前，我们先来

确

定一个最适合用在代

码自动补全场景的架构

。

在本节中，我们会编写一

段很长的代码，基于分布

式基础设施训练出

一个

模型。所以不要单独运行

该代码的某一个片段，而

应该下载

Hugging Face

Transformers库（https://oreil.ly/ZyPPR）中提供

的脚

本，并使用Hugging Face Accelerate库来执行。

10.3.1

预训

练模型

现在我们拥有了

一个大规模的预训练语

料库和一个高效的词元

分析

器，可以考虑用其预

训练一个Transformer模型。有了如图

10-1所示的

由大量代码片段

组成的语料库，就可以拉

起好几个训练任务，最后

我

们根据预训练的目的

来选择一个任务。

图10-1：语料

库中的一个Python代码片段

下

面介绍一下三种常见的

训练任务。

因果语言建模

一种非常容易想到的任

务类型是向模型提供一

段代码作为开头，并让

模

型补全剩余可能的代码

。这是一种自监督类型的

训练任务，并且要

确保使

用不包含标注的数据集

，在第5章中我们讲到过类

似的因果语言

模型任务

。一种最容易想到的下游

应用场景就是代码自动

填充，所以

这种模型在我

们的考虑范围。像GPT这样的

只有解码器的架构通常

比较

适合这类任务，如图

10-2所示。

图10-2：在因果语言模型

中，模型需要预测句子中

下一位置的字符，

通常像

GPT这样的纯解码器模型能

用在这个场景

掩码语言

建模

一种与此相关但稍

显不同的方法是给模型

提供一段有噪声的代码

，比

如使用一个随机的或

被掩码的词来代替一个

代码指令，再用相关模型

预测出原来的代码段，如

图10-3所示。这也是一个自监

督的训练任

务，通常被称

为掩码语言建模。要想出

一个与去噪直接相关的

下游任

务是比较困难的

，但是去噪通常是一种很

好的预训练任务，可为以

后

的下游任务学习表示

方式。我们在前几章中使

用的许多模型（如BERT

和XLM-RoBERTa）都是

以这种方式来预训练的

。因此，在一个大型语料

库

上训练一个掩码语言模

型，可以与下游任务（标注

数据有限）中做

微调的模

型相结合。

Seq2Seq训练

另一种方

式是使用像正则表达式

这样的启发式方法，将注

释和文档与

代码分开，构

建一个大规模的“代码-注

释”对的数据集。然后，训练

任务是监督的训练目标

，假设我们将代码当作模

型的输入，注释就会

被当

成标注。这样就成为标准

的具备“输入-标注”对的监

督学习任

务，如图10-4所示。有

了一个大型的、纯粹的、多

样化的数据集，以

及一个

具备足够能力的模型，就

可以尝试训练出一个能

够学习代码及

其注释的

模型。与这个监督训练任

务直接相关的下游任务

将根据代码

生成注释或

根据注释生成代码，这取

决于我们如何设置输入

与输出。

在这种设定下，一

个序列被翻译为另一种

序列，这就是诸如T5、

BART、PEGASUS这些具

备编码器-解码器架构的

模型的魅力所在。

▲图10-3：在掩

码语言建模中，一些输入

词元被掩码或替换，模型

的

目的是预测出原始词

元。这一般是Transformer模型编码器

分支的基

础架构

图10-4：为Seq2Seq任

务使用编码器-解码器架

构，使用启发式方法将

输

入拆分为注释/代码对——模

型获取一个元素作为输

入，并需要生

成另一个元

素

因为我们想构建一个

能完成代码自动补全的

模型，所以这里选用第一

种任务搭配GPT架构。下面我

们来初始化一个新的GPT-2模

型。

10.3.2

初始化模型

这里将是

本书中第一次不使用from_pretrained()方

法来加载模型，而

是初始

化新模型。但我们会加载

gpt2-xl的配置，因此将会使用相

同的

超参数，且会为新的

词元分析器调整词表大

小。随后通过

from_config()方法使用加

载的配置信息初始化一

个新的模型：

我们来看看

这个模型的最终大小：

这

居然是一个拥有超过15亿

个参数的模型！这个模型

的容量很大，但

其实数据

集也很大。一般来说，只要

数据集的规模大得合理

，用作大

型语言模型的训

练就会更有效率。我们把

初始化完成的模型保存

在

models/目录中，并将它推送到

Hub上：

由于checkpoint大于5GB，因此将模型

推送到Hub可能需要花费几

分钟

的时间。另外，我们将

为这个大模型创建一个

能正常运行的小版本，

使

用GPT-2为基础：

将此小型模型

保存到Hub，便于分享和复用

：

现在我们有了两个可供

训练的模型，需要确保在

训练期间的数据供

应。

10.3.3

实

现Dataloader

为了使训练效率最大

化，我们将为模型提供序

列以填充到上下文。例

如

，如果模型上下文包含1024个

词元，就需要1024个词元的序

列。但

实际上一些代码段

很少能精准地获得1024个词

元，为了给模型提供具

备

sequence_length的序列，就应该放弃最后

一个不完整的序列，或是

填充序列。然而，这样会造

成训练效率略微降低，并

且还必须花精力

关注如

何放弃与填充序列，这样

在计算方面比在数据本

身上面的限制

更多，所以

我们可以采取一些方法

来解决这个问题。我们使

用一个小

技巧可以确保

不会丢失过多的尾部片

段：对几个例子进行词元

化后再

连接起来，用特殊

的代表序列结束的词元

将它们分隔开，就可以得

到

一个很长的序列。最后

再将它们拆分成同等大

小的块，如图10-5所

示。采用这

种方法，我们最多只会损

失最后那一小部分数据

。

我们可以指定输入字符

串的字符长度，来确保词

元实例中有100个完整

的序

列：

图10-5：将几个词元化的输

入例子与EOS词元连接起来

，再分块，为

因果语言建模

提供不同长度的序列

这

里的参数解释如下：

●input_characters：输入

到词元分析器的字符串

所包含的字符数

量。

●number_of_sequences：希望

从词元分析器中得到的

（拆分的）序列

数量（比如，100个

）。

●sequence_length：词元分析器返回的每个

序列的词元数量（比如，

1024个

）。

●characters_per_token：估算值，每个输出词元的

平均字符数量。

假如我们

输入一个带有“input_characters”字符的字

符串，还有

number_of_sequences的平均值，就可

以很容易算出最后一个

序列会丢

弃多少输入数

据。如果让number_of_sequences=100，表示大概连接

了

100个序列，则最多可以丢

弃1%的数据。这种方法可以

确保不会因丢弃

了大多

数文件尾而引入偏差。

我

们来估算一个数据集中

每个字符串的平均字符

长度：

按照上面这样操作

就创建好了IterableDataset（它是PyTorch提供的

一个辅助类）需要的所有

内容，以便为模型准备定

长的输入数据。只

需继承

IterableDataset，并编写__iter()__函数逻辑，用刚介

绍的这

套逻辑产生下一

个元素：

__Iter()__函数中建立了一

个字符串缓冲区，可以容

纳足够多的字

符。缓冲区

中所有元素都被词元化

，且与EOS词元相连接，然后将

all_token ids中的长序列拆分为具有

seq_length大小的片段。通常

情况下

，需要使用掩码来堆叠不

同长度的扩充序列，并确

保在训练过

程中忽略它

。可以通过只提供最大长

度的序列来解决这个问

题，所以

这里没有使用掩

码，而是只返回input

ids。下面我们

看看创建的可

迭代数据

集：

结果符合预期！我们为

模型提供了定长的输入

。现在我们有了一个供

模

型使用的可靠数据源，可

以创建训练回路了。

注意

，在创建ConstantLengthDataset之前，我们将原始

数据进行了洗

牌操作。因

为这是一个可迭代的数

据集，所以不能一开始就

进行洗牌

操作。我们设置

了一个大小为buffer_size的缓冲区

，在从数据集中获

取元素

之前，对缓冲区中的元素

做洗牌操作。

10.3.4

定义训练回

路

到目前，所有的准备工

作已经就绪，我们可以开

始编写训练回路了。

我们

自己在本地训练语言模

型的一个问题是单个GPU提

供的内存是有限

的。即使

在最新的GPU上面，也很难保

证在规定时间能将一个

GPT-2规

模的模型训练完成。所

以这里我们将实现数据

并行化，利用几个GPU进

行分

布式训练任务。幸运的是

，我们可以使用

Hugging Face Accelerate库来使训

练代码具备可扩展性。

Hugging Face Accelerate库

的推出，使模型训练突破

硬件的限制，

让分布式并

行训练变得简单。此外，我

们也可以使用Trainer进行分布

式训练，但使用Hugging Face Accelerate库能够完

全掌控训练回

路，这也是

本节需要探讨的。

Hugging Face Accelerate库提供

了一套简单的API，能让训练

脚本

以混合精度和任何

类型的分布式设置（单GPU、多

GPU和TPU）来运行。

同样的一套代

码能够在本地轻松运行

，用于调试，也能在资源富

集的

训练集群上做模型

训练，而这只需要对本地

的PyTorch训练回路代码做

少量

修改：

主要的修改点是在

调用prepare()函数的地方，需要确

保模型、优化器

和数据加

载器都已在基础设施之

上准备完成。在PyTorch代码上完

成这

些改动可以让我们

的模型在不同的硬件环

境中进行训练。下面我们

开

始编写训练脚本和辅

助函数，首先设置的是训

练使用的超参数，将它

们

封装在一个Namespace中，便于访问

：

接下来，设置训练日志打

印逻辑。由于我们是从头

开始训练一个模

型，时间

不定，并且基础设施资源

也比较昂贵，因此，我们需

要确保

所有的相关信息

都被记录下来，方便后期

查看。编写setup_logging()

函数，设置三种

日志记录方式：标准Python日志

（https://oreil.ly/P9Xrm），TensorBoard日志

（https://oreil.ly/kY5ri），Weights&Biases日志

（https://oreil.ly/BCC3k），可以根据需要

，添加或删除日志记录

框

架：

每个worker都有一个全局唯

一的accelerator.process index，这里

将其与FileHandler一起使

用，将每个worker的日志分别写

入单独的文

件中。我们还

使用了accelerator.

is_main_process属性，该属性仅

对

主worker有效。这里我们还避免

了TensorBoard日志和

Weights & Biases日志的多次初

始化，并降低了其他worker的日

志

级别。函数返回值是自

动生成且唯一的wandb.run.name，后面我

们使

用它来命名在Hub上的

实验分支。

此外，我们还定

义了一个函数，使用TensorBoard和

Weights & Biases记

录指标数据，并再次使用

了

accelerator.is_main_process属性来确保只记录一

次，而不是为每个

worker都记录

：

接下来我们编写数据加

载器的创建函数，使用全

新的

ConstantLengthDataset类来为训练集和验

证集创建数据加载器：

最

后，我们将数据集设置到

DataLoader，也能进行批处理，

Hugging Face

Accelerate库会将

批处理结果分配给每个

worker。

另一个需要实现的是优

化部分逻辑，我将在主流

程中设置优化器和学

习

率策略，但这里定义了一

个辅助函数来分辨权重

衰减参数。一般来

说，偏差

和LayerNorm权重不受权重衰减的

影响：

最后，我们希望随时

能在验证集上评估模型

，下面编写一个评估函

数

，用于计算验证集上的损

失与困惑度：

困惑度这个

指标度量的是模型的输

出概率分布对目标词元

的预测程

度，所以，困惑度

越低，代表语言模型的性

能越好。需要注意的是，

可

以通过对模型输出的交

叉熵损失进行指数化来

计算困惑度。特别是

在训

练刚开始的时候，那时的

损失还很高，在计算困惑

度的时候可能

会出现溢

出的情况。因此在这种情

况下，我们一般将困惑度

设置为无

穷大。

在我们将

这些函数写到训练脚本

中之前，还需要使用一些

与

Hugging Face有关的函数。我们知道

，Hugging Face Hub依靠Git

指令来存储模型与

数据集，通过huggingface_hub仓库中的Repository

类

，可以直接在代码中访问

仓库并拉取代码、建立分

支、提交变更或

推送产物

。我们会在训练脚本中使

用这些函数，保证在训练

过程中能

持续不断地将

checkpoint推送到Hub。

下面我们来编写

训练脚本代码：

这段代码

虽然很长，但它是基于分

布式基础设施训练大型

语言模型的

标准写法，下

面我们来剖析一下这段

代码，特别介绍重要部分

。

模型保存

我们在模型仓

库中运行这段代码，在开

始的时候，设置一个新分

支，

并从Weights& Biases获取run name来命名新分

支。之后，我们会在

每个checkpoint提

交模型，并推送到Hub。通过这

种设置，会让每个实

验都

有一个单独的分支，每次

提交也对应于一个模型

checkpoint。不

过需要注意的是，务必

调用wait_for_everyone()和unwrap_model()方

法，因为我们需

要确保模型在存储时已

经与版本同步。

优化

T. Brown

et al., “Language Models Are Few-Shot

Learners”

（https://arxiv.org/abs/2005.14165），（2020）.

对于

模型的优化，我们使用AdamW，并

在一个线性预热周期后

，使用余

弦学习率调整策

略。对于超参数，我们需要

严格遵循GPT-3论文中提到

的

类似规模模型的设置方

式 。

评估

当每次保存的时

候我们在验证集上评估

模型，也就是

save_checkpoint_steps步骤和之后

的训练。与验证集的损失

一起，我

们还记录了验证

集的困惑度。

梯度累加与

梯度checkpoint

你可以在OpenAI的发布帖

子上阅读更多关于梯度

checkpoint的信息

（https://oreil.ly/94oj1）。

即便在最新一代

的GPU上运行，需要的数据批

量大小也很难刚好就等

于

内存大小。因此，我们应

用梯度累加方法，即在几

个后向通道上收集

梯度

，一旦梯度累加到一定量

就开始优化。在第6章中，我

们介绍了使

用Trainer来完成这

个操作。对于大型模型来

说，即使是单批量数据也

不适合使用单个GPU来训练

。使用一种叫作梯度checkpoint的方

法，允

许空间换时间（使用

一些内存来换取20%的训练

速度提升

），这样甚

至能打

破使用单个GPU的限制。

有一

个地方可能还有点令人

疑惑，那就是在多GPU上训练

模型究竟意味

着什么。其

实有好几种方法可以完

成分布式训练，但是需要

考虑模型

的大小和数据

量。Hugging Face

Accelerate库所使用的方法叫作

DataDistributedParallelism（简称DDP）

（https://oreil.ly/m4iNm），这种方法的主要优

点是允许使用大批

量数

据来更快地训练模型（这

种批量数据不能在任何

单GPU上被处

理）。这个过程如

图10-6所示。

下面分步骤介绍

这个pipeline：

1.每个worker由一个GPU组成，在

Hugging

Face Accelerate库中，

有一个运行在主进

程上的数据加载器，它准

备数据批量，并发送给所

有的worker。

2.每个GPU接收一个批量

的数据，并通过模型的本

地副本计算前向和后

向

的损失和各自的累积梯

度。

3.每个节点的梯度用reduce模

式进行平均，将平均后的

梯度返还给每

个worker。

4.在每个

节点上使用优化器单独

应用梯度。虽然看起来这

是多余的，

但它避免了在

节点之间传输大型模型

的副本。我们至少需要更

新一次

模型，如果没有这

种方法，则其他节点在收

到更新的版本之前都将

会

处于等待状态。

5.一旦所

有模型都更新了，就由主

worker准备新的数据批量。

图10-6：用

4个GPU来展示DDP处理过程

使用

这种简单的方式，就可以

增加GPU规模来加速大型模

型的训练过

程，且无须其

他额外的开销。然而，在有

些情况下，这还不足以获

得

理想的性能。例如，如果

模型并不适用于单个GPU，就

需要更复杂的并

行化策

略（https://oreil.ly/3uhfq）。现在我们已经做好了

训练所

需的所有准备，10.3.5节

将会启动一个训练任务

。

10.3.5

开启训练任务

这里我们

将训练源代码保存在codeparrot_training.py文

件中，并将

它和包含所有

Python依赖关系的requirements.txt文件一起上

传到Hub

上的模型仓库（https://oreil.ly/ndqSB）。由于

Hub仓库的本质是

Git仓库，因此

我们可以使用Git的方式来

操作它。在训练服务器上

，

可以通过下列命令来开

启训练任务：

执行完上述

命令，模型就开始训练了

。请注意，输入wandb login

后，会有Weights & Biases日志

提示你进行认证。

accelerate config命令会

帮助你完成基础设施的

设置；可以在表10-

2中查看本

实验使用的设置参数。使

用一个a2-megagpu-16g实例运行所

有的

实验，这是个拥有16个A100（40GB内存

）的工作站。

表10-2：用于训练CodeParrot模

型的环境参数

在这样的

基础设施上训练小型模

型需要24h左右，大型模型则

需要7天

左右。如果是训练

自定义模型，则要确保其

能在小规模基础设施上

能

稳定运行，保障长期训

练的结果。在整个训练过

程完毕后，可以用下

面的

命令将Hub上的实验分支合

并到主分支：

上面的RUN NAME是你

想设置的分支名称。现在

我们已经训练完成了一

个模型，下面来看看如何

评估它的性能。

10.4

结果与分

析

在持续监控一周的训

练过程之后，可能会得到

如图10-7所示的损失和

困惑

度曲线。从图中可以明显

看出，训练损失和困惑度

持续下降，并

且损失曲线

在对数坐标系几乎是线

性的；还可以看出，大模型

在处理

词元方面收敛很

快，尽管它的训练需要更

多的时间。

下面我们来趁

热打铁，用刚出炉的模型

来完成一些代码。在评估

结果

方面，可以采用两种

分析方法：定性分析和定

量分析。定性分析需要

根

据具体的案例，确定模型

输出在哪些情况下符合

预期，以及哪些情

况下不

符合预期。定量分析则需

要在一大批案例上评估

模型的性能，

本节将就这

两个问题展开讨论。下面

会介绍几个例子，以便介

绍如何

系统性地、稳健地

评估模型性能。首先，把小

模型设置到pipeline

中，来续写代

码：

图10-7：对比大型和小型CodeParrot模

型处理词元的训练损失

和验证

困惑度趋势

设置

好之后就可以使用pipeline根据

给定的提示来续写代码

。在默认

情况下，这个pipeline将生

成预定义长度的代码，输

出内容还可能包

含多个

函数和类。为了保证输出

代码的简洁性，这里将实

现一个

first_block()函数，该函数使用

正则表达式来提取一个

函数或类的首

段代码，后

面的complete_code()函数运用此逻辑来

输出CodeParrot模

型自动生成的代

码补全内容：

下面让模型

输出一个计算矩形面积

的函数：

从结果看起来，效

果非常棒！虽然并不是所

有结果都对，但正确的结

果就在其中。下面来尝试

另一个场景，这个模型能

从HTML字符串中提

取出URL吗？来

看看：

结果表明，虽然模型

的第二次输出是错误的

，但其他三次都是正确

的

。在Hugging Face主页上测试这个函数

：

结果表明，所有https开头的URL都

是外站链接，而其他则是

Hugging Face的子页面路径。结果完全

符合预期。最后，我们尝试

使

用这个大模型来尝试

将一个Python函数转换为NumPy库函

数写法：

这非常有效！那么

，是否能用CodeParrot模型来辅助我

们建立一个

Scikit-Learn模型呢？

尽管

在第二次尝试中，它试图

训练一个extra-trees分类器

（https://oreil.ly/40Uy7），但最后

它生成了我们在其他案

例中期

望的结果。

在第5章

中，我们介绍了一些用于

度量生成文本质量的指

标，其中的

BLEU分数被广泛使

用。然而这个指标在总体

上存在一些局限性，非常

不适用于我们的案例。BLEU分

数通常度量的是参考文

本和生成文本之

间的n-grams重

叠程度。在实际编写代码

时，变量名、类名和方法名

都

有很大的自由度，只要

它们是符合要求的，就不

会有问题。因此，这

类信息

几乎是不可预测的（对人

来说也一样）。

M. Chen et

al., “Evaluating Large Language Models Trained

on

Code”（https://arxiv.org/abs/2107.03374），（2021）.

在软件开发

中，存在更好、更可靠的方

法来度量代码的质量，比

如常

见的单元测试。然而

这就是所有OpenAI Codex模型的评估

方式：通过

一组单元测试

来运行几代编码任务的

模型代码，并计算出通过

测试的

百分比 。为了将性

能评估做得更完善，我们

可以使用这种方案，但

这

超出了本章的讨论范围

，不做展开。如果感兴趣，你

可以在该相关

博客（https://oreil.ly/hKOP8）中找

到CodeParrot在HumanEval基准

测试上的细节

。

10.5

本章小结

让我们回过头

来思考一下在本章中获

取的知识。本章我们主要

针对

Python代码完成自动补全

功能。首先，我们构建了一

个适合大规模预

训练语

言模型的大规模数据集

，然后构建了一个词元分

析器，能够用

该数据集对

Python代码进行有效编码。最后

，在

Hugging

Face Accelerate库的帮助下，我们编写

了一个涵盖所有环

节的

训练脚本，运用多GPU从头开

始训练小型和大型版本

的GPT-2模

型，该模型代码前后

不到200行。之后检查模型的

输出，我们看到训练

的模

型能够合理地给出补全

内容，并讨论了如何评估

模型性能。

到目前为止，我

们知道了如何微调Hub上的

预训练模型，还了解了当

有

足够多的数据和计算

资源时，如何从头开始训

练一个自定义语言模

型

。在第11章，也就是本书最后

一章中，我们将介绍NLP领域

最新的发

展情况，以及更

多的应用领域。

第11章

未来

发展趋势

本书前10章探讨

了Transformer模型应用在NLP领域的强

大能力，在本

章中，我们将

换个视角，看看前面介绍

的模型在当前面临的技

术挑

战，以及业界应对这

些挑战的研究趋势。首先

我们将会介绍如何从模

型和语料库方面着手来

扩展Transformer模型的规模。随后，将

聚焦于

已有技术，介绍如

何能让自注意力机制高

效运作。最后我们将介绍

业

界最为津津乐道的话

题，那就是Transformer在多模态领域

的应用，看

看它如何处理

文本、图像和音频等多模

态输入内容。

11.1

Transformer的扩展

在2019年

，研究员Richard Sutton（https://oreil.ly/119br）写了

一篇题为“The Bitter Lesson”（惨

痛的教训）

（https://oreil.ly/YtD3V）的具有争议的

文章，文中指出：

从人类历

经了70年的AI研究中得到的

最大教训是，利用算力一

般最终

都能解决问题，而

且可选的算力范围很大

……为了寻求能在短期带来

较大的提升，研究人员只

能依靠人类的领域知识

来进行优化，但从长

远来

看，最重要的还是需要寻

求更好地利用算力的方

法。二者并不矛

盾，但在实

践当中往往会产生冲突

……人类的知识往往会让方

法复杂

化，使得不能很好

地利用算力。

这篇文章举

了几个业界历史上的例

子，比如利用AI下围棋或者

象棋，

基于人类领域知识

的程序最终被算力的提

升所超越，Sutton称之为AI

研究领

域的“惨痛教训”。

我们必须

从中吸取惨痛的教训，用

固有的思维模式来解决

问题是行不

通的……但是从

中我们可以学到：一些常

用的工程方法也可以带

来很

大的提升，这种方法

就是扩容，搜索领域和机

器学习领域都能使用这

种方法提升效率。

有迹象

表明，Transformer模型也经历了类似

的演化。虽然许多基于

BERT和

GPT的模型此后一直专注在

架构的调整或预训练目

标之上，但

2021年最受关注的

模型还是GPT-3，它基本是原始

模型的扩展版本，并

没有

多少架构上的改进。在图

11-1中，我们可以看到自2017年以

来，

最原始的Transformer架构发布之

后的大模型更迭时间表

，可以看出在

短短几年的

时间，模型规模居然增加

了4个以上的数量级！

图11-1：基

于Transformer架构的模型随时间推

移的参数数量变化

J. Kaplan et al., “Scaling

Laws for Neural Language Models”

（https://arxiv.org/abs/2001.08361），（2020）.

这种

急剧增长的趋势是由实

验结论来推动的，即大型

语言模型在下游

任务中

往往表现更好，且在100亿～1000亿

参数范围内出现了一些

有趣

的应用方式，比如零

样本学习和少样本学习

。然而，参数数量并不是

影

响模型性能的唯一因素

，计算量和训练数据也需

要同步扩展，才能

跟得上

模型的训练需要，像GPT-3这样

的大型语言模型就大概

花费了

460万美元（https://oreil.ly/DUVcq）来训练。因

此，提前预估模型

的性能

，就显得很有必要。令人惊

讶的是，语言模型的性能

似乎与模

型大小以及其

他一些因素遵循一种幂

律关系，这种关系被应用

在了模

型的扩展性上面

。让我们来看看这个令人

兴奋的研究领域。

11.1.1

扩展准

则

数据集大小可以用词

元的数量来度量，而模型

大小不包括嵌入层中的

参数。

扩展准则通过研究

语言模型在不同的计算

量C、数据集大小D和模型大

小N 之下的表现来量化扩

展范式。对于像GPT中的自回

归模型，其损

失曲线如图

11-2所示，其中每条曲线都代

表一个模型的训练过程

。

图11-2：测试损失与计算量（左

）、数据集大小（中）和模型大

小

（右）的幂律比例（由Jared Kaplan提供

）

从以上的损失曲线中，可

以得出下面的结论：

性能

与模型扩展规模的关系

尽管许多NLP领域的研究人

员专注于模型架构调整

或超参数优化（如调

整层

数或注意力头数），以此来

提升其在一组固定数据

集上的性能。

其实也可以

关注模型的扩展方面，研

究如何调整N、C和D来获取较

高的

性能表现。

平滑幂律

α

T. Henighan et al., “Scaling Laws

for Autoregressive

Generative Modeling”（https://arxiv.org/abs/2010.14701），

（2020）.

测试得出，损失L与N、C和D中的

每一个都有几个数量级

的幂律关系

（幂律关系在

对数尺度上是线性的）。对

于X=N、C、D，我们可以将这

些幂律

关系表示为L（X）～1/X，其中α是一个

扩展指数，由图11-2的

损失曲

线的拟合来决定 。αX的值一

般在0.05～0.095之间，这些幂

律关系

的一个主要特点是，可以

根据规律来推断随训练

时间的增加，

会出现什么

样的损失结果。

采样效率

通过比较损失曲线在一

定数量的训练步骤中较

规律的部分可以看出，

大

型模型能够在较少的训

练步骤下达到与小型模

型相同的性能，这说

明如

果只是单纯地扩大模型

的规模，其收益会越来越

小。

不过令人惊讶的是，业

界还总结出了其他模态

的扩展规律，比如图

像、视

频和数学问题的解决，如

图11-3所示。

目前仍然不确定

Transformer语言模型是否符合幂律

扩展规律。不过用

这种方

法来预测一些大型且昂

贵的模型效果不失为一

种解决方案，而

不必去做

繁杂的训练工作。然而，模

型扩展并不是看上去那

么容易，

下面我们看看该

领域的几个挑战。

图11-3：各种

模态下的测试损失与计

算量的幂律比例（由

Tom Henighan提供

）

11.1.2

扩展挑战

虽然将模型扩

大规模在理论上听起来

简单（似乎只需要增加更

多的

层），但在实践中会遇

到很多挑战，如下所示：

基

础设施

在实际环境中，我

们可能需要去管理具有

数千个物理节点的基础

设

施，其中还包括GPU的配套

管理。只看数字就知道这

其中会有很多问

题：节点

的可用性如何？节点的通

信瓶颈是否存在？解决这

些问题需

要依赖非常专

业的工程团队，以及科学

的管理方式。

成本

但是，最

近业界提出了一种新的

分布式深度学习框架，可

以使小公司

协调计算资

源来进行预训练任务。参

见M.

Diskin等人的

“Distributed Deep Learning in Open

Collaborations”

（https://arxiv.org/abs/2106.10207），（2021）.

ML从业者需要借

助性能强大的GPU才能快速

完成模型的训练与推理

，但

GPU往往价格不菲。当需要

进行大规模学习任务的

时候，预算更是一再

拔高

。比如训练一个GPT-3这样规模

的模型，就需要上百万美

元，这不

是所有公司都能

承受的

。

数据集整理

一个

模型的好坏很大程度上

取决于训练数据。训练大

模型更是需要大

规模、高

质量的数据集。当使用庞

大的数据集训练模型时

，我们很难

知晓其中所有

语料的质量，这样在做预

处理的时候就很有挑战

性。此

外，还需要控制倾向

性，例如，如果数据集中包

含大量的性别歧视和

种

族主义的语料，那么训练

出的模型也会具有这些

特征。另外一点则

是需要

注意数据集中的敏感信

息，例如身份证号码、电话

等。

模型评估

当模型训练

完成，又会面临另一个挑

战，那就是在下游任务上

评估模

型。这又需要耗费

时间和精力。此外，我们需

要测试模型是否有较大

倾向性的内容生成，以避

免之后在使用过程中出

现不必要的麻烦。

模型部

署

在模型训练与评估完

成后，如何将它以服务的

方式提供给使用者也是

一大挑战，这就是模型的

工程化问题。在第8章中，我

们介绍了蒸馏、

剪枝和量

化等方法，来解决一些工

程化问题。但是，如果模型

大小高

达几百GB，用这些方

法是肯定不够的。一些提

供模型托管服务的公

司

，如OpenAI API（https://beta.openai.com）或者

Hugging

Face Accelerated Inference API

（https://oreil.ly/E4q3b），可以帮助解决这

些问题。

以上列举的这些

并不是所有的挑战，我们

在实际操作的时候还可

能遇

到更多的情况。虽然

我们自行研究某些大模

型非常困难，但目前有两

个社区开放项目，旨在让

更多人可以参与到大模

型的研究中来：

BigScience

这是一个

在2021年诞生的研讨会，主要

研究大型语言模型。该研

讨会

围绕模型的常见问

题，如能力、局限性、潜在改

进点、偏见、伦理、

环境影响

、在AI业界的作用等，展开讨

论与反思，以及以研究为

目的

来构建一些模型和

数据集，且为此分配了庞

大的计算资源（上千个

GPU）。如

果你想加入的话，可以访

问项目网站

（https://oreil.ly/13xfb）。

EleutherAI

该组织由志

愿研究员、工程师和开发

者组成，专注于AI领域的协

调、

扩展和开源的研究。它

的目标是训练并开源一

个GPT-3大小的模型，目

前该小

组已经发布了一些有影

响力的模型，如GPT-Neo

（https://oreil.ly/ZVGaz）和GPT-J（https://oreil.ly/Kup60），

它们拥

有60亿级别的参数，目前是

零样本训练领域表现最

好的公开且

可用的Transformer模型

。你可以在其网站上获取

更多信息

（https://eleuther.ai）。

现在，我们探讨

了如何在计算量、模型大

小和数据集大小之间来

扩展

Transformer模型，下面介绍另一

个火爆的研究领域：如何

让自注意力

机制更有效

率。

11.1.3

注意力效率提升

2

尽管

自注意力的标准实现具

有O（n²）的时间和空间复杂度

，但谷歌的

研究人员最近

发表的一篇论文

（https://arxiv.org/abs/2112.05682）表明通

过简单的操作，即重

新排

序可以将空间复杂度降

低到O（log n）。

本书专门介绍过自

注意力机制在Transformer的架构中

起着核心作用。

毕竟Transformer的原

始论文就叫作

“Attention

Is All You Need”！然而，自注

意力却有一个关键

挑战

：由于权重是根据对序列

中所有词元进行配比产

生的，因此当试

图处理长

文本或将Transformer用在智能语音

与计算机视觉领域等时

，

这一层就会成为计算瓶

颈。从时间复杂度和空间

复杂度角度来看，

Transformer架构的

自注意力层的规模符合

O（n）规律，其中n代表序

列长度

。

因此，业界最近关于Transformer的研

究方向都围绕着提升自

注意力层

的效率，如图11-4所

示。

Yi

Tay et al., “Efficient Transformers:A Survey”

（https://arxiv.org/abs/2009.06732），（2020）.

图11-4：提升注意力机制效

率的研究方向综述（由Yi Tay等

人提

供） 2

一种常见的方式

是在注意力机制中引入

稀疏性或将核方法应用

于注意

力矩阵，下面我们

将分别介绍。

11.1.4

稀疏化注意

力

降低自注意力层中的

计算量的一个简单方法

，就是限制由预定义模式

产生的query-key对的数量。许多文

献都提到了这一点，但绝

大多数都

可以用图11-5中的

“原子”模式来解释。

图11-5：原子

稀疏注意力模式：彩色方

块表示计算注意力分数

，空白

方块表示放弃计算

分数（由Tianyang Lin提供）

T. Lin et al.,

“A Survey of Transformers”

（https://arxiv.org/abs/2106.04554），（2021）.

图中所有模

式解释如下

：

全局注意力

机制

在序列中定义几个

特殊的词元，并允许其注

意其他所有的词元。

局部

注意力机制

在对角线区

域计算注意力分数。

扩张

注意力机制

通过使用具

有间隙的扩张窗口，跳过

一些query-key对。

随机注意力机制

对每次查询随机提取几

个key来计算注意力分数。

本

地块注意力机制

将序列

划分成若干个块，并将注

意力限制在每个块内。

在

实践中，大多数具有稀疏

注意力的Transformer模型一般都使

用原子

稀疏混合模式来

生成注意力矩阵，如图11-6所

示。比如Longformer模

型（https://oreil.ly/F7xCY）使用全局和

局部注意力的混合模式

，

BigBird模型（https://oreil.ly/yFPyj）则在混合模式中又

加入了随

机注意力。在注

意力矩阵中引入稀疏性

能够使模型处理更长的

序列，

这样的Longformer模型和BigBird模型

能将处理的最大序列长

度扩增到

4096个词元，比BERT模型

大8倍。

还可以通过数据驱

动的方式将稀疏模式运

用到模型，这类方法的基

本

思想是将词元聚集成

为块。例如，Reformer模型

（https://oreil.ly/yIVvX）使用哈希

函数将相似的词元聚集

到一起

成为块。

图11-6：近期Transformer派

生模型运用的稀疏注意

力模式（由

Tianyang Lin提供）

以上介绍

了如何运用稀疏性来降

低自注意力的复杂性方

法，接下来我

们介绍一种

直接改变操作的方式。

11.1.5

线

性化注意力

另一种能使

自注意力更高效的方法

是改变计算注意力分数

时的操作顺

序。回想一下

，为了计算query和key的自注意力

分数，我们引入了一

个相

似度函数，对于Transformer来说，它只

做了一个简单的点积。然

而，对于一般的相似度函

数sim（q，k），我们可以用以下公式

来表示

注意力输出：

ij

线性

化注意力机制的诀窍是

将相似度函数表示为一

个核函数，将操作

分解为

两部分：

其中φ是一个高维

的特征图，由于φ（Q）与j和k均无

关，因此注意力

输出形式

可以变换为

i

A. Katharopoulos et al.,

“Transformers Are RNNs: Fast

AutoregressiveTransformerswith Linear

Attention”

（https://arxiv.org/abs/2006.16236），（2020）； K.

Choromanski et al.,

“Rethinking Attention with Performers”

（https://arxiv.org/abs/2009.14794），（2020）.

通过先计算

和∑kφ（K），就可以有效地将自注

意力的时间和空间复

杂

度线性化。图11-7比较了这两

种方法，采用这种线性化

自注意力的

模型有Transformer和Performer 。

k

图

11-7：标准自注意力和线性化

自注意力的复杂度比较

（由

Tianyang

Lin提供）

在本节中，我们知

道了Transformer模型的架构如何扩

展规模以获取更

高的性

能，在11.2节中，我们将介绍Transformer在

NLP之外的领域是

如何运用

的，比如智能语音和计算

机视觉领域。

11.2

其他应用领

域

与迁移学习结合，借助

文本语料训练语言模型

，是Transformer模型大

获成功的主要

原因。一方面，丰富的文本

可以实现大模型的自监

督训

练；另一方面，像文本

分类和问答对提取这样

的文本类需求应用广

泛

，驱使业界不断探索新的

策略，解决现实问题。

然而

，这些解决问题的方法也

有局限性，包括：

人类报告

偏见

J. Gordon and B. Van Durme，“Reporting

Bias and Knowledge

Extraction”（https://openreview.net/pdf?id=AzxEzvpdE3Wcy），

（2013）.

文本中的事件频率

并不能代表真实事件频

率

，仅根据互联网上的文

本语料进行训练的模型

很可能具有人类报告偏

见的现象。

常识

常识是人

类推理出的一种普遍结

果，但很少会被书面化。因

此，根据

文本训练的语言

模型可能知道很多事实

性知识，但缺乏常识性推

理。

事实

语言模型都是以

概率的方式工作，不可能

直接存储事实，可能会导

致

产生出与事实不相符

的文本。同样道理，这种模

型虽然能够检测到命

名

的实体，但很难直接获取

关于它们的信息。

模态

语

言模型没法直接泛化到

其他模态，比如处理音频

、视频或表格数

据。

因此，如

果能够解决模态的限制

，就能解决很多问题，最近

，

Transformer在新的模态方面取得了

一些成绩，甚至在构建多

模态模型

方面也取得了

进展。下面我们将介绍这

些方向的最新研究成果

。

11.2.1

图像处理

自从卷积神经

网络（CNN）掀起了深度学习革

命，计算机视觉领域一直

被卷积神经网络牢牢占

据。最近，Transformer模型也被应用于

这一领

域，并取得了喜人

的效果，几乎能与CNN平分秋

色，下面我们来看几个

例

子。

iGPT

M. Chen et al.,

“Generative Pretraining from Pixels，”

Proceedings of

the 37th International Conferenceon Machine

Learning

119（2020）:1691-1703，

https://proceedings.mlr.press/v119/chen20s.html.

受到GPT模型在文本处理

领域大获成功的启发，iGPT（image GPT）将

同样的方法应用于图像

处理 。通过将图像视为像

素序列，iGPT沿用

GPT的架构和自

回归预训练目标来预测

下一个像素值。经过大型

图像数

据集预训练的iGPT能

够“自动填充”图像的部分

内容，如图11-8所

示。当分类头

被添加到模型中时，iGPT还能

在分类任务中获得不错

的

效果。

图11-8：使用iGPT填充图像

内容示例（由Mark Chen提供）

ViT

A. Dosovitskiy et al., “An Image

Is Worth 16x16 Words:

Transformersfor Image

Recognition at Scale”

（https://arxiv.org/abs/2010.11929），（2020）.

从iGPT的介

绍中可以获知，iGPT严格按照

GPT架构风格与预训练方式

，

而ViT（Vision

Transformer） 是一个依照BERT风格的用

于视觉领

域的Transformer模型，如图

11-9所示。它的原理是先将图

像分割成为

较小的图像

块，再通过线性投影进行

向量化。处理过程非常类

似BERT

模型对词元的向量化

。而后面的处理也几乎相

同，将图像块向量和位

置

向量相结合，再提交给Transformer的

编码器。在预训练过程中

，一

些图像块被掩码或扭

曲，目的是预测被掩码的

图像块的平均色彩。

图11-9：ViT模

型架构（由Alexey Dosovitskiy等人提供）

虽然

这种方法在标准的ImageNet数据

集上进行预训练时并没

有取得多

么好的效果，但

在更大的数据集上，其扩

展性明显优于CNN。

ViT被集成到

Hugging

Face Transformers库中，它的使用方式与本

书介绍的NLP pipeline的使用方式很

相似，下面从加载那只著

名的柴

犬图片开始：

要加

载一个ViT模型，只需指定image-classification pipeline即

可，然后输入图像来提取

预测出的类别：

结果显示

预测结果非常准确！

G. Bertasius, H. Wang, and

L. Torresani, “Is Space-Time

Attention All

You Need for Video Understanding?”

（https://arxiv.org/abs/2102.05095）,

（2021）.

谈到

图像处理模型很自然就

能延伸到视频处理模型

，但视频除了空间

维度之

外还有时间维度，这会使

任务更具有挑战性，因为

需要处理的

数据量更大

。于是TimeSformer这样的模型就引入

了一个空间和时间注

意

力机制来处理这些问题

。在未来，这类模型可以帮

助人们构建用

途更加广

泛的应用，比如视频序列

的分类或者标注。

11.2.2

表格处

理

很多数据，比如公司内

部的客户关系数据，都存

储在结构化的数据库

中

，而不是作为原始文本。我

们在第7章中介绍过，通过

问答模型可以

用问题来

查询答案文本。如果能像

图11-10中所示的那样，岂不是

更

好？

图11-10：表格中的问答（由

Jonathan Herzig提供）

J. Herzig et al.,

“TAPAS: Weakly Supervised Table Parsing

via

Pre-Training”（https://arxiv.org/abs/2004.02349），

（2020）.

TAPAS（Table Parse） 的出现，让我们能将

Transformer模型架构

应用于表格。该

模型将表格的信息与查

询相结合，如图11-11所示。

图11-11：TAPAS架

构（由Jonathan Herzig提供）

下面我们来看

看TAPAS在实际应用中是如何

工作的，借助一个案例，我

们创建了本书（英文原书

）目录的虚构版本，包含章

节编号、章节名

称以及章

节起始、结束页码：

我们也

可以用现有的字段轻松

地为每章添加页数。为了

与TAPAS模型更

好地配合，需要

确保所有的列都是str类型

：

现在我们知道了这个操

作步骤了，下面我们来加

载table-question￾answeringpipeline：

然后通过一些查询问

题来提取答案：

这些预测

将表的操作类型和答案

一起封装在aggregator字段中，下面

看看TAPAS模型在我们的问题

上实际效果如何：

从结果

可以看出，四个问题均得

到了正确的答案，当然也

可以使用

Pandas来解决，但是拥

有一个能理解语义并给

出答案的工具，就可以

做

更多的事。

11.3

多模态的Transformer

到目

前为止，我们已经介绍了

将Transformer扩展到其他单一模态

的方

法。可能很多人会将

TAPAS看做是多模态的，因为它

结合了文本和表

格，但其

实表格也被当成了文本

来处理。在本节中，我们将

为大家介

绍如何将Transformer应用

在多模态的解决方案中

，比如音频结合文本

或者

图像结合文本。

11.3.1

语音和文

本处理

虽然将计算机与

文本对接起来是工业界

一个巨大的进步，但我们

日常

生活中更自然的沟

通方式依然是使用语音

交流。现在像Siri或Alexa这

样的应

用程序越来越多，并且成

为一种趋势。另外，对于很

大一部分

人来说，写作与

阅读比进行语音交流更

具备挑战性。因此，语音识

别

与理解就显得很有必

要了，可以帮助到许多人

。这个领域的一个常见

任

务是自动语音识别（Automatic Speech Recognition，ASR），它

可

以将语音转换为文本，然

后使用NLP技术处理文本，这

样就能像Siri

那样回答很多

问题。

A. Baevski et al., “wav2vec

2.0: A Framework for Self￾Supervised Learning

of Speech Representations”

（https://arxiv.org/abs/2006.11477），（2020）.

目前，wav2wav 2.0（https://oreil.ly/tPpC7）系列模型是自

动语

音识别领域的最新

技术之一：它们使用Transformer与CNN相

结合，如

图11-12所示 。通过在预

训练期间利用未标注的

数据，这些模型只需

要几

分钟的语料就可以获得

理想效果。

图11-12：wav2wav 2.0架构（由Alexei

Baevski提供

）

wav2wav 2.0模型也被集成到了Hugging Face Transformers库之

中，可以使用之前熟悉的

步骤来加载它。下面来加

载一个预训练模

型，此模

型已经进行了960h的语音数

据的训练：

为了将此模型

应用于一些音频文件，我

们将使用SUPERB数据集

（https://oreil.ly/iBAK8）的ASR子集

，这也是该模型预训练使

用的

数据集。由于该数据

集相当庞大，这里只加载

一个案例用于演示：

这里

我们可以看到，文件中的

音频是以FLAC格式存储的，识

别出的内

容则在text字段。为

了将音频转换为浮点数

组，可以使用SoundFile库

（https://oreil.ly/eo106），再用map()函数

读取数据集中的每个文

件：

如果你使用的是Jupyter notebook，则可

以利用下面的IPython小工

具来

播放语音文件：

最后，将输

入传给pipeline，获取识别结果：

通

过区区几行代码，我们就

构建了一个语音识别应

用程序。这个识别

结果看

起来是正确的，但缺少标

点符号，可以在后期的处

理步骤中添

加处理逻辑

。

A. Baevski et al., “Unsupervised

Speech Recognition”

（https://arxiv.org/abs/2105.11084），（2021）.

为一种语言构建语音识

别模型需要相当多的标

注数据，获取这种高保

真

的数据以及数据标注要

耗费不少成本，特别是那

种低资源语言。在

wav2wav

2.0发布后

不久，一篇介绍wav2vec-U方法的论

文被发表 。

它是一种无监

督的方法，只需要从未标

注语音和未标注的文本

数据中

进行学习，无须进

行任何转录，原理如图11-13所

示。它适用于任何语

言或

者方言的语音识别。

图11-13：wav2vec-U的

训练模式（由Alexei

Baevski提供）

所以Transformer模

型也可以同时具备处理

语音和文本的能力。最新

的

研究不止如此，它还具

备同时进行图形处理的

能力，这也是目前最前

沿

的研究领域之一。

11.3.2

图像和

文本处理

图像与文本结

合处理又是另一种多模

态结合形式，在日常生活

中，我

们也时常会从图像

和视频中提取并处理有

关内容。除了将Transformer

单纯用于

处理图像之外，结合文本

处理也取得了一定的进

展。在本节

中，我们将介绍

处理图像与文本双模态

的四个实践：VisualQA、

LayoutLM、DALL·E和CLIP。

VQA

Y. Goyal et al., “Making the

V in VQA Matter:Elevating the

Role

of Image Understanding in Visual Question

Answering”

（https://arxiv.org/abs/1612.00837），（2016）.

在第7章中

，我们介绍了如何使用Transformer模

型来从文本中提取问

答

对，处理方式包括在线处

理和离线处理，这里的问

答模型用于从一

组文档

中提取结构化信息。最新

的研究已经将它扩展到

了视觉领域，

例如如图11-14所

示的VQA

等数据集。

H. Tan and M. Bansal，“LXMERT:

Learning Cross-Modality

Encoder Representations from Transformers”

（https://arxiv.org/abs/1908.07490），（2019）；L.H. Li et

al., “VisualBERT:A Simple

and Performant Baseline for Vision

and

Language”（https://arxiv.org/abs/1908.03557），（2019）.

像LXMERT和VisualBERT这样

的模型使用ResNets等视觉模型

从图像中提

取特征，然后

利用Transformer的编码器将其与自

然问题结合并预测出

答

案 。

图11-14：VQA数据集中的视觉问

答任务示例（由Yash

Goyal提供）

LayoutLM

单据

、发票或者报告识别等业

务在很多公司都需要，这

也是另一个研

究领域，业

内常使用提取文本或者

布局信息等手段来处理

。在这个领

域中，LayoutLM（https://oreil.ly/uQc5t）系列模型

是目前最先进

的。它们运

用一个增强Transformer架构，接收三

个模态的输入信息：

文本

、图像和布局。因此，如图11-15所

示，每个模态都有与之对

应的

嵌入层，一个空间感

知的自我关注机制，以及

一个将图像与文本混合

的预训练目标。通过数以

百万计的扫描文件进行

预训练，LayoutLM模

型能够以类似

NLP领域BERT模型的方式转移到

各种下游任务中。

DALL·E

A. Ramesh

et al., “Zero-Shot Text-to-Image Generation”

（https://arxiv.org/abs/2102.12092），（2021）.

DALL·E 是一个

结合了图像和文本生成

能力的模型。它使用GPT模型

架构和自回归建模方式

来从文本中生成图像。受

iGPT模型的启发，它

将文字和

像素视为一个词元序列

，因此能够从文本提示中

生成图像，

如图11-16所示。

▲图11-15：LayoutLMv2模

型的架构与预训练策略

（由Yang Xu提

供）

图11-16：DALL·E的内容生成示

例（由Aditya Ramesh提供）

CLIP

A. Radford

et al., “Learning Transferable Visual Models

from

Natural Language Supervision”

（https://arxiv.org/abs/2103.00020），（2021）.

最后，我们来看

看CLIP

，它也将文本和图像结

合处理，专为监督任

务设

计。它的创造者构建了一

个有4亿图像与对应图像

描述的数据集，

并使用对

比学习来预训练模型。CLIP的

架构包括一个文本和一

个图像

编码器（都是Transformer），构建

了图像和描述的向量。将

一批带有

描述的图像采

样，对比性目标是使相应

的一对向量的相似度最

大（由

点积来度量），同时让

其他向量的相似度最小

，如图11-17所示。

图11-17：CLIP的架构（由Alec Radford提

供）

为了用预训练的模型

进行分类，一些可能的类

被加入文本编码器中，

类

似于我们使用零样本pipeline的

方式。然后我们将所有类

的向量与

我们想要的图

像向量进行比较，选择相

似度最高的类。

CLIP的零样本

图像分类性能不错，几乎

能与完全监督训练出的

视觉模

型相媲美，并且能

够在新类别的识别方面

具备更好的灵活性。CLIP也

被

集成到了Hugging Face Transformers库当中，我们可

以直接使用

它。对于从图

像中提取文本的任务，这

里实例化了一个processor，由

一个

特征提取器和词元分析

器组成。特征提取器的作

用是将图像转换

成适合

于模型的形式，而词元分

析器负责将模型的预测

解码成文本。

这里我们使

用擎天柱的图片来测试

：

接下来，设置描述文本，与

图像进行比较，并传给模

型：

最后得到了正确的答

案，CLIP使图像分类非常灵活

，它允许通过文本

定义类

，而不是在模型架构中硬

编码类。

11.4

继续前行的建议

好了，这就是我们带你穿

越Transformer领域的全部旅程！在本

书中，

我们探讨了Transformers如何应

对各种任务并取得最先

进的结果。在

本章中，我们

看到了当前的模型是如

何通过扩大规模和拓展

新领域和

模态性能够推

动其极限的。

如果你想加

强本书中所学习的概念

和技能，以下是一些继续

前行的建

议：

参加Hugging Face社区活

动

Hugging Face举办了短期冲刺活动

，专注于改善生态系统中

的库，这

些活动是认识社

区和尝试开源软件开发

的绝佳方式。迄今为止，这

里

已经有关于向Hugging

Face Datasets添加600多

个数据集、在多种

语言中

微调300多个ASR模型，以及在JAX/Flax中

实现数百个项目的冲

刺

活动。

构建自己的项目

测

试机器学习知识的一种

有效方法是构建一个解

决你感兴趣的问题的

项

目。你可以重新创作一篇

Transformer论文，或将Transformer应用

于新领域

。

向Hugging Face Transformers库贡献模型

如果你正

在寻找更高级的东西，那

么向Hugging

Face Transformers

库贡献新发布的架

构是深入了解库的细节

的好方法。

Hugging Face Transformers库文档中有一

份详细的指南，可以帮助

你开始（https://oreil.ly/3f4wZ）。

写博客记录所学

向他人教授你所学习到

的知识是考验自己知识

的一个强有力的测试，

在

某种意义上，这正是我们

写作本书的主要动力之

一！有很多优秀的

工具可

以帮助你开始技术博客

。我们推荐fastpages

（https://oreil.ly/f0L9u），因为你可以轻

松使用

Jupyter notebook来完成其中的所

有内容。

关于作者

Lewis Tunstall是Hugging Face的机

器学习工程师，他在NLP、拓

扑

数据分析、时间序列等领

域为初创公司和企业构

建了大量的机器学

习应

用程序。Lewis拥有理论物理学

博士学位，曾在澳大利亚

、美国和

瑞士担任研究职

务。他目前的工作重点是

为NLP社区开发工具，并教人

们有效地使用这些工具

。

Leandro von Werra是Hugging Face开源团队的机器学习

工程师。

他拥有多年的行

业经验，横跨整个机器学

习技术栈，致力于如何将

NLP

项目更好地投入生产。他

还是一个名为TRL的流行Python库

的创建者，

该库将Hugging Face Transformers库与强

化学习相结合。

Thomas Wolf是Hugging

Face的首席

科学官和联合创始人。他

建设

了一支促进NLP研究并

使其民主化的团队。在与

其他创始人共同创立

Hugging Face之

前，Thomas获得了物理学博士学

位，后来获得了法律

学位

，并曾担任物理学研究员

和欧洲专利律师。

关于封

面

本书封面上的动物是

虹彩吸蜜鹦鹉（Coconut Lorikeet，学名

Trichoglossus haematodus）。它是

长尾小鹦鹉和鹦鹉的近

亲，也被

称为绿颈鹦鹉，原

产于大洋洲。

虹彩吸蜜鹦

鹉的羽毛融入了热带和

亚热带丰富多彩的环境

。它的脖子

上有黄绿色环

带，头部为深蓝色，头部末

端是橙红色的喙，眼睛是

橙

色的，胸部羽毛是红色

的。虹彩吸蜜鹦鹉是七种

吸蜜鹦鹉中尖尾最长

的

，从上往下看是绿色，从下

往上看是黄色。它身长为

10～12in（或

25～30cm），重为3.8～4.8oz（或108～136g）。

虹彩吸蜜鹦鹉

实行一夫一妻制，一次会

排出两颗卵。它们在80ft（约

24m）高

的桉树上筑巢，在野外能

生活15～20年。虹彩吸蜜鹦鹉因

其美

丽的羽毛而被当成

宠物进行交易。由于被大

范围捕获和人为破坏栖

息

地，它曾一度被列为濒

危物种。

O'Reilly出版社的图书封

面上的许多动物都濒临

灭绝，它们对世界都

很重

要。

本书封面插图由Karen Montgomery基于

《大英百科全书》的黑白版

画

绘制而成。

推荐阅读

▲基

于深度学习的自然语言

处理

作者：Karthiek Reddy Bokka等

ISBN：978-7-111-65357-8 定

价：79.00元

▲面向

自然语言处理的深度学

习：用Python创建神经网络

作者

：Palash Goyal等

ISBN：978-7-111-61719-8 定价：69.00元

▲Java自然语言处理

（原书第2版）

作者：Richard M Reese等

ISBN：978-7-111-65787-3 定价：

79.00元

▲TensorFlow自然语言处理

作者：Thushan Ganegedara ISBN：978-7-111-62914-6

定价

：

99.00元
