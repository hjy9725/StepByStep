හਁᇇ๦्ก

图灵社区的电子书没有

采用专有客

户端，您可以

在任意设备上，用自

己喜

欢的浏览器和PDF阅读器进

行

阅读。

但您购买的电子

书仅供您个人使用，

未经

授权，不得进行传播。 

我们

愿意相信读者具有这样

的良知

和觉悟，与我们共

同保护知识产权。

如果购

买者有侵权行为，我们可

能

对该用户实施包括但

不限于关闭该

帐号等维

权措施，并可能追究法律

责任。

自然语言处理实战

：

从入门到项目实践

Practical Natural

Language Processing

[印] 索

米亚·瓦贾拉 博迪萨特瓦

·马祖达尔

阿努杰·古普塔

哈尔希特·苏拉纳 著

吴进

操 黄若星 译

Beijing

• Boston • Farnham • Sebastopol

• Tokyo

O’Reilly Media, Inc.授权人民邮

电出版社有限公司出版

人 民

邮 电 出 版 社

北

京

内

容 提 要

本书以实际业务

场景为例，介绍自然语言

处理（NLP）系统开发项目的整

个生命周期——从

收集数据

到部署和监控模型。读者

将深入理解

NLP 系统的开发

流程，知道如何消除开发

痛点，

从算法、数据等方面

提高 NLP 系统的质量。全书分

为四大部分，共有 11

章。第一

部分概述

NLP 技术，为全书奠

定知识基础。第二部分从

实战角度讲解 NLP 系统的开

发要点，内容涉及文

本分

类、信息提取等。第三部分

专注于

NLP 重点应用的垂直

领域：社交媒体、电子商务

、医疗

行业、金融业等。第四

部分将所有知识点融会

贯通，并讲解如何利用所

学知识部署 NLP 系统。

本书适

合在实际工作中与自然

语言处理系统打交道的

所有人，包括软件工程师

、测试工程师、

算法工程师

、数据工程师、产品经理和

相关技术负责人。

◆ 著

[印] 索

米亚 • 瓦贾拉 博迪萨特瓦

• 马祖达尔

阿努杰 •

古普塔

哈尔希特 • 苏拉纳

译

吴进

操　黄若星

责任编辑　温 雪

责任印制　彭志环

◆ 人民邮

电出版社出版发行　　北京

市丰台区成寿寺路11号

邮

编　100164

电子邮件　315@ptpress.com.cn

网址　https://www.ptpress.com.cn

北京

印

刷

◆ 开本：800×1000

1/16

印张：20 2022年 9 月第 1

版

字

数：500千字 2022年 9 月北京第 1

次印

刷

著作权合同登记号 图

字：01-2021-2124号

定价：109.80元

读者服务热

线：(010)84084456-6009　印装质量热线：(010)81055316

反盗版

热线：(010)81055315

广告经营许可证：京

东市监广登字 20170147 号

版权声

明

Copyright

© 2020 Anuj Gupta, Bodhisattwa Prasad

Majumder, Sowmya Vajjala, and Harshit

Surana. All rights reserved.

Simplified Chinese

edition, jointly published by O’Reilly Media,

Inc. and Posts & Telecom Press,

2022. Authorized translation of the English

edition, 2022 O’Reilly Media, Inc., the

owner of all 

rights to

publish and sell the same.

All

rights reserved including the rights of

reproduction in whole or in part

in any form.

英文原版由 O’Reilly Media,

Inc. 出版，2020。

简体

中文版由人民邮电出版

社有限公司出版，2022。英文原

版的翻译得到 O’Reilly Media, Inc.

的授权。此

简体中文版的出版和销

售得到出版权和销售权

的所有者——O’Reilly Media, Inc.

的许可。

版权所

有，未得书面许可，本书的

任何部分和全部不得以

任何形式重制。

谨以本书

献给我们各自的导师：Detmar

Meurers、Julian McAuley、

Kannan Srinathan 和

Luis von

Ahn。

目录

本书赞誉 ................................................................................................................................................xv

序 ...........................................................................................................................................................xvii

前言 ........................................................................................................................................................xix

第

一部分　基础

第 1

章　自然语

言处理概要 ..............................................................................................................3

1.1　真实世界中

的自然语言处理 .....................................................................................................4

1.2　什么是

语言 .................................................................................................................................7

1.2.1　语言的基本模块 ............................................................................................................8

1.2.2　为

什么自然语言处理很困

难 ......................................................................................10

1.3　机器学习、深度学习和

自然语言处理：概述 .......................................................................12

1.4　自然

语言处理方法 ...................................................................................................................13

1.4.1　基于启发

式的自然语言处理 ......................................................................................13

1.4.2　用于

自然语言处理的机器学

习 ..................................................................................16

1.4.3　用于自然语言处理的

深度学习 ..................................................................................18

1.4.4　为什么深度学

习还不是自然语言处理

的灵丹妙药 ..................................................22

1.5　自然语言处

理演练：对话智能体 ...........................................................................................25

1.6　小结

...........................................................................................................................................26

第 2 章　自然语言处理流水

线........................................................................................................27

2.1　数据获取 ...................................................................................................................................28

vii

2.2　文本提取和

清洗

.......................................................................................................................31

2.2.1 HTML 解析和清洗 ......................................................................................................32

2.2.2

Unicode 规范化

............................................................................................................33

2.2.3　拼写更正 ......................................................................................................................34

2.2.4

特定于系统的

错误更正 ..............................................................................................35

2.3　预处理 .......................................................................................................................................37

2.3.1

预备步

骤 ......................................................................................................................37

2.3.2　常用步骤 ......................................................................................................................39

2.3.3

其他预处理

步骤 ..........................................................................................................42

2.3.4　高级处理 ......................................................................................................................43

2.4

特征工程

...................................................................................................................................45

2.4.1　经典自然语言处理 / 机器

学习流水线 .......................................................................47

2.4.2　深度学习流

水线 ..........................................................................................................47

2.5　建模 ...........................................................................................................................................47

2.5.1　从简单的启发

式开始 ..................................................................................................47

2.5.2　构建自己的模型

..........................................................................................................48

2.5.3

构建最终模型 ..............................................................................................................49

2.6　评估 ...........................................................................................................................................51

2.6.1

内在

评估 ......................................................................................................................51

2.6.2　外在评估 ......................................................................................................................53

2.7

建模之后

的阶段 .......................................................................................................................54

2.7.1　部署 ..............................................................................................................................54

2.7.2

监控 ..............................................................................................................................54

2.7.3　模型更

新 ......................................................................................................................55

2.8

使用其他语言 ...........................................................................................................................55

2.9　案例研

究 ...................................................................................................................................56

2.10

小结 .........................................................................................................................................57

第 3 章　文本表示

..............................................................................................................................58

3.1　向

量空间模型 ...........................................................................................................................60

3.2　基本的向量

化方法

...................................................................................................................61

3.2.1　独热编码 ......................................................................................................................62

3.2.2　词袋

..............................................................................................................................63

3.2.3 n-gram 袋

......................................................................................................................64

3.2.4 TF-IDF

..........................................................................................................................65

viii ｜ 目录

3.3　分布式表示

...............................................................................................................................67

3.3.1　词嵌入

..........................................................................................................................68

3.3.2　词语之上 ......................................................................................................................75

3.4　词和字符之上

的分布式表示 ...................................................................................................77

3.5　通用文本

表示 ...........................................................................................................................77

3.6　可视化嵌入 ...............................................................................................................................79

3.7　人工特

征表示 ...........................................................................................................................82

3.8　小结 ...........................................................................................................................................83

第二部分　核

心

第

4 章　文本分类 ..............................................................................................................................87

4.1　应用程

序

...................................................................................................................................88

4.2　文本分类流水线 .......................................................................................................................90

4.2.1　不使

用文本分类流水线的简

单分类器

......................................................................91

4.2.2　使用现成的文

本分类 API ...........................................................................................91

4.3

一个流水线，多个

分类器 .......................................................................................................92

4.3.1　朴素贝叶斯分类

器 ......................................................................................................92

4.3.2

逻辑回归 ......................................................................................................................96

4.3.3 SVM ..............................................................................................................................97

4.4

在文本分类

中使用神经嵌入 ...................................................................................................98

4.4.1　词嵌入

..........................................................................................................................98

4.4.2　子词嵌入和

fastText ...................................................................................................100

4.4.3　文档嵌入 ....................................................................................................................101

4.5

用

于文本分类的深度学习

.....................................................................................................103

4.5.1　用于文本分类的 CNN ...............................................................................................104

4.5.2

用于文

本分类的 LSTM .............................................................................................106

4.5.3　使用大型预训

练语言模型进行文本分

类 ................................................................106

4.6　解释文本分类模型 .................................................................................................................107

4.7　无

数据或少数据学习和新

领域适应 .....................................................................................109

4.7.1　无训练数据 ................................................................................................................109

4.7.2　少

训练数据：主动学习和领

域适应 ........................................................................110

4.8　案例研究：企业工

单系统 ..................................................................................................... 111

4.9　实用建议

.................................................................................................................................114

4.10　小结 .......................................................................................................................................115

目

录 ｜

ix

第 5 章　信息提取 ............................................................................................................................116

5.1　信息提

取应用程序 .................................................................................................................117

5.2　信息提取任

务 .........................................................................................................................117

5.3　信息提取的通用流水

线 .........................................................................................................119

5.4　关键词提取 .............................................................................................................................120

5.4.1　实现关键

词提取 ........................................................................................................121

5.4.2　实用建议 ....................................................................................................................121

5.5　命名实

体识别 .........................................................................................................................122

5.5.1　构建命名实体识

别系统 ............................................................................................123

5.5.2　命名实体识别：使

用现有库 ....................................................................................126

5.5.3　命名实体识别

：使用主动学习 ................................................................................126

5.5.4　实用建议

....................................................................................................................127

5.6　命名实体消歧与链接 .............................................................................................................128

5.7

关

系提取 .................................................................................................................................129

5.7.1　关系提取的方法

........................................................................................................130

5.7.2　关系提取：使用

IBM 沃森 API ...............................................................................132

5.8　其他

高级信息提取任务

.........................................................................................................133

5.8.1　时间

信息提取 ............................................................................................................133

5.8.2　事件提取

....................................................................................................................134

5.8.3　模板

填充 ....................................................................................................................135

5.9　案例研究

.................................................................................................................................136

5.10　小结 .......................................................................................................................................139

第 6

章

聊天机器人 .......................................................................................................................140

6.1　聊天机器人

的应用 .................................................................................................................141

6.2

聊天机器人的分

类 .................................................................................................................143

6.2.1　目标导向对话式 ........................................................................................................144

6.2.2

闲聊

式 ........................................................................................................................144

6.3　构建对话系统的流水

线 .........................................................................................................144

6.4

对话系统原理 .........................................................................................................................146

6.5　深入对

话系统的组件 .............................................................................................................155

6.5.1

对话行为

分类 ............................................................................................................156

6.5.2　识别插槽 ....................................................................................................................156

6.5.3

生成响应

....................................................................................................................157

6.5.4　带有代码演练的对话示

例 ........................................................................................158

x ｜

目录

6.6　其他对话流水线

.....................................................................................................................162

6.6.1　端到端方法 ................................................................................................................162

6.6.2　用于对话生

成的深度强化学习 ................................................................................163

6.6.3　人工

监督 ....................................................................................................................164

6.7 Rasa NLU ................................................................................................................................165

6.8　案例研究：食谱推荐

.............................................................................................................167

6.8.1　利用现有框架 ............................................................................................................168

6.8.2　开放式生

成聊天机器人 ............................................................................................169

6.9　小结 .........................................................................................................................................170

第 7 章

主题简介

............................................................................................................................172

7.1　搜索和信息检

索 .....................................................................................................................173

7.1.1　搜索引擎组件

............................................................................................................175

7.1.2　常见企

业搜索流水线 ................................................................................................177

7.1.3　一个配置

搜索引擎的例子

........................................................................................178

7.1.4　案例研

究：书店搜索 ................................................................................................179

7.2　主题建模

.................................................................................................................................180

7.2.1　一

个构建主题模型的例子

........................................................................................183

7.2.2　下一步是什么 ............................................................................................................184

7.3　文本摘要

.................................................................................................................................185

7.3.1　摘要用例 ....................................................................................................................185

7.3.2

一个设置摘要

器的示例 ............................................................................................186

7.3.3　实用建议 ....................................................................................................................187

7.4

文本

推荐系统 .........................................................................................................................188

7.4.1　一个图书推荐

系统示例 ............................................................................................188

7.4.2

实用建议 ....................................................................................................................189

7.5　机器

翻译 .................................................................................................................................189

7.5.1

一个使用机器翻译

API 的示例 ................................................................................190

7.5.2　实用建议 ....................................................................................................................191

7.6　问答系

统 .................................................................................................................................192

7.6.1　开发自定义问答系统

................................................................................................193

7.6.2

寻找更有深度的答案 ................................................................................................193

7.7　小

结 .........................................................................................................................................194

目录

｜ xi

第三部分　应用

第

8 章

社交媒体 ............................................................................................................................197

8.1　应用 .........................................................................................................................................198

8.2

独特的

挑战 .............................................................................................................................199

8.3　用于社交平台数据

的自然语言处理 .....................................................................................205

8.3.1

词云 ............................................................................................................................205

8.3.2　用

于 SMTD 的分词器

...............................................................................................206

8.3.3　热门话题 ....................................................................................................................207

8.3.4　理

解

Twitter 的情绪 ...................................................................................................207

8.3.5 SMTD 的预处理

........................................................................................................209

8.3.6 SMTD 的文

本表示 ....................................................................................................212

8.3.7

社交媒体渠道的

客户支持 ........................................................................................215

8.4　模因与虚假新

闻 .....................................................................................................................216

8.4.1

识别模因 ....................................................................................................................217

8.4.2　虚假新闻 ....................................................................................................................218

8.5

小

结 .........................................................................................................................................219

第 9 章　电子商务与零售

..............................................................................................................220

9.1　电子商务目录 .........................................................................................................................221

9.1.1　评论分析

....................................................................................................................221

9.1.2

产品搜索 ....................................................................................................................221

9.1.3　产品推荐 ....................................................................................................................222

9.2

电子

商务中的搜索 .................................................................................................................222

9.3　构建电子

商务目录 .................................................................................................................224

9.3.1

属性提取 ....................................................................................................................224

9.3.2　产品

分类与分类树 ....................................................................................................228

9.3.3

产品浓缩

....................................................................................................................231

9.3.4　产品去重和匹配 ........................................................................................................233

9.4　评论分

析

.................................................................................................................................234

9.4.1　情感分析 ....................................................................................................................234

9.4.2　方面级情感

分析

........................................................................................................236

9.4.3　将总体评分与“方面

”联系起来 ............................................................................238

9.4.4　理解“方面”

..............................................................................................................239

xii ｜ 目录

9.5　电子商务推荐 .........................................................................................................................240

9.6　小结 .........................................................................................................................................243

第 10 章

医疗、金融和法律

.......................................................................................................244

10.1　医疗 .......................................................................................................................................244

10.1.1　健

康和医疗记录.....................................................................................................245

10.1.2　患者优先

级和计费.................................................................................................246

10.1.3　药物安全监视

.........................................................................................................246

10.1.4　临床决策支持系统.................................................................................................246

10.1.5　健康

助理.................................................................................................................247

10.1.6　电子健康记录.........................................................................................................248

10.1.7　心理

健康监测.........................................................................................................255

10.1.8　医疗信息提取

与分析.............................................................................................257

10.2　金融与法律 ...........................................................................................................................259

10.2.1

自然

语言处理在金融领域中

的应用.....................................................................261

10.2.2　自然语言处理与

法律行业.....................................................................................263

10.3　小结 .......................................................................................................................................266

第四部分

综合

第 11 章　端到端自然语

言处理系统 ..........................................................................................269

11.1　重温自然语

言处理流水线：部署自然

语言处理软件 .......................................................270

11.2　构建和维

护成熟的系统 .......................................................................................................272

11.2.1　寻找更好

的特征 .....................................................................................................273

11.2.2　迭代现有模型 .........................................................................................................274

11.2.3　代

码和模型再现性 .................................................................................................274

11.2.4　故障排

除和可解释性 .............................................................................................275

11.2.5　监控 .........................................................................................................................277

11.2.6　尽量

减少技术债务 .................................................................................................278

11.2.7　自动化机

器学习 .....................................................................................................279

11.3　数据科学过程 .......................................................................................................................282

11.3.1 KDD 过

程 ...............................................................................................................282

11.3.2　微软

TDSP ..............................................................................................................283

11.4　让人工智能在组

织中取得成功 ...........................................................................................284

目录

｜ xiii

11.4.1　团队

.........................................................................................................................285

11.4.2　正确的问题和正确的期

望

.....................................................................................285

11.4.3　数据和时间 .............................................................................................................286

11.4.4　好的流程

.................................................................................................................287

11.4.5　其他方面 .................................................................................................................288

11.5　展望未来 ...............................................................................................................................290

11.6　结语

.......................................................................................................................................292

xiv ｜ 目录

本书赞誉

这本书直

接关注两个被忽视的群

体：自然语言处理从业者

和商业领导者。很多优秀

图书的

内容侧重于机器

学习的算法基础，这本书

则全面剖析了从电子商

务应用程序到虚拟助理

等

现实世界中的各种系

统。书中描绘了现代生产

系统的真实图景：不仅讲

述了深度学习，而

且还讲

述了启发式和流水线，使

部署后的自然语言处理

系统能够真正达到先进

水平。作者

既能跳出来讲

述问题的形式化，亦不惧

钻进去探讨烦琐的细节

，包括处理杂乱的数据、维

持运行中的系统等。对于

那些热衷于构建和部署

自然语言处理系统的专

业人士，这本书是

非常宝

贵的参考资料。

——Zachary Lipton 

卡内基 – 梅

隆大学助理教授，亚马逊

人工智能科学家，《动手学

深度学习》合著者

这本书

很好地跨越了自然语言

处理在理论研究和实际

应用之间的鸿沟。从医疗

保健到电

商、金融，这本书

涵盖了正在运用自然语

言处理技术的众多热门

领域，并以清晰易懂的方

式展示了其中的核心任

务。总之，这是一本很棒的

图书，它告诉你如何在所

在行业充分利

用当前的

自然语言处理技术。

——Sebastian Ruder

谷歌

DeepMind 研究科学家

市面上的计

算机科学图书可以分成

两种：一种是学术教科书

，它能让你对某个领域有

深入

的理解，但对于非学

术的人来说可能难以接

近；另一种是技术手册，它

只勾勒具体问题的

解决

方案，不提供技术背景，使

读者无法对其中的技术

推而广之。这本书则做到

了两全其

美，既透彻又易

懂。它为你学习自然语言

处理提供了坚实的基础

……如果你想从

0 到 1 开

发自然

语言处理系统，那么这本

书就是为你准备的。

——Marc

Najork 

谷歌

人工智能研究工程总监

，ACM、IEEE 会士

xv

教科书、研究论文或

其他图书会谈到编程技

巧，但不会讲述如何从零

开始搭建端到端的自

然

语言处理系统。我很高兴

看到这本书，它急人之所

需，真正介绍了从零开始

的搭建过

程。作者细致、周

到、清晰地介绍了构建大

规模真实自然语言处理

系统时必须注意的方方

面面。同时，这本书还设法

涵盖了大量的示例，以及

各种应用领域和垂直领

域。对于所有

志存高远的

自然语言处理工程师、想

要围绕语言技术开办公

司的创业者，以及希望看

到自

己的发明创造真正

到达用户手中的科研人

员，这本书值得一读。

——Monojit Choudhury

微软

印度研究院首席研究员

，海得拉巴国际信息技术

研究所、

阿育王大学、印度

理工学院卡哈拉格普尔

分校特约教授

这本书不

但解释了基本概念，同时

也不忘介绍自然语言处

理在不同垂直行业的各

种实际部

署，架起了理论

与实践之间的桥梁。无论

是调整开源库的参数、构

建模型的数据流水线，

还

是优化快速推理，这本书

都有许多真枪实弹的实

战建议。这是工程师构建

自然语言处理

应用程序

的实用参考。

——Vinayak Hegde 

微软加速器

（Microsoft For Startups）常驻首席技术官

这本书

展示了如何将自然语言

处理付诸实践。它填补了

自然语言处理理论与实

际工程之间

的缺口。生产

级机器学习系统的设计

和架构是一门深奥难懂

的艺术，本书作者却能将

其化

繁为简，讲解深入浅

出，令人不得不为之叹服

。多么希望我在职业生涯

的早期就接触过这

本书

，这样就能避免一路走来

所犯的种种错误……我深信

，对于任何想要开发稳健

且高效

的自然语言处理

系统的人来说，这是一本

必不可少的参考指南。

——Siddharth

Sharma 

Facebook 机

器学习工程师

我认为这

本书不仅是自然语言处

理从业者的案头参考书

，也是研究人员了解实际

应用中各

种问题的宝贵

参考。我非常欣赏这本书

，并希望这是一个长期项

目，能够时刻跟进自然语

言处理应用方面的新趋

势。

——万梦婷

微软体验与设

备部门应用研究办公室

高级应用科学家

xvi ｜ 本书赞

誉

序

近年来，自然语言处

理（NLP）领域在方法论和所支

持的应用程序方面发生

了翻天覆地的

变化。方法

论方面的进展多种多样

，既有文档表示方法的创

新，也有语言合成技术的

创

新。随之而来的是应用

程序的创新，从开放式对

话系统到使用自然语言

做模型解释等，不

一而足

。最后，这些进展让自然语

言处理在计算机视觉、推

荐系统等相关领域也取

得一席

之地。

随着自然语

言处理不断延伸到这些

令人振奋的新领域，学习

运用自然语言处理技术

的从业

人员也在不断增

加。我在加州大学圣迭戈

分校开设的数据科学课

程（CSE 258），是本校计

算机系参与

人数最多的课程。我发现

越来越多的学生选择自

然语言处理作为项目课

题。对

于希望使用自然语

言数据构建应用程序的

工程师、产品经理、科学家

、学生和爱好者，自

然语言

处理正在迅速成为一项

必备技能。一方面，自然语

言处理和机器学习的新

工具和

库，使得自然语言

建模比以往任何时候都

更容易。但另一方面，自然

语言处理的学习资源

又

必须面向这一数量不断

增长的多样化受众群体

。对于最近采用自然语言

处理的公司和首

次使用

自然语言数据的学生来

说，情况尤其如此。

在过去

的几年里，我很高兴与博

迪萨特瓦 • 马祖达尔合作

，在自然语言处理和对话

领域研

究令人兴奋的新

应用程序。因此，听说他与

索米亚

• 瓦贾拉、阿努杰 • 古

普塔和哈尔希特 •

苏拉纳

一起合写了一本关于自

然语言处理的书时，我十

分欣喜。他们在扩展自然

语言处理

方面拥有广泛

的经验，包括多个创业公

司、麻省理工学院媒体实

验室、微软研究院和谷歌

人工智能的经验。

让我感

到兴奋的是，书中采用了

端到端的方法，这种方法

适用于一系列场景，而且

使读者

在构建自然语言

处理应用程序时不至于

迷失在各种可能的选项

里。尤其令我感兴趣的是

，

他们不但重视聊天机器

人等现代自然语言处理

应用程序，还关注电商、零

售等跨学科主

题。这些主

题对于行业领导者和研

究人员特别有用，但大部

分现有的教科书只对这

些重要

的主题一笔带过

。这本书既可以作为新手

认识自然语言处理领域

的第一资源，也可以作为

老手探究这一领域最新

进展的实用指南，是理想

的自然语言处理学习参

考书。

——Julian McAuley 

加州大学圣迭戈分

校计算机科学与工程教

授

xvii

前言

自然语言处理（NLP）是

计算机科学、人工智能和

语言学的交叉学科。它关

注的是如何构

建能够处

理和理解人类语言的系

统。自 20 世纪 50 年代创立以来

直到最近，自然语言处理

主要是学术界和实验室

的阵地，掌握它需要长期

的正规教育和训练。但过

去十年的突破使

得自然

语言处理越来越多地应

用于零售、医疗、金融、法律

、市场营销和人力资源等

一系

列领域。这些进展背

后的推动力列举如下。

• 广

泛可用和易于使用的自

然语言处理工具、技术和

API 已经在这一行业遍地开

花。现

在正是快速构建自

然语言处理解决方案的

好时代。

• 更具可解释性和

通用性的方法改善了开

放式对话、问题回答等复

杂自然语言处理任务的

基准性能，这在以前是不

切实际的。

• 谷歌、微软和亚

马逊等越来越多的公司

在大力投资以语言为主

要交流媒介的交互性更

强

的消费产品。

•

不断增加

的开源数据集及其标准

基准，在这场变革中起到

了催化剂的作用（相反，仅

限

于个别组织和个人使

用的专有数据集则会起

到阻碍作用）。

• 自然语言处

理的可用性已经延伸到

英语以外的其他语言。对

于数字化程度较低的语

言，

数据集和基于特定语

言的模型也正在创建中

。这项工作的一个成果是

自动机器翻译，它

接近完

美，凡是有智能手机的人

都可以使用。

随着使用范

围的迅速扩大，搭建自然

语言处理系统的人也越

来越多。他们亟须克服经

验

不足和理论知识欠缺

的问题。这本书从应用的

角度解决了这种需求。本

书的目的是指导

读者在

业务场景中构建、迭代和

扩展自然语言处理系统

，并根据各个垂直行业进

行相应的

调整。

为什么要

写这本书

自然语言处理

这一主题下有很多畅销

书，其中一些用作教科书

，侧重于理论方面；另一些

则旨在通过大量代码示

例来介绍自然语言处理

的概念；还有一些则专注

于特定的自然语言

处理

库或机器学习库，并提供

使用这些库来解决不同

自然语言处理问题的“操

作指南”。

那么，为什么还要

再写一本关于自然语言

处理的书？

xix

十多年来，我们

一直在重点大学和头部

技术公司构建和扩展自

然语言处理解决方案。在

指

导同事和其他工程师

时，我们注意到新工程师

，尤其是自然语言处理新

手的个人技能和自

然语

言处理的行业标准之间

存在差距。后来我们为专

业人士举办了很多场自

然语言处理研

讨会，并从

中注意到，业务部和工程

部的负责人身上也存在

这种实际技能和行业标

准之间

的差距，这加深了

我们对此问题的理解。

大

多数在线课程和图书只

使用简单的用例和常见

的数据集（通常是干净且

定义良好的大型

数据集

）来解决自然语言处理问

题。虽然这样也能传授自

然语言处理的一般方法

，但是我

们不认为这样能

提供足够的基础知识来

解决新的问题，并在现实

世界中开发特定的解决

方

案。我们发现，在构建实

际应用程序时遇到的常

见问题，如数据收集、噪声

数据

/ 信号处

理、解决方案

的增量开发以及将解决

方案部署到大型应用程

序的相关问题，在现有的

资源

中并没有涉及。我们

还发现，在大多数情况下

，开发自然语言处理系统

的最佳实践也是缺

失的

。因此，我们认为需要写一

本书来补充相关知识，这

也是本书诞生的原因。

写

作理念

本书希望提供一

种整体和实用的视角，使

读者能够成功地构建真

实世界的自然语言处理

解

决方案，并将其嵌入更

大的产品系统中。因此，书

中的大部分章附有代码

练习。本书还补

充了大量

的参考资料，供感兴趣的

读者深入研究。全书处理

问题的思路更是采用行

业中的

普遍做法：先从简

单的解决方案开始，形成

最小可行产品（MVP）后，再逐步

构建更加复

杂的解决方

案。本书会根据作者自身

的经验和教训给出适当

的建议。每一章还会尽可

能讨

论相关专题的新进

展。大多数章的最后会给

出真实世界中的案例研

究。

以构建聊天机器人或

文本分类系统为例。在开

始阶段，可用的数据可能

很少，甚至没有。

此时，不妨

使用基于规则的系统或

传统的机器学习来构建

基本的解决方案。随着数

据的积

累，再使用深度学

习等更复杂的自然语言

处理技术（通常需要大量

数据）。在整个过程中，

每一

步都有许多不同的方法

可以选择。这本书将帮助

你在选择的迷宫中确定

方向。

内容范围

本书将以

全面的视角讲述如何构

建真实世界的自然语言

处理应用程序。从数据收

集一直到

模型部署和监

控，本书将涵盖一个典型

自然语言处理项目的完

整生命周期，其中一些步

骤

适用于任何机器学习

流水线，而有些步骤则是

自然语言处理所特有的

。本书还将介绍特定

于任

务的案例研究和特定于

领域的指南，便于从零开

始构建自然语言处理系

统。具体而

言，本书将介绍

从文本分类到问题回答

、从信息提取到对话系统

等一系列任务。同时，本

书

还提供将这些任务应用

于电子商务、医疗保健、社

交媒体和金融等各个领

域的方法。由

于主题和场

景的深度和广度，本书不

会一一解释每行代码和

每个概念。对于实现的细

节，

本书提供了详细的源

代码笔记本。书中的代码

片段只涵盖核心的逻辑

。一些介绍性的步

骤，如设

置库或导入包，已在相关

的笔记本中有所涉及，书

中通常会直接跳过。为了

涵盖

大量的概念，本书提

供了许多参考文献，方便

读者深入研究这些主题

。这本书既可作为日

常使

用的技术手册，让你从实

用的角度构建自然语言

处理系统，也可以作为进

阶参考，以

将自然语言处

理扩展到你自己的领域

。

xx

｜ 前言

目标读者

本书的目

标读者包括软件开发者

和测试人员、机器学习工

程师、数据工程师、机器学

习

运维工程师、自然语言

处理工程师、数据科学家

、产品经理、人事经理、副总

裁、各种

首席官和企业创

始人，以及参与数据创建

和标注的人。总而言之，无

论何人，无论以何

种方式

，凡是参与构建自然语言

处理系统的人，都可以阅

读本书。虽然并非所有的

内容

对所有的职位都有

用，但本书力求少用专业

术语，多用平实的语言来

给出清晰的解释。

我们相

信，每一位想要全面了解

如何构建自然语言处理

应用程序的读者，都能在

每一章

中有所收获。

有些

内容不需要太多的编程

经验就可以理解，代码片

段可以根据需要直接跳

过。例如，第

1

章和第 9 章的前

两节，以及第 11 章的 11.3

节和 11.4 节

，所有的读者群体都可以

理解，

不需要任何编程经

验。随着阅读的深入，你会

发现更多这样的内容。但

是，为了从本书、

代码笔记

本和参考文献中获得最

大的收获，我们希望读者

具备以下背景知识。

•

中级

Python 编程能力。例如，了解列表

推导式等 Python 特性，能编写函

数和类，能使

用现有的库

。

•

熟悉软件开发生命周期

（SDLC）的各个阶段，如设计、开发

、测试、运维等。

• 掌握机器学

习的基础知识，包括逻辑

回归、决策树等常用的机

器学习算法，并能在

Python 中使

用 scikit-learn

等库提供的现成算法

。

• 自然语言处理的基础知

识对于理解本书内容是

有用的，但不是必需的。对

文本分类、命

名实体识别

等任务有所了解，对于阅

读本书也是有帮助的。

你

将学到什么

本书的主要

受众是那些在不同垂直

领域构建真实自然语言

处理系统的工程师和科

学家。一

些常见的职位有

软件工程师、自然语言处

理工程师、机器学习工程

师和数据科学家。另

外，本

书对产品经理和工程主

管也有帮助。但是本书没

有深入讲解自然语言处

理各种概念

背后的理论

细节和技术细节，因此对

于从事自然语言处理前

沿研究的人来说，这本书

可能

帮助不大。通过阅读

本书，你将学到以下知识

及技能。

• 了解自然语言处

理中的各种问题、任务和

解决方案。

• 实现和评估不

同的自然语言处理应用

程序，并在此过程中应用

机器学习和深度学习方

法，

由此获得相关经验。

• 根

据业务问题和垂直行业

微调自然语言处理解决

方案。

•

给定自然语言处理

产品的任务、数据集和所

处阶段，评估各种算法和

方法。

• 规划自然语言处理

产品的生命周期，并根据

自然语言处理系统发布

、部署和运维的最佳

实践

来生成软件的解决方案

。

• 从业务和产品主管的角

度理解自然语言处理的

最佳实践、机会和路线图

。

本书还将介绍如何根据

医疗保健、金融和零售等

垂直行业的需求来调整

解决方案。此外，

本书还会

给出针对每个行业应用

的注意事项。

前言 ｜ xxi

xxii

｜ 前言

本

书结构

本书分为四个部

分。图 P-1 显示了其中的内容

组织。有些章是独立的，与

其他章没有直接

联系，阅

读时可以轻松跳过。

本书

结构

自然语言处理概要

聊天机器人

主题简介

第

一部分

基础

第二部分

核

心

第四部分

综合

第三部

分

应用

文本表示

文本分

类

电子商务与零售

社交

媒体

医疗、金融和法律

自

然语言处理流水线

信息

提取

端到端自然语言

处

理系统

图 P-1：本书结构

第一

部分

基础，是本书其余部

分的基础，给出了自然语

言处理的概述（第 1 章），讨论

了构建自然语言处理系

统时所用到的典型数据

处理和建模流水线（第 2 章

），并介绍了自

然语言处理

中文本数据的不同表示

方法（第

3 章）。

第二部分　核心

，重点介绍了最常见的自

然语言处理应用程序，并

强调了真实世界的用

例

。这些章会尽量就同一个

问题给出多个解决方案

，告诉你在不同的选项中

如何选择。这

些应用程序

包括文本分类（第

4 章）、信息

提取（第 5 章）和聊天机器人

（第 6 章）。另

外，这一部分还介

绍了搜索、主题建模、文本

摘要、机器翻译等其他应

用程序，并讨论了

实际的

用例（第 7 章）。

第三部分　应用

（第

8~10 章），侧重于大量使用自

然语言处理技术的三个

垂直行业，详细

讨论了这

些领域的具体问题以及

自然语言处理在解决这

些问题中的作用。

第四部

分　综合（第 11

章），通过端到端

部署自然语言处理系统

来处理所涉及的实际问

题，帮助读者将所学知识

融会贯通。

如何阅读本书

如何阅读本书取决于读

者的职业和目的。对于深

入研究自然语言处理的

数据科学家或工程

师，建

议阅读第 1~6 章，同时要特别

关注感兴趣的特定领域

或子问题。对于担任领导

角色

的读者，建议把注意

力集中在第

1、2 和 11 章，同时要

特别关注第 3~7 章的案例研

究，从

而全面了解从头开

始构建自然语言处理应

用程序的过程。对于产品

负责人，建议多关注相

关

内容的参考资料以及第

11 章。

第 3~7 章只介绍一般性的

问题。不同领域的自然语

言处理应用程序可能会

有所不同。因此

本书会侧

重某些领域，如电子商务

、社交媒体、医疗保健、金融

和法律。如果你的兴趣或

工作就在这些领域，不妨

深入挖掘这些内容和相

应的参考文献。

排版约定

本书使用如下排版约定

。

黑体字

表示新术语或重

点强调的内容。

等宽字体

（constant width）

表示程序片段，以及正文

中出现的变量名、函数名

、数据库、数据类型、环境变

量、语

句和关键字等。

等宽

粗体（constant width bold）

表示应该由用户输

入的命令或其他文本。

等

宽斜体（constant width italic）

表示应该由用户

输入的值或根据上下文

确定的值替换的文本。

该

图标表示提示或建议。

该

图标表示一般注记。

该图

标表示警告或警示。

前言

｜ xxiii

xxiv ｜ 前言

使用示例代码

如果

在使用示例代码时遇到

技术问题或难题，请发送

电子邮件至 errata@oreilly.com.cn。

这本书的目

的是帮助你完成工作。一

般来说，本书提供的示例

代码，可以在程序和文档

中

使用，不需要联系我们

获得许可，但大规模复制

本书代码的除外。例如，编

写程序使用了

本书中的

几段代码不需要获得许

可。出售或分发

O’Reilly 图书的示

例确实需要许可。引用

本

书和引用示例代码来回

答问题不需要获得许可

。在产品文档中大量借鉴

本书的示例代码

则需要

获得许可。

我们很希望但

不强制要求你在引用本

书的内容时加上引用说

明。引用说明通常包括标

题、

作者、出版商和

ISBN。例如，“Practical Natural Language Processing by Sowmya

Vajjala, 

Bodhisattwa Majumder, Anuj Gupta,

and Harshit Surana (O’Reilly). Copyright 2020

Anuj Gupta, 

Bodhisattwa Prasad Majumder,

Sowmya Vajjala, and Harshit Surana, 978-1-492-05405-4.”。

如

果你使用的示例代码超

出了合理使用或上面给

出的许可范围，请随时与

我们联系，邮箱

地址为 permissions@oreilly.com。

O’Reilly在

线学习平台（O’Reilly Online Learning）

40 多年来，O’Reilly Media 致力

于提供技术和商业培训

、知识和

卓越见解，来帮助

众多公司取得成功。

我们

拥有独特的由专家和创

新者组成的庞大网络，他

们通过图书、文章、会议和

我们的在

线学习平台分

享他们的知识和经验。O’Reilly 的

在线学习平台让你能够

按需访问现场培训

课程

、深入的学习路径、交互式

编程环境，以及 O’Reilly 和 200

多家其

他出版商提供的大

量文

本资源和视频资源。有关

的更多信息，请访问 https://www.oreilly.com。

联系

我们

如有与本书有关的

评价或问题，请联系出版

社。

美国：

O’Reilly Media, Inc.

1005 Gravenstein Highway

North

Sebastopol, CA 95472

中国：

北京市西城

区西直门南大街

2 号成铭

大厦 C 座 807 室（100035）

奥莱利技术咨

询（北京）有限公司

O’Reilly 的每一

本书都有专属网页，你可

以在那儿找到本书的相

关信息，包括勘误表 1、示

例

代码以及其他信息。

你还

可以发送电子邮件至

errata@oreilly.com.cn 评

论或询问与本书有关的

技术问题。

注 1：也可以通过

图灵社区提交中文版勘

误：ituring.cn/book/2818。——编者注

要了解更多 O’Reilly

图

书、培训课程、会议和新闻

的信息，请访问以下网站

：https://www.

oreilly.com。

我们在 Facebook 的地址如下：http://facebook.com/oreilly。

请关

注我们的

Twitter 动态：http://twitter.com/oreillymedia。

我们的 YouTube 视

频地址如下：http://www.youtube.com/oreillymedia。

更多信息

自

然语言处理的世界总是

在不断发展。未来一年、两

年甚至五年，书中提到的

概念将会发

生怎样的演

变，要了解这些，请关注我

们。我们会及时更新相关

的作品和文章，并为每一

篇文章加上本书相应的

章标题或节标题。

本书作

者电子邮件：authors@practicalnlp.ai。

致谢

本书是

各种知识的汇编。因此，它

不可能独立存在。在写这

本书的时候，我们从若干

图

书、研究论文、软件项目

和互联网上众多的其他

资源中汲取了大量的灵

感和信息。我们感

谢自然

语言处理和机器学习社

区所做的一切努力，我们

的工作只不过是站在这

些巨人的肩

膀上。还要感

谢出席作者会谈、讲习班

并参与讨论的各位人士

，是他们塑造了本书的写

作

思路和前提。这本书是

长期合作的结果，很多人

以不同的方式支持我们

。

感谢 O’Reilly 审稿人

Will Scott、Darren Cook、Ramya Balasubramaniam、Priyanka Raghavan

和

Siddharth Narayanan 提出的审

慎、宝贵和详细的意见，帮

助我们改进了前期的草

稿。

Siddharth Sharma、Sumod Mohan、Vinayak

Hegde、Aasish Pappu、Taranjeet Singh、Kartikay 

Bagla 和

Varun Purushotham 提供的详细反馈帮

助提升了本书的内容质

量。

也非常感谢 Rui Shu、Shreyans

Dhankhar、Jitin Kapila、Kumarjit Pathak、Ernest Kirubakaran 

Selvaraj、Robin

Singh、Ayush Datta、Vishal Gupta 和 Nachiketh 帮助我

们编写了早期版本的

代

码笔记本。特别感谢 Varun Purushotham，他花

了几个星期的时间反复

审阅我们的草稿，

并编写

和核查代码笔记本。如果

没有他的贡献，这本书就

不会如此出色。

还要感谢

O’Reilly Media

团队，这本书的顺利出版

离不开他们。Jonathan Hassell 给了我们出

版

这本书的机会；Melissa Potter 在整个

出版过程中定期跟进我

们，并耐心回答我们所有

的问题。

Beth Kelly 和 Holly Forsyth 提供各种帮助

和支持，将各章零散的草

稿组合成一本完整的书

。

最后，以下是每位作者个

人的致谢。

索米亚 • 瓦贾拉

首先感谢我的女儿 Sahasra Malathi，从她

出生到一岁正好是我写

这本书的

时候。写一本书

不容易，在要照顾一个新

生儿的情况下，这尤其不

容易。然而，我们到达目

的

地了。谢谢你，Sahasra ！另外，我的母

亲 Geethamani 和丈夫 Sriram

在我写作期间

分担了

照顾孩子和做家

务的重担。我的朋友 Purnima 和 Visala 随

时倾听我的最新进展和

抱怨。我的

老板 Cyril Goutte 一直鼓励

我，并检查我的写作进度

。最后，我从与前同事 Chris Cardinal

和

Eric Le Fort 的

讨论中学到了很多为行

业问题开发自然语言处

理解决方案的知识，如果

没有这

些讨论，我可能永

远不会想到这些知识会

成为本书的一部分。我感

谢他们所有人的支持。

前

言 ｜ xxv

博迪萨特瓦 • 马祖达尔

我想借此机会感谢我的

父母，感谢他们无可置疑

的牺牲，以及不

断的鼓励

，是他们成就了今天的我

。他们潜移默化地影响着

我，让我在生活中形成了

热

爱学习的习惯。我永远

感谢导师 Animesh Mukherjee 教授和 Pawan

Goyal 教授，是

他们带

领我走进了自然

语言处理的世界。还有 Julian McAuley 教

授，在我的读博生涯中，他

对我

的技术、学术和个人

发展起着至关重要的作

用。Taylor Berg-Kirkpatrick、Lawrence Saul、

David Kriegman、Debasis Sengupta、Sudeshna

Sarkar 和 Sourav Sen Gupta 等教授所开的课

程

塑造了我对这门学科的

研究思路。在这本书的写

作早期，我在沃尔玛实验

室的同事，特

别是 Subhasish Misra、Arunita Das、Smaranya Dey、Sumanth

Prabhu 和 Rajesh Bhat 给了

我

实现这个疯狂想法的

动力。感谢我在谷歌人工

智能、微软研究院、亚马逊

Alexa

的导师们，

以及我在加州

大学圣迭戈分校自然语

言处理小组实验室的伙

伴们，感谢你们在整个过

程中

给予的支持和帮助

。另外，必须提一下我的朋

友 Sanchaita Hazra、Sujoy Paul

和 Digbalay 

Bose，在这个庞大的项目

中，他们在任何情况下都

支持我。最后，如果没有我

的合著者的

帮助，这一切

都是不可能的，他们相信

这个项目，并团结奋斗到

最后一刻。

阿努杰

• 古普塔

首先，我想对我的妻子 Anu 和

我的儿子 Nirvaan 表示衷心的感

谢。没有

他们的坚定支持

，我不可能在过去三年中

致力于这项工作。我还要

感谢父母和家人的鼓励

。

我要大声感谢 Saurabh Arora，是他带领

我走进了自然语言处理

的世界。非常感谢我的朋

友，

已故的 Vivek

Jain 和 Mayur Hemani，他们总是鼓

励我坚持下去，尤其是在

写作的困难时

期。我还要

感谢所有参与班加罗尔

机器学习社区的杰出人

士，特别是 Sumod

Mohan、Vijay 

Gabale、Nishant Sinha、Ashwin Kumar、Mukundhan Srinivasan、Zainab

Bawa 和 Naresh Jain

进行了精彩

且发人深省的讨论。我要

感谢以前和现在在 CSTAR、Airwoot、FreshWorks、华

为

研究院、Intuit 和 Vahan 公司的同事们

，感谢他们教给我的一切

。感谢我的教授 Kannan

Srinathan、P.R.K Rao 和 B. Yegnanarayana，他们的

教导对我产生了深远的

影响。

哈尔希特

• 苏拉纳　我

要感谢父母，是他们支持

并鼓励我去追求每一个

疯狂的想法。我对我

亲爱

的朋友 Preeti Shrimal

和 Dev Chandan 感激不尽。在这

本书的整个写作过程中

，他们一直

陪伴着我。感谢

我的联合创始人 Abhimanyu

Vyas 和 Aviral Mathur，他们

为了帮助我完成这

本书

而调整了创业计划。感谢

我在 Quipio

和 Notify.io 的所有前同事，他

们帮助我厘清了思

路，特

别是 Zubin Wadia、Amit

Kumar 和 Naveen Koorakula。如果没有我的老

师和他们教给我

的一切

，这一切都不可能实现。谢

谢你们，Luis von

Ahn、Anil Kumar Singh、Alan W Black、

William

Cohen、Lori Levin 和 Carlos Guestrin 教授。我还要感

谢

Kaustuv DeBiswas、Siddharth 

Narayanan、Siddharth Sharma、Alok Parlikar、Nathan

Schneider、Aasish Pappu、Manish Jawa、

Sumit Pandey 和

Mohit Ranka，他们在我这段写作

旅程的每个时刻都给予

我支持。

电子书

扫描如下

二维码，即可购买本书中

文版电子书。

xxvi ｜

前言

第一部

分

基础

第 1 章

自然语言处

理概要

语言不仅仅是文

字。它还是一种文化，一种

传统，一个群体的一致性

，一段塑造

了群体面貌的

完整历史。所有这些都体

现在一种语言中。

——诺姆 • 乔

姆斯基

想象一个虚构的

人物：约翰。他在一家快速

发展的科技创业公司担

任首席技术官。在繁忙

的

一天，约翰醒来后，与数字

助理进行了以下对话。

约

翰：“今天天气怎么样？”

数字

助理：“今天外面 37℃，没有下雨

。”

约翰：“我的日程安排是怎

样的？”

数字助理：“您下午 4:00 有

一个战略会，下午 5:30 有一个

全体员工会议。根据今

天

的交通状况，建议您在上

午

8:15 之前出发去办公室。”

约

翰一边穿衣服，一边向助

理打听他的着装选择。

约

翰：“我今天该穿什么衣服

？”

数字助理：“白色似乎是个

不错的选择。”

你可能已经

使用亚马逊

Alexa、谷歌 Home 或 Apple Siri 等智

能助手来做类似的事情

了。我

们和这些智能助手

交谈，不是通过编程语言

，而是通过自然语言——一种

人与人交流所采

用的语

言。自远古以来，自然语言

一直是人类交流的主要

媒介。但是计算机只能处

理由 0

和 1 组成的二进制数

据。虽然语言数据可以用

二进制来表示，但是如何

让机器理解语言

呢？这就

产生了一个新的领域：自

然语言处理（natural language processing, NLP）。自然语

言处

理是计算机科学的一个

分支领域，它研究的是分

析、建模和理解人类语言

的方法。每

3

4 ｜ 第 1 章

一个涉及

人类语言的智能应用程

序，背后都有一定程度的

自然语言处理。本书将解

释什么

是自然语言处理

，以及如何使用自然语言

处理来构建和扩展智能

应用程序。由于自然语言

处理问题的开放性，同一

个问题可能有几十种备

选方案。这本书将帮助你

在迷宫里确定方

向，并根

据问题找到最佳选项。

本

章的目的是简要介绍什

么是自然语言处理，方便

后续内容深入研究如何

在不同的应用场

景中实

现基于自然语言处理的

解决方案。本章首先概述

真实场景中的各种自然

语言处理应

用程序，接着

介绍自然语言处理应用

程序背后的各种基础任

务。接下来，从自然语言处

理

的角度来介绍语言是

什么，以及自然语言处理

为什么很难。随后，概述启

发式、机器学习

和深度学

习，并介绍自然语言处理

的几种常用算法。然后是

自然语言处理应用程序

的演

练。本章的最后会简

要介绍本书的其余主题

。图 1-1 从自然语言处理任务

和应用程序两方

面梳理

了本书的组织结构。

文本

分类

信息提取 对话智能

体 信息检索 问答系统

垃

圾邮件

分类

日历事件

提

取 个人助理 搜索引擎 问

答节目

社交媒体

分析

零

售产品

提取

健康记录

分

析 金融分析

法律实体

提

取

核心任务

（第4~7章）

通用应

用

（第4~7章）

具体行业应用

（第

8~10章）

图 1-1：从自然语言处理任

务和应用程序梳理的组

织结构

在日常生活中，很

多应用程序使用了某种

形式的自然语言处理作

为主要组件，下面先来看

其中的一些。

1.1

真实世界中

的自然语言处理

自然语

言处理是日常生活中各

种软件应用程序的重要

组成部分。这一节将介绍

其中的一些

关键应用程

序，以及不同应用程序中

的一些通用任务。本节会

补充图 1-1 所示的应用程序

，

后续内容也会详细介绍

。

核心应用程序

• 电子邮件

平台，如 Gmail、Outlook 等，广泛使用自然

语言处理来提供垃圾邮

件分类、

智能收件箱、日历

事件提取、输入自动补全

等一系列产品功能。第

4 章

和第 5 章将详细

讨论其中

的一些功能。

•

语音助手，如

Apple Siri、谷歌 Assistant、微软 Cortana 和亚马逊 Alexa，依赖

于一系列

自然语言处理

技术来与用户交互，理解

用户命令，并依此做出响

应。第 6 章将讨论这类

系统

的核心技术。

• 现代搜索引

擎，如谷歌搜索和微软必

应搜索，作为当今互联网

的基石，大量使用自然语

言处理技术来处理各种

子任务，例如查询理解、查

询扩展、问题回答、信息检

索，以及

结果排序、分组等

。第 7 章将讨论其中的一些

子任务。

• 机器翻译服务，如

谷歌翻译、微软必应翻译

和亚马逊翻译，在当今世

界越来越多地用于

各种

场景和业务用例。这些服

务是自然语言处理的直

接应用。第

7 章将介绍机器

翻译。

其他应用程序

• 很多

垂直行业的公司通过分

析社交媒体帖文，加深对

客户声音的理解。第 8

章将

讨论这

个问题。

• 自然语言

处理广泛用于亚马逊等

电商平台的各种用例，例

如提取产品描述中的相

关信

息、理解用户评论等

。第 9

章将详细介绍这些内

容。

• 自然语言处理的最新

进展正在应用于医疗、金

融和法律等领域。第 10 章会

讨论这些

问题。

• 一些公司

正在致力于使用自然语

言处理技术自动生成天

气预报、金融服务等各个

领域的

报告。

• 自然语言处

理是拼写和语法纠正工

具的重要基础，例如 Grammarly

和微

软 Word、谷歌

文档中的拼写检

查器。

• Jeopardy! 是美国一个很受欢

迎的电视问答节目。在节

目中，参赛者会得到以答

案形式

提供的各种线索

，然后必须以问题的形式

作答。为了战胜该节目的

顶级玩家，IBM 打

造了“沃森”人

工智能系统。最后，沃森获

得一等奖，赢得奖金 100 万美

元，这个金额

比人类冠军

还多。沃森是使用自然语

言处理技术构建的，是自

然语言处理机器人战胜

人

的一个例子。

• 自然语言

处理用于一系列学习和

评估的工具和技术，例如

考试自动评分（如 GRE）、剽

窃检

测（如 Turnitin

论文查重）、智能辅导

系统和语言学习应用程

序（如多邻国）。

• 自然语言处

理用于构建大型知识库

，例如谷歌知识图谱，这些

知识库在搜索和问答等

一

系列应用程序中都很

有用。

这份清单绝非详尽

无遗。自然语言处理在其

他领域的应用越来越广

泛，新的应用程序也在

不

断涌现。本书的重点是介

绍构建这些应用程序背

后的思想。具体来说，本书

会讨论不同

类型的自然

语言处理问题以及如何

解决这些问题。为了对本

书的学习内容有一个直

观的认

识，并理解构建不

同自然语言处理应用程

序的细微差别，下面先来

看看众多自然语言处理

应用程序和行业用例背

后的一些基础任务。

自然

语言处理任务

在各种自

然语言处理项目中，有些

基本任务会频繁出现。因

其重复性和基础性，这些

任务

得到了广泛的研究

。掌握好这些基础任务，有

助于在垂直领域构建各

种自然语言处理应用

程

序。前面的图

1-1 已经展示了

其中的一些任务。下面简

单介绍一下这些任务。

自

然语言处理概要 ｜ 5

语言模

型

语言模型是根据句子

中的前一个词来预测下

一个词的任务。这项任务

的目标是学习词序

列在

给定语言中出现的概率

。语言模型可用于构建语

音识别、光学字符识别、手

写识

别、机器翻译和拼写

更正等一系列问题的解

决方案。

文本分类

文本分

类是根据文本内容将文

本分类为某个已知类别

的任务。文本分类是目前

自然语言

处理中最受欢

迎的任务，被广泛应用于

垃圾邮件识别、情感分析

等各种工具中。

信息提取

顾名思义，信息提取是从

文本中提取相关信息的

任务，例如从电子邮件中

提取日历事件

或从社交

媒体帖文中提取人名等

。

信息检索

信息检索是根

据用户查询在大量文档

中找到相关文档的任务

。像谷歌搜索这样的应用

程

序是信息检索的著名

用例。

对话智能体

对话智

能体是构建能够用人类

语言交谈的对话系统的

任务。Alexa、Siri 等是这个任务

下的

常见应用程序。

文本摘要

文本摘要是根据长篇文

档生成简短摘要的任务

，同时保留文本的核心内

容和整体含义。

问题回答

问题回答任务是构建一

个系统，能够自动回答用

自然语言提出的问题。

机

器翻译

机器翻译是把一

段文字从一种语言转换

成另一种语言的任务。像

谷歌翻译这样的工具是

这项任务的常见应用程

序。

主题建模

主题建模是

发掘大量文档的主题结

构的任务。主题建模是一

种常见的文本挖掘工具

，广

泛应用于文学研究、生

物信息学等一系列领域

。

图 1-2

显示了这些任务，它们

按照开发综合解决方案

的难易程度排序。

6 ｜ 第 1 章

容

易

拼写检查

基于关键词

的信息检索

主题建模

文

本分类

信息提取

中等

封

闭式对话智能体

文本摘

要

问题回答

机器翻译

开

放式对话智能体

困难

图

1-2：按难易程度排序的自然

语言处理任务

接下来的

内容将展示这些任务的

挑战，并介绍如何开发适

用于特定用例（甚至是图

1-2 中

所示的“困难”任务）的解

决方案。在此之前，先简要

介绍一下人类语言的本

质和自动化

语言处理的

挑战。

1.2　什么是语言

语言是

一种结构化的交流系统

，它涉及字、词、句等成分的

复杂组合。语言学是对语

言的

系统研究。为了研究

自然语言处理，必须首先

了解语言学中有关语言

结构的一些概念。本

节将

介绍这些概念，以及它们

与上文中部分自然语言

处理任务的关系。

可以认

为，人类语言主要由音素

、词素

/ 词位、句法和语境四

个基本模块组成。自然语

言

处理应用程序需要获

得语言的基本发音（音素

）一直到文本的意义（语境

）等不同层次的

知识。图 1-3 显

示了这些语言模块，它们

所包含的内容，以及需要

这些知识的自然语言处

理应用程序。句法解析、词

嵌入等术语之前没有介

绍过，本章后面以及第

2 章

和第 3 章会

相应介绍。

自然

语言处理概要

｜ 7

8 ｜ 第 1

章

语境

语言模块 应用程序

意义

文本摘要

主题建模

情感

分析

句法解析

实体提取

关系提取

分词

词嵌入

词

性标注

语音转文本

说话

人识别

文本转语音

词素

和词位

词

音素

语音和声

音

句法

短语和句子

图 1-3：语

言模块及对应的应用程

序

1.2.1　语言的基本模块

下面

先介绍语言的基本模块

，为读者理解自然语言处

理的挑战提供必要的背

景知识。

1. 音素

音素是最小

的语音单位。音素本身可

能没有任何意义，但音素

组合使用时可以产生意

义。例如，

标准英语有 48

个音

素，有的是单个字母，有的

是字母组合。图 1-4 显示了部

分词例。音素

在语音识别

、语音转文本和文本转语

音等涉及语音理解的应

用程序中尤其重要。

（非重

读元音，

接近/u/）

辅音音素及

词例 元音音素及词例

图

1-4：音素（非国际音标）及词例

2. 词素和词位

词素是最小

的语义单位，由音素组合

而成。词素并非都是词，但

前缀和后缀都是词素。例

如，在英语单词“multimedia”中，“multi-”不是一

个词，而是一个前缀，当它

与单词

“media”放在一起时，会改

变该词的意思。“multi-”是一个词

素。图 1-5 展示了四个单词

及

其词素。对于“cats”和“unbreakable”这样的词

来说，词素就是词的一部

分，而对于

“tumbling”和“unreliability”这样的词，在

把它们分解成词素时，词

素会有所变化，不再

是词

的一部分。

图 1-5：词素示例

词

位和词素意思相近，但结

构稍有不同。例如，“run”和“running”具有

相同的词位。词

形分析是

通过研究词素和词位来

分析词的结构，是分词、词

干提取、学习词嵌入、词性

标

注等许多自然语言处

理任务的基础模块，下一

章会介绍这些任务。

3.

句法

句法是用语言中的词汇

和短语来构造语法正确

的句子的一组规则。语言

学中的句法结构有

很多

不同的表示方式。表示句

子的一种常用方法是解

析树。图 1-6 展示了两个英语

句子的

解析树。

图

1-6：具有相

似句法结构的两个句子

句法解析树显示了语言

的层次结构，最低层次的

是词，然后是词性标签，接

着是短语，最

后是最高层

次的句子。在图 1-6 中，两个句

子具有相似的结构，因此

也具有相似的句法解

析

树。在句法解析表示中，N 代

表名词，V

代表动词，P 代表介

词。名词短语用 NP 表示，

自然

语言处理概要 ｜

9

动词短语

用 VP 表示。在图 1-6 中，两个名词

短语是“The

girl”和“The boat”，两个动

词短语

是“laughed at the monkey”和“sailed

up the river”。句法结构由一组语

法规则指导

（例如，句子 S 包

括

NP 和 VP），这反过来指导句法

解析等基本的语言处理

任务。句法解析

就是自动

构造此类句法树的自然

语言处理任务。实体提取

和关系提取是建立在句

法解析知

识基础上的自

然语言处理任务，第 5

章将

详细讨论这些任务。注意

，上面描述的句法解析

结

构是针对英语的。语言不

同，句法可能截然不同，所

需的语言处理方法也会

随之改变。

4. 语境

语境是语

言的各个部分组合在一

起能传达特定的意义。语

境包括远距离指代、世界

知识、

常识以及词汇和短

语的字面意义。由于词汇

和短语有时具有多种含

义，句子的意义可随语

境

变化。语境通常由语义和

语用组成。语义是词和句

子的直接意义，不考虑外

部语境。语

用则增加了对

话的世界知识和外部语

境，从而可以推断隐含的

意义。讽刺检测、摘要、主

题

建模等复杂的自然语言

处理任务都严重依赖语

境。

语言学是研究语言的

学科，因此它本身就是一

个广阔的领域。这里仅介

绍部分基本概念，

旨在说

明语言知识在自然语言

处理中的作用。不同的自

然语言处理任务需要不

同程度的语

言模块的知

识。在对语言模块有了基

本的了解之后，下面来看

为什么计算机很难理解

语

言，以及为什么自然语

言处理很困难。

1.2.2　为什么自

然语言处理很困难

为什

么自然语言处理很困难

？人类语言充满歧义性和

创造性，仅仅是这两个特

点，就大大

提高了自然语

言处理的门槛。本节从语

言的歧义性开始，详细地

探讨自然语言的每一个

特点。

1.

歧义性

歧义性是指

意义的不确定性。大多数

人类语言天生就是模棱

两可的。考虑这个句子，“I 

made her duck.”。这

个句子有多个意思。第一

个意思：我给她做了一只

鸭子。第二个意思：

我让她

弯下腰去躲避一个物体

。可能还有其他意思，这里

留给读者去思考。句子的

歧义来

自“made”一词。这句话到

底适用于哪种意思，取决

于句子出现的语境。如果

出现在一个

母亲和孩子

的故事中，那么第一个意

思可能适用。但如果出现

在一本体育书中，那么第

二

个意思很可能适用。这

个例子是一个直接的句

子。

当使用成语或其他修

辞时，歧义只会增加。例如

：“他和约翰一样好。”试着回

答：“他有

多好？”答案取决于

约翰有多好。图

1-7 展示了语

言歧义的一些例子。

10 ｜ 第 1

章

自然语言处理概要 ｜ 11

谁很

虚弱？

谁很重？

玛丽和休是

什么关系？

谁获得了帮助

？

谁提供了帮助？

谁一小时

后走了？

那个人举不动他

儿子，

因为他很虚弱。

那个

人举不动他儿子，

因为他

很重。

玛丽和休是姐妹。

玛

丽和休是母亲。

琼一定要

感谢苏珊，

因为她获得了

帮助。

琼一定要感谢苏珊

，

因为她提供了帮助。

约翰

答应比尔离开，

所以一小

时后他走了。

约翰命令比

尔离开，

所以一小时后他

走了。

图

1-7：威诺格拉德模式

挑战赛中的语言歧义示

例

这些例子来自威诺格

拉德模式挑战赛（Winograd Schema Challenge），该挑战

赛以斯坦福大

学威诺格

拉德教授的名字命名。该

模式有成对的句子，句子

之间只有几个词的差别

，但是

句子的意思经常因

为这种微小的变化而翻

转。人很容易消除这些例

子的歧义，但大多数自

然

语言处理技术做不到。考

虑图 1-7 中的句子对以及与

之相关的问题。稍加思考

后就能看

出，一个词的改

动就能改变问题的答案

。再做一个实验，考虑使用

一个现成的自然语言处

理系统，比如谷歌翻译，并

尝试各种例子，看看这种

歧义性是否会影响系统

的输出。

2. 常识

人类语言的

一个重要方面是“常识”，常

识是大多数人知道的所

有事实的集合。在任何对

话中，都假定这些事实是

已知的，因此它们不会被

明确地提及，但会对句子

的意思产生影

响。例如，考

虑这两句话，“人咬狗”和“狗

咬人”。我们都知道第一句

话所说的情况不

太可能

发生，而第二句所说的情

况是很可能发生的。为什

么这么说？这是因为我们

都“知

道”人不太可能咬狗

。此外，我们还知道狗会咬

人。说第一句不太可能发

生，而第二句是

可能的，就

需要这样的知识。请注意

，这两个句子都没有提到

这个常识。人类时刻都使

用

常识来理解和处理任

何语言。在上面的例子中

，这两个句子在句法上非

常相似，但是计算

机很难

区分这两个句子，因为计

算机缺乏人类所拥有的

常识。自然语言处理中的

一个重要

挑战就是，如何

在计算模型中编码所有

对人类来说是常识的知

识。

3. 创造性

语言不仅仅是

规则驱动的，它还有创造

性的一面。任何语言都会

有各种风格、方言、体裁

和

变体。诗歌是语言创造性

的一个很好的例子。让机

器理解创造性，这不仅在

自然语言处

理领域，而且

在整个人工智能领域都

是一个难题。

4. 语言的多样

性

对于世界上的大多数

语言来说，任何两种语言

的词汇表之间都没有直

接的映射。因此很难

将自

然语言处理解决方案从

一种语言移植到另一种

语言。适用于一种语言的

解决方案可能

根本不适

用于另一种语言。这意味

着，要么构建一个与语言

无关的解决方案，要么需

要为

每种语言构建单独

的解决方案。前者在理论

上非常困难，后者则费时

费力。

上述所有这些问题

，使得自然语言处理成为

一个具有挑战性但值得

研究的领域。在研究自

然

语言处理如何应对这些

挑战之前，需要先了解解

决自然语言处理问题的

常见方法。在深

入研究自

然语言处理的不同方法

之前，下面先简单介绍一

下机器学习和深度学习

与自然语

言处理的关系

。

1.3

机器学习、深度学习和自

然语言处理：概述

笼统地

说，人工智能（AI）是计算机科

学的一个分支，它旨在构

建能够执行需要人类智

能

的任务的系统。人工智

能有时也叫“机器智能”。20 世

纪 50 年代，达特茅斯学院组

织的研

讨班奠定了人工

智能的基础。最初的人工

智能在很大程度上是基

于逻辑、启发式和规则构

建的。机器学习（ML）是人工智

能的一个分支，它研究的

是无须人工编写规则，直

接从

大量样例中自动学

习执行任务的算法。深度

学习（DL）是机器学习的一个

分支，它以人工

神经网络

结构为基础。机器学习、深

度学习和自然语言处理

都是人工智能的子领域

，它们

之间的关系如图 1-8 所

示。

AI：人工智能

 ML：机器学习

NLP：自

然语言处理

DL：深度学习

图

1-8：自然语言处理、机器学习

和深度学习之间的关系

12

｜ 第 1 章

尽管自然语言处理

、机器学习和深度学习存

在一定的重叠，但它们也

是非常不同的研究领

域

，如图

1-8 所示。和人工智能的

其他领域类似，早期的自

然语言处理应用程序也

是基于

规则和启发式的

。然而，在过去的几十年中

，自然语言处理应用程序

的开发受到了机器学

习

方法的深刻影响。最近，深

度学习也被频繁地用于

构建自然语言处理应用

程序。考虑到

这一点，本节

会对机器学习和深度学

习做一个简短的介绍。

机

器学习的目标是在没有

明确指令的情况下，基于

样例（称为“训练数据”）来“学

习”

执行任务。具体而言就

是创建训练数据的数值

表示（称为“特征”），并使用数

值表示来学

习样例中的

模式。机器学习算法可以

归结为三种主要的范式

：监督学习、无监督学习和

强

化学习。在监督学习中

，大量样例以“输入 – 输出”对

的形式给定，目标是学习

从输入

到输出的映射函

数。“输入

– 输出”对被称为训

练数据，而输出被专门称

为标签或真实值

（ground truth）。例如，分

别给定垃圾邮件和非垃

圾邮件的数千个样例，然

后学习将电子邮

件分类

为垃圾邮件或非垃圾邮

件，这个问题就是语言领

域的监督学习。监督学习

是自然语

言处理的常见

场景，监督学习的示例会

贯穿本书，特别是第

4 章。

无

监督学习是指在没有任

何参考输出的情况下，发

现给定输入数据中隐藏

模式的机器学习

方法。也

就是说，与监督学习不同

的是，无监督学习处理的

是大量的未标注数据。在

自然

语言处理中，这类任

务的一个例子是，在不知

道主题的情况下识别大

量文本数据集合中的

潜

在主题。这叫主题建模，第

7

章会讨论它。

在真实的自

然语言处理项目中，常见

的是半监督学习：有一个

小的标注数据集和一个

大的

未标注数据集。半监

督技术就是使用这两个

数据集来学习手头的任

务。最后，强化学习是

指通

过试错法来学习任务的

方法，其特点是缺少大量

的标注数据或未标注数

据。学习是在

一个自给自

足的环境中完成的，并通

过环境提供的奖励或惩

罚反馈来改进。这种学习

形式

在自然语言处理应

用程序中还不常见。它在

围棋或国际象棋等机器

游戏、自动驾驶车辆设

计

和机器人技术等应用程

序中更为常见。

深度学习

是机器学习的一个分支

，它基于人工神经网络结

构。神经网络背后的思想

灵感来

自人脑神经元及

其相互连接。在过去的十

年里，基于深度学习的神

经网络结构已经被成功

地用于提高图像识别、语

音识别、机器翻译等各种

智能应用程序的性能。这

导致了基于深

度学习的

解决方案在行业中大量

涌现，包括在自然语言处

理领域中的应用。

本书后

面会讨论如何使用上述

所有这些方法来开发各

种自然语言处理应用程

序。接下来介

绍解决任何

给定自然语言处理问题

的不同方法。

1.4　自然语言处

理方法

解决自然语言处

理问题的方法通常分为

三类：启发式、机器学习和

深度学习。本节只对每

种

方法做简单介绍。这些概

念即使不能全部掌握，也

没关系，后面的内容还会

详细讨论。

下面先从启发

式方法开始。

1.4.1

基于启发式

的自然语言处理

和其他

人工智能系统类似，早期

的自然语言处理系统也

是基于规则设计的。这就

要求开发

人员具有相关

领域的专业知识，才能制

定规则并整合到程序中

。另外，这类系统还需要词

自然语言处理概要 ｜ 13

典、同

义词库等资源，这些资源

的编写和数字化通常需

要一定的时间。使用这些

资源设计

规则来解决自

然语言处理问题的一个

例子是基于词汇的情感

分析。它利用文本中正向

词和

负向词的计数来推

断文本的情感。第 4 章将简

要介绍这部分内容。

除了

词典和同义词库外，自然

语言处理，特别是基于规

则的自然语言处理，还需

要构建

更详细的知识库

。例如

WordNet，它是单词及其语义

关系的数据库。这种语义

关系包括同

义词、下义词

和部分词。同义词是指意

思相近的词。下义词捕捉

的是从属关系。例如，棒

球

、相扑和网球是体育的下

义词。部分词捕捉的是部

分和整体的关系。例如，手

和腿是身

体的部分词。在

构建基于规则的语言系

统时，所有这些信息都会

派上用场。图 1-9 展示了

一个

WordNet 的示例。

图 1-9：单词“SPORT”的 WordNet 图示

近

期，常识和世界知识也被

纳入知识库，如“开放思维

常识库”，这也有助于构建

基于规

则的系统。虽然上

面的词汇资源主要是基

于词汇信息的，但是基于

规则的系统完全可以突

破词汇的限制，整合其他

形式的信息。下面介绍其

中的一些。

对于文本分析

和构建基于规则的系统

，正则表达式（regex）是一个很好

的工具。正则

表达式是一

组字符或一个模式，用于

匹配和查找文本中的子

字符串。例如，正则表达式

'^([a-zA-Z0-9_\-\.]+)@([a-zA-Z0-9_\-\.]+)\.([a-zA-Z]{2,5})



$' 可用于查找文本中所有

14 ｜ 第 1 章

的电子邮件地址。正则表达式是将领域知识整合到自然语言处理系统的一种好方法。例

如，如果顾客通过聊天或电子邮件投诉，那么如何构建一个系统来自动识别顾客所投诉的

产品？如果现在有一系列的产品代码可以映射到特定的品牌名称，那么使用正则表达式就

可以轻松地匹配这些。

正则表达式是构建基于规则的系统的常见范式。自然语言处理软件 StanfordCoreNLP 自带

的 TokensRegex 是一个定义正则表达式的框架。它用于识别文本中的模式，并使用匹配到

的文本来创建规则。正则表达式用于确定性匹配，这意味着它要么匹配，要么不匹配。概

率正则表达式是正则表达式的一个分支，它通过增加匹配概率来克服这一缺陷。感兴趣的

读者可以查看 pregex 等软件库。

上下文无关语法（context-free grammar, CFG）是一种用于自然语言建模的形式语法。CFG

由著名语言学家和科学家诺姆 • 乔姆斯基教授发明。CFG 可用于捕获正则表达式可能无法

捕获的复杂和层次化的信息。例如，Earley 解析器可以解析各种 CFG。如果要对更复杂的

规则建模，可以使用 JAPE（Java 注解模式引擎）等语法语言。JAPE 兼具正则表达式和

CFG 的特性，可用于基于规则的自然语言处理系统，如 GATE（文本工程通用架构）。对

于定义明确的封闭域，准确率和全覆盖更为重要，因此可用 GATE 构建文本提取。例如，

JAPE 和 GATE 曾用于起搏器植入手术临床报告的信息提取。图 1-10 显示了 GATE 界面：

文本中有几类信息得到了突出显示。

图 1-10：GATE 工具

即使是现在，规则和启发式在自然语言处理项目的整个生命周期中仍然发挥着一定的作

用。在项目的开始阶段，规则和启发式是构建自然语言处理系统最初版本的好方法。简单

自然语言处理概要 ｜ 15

地说，规则和启发式有助于快速构建模型的第一个版本，帮助理解手头的问题。第 4 章和

第 11 章将深入讨论这一点。在项目的中间阶段，对于基于机器学习的自然语言处理系统，

规则和启发式可以用于提取特征。在项目的最后阶段，规则和启发式可以堵住系统的漏

洞。任何使用统计、机器学习或深度学习技术构建的自然语言处理系统都难免出错，有些

错误可能会导致严重的损失。例如，如果一个医疗保健系统查看了某个患者的所有医疗记

录，却错误地决定不建议进行关键检查，那么这种错误甚至可能会让人付出生命的代价。

规则和启发式是堵住生产系统中这类漏洞的好方法。接下来我们换一个话题，讨论用于自

然语言处理的机器学习技术。

1.4.2　用于自然语言处理的机器学习

和图像、语音、结构化数据等其他形式的数据一样，文本数据也可以使用机器学习技术。

分类、回归等有监督的机器学习技术已经大量用于各种自然语言处理任务。例如，将新闻

文章按照体育、政治等主题分类就是自然语言处理分类任务。再比如，社交媒体上关于股

票的讨论经过处理后，就可以使用回归技术来给出预测数值，从而估计股票的价格。类似

地，无监督聚类算法可以对文本文档进行聚类。

任何用于自然语言处理的机器学习方法，无论是监督学习还是无监督学习，都可以描述为

三个步骤：提取文本特征、使用特征表示来学习模型，以及评估和改进模型。文本的特征

表示将在第 3 章中专门介绍，模型评估将在第 2 章中讨论。这里简要介绍第二步（使用特

征表示来学习模型）中常用的监督机器学习方法。对这些方法有一个基本的认识，将有助

于理解后续内容中讨论的概念。

1. 朴素贝叶斯

朴素贝叶斯是一种用于分类任务的经典算法。顾名思义，该算法的基础是贝叶斯定理。

朴素贝叶斯计算的是给定输入数据的特征集合，观察到某个类别标签的概率。该算法的一

个特点是，它假设每个特征都是独立的。对于本章前面提到的新闻分类示例，用数值表示

文本的一种方法是使用文本中出现的体育或政治类词汇的计数。假设这些词汇计数彼此不

相关。如果假设成立，就可以使用朴素贝叶斯对新闻文章进行分类。虽然这在许多情况下

是一个强假设，但朴素贝叶斯通常是文本分类的起始算法。这主要是因为它简单易懂，训

练和运行速度非常快。

2. 支持向量机

支持向量机（support vector machine, SVM）是另一种常见的分类算法。任何分类方法的目

标都是学习一个决策边界，作为不同类别文本之间的分隔（例如，新闻分类中的政治和体

育类）。该决策边界可以是线性的，也可以是非线性的（例如圆）。支持向量机可以通过学

习线性和非线性决策边界来区分不同类别的数据点。线性决策边界通过使不同类别之间的

差异变得明显的方式来学习数据的表示。图 1-11 展示了二维特征表示的一个示例，其中黑

点、白点分别属于不同的类别（例如，体育类新闻和政治类新闻）。支持向量机的目标是

学习一个最优的决策边界，使得不同类别点之间的距离达到最大。支持向量机的最大优点

是对数据变化和噪声具有稳健性。这种方法的主要缺点是训练时间长，当有大量训练数据

时，便无法扩展。

16 ｜ 第 1 章

图 1-11：支持向量机的二维特征表示

3. 隐马尔可夫模型

隐马尔可夫模型（hidden Markov model, HMM）是一种统计模型，它假定存在一个不可观

察、具有隐藏状态的潜在过程，数据由潜在过程生成。也就是说，只有在数据生成后才能

观察到数据。隐马尔可夫模型试图根据这些数据对隐藏状态进行建模。例如，考虑词性标

注任务（将词性标记分配给句子）。HMM 可用于文本数据的词性标注。这里假设文本是根

据背后的隐藏语法生成的。隐藏状态就是词性，这些词性按照自然语言的语法，内在地定

义了句子的结构，但我们只观察到了受这些隐藏状态支配的词。除此之外，HMM 还做了

马尔可夫假设，即每个隐藏状态都依赖于先前的一个或多个状态。人类语言本质上是顺序

的，句子中的当前词依赖于前面的词。因此，有了这两个假设，HMM 成为文本数据建模

的强大工具。图 1-12 展示了学习句子词性的 HMM 示例。JJ（形容词）、NN（名词）等词

性是隐藏状态，而“natural language processing (NLP) ...”是直接观察到的句子。

左括号 右括号

NLP

图 1-12：隐马尔可夫模型图示

自然语言处理概要 ｜ 17

18 ｜ 第 1 章

关于自然语言处理的 HMM，请参阅 Daniel Jurafsky 和 James H. Martin 的著作 Speech and 

Language Processing (3rd ed. draft) 中第 8 章的详细讨论。

4. 条件随机场

条件随机场（conditional random field, CRF）是另一种用于序列数据的算法。从概念上讲，

CRF 本质上是对序列中的每个元素执行分类任务。考虑同样的词性标注例子，CRF 可以通

过将每个词分类到某个词性（属于词性标注池）来逐词标注。由于 CRF 考虑了顺序输入和

标注的语境，因此比其他常用的分类方法更具表现力，并且效果更好。在词性标注等依赖

语言顺序的任务上，CRF 的性能优于 HMM。第 5 章、第 6 章和第 9 章将讨论 CRF 及其变

体和应用程序。

以上是一些常见的机器学习算法，它们在自然语言处理任务中被大量使用。对这些机器学习

方法有一些了解，将有助于理解本书中讨论的各种解决方案。除此之外，了解何时使用哪

种算法也很重要，这些会在接下来的内容中讨论。如果想深入了解机器学习过程和详细

的理论细节，推荐阅读 Christopher Bishop 的教科书 Pattern Recognition and Machine Learning。

如果从应用的角度来学习机器学习，Aurélien Géron 的《机器学习实战：基于 Scikit-Learn、

Keras 和 TensorFlow》是很好的入门读物。下面介绍自然语言处理的深度学习方法。

1.4.3　用于自然语言处理的深度学习

前面简要介绍了自然语言处理任务中常用的几种机器学习方法。在过去的几年里，使用神

经网络处理复杂、非结构化数据的任务出现了大幅度增长。语言本质上是复杂和非结构化

的。因此，理解和解决语言任务的模型，需要具有更好的表示能力和学习能力。下面是几

种常见的深度神经网络结构，它们在自然语言处理中已经深入人心。

1. 循环神经网络

正如前面提到的，语言本质上是顺序的。任何语言的句子都是沿着一种方向阅读的。例

如，英语句子是从左到右阅读的。因此，一个能够从头到尾逐步读入输入文本的模型对于

语言理解是非常有用的。循环神经网络（recurrent neural network, RNN）的特殊设计可以

确保这样的顺序处理和学习。RNN 的神经单元能够记忆目前为止所处理的内容。这种记忆

是时间性的，当 RNN 每隔一个时间步读取输入中的下一个词时，信息就会被存储和更新。

图 1-13 显示了一个展开的 RNN，以及它如何在不同的时间步跟踪输入。

ht ht h0 h1 h2

Xt Xt X0 X1 X2

图 1-13：展开的循环神经网络（参见 Christopher Olah 的文章“Understanding LSTM Networks”）

自然语言处理概要 ｜ 19

RNN 功能强大，非常适合处理文本分类、命名实体识别、机器翻译等各种自然语言处理任

务。RNN 还可以用来生成文本，即通过读取前面的文本，预测下一个词或下一个字符。

2. 长短期记忆

尽管 RNN 功能强大、用途广泛，但它们也存在健忘的问题。它们无法记住较长的语境，

因此当输入文本较长时，就会表现不佳，而输入文本较长是普遍情况。长短期记忆（long 

short-term memory, LSTM）网络是 RNN 的一种，但它弥补了 RNN 的不足。LSTM 放弃了

不相关的语境，只记住解决手头任务所需的语境，从而避开了这个问题。这减轻了向量表

示的负担，不必记忆很长的语境。由于这种解决方法的优点，LSTM 在大多数应用程序中

已经取代了 RNN。门控循环单元（gated recurrent unit, GRU）是 RNN 的另一种变体，主要

用于语言生成。图 1-14 展示了单个 LSTM 单元的结构。第 4、5、6 和 9 章将讨论 LSTM

在各种自然语言处理应用程序中的具体用途。

ht-1 ht ht+1

Xt-1 Xt Xt+1

图 1-14：LSTM 单元的结构（参见 Christopher Olah 的文章“Understanding LSTM Networks”）

3. 卷积神经网络

卷积神经网络（convolutional neural network, CNN）在图像分类、视频识别等计算机视觉

任务中得到了广泛应用。CNN 在自然语言处理，特别是文本分类任务中也取得了成功。将

句子中的每个词替换为对应的词向量，所有的向量都具有相同的维度 d（见第 3 章的 3.3.1

节），因此，它们可以编排在一起形成维数为 n×d 的矩阵或二维数组，其中 n 是句子的词

数，d 是词向量的大小。现在可以像图像一样处理这个矩阵，并且可以用 CNN 进行建模。

CNN 的主要优点是能够使用语境窗口查看一组词。例如，在做情感分类时，有这样的句

子：“我非常喜欢这部电影！（I like this movie very much!）”为了理解这句话，就需要关注

词及其不同的相邻词集。根据结构定义，CNN 自然可以做到这一点。后面的内容将详细讨

论这个问题。图 1-15 展示了 CNN 作用于一段文本，从中提取有用的短语，最终得出一个

二进制数来指示句子的情感。

如图 1-15 所示，CNN 使用若干卷积层和池化层来实现文本的压缩表示，然后将其作为输

入馈送到一个全连接层，从而学习文本分类等自然语言处理任务。第 4 章也会讨论 CNN。

20 ｜ 第 1 章

激活函数

1-最大值

池化

该层使用softmax

函数正则化

卷积

3个大小不同的区域：(2,3,4)

每个区域有2个滤波器

共6个滤波器

每个区域

有2个

特征图

句子矩阵

7×5 6个单变量

向量拼接成

一个单一的

特征向量

2类

d=5

图 1-15：CNN 模型示意

4. Transformer

Transformer 是自然语言处理深度学习模型联盟的新成员。在过去的两年中，Transformer

模型在几乎所有主要的自然语言处理任务中都达到了先进水平。Transformer 对文本语境进

行建模，但不是按顺序进行的。给定输入中的一个词，Transformer 着重关注其周围的所有

词（称为自注意力），并根据其语境来表示每个词。例如，“bank”一词根据其出现的语境

可能具有不同的含义。如果语境涉及金融，那么它很可能指的是银行。另一方面，如果语

境提到河流，那么它很可能指的是河岸。Transformer 能对这样的语境进行建模，因此在自

然语言处理任务中被大量使用。这是因为与其他深度网络相比，Transformer 具有更强的表

示能力。

最近，大型 Transformer 已被用于下游小型任务的迁移学习。迁移学习是将解决一个问题

时获得的知识应用到其他不同但相关的问题的人工智能技术。Transformer 的思想是以无监

督的方式训练一个非常大的 Transformer 模型（称为预训练）。Transformer 根据句子的其他

部分预测句子的一部分，从而能对语言中高层次的细微差别进行编码。训练 Transformer

模型的文本数据超过 40GB，是从整个互联网收集的。大型 Transformer 的一个例子是

自然语言处理概要 ｜ 21

BERT（来自 Transformer 的双向编码器表示），如图 1-16 所示，它由海量数据预训练而得，

并由谷歌开源。

预训练 微调

下一句

预测

掩码语言

模型

掩码语言

模型

掩码句子A 掩码句子B

多类型 命名实 斯坦福问答数据集 起始/结束片断

未标注句对（句子A和B）

问题 段落

问答对

N M

N M

N M

N M

N M

N M

图 1-16：BERT 架构：预训练模型和微调后适用于特定任务的模型

预训练模型如图 1-16 左侧所示。微调后可以用于文本分类、实体提取、问题回答等下游自

然语言处理任务，如图 1-16 右侧所示。由于预训练知识量巨大，BERT 可以高效地将知识

迁移到下游任务中，并且在许多下游任务中都达到了先进水平。本书将介绍使用 BERT 执

行各种任务的各种示例。图 1-17 展示了 Transformer 的关键组件，即自注意力机制的工作

原理。第 4、6 和 10 章将介绍 BERT 及其应用。

图 1-17：Transformer 中的自注意力机制（参见 Jay Alammar 的文章“The Illustrated Transformer”）

22 ｜ 第 1 章

5. 自动编码器

自动编码器（autoencoder）是一种不同类型的网络，主要用于学习输入的密集向量表示。

例如，如何用一个向量来表示一个文本？这时不妨学习一个从输入文本到向量的映射函

数。为了使映射函数有效，可以从向量表示反过来“重构”输入。这是一种无监督学习方

式，不需要人工标注。训练结束后得到的密集向量表示，可以作为输入文本的编码。自动

编码器通常用于创建下游任务所需的特征表示。图 1-18 描述了自动编码器的结构。

自动编码器

输入

节点

输出

节点

隐层

节点

电影 1

电影 2

电影 3

电影 4

电影 1

电影 2

电影 3

电影 4

图 1-18：自动编码器的结构

在该方案中，隐层相当于输入数据的压缩表示，能捕捉数据的本质，输出层（解码器）则

从压缩表示中重构输入表示。虽然图 1-18 中所示的自动编码器结构无法处理文本等顺序数

据的特有属性，但把自动编码器改造成 LSTM 自动编码器，就可以很好地解决这些问题。

上面简要介绍了自然语言处理中常用的一些深度学习结构。希望以上介绍提供了足够的背

景知识，便于读者理解本书后面提到的深度学习。

鉴于深度学习模型取得的新进展，人们可能会认为，深度学习应该是构建自然语言处理系

统的首选方法。然而，对于大多数行业用例来说，这远非事实。下面来看其中的原因。

1.4.4　为什么深度学习还不是自然语言处理的灵丹妙药

在过去的几年里，深度学习在自然语言处理领域取得了惊人的进展。例如，在文本分类

中，基于 LSTM 和 CNN 的模型在许多分类任务中的性能超过了朴素贝叶斯和支持向量机

等标准的机器学习技术。类似地，LSTM 在序列标注任务（如实体提取）中比条件随机场

模型表现得更好。最近，功能强大的 Transformer 模型在文本分类、序列标注等大多数自

然语言处理任务中已经成为最先进的技术。目前的一个大趋势是，设计大型 Transformer

模型（就参数数量而言），在庞大的数据集上进行训练，以完成语言模型等通用的自然语

言处理任务，然后微调 Transformer，使之适应下游的小型任务。这种迁移学习方法在计算

机视觉、语音等其他领域也取得了成功。

尽管取得了如此巨大的成功，但在行业应用程序中，深度学习仍然不是所有自然语言处理

任务的灵丹妙药，其中的一些关键原因列举如下。

小数据集上的过拟合

与传统的机器学习模型相比，深度学习模型具有更多的参数，这意味着它们具有更强的

表达能力。但这也伴随着一个诅咒。奥卡姆剃刀法则指出，在所有其他条件都相同的情

况下，更简单的解决方案总是更可取的。在开发阶段，很多时候都没有足够的训练数据

来训练复杂的网络。在这种情况下，与深度学习模型相比，应该首选更简单的模型。深

度学习模型在小数据集上过度拟合，导致泛化能力差，进而导致产品性能差。

少样本学习与合成数据生成

在计算机视觉等学科中，深度学习在少样本学习（即从很少的训练样例中学习）和高质

量图像生成模型方面取得了重大进展。这两个进步都使得在少量数据上训练基于深度学

习的视觉模型变得可行。因此，深度学习已经被广泛应用于解决行业场景中的问题。但

是在自然语言处理领域，还没有看到与之类似的、成功的深度学习技术。

领域适应

如果大型深度学习模型是用某些常用领域（例如新闻文章）的数据集训练的，那么将训

练好的模型应用到其他领域（例如社交媒体帖文），就可能导致性能较差。这种泛化带

来的性能损失表明深度学习模型并不是百试百灵的。例如，在互联网文本和产品评论上

训练的模型，如果用于法律、社交媒体或医疗保健等领域，就会效果不佳。这是因为在

这些领域所用的语言，其句法和语义结构是特定的。这就需要专门的模型来编码领域知

识，这种模型需要像领域特定的、基于规则的模型一样简单。

可解释模型

除了有效的领域适应外，可控性和可解释性对于深度学习模型来说也是困难的。在大多

数时候，深度学习模型像黑箱一样工作。业务部门通常需要更可解释的结果，以便解释

给客户或最终用户。在这些情况下，传统技术可能更有用。例如，在情感分类中，朴素

贝叶斯模型可以解释强烈的正向词汇和负向词汇对最终情感预测的影响。

到目前为止，从 LSTM 分类模型中获得这样的见解是困难的。相比之下，在计算机视

觉领域，深度学习模型不再是黑箱。有许多技术用于解释模型做出特定预测的原因。但

在自然语言处理领域，这种方法尚不常见。

常识与世界知识

尽管机器学习和深度学习模型在基准自然语言处理任务上已经取得了很好的性能，但是

对于科学家来说，语言仍然是一个较大的谜团。除了句法和语义之外，语言还包含了周

围世界的知识。语言交流依赖于对世界事件的逻辑推理和常识。例如，“我喜欢比萨”

意味着“我吃比萨的时候很开心”。更复杂一点，“如果约翰走出卧室去花园，那么约翰

已经不在卧室了，他现在的位置是花园”。这对人类来说可能是显而易见的，但它需要

机器进行多步推理来识别事件并理解其后果。由于世界知识和常识是语言所固有的，理

解它们对深度学习模型在各种语言任务上的良好表现是至关重要的。当前的深度学习模

型可以在标准测试上表现良好，但仍然不能进行常识理解和逻辑推理。虽然有人在收集

常识事件和逻辑规则（如“若 – 则”推理）方面做了一些努力，但它们还没有很好地与

机器学习或深度学习模型集成。

自然语言处理概要 ｜ 23

成本

为自然语言处理任务构建基于深度学习的解决方案可能非常昂贵。从金钱和时间方面来

看，成本有多个来源。深度学习模型是众所周知的数据吞噬者。收集大型数据集并对其

进行标注会非常昂贵。由于深度学习模型体积庞大，训练它们达到期望的性能不仅会增

加开发周期，而且还会导致专用硬件（GPU）上的巨大开销。此外，部署和维护深度学

习模型在硬件要求和工作量方面都很昂贵。最后，由于体积庞大，深度学习模型会在推

理过程中导致延迟问题，如果低延迟是硬性要求，那么这些模型反而毫无用处。在这个

缺点列表中，还可以添加一项：构建和维护重型模型会产生技术债务。宽泛地说，技术

债务是由于重快速交付、轻良好设计和实现选型而产生的返工成本。

设备上部署

对于许多用例，自然语言处理解决方案需要部署在嵌入式设备上，而不是部署在云端。

例如一个机器翻译系统，需要未联网的情况下，也可以帮助游客说出翻译后的文本。在

这种情况下，由于设备的限制，解决方案必须在有限的内存和电量下工作。大多数的深

度学习解决方案都不满足这样的约束。虽然这个方向上有一些努力，即在边缘设备上部

署深度学习模型，但是这离通用的解决方案还有相当远的距离。

在大多数行业项目中，上面提到的一个或多个因素都会体现出来。这会导致更长的项目周

期和更高的硬件和人力成本，但性能只与机器学习模型相当，有时甚至低于机器学习模

型。这使得投资回报率很低，并且经常导致项目失败。

基于上述讨论，很明显，深度学习并不总是业界所有自然语言处理应用程序的最佳解决方

案。因此，本书先介绍各种自然语言处理任务的基本情况，然后使用一系列技术，包括基

于规则的系统和深度学习模型等来解决它们。本书强调数据需求和模型构建流水线，而不

仅仅是单个模型的技术细节。鉴于这一领域的快速发展，预计未来会出现更新的深度学习

模型，来推进技术的发展，但自然语言处理任务的基本原理不会发生实质性的变化。因

此，本书先讨论自然语言处理的基础，并在此基础上开发尽可能复杂的模型，而不是直接

跳到前沿技术。

与卡内基 – 梅隆大学的 Zachary Lipton 教授和加州大学伯克利分校的 Jacob Steinhardt 教授

在其文章“Troubling Trends in Machine Learning Scholarship”中所主张的一样，我们也在

此警示：不要在没有来龙去脉和适当训练的情况下大量阅读机器学习和自然语言处理方面

的科学文章、研究论文和博客。紧跟大量前沿工作可能会造成概念混淆和理解不准确。许

多最近的深度学习模型没有办法充分解释其经验收益的原因。Lipton 和 Steinhardt 也认识

到，机器学习类的科学文章往往无法提供解决手头问题的清晰路径，而且还存在术语的混

淆和语言的误用。因此，本书通过各章的示例、代码和提示，仔细描述了自然语言处理任

务中机器学习的各种技术概念。

到目前为止，我们已经介绍了语言、自然语言处理、机器学习和深度学习相关的一些基本

概念。在结束第 1 章之前，先来看一个案例研究，以便更好地理解自然语言处理应用程序

的各个组件。

24 ｜ 第 1 章

1.5　自然语言处理演练：对话智能体

亚马逊 Alexa、Apple Siri 等基于语音的对话智能体是最普遍的自然语言处理应用程序，也

是大多数人已经熟悉的应用程序。图 1-19 展示了对话智能体的典型交互模型。

语音识别 自然语言理解

对话管理

语音合成 响应生成

图 1-19：对话智能体流程

下面介绍图中流程用到的主要自然语言处理组件。

1. 语音识别和合成。这些是任何基于语音的对话智能体的主要组件。语音识别包括将语音

信号转换成音素，然后将这些音素转录成词。语音合成则是将文本结果转化成口语的

反向过程。这两种技术在过去十年中都有了长足的进步，建议在大多数标准情况下使用

云 API。

2. 自然语言理解。这是对话智能体流水线中的下一个组件，它使用自然语言理解系统分析

接收到的用户响应（转录为文本）。这可以分解为许多小的自然语言处理子任务，列举

如下。

• 情感分析。这里分析的是用户响应的情感。第 4 章将介绍这一点。

• 命名实体识别。这里识别的是用户响应中提到的所有重要实体。这将在第 5 章讨论。

• 共指消解。这里是指从对话历史中找出所提取实体的指代。例如，用户可能会说

“《复仇者联盟 4：终局之战》很棒”，后面再次提到电影时说“电影的特效很棒”。

在这种情况下，“电影”指的是《复仇者联盟 4：终局之战》。第 5 章会对此做简

要介绍。

3. 对话管理。从用户响应中提取了有用的信息之后，就需要理解用户的意图：他们是在问

一个事实性的问题，比如“今天天气如何”，还是在给出一个命令，比如“播放莫扎特

歌曲”。可以使用文本分类系统将用户响应分类为预定义的意图之一。这有助于对话智

能体知道用户在问什么。意图分类将在第 4 章和第 6 章讨论。在此过程中，系统可能会

提出一些澄清问题，以从用户那里获得进一步的信息。一旦弄清楚了用户的意图，对话

智能体就需要知道应该采取哪些合适的行动来满足用户的请求。这是基于从用户响应中

提取的信息和意图来完成的。适当的行动包括通过互联网生成答案、播放音乐、调暗灯

光或者提出澄清问题。第 6 章将讨论这个问题。

自然语言处理概要 ｜ 25

4. 响应生成。最后，对话智能体根据用户意图的语义解释和用户对话的其他输入来生成合

适的执行动作。如前所述，智能体可以从知识库中检索信息，并使用预定义的模板生

成响应。例如，它可能会回应说，“现在正在演奏《第 25 号交响曲》”或“灯光已经调

暗”。在某些情况下，它还会生成一个全新的响应。

这个简短的案例研究概述了不同的自然语言处理组件如何结合在一起构建对话智能体应用

程序。随着本书的进展，后面还会介绍更多关于这些组件的细节。第 6 章将专门讨论对话

智能体。

1.6　小结

从“语言是什么”的大致介绍，到真实自然语言处理应用程序的具体案例研究，本章涵盖

了一系列的自然语言处理主题。本章还讨论了自然语言处理在现实世界中的应用，它的一

些挑战和不同的任务，以及机器学习和深度学习在自然语言处理中的作用。这一章的目的

是提供全书的基础知识。接下来的两章（第 2 章和第 3 章）将介绍构建自然语言处理应用

程序所需的一些基本步骤。第 4~7 章关注自然语言处理的核心任务以及可以用它们解决的

行业用例。第 8~10 章将讨论自然语言处理在电子商务、医疗保健、金融等各种垂直行业

中的使用。第 11 章将所有内容汇总到一起，并讨论了在设计、开发、测试和部署方面构

建端到端自然语言处理应用程序需要采取的措施。有了这个全面的概述，下面开始深入探

索自然语言处理的世界。

26 ｜ 第 1 章

第 2 章

自然语言处理流水线

整体大于各部分之和。更准确的说法是，整体不同于各部分之和。这是因为简单

相加没有意义，而整体和部分的关系才是意义之所在。

——库尔特 • 考夫卡

在日常生活中，我们可能会碰到各种各样的自然语言处理应用程序。上一章已经介绍了一

些常见的例子。那么一个自然语言处理应用程序应该如何构建？通常，我们会遍历需求并

将问题分解成若干子问题，然后尝试开发一个过程，逐步解决这些子问题。由于涉及语言

处理，因此还要列出每一步所需的各种文本处理。这种分步骤处理文本的过程叫流水线

（pipeline）。流水线是构建自然语言处理模型所涉及的一系列步骤。这些步骤在每个自然语

言处理项目中都很常见，因此通过本章来研究它们是理所当然的。理解自然语言处理流水

线中的一些常见步骤后，就可以开始处理工作场所中遇到的自然语言处理问题了。设计和

开发文本处理流水线被视为任何自然语言处理应用程序开发的起点。本章将介绍各种相关

步骤，以及它们在解决自然语言处理问题中的重要作用。关于使用哪个步骤、何时使用、

如何使用，本章也会提供一些指南。后面的内容还将讨论各种自然语言处理任务的特定流

水线（例如第 4~7 章）。

数据驱动的现代自然语言处理系统在开发中使用了通用的流水线。图 2-1 显示了其中的主

要组件。流水线中的关键阶段列举如下：

1. 数据获取；

2. 文本清洗；

3. 预处理；

4. 特征工程；

5. 建模；

6. 评估；

27

28 ｜ 第 2 章

7. 部署；

8. 监控和模型更新。

数据获取

监控和模型更新

文本清洗

部署

预处理

评估

特征工程

建模

改进模型

图 2-1：自然语言处理的通用流水线

开发任何自然语言处理系统的第一步是收集给定任务的相关数据。即使构建一个基于规则

的系统，也仍然需要一些数据来设计和测试规则。由于获得的数据很少是干净数据，因此

需要进行文本清洗。经过清洗后，文本数据往往具有很多不同的形式，因此需要将其转换

成规范形式。这是在预处理这一步中完成的。接下来是特征工程，其目的是精心设计出最

能表征当前任务的若干指标，并将这些指标转换成建模算法可以理解的格式。然后是建模

和评估阶段，即构建一个或多个模型，并采用相关的评估方法对它们进行比较。一旦从中

选择了最佳模型，就可以开始在生产中部署该模型。最后一步是定期监控模型的性能，并

在需要时更新模型以保持其性能。

注意，在现实世界中，这个过程可能并不总像图 2-1 中所示的流水线那样一帆风顺——它

经常会在各个步骤之间，例如在特征提取和建模之间，在建模和评估之间等出现来回反复。

而且，步骤之间可能还有循环，最常见的循环是从评估到预处理、特征工程、建模，再回

到评估的循环。此外，在项目这个级别上，还会出现从监控回到数据获取的整体循环。

注意，具体采取什么样的步骤可能取决于当前的具体任务。例如，文本分类系统需要的特

征提取步骤可能不同于文本摘要系统。本书的后续内容将关注特定于应用的流水线阶段。

此外，不同的步骤可能需要不同的时间，这取决于项目所处的阶段。在初始阶段，大部分

时间会用于建模和评估，而一旦系统成熟，特征工程就会花费更多的时间。

本章接下来将结合示例，详细介绍流水线的各个阶段，描述每个阶段的一些常见步骤，并

讨论一些用例来说明它们。现在开始第一步：数据获取。

2.1　数据获取

数据是机器学习系统的核心。在大多数行业项目中，成为瓶颈的往往是数据。本节将讨论

自然语言处理项目中收集相关数据的各种策略。

假如现在要开发一个自然语言处理系统，它能识别传入的客户查询（比如通过聊天界面）

是销售查询还是客服查询，并根据查询的类型，自动将其发送到对应的团队。怎样才能构

建这样一个系统呢？答案取决于数据的类型和数量。

在理想的情况下，所需的数据集拥有成千上万个数据点。在这种情况下，我们不必担心数

据获取的问题。例如，在刚才描述的场景中，不仅有来自前几年的历史性查询，而且销售

团队和支持团队还将这些查询标注为“销售”“支持”或“其他”类别。因此，我们不仅

有数据，还有标注。然而，在很多人工智能项目中，我们就没有那么幸运了。那么在不太

理想的场景中，我们可以做些什么？下面来看一看。

如果只有很少的数据或者没有数据，可以先看一看数据中是否存在某些模式，表明传入的

消息是销售查询还是支持查询。然后使用正则表达式和其他启发式来匹配这些模式，从而

将销售查询和支持查询分开。接下来是评估这一方案，方法是从两个类别中收集一组查询

并计算消息被系统正确识别的百分比。结果可能还凑合。我们希望提高系统性能。

现在可以开始考虑使用自然语言处理技术了。为此，我们需要标注好的数据，也就是查询

集合中的每个查询都被标注为“销售”或“支持”。那么怎样才能得到这样的数据？

使用公开数据集

可以看看是否有可以利用的公开数据集。如果找到了与手头任务相似的合适数据集，那

么太好了！下一步就是构建模型并进行评估。如果没有，那么接下来该怎么办？

抓取数据

可以在互联网上找到相关数据的来源，例如发布了销售或支持查询的消费者论坛或产品

页面讨论区。从那里抓取数据，然后进行人工标注。

对于许多行业场景，从外部来源收集数据是不够的，因为外部数据不包含产品名称或特

定于产品的用户行为等细微信息，因此可能与生产环境中看到的数据非常不同。这就需

要在组织内部寻找数据。

产品干预

在大多数行业场景中，人工智能模型很少是单独存在的。它们主要通过某项功能或某个

产品为用户提供服务。在这种情况下，人工智能团队应该与产品团队合作，开发更好的

产品监测指标来收集更多、更丰富的数据。在科技界，这叫产品干预。

在行业场景中构建智能应用程序，产品干预通常是收集数据的最佳方式。谷歌、Facebook、

微软、Netflix 等科技巨头早就深谙此道，并努力从尽可能多的用户那里收集尽可能多的

数据。

数据增强

虽然监测产品是收集数据的好方法，但这需要时间。即使从现在开始监测产品，那也要

等 3~6 个月才能收集到一个规模庞大、内容丰富的数据集。那么在此期间，我们可以做

些什么？

可以在小数据集上使用某些技巧来创建更多的数据。这些技巧也叫数据增强。数据增强试

图利用语言特性，来生成句法相似的文本。数据增强可能看起来像是在篡改数据，但在实

践中效果很好。自然语言处理中有很多数据增强的技术。下面来看看其中的一些。

同义词替换

在句子中随机选择 k 个非停用词，然后用同义词进行替换。可以使用 WordNet 的 Synsets

来获取同义词。

自然语言处理流水线 ｜ 29

回译

假设有一个英语句子 S1。使用谷歌翻译等机器翻译库把它翻译成其他语言，比如德语。

令对应的德语句子为 S2。现在，再次使用机器翻译库，将 S2 翻译回英语，令输出句子

为 S3。

不难发现，S1 和 S3 意思非常接近，但又稍有不同。现在可以把 S3 添加到数据集中。

这个技巧非常适合文本分类。图 2-2（参见 Qizhe Xie、Zihang Dai、Eduard Hovy 等人

的文章“Unsupervised Data Augmentation for Consistency Training”）显示了回译的一个

实例。

回译

图 2-2：回译

基于 TF-IDF 的词替换

回译后，句子中的某些重要词语可能会丢失。在 Qizhe Xie、Zihang Dai、Eduard Hovy

等人的文章“Unsupervised Data Augmentation for Consistency Training”中，作者使用

TF-IDF 来处理这个问题，第 3 章将引入这一概念。

二元语法翻转

把句子按二元语法进行切分。随机取一组二元语法，将其翻转。例如，在“我要去超

市”中，取二元语法“要去”，翻转成“去要”，并进行替换。

替换实体

找出人名、地点、组织等实体，用其他同类实体进行替换，即用其他人名替换原有人名，

用其他城市替换原有城市等。例如，在“我住在加州”中，用“伦敦”替换“加州”。

数据加噪

在很多自然语言处理应用程序中，输入数据本身就带有拼写错误。这主要是由数据平台

的自身特点决定的，例如 Twitter。在这种情况下，可以在数据中添加一点噪声，从而

训练出稳健的模型。例如，在句子中随机选择一个词，然后用拼写相近的词进行替换。

另外，移动键盘上因误碰触按键而导致的打字错误也可以产生噪声。这时可以用全键盘

上的相邻字符来替换正常字符，从而模拟键盘输入错误。

30 ｜ 第 2 章

高阶技术

其他一些高阶技术和系统也可以增强文本数据。以下是值得注意的几个。

Snorkel

该系统可以自动创建训练数据，无须人工标注。Snorkel 使用启发式，通过转换现有

数据和创建新数据样本来创建合成数据，从而“创建”大型训练数据集，这里不需

要人工标注。

简单数据增强（EDA）和 NLPAug

这两个库的功能是创建自然语言处理合成样例。它们提供了各种数据增强技术的实

现，包括前面讨论过的一些技术。

主动学习

这是一种专门化的机器学习范式，其学习算法可以交互地查询数据点并获得它的标

签。它适用于存在大量未标注数据、但手动标注代价高昂的场景。在这样的情况下，

问题就变成：怎样选择需要标注的数据点，从而使学习效果最好，同时保持标注成

本较低？

本节中讨论了很多技术。但要想发挥它们的作用，一个关键的要求是数据集必须干净。即

使数据集不够大，根据我们的经验，也可以使用数据增强技术来增加数据量。另外，在日

常的机器学习实践中，数据集还可以有不同的来源。在早期阶段，通常没有大规模数据集

供自定义场景使用，因此在这个阶段构建生产模型时，就可以组合利用公开数据集、标注

数据集和增强数据集。一旦有了给定任务所需的数据，就可以进入流水线的下一步：文本

清洗。

2.2　文本提取和清洗

文本提取和清洗是指从输入数据中提取原始文本的过程，它会删除标记、元数据等所有其

他非文本信息，并将文本转换为所需的编码格式。通常，这一过程取决于组织中可用数据

的格式，例如来自 PDF、HTML 或图像文本等的静态数据，如图 2-3 所示。

文本提取是一个标准的数据整理步骤。这个过程通常不需要特定的自然语言处理技术。然

而，这一步非常重要，如果处理不好就会影响自然语言处理流水线的所有后续步骤。此

外，文本提取可能也是项目中最耗时的部分。虽然文本提取工具的设计超出了本书的讨论

范围，但本节会通过几个示例来说明这一步骤中涉及的各种问题。另外，本节还将讨论从

各种来源提取文本的一些重要问题，包括文本清洗，以便其在下游流水线中使用。

自然语言处理流水线 ｜ 31

a b

c

图 2-3：(a) PDF 发票；(b) HTML 文本；(c) 图像中嵌入的文本

2.2.1 HTML解析和清洗

以建立编程问答论坛搜索引擎项目为例。假如已经确定 Stack Overflow 为数据来源，并决

定从该网站中提取问题和最佳答案对。在这种情况下，应该如何完成文本提取的步骤？

如果观察 Stack Overflow 问题页面的 HTML 标记，就会注意到问题和答案都有特殊的标

记。从 HTML 页面提取文本时，可以利用这些信息。虽然编写自己的 HTML 解析器似乎

是一种可行的方法，但对于大多数情况来说，更可行的方法是利用现有的库，如 Beautiful 

Soup 和 Scrapy，它们提供了一系列解析网页的实用程序。下面的代码片段展示了如何使

32 ｜ 第 2 章

用 Beautiful Soup 来解决这里描述的问题，即从 Stack Overflow 网页中提取问题及其最佳

答案对：

from bs4 import BeautifulSoup 

from urllib.request import urlopen 

myurl = "https://stackoverflow.com/questions/415511/ 

 how-to-get-the-current-time-in-python" 

html = urlopen(myurl).read() 

soupified = BeautifulSoup(html, "html.parser") 

question = soupified.find("div", {"class": "question"}) 

questiontext = question.find("div", {"class": "post-text"}) 

print("Question: \n", questiontext.get_text().strip()) 

answer = soupified.find("div", {"class": "answer"}) 

answertext = answer.find("div", {"class": "post-text"}) 

print("Best answer: \n", answertext.get_text().strip())

这里，提取想要的内容依赖于对 HTML 文档结构的了解。此代码显示以下输出：

Question: 

What is the module/method used to get the current time? 

Best answer: 

 Use: 

>>> import datetime 

>>> datetime.datetime.now() 

datetime.datetime(2009, 1, 6, 15, 8, 24, 78915) 

>>> print(datetime.datetime.now()) 

2009-01-06 15:08:24.789150 

And just the time: 

>>> datetime.datetime.now().time() 

datetime.time(15, 8, 24, 78915) 

>>> print(datetime.datetime.now().time()) 

15:08:24.789150 

See the documentation for more information. 

To save typing, you can import the datetime object from the datetime module: 

>>> from datetime import datetime 

Then remove the leading datetime. from all of the above.

这个例子有一个特定的需求：提取问题及其答案。在某些场景中，例如从网页中提取邮寄

地址，则是先从网页中获取所有文本（而不是部分文本），然后再执行其他操作。通常，

所有的 HTML 库都有一些函数，可以剥离所有的 HTML 标记，并只返回标记之间的内容。

但这通常会导致噪声输出，并且可能会在提取的内容中看到大量的 JavaScript 。在这种情

况下，应该只提取网页中包含文本的内容。

2.2.2 Unicode规范化

在开发代码清洗 HTML 标记时，还可能遇到各种 Unicode 字符，包括符号、表情符号和其

他图形字符。图 2-4 中显示了一些 Unicode 字符。

自然语言处理流水线 ｜ 33

34 ｜ 第 2 章

图 2-4：Unicode 字符

为了解析这些非文本符号和特殊字符，需要使用 Unicode 规范化。这意味着我们看到的文

本应该转换成某种形式的二进制表示来存储在计算机中。这个过程称为文本编码。忽略编

码问题可能会导致后续流水线中出现处理错误。

编码方案有多种，对于不同的操作系统，默认编码可能不同。在很多情况下，特别是在处

理多语言文本、社交媒体数据等时，可能需要在文本提取过程中在这些编码方案之间进行

转换。以下是 Unicode 处理的一个示例：

text = 'I love ! Shall we book a to get pizza?' 

Text = text.encode("utf-8") 

print(Text)

输出：

b'I love Pizza \xf0\x9f\x8d\x95! Shall we book a cab \xf0\x9f\x9a\x95 

 to get pizza?'

处理后的文本是机器可读的，可以在下游流水线中使用。第 8 章将用这个相同的例子详细

讨论处理 Unicode 字符的问题。

2.2.3　拼写更正

在速记问题和误触键盘问题的世界中，传入的文本数据经常存在拼写错误。这在搜索引

擎、文本聊天机器人、社交媒体等很多数据来源中可能很普遍。虽然删除了 HTML 标记并

处理了 Unicode 字符，但拼写错误仍然是一个独特的问题，可能会损害对数据的语义理解，

而微博中的速记文本消息往往会妨碍语言处理和上下文理解。以下是两个这样的例子。

速记问题：Hllo world! I am back!

误触键盘问题：I pronise that I will not bresk the silence again!

速记问题在聊天界面中很普遍，而误触键盘问题在搜索引擎中也很常见，而且大多是无意

间造成的。尽管这个问题不难理解，但目前还没有可靠的方法来解决这个问题。即便如

此，我们仍然可以尝试应对。微软发布了一个 REST API，可以在 Python 中用于拼写检查。

import requests 

import json 

api_key = "<此处输入密钥>" 

example_text = "Hollo, wrld" # 需要拼写检查的文本

data = {'text': example_text} 

params = { 

 'mkt':'en-us', 

 'mode':'proof' 

 } 

headers = { 

 'Content-Type': 'application/x-www-form-urlencoded', 

 'Ocp-Apim-Subscription-Key': api_key, 

 } 

response = requests.post(endpoint, headers=headers, params=params, data=data) 

json_response = response.json() 

print(json.dumps(json_response, indent=4))

输出（仅显示部分结果）：

"suggestions": [ 

 { 

 "suggestion": "Hello", 

 "score": 0.9115257530801 

 }, 

 { 

 "suggestion": "Hollow", 

 "score": 0.858039839213461 

 }, 

 { 

 "suggestion": "Hallo", 

 "score": 0.597385084464481 

 }

完整的教程参见微软文档中的“Quickstart: Check spelling with the Bing Spell Check REST 

API and Python”。

除了 API 之外，还可以使用特定语言的大词典来构建自己的拼写检查器。一个简单的解决

方案是寻找所有改动（添加、删除、替换）最少的词。例如，如果“hello”是词典中已经

存在的有效单词，那么在“hllo”中只添加“e”（改动最少）就可以进行拼写更正。

2.2.4　特定于系统的错误更正

互联网上获取的 HTML 和原始文本只是文本数据的两个来源。考虑另一个场景，假设数据

集是 PDF 文档。在这种情况下，流水线的第一步是从 PDF 文档中提取纯文本。然而，不

同的 PDF 文档具有不同的编码方式。有时，提取全部文本可能非常困难，或者文本的结构

可能会变得混乱。如果需要全部文本，或者文本必须符合语法，或者文本必须是完整的句

子，那么这可能会影响我们的应用程序，例如根据报纸文本提取新闻中不同人物之间的关

自然语言处理流水线 ｜ 35

系。虽然有几个库可以从 PDF 文档中提取文本，比如 PyPDF、PDFMiner 等，但它们还远

远不够完美，而且这种库无法处理 PDF 文档的情况并不少见。我们把这些库的探索留给读

者作为练习。

文本数据的另一个常见来源是扫描文档。从扫描文档中提取文本通常使用 Tesseract 等库

的光学字符识别（optical character recognition, OCR）来完成。考虑下面的示例图片，如图

2-5 所示，它摘自 1950 年的某期刊文章片段。

图 2-5：扫描文本示例

下面的代码片段显示了如何使用 Python 库 pytesseract 来提取图片文本：

from PIL import Image 

from pytesseract import image_to_string 

filename = "somefile.png" 

text = image_to_string(Image.open(filename)) 

print(text)

这段代码将打印如下输出，其中 \n 表示换行符：

'in the nineteenth century the only Kind of linguistics considered\nseriously 

was this comparative and historical study of words in languages\nknown or 

believed to Fe cognate—say the Semitic languages, or the Indo-\nEuropean 

languages. It is significant that the Germans who really made\nthe subject what 

it was, used the term Indo-germanisch. Those who know\nthe popular works of 

Otto Jespersen will remember how fitmly he\ndeclares that linguistic 

science is historical. And those who have noticed'

不难发现，在这种情况下，OCR 系统的输出有两个错误。在其他情况下，OCR 输出可能

存在更多的错误，这取决于原始扫描件的质量。在进入流水线的下一个阶段之前，应该如

何清洗文本？一种方法是使用拼写检查器（如 pyenchant）检查文本，识别拼写错误并提出

替换方案。近些年的方法则使用神经网络架构来训练基于词 / 字符的语言模型，然后使用

这些语言模型根据上下文来校正 OCR 的文本输出。

回到第 1 章介绍过的语音助手示例。在这种情况下，文本提取的来源是自动语音识别

（automatic speech recognition, ASR）系统的输出。与 OCR 一样，ASR 中的错误也很常见，

这是由方言、俚语、非母语英语、新词或专业术语等各种因素造成的。这里也可以遵循上

述拼写检查器或神经语言模型的方法来清洗提取的文本。

以上只是文本提取和清洗过程中可能出现的潜在问题的一些示例。虽然自然语言处理在这

36 ｜ 第 2 章

个过程中起到的作用非常有限，但这些示例表明，文本提取和清洗可能会给典型的自然语

言处理流水线带来挑战。接下来的相关内容中，还会涉及这些方面。现在进入流水线的下

一步：预处理。

2.3　预处理

先从一个简单的问题开始：既然上一步已经对文本做了一些清洗，那为什么还要进行预处

理？考虑这样一个场景：处理维基百科人物页面的文本，提取传记信息。数据获取从抓取

页面开始。然而，抓取的数据都是 HTML 格式的，其中有很多维基百科的样板文本（例

如，左侧面板中的所有链接），同时还可能存在指向多种语言的链接（在脚本中）等。大

多数情况下，这些信息与文本特征提取无关。文本提取步骤已经移除了这些信息，并给出

了所需文章的纯文本。然而，所有的自然语言处理软件通常是在句子级别上工作的，并且

至少需要分词。因此，需要某种方法将文本分解成词和句子，然后在流水线中进一步处

理。有时，特殊字符和数字需要删掉；有时，大小写不重要，所有内容需要转换成小写。

在处理文本时，还有很多类似的决定。这些决定都属于自然语言处理流水线的预处理步

骤。以下是自然语言处理软件中常用的一些预处理步骤。

预备步骤

句子切分和分词。

常用步骤

停用词删除、词干提取和词形还原、数字 / 标点符号删除、大小写转换等。

其他步骤

规范化、语言检测、语码混用、音译等。

高级处理

词性标注、句法解析、共指消解等。

虽然并非所有的自然语言处理流水线都会遵循以上步骤，但前两个步骤或多或少是随处可

见的。下面来看一看这些步骤的含义。

2.3.1　预备步骤

如前所述，自然语言处理软件在分析文本之前通常需要先将文本分解成词（词符，token）

和句子。因此，任何自然语言处理流水线都必须可靠地将文本切分成句子（句子切分），

并进一步将句子切分成词（分词）。从表面上看，这些似乎是简单的任务，但为什么还需

要特殊处理？接下来解释其中的原因。

1. 句子切分

在句号和问号出现时将文本切分成句子来进行句子切分，这是一个简单的规则。但是，缩

写、称呼（Dr.、Mr. 等）或者英文省略号（...）可能会打破这个简单的规则。

幸运的是，大多数自然语言处理库实现了一定的句子切分和分词，因此不必担心如何解决

这些问题。一个常用的库是“自然语言工具包”（Natural Language Tool Kit, NLTK）。下面

自然语言处理流水线 ｜ 37

的代码以本章第一段英文原文为输入，展示了如何使用 NLTK 的句子切分和分词器：

from nltk.tokenize import sent_tokenize, word_tokenize 

mytext = "In the previous chapter, we saw examples of some common NLP 

applications that we might encounter in everyday life. If we were asked to 

build such an application, think about how we would approach doing so at our 

organization. We would normally walk through the requirements and break the 

problem down into several sub-problems, then try to develop a step-by-step 

procedure to solve them. Since language processing is involved, we would also 

list all the forms of text processing needed at each step. This step-by-step 

processing of text is known as pipeline. It is the series of steps involved in 

building any NLP model. These steps are common in every NLP project, so it 

makes sense to study them in this chapter. Understanding some common procedures 

in any NLP pipeline will enable us to get started on any NLP problem encountered 

in the workplace. Laying out and developing a text-processing pipeline is seen 

as a starting point for any NLP application development process. In this 

chapter, we will learn about the various steps involved and how they play 

important roles in solving the NLP problem and we’ll see a few guidelines 

about when and how to use which step. In later chapters, we’ll discuss 

specific pipelines for various NLP tasks (e.g., Chapters 4–7)." 

my_sentences = sent_tokenize(mytext)

2. 分词

与句子切分类似，要将句子切分成词，也可以从一个简单的规则开始：根据标点符号将文

本切分成词。NLTK 库实现了这一功能。仍然使用前面的例子：

for sentence in my_sentences: 

 print(sentence) 

 print(word_tokenize(sentence))

对于第一个句子，输出打印如下：

In the previous chapter, we saw a quick overview of what is NLP, what are some 

of the common applications and challenges in NLP, and an introduction to 

different tasks in NLP. 

['In', 'the', 'previous', 'chapter', ',', 'we', 'saw', 'a', 'quick', 

'overview', 'of', 'what', 'is', 'NLP', ',', 'what', 'are', 'some', 'of', 'the', 

'common', 'applications', 'and', 'challenges', 'in', 'NLP', ',', 'and', 'an', 

'introduction', 'to', 'different', 'tasks', 'in', 'NLP', '.']

虽然现成的解决方案可以满足大多数需求，而且大多数自然语言处理库附带分词器和句子

切分器，但重要的是，它们还远远不够完美。例如，考虑这样一个句子，“Mr. Jack O’Neil 

works at Melitas Marg, located at 245 Yonge Avenue, Austin, 70272”。使用 NLTK 分词器分词后，

“O”“’”和“Neil”被识别为三个独立的词。类似地，如果通过这个分词器运行这个句子，

“There are $



10,000 and € 1000 which are

there just for testing a tokenizer”，“



$”和“10,000”

被识别为两个词，而“€1000”被识别为一个词。另外，如果要对推文进行分词，这个分

词器会将标签切分成两个词：“#”号和后面的字符串。在这种情况下，可能需要使用专门

构建的自定义分词器。回到刚才的例子，总之，在执行句子切分之后，还要执行分词。

38 ｜ 第 2 章

需要注意，NLTK 还有一个推文分词器。第 4 章和第 8 章会讲述它的用法。总而言之，尽

管词和句子的切分方法看起来是初级的和易于实现的，但它们可能并不总能满足特定的切

分需求，正如以上示例所示。请注意，以上是 NLTK 的示例，但是这些观察结果同样适用

于其他库。这里把其他库的探索留给读者作为练习。

正如分词可能因领域而异，分词也严重依赖于语言。每种语言都有不同的语言规则和例外

情况。图 2-6 显示了一个例子，其中“N.Y.!”共有三个标点符号。但在英语中，N.Y. 代表

纽约，因此“N.Y.”应被视为一个词，不应进一步切分。这种特定于语言的例外情况可以

在 spaCy 提供的分词器中指定。另外，spaCy 还可以开发自定义规则，用于处理具有丰富

屈折变化（前缀或后缀）和复杂形态的语言的例外情况。

前缀

例外

后缀

后缀

例外

完成

图 2-6：特定于语言（此处为英语）的分词的例外情况（参见 spaCy 网站文章“spaCy 101: Everything 

you need to know”）

另一个需要记住的重要事实是，任何句子切分器和分词器都会对接收到的输入敏感。假设

需求是编写一个软件，从求职信中提取公司、职位和薪水等信息。求职信遵循一定的格

式，包括收件人地址、发件人地址、文末签名等。在这种情况下，应该如何决定什么是句

子？是整个地址被当作一个“句子”，还是每一行都单独切分？这些问题的答案取决于想

要提取的内容，以及流水线其他部分对此类决策的敏感程度。对于识别特定的模式（例如

日期或货币表达式），格式良好的正则表达式是第一步。在许多实际场景中，最终可能会

使用适合文本结构的自定义分词器或句子切分器，而不是标准自然语言处理库中现有的分

词器或句子切分器。

2.3.2　常用步骤

现在来看自然语言处理流水线中其他一些常用的预处理操作。假设需求是设计一个软件，

将新闻文章的类别标识为政治、体育、商业和其他四类。假设有一个好的句子切分器和分

词器。这时，就必须开始思考什么样的信息对开发分类工具是有用的。英语中的一些常用

自然语言处理流水线 ｜ 39

词，如 a、an、the、of、in 等，对这项任务来说并不是特别有用，因为它们本身不携带任

何含义来区分这四个类别。这样的词叫停用词。在这样的问题场景中，停用词通常（但并

不总是）需要删除，以便进一步分析。不过，英语没有标准的停用词列表。虽然有一些常

见的列表（例如 NLTK 就有一个），不过停用词可能会根据正在处理的内容而有所不同。

例如，“news”可能是这个问题场景的停用词，但对于上一步示例中的求职信数据，可能

又不是停用词。

类似地，在某些情况下，大写或小写可能对问题没有影响。因此，所有的文本都转换成小

写（或者大写，不过小写更常见）。另外，删除标点和 / 或数字也是许多自然语言处理问题

的常见步骤，例如文本分类（第 4 章）、信息检索（第 7 章）和社交媒体分析（第 8 章）。

这些步骤是否有用，以及如何有用，接下来的内容会给出示例。

下面的代码示例显示了如何删除给定文本集合中的停用词、数字和标点符号，并将其转换

成小写：

from nltk.corpus import stopwords 

from string import punctuation 

def preprocess_corpus(texts): 

 mystopwords = set(stopwords.words("english")) 

 def remove_stops_digits(tokens): 

 return [token.lower() for token in tokens if token not in mystopwords and 

 not token.isdigit() and token not in punctuation] 

 return [remove_stops_digits(word_tokenize(text)) for text in texts]

需要注意的是，这四个过程在本质上既不是强制的，也不是顺序的。上面的函数只是用于

说明如何将这些处理步骤添加到项目中。这里看到的预处理，虽然针对的是文本数据，但

并没有涉及语言学特征，也就是除了频率（停用词是出现非常频繁的词）之外，并不关注

任何语言特征，而且删除的都是非字母数据（标点符号、数字）。将词级属性考虑在内的

两个常用预处理步骤分别是词干提取和词形还原。

词干提取和词形还原

词干提取是指去掉后缀并将一个词简化为某种基本形式的过程，以便该词的所有不同变体

都可以用相同的形式表示（例如，“car”和“cars”都被简化为“car”）。这是通过应用一

组固定的规则来完成的（例如，如果该词以“es”结尾，则删除“es”）。更多这样的例子

如图 2-7 所示。虽然这样的规则可能并不总是得到语言学上正确的基础形式，但词干提取

通常用于搜索引擎，以将用户查询与相关文档匹配，也用于文本分类，以减少特征空间来

训练机器学习模型。

词干提取 词形还原

图 2-7：词干提取和词形还原的区别（参见 Devopedia 网站的文章“Lemmatization”）

40 ｜ 第 2 章

下面的代码片段显示了如何使用 NLTK Porter Stemmer 这种词干提取算法：

from nltk.stem.porter import PorterStemmer 

stemmer = PorterStemmer() 

word1, word2 = "cars", "revolution" 

print(stemmer.stem(word1), stemmer.stem(word2))

这给出了“cars”的词干“car”，“revolution”的词干“revolut”，不过“revolut”在语言学

上并不正确。虽然这可能不会影响搜索引擎的性能，但在其他一些情况下，推导出正确的

语言形式是有用的。这可以通过词形还原来完成。词形还原和词干提取很接近。

词形还原是将一个词的所有不同形式映射到其基本词或词元（lemma）的过程。虽然这看

起来很接近词干提取的定义，但事实上它们是不同的。例如，形容词“better”在词干提取

后保持不变，但在词形还原后，应该变成“good”，如图 2-7 所示。词形还原需要较多的语

言学知识，建模和开发高效的词形还原器仍然是自然语言处理研究中的一个遗留问题。

以下代码片段显示了 NLTK 中基于 WordNet 的词形还原器的用法：

from nltk.stem import WordNetLemmatizer 

lemmatizer = WordNetLemmatizer() 

print(lemmatizer.lemmatize("better", pos="a")) # a代表形容词

以下代码片段显示了 spaCy 的词形还原器：

import spacy 

sp = spacy.load('en_core_web_sm') 

token = sp(u'better') 

for word in token: 

 print(word.text, word.lemma_)

NLTK 打印输出为“good”，而 spaCy 打印输出为“well”——两者都是正确的。由于词形

还原需要对词及其上下文进行一定程度的语言分析，因此它比词干提取要花更长的时间，

而且通常只有在绝对必要时才使用。接下来的内容还会涉及词干提取和词形还原的使用。

词形还原器的选择根据情况而定，可以选择 NLTK 或 spaCy。这具体取决于其他预处理步

骤使用的是什么框架，但最终的目的是确保在完整的流水线中使用同一种框架。

记住，并非所有这些步骤都是必需的，也不是所有这些步骤都是按照这里讨论的顺序执行

的。例如，如果要删除数字和标点符号，那么谁先删除可能无关紧要。但是，文本转小写

通常先于词干提取，而词形还原先于删除词元或文本转小写，这是因为词形还原需要知道

词的词性，而这又要求句子中的所有词都必须原封不动。一个好的做法是，在对如何处理

数据有了清楚的了解之后，按顺序编写一个预处理任务列表。

图 2-8 简要总结了到目前为止这一节中介绍的各种预处理步骤。

请注意，这些是常见的预处理步骤，但它们绝不是详尽无遗的。根据数据的性质，其他预

处理步骤可能也很重要。下面来看其中的一些步骤。

自然语言处理流水线 ｜ 41

42 ｜ 第 2 章

文本

句子

句子切分

小写转换

标点删除

词干提取

词形还原

基本步骤

句子

图 2-8：文本块的常见预处理步骤

2.3.3　其他预处理步骤

以上是自然语言处理流水线的常见预处理步骤。虽然没有明确说明文本的性质，但都假设

处理的是普通英语文本。但如果情况并非如此，那预处理步骤又有什么不同？下面用几个

例子介绍处理这类场景的几个预处理步骤。

1. 文本规范化

考虑这样一个场景：使用社交媒体帖文来检测新闻事件。社交媒体文本与报纸上看到的语

言有很大的不同。一个词可以用不同的方式拼写，包括缩写形式，一个电话号码可以用不

同的格式书写（例如，带连字符和不带连字符），名字有时用小写，等等。当我们致力于

开发自然语言处理工具来处理这类数据时，将所有这些变体捕获到一个表示中并获得文本

的规范表示是很有用的。这就是所谓的文本规范化。文本规范化的一些常见步骤是将所有

文本转换为小写或大写，将数字转换为文本，展开缩写，等等。spaCy 的源代码提供了文

本规范化的一种简单方法，它是一个字典，将预置单词集合的不同拼写映射到单一拼写

上。第 8 章会给出文本规范化的更多示例。

2. 语言检测

很多网络内容是非英语语言的。以收集网上的所有产品评论为例。当浏览各个电商网站并

开始爬取相关的产品页面时，一些非英语评论出现了。既然流水线大部分是用特定于语言

的工具构建的，那么本来期待英语文本的自然语言处理流水线会发生什么呢？在这种情况

下，自然语言处理流水线的第一步就是执行语言检测。可以使用 Polyglot 之类的库进行语

言检测。完成这一步后，接下来的步骤可以沿用特定于语言的流水线。

3. 语码混用和音译

上面讨论了文本内容是非英语语言的场景。然而，还有另一种情况，即一段内容使用多种

自然语言处理流水线 ｜ 43

语言。世界上许多人在日常生活中讲不止一种语言。因此，在社交媒体帖文中使用多种语

言并不少见，甚至一篇帖文中也可能包含多种语言。图 2-9 展示了一个新加坡式英语（新

加坡俚语 + 英语）短语，作为语码混用的一个例子。

翻译：嘿，当我们约会时，我们总在那家咖啡厅吃饭。

泰米

尔文

中文，普通话

（我们）

??? 中文，粤语

（拍拖）

英文 英文 马来文 马来文 中文，闽南语

（店）

图 2-9：新加坡式英语短语中的语码混用

这个流行短语中包含泰米尔文、英文、马来文和中文。语码混用指的是这种在语言之间切

换的现象。当人们在书面写作中使用多种语言时，他们经常用罗马文字和英语拼写来输入

这些语言中的词汇。因此，其他语言的词汇被写在英语文本中。这就是所谓的音译。这两

种现象在多语言社区中都很常见，需要在文本预处理过程中加以处理。第 8 章将讨论更多

这方面的内容，并给出社交媒体文本中出现这些现象的例子。

对常见预处理步骤的讨论到此结束。虽然这个列表并不是详尽无遗的，但是希望它能让你

明白不同性质的数据集可能需要不同形式的预处理。自然语言处理流水线还有一些预处理

步骤需要高级的语言处理，下面来看一下。

2.3.4　高级处理

假如现在需要开发一个系统来识别公司 100 万份文档中的人员和组织名称，那么前面讨论

的常见预处理步骤就无能为力了。识别名称需要词性标注。如果词性是专有名词，那么这

将有助于识别人员和组织名称。如何在项目的预处理阶段进行词性标注？本书不会详细讨

论词性标注器的开发（详见 Daniel Jurafsky 和 James H. Martin 的著作 Speech and Language 

Processing (3rd ed. draft) 中的第 8 章）。预先训练好的、易于使用的词性标注器已在 NLTK、

spaCy、Parsey McParseface Tagger 等自然语言处理库中实现，通常不必开发自己的词性标

注解决方案。下面的代码片段说明了如何使用预置在 spaCy 库中的多个预处理函数：

import spacy 

nlp = spacy.load('en_core_web_sm') 

doc = nlp(u'Charles Spencer Chaplin was born on 16 April 1889 toHannah Chaplin 

 (born Hannah Harriet Pedlingham Hill) and Charles Chaplin Sr') 

for token in doc: 

 print(token.text, token.lemma_, token.pos_, 

 token.shape_, token.is_alpha, token.is_stop)

在这个简单的代码片段中，可以看到分词、词形还原、词性标注和其他几个步骤。注意，

如果需要，还可以在这个代码片段中添加其他的处理步骤，这里留给读者作为练习。需要

注意的是，对于相同的预处理步骤，不同自然语言处理库的输出可能存在差异。部分原因

是，不同的库使用不同的实现和算法。最终在项目中使用哪一个（或多个）库，是一个主

观决定，取决于所需的语言处理量。

44 ｜ 第 2 章

现在考虑一个稍微不同的问题：除了在公司的 100 万份文档中识别人员和组织名称之外，

还需要识别给定的个人和组织是否具有某种关系 [ 例如，萨蒂亚 • 纳德拉和微软之间的关

系是“首席执行官”（CEO）]。这就是所谓的关系提取问题，第 5 章将详细讨论。但是现

在先想一下这种情况需要什么样的预处理。首先需要词性标注，前面已经介绍如何把词性

标注添加到流水线。其次需要一种识别人员和组织名称的方法，这是一个单独的信息提取

任务，称为命名实体识别（named entity recognition, NER），具体将在第 5 章中讨论。除此

之外，还需要一种方法来识别句子中两个实体之间的“关系”模式。这就需要对句子有某

种形式的句法表示，比如句法解析，这在第 1 章中已经谈到。此外，还需要一种方法来识

别和链接一个实体的多个提及（例如，萨蒂亚 • 纳德拉、纳德拉先生、他等）。这一点通过

共指消解预处理步骤来实现。第 1 章的 1.5 节中展示了这方面的一个例子。图 2-10 显示了

Stanford CoreNLP 的输出，包括示例句子的句法解析器输出和共指消解输出，以及前面讨

论过的其他预处理步骤。

输入

词性标注

句法解析树

共指消解

词形还原和分词

提及 提及 共指

图 2-10：自然语言处理流水线不同阶段的输出

自然语言处理流水线 ｜ 45

到目前为止，本节展示的是流水线中一些最常见的预处理步骤。在各个自然语言处理库

中，都有经过预先训练的模型，可以直接使用。除此之外，可能还需要额外的、定制的预

处理，具体取决于应用程序。例如，考虑这样一个案例：挖掘产品的社交媒体情绪。从

Twitter 上收集数据后，很快就会发现有些推文不是用英语写的。在这种情况下，可能需要

在其他步骤之前加一个语言检测步骤。

此外，需要哪些步骤，还取决于具体的应用程序。如果创建的系统是识别影评人在影评中

表达对电影的正向情感或负向情感，可能就不用太担心句法解析或共指消解，但会考虑去

掉停用词、小写转换和去掉数字。然而，如果对从电子邮件中提取日历事件感兴趣，那么

最好不要删除停用词或进行词干提取处理，而是增加句法解析等步骤。如果想要提取文本

中不同实体和其中提到的事件之间的关系，那么将需要共指消解，正如前面所讨论的。第

5 章会展示需要这些步骤的例子。

最后，必须考虑每种情况下预处理的详细程序，如图 2-11 所示。

文本

句子

句子切分

小写转换

标点删除

词干提取

词形还原

基本步骤

词性标注

句法解析

共指消解

高级步骤

句子

图 2-11：文本块的高级预处理步骤

例如，词性标注前不能先去掉停用词、转换小写等，否则会改变句子的语法结构，从而影

响词性标注器的输出。预处理步骤如何帮助处理某个给定的自然语言处理问题，这也是特

定于应用程序的，只能通过大量的实验来回答。接下来的内容还会再次讨论不同自然语言

处理应用程序所需的更具体的预处理步骤。现在进入下一个步骤：特征工程。

2.4　特征工程

前面介绍了不同的预处理步骤，以及它们的应用范围。但在后面使用机器学习方法来执行

建模步骤之前，仍然需要一种方法来将预处理后的文本馈送到机器学习算法中。特征工程

是指完成这项任务的一套方法，也叫特征提取，其目标是捕捉文本的特征，将其转换成可

以被机器学习算法理解的数值向量。在本书中，这一步骤称为“文本表示”，这是第 3 章

46 ｜ 第 2 章

的主题。此外，第 11 章还将在通过开发完整的自然语言处理流水线和迭代流水线来提高

性能的背景下详细介绍特征提取。这里简要介绍：(1) 经典自然语言处理和传统机器学习

流水线；(2) 深度学习流水线中特征工程的两种不同方法。图 2-12（改编自 Parsa Ghaffari

的文章“Leveraging Deep Learning for Multilingual Sentiment Analysis”）显示了这两种方法

的区别。

经典自然语言处理

预处理

建模

输出

输出

文档

文档

分词 词性标注 停用词

删除

推理 建模 特征提取

情感

分类

实体提取

翻译

主题建模

预处理 基于深度学习的自然语言处理

情感

分类

实体提取

翻译

主题建模

稠密嵌入

通过word2vec、doc2vec、

GloVe等获得

隐藏层 输出单元

图 2-12：经典自然语言处理与基于深度学习的自然语言处理的特征工程

2.4.1　经典自然语言处理/机器学习流水线

特征工程在任何机器学习流水线中都是一个不可或缺的步骤。特征工程步骤将原始数据转

换为机器可以使用的格式。在经典的机器学习流水线中，这些转换函数通常是人工编写

的，以适应手头的任务。考虑电商产品评论的情感分类任务。如何将评论转换成有意义的

“数值”，以帮助预测评论的情感（正向或负向）？一种方法是计算每个评论中正向和负向

词的数量。另外，还有其他统计方法可以用来理解某个特征是否对任务有用，第 11 章会

讨论这个问题。构建经典机器学习模型的主要启示是，这些特征在很大程度上需要手头任

务和领域知识的启发（例如，在影评示例中使用情感词汇）。人工提取特征的一个优点是

模型可以保持可解释性——可以精确量化每个特征对模型预测的影响程度。

2.4.2　深度学习流水线

经典机器学习模型的主要缺点是特征工程。人工提取特征工程已经成为模型性能和模型开

发周期的瓶颈。一个有噪声或不相关的特征可能会给数据增加更多的随机性，从而潜在地

损害模型的性能。最近，随着深度学习模型的出现，这种方法发生了变化。在深度学习流

水线中，原始数据经过预处理后，直接输入模型，模型能够直接从数据中“学习”特征。

因此，这些特征与手头任务更一致，通常可以提高性能。但是，由于所有这些特征都是通

过模型参数学习的，因此模型失去了可解释性。很难解释深度学习模型的预测，这在业务

驱动的用例中是一个缺点。例如，当把一封电子邮件识别为正常邮件或垃圾邮件时，需要

知道哪个词或短语在造成正常邮件或垃圾邮件中发挥了重要作用。虽然这对于人工提取特

征来说很容易做到，但对于深度学习模型来说就不容易了。

正如前面提到的，特征工程是非常特定于任务的，因此本书会以文本数据和一系列任务为背

景来讨论特征工程。有了对特征工程的高层次理解之后，现在来看流水线的下一步：建模。

2.5　建模

假如现在有了自然语言处理项目的相关数据，并且也清楚地知道需要做什么样的清洗和预处

理以及需要提取哪些特征。那么下一步就是如何在此基础上构建一个有用的解决方案。在开

始阶段，当拥有的数据有限时，可以使用简单的方法和规则。随着时间的推移，随着数据的

增加和对问题理解的加深，就可以增加更多的复杂性并提高性能。本节将介绍这一过程。

2.5.1　从简单的启发式开始

在构建模型的最开始，机器学习本身可能不会发挥主要作用，部分原因是缺乏数据。另

外，人工构建的启发式方法在某种程度上也可以提供一个很好的开端。有时，启发式——

或者隐式，或者显式——可能已经是系统的一部分。例如，在垃圾邮件分类任务中，对专

发垃圾邮件的域设置黑名单。这些信息可以用来过滤来自这些域的电子邮件。类似地，把

极有可能表示垃圾邮件的词加入黑名单，也可以用于垃圾邮件分类。

这种启发式方法可以在一系列任务中找到，尤其是在应用机器学习的开始阶段。在电子商

务场景中，可以使用基于购买数量的启发式，来对搜索结果进行排序，并显示属于同一类

自然语言处理流水线 ｜ 47

别的产品作为推荐。与此同时，可以收集数据，构建一个更大的协同过滤系统，从而根据

具有相似购买习惯的客户所购买的产品等一系列其他特征来推荐产品。

另一种在系统中引入启发式的常见方法是使用正则表达式。考虑从文本文档中提取日期、

电话、人名等不同形式的信息。虽然电子邮件地址、日期和电话号码等信息可以使用普通

（但也复杂）的正则表达式提取，但 Stanford NLP 的 TokensRegex 和 spaCy 的“基于规则

的匹配器”这两个工具，可以定义高级的正则表达式，以捕获人名等其他信息。图 2-13 显

示了 spaCy 的基于规则的匹配器的一个实例。

图 2-13：spaCy 基于规则的匹配器

该模式将查找包含词元为“match”（且为名词形式）的文本，而且该词前面可以有一个形

容词，但是后面必须跟着词元为“be”的词。这种模式是正则表达式的高级形式，需要本

章前面介绍的一些自然语言处理预处理步骤。在缺乏大量训练数据的情况下，如果有一些

领域知识，就可以使用规则 / 启发式来编码这些知识以开始构建系统。即使在构建基于机

器学习的模型时，也可以使用这种启发式来处理特殊情况，例如模型效果不好的情况。因

此，简单的启发式可以提供一个很好的起点，而且启发式在机器学习模型中也是有用的。

假设现在已经构建了基于启发式的系统，那么接下来应该怎么办？

2.5.2　构建自己的模型

虽然一组简单的启发式是一个好的开始，但是随着系统的成熟，添加越来越新的启发式可

48 ｜ 第 2 章

能会导致一个复杂的、基于规则的系统。这样的系统很难管理，诊断错误的原因可能更

难。我们需要一个在成熟时更容易维护的系统。此外，随着收集的数据越来越多，机器学

习模型开始战胜纯粹的启发式方法。这时，通常的做法是将启发式直接或间接地与机器学

习模型相结合。有两种方法可以做到这一点。

为机器学习模型创建启发式特征

当存在许多启发式时，其中单个启发式的行为是确定的，但它们的组合行为在预测效果

方面是模糊的，因此最好使用这些启发式作为特征来训练机器学习模型。例如，在垃圾

邮件分类示例中，可以向机器学习模型添加一些特征，例如电子邮件中黑名单中的词出

现的次数，或电子邮件弹回率。

对机器学习模型的输入进行预处理

如果启发式方法对于某个类别有很高的预测率，那么最好在将数据输入机器学习模型之

前使用它。例如，如果电子邮件中的某些词可以 99% 地判定这是垃圾邮件，那么最好

将该电子邮件直接分类为垃圾邮件，而不是将其发送到机器学习模型。

此外，自然语言处理服务提供商——如谷歌云自然语言、亚马逊 Comprehend、微软 Azure

认知服务、 IBM 沃森自然语言理解——提供了现成的 API 来解决各种自然语言处理任务。

如果项目中的自然语言处理问题可以由 API 解决，那么不妨使用 API 来估计任务的可行性

以及现有数据集的质量。一旦确信任务是可行的，并且现成的模型给出了合理的结果，就

可以开始构建自定义的机器学习模型并对其进行完善。

2.5.3　构建最终模型

前面介绍了使用启发式或现有 API，抑或是通过构建自定义机器学习模型来开始构建自然

语言处理系统。从基线方法开始，只有不断改进模型，经过多次迭代后，才有可能构建具

有良好性能并可用于生产的“最终模型”。下面介绍解决这个问题的一些方法。

集成与编排

根据经验，常见的做法不是使用单一的模型，而是使用一组机器学习模型，从而应对预

测问题的不同方面。这里有两种方法。其一是将一个模型的输出作为另一个模型的输

入，从而顺序地从一个模型进入另一个模型，并获得最终的输出。这叫模型编排 1。其二

是将多个模型的预测结果汇集起来，并做出最终的预测。这叫模型集成。图 2-14 展示

了这两种过程。

在图 2-14 中，训练数据用于构建模型 1、2 和 3。这些模型的输出合并后进入元模型

（模型的模型），以预测最终结果。例如，在垃圾邮件分类案例中，假设运行了三种不同

的模型：基于启发式的评分模型、朴素贝叶斯模型和 LSTM 模型，这三个模型的输出

随后会输入基于逻辑回归的元模型中，然后由元模型给出电子邮件是否为垃圾邮件的概

率。随着产品特征的增多，模型的复杂性也会增加。因此，最终可能会组合使用启发

式、机器学习、编排和集成模型等多种方式，以整合到更大的产品中。

注 1：这与 LSTM 等神经网络中的垂直编排不同。

自然语言处理流水线 ｜ 49

50 ｜ 第 2 章

编排

集成

模型 1

模型 2 元模型

训练数据 最终预测

模型 3

第 1 层 第 2 层 2 层输入第

图 2-14：模型集成与编排

更好的特征工程

无论是基于 API 的模型，还是自定义的模型，特征工程都是重要的一步，而且特征工

程还会在整个过程中不断演进。更好的特征工程可能会带来更好的性能。如果有很多的

特征，那么可以使用特征选择来找到较好的模型。第 11 章会详细介绍如何迭代特征工

程以实现最佳设置的策略。

迁移学习

除了模型编排和集成之外，自然语言处理界还有一种新的趋势正在流行，这就是迁移学

习，第 1 章介绍过。通常，为了更好地理解语言和问题，模型需要数据集之外的外部知

识。迁移学习试图在初始阶段将先前存在的知识从训练好的大型模型迁移到新的模型

中。然后，新模型会慢慢适应手头的任务。这就好比老师把智慧和知识传授给学生。迁

移学习提供了更好的初始化，这有助于下游任务，特别是当下游任务的数据集较小时。

在这些情况下，迁移学习比直接随机初始化效果更好。例如，在垃圾邮件分类中，可以

使用 BERT 来微调电子邮件数据集。第 4~6 章会详细讨论 BERT。

再次使用启发式

机器学习模型并非完美无缺。它们仍然会出错。因此，在建模流水线的最后，不妨再来

看一看这些错误情况，发现其中的常见模式，并使用启发式方法来纠正错误。另外还可

以使用无法从数据中捕捉的特定领域知识，来改进模型预测。如果说模型是表演惊人技

巧的空中飞人，那么启发式规则就是安全网，保证表演者不会从空中掉下来。

从完全依赖启发式的无数据阶段，到可以尝试一系列建模技术的多数据阶段，中间会遇到

这样的情况：拥有少量的数据，但又通常不足以构建好的机器学习模型。在这样的场景

中，一种可以遵循的方法是主动学习，即利用用户反馈或其他类似来源不断收集新的数

据，以构建更好的模型。第 4 章将详细讨论这一点。正如刚才所看到的，建模策略在很大

程度上依赖于手头的数据。表 2-1 显示了基于数据数量和质量的决策路径。

自然语言处理流水线 ｜ 51

表2-1：数据特点和相应的决策路径

数据特点 决策路径 示例

数据量大 可以使用需要较多数据的技术，如深度学习。

也可以使用更丰富的特征集。如果数据足够

大但没有标注，也可以使用无监督技术

如果拥有很多评论和与之相关的元数

据，可以从头开始构建情感分析工具

数据量小 需要从对数据需求较少的基于规则的解决方

案或传统的机器学习解决方案开始。还可以

使用云 API 并在弱监督下生成更多数据

如果类似的任务有大量的数据，也可以使用

迁移学习

这通常发生在全新项目的开始阶段

数据质量差，数据

异质性严重

可能需要更多的数据清洗和预处理 可能存在语码混用（不同语言在同一

个句子中混用）、非常规语言、音译或

噪声（如社交媒体文本）等问题

数据质量良好 可以更容易地直接应用现成的算法或云 API 法律文本或报纸

数据由具有完整长

度的文档组成

根据问题的不同，选择正确的策略将文档切

分成较低的层次，如段落、句子或短语

文档分类、评论分析等

以上简要介绍了自然语言处理流水线中用到的不同建模形式，以及如何根据所拥有的数据

选择建模路径。在行业场景中构建自然语言处理项目时，监督学习，特别是分类，是最常

见的建模过程。第 4 章将讨论分类模型，第 5~7 章将讨论自然语言处理中用于不同应用场

景的模型。现在来看流水线中的下一步：评估。

2.6　评估

自然语言处理流水线的一个关键步骤是衡量模型的质量。模型的质量可以有多种含义，但

最常见的解释是用新数据来衡量模型的性能。这一阶段的成功取决于两个因素：(1) 使用

正确的评估指标；(2) 遵循正确的评估流程。先关注第一个因素。根据自然语言处理任务

或问题的不同，评估指标可能会有所不同。评估指标还可能根据不同阶段而有所不同：模

型构建、部署和生产阶段。在前两个阶段，通常使用机器学习指标来评估。在最后一个阶

段，还会使用业务指标来衡量业务影响。

此外，评估还分成两种类型：内在评估和外在评估。内在评估侧重于中间目标，而外在评

估侧重于最终目标。考虑垃圾邮件分类系统的例子。机器学习指标是精确率和召回率，而

业务指标则是“用户在垃圾邮件上花费的时间”。内在评估侧重于使用精确率和召回率来

衡量系统的性能。外部评估侧重于衡量用户因垃圾邮件未被检测出来或普通邮件被误检测

为垃圾邮件而浪费的时间。

2.6.1　内在评估

本节将探讨衡量自然语言处理系统常用的内在评估指标。大多数内在评估指标需要设置测

试集，其中有真实值或标签（即人类标注的正确答案）。标签可以是二分类的（例如，文

本分类为 0/1）、一两个词（例如，命名实体识别的名称），或者大段文本本身（例如，机

器翻译后的文本）。将自然语言处理模型对数据点的输出与该数据点的对应标签进行比较，

52 ｜ 第 2 章

并且根据输出与标签之间的匹配（或不匹配）来进行指标计算。对于大多数自然语言处理

任务，比较可以自动化，因此内在评估也可以自动化。对于某些情况，如机器翻译或摘

要，因为不能像人类一样做出主观判断，所以自动化评估并不总是可能的。

表 2-2 列出了用于不同自然语言处理任务的内在评估的各种指标。有关指标的详细讨论，

请参阅相应的参考资料。

表2-2：常用的指标和对应的自然语言处理应用程序

指标 描述 应用程序

准确率 当输出变量是分类变量或离散变量时使用。

它表示模型做出正确预测的次数与它所做的

预测总数的比率

主要用于分类任务，如情感分类（多

分类）、自然语言推理（二分类）、释

义检测（二分类）等

精确率 显示模型的预测有多精确，即给定所有的正

例（所关心的类别），模型能正确分类的有

多少

用于各种分类任务，特别是正类错误

比负类错误代价更大的情况，例如医

疗保健中的疾病预测

召回率 召回率是精确率的补充。它捕捉了模型对正

类别的召回程度，即考虑到模型做出的所有

正类别预测，其中有多少是真正的正类别

用于分类任务，特别是检索正类别结

果更为重要的情况，例如电子商务搜

索和其他信息检索任务

F1 分数 结合精确率和召回率给出了一个单一的衡量

指标，这也捕捉了精确率和召回率，即完整

性和准确性之间的权衡

F1 定义为 (2× 精确率 × 召回率 )/( 精确率

+ 召回率 )

在大多数分类任务中与准确率同时使

用。它还可以用于序列标注任务，如

实体提取、基于检索的问题回答等

ROC 曲线下面积 捕获当改变预测阈值时，正确的正预测数与

不正确的正预测数之比

用于衡量独立于预测阈值的模型质量。

用于寻找分类任务的最佳预测阈值

MRR（平均排序倒数） 用于在给定其正确性概率的情况下评估检索

到的响应。它是检索结果排序倒数的平均值

大量用于各种信息检索任务，包括文

章搜索、电子商务搜索等

MAP（平均精度均值） 用于排序检索结果，如 MRR。它计算每个

检索结果的平均精度

用于信息检索任务

RMSE（均方根误差） 捕获模型在实际值预测任务中的性能。计算

每个数据点的均方根误差

与 MAPE 一起用于回归问题，例如

温度预测和股价预测

MAPE（平均绝对百分

比误差）

当输出变量为连续变量时使用。它是每个数

据点的绝对百分比误差的平均值

用于测试回归模型的性能

通常与均方根误差一起使用

BLEU（双语评估辅助

指标）

捕获输出语句和参考语句之间的 n-gram 重

叠度。它有很多变体

主要用于机器翻译任务。最近适应于

其他文本生成任务，如释义生成和文

本摘要

METEOR 一种基于精度的指标，用于衡量生成文本的

质量。它修复了 BLEU 的一些缺点，例如

计算精度时出现的精确词匹配。METEOR

允许同义词和词干与参考词匹配

主要用于机器翻译

ROUGE 还是衡量生成文本相对于参考文本的质量。

和 BLEU 不同，它衡量的是召回率

因为衡量的是召回率，所以主要用于

摘要任务。在摘要任务中，评估一个

模型能召回多少词很重要

困惑度 捕捉自然语言处理模型混乱程度的概率指

标。它源于下一个词预测任务中的交叉熵

用于评估语言模型。也可用于语言生

成任务，如对话生成

除了表 2-2 中列出的指标之外，还有更多的指标和可视化方法，用于解决自然语言处理问

题。虽然这里简要介绍了这些主题，但我们鼓励你根据参考资料，深入了解这些指标。

对于分类任务，一种常用的可视化评估方法是混淆矩阵。它允许我们检查数据集中不同类

别的实际输出和预测输出。混淆矩阵源于这样一个事实，即它有助于理解分类模型在识别

不同类别方面的“混淆”程度。混淆矩阵可以用于计算精确率、召回率、F1 分数和准确率

等指标。第 4 章将展示如何使用混淆矩阵。

像信息搜索和检索这样的排序任务主要使用基于排序的指标，如 MRR 和 MAP，但也可以

使用常用的分类指标。在检索任务中，主要关心的是召回率，因此会计算不同排序下的召

回率。例如，对于信息检索，一个常用的指标是“排名前 K 位的召回率”，它会在检索到

的前 K 个结果中寻找真实值是否存在。如果存在，则表示是成功。

当涉及文本生成任务时，根据任务的不同，可以使用多种指标。尽管 BLEU 和 METEOR

对于机器翻译来说是很好的指标，但是将其应用到其他生成任务时，它们可能不是很合

适。例如，在生成对话的情况下，真实值只是正确答案之一，还有很多不同的回答可能没

有列出来。在这种情况下，BLEU 和 METEOR 等基于精确率的指标将完全无法忠实地衡

量任务的性能。基于这些原因，人们广泛使用困惑度来衡量模型的文本生成能力。

然而，任何文本生成的评估方案都不是完美的。这是因为具有相同意思的句子可能有多

个，不可能将所有的变体都列为真实值。因此，生成的文本和真实值可以是不同的句子，

但仍然具有相同的意思。这使得自动化评估变得很难。以法英机器翻译模型为例，考虑

下面这个法语句子，“J’ai mangé trois filberts”。在英语中，这句话的意思是“I ate three 

filberts”（我吃了三个榛子）。

所以，把这句话作为标签。假设模型生成以下英文翻译，“I ate three hazelnuts”。由于输出

与标签不匹配，自动化评估会认为输出不正确。但这种评估是不正确的，因为说英语的人

经常会把 filberts 称为 hazelnuts。即使添加这句话作为一个可能的标签，模型仍然可能生成

“I have eaten three hazelnuts”作为输出。再一次，自动评估会说模型搞错了，因为输出结

果与两个标签中的任何一个都不匹配。这里就需要引入人工评估。但是人工评估的时间成

本和金钱成本都很高。

2.6.2　外在评估

如前所述，外在评估侧重于在最终目标上评估模型的性能。在行业项目中，任何人工智能

模型的构建都是以解决一个商业问题为目的的。例如，构建回归模型的目的是对用户的电

子邮件进行排序，并将最重要的电子邮件放在收件箱的顶部，从而帮助用户节省时间。考

虑这样一个场景：回归模型在机器学习指标方面做得很好，但并没有真正为电子邮件用户

节省大量时间；或者问题回答模型在内在指标方面做得很好，但无法解决生产环境中的大

量问题。这样的模型会被认为是成功的吗？不，因为它们没能实现商业目标。虽然这对学

术研究人员来说不是一个问题，但对于从业者来说，这是非常重要的问题。

进行外在评估的方法是在项目开始阶段设置业务指标以及正确衡量这些指标的流程。后面

的内容会给出正确业务指标的示例。

自然语言处理流水线 ｜ 53

你可能会问：如果外在评估很重要，那么为什么还要内在评估呢？必须在外在评估之前进

行内在评估的原因是，外在评估通常包括人工智能团队之外的项目干系人，有时甚至包括

最终用户。内在评估大部分可以由人工智能团队自己完成。这使得外在评估比内在评估更

加昂贵。因此，内在评估被看作外在评估的指标。只有在内在评估中取得一致的好结果

时，才应该进行外在评估。

另外一件需要记住的事情是，内在评估中的坏结果往往意味着外在评估中的坏结果。但

是，反过来未必会成立。也就是说，模型可能会出现好的内在评估和差的外在评估，但不

会出现好的外在评估和差的内在评估。外在评估中表现不佳的原因可能有很多，例如设置

错误的指标、不具备合适的数据或拥有错误的期望。第 1 章谈到了其中的一些，第 11 章

会有更详细的讨论。

以上介绍了内在评估通用的一些指标，以及外在评估对于衡量自然语言处理模型性能的重

要性。还有一些特定于任务的指标，并非所有的自然语言处理应用场景都会用到。接下来

的内容还会在讨论具体应用程序时详细讨论这些评估方法。现在进入流水线的剩余组件：

模型部署、监控和更新。

2.7　建模之后的阶段

模型经过反复测试之后，就进入建模之后的阶段：模型部署、监控和更新。本节将简要介

绍这些内容。

2.7.1　部署

在大多数实际应用场景中，自然语言处理模块只是大系统的一部分（例如，垃圾邮件分类

系统属于更大的电子邮件应用程序）。因此，处理、建模和评估流水线只是故事的一部分。

一旦对最终解决方案感到满意，就需要将其作为大系统的一部分部署到生产环境中。部署

意味着将自然语言处理模块插入大系统中。部署还意味着要确保输入和输出数据流水线是

有序的，并确保自然语言处理模块在高负载下是可扩展的。

自然语言处理模块通常部署为 Web 服务。假如现在设计了一个 Web 服务，它接受文本作

为输入，并返回电子邮件的类别（垃圾邮件或非垃圾邮件）作为输出。现在，每当有人收

到一封新的电子邮件时，它就会转到微服务，微服务会对电子邮件文本进行分类。这反过

来又可以用来决定如何处理电子邮件（直接显示或者发送到垃圾邮件文件夹）。在批处理

等特殊情况下，自然语言处理模块需要部署在较大的任务队列中，例如谷歌云或亚马逊云

服务中的任务队列。第 11 章将详细介绍部署。

2.7.2　监控

和任何软件工程项目一样，在最终部署之前必须进行大量的软件测试，并且在部署之后不

断地监控模型性能。由于需要确保模型每天产生的输出是有意义的，因此自然语言处理项

目和模型的监控必须不同于常规的工程项目。如果定期自动训练模型，还必须确保模型产

生合理的结果。这在某种程度上可以通过性能仪表盘来实现，性能仪表盘可以显示模型参

数和关键性能指标。第 11 章将详细讨论这一点。

54 ｜ 第 2 章

自然语言处理流水线 ｜ 55

2.7.3　模型更新

一旦部署了模型并开始收集新的数据，就可以基于新的数据来迭代模型，以保持预测为最

新。本书各章都会涉及每种任务的模型更新，特别是第 4 章到第 7 章和第 11 章。表 2-3 初

步介绍了部署之后如何针对不同的场景进行模型更新。

表2-3：项目特点和相应的决策路径

项目特点 决策路径 示例

部署后会生成更多的训练数据 一旦部署，提取的信号就可以用来自动

改进模型。也可以尝试在线学习，对模

型进行日常自动训练

基于用户标记数据的滥用检测

系统

部署后不生成训练数据 人工标注可以用来改进评估和模型

理想情况下，每个新模型都必须手动构

建和评估

更大自然语言处理流水线的子

集，无直接反馈

需要较低的模型延迟，或者模

型必须在线且响应接近实时

需要使用可以快速推断的模型。另外也

可以选择创建内存策略，比如缓存，或

者使用更强的计算能力

需要立即响应的系统，如聊天

机器人或紧急跟踪系统

不需要较低的模型延迟，或者

模型可以脱机运行

可以使用更高级和更慢的模型。这也有

助于在可行的情况下优化成本

可以在批处理过程中运行的系

统，如零售产品目录分析

2.8　使用其他语言

到目前为止，上述讨论的前提假设是英语文本。根据手头的任务，可能还需要为其他语言

构建模型和解决方案。不同的语言有着不同的处理方式。有些语言的流水线可能与英语非

常相似，而有些语言和场景可能需要重新思考如何处理问题。根据我们在非英语语言处理

项目中的工作经验，下面概括了不同语言的处理方案，如表 2-4 所示。

表2-4：语言特点与处理方案

语言特点 示例和语言 处理方案

高资源语言 既有充足数据又有预建模型的语言

例如英语、法语和西班牙语

可以使用预训练的深度学习模型。更易于使用

低资源语言 数据有限且最近才开始采用数字技术的

语言。可能没有预建模型

例如斯瓦希里语、缅甸语和乌兹别克语

根据任务的不同，可能需要标注更多的数据以及

探索各个组件

形态丰富 语言和语法信息，如主语、宾语、谓语、

时态和语气不是独立的词，而是连接在

一起的

例如拉丁语、土耳其语、芬兰语和马拉

雅拉姆语

如果语言资源不丰富，则需要探索现有的用于该

语言的形态分析器。在最坏的情况下，可能需要

人工编写规则来处理某些情况

词汇变化大 拼写不规范，词的变体较多

例如阿拉伯语和印地语没有标准拼写

如果语言资源不丰富，那么可能需要在训练任何

模型之前首先对词 / 拼写进行规范化

对于具有大型数据集的语言来说，这可能不需

要，因为模型仍然可以学习词汇变化

邮

电

56 ｜ 第 2 章

语言特点 示例和语言 处理方案

中文、日文、

韩文（CJK）

这些语言都是从古代汉字中派生出来的。

它们不是基于字母表的，有几千个字符

用于基本识字，全部字符则超过 4 万个。

因此，必须以不同的方式处理这些问题

它们包括中文、日文和韩文，因此得名

“CJK”

在这些语言中使用特定的分词方案。由于有大量

的此类语言数据可用，因此可以从头开始为各种

任务构建自然语言处理模型

它们也有预训练模型从用 CJK 以外的其他语言训

练的模型中进行迁移学习，在这种情况下可能没

有用处

接下来是案例研究，它将综合上述所有这些步骤。

2.9　案例研究

上面介绍了自然语言处理流水线的各个阶段以及每个阶段的原因、作用和加入流水线通用

框架的方式。但是，这些阶段是分开介绍的，脱离了整体背景。在真实的自然语言处理系

统流水线中，所有这些阶段是如何协同工作的？下面来看一个案例研究：使用 Uber 的人

工智能客服工具 COTA 来改善客户服务。

Uber 在全球 400 多个城市运营，根据每天使用 Uber 的人数，可以估计其客户支持团队每

天会收到数十万张关于不同问题的服务单。对于给定的服务单，有两种解决方案可供选

择。COTA 的目标是对这些解决方案进行排序，并选择可能的最佳解决方案。Uber 使用机

器学习和自然语言处理技术开发了 COTA，以提供更好的客户支持和快速高效的服务单问

题解决方案。图 2-15 显示了 Uber COTA 的流水线以及其中的各种自然语言处理组件。

数据源 预处理 特征工程 机器学习算法 预测

问题

逐点排序余弦相似性

解决方案

服务单

信息

服务单

文本

出行

数据

- 分词

- 小写转换

- 停用词删除

- 词形还原

LSI

TF-IDF

图 2-15：Uber 服务单系统服务单排序的自然语言处理流水线

在该系统中，识别服务单问题并选择解决方案需要三个信息来源，如图 2-15 所示。服务单

文本，顾名思义，就是文本内容，这是自然语言处理发挥作用的地方。通过移除 HTML 标

记（图 2-15 中未显示）来清洗文本后，预处理步骤包括分词、小写转换、停用词删除和词

形还原。本章前面已经介绍了如何完成这些步骤。经过预处理后，服务单文本被表示为词

（续）

的集合（称为词袋，第 3 章将详细讨论）。

流水线的下一步是特征工程。前面获得的词袋进入两个自然语言处理模块：TF-IDF（词

频 – 逆文档频率）和 LSI（潜在语义索引），这两个模块使用词袋表示来理解文本的含义。

这个过程属于主题建模，第 7 章会讨论。那么 Uber 如何在这种背景下使用这些自然语言

处理任务？ Uber 在数据库中找到每个解决方案的历史服务单，为每个解决方案形成一个

词袋向量表示，并基于这些表示创建一个主题模型。然后，将传入的服务单映射到解决方

案的主题空间，为服务单创建一个向量表示。余弦相似性是衡量任意两个向量之间相似度

的一种常用方法。它用于创建一个向量，其中每个元素指示服务单文本与某个解决方案的

相似度。因此，在特征工程步骤的最后，会得到一个表示，该表示指示服务单文本与所有

可能解决方案的相似性。

下一阶段是建模。在建模过程中，上面得到的表示会与服务单信息和出行数据相结合，构

建一个排名系统，显示服务单的三个最佳解决方案。在排名系统中，排序模型为二分类系

统，它将每个服务单和解决方案的组合分类为匹配或不匹配。然后根据评分函数对多个匹

配项进行排名。

流水线的下一步是评估。在这种情况下，评估是如何工作的？虽然模型性能本身的评估可

以根据内在评估指标（如 MRR）来完成，但是这种方法的总体有效性是通过外在评估判

断的。据估计，COTA 的快速服务单解决方案每年能为 Uber 节省数千万美元。

正如前面所了解到的，一个模型并非只构建一次。COTA 也在不断试验和改进。在探索

了一系列深度学习架构之后，最终选择的最佳解决方案与之前的二分类排序系统相比，

准确率提高了 10%。不过，这一过程并没有就此结束。从 COTA 团队的文章“COTA: 

Improving Uber Customer Care with NLP & Machine Learning”中可以看到，这个过程是模

型部署、监控和更新的连续过程。

2.10　小结

本章介绍了给定项目描述开发自然语言处理流水线所涉及的各个步骤，并给出了实际应用

程序的详细案例研究。此外，还介绍了传统的自然语言处理流水线和基于深度学习的自然

语言处理流水线的区别，并介绍了非英语语言的处理方法。除了具体的案例研究，本章还

以更一般的方式介绍了这些步骤。每个步骤的具体细节取决于手头的任务和实现的目的。

从第 4 章开始，本书将关注特定于任务的流水线，并详细描述不同任务之间流水线的相同

点和不同点。第 3 章将详细讨论前面提到的文本表示问题。

自然语言处理流水线 ｜ 57

58

第 3 章

文本表示

在语言处理中，用向量 x 表示文本数据，以反映文本的各种语言属性。

——约阿夫 • 戈尔德贝格

对于任何机器学习问题，特征提取都是一个重要的步骤。不管建模算法有多好，差的特征

肯定会导致差的结果。在计算机科学中，这通常称为“垃圾进，垃圾出”。前两章已经介

绍了自然语言处理的概述，所涉及的不同任务和挑战，以及典型的自然语言处理流水线。

本章将讨论这样一个问题：如何对文本数据进行特征工程。换句话说，如何将给定的文本

转换成数值形式，从而可以将其输入自然语言处理和机器学习算法中。在自然语言处理

中，这种将原始文本转换为适当数值形式的过程叫文本表示。本章将研究文本表示（将文

本表示为数值向量）的不同方法。在自然语言处理流水线中，本章的讨论范围如图 3-1 的

虚线框所示。

原始文本 清理和预处理 分词：获得词和

其他语言单位

评估 建模 用数学表示语言单位

图 3-1：本章在自然语言处理流水线中的位置

无论数据是文本、图像、视频还是语音，特征表示是机器学习项目的通用步骤。然而，与

其他格式的数据相比，文本的特征表示往往要复杂得多。为了理解这一点，先来看其他数

据格式是如何用数值表示的。首先，考虑图像的情况。假如现在要构建一个猫狗图像分类

器。为了训练机器学习模型来完成这个任务，需要向它提供标注好的图像。如何将图像馈

送到机器学习模型中？图像在计算机中是以像素矩阵的形式存储的，矩阵中的每个元素

[i,j] 表示图像的像素 i,j。存储在元素 [i,j] 处的实数值表示图像中相应像素的强度，如

图 3-2 所示。这种矩阵表示精确地表示了完整的图像。视频也是类似的：视频只是帧的集

合，其中的每一帧都是一幅图像。因此，任何视频都可以表示为矩阵的顺序集合，其中每

帧一个矩阵，按顺序排列。

人类眼中的图像 计算机眼中的图像

图 3-2：人类眼中的图像和计算机眼中的图像（参见 Suraj Bansal 的文章“Convolutional Neural 

Networks Explained”）

现在考虑语音，语音是以波的形式传输的。为了在数学上表示语音，需要对波进行采样并

记录其振幅（高度），如图 3-3 所示。

1.0

0.5

0.0

-0.5

-1.0

图 3-3：对语音波形进行采样

采样后得到一个数值数组，表示声波在固定时间间隔的振幅，如图 3-4 所示。

文本表示 ｜ 59

图 3-4：用数值向量表示的语音信号

从上面的讨论中，可以清楚地看到，用数学形式表示图像、视频和语音是非常简单的。

那么文本呢？事实证明，表示文本并不简单，因此本章会集中讨论解决这个问题的各种

方法。给定一段文本，找到用数学形式来表示它的方法，这叫文本表示。在过去的几十

年里，尤其是在最近的十年里，文本表示一直是活跃的研究领域。本章将从简单的方法开

始，然后一直讨论到文本表示的最新技术。这些方法分为以下四类：

• 基本的向量化方法；

• 分布式表示；

• 通用语言表示；

• 人工特征。

接下来，本章将逐一介绍这四类方法，包括每类方法中的各种算法。但在深入研究各种方

法之前，先考虑以下场景：给定一个标注好的文本语料库，构建一个情感分析模型。为了

正确预测句子的情感，模型需要理解句子的意思。为了正确提取句子的意思，需要把握以

下关键点。

1. 把句子切分成词素、词和短语等词法单位。

2. 推导每个词法单位的意义。

3. 理解句子的句法（语法）结构。

4. 理解句子所在的语境。

句子的语义（意义）是由以上关键点的结合而产生的。因此，任何好的文本表示方法都必

须全力促成这些关键点的提取，以反映文本的语言属性。否则，文本表示方法就不会有多

大的效果。

在自然语言处理领域，与其将顶级算法应用于普通的文本表示，不如向普通

算法提供优秀的文本表示，后者会让你走得更远。

先来看一个贯穿本章的关键概念：向量空间模型。

3.1　向量空间模型

从上述引言中可以清楚地看到，为了使机器学习算法能够处理文本数据，必须先将文本数

60 ｜ 第 3 章

文本表示 ｜ 61

据转换成某种数学形式。在本章中，数字向量将用于表示文本单元（字符、音素、词、短

语、句子、段落和文档）。这叫向量空间模型（vector space model, VSM）1。向量空间模型是

一个简单的代数模型，广泛用于表示任何文本对象。向量空间模型是文档评分、文档分类

和文档聚类等许多信息检索操作的基础。向量空间模型是将文本单元表示为向量的数学模

型。向量的最简单形式是标识符向量，例如语料库词汇表索引号向量。在这种情况下，计

算两个文本对象之间相似度的最常用方法是使用余弦相似度：对应向量之间夹角的余弦。

0°的余弦为 1，180°的余弦为 –1，且余弦从 0°到 180°单调下降。给定两个向量 A 和 B，

每个向量都有 n 个分量，它们之间的相似度计算如下：

相似度 1

2 2 2 2

1 1

= cos =

n

i i

i

n n

i i

i i

A B

A B

θ

=

= =

⋅

=

∑

∑ ∑

A B

A B

其中 Ai 和 Bi 分别是向量 A 和 B 的第 i 个分量。有时，人们也使用向量之间的欧氏距离来

捕捉相似性。

本章研究的所有文本表示方法都属于向量空间模型的范畴。但是，不同方法之间的区别在

于，产生的向量能否更好地捕捉文本的语言属性。好了，现在可以开始讨论各种文本表示

方法了。

3.2　基本的向量化方法

先从文本表示的基本思想开始：将文本语料库词汇表（V）中的每个词映射到一个唯一的

ID（整数值），然后将语料库中的每个句子或文档表示为 V 维向量。那么这一思想是如何

实现的？为了更好地理解这一点，假设语料库只有四个文档——D1、D2、D3、D4，如表

3-1 所示。

表3-1：简易语料库

文档编号 文档内容

D1 Dog bites man.

D2 Man bites dog.

D3 Dog eats meat.

D4 Man eats food.

将文本转换成小写格式并忽略标点符号后，这个语料库的词汇表由六个词组成：[dog, 

bites, man, eats, meat, food]。词汇表可以按任何顺序组织。本例直接使用词汇在语料

库中出现的顺序。现在，语料库中的每个文档都可以用六维向量表示。本节将讨论实现这

一目标的多种方法。假设文本已经按照第 2 章的预处理步骤进行了预处理（转换成小写、

删除标点符号等）并进行了分词（将文本字符串拆分为词）。现在从独热编码（one-hot 

encoding）开始。

注 1：有时也叫向量模型，但本书坚持使用向量空间模型这种说法。

3.2.1　独热编码

在独热编码中，语料库词汇表中的每个词 w 被赋予一个介于 1 和 |V| 之间的唯一整数 ID，

wid，其中 V 是语料库词汇的集合。然后，每个词都由 V 维二进制向量（若干 0 和 1）表

示。在索引 =wid 处，只需简单地设置成 1，其余元素都用 0 填充。多个词表示经组合后形

成句子表示。

现在通过简易语料库来理解这一点。首先将这六个词映射到唯一的 ID：dog=1, bites=2, 

man=3, meat=4, food=5, eats=62。根据该方法，每个词是一个六维向量。由于“dog”映

射到 ID 1，因此 dog 表示为 [1 0 0 0 0 0]。bites 表示为 [0 1 0 0 0]，以此类推。因此，

D1 表示为 [ [1 0 0 0 0] [0 1 0 0 0] [0 0 1 0 0 0] ]。D4 表示为 [ [0 0 1 0 0] [0 0 0 

0 1 0] [0 0 0 0 0 1] ]。语料库中的其他文档也可以类似地表示。

现在从基本原理的角度看一下在 Python 中实现独热编码的简单方法。以下简化的示例实现了

独热编码。现实世界的项目主要使用 scikit-learn 实现的独热编码，它的优化程度要高很多。

因为文本需要分词，所以在这个例子中可以在空白处拆分文本。

def get_onehot_vector(somestring): 

 onehot_encoded = [] 

 for word in somestring.split(): 

 temp = [0]*len(vocab) 

 if word in vocab: 

 temp[vocab[word]-1] = 1 

 onehot_encoded.append(temp) 

 return onehot_encoded 

get_onehot_vector(processed_docs[1])

输出：[[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]]。

前面已经介绍了这个方法，现在来讨论它的优点和缺点。从积极的方面来看，独热编码是

直观的，易于理解和实现。但是，它有以下几个缺点。

• 独热向量的大小与词汇量的大小成正比，而大多数真实世界的语料库有很大的词汇量。

这将造成稀疏表示，其中向量中的大多数元素是零，使得存储、计算和学习的计算效率

低下（稀疏导致过拟合）。

• 独热编码的文本表示并非固定长度，也就是说，如果文本有 10 个词，那么与 5 个词的

文本相比，得到的表示将更长。对于大多数学习算法，特征向量需要具有相同的长度。

• 独热向量把词看作基本单位，没有词与词之间相似性的概念。例如，考虑三个词：run、

ran 和 apple。run 和 ran 意思相似，run 和 apple 意思不同。但是如果取它们各自的向量，

计算它们之间的欧氏距离，那么它们之间的距离都是相等的（ 2 ）。因此，从语义上

来说，独热向量很难捕捉一个词相对于其他词的意义。

• 假设现在使用简易语料库训练一个模型。在运行时，如果出现句子“man eats fruits”，

由于训练数据中不包括“fruits”，因此模型无法表示它。这就是所谓的未登录词（out of 

vocabulary, OOV）问题。独热编码方法无法处理此问题。唯一的处理办法是扩展词汇表、

给新词分配 ID、重新训练模型等。

注 2：这种映射是任意的。任何其他映射也同样有效。

62 ｜ 第 3 章

目前，独热编码方法已经很少有人使用。

独热编码的部分缺点可以通过下一节中描述的词袋方法来解决。

3.2.2　词袋

词袋（bag of words, BoW）是一种经典的文本表示技术，在自然语言处理中得到了广泛的

应用，特别是在文本分类问题中（见第 4 章）。词袋背后的关键思想是，忽略顺序和语境，

将所考虑的文本表示为“一袋词”（也就是词的集合）。词袋背后的基本直觉是，在数据集

中属于给定类别的文本由一组唯一的词来表征。如果两个文本片段具有几乎相同的词，那

么它们就属于同一个袋子（类别）。因此，通过分析文本中出现的词汇，可以识别出文本

所属的类别（袋子）。

类似于独热编码，词袋也将词映射到 1 和 |V| 之间的唯一整数 ID。区别在于，语料库中的

每个文档直接转换为 |V| 维向量，向量的第 i 个分量（i=wid），就是词 w 在文档中出现的次

数。也就是说，只需根据词在文档中出现的次数来给 V 中的每个词打分。

因此，对于简易语料库（见表 3-1），词 ID 分别为 dog=1, bites=2, man=3, meat=4, food=5, 

eats=6，D1 变为 [1 1 1 0 0 0]。这是因为词汇表中的前三个词在 D1 中正好出现了一次，

后三个词根本没有出现。D4 变为 [0 0 1 0 1 1]。下面的代码显示了其中的关键部分。

from sklearn.feature_extraction.text import CountVectorizer 

count_vect = CountVectorizer() 

# 为语料库构建词袋表示

bow_rep = count_vect.fit_transform(processed_docs) 

# 打印词汇表映射

print("Our vocabulary: ", count_vect.vocabulary_) 

# 打印前两个文档的词袋表示

print("BoW representation for 'dog bites man': ", bow_rep[0].toarray()) 

print("BoW representation for 'man bites dog: ",bow_rep[1].toarray()) 

# 使用此词汇表获取新文本的表示

temp = count_vect.transform(["dog and dog are friends"]) 

print("Bow representation for 'dog and dog are friends':", 

temp.toarray())

运行这段代码，就会注意到，在“dog and dog are friends”这个句子中，词“dog”这一

维度的值为 2，表示它在文本中出现的频率。有时，我们并不关心词在文本中出现的频

率，只想表示一个词是否存在于文本中。研究人员已经表明，这种不考虑频率的表示对

于情感分析是有用的（见 Daniel Jurafsky 和 James H. Martin 的著作 Speech and Language 

Processing (3rd ed. draft) 中的第 4 章）。在这种情况下，只需使用 binary=True 选项初始化

文本表示 ｜ 63

CountVectorizer，如以下代码所示。

count_vect = CountVectorizer(binary=True) 

bow_rep_bin = count_vect.fit_transform(processed_docs) 

temp = count_vect.transform(["dog and dog are friends"]) 

print("Bow representation for 'dog and dog are friends':", temp.toarray())

以上是同一句子的不同表示。CountVectorizer 还支持字符和词的 n-gram。

下面来看看这种编码的三个优点。

• 与独热编码一样，词袋也很容易理解和实现。

• 使用词袋向量表示后，具有不同词汇的文档距离更远，具有相同词汇的文档距离更近。

D1 和 D2 之间的距离为 0，而 D1 和 D4 之间的距离为 2。因此，词袋方法产生的向量空

间捕获了文档的语义相似性。因此，如果两个文档有相似的词汇表，那么它们在向量空

间中会更接近，反之则会更远。

• 任意长度的句子，都具有固定长度的编码。

然而，词袋表示也有以下缺点。

• 向量的大小随着词汇表的增大而增大。因此，稀疏性仍然是一个问题。控制稀疏性的一

种方法是将词汇表限制在前 n 个最频繁的词汇中。

• 词袋表示不能捕捉到同义词之间的相似性。假设有三个文档：“I run”“I ran”和“I 

ate”。这三个文档的词袋向量的距离是相等的。

• 词袋表示无法处理未登录词（即语料库中从未出现过的新词）。

• 顾名思义，词袋是词汇的“袋子”，语序信息在词袋表示中丢失了。在词袋方法中，D1

和 D2 具有相同的表示。

然而，尽管存在这些缺点，但由于原理简单、易于实现，词袋仍是一种常用的文本表示方

法，尤其是对于文本分类问题。

3.2.3 n-gram袋

到目前为止，所有的文本表示方法都将词视为独立的单元，并没有涉及短语或词序的概

念。n-gram 袋（bag-of-n-grams, BoN）方法试图解决这一问题。它将文本分成多个块，每

一块由 n 个连续词组成。这有助于捕获一定的语境，而早期的方法无法做到这一点。每个

块叫 n-gram。语料库词汇表 V 则是文本语料库中所有不同 n-gram 的集合。语料库中的每

个文档由长度为 |V| 的向量表示。该向量只统计文档中出现的 n-gram 的频率计数，对于不

存在的 n-gram，频率计数为零。

为了展开说明，考虑示例语料库。现在构造 2-gram 模型（亦称二元语法模型）。语料库中

所有的 2-gram 集合为：{dog bites, bites man, man bites, bites dog, dog eats, eats 

meat, man eats, eats food}。每个文档的 n-gram 袋表示由一个八维向量组成。前两个文

档的 2-gram 袋，D1 表示为 [1,1,0,0,0,0,0,0]，D2 表示为 [0,0,1,1,0,0,0,0]。其余两个

文件也遵循同样的方法来表示。注意，词袋方法是 n-gram 袋方法的一个特例，此时 n=1。

n=2 时叫“二元语法模型”，n=3 时叫“三元语法模型”，以此类推。此外需要注意，通过

增大 n 的值，可以体现更多的语境。然而，这进一步增强了稀疏性。在自然语言处理中，

64 ｜ 第 3 章

n-gram 袋方法也叫“n-gram 特征选择”。

以下代码展示了 n-gram 袋表示的示例，它考虑了从一元、二元、三元语法模型的特征来表

示上述语料库。这里通过设置 ngram_range = (1,3) 来使用一元、二元、三元语法向量。

# 使用CountVectorizer和一元、二元、三元语法构建n-gram向量示例

count_vect = CountVectorizer(ngram_range=(1,3)) 

# 为语料库构建词袋表示

bow_rep = count_vect.fit_transform(processed_docs) 

# 打印词汇表映射

print("Our vocabulary: ", count_vect.vocabulary_) 

# 使用此词汇表获取新文本的表示

temp = count_vect.transform(["dog and dog are friends"]) 

print("Bow representation for 'dog and dog are friends':", temp.toarray())

以下是 n-gram 袋表示的主要利弊。

• n-gram 袋以 n-gram 的形式捕捉了一定的语境和语序信息。

• 因此，得到的向量空间能够捕捉一定的语义相似性。具有不同 n-gram 的文档距离更远，

具有相同 n-gram 的文档距离更近。

• 随着 n 的增大，维数（以及稀疏性）将会迅速增加。

• n-gram 袋仍然没有解决未登录词的问题。

3.2.4 TF-IDF

在以上三种方法中，文本中的所有词汇都被视为同等重要——不存在某些词比其他词更重

要的概念。TF-IDF，即词频 – 逆文档频率，解决了这个问题。TF-IDF 的目的是量化给定

词相对于文档和语料库中其他词的重要性。TF-IDF 是信息检索系统中常用的表示方法，用

于从语料库中提取所查询的相关文档。

TF-IDF 背后的直觉是，如果词 w 在文档 di 中出现多次，但在语料库的其他文档 dj 中出现

的次数不多，那么词 w 对文档 di 一定非常重要。w 的重要性应该与 w 在 di 中的频率成正

比；同时，w 的重要性应该与 w 在语料库中其他文档 dj 中的频率成反比。在数学上，这是

使用 TF 和 IDF 两个量来得到的。将两者结合起来可以算出 TF-IDF 分值。

TF（词频）测量的是词在给定文档中出现的频率。由于语料库中的不同文档可能具有不同

的长度，因此一个词在较长文档中出现的频率可能高于较短的文档。为了计数的归一化，

将出现的次数除以文档的长度。词 t 在文档 d 中的 TF 定义为：

词 t 在文档 d 中出现的次数

TF(t, d) = 文档 d 中词的总数

IDF（逆文档频率）测量的是词在语料库中的重要性。在计算 TF 时，所有词都被赋予同等

的重要性（权重）。然而，众所周知的事实是，is、are、am 等停用词并不重要，即使它们

经常出现。为了解释这种情况，IDF 对语料库中非常常见的词降低了权重，并对罕见的词

增加了权重。词 t 的 IDF 计算如下：

文本表示 ｜ 65

66 ｜ 第 3 章

IDF(t) = loge

语料库中的文档总数

包含词 t 的文档数

TF-IDF 分值是以上两项的乘积。因此，TF-IDF=TF × IDF。下面来计算简易语料库的 TF￾IDF 分值。有些词只出现在一个文档中，有些出现在两个文档中，而另一些则出现在三个

文档中。语料库的大小是 N=4。因此，每个词的 TF-IDF 值如表 3-2 所示。

表3-2：简易语料库的TF-IDF值

词 TF值 IDF值 TF-IDF值

dog 1/3 ≈ 0.33 log2

(4/3) ≈ 0.4114 0.4114 × 0.33 ≈ 0.136

bites 1/6 ≈ 0.17 log2

(4/2)=1 1 × 0.17=0.17

man 0.33 log2

(4/3) ≈ 0.4114 0.4114 × 0.33 ≈ 0.136

eats 0.17 log2

(4/2)=1 1 × 0.17=0.17

meat 1/12 ≈ 0.083 log2

(4/1)=2 2 × 0.083 ≈ 0.17

food 0.083 log2

(4/1)=2 2 × 0.083 ≈ 0.17

文档的 TF-IDF 向量表示则是该文档中每个词的 TF-IDF 值。因此，对于 D1，得：

dog bites man eats meat food

0.136 0.17 0.136 0 0 0

以下代码演示了如何使用 TF-IDF 来表示文本。

from sklearn.feature_extraction.text import TfidfVectorizer 

tfidf = TfidfVectorizer() 

bow_rep_tfidf = tfidf.fit_transform(processed_docs) 

print(tfidf.idf_) # 词汇表中所有词的IDF 

print(tfidf.get_feature_names()) # 词汇表中所有的词

temp = tfidf.transform(["dog and man are friends"]) 

print("Tfidf representation for 'dog and man are friends':\n", temp.toarray())

实际使用的 TF-IDF 公式与上述基本公式之间有一定的区别。因此，表 3-2 中计算的 TF￾IDF 值可能与 scikit-learn 给出的 TF-IDF 值不同。这是因为 scikit-learn 使用了稍微不同的

IDF 公式。这是因为要考虑除数为零的情况，并且不能完全忽略那些所有文档中都出现的

词。感兴趣的读者可以查看 TF-IDF vectorizer 文档来获得确切的公式。

和词袋类似，TF-IDF 向量也可用于计算两个文本之间的相似度，比如使用欧氏距离或余弦

相似度等。TF-IDF 是信息检索和文本分类等应用场景中常用的表示方法。然而，尽管 TF￾IDF 在捕捉词相似性方面优于之前的向量化方法，但它仍然面临着维数灾难的问题。

即使在今天，TF-IDF 仍然是许多自然语言处理任务的常用表示方法，尤其是

在构建初步解决方案的时候。

回顾前面的讨论，不难发现，所有的表示方法都存在以下三个基本缺陷。

• 它们是离散的表示，也就是说，它们将语言单位（词、n-gram 等）视为基本单位。这

种离散性妨碍了它们捕捉词与词之间关系的能力。

• 特征向量是稀疏的高维表示。维数随着词汇表的增大而增加，但向量中的大多数值是零。

这会妨碍学习能力。此外，高维表示还会导致计算效率低下。

• 它们无法处理未登录词的问题。

好，基本的向量化方法就介绍到这里。下面开始讨论分布式表示。

3.3　分布式表示

上一节讨论了基本向量化方法普遍存在的主要缺点。为了克服这些局限性，人们设计了学

习低维表示的方法。本节所述的这些方法在过去六七年中取得了突飞猛进的发展。它们使

用神经网络结构来创建稠密、低维的词和文本表示。但是在研究这些方法之前，需要先了

解以下关键术语。

分布相似性

分布相似性背后的思想是，词的意思可以通过其所在的语境来理解。这也叫内涵

（connotation）：词义由语境定义。这与外延（denotation）相反：词义由字面意思定义。

例如，“NLP rocks”。“rocks”的字面意思是“石头”，但从语境来看，此句中“rocks”

是动词，形容某些事物非常棒。

分布假说

在语言学中，分布假说（distributional hypothesis）认为：语境相似的词，其语义也相

似。例如，英语单词“dog”和“cat”经常出现在相似的语境中，因此，根据分布假

说，这两个词一定具有相似的语义。根据向量空间模型，词义由向量表示。因此，如果

两个词经常出现在相似的语境中，那么对应的向量表示也肯定是彼此接近的。

分布表示

分布表示（distributional representation）是指根据语境中词的分布而获得的表示方法。

分布表示方法基于分布假说。分布的性质是从语境（周围的文本）中归纳出来的。在

数学上，分布表示方法使用高维向量来表示词。这些向量是从词和语境的共现矩阵中

获得的，矩阵的维数等于语料库词汇量的大小。前面看到的四种方法——独热、词袋、

n-gram 袋和 TF-IDF——都属于分布表示的范畴。

分布式表示

分布式表示（distributed representation）也是一个基于分布假说的相关概念。如前一段

所述，分布表示中的向量是非常高维和稀疏的。这使得它们计算效率低下，妨碍了学

习。为了应对这种情况，分布式表示方法显著地压缩了维数。这会产生紧凑（即低维）

和稠密（即几乎没有零）的向量。由此产生的向量空间称为分布式表示。本章后面讨论

的所有方法都属于分布式表示。

文本表示 ｜ 67

嵌入

嵌入（embedding）是将语料库中的词汇从分布表示的向量空间映射到分布式表示的向

量空间。

向量语义学

向量语义学（vector semantics）是指根据词在大型语料库中的分布性质来学习词的向量

表示的自然语言处理方法。

在对这些术语有了基本的了解之后，现在开始讨论第一种方法：词嵌入。

3.3.1　词嵌入

文本表示应该捕捉“词之间的分布相似性”，这是什么意思？考虑几个例子。对于“美

国”一词，分布相似的词可能是其他国家（如加拿大、德国、印度等）或美国的城市。对

于“美丽”一词，与该词有某种关系的词（如同义词、反义词）可以被认为是分布相似的

词。这些词很可能出现在相似的语境中。基于“分布相似性”和神经网络的词表示模型

“Word2vec”可以捕捉到词的类比关系，例如：

国王 – 男人 + 女人 ≈ 女王

该模型能够正确回答很多类似的类比问题。图 3-5 显示了某个基于 Word2vec 的类比回答

系统的快照。Word2vec 模型在很多方面是现代自然语言处理的鼻祖。

图 3-5：基于 Word2vec 的类比回答系统

除了学习丰富的语义关系，Word2vec 还确保了学习到的词表示是低维的（向量维数为

50~500，而非几千）和稠密的（向量中的大多数值为非零）。低维和稠密的词表示使机器

学习任务更加易于处理和高效。在使用神经网络来学习文本表示的方向上，Word2vec 产生

了大量的理论成果和应用成果。这种表示也叫“嵌入”。那么嵌入是如何工作的？如何使

用嵌入来表示文本？下面先来建立直观理解。

给定文本语料库，Word2vec 的目标是学习语料库中每个词的嵌入，使得嵌入空间中的词向

68 ｜ 第 3 章

量能最好地捕捉词的意义。为了“推导”词的意义，Word2vec 使用分布相似性和分布假

说。也就是说，Word2vec 从词的语境（出现在周围的词）中推导出词的意义。因此，如

果两个不同的词经常出现在相似的语境中，那么它们的意思很可能也是相似的。Word2vec

的实现方法是，将词的意义投射到向量空间中，其中具有相似语义的词会趋向于聚集在一

起，而具有不同语义的词则会距离较远。

从概念上讲，Word2vec 以大型文本语料库作为输入，并基于词在语料库中出现的语境，

“学习”在公共向量空间中表示词。给定词 w 和语境 C 中的词，如何找到最能表示该词含

义的向量？对于语料库中的每个词 w，首先用随机值来初始化向量 vw。然后，Word2vec 模

型会根据语境 C 中的词的向量来预测 vw，从而改善 vw 中的值。Word2vec 使用两层神经网

络来实现这一点。在继续讨论如何训练自己的嵌入之前，先来看看预训练嵌入，借此深入

研究这个问题。

1. 预训练词嵌入

训练自己的词嵌入需要耗费大量的时间和计算资源。值得庆幸的是，对于许多场景，通常

不需要训练自己的词嵌入，直接使用预训练词嵌入就够了。那什么是预训练词嵌入？有人

已经使用大型语料库（例如维基百科、新闻文章，甚至整个互联网）训练好了词嵌入，并

把词和对应的向量放在了网上。困难的工作已经完成。下载这些嵌入可以直接获得所需的

词向量。预训练词嵌入可以被认为是键 – 值对的大集合，其中键是词汇表中的词，值是对

应的词向量。谷歌的 Word2vec、斯坦福的 GloVe 和 Facebook 的 fastText 词嵌入等都是最常

见的预训练词嵌入。此外，它们还提供多种维数选择，如 d = 25, 50, 100, 200, 300, 600。

下面的代码涵盖了关键步骤。这里找到了语义上与“beautiful”一词最相似的词，最后一

行返回单词“beautiful”的嵌入向量。

from gensim.models import Word2Vec, KeyedVectors 

pretrainedpath = "NLPBookTut/GoogleNews-vectors-negative300.bin" 

w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True) 

print('done loading Word2Vec') 

print(len(w2v_model.vocab)) # 词汇表中词的数量

print(w2v_model.most_similar['beautiful']) 

W2v_model['beautiful']

most_similar('beautiful') 返回与“beautiful”最相似的词，输出如下所示。每个词都附

有相似度分值，分值越高，表示该词与查询词越相似。

[('gorgeous', 0.8353004455566406), 

 ('lovely', 0.810693621635437), 

 ('stunningly_beautiful', 0.7329413890838623), 

 ('breathtakingly_beautiful', 0.7231341004371643), 

 ('wonderful', 0.6854087114334106), 

 ('fabulous', 0.6700063943862915), 

 ('loveliest', 0.6612576246261597), 

 ('prettiest', 0.6595001816749573), 

 ('beatiful', 0.6593326330184937), 

 ('magnificent', 0.6591402292251587)]

w2v_model 返回查询词的向量。对于“beautiful”这个词，得到的向量如图 3-6 所示。

文本表示 ｜ 69

图 3-6：预训练 Word2vec 中表示“beautiful”的词向量

注意，如果搜索的词在 Word2vec 模型中不存在（例如，“practicalnlp”），将出现“key not 

found”错误。因此，作为一种良好的编程实践，建议在尝试检索词向量之前，先检查该词

是否存在于模型的词汇表中。这个代码片段中使用的 Python 库 gensim 还支持训练和加载

GloVe 预训练模型。

如果对词嵌入不熟悉，那么在项目的开始阶段，最好使用预先训练好的词嵌

入。了解它们的优缺点后，再考虑构建自己的嵌入。使用预先训练的嵌入可

以很快为手头任务提供一个强大的基线。

70 ｜ 第 3 章

下面来看如何训练自己的词嵌入。

2. 训练自己的嵌入

现在着重讨论训练自己的词嵌入。为此，这里先看看 Word2vec 最初提出的两种结构变体。

它们分别是：

• 连续词袋（CBOW）模型；

• 跳词（SkipGram）模型。

两者具有很多相似之处。下面分别介绍 CBOW 模型和 SkipGram 模型。本节将使用“The 

quick brown fox jumps over the lazy dog”这句话作为简易语料库。

CBOW 模型。CBOW 的首要任务是构建语言模型，即在给定周围语境词的情况下，正确地

预测中心词。那什么是语言模型？语言模型是一种统计模型，它试图给出词序列的概率分布。

例如，给定一个含有 n 个词的句子，语言模型试图给出整个句子的概率 Pr(w1

, w2

, …, wn

)。

语言模型的目标是给“好句子”分配高概率，给“坏句子”分配低概率。所谓“好句子”，

指的是语义和句法都正确的句子。所谓“坏句子”，指的是语义或句法不正确的句子。因

此，对于像“The cat jumped over the dog”这样的句子，语言模型会尝试分配一个接近于

1.0 的概率，而对于像“jumped over the the cat dog”这样的句子，语言模型会尝试分配一

个接近于 0.0 的概率。

CBOW 试图学习一种根据语境词来预测“中心词”的语言模型。下面使用简易语料库来理

解这一点。如果把“jumps”这个词作为中心词，那么它的语境就由它附近的词构成。如

果语境大小取 2，那么上述示例的语境就是 brown、fox、over 和 the。CBOW 使用语境词

来预测目标词 jumps，如图 3-7 所示。CBOW 尝试对语料库中的每个词都做这样的处理，

也就是说，CBOW 把语料库中的每一个词都当作目标词，并试图根据对应的语境词来预测

目标词。

图 3-7：CBOW：给定语境词，预测中心词

将上述思想扩展到整个语料库，以构建训练集。具体而言，就是在文本语料库上运行大小

为 2k+1 的滑动窗口。在刚才的例子中，k 取值为 2。窗口中的每个位置构成了当前正在考

虑的 2k+1 个词的集合。窗口中的中心词是目标词，中心词两侧的 2k 个词构成了语境。这

是一个数据点。如果数据点表示为 (X, Y)，则语境为 X，目标词为 Y。每个数据点由一组

数字组成：(2k 个语境词的索引 , 1 个目标词的索引 )。为了得到下一个数据点，只需将语

料库上的窗口向右移动一个词，然后重复这个过程。这样，在整个语料库上滑动窗口就可

以创建出训练集，如图 3-8 所示，其中目标词用蓝色表示，k=2。

文本表示 ｜ 71

72 ｜ 第 3 章

原始文本 训练样例

（语境词, 目标词）

图 3-8：为 CBOW 准备数据集

现在训练数据已经准备好了，接下来构建模型。这里构建的是一个浅层网络（之所以是浅

层，是因为只有一个隐藏层），如图 3-9 所示。假设要学习的是 D 维词嵌入。令 V 为文本

语料库的词汇表。

CBOW模型

输入 处理

加和

输出

输入层

隐藏层 输出层

w(t−2)

w(t−1)

w(t+2)

w(t+1)

w(t)

X1k

X2k

图 3-9：CBOW 模型

建模的目标是学习嵌入矩阵 E|V| × d，其中 |V| 是语料库词汇表的大小，d 是词嵌入的维数。

首先，需要将嵌入矩阵随机初始化。接下来看一下图 3-9 中所示的浅层网络。在输入层中，

使用语境词的索引从嵌入矩阵 E|V| × d 中获取相应的行，再将获取的向量相加，得到一个 d

维向量，并将其传递到下一层。下一层直接将 d 维向量与矩阵 E'd × |V| 相乘，得到 1 × |V| 的

向量，送入 softmax 函数后，得到它在词汇表空间上的概率分布。然后将该分布与标签进

行比较，并使用反向传播来相应地更新矩阵 E 和 E'。在训练结束时，E 就是学习到的嵌入

矩阵 3。

SkipGram 模型。SkipGram 与 CBOW 非常相似，只是有一些细微的变化。在 SkipGram

中，模型的任务是根据中心词来预测语境词。对于刚才的简易语料库，如果语境大小为 2，

则使用中心词“jumps”来预测各个语境词——“brown”“fox”“over”“the”，如图 3-10

所示。这构成流程中的一步。SkipGram 会以语料库中的每个词为中心词重复这一步。

图 3-10：SkipGram：给定中心词，预测各个语境词

训练 SkipGram 的数据集按如下方式准备：在文本语料库上运行大小为 2k+1 的滑动窗口，

获得当前正在考虑的 2k+1 个词的集合。窗口中的中心词是 X，中心词两边的 2k 个词是 Y。

与 CBOW 不同，这里提供了 2k 个数据点。每个数据点由一对数字组成：( 中心词索引 , 

目标词索引 )。然后将语料库上的窗口向右移动一个词，重复这个过程。这样，在整个语

料库上滑动窗口就可以创建出训练集，如图 3-11 所示。

原始文本 训练样例

（目标词, 语境词）

图 3-11：为 SkipGram 准备数据集

注 3：从技术上讲，E 和 E' 是两个不同的嵌入矩阵。可以使用其中的任何一个，也可以直接求平均，将两

者合二为一。

文本表示 ｜ 73

74 ｜ 第 3 章

如图 3-12 所示，训练 SkipGram 模型所用的浅层网络，与 CBOW 所用的网络非常相似，

只是有一些细微的变化。在输入层中，利用目标词的索引从嵌入矩阵 E|V| × d 中获取相应

的行。获取的向量随后被传入下一层。下一层直接将 d 维向量与矩阵 E'd × |V| 相乘，得到

1×|V| 的向量，输入 softmax 函数后，得到它在词汇表空间上的概率分布。将该分布与标

签进行比较，并使用反向传播来相应地更新矩阵 E 和 E'。在训练结束时，E 就是所要学习

的嵌入矩阵。

输入 处理 输出

w(t)

w(t−2)

w(t−1)

w(t+2)

w(t+1)

输出层

输入层

隐藏层

连续SkipGram模型

y1j

y2j

图 3-12：SkipGram 结构

CBOW 和 SkipGram 模型还有许多其他细节。感兴趣的读者可以参考 Xin Rong 的文章

“word2vec Parameter Learning Explained”，其中有对 Word2vec 参数的详细推导。另一个需

要牢记的要点是模型的超参数，例如窗口大小、向量维数、学习率、轮数（epoch）等。众

所周知，超参数对模型的最终质量起着至关重要的作用。

要在实践中使用 CBOW 和 SkipGram 算法，可以使用现成的库，它们抽象了其中的数学细

节。最常用的库是 gensim。

尽管有现成的库可以使用，但仍然需要对超参数（即训练之前需要设置的变量）进行设

置。下面来看两个例子。

词向量的维数

词向量的维数决定了嵌入空间的维数。虽然维数不存在一个理想的数字，但通常会构造

维数在 50 和 500 之间的词向量，并在任务中对它们进行评估，以选择最佳维数。

语境窗口

学习向量表示所需的语境的长度。

另外，在学习词嵌入时，还会面临其他选择，例如究竟是使用 CBOW 还是 SkipGram。在

这一点上，这种选择更像是一门艺术，而非科学。而且，关于选择正确超参数的方法，有

很多研究仍在进行当中。

从代码的角度来看，使用 gensim 等包可以非常容易地实现 Word2vec。下面的代码展示了

如何使用 gensim 中提供的 common_texts 简易语料库来训练自己的 Word2vec 模型。如果使

用自己领域的语料库，沿用下面的代码片段也能很快地得到自己的词嵌入。

# 导入gensim中提供的测试数据集来训练模型

from gensim.test.utils import common_texts 

# 选择参数，并构建模型

our_model = Word2Vec(common_texts, size=10, window=5, min_count=1, workers=4) 

# 保存模型

our_model.save("tempmodel.w2v") 

# 检查模型：找出与测试词最相似的词

print(our_model.wv.most_similar('computer', topn=5)) 

# 看看computer的10维向量是什么样子的

print(our_model['computer'])

现在，只需在模型中查找一下，就可以得到语料库中任何词的向量表示，前提是该词存在

于模型的词汇表中。但是如何得到一个短语（例如“word embeddings”）的向量呢？

3.3.2　词语之上

前面展示了使用预训练词嵌入，以及训练自己的词嵌入的例子。最后得到的是紧凑和稠密

的词表示。然而，大多数自然语言处理应用程序不会直接处理词这种基本单元，它们处理

的是句子、段落，甚至是全文。因此，需要一种方法来表示更大的文本单元。那么能否使

用词嵌入来获取更大文本单元的特征表示呢？

一种简单的方法是将文本分解成词，取每个词的嵌入，并将它们组合起来形成文本的表

示。组合的方法有很多，最常见的是求和、取平均值等。虽然这些方法可能无法捕捉词序

等文本的整体特征，但令人惊讶的是，这些方法在实践中效果非常好（见第 4 章）。事实

上，在 CBOW 中，对语境词向量求和已经证明了这一点。得到的向量表示整个语境，可

以用来预测中心词。

在选择其他表示之前，最好先对上述方法进行实验。下面的代码展示了如何使用 spaCy 库

来对词向量求平均，从而获得文本的向量表示。

import spacy 

import en_core_web_sm 

文本表示 ｜ 75

# 加载spaCy模型。这需要几秒钟

nlp = en_core_web_sm.load() 

# 使用模型处理句子

doc = nlp("Canada is a large country") 

# 获取单个词的向量

#print(doc[0].vector) # 文本中第一个词Canada的向量

print(doc.vector) # 整个句子的平均向量

预训练和自训练的词嵌入都依赖于它们在训练数据中看到的词汇。但是，应用程序的生产

数据不可能只出现这些词汇。尽管使用 Word2vec 等词嵌入可以很容易地从文本中提取特

征，但是处理未登录词还没有比较好的方法。到目前为止，在上文所述的所有表示中，未

登录词是一个反复出现的问题。怎么办？

一种简单有效的方法是在特征提取过程中排除这些未登录词，这样就不必担心如何获得未

登录词的表示。如果使用的模型是用大型语料库训练的，那么应该不会出现太多的未登录

词。但是，如果生产数据中出现了大量未登录词，那么就不可能有好的性能。这种词汇重

叠度是衡量自然语言处理模型性能的一个有效方法。

如果语料库和词嵌入的词汇重叠度低于 80%，那么自然语言处理模型的性能

就可能不是很好。

即使重叠度超过 80%，模型效果可能仍然很差，这取决于哪些词处于这 20% 的范围中。如

果这些词对于任务很重要，那么模型效果很可能较差。例如，在癌症医疗文档和心脏病医

疗文档的分类任务中，心脏病、癌症等词对于区分这两种文档非常重要。如果这些词没有

出现在词嵌入的词汇表中，分类器效果就可能较差。

另一种处理词嵌入未登录词问题的方法是创建随机初始化的向量，其中每个分量在 –0.25

和 +0.25 之间，并在构建的整个应用程序中一直使用这些向量。根据经验，这可以使性能

提高 1%~2%。

此外，在训练时引入字符、子词等语言成分，也可以处理未登录词问题。下面来看其中的

一种方法。其关键思想是，使用词法属性（如前缀、后缀、词尾）等子词信息，或使用字

符表示来处理未登录词问题。Facebook 人工智能研究院的 fastText 就是使用这种方法的常

见算法之一。一个词可以用它的字符 n-gram 来表示。fastText 采用类似于 Word2vec 的结

构，同时学习词和字符 n-gram 的嵌入，并将词嵌入向量视为其字符 n-gram 的聚合。如此

一来，即使词汇表中不存在的词，也可以生成嵌入。例如，“gregarious”如果在嵌入的词

汇表中不存在，就可以将该词分解成字符 n-gram——gre, reg, ega, ..., ous——并将这些字符

n-gram 的嵌入结合起来，就得到了“gregarious”的嵌入。

gensim 的 fastText 包装器可以用于加载预训练模型，也可以使用 fastText 以类似于 Word2vec

的方式训练模型。这留给读者作为练习。第 4 章将介绍如何使用 fastText 嵌入进行文本分

类。现在来看词语之上的分布式表示。

76 ｜ 第 3 章

文本表示 ｜ 77

3.4　词和字符之上的分布式表示

前面介绍了使用嵌入来实现文本表示的两种方法。Word2vec 学习的是词的表示，词表示

经过聚合后形成文本表示。fastText 学习的是字符 n-gram 的表示，字符 n-gram 表示经过

聚合后形成词表示，进而形成文本表示。这两种方法的一个潜在问题是没有考虑到词的语

境。以“狗咬人”（dog bites man）和“人咬狗”（man bites dog）这两个句子为例，在上述

两种方法中，它们得到了相同的表示，但它们显然具有不同的含义。现在来看另一种方法

Doc2vec，它通过考虑文本中词的语境来直接学习任意长度文本（短语、句子、段落和文

档）的表示。

Doc2vec 基于段落向量框架，在 gensim 中已经实现。Doc2vec 的基本结构和 Word2vec 类

似，不同的是，Doc2vec 不仅学习词向量，还要学习“段落向量”来表示整个文本（即通过

语境中的词）。在使用大型语料库（拥有很多文本）进行学习时，段落向量对于给定的文本

（“文本”可以指任意长度的文本）是唯一的，而词向量在所有文本之间共享。学习 Doc2vec

嵌入所用的浅层神经网络（见图 3-13）与 Word2vec 的 CBOW 和 SkipGram 结构非常相似。

这两种结构分别叫分布式存储（DM）和分布式词袋（DBOW)，如图 3-13 所示。

分类器

求平均值或拼接

段落矩阵

分类器

段落矩阵

段落ID 段落ID

DM DBOW

D D W W W

图 3-13：Doc2vec 结构：DM（左）和 DBOW（右）

Doc2vec 模型训练好后，利用训练得到的公共词向量来推断新文本的段落向量。Doc2vec

也许是第一个不直接通过词向量的组合而获得全文嵌入表示的常见方法。由于 Doc2vec 对

语境进行了一定程度的建模，并且可将任意长度的文本编码为固定长度的低维稠密向量，

因此它在文本分类、文档标记、文本推荐和常见问题聊天机器人等自然语言处理应用程序

中得到了广泛的应用。第 4 章将展示如何训练 Doc2vec 表示并将其用于文本分类的示例。

下面继续讨论涉及全文的文本表示方法。

3.5　通用文本表示

在前面介绍的所有表示中，每一个词都对应一个固定的表示。这有没有问题？在某种程

度上会有问题。词在不同的语境中可能有不同的意思。例如，“I went to a bank to withdraw 

money”和“I sat by the river bank and pondered about text representations”这两个句子都使

用了“bank”一词，但它们在句子中的意思是不同的。前面介绍的向量方法和嵌入方法都

无法直接捕捉这方面的信息。

2018 年，研究人员提出了语境化词表示（contextual word representation）的思想，解决了

这一问题。语境化词表示使用“语言建模”，即预测词序列中下一个词的任务。在最早的

形式中，语境化词表示使用 n-gram 频率来估计给定历史词后下一个词的概率。在过去的几

年中，出现了高级的神经语言模型（例如 Transformer），它们利用了前面讨论过的词嵌入，

但使用了复杂的网络结构，包括多次通过文本，以及从左到右和从右到左的多次读取，从

而对语言使用的语境进行建模。

人们使用循环神经网络（RNN）和 Transformer 等神经网络来开发大规模语言模型（例如

ELMo 和 BERT），然后使用这些大规模语言模型作为预训练模型来生成文本表示。这里的

核心思想是利用“迁移学习”，即在大规模语料库中学习语言模型等通用任务的嵌入，然

后在特定任务的数据上进行微调学习。这些模型在问题回答、语义角色标注、命名实体识

别和共指消解等基本的自然语言处理任务上都有了显著的改进。第 1 章简要介绍了其中的

一些任务。

前面三节介绍了词嵌入背后的核心思想、训练方法，以及如何使用预训练的词嵌入来获得

文本表示。后面的内容还将进一步介绍如何在不同的自然语言处理应用程序中使用这些表

示。这些表示在现代自然语言处理中非常有用和流行。然而，根据我们的经验，在项目中

使用这些表示时，需要牢记以下几个要点。

• 所有的文本表示都是基于训练数据的，因此会存在固有偏见。例如，用科技新闻或文章

训练的嵌入模型很可能会认为“Apple”更接近微软或 Facebook，而不是橘子或梨。虽

然这不一定是真的，但这种来自训练数据的偏见可能会对依赖于这些表示的自然语言处

理模型以及系统的性能产生严重影响。因此，理解所学嵌入中可能存在的偏见，并开发

相应的解决方法是非常重要的。在开发任何自然语言处理软件的过程中，这些偏见都是

需要考虑的重要因素。

• 不同于基本的向量化方法，预训练的嵌入通常是大型文件（GB 级），这可能会带来一

定的部署问题。因此，需要解决这样的问题，否则它会成为性能上的一个工程瓶颈。

Word2vec 模型大约占用 4.5GB 的内存。一个很好的方法是使用 Redis 这样的内存数据库，

其中的缓存可以解决扩展和延迟的问题。因此，可将嵌入加载到这样的数据库中，并像

在内存中一样使用嵌入。

• 真实应用程序的语言任务不仅仅是使用词嵌入和句子嵌入来捕获信息。仍然需要一些方

法来编码文本的特定属性、句子之间的关系，以及嵌入表示本身可能无法解决的任何其

他特定于领域和应用程序的需求。例如，讽刺语检测任务需要细腻的语言信息，嵌入技

术目前尚不能很好地捕捉。

• 正如前文所说，神经文本表示是自然语言处理中一个不断发展的领域，其技术发展正在

突飞猛进。虽然新闻中的下一个大模型很容易让人忘乎所以，但从业者在尝试将其用于

生产级应用程序之前，需要谨慎行事，并考虑投资回报率、业务需求和基础设施限制等

实际问题。

感兴趣的读者可以参考 Noah A. Smith 的文章“Contextual Word Representations: A Contextual 

Introduction”，它简要总结了词表示的演变和神经网络文本表示模型的研究挑战。接下来开

始讨论嵌入的可视化技术。

78 ｜ 第 3 章

3.6　可视化嵌入

上面介绍了文本表示的各种向量化技术。得到的向量可以用作文本分类、问答系统等自然

语言处理任务的特征。而对特征进行探索是任何机器学习项目的重要环节。那么如何探索

这些必须使用的向量？任何与数据相关的问题通常都会涉及可视化探索。有没有一种方法

可以对词向量进行可视化？虽然嵌入向量已经是低维向量，但仍然具有 100~300 维，维数

还是太高，无法进行可视化。

t-SNE，全称 t 分布随机邻域嵌入（t-distributed Stochastic Neighboring Embedding），是一

种通过将高维数据（如嵌入）简化为二维或三维数据来实现可视化的技术。t-SNE 以嵌入

（或任何其他数据）为输入，并使用较少的维度来最好地表示输入数据，同时在原始高维

输入空间和低维输出空间中保持相同的数据分布。因此，这使得输入数据的绘制和可视化

成为可能。t-SNE 有助于对词嵌入空间有一个直观的感受。

下面来看使用 t-SNE 进行可视化的一些例子。先来看 MNIST 数字数据集特征向量的可视

化。在这里，MNIST 数字图像通过卷积神经网络后形成最终的特征向量。图 3-14 显示了

向量的二维绘图。它清楚地表明，这些特征向量的效果是很好的，因为同一类别的向量集

中在一起。

图 3-14：使用 t-SNE 可视化 MNIST 数据（参见 Cyril Rossant 的文章“An illustrated introduction 

to the t-SNE algorithm”）

文本表示 ｜ 79

现在来看词嵌入的可视化。虽然图 3-15 中只显示了几个词，但有趣的是，意思相似的词往

往会集中在一起。

图 3-15：词嵌入的 t-SNE 可视化（左：数字；右：职务）

再看一个词嵌入的可视化，它可能是自然语言处理界最著名的例子。图 3-16 显示了一组词

（男人、女人、叔叔、阿姨、国王、皇后）的嵌入向量的二维可视化。图 3-16 不仅显示了

这些词向量的位置，还显示了向量之间的一个有趣现象——箭头捕捉了词之间的“关系”。

使用 t-SNE 可视化非常有助于人们观察到这类现象。

女人

阿姨

男人

叔叔

王后

国王

图 3-16：t-SNE 可视化显示了一些有趣的关系

t-SNE 同样适用于文档嵌入的可视化。例如，获取维基百科上不同主题的文章，获得每篇

文章对应的文档向量，然后使用 t-SNE 绘制这些向量。图 3-17 中的可视化清楚地显示了同

一类别的文章会分在同一组。

80 ｜ 第 3 章

图 3-17：维基百科文档向量的可视化

显然，t-SNE 对于观察特征向量的质量非常有用。可以使用 TensorBoard 中的嵌入投影仪等

工具来可视化日常工作中的嵌入。如图 3-18 所示，TensorBoard 有一个很好的界面，专门

为可视化嵌入而定制。这里把它作为练习留给读者进一步探索。

图 3-18：用于嵌入可视化的 TensorBoard 界面截图

文本表示 ｜ 81

3.7　人工特征表示

前面已经介绍了各种基于文本语料库的特征表示方法。这些特征表示大都不依赖于特定

的自然语言处理问题或应用领域 4。无论文本表示用于信息提取还是文本分类，也无论使用

Twitter 语料库还是科技文章语料库，都可以使用相同的方法。

然而，在许多情况下，对于给定的自然语言处理问题，一些特定于领域的知识确实是存在

的。如果希望将这些知识融入构建的模型当中，就需要使用人工特征。下面以真实的自然

语言处理系统 TextEvaluator 为例。TextEvaluator 是美国教育考试服务中心（ETS）开发的

软件。该工具的目的是帮助教师和教育工作者为学生选择相应年级的阅读材料，并找到

文本理解困难的原因。显然，这是一个非常专门的问题。使用通用的词嵌入不会有多大帮

助。它需要从文本中提取专门的特征来对某种形式的年级适当性进行建模。图 3-19 中的屏

幕截图显示了从文本中提取的一些专门特征，从而对文本复杂度的各个维度进行建模。显

然，只将文本转换为词袋表示或嵌入表示是不能计算句法复杂性（syntactic complexity）、

具体性（concreteness）等指标的。它们必须结合领域知识和机器学习算法来人工设计，从

而训练自然语言处理模型。这就是它被称为人工特征表示的原因。

图 3-19：TextEvaluator 软件输出需要人工特征

ETS 的另一个很受欢迎的评分软件是自动作文评分系统，它用于评估 GRE、托福等在线考

试考生的作文。这个工具也需要人工特征。对一篇文章的各个方面进行评估需要专门的特

征来满足这些需求。仅仅依靠 n-gram 或词嵌入是不够的。另外，微软 Word、Grammarly

等工具中使用的拼写和语法纠正功能，可能也需要这种专门的特征工程。在所有这些常用

工具的例子中，通常需要自定义特征来融合领域知识。

显然，自定义特征工程比其他特征工程方法要难得多。正是由于这个原因，向量化方法更

容易上手，特别是在对专业领域没有足够了解的情况下。尽管如此，在一些真实的应用中，

注 4：除非已经针对手头的任务进行了微调。

82 ｜ 第 3 章

人工特征还是非常常见的。在大多数工业应用场景中，人们会将通用的特征表示（基本向

量化表示和分布式表示）与特定于领域的特征相结合，由此来开发混合特征。IBM 研究院

和沃尔玛最近的研究展示了在真实的行业系统中综合使用启发式、人工特征和机器学习来

解决自然语言处理问题的例子。接下来的内容（例如第 4 章、第 5 章）还会涉及使用人工

特征的例子。

3.8　小结

本章详细介绍了文本表示的不同技术，既包括基本的向量化方法，也包括先进的深度学习

方法。这时自然会出现一个问题：什么时候应该使用向量化特征和嵌入，什么时候应该使

用人工特征？答案取决于手头的任务。对于某些应用，例如文本分类，更常见的是直接将

向量化方法和嵌入作为文本的特征表示。对于其他一些应用，例如信息提取，或者上一节

出现的示例，更常见的是使用特定于领域的人工特征。但在实践中，人们常常会使用结合

这两种特征的混合方法。尽管如此，向量化方法仍然是一个很好的起点。

希望本章的各种讨论和观点能让你很好地理解文本表示在自然语言处理中的作用、文本表

示的不同技术，以及它们各自的优缺点。接下来的内容（第 4~7 章）将继续解决自然语言

处理的基本任务，它们将使用不同的文本表示。

文本表示 ｜ 83

第二部分

核心

第 4 章

文本分类

无论做什么事，都应该提前组织规划，这样做事才能有条不紊。

——艾伦 • 亚历山大 • 米恩

我们每天都会查看电子邮件，而且可能不止一次。大多数电子邮件服务商能提供自动过滤

垃圾邮件的有用功能。这就是文本分类的一个用例。文本分类是一项常见的自然语言处理

任务，是本章讨论的重点。文本分类是将潜在类别集合中的一个或多个类别分配给给定文本

的任务。在垃圾邮件识别的例子中，有两个类别：垃圾邮件和非垃圾邮件。每一封传入的电

子邮件都会被分配到其中的一个类别。基于某些属性对文本进行分类的任务在社交媒体、电

子商务、医疗保健、法律和市场营销等各种领域都有着广泛的应用。尽管文本分类的目的和

应用可能因领域而异，但背后的抽象问题是相同的。这种核心问题的不变性以及在众多领

域的应用使得文本分类成为目前工业界应用最广泛、学术界研究最多的自然语言处理任务。

本章将讨论文本分类的用处、文本分类器的构建方法，以及针对真实场景的实用技巧。

在机器学习中，分类是将数据实例分类到一个或多个已知类别的问题。原始数据点可能具

有不同的格式，例如文本、语音、图像或数值。文本分类是分类问题中的一个特殊实例，

其输入数据点是文本，目标是将文本分类到预定义桶（类）中的一个或多个桶（类）中。

“文本”可以是任意长度的字符、词语、句子、段落，或者整个文档。考虑这样一个场景：

将产品的所有客户评论分为正面、负面和中性这三类。文本分类的挑战是从各个类别的样

例集合中“学习”这种分类，并预测新产品和新客户评论的类别。但是，文本分类不一定

总是产生一个类别，它可以是任意数量的已知类别。为了理解这一点，下面先快速介绍文

本分类的分类方法。

任何监督分类方法，包括文本分类，都可以根据所涉及类别的数量进一步分为三类：二分

类、多分类和多标签分类。如果类别的数量是两个，则称为二分类。如果类别的数量超过

两个，则称为多分类。因此，将电子邮件分为垃圾邮件或非垃圾邮件是二分类的例子，而

87

将客户评论的情绪分为负面、中性或正面是多分类的例子。在二分类和多分类中，每个文

档恰好属于类别集合 C 中的一个类别。在多标签分类中，一个文档可以拥有一个或多个标

签 / 类。例如，关于足球比赛的新闻文章可能同时属于“体育”和“足球”两个类别，而

关于美国选举的新闻文章可能具有“政治”“美国”和“选举”三个标签。因此，每个文

档所具有的标签属于 C 的子集。每篇文章可以不属于任何类，也可以属于一个类、多个类

或所有类。有时，集合 C 中的标签数量可能很多，这叫“极端分类”。在有些场景中，可

能会使用层级分类系统，文本在不同的层级具有不同的标签。本章将只关注二分类和多分

类，因为它们是业界最常见的文本分类用例。

文本分类有时也称为主题分类或文档分类。本书后面将使用“文本分类”这一说法。

注意，主题分类不同于话题检测，话题检测指的是从文本中发现或提取“话题”的问题，

第 7 章将对此进行研究。

本章将深入探讨文本分类任务，并使用多种方法构建文本分类器。本章的目标是介绍最常

用的技术，并给出应对不同场景的实用建议和构建文本分类系统时必须做出的决策。下面

首先介绍文本分类的常见应用程序，然后讨论文本分类的流水线，并说明如何使用该流水

线来训练和测试文本分类器，使用的方法不仅有传统的方法，而且还有先进的方法。接下

来是解决训练数据收集 / 稀疏性的问题及其处理方法。最后是总结本章各节的知识，并提

供一些实用建议和一个案例研究。

注意，本章将只讨论文本分类器的训练和评估。有关部署自然语言处理系统和执行质量保

证的一般性问题将在第 11 章中讨论。

4.1　应用程序

从 19 世纪的未知文本作者识别到 20 世纪 60 年代的美国邮政局对地址和邮政编码的光学

字符识别，文本分类在许多应用场景中引起了人们的兴趣。20 世纪 90 年代，研究人员开

始成功地将机器学习算法应用于大数据文本分类。电子邮件过滤，通常也叫“垃圾邮件分

类”，是最早的文本自动分类的例子之一，它至今还在影响我们的生活。从文本文档的手

动分析到基于计算机的纯统计方法，再到先进的深度神经网络，文本分类已经取得了长足

的进步。在深入探究文本分类的不同方法之前，下面先简要讨论一些常见的应用程序。这

些例子有助于识别哪些问题可以使用文本分类的方法予以解决。

内容分类与组织

内容分类与组织是指对大量的文本数据进行分类或标注的任务。这反过来又可以支持内

容组织、搜索引擎和推荐系统等用例。文本数据包括新闻网站、博客、在线书架、产品

评论、推文等。对电商网站上的产品说明进行标注，将公司的客户服务请求发送给相应

的支持团队，将电子邮件组织成个人、社交和促销三类，都是使用文本分类进行内容分

类与组织的例子。

客户支持

顾客经常使用社交媒体来表达他们对产品或服务的看法和体验。文本分类通常用于识别

品牌必须回应的推文（即需要采取行动的推文）和不需要回应的推文（即噪声）。为了

说明这一点，请考虑图 4-1 所示的关于梅西百货品牌的三条推文。

88 ｜ 第 4 章

不要在@Macys网上订购任何东西，除非你要的东西有库存!

我们的#WCW属于莉莉·罗查、凯伦·希尔和所有从心脏病和中风

中幸存下来的女性。我们很自豪能与你一起建设更健康的生活。

#RedDressCollection由@Macys呈现

带着节日的精神来看我明天在@Macys感恩节活动上的表演!

# YouMakeltFeelLikeChristmas # MacysParade

图 4-1：涉及品牌的推文：一条需要采取行动，另外两条是噪声

尽管这三条推文都明确提到了梅西百货这个品牌，但只有第一条推文需要梅西百货客户

支持团队回复。

电子商务

顾客会在亚马逊、eBay 等电商网站上留下一系列的产品评论。在这种情况下，文本分

类的一个例子就是根据顾客评论来理解和分析顾客对产品或服务的看法。这通常叫“情

感分析”。世界各地的品牌都广泛使用情感分析来更好地了解品牌与顾客的距离。在一

段时间内，情感分析不再只是将顾客反馈简单地分为正面、负面或中性，而是演变成一

种更复杂的范式：基于多个方面的情感分析。为了理解这一点，请考虑图 4-2 中所示的

餐馆顾客评论。

食物不错，服务较差

乔达安的咖啡馆在寒冷的冬天或在夏天的室外都很不错。食物和饮料都很棒，

还有很好的菜单。

但是这里的服务糟透了。虽然良好的服务不等同于过度热心，但是我必须自己

走到服务员那里询问我需要的东西。虽然美中不足，但还是值得光顾。

图 4-2：赞扬某些方面、批评另一些方面的评论

图 4-2 中的评论是负面、正面，还是中性？这个问题很难回答——食物很棒，但服务很差。

情感分析的相关从业者和品牌已经意识到，许多产品或服务具有多个方面。为了了解整体

情绪，需要了解情绪的每个方面。在对客户反馈进行这种细粒度分析时，文本分类起到了

重要的作用。第 9 章将详细讨论电子商务。

其他应用

除了上述范畴外，文本分类还用于以下多个不同的领域。

• 文本分类用于语言识别，例如识别新推文或新帖文的语言。谷歌翻译具有自动识别语言

的功能。

文本分类 ｜ 89

90 ｜ 第 4 章

• 作者身份归属，也就是从作者库中识别出未知文本的作者，是文本分类的另一个常见用

例，它被广泛应用于从法医分析到文学研究等各个领域。

• 最近，文本分类已被用于在线心理健康论坛的帖文分类。在自然语言处理界，每年都会

举办解决这种源于临床研究的文本分类竞赛。

• 最近，文本分类还被用于区分真假新闻。

注意，本节旨在说明文本分类的广泛应用，列表并非详尽无遗，但这些背景知识有助于快

速识别工作项目中遇到的文本分类问题。下面来看如何构建文本分类模型。

4.2　文本分类流水线

第 2 章讨论了常见的自然语言处理流水线。文本分类流水线中的部分步骤与第 2 章学习的

流水线相同。

在构建文本分类系统时，通常要遵循以下步骤。

1. 收集或创建适合任务的标注数据集。

2. 将数据集分成训练集和测试集两个部分，或训练集、验证集（即开发集）和测试集三个

部分，然后确定评估指标。

3. 将原始文本转换为特征向量。

4. 在训练集中使用特征向量和对应的标签训练分类器。

5. 使用步骤 2 中的评估指标，在测试集中测试模型性能。

6. 部署模型，服务于真实世界的用例，并监控其性能。

图 4-3 显示了构建文本分类系统的典型步骤。

训练数据

（文本及其分类）

预处理，文本特征提取

训练和评估分类器，

学习“特征-类别”映射

使用分类器，

在新的任务上预测

未知类别的

新文本

训练过程

1

2~3

6

4~5

图 4-3：文本分类流水线

重复第 3~5 步，探索不同的特征和分类算法及其参数，并调整超参数，然后进入第 6 步：

在生产中部署最优模型。

数据收集和预处理的相关步骤已在之前讨论过。例如，第 1 步和第 2 步已在第 2 章中详

细讨论过。第 3 章则集中讨论了第 3 步。本章的重点是第 4 步和第 5 步，最后再回到第 1

步，讨论特定于文本分类的问题。第 11 章将讨论第 6 步。为了能够执行第 4 步和第 5 步

（即测试模型性能或比较多个分类器），需要正确的评估指标。第 2 章讨论了自然语言处理

系统评估中使用的各种通用指标。具体到分类器的评估，在第 2 章介绍的指标中，以下几

个比较常用：分类准确率、精确率、召回率、F1 分数和 ROC 曲线下面积。本章将使用其

中的部分指标来评估模型，同时还将通过混淆矩阵来详细了解模型的性能。

此外，当在实际应用程序中部署分类系统时，还会使用特定于给定业务用例的关键性能指

标（KPI）来评估分类系统的影响和投资回报率（ROI）。这些通常是业务团队关心的指标。

例如，如果使用文本分类来自动发送客户服务请求，那么与手动发送相比，一个可能的

KPI 是减少请求得到响应的等待时间。本章的重点是讨论自然语言处理的评估方法。本书

的第三部分（讨论垂直行业的自然语言处理用例）将介绍垂直行业中常用的 KPI。

在使用流水线来构建文本分类器之前，先介绍几个不需要或不可能使用流水线的场景。

4.2.1　不使用文本分类流水线的简单分类器

文本分类流水线通常指的是有监督的机器学习场景。然而，不使用机器学习，不使用流水

线，也可以构建简单的分类器。考虑以下场景：给定 Twitter 语料库，其中每个推文都有

对应的情感标签：消极或积极。例如，一条推文显示“詹姆斯 • 邦德的新电影太棒了！”，

显然是在表达积极情绪。而另一条推文显示“我再也不会光顾这家餐厅了，可怕的地

方！！！”，则是在表达消极情绪。我们希望构建一个分类系统，只使用推文文本来预测新

推文的情感。一个简单的解决办法是创建积极词和消极词列表，然后比较输入推文中积极

词和消极词的使用情况，并根据这些信息做出预测。进一步的改进可能涉及创建更复杂的

词典，其中包含词的积极、消极和中性情感的程度，或者制定特定的启发式（例如，使用

笑脸表示积极情感），并使用它们来进行预测。这种方法叫基于词汇的情感分析。

显然，这里的文本分类是基于启发式 / 规则和情感词词典等定制资源，并不涉及任何“学

习”。虽然这种方法看起来过于简单，无法在许多真实的场景中取得理想的效果，但是它

有利于快速部署最小可行产品（MVP）。最重要的是，这种简单的模型有助于更好地理解

问题，并为评估指标和模型速度提供一个简单的基线。根据经验，在处理新的自然语言处

理问题时，最好从这些简单的方法开始。但是，如果要在大量的文本数据集合中推断出更

多的洞见，并获得更好的效果，最终仍然需要使用机器学习方法。

4.2.2　使用现成的文本分类API

如果手头任务属于通用型任务，例如识别文本的一般类别（如技术或音乐），就可能不必

自行“学习”分类器或遵循上述文本分类流水线。在这种情况下，可以使用谷歌云自然

语言等现成的 API，这些 API 提供现成的内容分类模型，可以识别近 700 种不同的文本类

别。另一个常见的分类任务是情感分析。所有主要的服务提供商（如谷歌、微软和亚马

逊）都提供了情感分析 API，并有多种支付方案。对于情感分类任务，如果现成的 API 能

文本分类 ｜ 91

够满足业务需求，那么就不必构建自己的系统。

然而，许多分类任务需要满足特定的业务需求。因此，本章接下来将参照前面描述的流水

线，来讨论构建自己的分类器。

4.3　一个流水线，多个分类器

现在来看文本分类器的构建。流水线中的第 3~5 步需要修改，其余步骤保持不变。好的数

据集是开始使用流水线的先决条件。所谓“好的数据集”指的是能够代表真实生产数据的

数据集。本章将使用公开数据集进行文本分类。大量的自然语言处理数据集，包括文本分

类数据集，都可以在网上找到。

注意，本章的目标是提供不同方法的概述。目前还没有一种方法可以普遍适用于所有类型

的数据和所有的分类问题。在现实世界中，通常需要尝试和评估多种方法，并选择最优的

方法在实践中部署。

接下来，本节将使用一个新闻数据集来演示文本分类。它由 8000 篇新闻文章组成，每篇文

章标注了是否与美国经济相关（属于是 / 否二分类）。这个数据集是不平衡的，1500 篇为相

关文章，6500 篇为不相关文章，这就提出了一个挑战，要防止学习偏向多数类别（在本例

中为不相关文章）。显然，使用这个数据集学习什么是相关的新闻文章比学习什么是不相关

的新闻文章更具挑战性。毕竟，只要猜测都是不相关的，就已经有了 80% 的准确率。

下面沿着本章前面描述的流水线，探讨词袋表示（在第 3 章中介绍过）在该数据集中的使

用。分类器的构建将使用朴素贝叶斯、逻辑回归和支持向量机三种著名的算法。本节主要

讨论其中的重要步骤。

4.3.1　朴素贝叶斯分类器

朴素贝叶斯是一种概率分类器，它利用贝叶斯定理，根据训练数据中观察到的证据对文本

进行分类。朴素贝叶斯根据特征在类中的出现情况来估算给定文本中的每个特征在每个类

中的条件概率。每个类的概率乘以给定文本的所有特征的条件概率后，计算出每个类的最

终分类概率。最后选择概率最大的类。对分类器的详细解释超出了本书的讨论范围。然

而，如果读者对朴素贝叶斯文本分类感兴趣，可以查看 Daniel Jurafsky 和 James H. Martin

的著作 Speech and Language Processing (3rd ed. draft) 中第 4 章的详细解释。朴素贝叶斯虽

然简单，但在分类实验中常常用作基线算法。

下面浏览一下流水线的关键步骤。这里使用 scikit-learn 实现的朴素贝叶斯。数据集加载

后，将数据分为训练数据和测试数据，如下面的代码片段所示。

# 步骤1：划分训练集和测试集

X = our_data.text 

# text列包含了文本数据，用于从中提取特征

y = our_data.relevance 

# relevance列是所要学习预测的列

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) 

# 将X和y拆分为训练集和测试集。默认情况下，训练集为75%，测试集为25% 

# random_state=1，便于复现结果

92 ｜ 第 4 章

文本分类 ｜ 93

下一步是对文本进行预处理，然后将其转换为特征向量。虽然预处理涉及许多不同的操作，

但这里需要的操作包括：转换小写；删除标点符号、数字和自定义字符串；删除停用词。

下面的代码片段显示了如何使用 scikit-learn 中的 CountVectorizer 对训练数据和测试数据进

行预处理并将其转换为特征向量，CountVectorizer 实现了第 3 章中介绍的词袋方法。

# 步骤2~3：对训练数据和测试数据进行预处理和向量化

vect = CountVectorizer(preprocessor=clean) 

# clean是自定义的预处理函数

X_train_dtm = vect.fit_transform(X_train) 

X_test_dtm = vect.transform(X_test) 

print(X_train_dtm.shape, X_test_dtm.shape)

运行代码后，将得到超过 45 000 个特征的特征向量。现在数据转换成了所需的格式：特征

向量。因此，下一步是训练和评估分类器。下面的代码片段展示了如何使用提取的特征来

训练和评估朴素贝叶斯分类器。

nb = MultinomialNB() # 实例化一个多项式朴素贝叶斯分类器

nb.fit(X_train_dtm, y_train) # 训练模型

y_pred_class = nb.predict(X_test_dtm) # 预测测试数据的类别

图 4-4 显示了朴素贝叶斯分类器在测试数据上的混淆矩阵。

混淆矩阵，使用全部特征

不相关

预测标签

相关

相关不相关

图 4-4：朴素贝叶斯分类器的混淆矩阵 真实标签

94 ｜ 第 4 章

如图 4-4 所示，在识别不相关文章方面，分类器效果较好，错误率只有 14%，但在识别相

关文章方面，分类器效果并不好，准确率只有 42%。一个显而易见的想法是收集更多的数

据。这是正确的，而且往往也是最有回报的方法。但是为了介绍其他方法，这里假设不能

改变数据或收集更多的数据。这个假设并非牵强附会——在业界，收集更多的数据通常是

奢侈的，我们必须利用现有的数据。分类器性能较差的可能原因及其改进方法见表 4-1，

本章接下来会介绍其中的一部分。

表4-1：分类器效果不佳的可能原因

编号 内容

原因 1 因为提取了所有可能的特征，所以最后得到的是大而稀疏的特征向量，其中大多数特征非常罕

见，最终成为噪声。稀疏的特征集也使训练变得困难

原因 2 数据集不相关文章占约 80%，相关文章仅占约 20%。这种类别不平衡使得学习过程偏向于“非相

关”文章的类别，这是因为“相关”文章的样例非常少

原因 3 也许需要更好的学习算法

原因 4 也许需要更好的预处理和特征提取机制

原因 5 也许应该考虑调整分类器的参数和超参数

如何提高分类性能？针对原因 1 的解决办法是减少特征向量中的噪声。前面代码示例中的

方法得到了近 40 000 个特征。大量的特征导致稀疏性，即特征向量中的大部分特征是零，

只有少数值为非零。这反过来又影响了文本分类算法的学习能力。如果将特征数限制在

5000，并重新运行训练和评估过程，会发生什么？这需要修改 CountVectorizer 实例化时

的参数，如下面的代码片段所示，其他步骤保持不变。

vect = CountVectorizer(preprocessor=clean, max_features=5000) # 第1步

X_train_dtm = vect.fit_transform(X_train) # 合并第2步和第3步

X_test_dtm = vect.transform(X_test) 

nb = MultinomialNB() # 实例化一个多项式朴素贝叶斯分类器

%time nb.fit(X_train_dtm, y_train) 

# 训练模型（使用IPython“魔法命令”计时）

y_pred_class = nb.predict(X_test_dtm) 

# 对X_test_dtm的类别进行预测

print("Accuracy: ", metrics.accuracy_score(y_test, y_pred_class))

图 4-5 显示了此设置下的新混淆矩阵。

很明显，虽然识别不相关文章的准确率似乎有所下降，但识别相关文章的准确率提高了

20% 以上。这时，有人可能会怀疑这是否是我们想要的。问题的答案取决于要解决的问

题。如果要在识别不相关文章方面获得合理的准确率，同时尽可能提高识别相关文章的准

确率，或者两者的准确率要达到同样高，那么可以得出结论：在使用朴素贝叶斯分类器的

情况下，减小特征向量的大小对于这个数据集是有用的。

混淆矩阵，使用5000个特征

不相关

相关

相关不相关

预测标签

图 4-5：使用朴素贝叶斯和特征选择改进分类性能

如果特征太多，为了减少数据稀疏性，不妨考虑减少特征的数量。

表 4-1 中的原因 2 是数据向多数类倾斜的问题。这个问题有多种解决方法。比较典型的两

种方法是对少数类的实例进行过采样和对多数类的实例进行欠采样，以创建一个平衡的数

据集。Python 库 Imbalanced-Learn 集成了解决这个问题的部分采样方法。虽然这里不会深

入探究库的细节，但是分类器也有内置的机制来处理不平衡的数据集。下一节将通过逻辑

回归分类器来介绍如何使用类别权重平衡。

类别不平衡是导致分类器性能不佳的最常见原因之一。必须经常检查手头任

务是否存在这种情况，并加以解决。

针对原因 3 的解决办法是尝试使用其他算法，接下来从逻辑回归开始。

文本分类 ｜ 95

真实标签

96 ｜ 第 4 章

4.3.2　逻辑回归

前面在描述朴素贝叶斯分类器时，提到了朴素贝叶斯分类器学习的是文本属于各个类别

的概率，并选择概率最大的类别。这样的分类器称为生成式分类器（generative classifier）。

相反，还有判别式分类器（discriminative classifier），它的目标是学习所有类别的概率分

布。逻辑回归属于判别式分类器，通常用作文本分类研究的基线，以及真实行业场景中的

MVP。

朴素贝叶斯根据特征在类中的出现情况来估计概率，但逻辑回归不同，它根据特征对分类

决策的重要性来“学习”每个特征的权重。逻辑回归的目标是学习训练数据中的类之间的

线性分隔，目的是使数据的概率最大化。学习特征权重和所有类别的概率分布是通过“逻

辑”函数和“逻辑回归”来完成的。

下面使用朴素贝叶斯例子最后一步得到的 5000 维特征向量来训练逻辑回归分类器。下面

的代码片段显示了如何将逻辑回归用于分类任务。

from sklearn.linear_model import LogisticRegression 

logreg = LogisticRegression(class_weight="balanced") 

logreg.fit(X_train_dtm, y_train) 

y_pred_class = logreg.predict(X_test_dtm) 

print("Accuracy: ", metrics.accuracy_score(y_test, y_pred_class))

分类器的准确率为 73.7%。图 4-6 显示了这种方法的混淆矩阵。

混淆矩阵，使用归一化

不相关

预测标签

相关

相关不相关

图 4-6：逻辑回归分类性能 真实标签

逻辑回归分类器实例化时有一个参数 class_weight，赋值为 balanced 表示分类器会按照各

个类别样本量的倒数来改变类的权重。因此，代表性较低的类预计会有更好的表现。作为

实验，删除该参数并重新训练分类器后，可以看到混淆矩阵右下角单元格数值下降了大约

5%。然而，对于这个数据集，逻辑回归的效果显然比朴素贝叶斯差。

表 4-1 中的原因 3 是“也许需要更好的学习算法”。这就引出了一个问题：什么是更好的学

习算法？使用机器学习方法时的一般经验法则是，没有一种算法能适用于所有的数据集。

因此，通常需要对各种算法进行实验和对比。

下一节中用另一种著名的分类算法“支持向量机”来代替逻辑回归，看看这个想法是否有

帮助。支持向量机在部分文本分类任务中被证明是有用的。

4.3.3 SVM

根据前文描述，逻辑回归是一种判别式分类器，它学习各个特征的权重并预测类的概率分

布。支持向量机（SVM）最早出现于 20 世纪 60 年代初，是一种类似于逻辑回归的判别式

分类器。但与逻辑回归不同的是，SVM 在更高维的空间中寻找最优超平面，以最大可能

的间隔将数据中的类分开。此外，与逻辑回归不同，SVM 甚至能够学习类之间的非线性

分离。但是，SVM 可能需要更长的时间来训练。

在 sklearn（scikit-learn）中，SVM 有多种形式。现在来看其中的一种。最大特征数需要

改为 1000，而不是前面示例中的 5000，其余所有内容保持不变。之所以将特征数限制为

1000，是因为支持向量机算法的训练时间较长。下面的代码片段展示了具体的做法，图 4-7

显示了得到的混淆矩阵。

from sklearn.svm import LinearSVC 

vect = CountVectorizer(preprocessor=clean, max_features=1000) # 第1步

X_train_dtm = vect.fit_transform(X_train) # 合并第2步和第3步

X_test_dtm = vect.transform(X_test) 

classifier = LinearSVC(class_weight='balanced') # 注意balanced选项

classifier.fit(X_train_dtm, y_train) # 用训练数据拟合模型 

y_pred_class = classifier.predict(X_test_dtm) 

print("Accuracy: ", metrics.accuracy_score(y_test, y_pred_class))

与逻辑回归相比，SVM 识别相关文章的准确率似乎更高。但在这组实验中，朴素贝叶斯

（使用较小的特征集）似乎是这一数据集的最佳分类器。

前面这些例子展示了各个步骤的改变是如何影响分类性能的，同时也给出了对不同结果的

解释。很明显，本节没有考虑许多其他的可能性，比如尝试其他文本分类算法，改变不同

分类器的不同参数，提出更好的预处理方法等。这里留给读者作为进一步的练习。在真实

世界中，文本分类项目需要尝试多种选项：先从最简单的方法开始建模、部署和扩展，然

后逐渐增加复杂性，最终的目标是在考虑所有其他约束条件的情况下，构建最能满足业务

需求的分类器。

文本分类 ｜ 97

混淆矩阵，使用归一化

不相关

相关

相关不相关

预测标签

图 4-7：支持向量机分类的混淆矩阵

现在考虑表 4-1 中的原因 4，“也许需要更好的预处理和特征提取机制”。前面已经使用了

词袋特征，下面使用第 3 章介绍的其他特征表示技术进行文本分类。

4.4　在文本分类中使用神经嵌入

第 3 章的后半部分讨论了基于神经网络的特征工程技术，如词嵌入、字符嵌入和文档嵌

入。使用基于嵌入的特征的优势在于，它们可以创建稠密、低维的特征表示，而不是词袋

/TF-IDF 等稀疏、高维的结构。设计和使用基于神经嵌入的特征有不同的方法。本节将介

绍在文本分类中使用嵌入表示的一些方法。

4.4.1　词嵌入

长期以来，文本分类主要使用词和 n-gram 作为特征。词的向量化有不同的方法，4.3 节使

用了 CountVectorizer 的向量化表示。在过去的几年里，使用神经网络结构来“学习”词

的表示（即词嵌入）变得流行起来。第 3 章介绍了这背后的一些直觉。下面来看如何使用

词嵌入特征进行文本分类。这里只介绍重要的步骤，以及这种方法与 4.3 节方法的区别。

文本数据的加载和预处理仍然是一样的。但是文本的向量化不再使用基于词袋的特征，而

是使用神经嵌入模型，具体而言，也就是前面介绍过的预训练嵌入模型。Word2vec 是一种

98 ｜ 第 4 章真实标签

常用的词嵌入模型训练算法，如第 3 章所讨论。互联网上提供了几个在大型语料库上训练

的 Word2vec 预训练模型。这里使用谷歌提供的预训练模型。下面的代码片段展示了如何

使用 gensim 将这个模型加载到 Python 中。

data_path= "/your/folder/path" 

path_to_model = os.path.join(data_path,'GoogleNews-vectors-negative300.bin') 

training_data_path = os.path.join(data_path, "sentiment_sentences.txt") 

# 加载Word2vec模型。这需要一点时间

w2v_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True) 

print('done loading Word2Vec')

这个大型模型可以看作一个字典，其中键是词汇表中的词，值是模型所学习的嵌入表示。

给定一个查询词，如果该词的嵌入存在于字典中，将返回该词的嵌入。如何使用这种预先

学习的嵌入来表示特征？正如在第 3 章中所讨论的，有多种方法可以实现这一点。一个简

单的方法就是对文本中的词嵌入求平均值。下面的代码片段显示了实现此操作的一个简单

函数。

# 通过对所有词嵌入求平均值，创建一个特征

def embedding_feats(list_of_lists): 

 DIMENSION = 300 

 zero_vector = np.zeros(DIMENSION) 

 feats = [] 

 for tokens in list_of_lists: 

 feat_for_this = np.zeros(DIMENSION) 

 count_for_this = 0 

 for token in tokens: 

 if token in w2v_model: 

 feat_for_this += w2v_model[token] 

 count_for_this +=1 

 feats.append(feat_for_this/count_for_this) 

 return feats 

train_vectors = embedding_feats(texts_processed) 

print(len(train_vectors))

注意，上述代码只对字典中存在的词使用嵌入，忽略没有嵌入的词。另外，上述代码将返

回维度为 DIMENSION(=300) 的单一向量。得到的嵌入向量视为代表整个文本的特征向量。

特征工程完成后，最后一步类似于 4.3 节：使用这些特征训练一个分类器。这里把它留给

读者作为练习。

使用这些特征来训练逻辑回归分类器，得到的分类准确率是 81%。考虑到只使用了预训练

词嵌入模型，并且只遵循了基本的预处理步骤，这是一个很棒的基线模型。另外，也可以

对第 3 章介绍的 GloVe 等其他预训练嵌入方法进行实验。本例中使用的 gensim 还支持训

练自己的词嵌入。如果自定义领域的词汇表与预训练嵌入的词汇表相差很大，那么就需要

训练自己的嵌入来提取特征。

为了决定是训练自己的嵌入还是使用预先训练的嵌入，一个很好的经验法则是计算词汇重

叠度。如果自定义领域和预训练嵌入的词汇重叠度大于 80%，那么使用预训练词嵌入往往

能得到较好的文本分类效果。

文本分类 ｜ 99

在使用基于嵌入的特征提取方法部署模型时，需要考虑的一个重要因素是，学习到的或预

训练的嵌入模型必须加载到内存中。如果模型本身很庞大（例如，上面使用的预训练模型

需要 3.6GB），那么部署时需要考虑这一因素。

4.4.2　子词嵌入和fastText

词嵌入，顾名思义，是关于“词”的表示的。如前文所述，现成的嵌入在分类任务上似乎

效果不错。但是，如果数据集中的词在预训练模型的词汇表中不存在，那么如何获得这个

词的表示呢？这个问题通常叫未登录词（OOV）问题。在前面的例子中，特征提取直接忽

略了未登录词。有没有更好的办法？

第 3 章讨论过 fastText 嵌入，其思想是利用子词信息来丰富词嵌入。词嵌入因此可以表示

为各个字符 n-gram 的表示的和。与词嵌入相比，子词嵌入似乎过程更长，但它有以下两个

优点。

• 这种方法可以处理训练数据中没有出现的词（即未登录词）。

• 这种实现有助于在非常大的语料库上进行极快的学习。

虽然 fastText 是学习嵌入的通用库，但它也提供端到端的分类器训练和测试来支持现成的

文本分类。也就是说，不需要单独的特征提取。接下来，本节将展示如何使用 fastText 分

类器进行文本分类。这里使用的数据集是一个平衡的数据集，由 14 个类组成，每个类有

40 000 个训练样例和 5000 个测试样例。因此，数据集的总大小为 560 000 个训练数据点和

70 000 个测试数据点。显然，这个数据集比之前的要大得多。能否使用 fastText 快速构建

训练模型？来试一试吧。

训练集和测试集以 CSV 文件提供。因此，第一步是将这些文件读入 Python 环境，并执

行文本清理操作删除无关字符，这与前面其他分类器的预处理步骤相同。完成后，使用

fastText 的过程就非常简单了。下面的代码片段显示了一个简单的 fastText 模型。

## 使用fastText进行特征提取和训练 

from fasttext import supervised 

"""fastText expects and training file (csv), a model name as input arguments. 

label_prefix refers to the prefix before label string in the dataset. 

default is __label__. In our dataset, it is __class__. 

""" 

model = supervised(train_file, 'temp', label_prefix="__class__") 

results = model.test(test_file) 

print(results.nexamples, results.precision, results.recall)

运行这段代码，就会注意到，尽管这是一个巨大的数据集，而且提供给分类器的是原始文

本而不是特征向量，但是训练只需要几秒钟，就能获得接近 98% 的准确率和召回率。作为

练习，请尝试在这个数据集上使用词袋或词嵌入特征和逻辑回归等算法来构建分类器。注

意记录特征提取和分类学习分别需要多长时间。

面对大型数据集，如果前面的方法效果都不好，那么不妨选择 fastText 来构建强大而有效

的基线。然而，在使用 fastText 时，需要注意，fastText 使用了预先训练好的字符 n-gram

嵌入。因此，当保存训练好的模型时，它会携带整个字符 n-gram 嵌入字典。这将导致模型

100 ｜ 第 4 章

臃肿，并可能导致出现工程问题。例如，在上面的代码片段中，“temp”模型的大小接近

450MB。不过，fastText 提供了减少分类模型内存占用的选项，同时尽量减少对分类性能

的影响。fastText 使用词汇剪枝和压缩算法来做到这一点。在模型尺寸受到限制的情况下，

探索这些可能性也许不失为一种好的选择。

fastText 训练速度极快，非常有利于构建强大的基线，缺点是模型太大。

上面介绍了 fastText 在文本分类中的作用。这里仅展示默认的分类模型，未对超参数进行

任何调整。关于分类器参数调整和自定义嵌入训练，详见 fastText 的官方文档。但是，前

面介绍的两种嵌入表示都只学习词和字符的表示，然后汇集起来形成文本表示。下面来看

如何使用第 3 章中讨论的 Doc2vec 方法直接学习文档的表示。

4.4.3　文档嵌入

Doc2vec 嵌入方法直接学习整个文档（句子或段落）的表示，而不是每个词的表示。正如

同词和字符嵌入可以作为文本分类的特征，Doc2vec 也可以用作特征表示机制。由于最新

版的 Doc2vec 无法使用现有的预训练模型，下面来看如何构建自己的 Doc2vec 模型，并将

其用于文本分类。

这里使用的数据集包含 40 000 条推文，分别用 13 个标签表示不同的情感。我们选取数据

集中最常见的“中性”“担忧”“高兴”三个标签来构建文本分类器，从而将新的推文分类

到三个类别中的一个。

加载数据集并选择三个最常见标签的子集之后，需要考虑的一个重要步骤是数据预处理。

与前面的例子相比，这里有什么不同？为什么不能直接照抄以前的步骤？正如第 2 章关

于文本预处理的简要讨论，推文与新闻文章或其他类似文本有一些不同之处。首先，推

文很短。其次，传统的分词器可能无法很好地将推文中的微笑符、标签、用户名等拆分

成多个词。最近，这种特殊的需求促使人们对 Twitter 的自然语言处理进行了大量的研

究，从而产生了几个用于推文的预处理方案，其中一个方案是 Python NLTK 库中实现的

TweetTokenizer。关于这个话题，第 8 章将详细讨论。现在来看如何在下面的代码片段中

使用 TweetTokenizer。

tweeter = TweetTokenizer(strip_handles=True,preserve_case=False) 

mystopwords = set(stopwords.words("english")) 

# 推文预处理和分词函数

def preprocess_corpus(texts): 

 def remove_stops_digits(tokens): 

 # 删除停用词和数字的嵌套函数

 return [token for token in tokens if token not in mystopwords 

 and not token.isdigit()] 

 return [remove_stops_digits(tweeter.tokenize(content)) for content in texts] 

文本分类 ｜ 101

mydata = preprocess_corpus(df_subset['content']) 

mycats = df_subset['sentiment']

下一步是训练 Doc2vec 模型来学习推文表示。对于这一步，任何大型推文数据集都可以。

然而，由于没有现成的语料库，这里将数据集拆分成训练集和测试集，并用训练数据来

学习 Doc2vec 表示。这个过程首先使用 TaggedDocument 类将文档表示为词的列表和“标

签”（最简单的形式是文件名或文档 ID），从而将数据转换为 Doc2vec 可读的格式。不过，

Doc2vec 本身也可以用作多分类问题和多标签分类问题的最近邻分类器。这里留给读者作

为探索性练习。下面的代码片段展示了如何训练用于推文的 Doc2vec 分类器。

# 准备doc2vec格式的训练数据

d2vtrain = [TaggedDocument((d),tags=[str(i)]) for i, d in enumerate(train_data)] 

# 训练doc2vec模型来学习推文的表示。只使用训练数据

model = Doc2Vec(vector_size=50, alpha=0.025, min_count=10, dm =1, epochs=100) 

model.build_vocab(d2vtrain) 

model.train(d2vtrain, total_examples=model.corpus_count, epochs=model.epochs) 

model.save("d2v.model") 

print("Model Saved")

如以上代码片段中的模型定义所示，Doc2vec 的训练需要设置几个参数：vector_size 是指

所要学习的嵌入的维数；alpha 是学习率；min_count 是保留在词汇表中的词的最低频率；

dm（分布式存储）是 Doc2vec 中实现的一种表示学习器（另一种是 dbow，即分布式词袋）；

epochs 是训练迭代的次数。还有一些其他参数也可以自定义。虽然 Doc2vec 模型的最佳训

练参数有一些指导方针，但这些指导方针并没有得到充分的验证，而且我们不知道这些指

导方针是否适用于推文。

解决这个问题的最佳方法是尝试 dm/dbow、向量大小、学习率等重要参数的各种取值，并

对多个模型进行比较。由于模型只学习了文本的表示，那么如何比较这些模型呢？一种

方法是在下游任务中使用这些所学习的表示——在本例中，这个下游任务是文本分类。

Doc2vec 的 infer_vector 函数使用预训练模型来推断给定文本的向量表示。由于不同的超

参数会产生一定的随机性，所以每次推断出的向量都是不同的。由于这个原因，为了得到

稳定的表示，需要运行多次（多步），然后将向量进行聚合。下面使用学习模型来推断数

据的特征，并训练逻辑回归分类器。

# 使用已训练的模型来推断训练数据和测试数据的特征表示

model= Doc2Vec.load("d2v.model") 

# 多步推断，以获得稳定的表示

train_vectors = [model.infer_vector(list_of_tokens, steps=50) 

 for list_of_tokens in train_data] 

test_vectors = [model.infer_vector(list_of_tokens, steps=50) 

 for list_of_tokens in test_data] 

myclass = LogisticRegression(class_weight="balanced") 

# 这是因为类别不平衡

myclass.fit(train_vectors, train_cats) 

preds = myclass.predict(test_vectors) 

print(classification_report(test_cats, preds))

在只有三个类的大语料库上，该模型的 F1 分数为 0.51，性能似乎很差。对于这个糟糕的

结果，有几种解释。首先，推文不同于完整的新闻文章或结构标准的句子，每条推文包含

102 ｜ 第 4 章

的数据非常有限。其次，人们发推文时会使用各种各样的拼写和语法，以及很多不同形式

的表情符号。特征表示需要捕捉这些方面的信息。虽然尝试大量参数可能有助于找到最佳

模型，但正如第 3 章所讨论的，也可以选择探究特定于问题的特征表示。第 8 章将介绍推

文的特征表示。和 fastText 一样，使用 Doc2vec 需要记住：如果使用 Doc2vec 进行特征表

示，就必须存储学习了这种表示的模型。虽然 Doc2vec 模型通常没有 fastText 那么臃肿，

但它的训练速度也不如 fastText 那么快。在部署之前，需要考虑和比较这些优缺点。

前面介绍了各种特征表示，以及它们在机器学习文本分类中的作用。现在来看这几年流行

起来的一个算法家族：深度学习。

4.5　用于文本分类的深度学习

正如第 1 章所讨论的，深度学习是通过各种多层神经网络结构进行学习的一系列机器学习

算法。在过去的几年里，深度学习已经显著地提高了图像分类、语音识别和机器翻译等标

准机器学习任务的性能。这使得人们产生了将深度学习用于文本分类等各种任务的广泛兴

趣。前面介绍了如何使用词袋等嵌入表示训练不同的机器学习分类器。现在来看如何使用

深度学习进行文本分类。

文本分类中最常用的两种神经网络分别是卷积神经网络（CNN）和循环神经网络（RNN）。

长短期记忆（LSTM）网络是一种常见的 RNN。最近的方法则是使用大型的预训练语言模

型来微调手头任务。本节将使用一个情感分类数据集来学习如何训练 CNN 和 LSTM，以

及如何微调预训练语言模型来进行文本分类。注意，关于神经网络原理的详细解释超出了

本书的讨论范围。Daniel Jurafsky 和 James H. Martin 的著作 Speech and Language Processing 

(3rd ed. draft) 对自然语言处理中的各种神经网络方法进行了简明的概述。

训练任何机器学习或深度学习模型的第一步是定义特征表示。这一步在前面看到的词袋或

嵌入向量等方法中是相对简单的。但是，对于神经网络，如第 3 章中所述，输入向量需要

进行进一步处理。下面快速回顾将训练和测试数据转换成神经网络输入层所需格式的步骤。

1. 对文本进行分词，并将其转换为词索引向量。

2. 填充文本序列，使所有文本向量具有相同的长度。

3. 将每个词索引映射到嵌入向量，方法是将词索引向量与嵌入矩阵相乘。嵌入矩阵可以使

用预训练嵌入来填充，也可以使用该语料库来训练。

4. 使用第 3 步的输出作为神经网络结构的输入。

这些步骤都完成后，接下来就是确定神经网络结构，并用神经网络训练分类器。本节中的

代码展示了从文本预处理到神经网络训练和评估的整个过程。这里使用的 Keras 是一个基

于 Python 的深度学习库。下面的代码片段展示了第 1 步和第 2 步。

# 使用Keras Tokenizer将文本样例转换成二维整数张量

# Tokenizer只使用训练数据进行拟合，拟合后可用于训练数据和测试数据的分词

tokenizer = Tokenizer(num_words=MAX_NUM_WORDS) 

tokenizer.fit_on_texts(train_texts) 

train_sequences = tokenizer.texts_to_sequences(train_texts) 

test_sequences = tokenizer.texts_to_sequences(test_texts) 

word_index = tokenizer.word_index 

print('Found %s unique tokens.' % len(word_index)) 

文本分类 ｜ 103

# 将其转换为输入神经网络的序列。序列的最大长度为1000，和前面的设置一样

# 初始填充为0，直到向量的大小为MAX_SEQUENCE_LENGTH为止

trainvalid_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH) 

test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH) 

trainvalid_labels = to_categorical(np.asarray(train_labels)) 

test_labels = to_categorical(np.asarray(test_labels))

第 3 步：如果使用预训练嵌入将训练数据和测试数据转换成嵌入矩阵，就必须下载预训练

嵌入，并使用预训练嵌入将数据转换成神经网络输入所需的格式。下面的代码片段演示了

如何使用 GloVe 嵌入（第 3 章中介绍过）实现这一点。GloVe 嵌入自带多种维度，这里选

择 100 作为维数。维度的值是一个超参数。可以使用其他维数进行实验 1。

embeddings_index = {} 

with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f: 

 for line in f: 

 values = line.split() 

 word = values[0] 

 coefs = np.asarray(values[1:], dtype='float32') 

 embeddings_index[word] = coefs 

num_words = min(MAX_NUM_WORDS, len(word_index)) + 1 

embedding_matrix = np.zeros((num_words, EMBEDDING_DIM)) 

for word, i in word_index.items(): 

 if i > MAX_NUM_WORDS: 

 continue 

 embedding_vector = embeddings_index.get(word) 

 if embedding_vector is not None: 

 embedding_matrix[i] = embedding_vector

第 4 步：现在可以开始训练文本分类的深度学习模型了。深度学习结构由输入层、输出

层和介于两者之间的若干隐藏层组成。不同的网络结构使用不同的隐藏层。文本输入的

输入层通常是嵌入层。输出层，特别是在文本分类的情况下，是一个产生分类输出的

softmax 层。如果不使用预训练嵌入，而是直接训练输入层，最简单的方法是调用 Keras 的

Embedding 类，指定输入和输出维度。但是，由于这里使用预训练嵌入，因此应该使用刚

刚构建的嵌入矩阵来创建一个自定义的嵌入层。下面的代码片段显示了如何进行此操作。

embedding_layer = Embedding(num_words, EMBEDDING_DIM, 

 embeddings_initializer=Constant(embedding_matrix), 

 input_length=MAX_SEQUENCE_LENGTH, 

 trainable=False) 

print("Preparing of embedding matrix is done")

这将作为 CNN、LSTM 或其他任何想要使用的神经网络的输入层。在了解如何预处理输入

并定义输入层之后，接下来就是确定 CNN 和 LSTM 等神经网络结构的其余部分。

4.5.1　用于文本分类的CNN

现在来看如何定义、训练和评估 CNN 文本分类模型。CNN 通常由一系列卷积层和池化层

等隐层组成。在文本分类中，CNN 将学习最有用的词袋或 n-gram 特征，而不是将整个词

注 1：还有其他预训练嵌入可以选择。这里的选择是任意的。

104 ｜ 第 4 章

集或 n-gram 集合作为特征。由于数据集只有正、负两个类别，因此输出层只有两个输出，

激活函数为 softmax。下面使用 Keras 中的 Sequential 模型类来定义一个具有三个卷积池

化层的 CNN，Sequential 允许我们将深度学习模型定义为层和层的顺序编排。每一层及

其激活函数确定后，接下来是定义优化器、损失函数和评估指标等重要参数来调整模型的

超参数。这些都完成后，下一步是对模型进行训练和评估。下面的代码片段显示了如何

使用 Python 库 Keras 来指定文本分类的 CNN 结构，并基于所用的数据集打印了该模型的

结果。

print('Define a 1D CNN model.') 

cnnmodel = Sequential() 

cnnmodel.add(embedding_layer) 

cnnmodel.add(Conv1D(128, 5, activation='relu')) 

cnnmodel.add(MaxPooling1D(5)) 

cnnmodel.add(Conv1D(128, 5, activation='relu')) 

cnnmodel.add(MaxPooling1D(5)) 

cnnmodel.add(Conv1D(128, 5, activation='relu')) 

cnnmodel.add(GlobalMaxPooling1D()) 

cnnmodel.add(Dense(128, activation='relu')) 

cnnmodel.add(Dense(len(labels_index), activation='softmax')) 

cnnmodel.compile(loss='categorical_crossentropy', 

 optimizer='rmsprop', 

 metrics=['acc']) 

cnnmodel.fit(x_train, y_train, 

 batch_size=128, 

 epochs=1, 

 validation_data=(x_val, y_val)) 

score, acc = cnnmodel.evaluate(test_data, test_labels) 

print('Test accuracy with CNN:', acc)

如上所示，在定义模型时，需要做很多选择，例如激活函数、隐藏层、层大小、损失函

数、优化器、评估指标、轮数和批大小。虽然有一些推荐选项，但是对于最适合所有数据

集和问题的最佳组合还没有达成共识。因此，构建模型的一个好方法是使用不同的设置

（即超参数）进行实验。记住，所有这些决策都伴随着一定的成本。例如，在实践中，可

以将轮数设为 10 以上，但这也增加了训练模型所需的时间。另外，如果要在模型中训练

一个嵌入层，而不是使用预训练嵌入，那么只需将 cnnmodel.add(embedding_layer) 这一行

改成 cnnmodel.add(Embedding(Param1, Param2))。下面的代码片段显示了相应的代码和模

型性能。

print("Defining and training a CNN model, training embedding layer on the fly 

 instead of using pre-trained embeddings") 

cnnmodel = Sequential() 

cnnmodel.add(Embedding(MAX_NUM_WORDS, 128)) 

... 

... 

cnnmodel.fit(x_train, y_train, batch_size=128, 

 epochs=1, validation_data=(x_val, y_val)) 

score, acc = cnnmodel.evaluate(test_data, test_labels) 

print('Test accuracy with CNN:', acc)

运行这段代码，就会注意到，在这种情况下，使用自己的数据集训练嵌入层似乎可以更好

文本分类 ｜ 105

地对测试数据进行分类。但是，如果训练数据非常少，那么最好选择使用预训练嵌入，或

者使用本章后面讨论的领域适应技术。现在来看如何使用 LSTM 来训练文本分类模型。

4.5.2　用于文本分类的LSTM

如第 1 章所述，LSTM 等 RNN 变体在过去几年中已经成为神经语言建模的首选方法。这

主要是因为语言在本质上是顺序的，而 RNN 专门用于处理顺序数据。在语言中，句子中

的当前词依赖于它的上下文，也就是它前后的词。但是，CNN 文本建模并没有考虑这个

至关重要的事实，而 RNN 在学习语言表示或语言模型时会使用这种语境。因此，RNN 在

自然语言处理任务中表现出了良好的效果。虽然有些 CNN 变体也能将语境信息考虑在内，

但 CNN 与 RNN 孰好孰坏仍然充满争议。本节将介绍一个使用 RNN 进行文本分类的例子。

由于前面已经展示了一个神经网络，再训练一个就相对容易，只需在前面的两个代码示例

中用 LSTM 替换卷积和池化部分即可。下面的代码片段演示了如何使用同样的 IMDB 数据

集对 LSTM 文本分类模型进行训练。

print("Defining and training an LSTM model, training embedding layer on the fly") 

rnnmodel = Sequential() 

rnnmodel.add(Embedding(MAX_NUM_WORDS, 128)) 

rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) 

rnnmodel.add(Dense(2, activation='sigmoid')) 

rnnmodel.compile(loss='binary_crossentropy', 

 optimizer='adam', 

 metrics=['accuracy']) 

print('Training the RNN') 

rnnmodel.fit(x_train, y_train, 

 batch_size=32, 

 epochs=1, 

 validation_data=(x_val, y_val)) 

score, acc = rnnmodel.evaluate(test_data, test_labels, 

 batch_size=32) 

print('Test accuracy with RNN:', acc)

注意，这段代码的运行时间比 CNN 示例要长很多。虽然 LSTM 更能利用文本的顺序特征，

但 LSTM 对数据的需求量要远远大于 CNN。因此，LSTM 在某些数据集上表现出相对较

差的效果，不一定是因为模型本身存在缺陷。也可能是因为拥有的数据量太少，所以不足

以充分利用 LSTM 的全部潜力。另外，和 CNN 一样，多个参数和超参数在模型性能中扮

演着重要的角色。因此，在确定最终模型之前，最好尝试多种选择并比较不同的模型。

4.5.3　使用大型预训练语言模型进行文本分类

在过去的两年中，基于神经网络的文本表示方法有了很大的改进。第 3 章的 3.5 节讨论了

其中的一部分。最近，这些文本表示已经成功地用于文本分类，方法是微调预训练模型来

适应给定的任务和数据集。第 3 章提到的 BERT 就是这样一种常见的文本分类模型。现在

来看如何使用前面的数据集将 BERT 用于文本分类。

这里使用 ktrain（TensorFlow Keras 的简化封装库）来训练和使用预训练深度学习模型。

ktrain 简化了数据集和预训练 BERT 获取、分类任务微调等各个步骤。

106 ｜ 第 4 章

加载数据集后，下一步是下载 BERT 模型，并根据 BERT 的要求对数据集进行预处理。下

面的代码片段展示了如何使用 ktrain 的函数执行此操作。

(x_train, y_train), (x_test, y_test), preproc = 

 text.texts_from_folder(IMDB_DATADIR,maxlen=500, 

 preprocess_mode='bert',train_test_names=['train','test'],

下一步是加载预训练 BERT 模型，并针对本数据集进行微调。下面是执行此操作的代码

片段。

model = text.text_classifier('bert', (x_train, y_train), preproc=preproc) 

learner=ktrain.get_learner(model,train_data=(x_train,y_train), 

 val_data=(x_test, y_test), batch_size=6) 

learner.fit_onecycle(2e-5, 4)

这三行代码的作用是使用 BERT 预训练模型来训练文本分类器。和前面的其他例子一

样，这里也需要进行参数调优和反复实验来选择性能最佳的模型。这里把它留给读者作

为练习。

本节通过 CNN 和 LSTM 两种神经网络结构介绍了如何使用深度学习进行文本分类的思想，

并展示了如何针对给定的数据集和分类任务来微调先进的预训练语言模型（BERT）。除了

CNN 和 LSTM，这些神经网络结构还存在多种变体，而且自然语言处理研究人员每天都在

提出新的模型。另外，预训练语言模型 BERT 也有其他类似的模型，这是自然语言处理研

究中一个不断发展的领域，技术水平每隔几个月（甚至几周）就会提升。然而，作为从业

者，根据我们的经验，一些自然语言处理任务，特别是文本分类，仍然广泛使用本章前面

介绍的几种非深度学习方法。造成这种情况主要有两个原因：一是神经网络需要大量的特

定于任务的训练数据，二是相关的计算和部署成本非常高昂。

基于深度学习的文本分类器通常只是训练数据的稠密表示。这些模型的性能

往往取决于训练数据集。因此，选择正确的数据集是非常重要的。

在本节的最后，我们再次强调：在大多数工业环境中，最好先从简单、易于部署的方法开

始，形成 MVP，然后考虑客户需求和可行性，逐步推进。

上面介绍了构建文本分类模型的几种方法。不同于启发式方法，机器学习模型在预测时通

常被视为黑箱。不过，可解释机器学习最近开始崭露头角，而能够“解释”机器学习模型

预测结果的程序也已经出现。下面快速了解一下它们在文本分类中的应用。

4.6　解释文本分类模型

前面已经介绍了如何使用不同的方法来训练文本分类器。所有这些例子都是直接接受分类

器的预测结果，不需要任何解释。事实上，大多数真实世界的文本分类用例可能是类似

的——直接使用分类器的输出，而不质疑它的决定。例如，在垃圾邮件分类中，人们通常

不需要解释为什么某封邮件被归类为垃圾邮件或普通邮件。但是，在某些情况下，解释是

文本分类 ｜ 107

必要的。

考虑这样一个场景：某论坛网站需要开发一个识别恶意评论的分类器。分类器需要识别出

恶意评论，并像人类版主一样删除或隐藏恶意评论。我们知道分类器是不完美的，可能会

出错。如果评论者质疑这种审核决定并要求解释，那么该怎么办？在这种情况下，指出影

响分类决策的特征来“解释”分类决策可能是有用的。这种方法也有助于深入了解模型及

其在实际数据（而不是训练集或测试集）上的表现，这反过来有助于后面产生更好、更可

靠的模型。

随着机器学习模型开始部署到实际应用程序中，人们对模型可解释性的兴趣也在增加。最

近的一些研究催生了解释模型预测（特别是分类）的工具。Lime 就是这样一种工具，它试

图使用训练实例周围的局部线性模型来近似分类模型，从而解释黑箱模型。这样做的好处

是，线性模型可以表示为特征的加权和，人类很容易理解。例如，对于具有 A 和 B 两个类

别的二分类器，对于给定的测试实例，如果存在两个特征 f1 和 f2，那么该实例附近的 Lime

线性模型可能是 –0.3 × f1 + 0.4 × f2，预测值为 B。这表明特征 f1 的存在会对预测结果产

生负面影响（0.3），并使其偏向 A。下面来看如何使用 Lime 来理解文本分类器的预测。

用Lime解释分类器预测

这里使用本章前面构建的模型来看 Lime 如何解释模型的预测。下面的代码片段使用了之

前构建的逻辑回归模型，可将给定的新闻文章分类为相关或不相关。代码片段同时展示了

Lime 的使用。

from lime import lime_text 

from lime.lime_text import LimeTextExplainer 

from sklearn.pipeline import make_pipeline 

y_pred_prob = classifier.predict_proba(X_test_dtm)[:, 1] 

c = make_pipeline(vect, classifier) 

mystring = list(X_test)[221] # 从测试实例中获取一个字符串

print(c.predict_proba([mystring])) # 预测值为"no"，也就是不相关

class_names = ["no", "yes"] # 不相关，相关

explainer = LimeTextExplainer(class_names=class_names) 

exp = explainer.explain_instance(mystring, c.predict_proba, num_features=6) 

exp.as_list()

这段代码展示了在预测中起到重要作用的六个特征，具体如下。

[('YORK', 0.23416984139912805), 

 ('NEW', -0.22724581340890154), 

 ('showing', -0.12532906927967377), 

 ('AP', -0.08486610147834726), 

 ('dropped', 0.07958281943957331), 

 ('trend', 0.06567603359316518)]

因此，上述代码的输出可以看作这六个特征的线性和。这意味着，如果去掉特征“NEW”

和“showing”，那么预测应该朝相反的类“relevant/Yes”移动 0.35（两个特征的权重之

和）。Lime 还提供预测的可视化函数。图 4-8 显示了上述解释的可视化。

108 ｜ 第 4 章

预测概率

0.08

0.07

图 4-8：Lime 对分类器预测的可视化解释

如图所示，YORK、trend 和 dropped 这三个词的存在使预测偏向 yes，而其他三个词使预

测偏向 no。除了前面提到的一些用途之外，分类器可视化还有助于我们做一些有根有据的

特征选择。

希望这个简短的介绍有助于你理解如何解释分类器的预测。

4.7　无数据或少数据学习和新领域适应

在前面的所有示例中，相关任务都有相对较大的训练数据集可用。然而，在大多数真实场

景中，这样的数据集并不容易获得。在另外一些情况下，数据集可能已经标注好，但数据

量不够大，不足以训练好的分类器。还可能有这样的情况：某个系列的产品有很多数据，

比如客户投诉和请求，但是另一个系列的产品只有很少的数据，因此需要调整现有的模型

来适应新的领域。本节将讨论如何为这些没有数据、有很少数据，或必须适应新领域训练

数据的场景构建良好的分类系统。

4.7.1　无训练数据

考虑这样一个任务：为电商公司设计顾客投诉分类器。分类器需要将顾客投诉邮件自动发

送到“账单”“发货”和“其他”三个类别中。如果幸运的话，公司内部可能已经有大量

的标注数据可用，其形式为客户请求及其类别的历史数据库。但是，如果这样的数据库不

存在，那么应该从何开始构建分类器呢？

在这种场景中，第一步是创建标注数据集，将顾客投诉映射到相应类别中。解决这个问题

的一种方法是让客服人员手动标注部分投诉，并将其作为机器学习模型的训练数据。另

一种方法是“自举”或“弱监督”。不同类别的客户请求可能存在不同的信息模式。账单

类的请求可能会提到“账单”之类的词语、货币金额等。发货类的请求可能会提到运输、

延迟等。不妨编译这些模式，并使用模式的存在与否来标注客户请求，从而为分类任务

创建小型标注数据集（可能带有噪声）。然后在此基础上构建一个分类器来标注更大的数

据集合。斯坦福大学最近开发的 Snorkel 软件工具可用于部署分类等各种任务的弱监督学

习。谷歌曾使用 Snorkel 部署了基于弱监督的工业级文本分类模型。这些模型表明，弱监

文本分类 ｜ 109

督分类器的质量堪比那些基于数万个手工标注样例训练出来的分类器。Snorkel 网站文章

“Snorkel Intro Tutorial: Data Labeling”展示了如何使用 Snorkel 基于大量未标注数据生成训

练数据并进行文本分类的示例。

在有些情况下，如果大规模收集数据是必要和可行的，那么可以选择众包进行数据标注。亚

马逊 Mechanical Turk 和 Figure Eight 等网站平台就是利用人类智能来创建机器学习任务的高

质量训练数据的。使用群体智慧创建分类数据集的一个常见例子是谷歌的“验证码测试”，

它要求用户回答一组图像是否包含给定物体（例如，“选择所有包含街道标志的图像”）。

4.7.2　少训练数据：主动学习和领域适应

在前面描述的场景中，使用人工标注或自举方法可以收集少量数据，但有时这些数据量太

小，无法构建较好的分类模型。另外，收集到的请求可能大部分属于“账单类”，只有很

少一部分属于其他类别，这会导致数据集高度不平衡。而且，要求客服人员花费大量时间

进行人工标注并不总是可行的。这种情况下该怎么办？

解决这类问题的一种方法是主动学习。主动学习主要是确定哪些数据点更重要，从而将其

用作训练数据。主动学习有助于回答以下问题：如果有 1000 个数据点，但只能标注 100

个，应该选择哪 100 个？这意味着，对于训练数据，并非所有的数据点都是平等的。在决

定分类器的训练质量方面，有些数据点比其他数据点更重要。主动学习将此转化为一个持

续的过程。

使用主动学习训练分类器的具体过程如下。

1. 使用现有的数据量训练分类器。

2. 开始使用分类器对新数据进行预测。

3. 如果分类器对预测结果非常不确定，则将数据点发送给人工标注员进行正确分类。

4. 将这些数据点加入现有的训练数据中，重新训练模型。

重复第 1~4 步，直到模型性能达到满意的效果。

Prodigy 等工具实现了文本分类的主动学习解决方案，并支持高效使用主动学习来快速创

建标注数据和文本分类模型。主动学习背后的基本思想是，模型不太确定的数据点对提高

模型质量贡献最大，因此只对这些数据点进行标注。

考虑这样一个场景：顾客投诉分类器使用了一系列产品的大量历史数据训练，现在需要对

其进行调优，使其能够适应新的产品系列。那么在这种情况下，潜在的挑战是什么？典型

的文本分类方法依赖于训练数据的词汇。因此，它们本质上会倾向于训练数据中出现的那

种语言。因此，如果新产品和原产品大不相同（例如，模型是基于电子产品训练的，而现

在将其用于处理化妆品投诉），那么使用其他数据训练的预训练分类器就不太可能有好的

效果。然而，为每个产品或每个系列的产品从头开始训练新的模型也是不现实的，因为仍

然会遇到训练数据不足的问题。领域自适应是解决此类情况的一种方法，这也叫迁移学

习。迁移学习就是把从源领域学习到的知识“迁移”到目标领域。源领域拥有大量数据，

目标领域拥有少量标注数据和大量未标注数据。本章前面已经介绍如何使用 BERT 进行文

本分类的示例。

110 ｜ 第 4 章

这种在文本分类中进行领域自适应的方法可以概括如下。

1. 在源领域的大型数据集（例如维基百科数据）上训练大型、预训练语言模型。

2. 使用目标语言的未标注数据来调优此模型。

3. 使用第 2 步的调优语言模型提取特征表示，进而在标注的目标领域数据上训练分类器。

另外，ULMFit 也是常见的文本分类领域自适应方法。研究实验表明，在文本分类任务中，

该方法在 100 个标注样本上的效果能匹敌在 10~20 倍数量的样本上从头开始训练的模型。

当使用未标注数据来微调预训练语言模型时，在同样的文本分类任务上，该方法能匹敌在

50~100 倍数量的样本上从头开始训练的模型。目前，迁移学习方法仍然是自然语言处理研

究的一个活跃领域。迁移学习用于文本分类，目前还没有在标准数据集上显示出显著的改

进，而且迁移学习也不是业内文本分类场景的默认解决方案。但可以预期的是，这种方法

在不久的将来会产生越来越好的效果。

到目前为止，本章介绍了一系列的文本分类方法，并讨论了如何获取合适的训练数据，以

及使用不同的特征表示来训练分类器。此外，本章还简要介绍了如何解释文本分类模型给

出的预测结果。下面使用一个小案例研究来巩固目前所学的知识：构建真实场景的文本分

类器。

4.8　案例研究：企业工单系统

下面考虑一个真实的场景，并借此来学习如何应用本章中讨论的一些概念。假设现在需要

构建一个企业工单系统，来跟踪组织中人们面临的所有工单或问题，并将它们发送给内部

或外部代理。图 4-9 显示了 Spoke 企业工单系统的截图。

图 4-9：企业工单系统

文本分类 ｜ 111

现在假设公司最近聘请了一位医疗顾问，并与一家医院合作。因此，我们的系统还应该能

够准确地指出任何与医疗相关的问题，并将其发送给相关的人员和团队。但是，虽然过去

有一些工单，但都没有标注为与“健康”相关。在没有标注的情况下，如何构建健康问题

分类系统？

先来探讨以下几个选项。

使用现成的 API 或库

一种选择是使用公开 API 或库，并将类别映射到相关内容上。例如，本章前面提到的

谷歌 API 可以将内容分为 700 多个类别，其中有 82 个类别与医疗或健康问题相关。这

些类别包括“/ 健康 / 健康状况 / 疼痛管理”“/ 健康 / 医疗设施和服务 / 医生办公室”

“/ 金融 / 保险 / 健康保险”等。

虽然并非所有类别都是相关的，但是有些类别可能是相关的，需要相应地映射这些类

别。例如，如果认为药物滥用和肥胖问题与医疗咨询无关，就可以忽略 API 中的“/ 健

康 / 药物滥用”和“/ 健康 / 健康状况 / 肥胖”。同样，保险是属于人力资源的一部分，

还是属于其他部门，也可以根据这些类别来处理。

使用公开数据集

也可以根据需要采用公开数据集。可以使用公开数据集来训练一个基本分类器。

使用弱监督

如果过去的工单记录是未标注的，那么可以考虑使用本节前面描述的方法，从未标注工

单中自举出一个数据集。例如，考虑规则：“如果过去的工单包含发烧、腹泻、头痛或

恶心之类的词，则将它们归入医疗顾问类别。”这条规则可以创建少量数据，作为分类

器的起点。

主动学习

可以使用 Prodigy 等工具进行数据收集实验：让客服人员查看工单描述，并用预先设置

的类别对其进行标注。图 4-10 显示了使用 Prodigy 实现此目的的例子。

从隐式反馈和显式反馈中学习

在构建、迭代和部署解决方案的整个过程中，可以使用反馈来改进系统。显式反馈可以

是医疗顾问或医院明确表示“工单不相关”的反馈。隐式反馈可以从工单响应时间、工

单响应率等其他因变量中提取。考虑所有这些因素，并使用主动学习技术来改进模型。

上述流水线如图 4-11 所示。首先从无标注数据开始，使用公开 API、公开数据集或弱监督

创建第一个基线模型。模型上线后，就会得到成功或失败的显式和隐式信息。使用这些信

息来改善模型，并使用主动学习来选择需要标注的最佳实例集。随着时间的推移，收集的

数据越来越多，这时可以构建更复杂和更深层的模型。

112 ｜ 第 4 章

文本分类 ｜ 113

当前

进度

标注

项目详情

一次关注

一个任务

最近的

标注 接受、拒绝

或忽略标注

撤销

图 4-10：使用 Prodigy 主动学习

无标注数据

阶段1：

初始数据收集

和建模

阶段2：

持续迭代，

改进模型

映射公开

API或库

映射公开

数据集

构建模型

分析和迭代

收集显式数据

和隐式数据 主动学习

使用弱监督

创建初始

数据集

图 4-11：在没有训练数据的情况下构建分类器的流水线

本节介绍了一个实际的场景：在没有足够训练数据的情况下构建自己的文本分类器，并讨

论了解决这个问题的几种可能办法。希望这有助于你将来在文本分类项目中进行数据收集

和创建。

4.9　实用建议

到目前为止，本章已经介绍了一系列构建文本分类器的不同方法，以及可能遇到的潜在问

题。最后，本章会根据在行业中构建文本分类系统的观察和经验，给出一些实用的建议，

其中大部分建议是通用的，可以应用到本书中的其他主题。

构建强大的基线

直接使用最先进的算法，这是常见的错误观点，在当前的深度学习时代尤其如此，因为

每天都有新的方法 / 算法在不断涌现。但是，使用简单的方法先构建强大的基线总是好

的。这主要有以下三个原因。

1. 有助于更好地理解问题陈述和关键挑战。

2. 快速构建 MVP 有助于从最终用户和利益相关者那里获得初步反馈。

3. 与基线相比，最先进的研究模型可能只会带来很小的改进，但它可能会带来大量的

技术债务。

平衡训练数据

在分类任务中，有一个平衡的数据集（各个类别的比例大致相当）是非常重要的。不平

衡的数据集会对算法的学习产生不利的影响，并导致分类器产生偏见。虽然训练数据的

平衡性并不总是能够控制，但是有各种技术可以处理训练数据中的类别不平衡。例如，

收集更多的数据、重新采样（多数类的欠采样和少数类的过采样）以及权重平衡等。

将模型和人类结合起来

在实际场景中，可以将多个分类模型的输出与各个领域的专家编写的规则相结合，以实

现业务的最佳性能。另外，如果机器对其分类不确定，那么可以将分类稍后交给人类评

估员来决定。最后，还可能出现这样的情况：学习的模型必须随着时间和数据更新而改

变。第 11 章将讨论这类场景的解决方案。

先运行起来，然后再提高

构建分类系统不仅仅是构建模型。在大多数工业场景中，构建模型通常只占整个项目的

5%~10%。剩下的工作包括收集数据、构建数据流水线、部署、测试、监控等。快速构

建模型，用它来构建系统，然后开始改进迭代，这总是好的，而且有助于快速找到主要

障碍和工作量最大的部分（通常不是建模）。

运用众人的智慧

每种文本分类算法都有自己的优点和缺点。没有一种算法可以适用于所有的情况。解决

这个问题的一个方法是训练多个分类器进行集成。数据进入各个分类器，生成的各个预

测经过汇总（例如多数投票法）后，得到最终的类别预测。

114 ｜ 第 4 章

4.10　小结

本章从多个角度探讨了如何解决文本分类的问题。具体而言，本章讨论了如何识别分类问

题，处理文本分类流水线中的各个阶段，收集数据创建相关数据集，使用不同的特征表

示，以及训练多种分类算法。有了这些基础知识，希望读者能够根据自己的使用情况和场

景解决文本分类问题，并知道如何使用现有的解决方案，如何使用各种方法构建自己的分

类器，包括解决这个过程中可能遇到的困难。本章只关注在行业应用中构建文本分类系统

的一个方面：构建模型。自然语言处理系统的端到端部署将在第 11 章中讨论。第 5 章将

使用这里学到的一些思想来处理另外一个相关的自然语言处理问题：信息提取。

文本分类 ｜ 115

第 5 章

信息提取

名称有什么关系呢？玫瑰即使不叫玫瑰，依然芳香如故。

——威廉 • 莎士比亚

我们每天都会接触大量的文本内容，包括手机短信、日常邮件、休闲或工作读物、时事新

闻等。这些文本文档对我们来说是丰富的信息来源。根据语境的不同，“信息”可以指关

键事件、人物、人物关系、地点或组织等多种事物。信息提取（IE）是指从文本文档中提

取相关信息的自然语言处理任务。信息提取在实际应用中的一个例子是，采用谷歌搜索引

擎搜索名人时，搜索框右侧所展示的人物简介。

与结构化信息源（如数据库或数据表）和半结构化信息源（如包含标记的网页）相比，文

本是一种非结构化的数据。例如，在数据库中，可以根据结构查找信息。然而，文本文档

在很大程度上通常是自由流动的文本，没有固定的结构。这使得信息提取成为一个具有挑

战性的问题。文本中可能包含各种各样的信息。然而，即使文本本身属于非结构化数据，

在大多数情况下，直接使用正则表达式等基于模式的提取技术仍然可以提取地址、电话号

码、日期等具有固定模式的信息。但是，提取人名、实体关系、日历事件等其他信息可能

需要更高级的语言处理。

本章将讨论各种信息提取任务以及在具体应用程序中实现信息提取的方法。本章将首先简

要介绍信息提取的历史背景，然后概述各种不同的信息提取任务以及信息提取在真实世界

中的应用。随后，本章将介绍用于解决任何信息提取任务的典型流水线，并讨论如何解决

关键词提取、命名实体识别、命名实体消歧和链接以及关系提取等特定的信息提取任务，

以及在项目中实现这些任务的一些实用建议。最后，本章将介绍如何在真实场景中使用信

息提取的案例研究，并简要介绍其他高级信息提取任务。好了，下面来探讨信息提取。先

从简单的历史回顾开始。

116

尽管研究界早就提出了从科学论文、医学报告等文档中提取不同信息的方法，但是“信息

理解会议”（1987~1998 年）可以被认为是现代文本信息提取研究的起点。后来，美国国家

标准与技术研究院（NIST）组织的“自动内容提取计划”（1999~2008 年）和“文本分析

会议”（2009~2018 年）引入了文本信息提取竞赛，包括识别不同实体的名称和构建可查

询的大型知识库等。无论是现有的文本信息提取库和方法，还是它们在实应用程序中的使

用，都可以追溯到这些会议中开始的研究。在介绍信息提取方法和库之前，先来看实际应

用程序中使用信息提取的例子。

5.1　信息提取应用程序

信息提取在新闻文章、社交媒体、收条收据等真实应用程序中有着广泛的应用。下面仅详

细讨论其中的部分应用程序。

新闻或其他内容标记

世界各地每天都在发生各种各样的事件，产生的文本更是层出不穷。除了使用第 4 章讨

论的方法对文本进行分类外，还可以把文本中提到的重要实体标记出来，这对于搜索引

擎、推荐系统等应用程序是有用的。

聊天机器人

为了生成或检索正确的响应，聊天机器人需要理解用户的问题。例如，考虑这样一个问

题：“埃菲尔铁塔周围最好的咖啡馆是哪些？”聊天机器人需要理解“埃菲尔铁塔”和

“咖啡馆”是位置，然后才能确定埃菲尔铁塔周围一定距离内的咖啡馆。信息提取常常

用于在现有数据池中提取这些特定的信息。第 6 章将详细讨论聊天机器人。

社交媒体应用

很多信息是通过 Twitter 等社交媒体渠道传播的。从社交媒体文本中提取信息摘要，例

如，根据推文提取交通更新、救灾工作等时效性强和频繁更新的信息，可能有助于正确

决策。“Twitter 自然语言处理”是最有用的应用程序之一，它利用了社交媒体中存在的

丰富信息。第 8 章将讨论社交媒体应用程序。

提取表单和收据数据

如今，很多银行应用程序提供了扫描支票并将钱直接存入账户的功能。无论是个人、小

型企业还是大型企业，使用应用程序扫描账单和收据的情况并不少见。信息提取技术和

光学字符识别（OCR）一起，在这些应用程序中扮演着重要角色。虽然 OCR 是这类应

用程序的主要步骤，但它不属于本书的处理流水线，因此本章不会讨论这一方面。

上面简要介绍了信息提取的概念及其应用。接下来继续介绍信息提取具体包括哪些任务。

5.2　信息提取任务

“信息提取”包括了一系列复杂程度不同的任务。信息提取的宗旨是提取文本中的“知

识”，不同的信息提取任务通过使用不同的信息来提取知识。要理解这些任务是什么，请

考虑图 5-1 所示的《纽约时报》文章片段。

信息提取 ｜ 117

图 5-1：2019 年 4 月 30 日《纽约时报》文章片段

作为人类读者，我们在这篇文章中发现了几条有用的信息。例如，这篇文章是关于 Apple

公司（而不是水果）的，而且它提到了公司的财务总监卢卡 • 梅斯特里（Luca Maestri）。

另外，这篇文章是关于股票回购以及其他相关问题的。对于一台机器来说，要理解这些内

容，就需要不同层次的信息提取。

判断文章是关于“回购”或“股价”的，属于关键词提取（KPE）任务。判断 Apple 是一

个组织，以及卢卡 • 梅斯特里是一个人，属于命名实体识别（NER）任务。判断 Apple 不

是水果，而是一家公司，而且指的是 Apple 公司，而不是名称中有“Apple”一词的其他

公司，属于命名实体消歧和链接任务。提取“卢卡 • 梅斯特里是 Apple 财务总监”的信息，

属于关系提取任务。

除此之外，还有一些高级的信息提取任务。例如，识别出文章中的某个事件（例如 Apple

公司回购股票事件），并链接到后续谈论同一事件的其他文章，这种信息提取任务叫事件

提取。与此相关的一个任务是时间信息提取，其目的是提取时间和日期信息，用于开发日

历应用程序和交互式个人助理。最后，许多应用程序，如自动生成天气报告或航班公告，

都遵循一个标准模板，其中的空白位置需要使用提取的数据进行填充，这种信息提取任务

叫模板填充。

以上的每一项任务都需要不同层次的自然语言处理。基于规则的方法以及监督、无监督和

半监督的机器学习方法（包括先进的深度学习方法）都可以用于开发这些任务的解决方

案。然而，考虑到信息提取在很大程度上依赖于应用领域（例如金融、新闻、航空等），

业界的信息提取通常会综合使用基于规则的方法和基于学习的方法。目前，信息提取仍然

是一个非常活跃的研究领域，并非所有这些任务都有解决方案，也并非所有任务都拥有可

用于真实场景的标准方法。虽然关键词提取、命名实体识别等任务得到了广泛的研究，并

且有一些经过实践检验的解决方案，但其他的任务相对来说更具挑战性，通常需要使用微

118 ｜ 第 5 章

信息提取 ｜ 119

软、谷歌和 IBM 等大厂提供的按量付费服务。

关于信息提取，需要注意的一个重要问题是，训练信息提取模型所需的数据集通常更加专

业化，这不像在第 4 章中，所需的数据集只是映射到某些类别的文本集合。因此，在真实

用例中，可能并不总是需要从头开始训练信息提取模型。对于某些任务，完全可以使用外

部 API。在继续讨论具体任务之前，下面先来看信息提取任务的通用流水线。

5.3　信息提取的通用流水线

与第 4 章的文本分类相比，信息提取的通用流水线需要更细粒度的自然语言处理。例如，

如果要识别人名、组织名等命名实体，就需要知道词性。如果要将多个指称关联到同一个

实体（例如，“阿尔伯特 • 爱因斯坦”“爱因斯坦”“科学家”“他”等），就需要共指消解。

注意，这些都不是构建文本分类系统的必要步骤。因此，信息提取是一项比文本分类更需

要自然语言处理的任务。图 5-2 显示了信息提取任务的典型流水线。不过，不是每一项信

息提取任务都要用到流水线中的所有步骤，不同的信息提取任务需要不同层次的分析，如

图 5-2 所示。

原始文本

句子分割

分词

词性标注

命名实体识别

句法解析

共指消解

关系提取

事件提取

实体消歧

关键词提取

图 5-2：信息提取流水线（部分信息提取任务所需的自然语言处理）

这些步骤的详细讨论见第 1 章和第 2 章。如图 5-2 所示，关键词提取是需要自然语言处理

最少的任务（不过有些算法在提取关键词之前仍然会进行词性标注），而除了命名实体识

别之外，所有其他的信息提取任务都需要更深入的自然语言处理预处理，然后才能针对这

些特定任务开发相关模型。信息提取任务通常使用标准评估集，根据精确率、召回率和 F1

分数进行评估。由于不同的信息提取任务需要不同层次的自然语言处理预处理，因此这些

预处理步骤的准确率会影响信息提取任务的效果。如果需要收集相关的训练数据，训练自

己的信息提取模型，那么就应该考虑这些方面。有了这样的背景介绍，现在开始逐一讲解

每项信息提取任务。

5.4　关键词提取

考虑这样一个场景：在亚马逊网站上购物，但商品评论有上百条。我们不可能阅读所有的

评论来了解其他用户的看法。为了方便这一点，亚马逊网站提供了一项根据关键词进行评

论筛选的功能。该功能会呈现用户评论中出现的高频关键词，从而对评论进行筛选，如图

5-3 所示。这个例子很好地说明了关键词提取在日常应用程序中的用处。

关键词提取，顾名思义，是从给定文本文档中提取那些体现了文本要旨的重要词语的信息

提取任务。关键词提取适用于搜索 / 信息检索、自动文档标注、推荐系统、文本摘要等下

游自然语言处理任务。

图 5-3：亚马逊网站的“筛选评论依据”

关键词提取是自然语言处理界研究得较多的问题，解决这个问题最常用的两种方法是监督

学习和无监督学习。监督学习方法需要提供语料库（包含文本和对应的关键词），并使用

特征工程或深度学习技术。对于关键词提取任务，创建这样的标注数据集是一项费时费力

的工作。因此，不需要标注数据集并且与领域基本无关的无监督方法往往更受欢迎，而且

无监督方法在实际应用程序中也更为常用。最近的研究也表明，对于关键词提取，先进的

深度学习方法并不比无监督学习方法性能更好。

所有常见的无监督关键词提取算法都是基于这样的思想：首先，将文本中的词和短语表示

为加权图中的节点，其中的权重表示关键词的重要性。然后，根据关键词与图中其他节点

的连接程度来识别关键词。最后，将图中前 n 个重要节点作为关键词返回。重要节点是指

那些足够频繁，且与文本其他部分有较强联系的词和短语。但是，对于基于图的关键词提

取，不同方法之间的差别在于如何从文本中（从整个文本中一大堆可能的词和短语中）选

择潜在的词 / 短语，以及如何为图中的词 / 短语打分。

120 ｜ 第 5 章

关键词提取这一主题已经取得了大量的成果和部分可行的实现。在大多数情况下，现成的

方法足以满足需求。那么如何在项目中使用这些方法来实现关键词提取器呢？下面来看一

个例子。

5.4.1　实现关键词提取

Python 库 textacy（基于著名的 spaCy 库）实现了部分常见的基于图的关键词提取算法。本

节中演示了如何使用 textacy 库中的 TextRank 和 SGRank 两种算法来提取关键词。使用

的测试文档是一个介绍自然语言处理历史的文本文件。下面的代码片段显示了如何使用

textacy 库来提取关键词。

from textacy import * 

import textacy.ke 

mytext = open("nlphistory.txt").read() 

en = textacy.load_spacy_lang("en_core_web_sm", disable=("parser",)) 

doc = textacy.make_spacy_doc(mytext, lang=en) 

print("Textrank output: ", [kps for kps, weights in textacy.ke.textrank(doc, 

normalize="lemma", topn=5)]) 

print("SGRank output: ", [kps for kps, weights in textacy.ke.sgrank(mydoc, 

n_keyterms=5)])

输出如下：

Textrank output: ['successful natural language processing system', 

'statistical machine translation system', 'natural language system', 

'statistical natural language processing', 'natural language task'] 

SGRank output: ['natural language processing system', 

'statistical machine translation', 'research', 'late 1980', 'early']

这里有很多选项需要选择：短语中 n-gram 应该有多长；是否考虑词性标注；应该事先进行

哪些预处理；如何消除重叠的 n-gram，如以上例子中的“statistical machine translation”和

“machine translation”；等等。

上面仅展示了一个用 textacy 库实现关键词提取的例子。不过除此之外，还有其他选择。例

如，Python 库 gensim 提供了一个基于 TextRank 的关键词提取器。因此不妨多考察几个库，

对比之后再选择。

5.4.2　实用建议

前面已经介绍了如何使用 spaCy 和 textacy 来实现关键词提取，以及如何修改选项来满足我

们的需要。但是，从实际的角度来看，在生产中使用基于图的算法时，有几个注意事项需

要牢记。下面列出其中的一些注意事项，同时给出如何在软件产品中添加关键词提取功能

的一些建议。

信息提取 ｜ 121

• 提取潜在的 n-gram 并用 n-gram 构建图的过程对文档长度很敏感，这在生产场景中可能

是一个问题。处理这一问题的一个方法是不使用全文，而是尝试使用文本的前 M% 和

后 N%，这是因为文本的介绍性部分和结论性部分通常包括了文本的主要信息。

• 由于每个关键词是独立排序的，因此有时会看到重叠的关键词（例如，“buy back stock”

和“buy back”）。解决这个问题的一种方法是在排名靠前的关键词之间使用相似性（例

如余弦相似性）进行度量，并选择彼此最不相似的关键词。textacy 已经实现了解决这

个问题的函数。

• 另一个常见的问题是碰到反常的模式（例如，以介词开头的关键词）。这个问题处理起

来比较简单，方法是调整算法的实现代码并显式地编码这些不需要的词的模式。

• 不当的文本提取也会影响关键词提取，特别是在处理 PDF 或扫描图像等格式的文本时。

这主要是因为关键词提取对文档中的句子结构很敏感。因此，最好对提取的关键词列表

做进一步的处理，以创建有意义和无噪声的最终列表。

现有的基于图的关键词提取算法如果解决了上述问题，再加上特定于领域的启发式列表，

就能形成自定义的解决方案。根据经验，这足以应对典型自然语言处理项目中关键词提取

最常遇到的问题。

本节介绍了如何使用关键词提取算法从文档中提取重要的词和短语，以及如何克服潜在的

挑战。虽然关键词可以捕获文本中重要实体的名称，但是关键词提取算法并非专门用于寻

找命名实体。现在来看下一个信息提取任务：命名实体识别。命名实体识别也许是最常见

的信息提取任务，它专门用来查找文本中存在的命名实体。

5.5　命名实体识别

考虑这样一个场景——使用谷歌搜索“Where was Albert Einstein born?（阿尔伯特 • 爱因斯

坦出生在哪里？）”。

为了能够显示“Ulm, Germany”（德国，乌尔姆）这个查询结果，搜索引擎首先需要识别

出阿尔伯特 • 爱因斯坦是一个人，然后再去查找他的出生地。这是命名实体识别在实际应

用程序中的一个例子。

命名实体识别是指识别文档中实体的信息提取任务。实体通常是人名、地名、组织名，以

及货币表达式、日期、产品、法律或文章名称 / 编号等特殊字符串。在涉及信息提取的一

些自然语言处理应用程序中，命名实体识别是一个重要的步骤。

对于给定的文本，命名实体识别的作用是识别其中的人名、地名、日期和其他实体。这里

识别出的不同实体类别是命名实体识别系统开发中常用的实体类别。命名实体识别是执行

关系提取、事件提取等其他信息提取任务的先决条件，这些任务在本章前面介绍过，稍后

将详细讨论。另外，命名实体识别在机器翻译等其他应用程序中也很有用，因为在翻译句

子时通常不需要翻译人名。因此，很明显，在很多自然语言处理项目中，命名实体识别是

重要的组成部分。而且，命名实体识别也是行业自然语言处理项目中可能遇到的常见任务

之一。下面将重点讨论如何构建命名实体识别系统，具体分三种情况：构建命名实体识别

系统、使用现有的库，以及使用主动学习。

122 ｜ 第 5 章

5.5.1　构建命名实体识别系统

构建命名实体识别系统的一个简单方法是维护一个最相关的人 / 组织 / 地点名称集合，例

如，所有客户的名称及其地址中的城市等，这通常叫名称词典（gazetteer）。要查看给定的

词是否是命名实体，只需在名称词典中进行查找即可。如果名称词典能覆盖数据中的大量

实体，那么不妨从名称词典开始，特别是在没有现成的命名实体识别系统可用时。但是这

种方法有几个问题需要考虑：如何处理新名称？如何定期更新数据库？如何跟踪别名，即

给定名称的不同变体，如美国、美利坚合众国等？

超越查找表的一种方法是基于规则的命名实体识别，这些规则可以是编译好的基于词元和

词性标记的模式串列表。例如，在模式串“NNP was born”中，“NNP”表示专有名词的

词性标记，如果一个词被标记为“NNP”，则它指的是人。通过编写这样的规则并涵盖尽

可能多的情况，就可以构建基于规则的命名实体识别系统。Stanford NLP 的 RegexNER 和

spaCy 的 EntityRuler 都提供了相应的功能来实现基于规则的命名实体识别系统。

更实用的方法是训练机器学习模型来预测新文本中的命名实体。对于每一个词，模型都必

须决定该词是否是一个实体，如果是，实体的类型是什么。这在许多方面都与第 4 章中讨

论的分类问题非常相似。唯一的区别是，命名实体识别属于“序列标注”问题。第 4 章中

介绍的标准分类器对文本标签的预测不依赖于上下文。例如在影评情感分类器中，分类器

对当前句子的分类通常不会考虑前面或后面句子的情感。但是在序列分类器中，这样的上

下文非常重要。序列标注的一个常见用例是词性标注。词性标注需要周围词的词性信息来

估计当前词的词性。命名实体识别建模在传统上属于序列分类问题，它对当前词是否为实

体的预测依赖于上下文。例如，在前一个词是人名的情况下，如果当前词是名词，那么当

前词也是人名（例如，名字和姓氏）的可能性更高。

为了说明普通分类器和序列分类器之间的区别，考虑这样一个句子：“华盛顿是一个多雨

的州”。普通分类器在看到这句话的时候只能逐词分类，直接决定华盛顿指的是乔治 • 华

盛顿还是华盛顿州，而不看前后的词。但是在这个句子中，只有查看了华盛顿所处的上下

文，才有可能将华盛顿一词分类为一个地点。正因为如此，命名实体识别模型需要使用序

列分类器进行训练。

条件随机场（CRF）是目前常见的一种序列分类器训练算法。本节展示了如何使用 CRF

来训练命名实体识别系统。这里使用 CONLL-03（训练命名实体识别系统的常用数据集）、

sklearn-crfsuite（开源序列标注库）以及基于词和词性标注的一组简单特征（提供任务所需

的上下文信息）。

为了执行序列分类，需要进行一定的数据格式转换，以便对上下文进行建模。训练命名实

体识别的典型数据格式如图 5-4 所示，示例句子选自 CONLL-03 数据集。

图 5-4 中的标签采用 BIO 表示法：B 表示实体的开始；I 表示处于实体内部，意味着该实

体包含多个词；O 表示非实体。在图 5-4 所示的例子中，“Peter Such”这个人名由两个词

组成。因此，“Peter”的标签是 B-PER，而“Such”的标签是 I-PER，以表示两者属于同一

个实体。Essex、Yorkshire 和 Headingley 等其他实体都由一个词组成。因此，它们的标签

只有 B-ORG 和 B-LOC。假如获得的句子数据集是以这种形式标注的，并且也有了序列分

类器算法，那么应该如何训练命名实体识别系统？

信息提取 ｜ 123

图 5-4：命名实体识别训练数据格式示例

步骤与第 4 章的文本分类器相同：

1. 加载数据集；

2. 提取特征；

3. 训练分类器；

4. 在测试集上评估。

加载数据集很简单。上述数据集已经分割成训练集、开发集和测试集。因此，这里直接使

用训练集来训练模型。前面第 3 章已经介绍了一系列的特征表示技术。这次来看一个使用

人工特征的例子。根据直觉，哪些特征与这项任务相关？为了识别人名或地名，不妨先使

124 ｜ 第 5 章

用这些模式来训练命名实体识别模型：单词是否以大写字母开头，前面或后面是否有动词

或名词，等等。下面的代码片段显示了如何用函数提取给定句子中每个词的前一个词和后

一个词的词性标注。

def sent2feats(sentence): 

 feats = [] 

 sen_tags = pos_tag(sentence) 

 for i in range(0,len(sentence)): 

 word = sentence[i] 

 wordfeats = {} 

 # 词性标注特征：当前标注、之前2个和之后2个标注

 wordfeats['tag'] = sen_tags[i][1] 

 if i == 0: 

 wordfeats["prevTag"] = "<S>" 

 elif i == 1: 

 wordfeats["prevTag"] = sen_tags[0][1] 

 else: 

 wordfeats["prevTag"] = sen_tags[i - 1][1] 

 if i == len(sentence) - 2: 

 wordfeats["nextTag"] = sen_tags[i + 1][1] 

 elif i == len(sentence) - 1: 

 wordfeats["nextTag"] = "</S>" 

 else: 

 wordfeats["nextTag"] = sen_tags[i + 1][1] 

 feats.append(wordfeats) 

 return feats

从上述代码中的 wordfeats 变量可以看出，每个词都转换成了一个特征字典，因此每个句

子看起来就像一个字典列表（即代码中的 feats 变量），该字典列表将用于 CRF 分类器。

下面的代码片段显示了一个函数，其作用是使用 CRF 模型来训练命名实体识别系统，并使

用开发集来评估模型性能。

# 训练序列模型

def train_seq(X_train,Y_train,X_dev,Y_dev): 

 crf = CRF(algorithm='lbfgs', c1=0.1, c2=10, max_iterations=50) 

 crf.fit(X_train, Y_train) 

 labels = list(crf.classes_) 

 y_pred = crf.predict(X_dev) 

 sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0])) 

 print(metrics.flat_f1_score(Y_dev,y_pred,average='weighted', 

 labels=labels))

训练好的 CRF 模型在开发数据上获得了 0.92 的 F1 分数，非常不错！这里使用的是主流

训练方法和开源数据集，并且只展示了训练命名实体识别系统时最常用的一些特征。很明

显，在调优模型和开发更好的特征方面还有很多工作要做。这个示例仅用来说明在拥有相

关数据集和特定库的情况下如何快速开发命名实体识别模型。另外，训练命名实体识别系

统还可以使用 MITIE 库。

命名实体识别研究的最新进展大都使用神经网络模型来排除或增强这个例子中所做的特征

工程。NCRF++ 库提供了不同的神经网络结构来训练自己的命名实体识别。

信息提取 ｜ 125

前面快速介绍了如何训练自己的命名实体识别系统。然而，在实际场景中，数据在不断变

化，新实体在不断增加，而且还会出现一些特定于领域的实体或模式，仅仅使用训练好的

模型是不够的。因此，在真实场景中部署的命名实体识别系统大都会将机器学习模型、名

称词典和基于模式匹配的启发式结合起来提高性能。“MITIE: MIT Information Extraction”

展示了 Rasa（一家构建智能聊天机器人的公司）如何利用查找表来改进实体提取的例子。

显然，要构建自己的命名实体识别系统，需要如图 5-4 所示格式的大型标注数据集。虽然

可以使用 CONLL-03 这样的开源数据集，但它们只能在有限的领域中处理有限的实体集

（人、组织、地点等）。虽然 OntoNotes 等数据集要大得多，并且能覆盖不同种类的文本，

但它们都不是免费的，通常需要根据昂贵的许可协议购买。如果组织预算不支持，那么应

该怎么办？

5.5.2　命名实体识别：使用现有库

这些关于训练命名实体识别系统的讨论，虽然可能会使构建和部署命名实体识别系统看起

来像一个漫长的过程（从获取数据集开始），但所幸在过去的几十年中，命名实体识别已

经得到了很好的研究，有很多现成的库可以直接使用。Stanford NER、spaCy 和 AllenNLP

等著名的自然语言处理库，可以用于将预先训练的命名实体识别模型整合到软件产品中。

下面的代码片段演示了 spaCy 命名实体识别的使用。

import spacy 

nlp = spacy.load("en_core_web_lg") 

text_from_fig = "On Tuesday, Apple announced its plans for another major chunk 

 of the money: It will buy back a further $



75 billion in stock." 

doc

= nlp(text_from_fig) 

for ent in

doc.ents: 

 if ent.text:

print(ent.text, "\t", ent.label_)

运行这个代码片段将显

示 Tuesday 为日期，Apple

为组织，



$75 billion 为货币。考虑到

spaCy 的命名实体识别使用了先进的神经网络模型，并结合了一定的模式匹配和启发式学

习，这是一个很好的起点。然而，我们可能会遇到以下两个问题。

1. 如前所述，如果在特定的领域使用命名实体识别，那么预先训练的模型可能无法捕捉到

该领域的特性。

2. 有时，我们可能希望向命名实体识别系统添加新的类别，但又不必为所有常见的类别收

集大量的数据。

在这种情况下应该怎么做？

5.5.3　命名实体识别：使用主动学习

根据经验，如果想要定制解决方案但又不想从头开始训练，那么构建命名实体识别的最佳

方法是对现有的产品进行增强。可以使用 RegexNER 或 EntityRuler 等工具，针对特定领域

定制启发式学习，也可以使用 Prodigy 等工具来实施主动学习（如第 4 章文本分类中所介

绍的）。这就允许通过手动标注少量的句子样例（包含新的命名实体识别类别）来改进现

126 ｜ 第 5 章

有的预训练命名实体识别模型，或者手动修正少量的模型预测并重新训练模型。

大多数情况下，通常不需要考虑从头开发命名实体识别系统。但如果确实需要，那么要

做的第一件事就是获得大型标注数据集，其中每个词都标注了类别（实体类型等）。一旦

有了这样的数据集，下一步就是用它来获得人工特征表示和 / 或神经特征表示，并将其

馈送到序列标注模型。但是如果没有这样的数据集，那么就要从基于规则的命名实体识

别开始。

首先构建预训练命名实体识别模型，然后再用启发式或主动学习或结合两者

来增强模型。

5.5.4　实用建议

前面快速介绍了如何增强现有的命名实体识别系统，并讨论了如何从头开始训练自己的命

名实体识别系统。尽管先进的命名实体识别具有很高的准确率（在标准的命名实体识别评

估框架下，F1 分数超过 0.90），但是在自己的软件应用程序中使用命名实体识别时，仍有

几个问题需要牢记。根据我们开发命名实体识别系统的经验，以下几点需要注意。

• 命名实体识别对输入数据的格式非常敏感。使用格式良好的纯文本比使用 PDF 文档更

准确。这是因为处理 PDF 文档，首先需要从中提取出纯文本。虽然在特定领域或使用

推文数据也可以构建自定义的命名实体识别系统，但 PDF 的挑战在于无法在保留结构

的同时，百分之百准确地从中提取文本。那么，为什么需要准确地从 PDF 中提取结构呢？

这是因为 PDF 中有很多不完整的句子、标题和格式，它们都可能影响命名实体识别的

准确性。目前对此还没有万能的解决方案。常用的办法是对 PDF 进行自定义的后期处理，

待提取出文本块后，再运行命名实体识别。

如果面对的是报表之类的文档，则需要先进行预处理，待提取文本块后，再

对其运行命名实体识别。

• 命名实体识别还对流水线中句子切分、分词、词性标注（见图 5-2）等前序步骤的准确

性非常敏感。例如，句子切分不当可能会导致命名实体识别效果变差。因此，在将文本

送入命名实体识别模型提取实体之前，一定的预处理可能是必要的。

尽管存在这些缺点，命名实体识别在内容标注、搜索和社交媒体挖掘等许多信息提取场景

中还是非常有用的。虽然命名实体识别（和关键词提取）可以用于识别文档中重要的词、

短语和实体，但是有些自然语言处理应用程序需要对语言做进一步分析，这就引出了更高

级的自然语言处理任务：实体消歧或实体链接，也就是下一节的主题。

信息提取 ｜ 127

5.6　命名实体消歧与链接

考虑这样一个场景：一家大型报业公司（比如《纽约时报》）的数据科学团队需要构建一

个新闻故事的可视化表示系统，如图 5-5 所示，该系统能将新闻故事中提到的不同实体与

它们在现实世界中所指的内容链接起来。

图 5-5：IBM 实体链接（参见 IBM Research Editorial Staff 的文章“Making sense of language. Any 

language”）

要做到这一点，除了前面介绍的命名实体识别和关键词提取，还需要掌握其他一些信息提

取任务的知识。首先，需要知道这些实体或关键词在现实世界中实际上指的是什么。为什

么这很难？举一个例子，考虑这句话，“Lincoln drives a Lincoln Aviator and lives on Lincoln 

Way（林肯开的是林肯飞行家，住在林肯路）”。这里提到的三个“Lincoln”分别指的是不

同的实体，而且是不同类型的实体——第一个是人，第二个是交通工具，第三个是地点。

那么如何才能像图 5-5 那样，正确地将三个 Lincoln 链接到相应的维基百科页面？

命名实体消歧（NED）是指这样一项自然语言处理任务：为文本中提到的实体分配一个唯

一的标识。通过识别实体之间的关系，命名实体消歧也是解决上述场景复杂任务的第一步。

命名实体识别和命名实体消歧一起叫命名实体链接（NEL）。需要命名实体链接的自然语言

处理应用程序还包括问题回答和大型知识库（关联事件和实体），例如谷歌知识图谱。

那么，执行命名实体链接的信息提取系统应该如何构建呢？正如命名实体识别使用语境信

息来识别实体及其跨度一样，命名实体链接也依赖于语境。然而，就所需的预处理而言，

命名实体链接的要求已经超越了词性标注。至少，命名实体链接需要某种形式的解析来识

别诸如主语、动词和宾语之类的语言项。此外，命名实体链接还可能需要共指解析，以解

析同一实体的多个指称（如“阿尔伯特 • 爱因斯坦”“科学家”“爱因斯坦”等）并将其链

接到大型百科全书知识库（如维基百科）中的同一指称。这通常被建模为有监督的机器学

128 ｜ 第 5 章

习问题，并根据标准测试集的精确率、召回率和 F1 分数进行评估。

先进的命名实体链接使用了一系列不同的神经网络结构。显然，学习命名实体链接模型需

要大型标注数据集以及百科全书链接资源。此外，与前面看到的文本表示、文本分类、命

名实体识别、关键词提取任务相比，命名实体链接是更加专业的自然语言处理任务。根据

经验，常见的做法是使用 IBM（沃森）和微软（Azure）等大型服务商提供的现成的、按

需付费的命名实体链接服务，而不是开发内部系统。

命名实体链接：使用Azure API

Azure 文本分析 API 是命名实体链接最常用的 API 之一。DBpedia Spotlight 是实现了同样

功能的免费工具。Azure 提供 7 天的免费试用，可借此了解 API 是否满足要求。

根据经验，在项目中使用命名实体链接时，需要记住以下几点。

• 现有的命名实体链接方法并不完美，它们无法很好地处理新名称或特定领域的术语。由

于命名实体链接还涉及句法分析等更多的语言处理步骤，因此准确性也受到其他处理步

骤的影响。

• 自然语言处理流水线的第一步——文本提取和清理——会影响命名实体链接的输出，这

和其他信息提取任务一样。当使用第三方服务时，通常很难根据需要来调整它们适应自

己的领域，或修改它们内部的工作方式来满足特定的需求。

前面简要介绍了如何将命名实体链接引入项目的自然语言处理流水线中。现在继续下一个

信息提取任务：关系提取，它以命名实体链接为先决条件。

5.7　关系提取

考虑这样一个任务：挖掘海量的新闻文章来获得金融方面的见解。为了能够每天对成千上

万的新闻文本进行分析，可能需要一个持续更新的知识库，它能根据新闻内容将不同的

人、组织和事件关联起来。这种知识库的一个用例是根据公司发布的文件及其相关的新闻

文章来分析股票市场。那么应该如何构建这样的工具？前面介绍的关键词提取、命名实体

识别和命名实体链接都在一定程度上有助于识别实体、事件、关键词等。但是接下来如何

用某种关系将它们“连接”起来？这些关系具体是什么？如何提取？回到如图 5-1 所示的

《纽约时报》文章。可以提取的一个关系是 ( 卢卡 • 梅斯特里 , 财务总监 , Apple)。在这里，

“卢卡 • 梅斯特里”通过“财务总监”与“Apple”关联。

关系提取（RE）是指从文本文档中提取实体及其关系的信息提取任务。关系提取是构建知

识库的一个重要步骤，有助于改进搜索和开发问答系统。图 5-6 显示了 Rosette Text Analytics

关系提取系统处理以下文本片段的例子。

Satya Nadella is an Indian-American business executive. He currently serves as the 

Chief Executive Officer (CEO) of Microsoft, succeeding Steve Ballmer in 2014. 

Before becoming chief executive, he was Executive Vice President of Microsoft’s 

Cloud and Enterprise Group, responsible for building and running the company’s 

computing platforms.

信息提取 ｜ 129

图 5-6：关系提取演示

输出显示，萨蒂亚 • 纳德拉（Satya Nadella）与微软（Microsoft）的关系是雇员（PER￾EMPLOYEE-MEMBER-OF），与 Indian 和 American 的关系是公民（CIT-OF），等等。那么

如何从文本中提取这些关系呢？显然，关系提取比前面介绍的其他信息提取任务更具挑战

性。与本书前面讨论的其他自然语言处理任务相比，关系提取需要更深的语言处理知识。

除了识别实体并消除它们的歧义之外，关系提取还需要考虑句子中连接实体的词及其用法

等，从而对实体关系提取的过程进行建模。进一步而言，关系提取需要解决的一个重要问

题：什么构成“关系”？不同的领域可能有不同的关系。例如，在医疗领域，关系可能包

括受伤类型、受伤位置、受伤原因、受伤治疗等。而在金融领域，关系可能指完全不同的

东西。人、地点和组织之间的关系通常包括：位置关系、从属关系、创始人关系、父母子

女关系等。那么如何提取关系？

5.7.1　关系提取的方法

在自然语言处理中，关系提取是一个研究得比较充分的课题，从人工模式到监督学习、半

监督学习和无监督学习等用于构建关系提取系统的各种方法都得到了探索和使用。人工构

建的模式由正则表达式组成，旨在捕获特定的关系。例如，“PER, [something] of ORG”这

样的模式可以表示人和组织之间的“所属”关系。人工模式具有精确度高的优点，但覆盖

130 ｜ 第 5 章

信息提取 ｜ 131

率通常较低，很难覆盖领域内所有可能的关系。

因此，关系提取通常采用监督分类方法。和分类数据集一样，用于训练关系提取系统的数

据集包含一组预定义的关系。关系提取可以建模为两个步骤的分类问题。

1. 文本中的两个实体是否相关（二分类）。

2. 如果相关，两个实体之间的关系是什么（多分类）。

这些都可以使用命名实体识别中用到的人工特征、语境特征（例如实体周围的词）、句法

结构（例如“NP VP NP”模式，其中 NP 是名词短语，VP 是动词短语）等，按照常规的

文本分类问题进行处理。神经模型通常会使用不同的嵌入表示（见第 3 章），以及循环神

经网络等结构（见第 4 章）。

监督方法和基于模式的方法通常是特定于领域的，因此每次开始新领域的自然语言处理，

都需要获取大量的标注数据，这既具有挑战性，又非常昂贵。正如第 4 章所述，这样的场

景可以使用自举方法：先使用少量种子模式开始提取句子，然后根据提取的句子学习新的

模式，从而进行泛化。这种弱监督方法的一个延伸就是远程监督（distant supervision）：不

使用少量种子模式，而是使用 Wikipedia、Freebase 等大型数据库来收集不同关系的数千个

样例（例如使用 Wikipedia infoboxes）来创建大型关系数据集，然后使用常规的有监督的

关系提取方法。但是，这种方法只有在存在大型数据库时才有效。

如果用于监督方法的训练数据无法获得，那么不妨采取无监督的方法。无监督关系提取

（也称为“开放信息提取”）旨在从网络中提取关系，而不依赖于任何训练数据或任何关系

列表。提取的关系为 <verb, argument1, argument2> 元组的形式。有时，一个动词可能有

更多的论元（argument）。图 5-7 显示了 AllenNLP 开放信息提取系统的输出。

论元 论元 论元

Albert Einstein, a German-born theoretical physicist, published the theory of relativity in 1915.

图 5-7：AllenNLP 开放信息提取演示

如图 5-7 所示，关系包括一个动词和三个论元：<published, albert einstein, the theory 

of relativity, in 1915>。此外，还可以提取关系元组 <published, albert einstein, the 

theory of relativity>、<published, albert einstein, in 1915> 和 <published, theory 

of relativity, 1915>。显然，在这样的系统中，此类元组 / 四元组至少和动词的数量一

样多（通常会更多）。虽然这是一个优点，因为它可以提取到所有的关系，但这种方法

的挑战在于，将提取的关系映射到数据库中的标准关系集（例如 fatherOf、motherOf、

inventorOf 等）。然后，为了提取信息中的特定关系，就必须综合考虑命名实体识别 / 命名

实体链接、共指消解和开放式信息提取的输出，从而设计自己的程序。

5.7.2　关系提取：使用IBM沃森API

关系提取是一个难题，从零开始开发自己的关系提取系统不仅难度很大，而且耗时很长。

业界在自然语言处理项目中常用的解决方案是依靠 IBM 沃森提供的自然语言理解服务。下

面的代码片段演示了如何使用 IBM 沃森来提取实体关系。

mytext3 = """Nadella attended the Hyderabad Public School, Begumpet [12] before 

receiving a bachelor's in electrical engineering[13] from the Manipal Institute 

of Technology (then part of Mangalore University)in Karnataka in 1988.""" 

response = natural_language_understanding.analyze(text=mytext3, 

 features=Features(relations=RelationsOptions())).get_result() 

for item in response['relations']: 

 print(item['type']) 

 for subitem in item['arguments']: 

 print(subitem['entities'])

图 5-8 显示了关系提取的输出。关系提取使用监督模型。由于使用了预先设置的关系列表，

因此关系列表之外的任何内容都不会被提取。

图 5-8：IBM 沃森关系提取输出

输出信息显示了不同实体之间的关系，这可以用于构建组织数据知识库。正如前面所介绍

的，关系提取还不是一个完全解决了的问题。而且，方法的性能也依赖于领域，适用于维

基百科文章的方法可能不适用于一般的新闻文章或社交媒体文本。NLP-progress 网站文章

“Relationship Extraction”概述了关系提取的新进展。

先从基于模式的方法开始，然后尝试预训练的监督模型，如果效果不佳，最

后再使用弱监督。

以上内容简要介绍了关系提取的用处，以及在工作中遇到关系提取问题时应该如何处理。

在结束本章讨论之前，再来看几个信息提取任务。

132 ｜ 第 5 章

5.8　其他高级信息提取任务

前面讨论了不同的信息提取任务，它们的应用场景，以及如何将它们构建到自然语言处理

项目中。虽然本书的介绍并非详尽无遗，但它们是行业用例中最常用的任务。本节中将快

速介绍几个更专门的信息提取任务。这些都不是很常见，在业界的自然语言处理项目中也

很少使用，因此本节中只做简单介绍。建议读者从 Daniel Jurafsky 和 James H. Martin 的著

作 Speech and Language Processing (3rd ed. draft) 开始，进一步了解解决这些任务的不同方

法。下面来看三个信息提取任务：时间信息提取、事件提取和模板填充。

5.8.1　时间信息提取

考虑这样一封电子邮件的文本，“Let us meet at 3 p.m. today and decide on what to present at 

the meeting on Friday（我们今天下午 3 点见面，然后决定星期五的会议内容）”。我们开发

的应用程序需要识别对话中的事件并将其同步到日历，就像 Gmail 一样。图 5-9 显示了

Gmail 中这个实用程序的屏幕截图。

图 5-9：识别和提取电子邮件中的时间事件

要构建类似的应用程序，除了从文本中提取日期和时间信息（3 p.m.、today、Friday）之

外，还应该将提取的数据转换成某种标准形式（例如根据上下文将“Friday”映射到确切

的日期，将“today”映射到今天的日期）。虽然提取日期和时间信息可以使用基于正则表

达式的人工模式集合，或者使用有监督的序列标注技术来完成，但是将提取的日期和时间

规范化为标准的“日期 - 时间”格式可能是具有挑战性的。两项任务统称为时间信息提取

和规范化。当前时间表达式规范化的方法主要是基于规则的，同时结合了语义分析（参见

Speech and Language Processing (3rd ed. draft)）。

Duckling 是 Facebook 机器人团队最近发布的一个 Python 库，用于为 Facebook Messenger

构建机器人程序。Duckling 包的设计目的是解析文本并获取结构化数据。它能完成很多任

务，其中之一是通过处理自然语言文本数据来提取时间事件。图 5-10 显示了使用 Duckling

运行句子“Let us meet at 3 p.m. today and decide on what to present at the meeting on Friday”

后的输出。它能够将“3 p.m. today”映射到某一天的正确时间。

信息提取 ｜ 133

图 5-10：Duckling 时间信息提取输出示例

Duckling 支持多种语言。根据经验，Duckling 效果非常好，而且是一个现成的包。如果项

目中要使用时间信息提取，那么不妨从 Duckling 开始。另外，Stanford SUTime、Natty、

Parsedatetime 和 Chronic 等包也能处理人类可读的日期和时间。读者可以进一步探索这些

包，看看它们提取时间信息的效果。现在进入下一个信息提取任务：事件提取。

5.8.2　事件提取

在上一节讨论的电子邮件文本例子中，提取时间表达式的最终目的是提取“事件”信息。

事件可以是在某个时间点上发生的任何事情：会议、某时某地油价上涨、总统选举、股票

涨跌和人生事件（出生、结婚和死亡）等。事件提取是指从文本数据中识别和提取事件的

信息提取任务。图 5-11 显示了从 Twitter 提要中提取生活事件的例子。

提取

提取

提取

图 5-11：Twitter 数据提取生活事件示例（参见 Jiwei Li 等人的文章“Major Life Event Extraction 

from Twitter based on Congratulations/Condolences Speech Acts”）

134 ｜ 第 5 章

事件提取有许多业务应用。例如，一家提供教育贷款的金融贷款公司肯定希望拥有一个能

够扫描 Twitter 提要并识别“大学录取”事件的系统。再比如，一位对冲基金的贸易分析

师需要密切关注世界各地发生的重大事件。据信，彭博终端（Bloomberg Terminal）的一个

子模块可以实时报告全球数千个新闻来源和社交渠道（如 Twitter）中确定的重大事件。另

外，事件提取的一个有趣应用是祝贺机器人。祝贺机器人会阅读推文，如果看到任何值得

祝贺的事件，就会回复一条“祝贺”信息，如图 5-12 所示。

图 5-12：祝贺机器人示例

那么，如何解决事件提取的问题？在自然语言处理文献中，事件提取被视为监督学习问

题。当前的方法是使用序列标注和多级分类器，这与前面的关系提取非常相似。最终的目

标是识别不同时间段内的各种事件，将它们连接起来，并创建按时间顺序排列的事件图。

事件提取目前是一个活跃的研究领域，前面提到的解决方案仍然只适用于特定的场景。也

就是说，不同于关系提取、命名实体识别等任务，事件提取不存在相对通用的解决方案。

据我们所知，事件提取目前还没有现成的服务或包。如果项目中确实需要使用事件提取，

那么最好先从基于规则的方法（基于领域知识）开始，然后尝试弱监督方法。随着数据的

不断积累，再转向机器学习方法。

5.8.3　模板填充

在天气预报和财务报告等应用场景中，文本的格式非常标准，只有特定的细节会随情况而

变化。例如，考虑这样一个场景：每天都需要发布公司的股价报告。对于大多数公司来

说，这些报告的格式是类似的。例如，在“模板”句子“X 公司的股票比昨天上涨 Y%”

中，X 和 Y 会发生变化，但句型保持不变。那么如何自动生成报告呢？这样的场景就是模

板填充。模板填充是指将文本生成建模为填空问题的信息提取任务。图 5-13 展示了一个模

板填充的例子，以及如何用它来构建实体图。

一般而言，要填充的模板是预先定义好的。和关系提取一样，模板填充通常被建模为一个

分两步、有监督的机器学习问题。第一步是识别给定句子中是否存在模板。第二步是识别

模板的槽填充器，其中每个槽都需要训练一个单独的分类器。目前相关的研究方向是自动

归纳模板。由于模板填充是一个依赖于领域的专业任务，因此模板填充目前还没有现成的

服务提供者。

信息提取 ｜ 135

136 ｜ 第 5 章

文本

实体图

模板

W

W

W

W

W

W

W

图 5-13：模板填充示例

至此，关于大多数信息提取任务的讨论就结束了。到目前为止，本章介绍了一系列的信息

提取任务，以及如何在代码中整合信息提取任务。那么在真实的应用程序中，这些任务是

如何联系起来的？现在来看一个案例研究。

5.9　案例研究

考虑这样一个场景：在一个大型传统企业，人们通过电子邮件和企业消息平台（如 Slack

或 Yammer）进行交流。电子邮件对话中会出现很多关于会议的讨论。会议主要有三种类

型：团队会议、一对一会议、演讲 / 报告。此外，会议还涉及相关的地点。现在的任务是

构建一个系统，自动找到相关的会议，预定会场或会议厅，并通知人们。下面来介绍如何

在这个场景中使用前面讨论的信息提取任务。这里假设每封电子邮件只涉及一个会议。具

体的场景描述见如图 5-14 所示的电子邮件交流。那么，应该如何构建这样的系统呢？

图 5-14：从电子邮件中提取会议信息（示意图）

提醒一下，在开始阶段，需要对构建的系统做一定的限制，从而能够集中精力解决核心

问题。例如，一封电子邮件中可能会提到多个会议，例如：“MountLogan 是一个很好的场

地。我们明天在那里会面，然后星期四在 MountRainer 参加全员会议。”但是本场景假设每

封邮件只涉及一个会议。那么应该如何按照 MVP 来构建一个简单的系统？

首先，需要一定数量的标注数据。标注数据的构建有多种方式，其中之一是访问过去的日

历信息、会议预订信息和电子邮件，并比较会议预定信息和电子邮件是否匹配。如果匹配

的话，可以尝试使用硬编码的弱监督方法（类似于第 4 章中介绍的）。另外，也可以尝试

使用谷歌云自然语言或 AWS Comprehend 等预先构建的服务进行自举。例如，使用谷歌云

自然语言提供的实体提取服务来提取事件，并用它来生成数据集。然而，由于这种自动创

建的数据集可能并不完美，因此需要手动验证。

信息提取 ｜ 137

138 ｜ 第 5 章

假如现在使用以下实体：会议室名称（会议地点）、会议日期、会议时间、会议类型（派

生字段）、会议受邀人，并且部分标注数据已经收集好了。第一个模型可以使用命名实体

识别所用的条件随机场（CRF）等序列标注模型。要对会议类型进行分类，可以使用会议

室大小（大会议室通常意味着大会议）、受邀人数等特征，并从基于规则的分类器开始。

当系统进入部署阶段后，就可以开始收集隐式反馈或带有标注的显式反馈，例如会议接受

率 / 拒绝率，以及会议日期冲突率和会议室冲突率。所有这些信息都可以用来收集更多的

数据，从而应用更复杂的模型。

当有了足够的数据（5000~10 000 个带标签的句子）时，就可以开始探索更强大的语言理

解模型。如果有足够的算力，还可以微调 BERT 等强大的预训练模型来适应新的标注数

据。这个过程的流水线如图 5-15 所示。

无标注数据

标注数据包含多于10 000个样例

映射过去

的邮件

云服务

或库

CRF实体

模型

事件类型

分类器V1

LSTM实体

模型

事件类型

分类器V2

生产 用户反馈

生产 用户反馈

手动验证

或/和

 阶段1：

 初始数据

 收集

 阶段2：

 初始模型

（数据较少）

 阶段3：

 高级模型

（收集到更多

 数据时）

图 5-15：会议信息提取系统开发流水线

现在考虑最开始提出的复杂情况：可能涉及多个实体（会议室名称），可能涉及不同时间

段发生的多个会议。这个问题可以按照多类别、多标签的分类问题来处理。语言歧义很

难通过人工特征工程（例如特定实体、固定词汇存在与否）来解决。合理的方法是使用

LSTM 或 GRU 等深度循环神经网络对每个词周围的语境信息进行建模，并将这些知识编

码到隐藏的向量中，最后再用这些向量对电子邮件进行分类。虽然这些讨论是针对现实世

界的信息提取问题，但是使用本节概述的方法，可以逐步实现和改进任何信息提取问题的

解决方案。

5.10　小结

本章介绍了信息提取任务及其在不同真实场景中的用途，并讨论了如何实现关键词提取、

命名实体识别、命名实体链接和关系提取等不同信息提取任务的解决方案。本章还介绍了

时间信息提取、事件提取和模板填充等任务。信息提取任务与第 4 章中文本分类的一个

重要区别是，信息提取依赖于大型标注语料库之外的资源，并且需要更多的领域知识。因

此，在实际场景中，更常见的做法是使用大型服务商提供的预训练模型和解决方案，而不

是从头开发自己的信息提取系统，除非面对的是需要定制解决方案的超级专业领域。另外

还要注意，文本提取和清理在所有这些任务中都扮演着重要的作用，本章也多次强调了这

一点。虽然本章没有给出端到端的例子（将在本书第三部分中介绍）来说明信息提取任

务，但是希望本章能够让你对信息提取以及在项目中实现信息提取任务时的注意事项有足

够的了解。下一章将介绍如何为工作中遇到的不同用例构建聊天机器人。

信息提取 ｜ 139

第 6 章

聊天机器人

一台机器可以取代 50 位普通人的工作，但无法取代一位天才的工作。

——阿尔伯特 • 哈伯德

聊天机器人是允许用户通过自然语言进行交互的交互式系统。它们通常使用文本交互，但

也可以使用语音接口。2016 年初的第一波聊天机器人浪潮使其家喻户晓。像 Facebook 

Messenger、谷歌 Assistant 和亚马逊 Alexa 这样的平台都属于聊天机器人的应用。开发者现

在可以使用工具为他们的品牌或服务定制聊天机器人，以便客户在他们的通信平台进行一

些日常活动。

聊天机器人的应用使我们的技术迈进了新时代：人机对话时代。很快人机交互不再需要屏

幕或鼠标。无须任何鼠标点击或滑动，只需要使用声音就足够了。此界面完全是对话式

的，并且这些人机对话与我们和朋友及家人间的对话难以区分。聊天机器人在后台处理文

本，主要是对用户的文本输入进行语义理解并生成合理的答复。从语义理解到文本生成，

自然语言处理都扮演着至关重要的角色，我们将在本章中看到。

聊天机器人和人工智能的历史密切相关。在 20 世纪五六十年代，计算机科学家艾伦 • 图灵

和约瑟夫 • 维森鲍姆提出了像人类一样交流的计算机的概念。1966 年，约瑟夫 • 维森鲍姆使

用了仅仅 200 行代码创造了伊丽莎（Eliza），历史上第一个通过编程实现的聊天机器人。伊

丽莎通过正则表达式和规则模仿一位罗杰斯式心理治疗师的对话。在实验中，人们知道他们

正在和一个计算机程序对话，但仍然会由于伊丽莎提供的情感回应而变得对程序有感情。

后来，随着强大的信号处理工具的出现，研究员开始专注于构建语音对话工具，旨在提升

用户体验。许多语音对话系统创建于 1980~2000 年，最初是基于军事的项目，旨在改善士

兵间的自动通信。这些系统用于提供说明，随后将其翻译成用来帮助用户获取各种服务的

常见问题答案的聊天机器人。聊天机器人仍然是人工制作的，因此它们生成的响应是固定

的，并且它们不善于处理对话上下文。

140

近年来，由于智能手机的普及，以及机器学习和深度学习的最新进展，聊天机器人变得更

加可行和实用。除了可以在流行的通信平台（例如 Facebook Messenger）上创建聊天机器

人的 API 之外，我们现在还有各种用于创建聊天机器人后台的人工智能和逻辑的平台。这

使得人工智能背景和经验有限的个人和公司可以轻松部署自己的聊天机器人。

本章主要介绍聊天机器人的基础系统和理论，以及使用不同场景构建聊天机器人的实践经

验。本章结尾将介绍一些当前最先进的研究，这些研究可能会为整个范式带来重大进展。

我们希望通过介绍聊天机器人的热门应用来激发读者的兴趣。

6.1　聊天机器人的应用

聊天机器人可用于许多不同行业的不同任务，从零售到新闻，甚至还有医疗领域。我们将

简要讨论聊天机器人的各种应用。近年来，许多用例已日益成熟，而有些还处于起步阶

段。这些用例列举如下。

购物与电商

近年来，聊天机器人正用于各种电子商务运作，包括下单或修改订单，以及支付信息

等。电子商务行业对推荐各种商品的机器人也很感兴趣。业界正专注于构建对话式推荐

系统以提供更无缝衔接的用户体验。

新闻和内容发现

与电子商务类似，聊天机器人可用于新闻和内容发现。用户可以以对话的形式指定其搜

索的各种含义，机器人能够返回和搜索相关的文章。

客户服务

客户服务是需要使用大量机器人的另一个领域。它们通常在根据业务需求设置的预定义

对话流中，用于处理投诉、帮助回答常见问题和导航查询。

医疗

在健康和医疗应用中，常见问题解答（FAQ）机器人非常有用。这些机器人可以根据患

者的症状，帮助他们快速获取相关信息。近来，构建通过向患者（尤其是老年患者）咨

询相关问题，并从中获取其健康状况相关信息的聊天机器人也正在兴起。

法务

在法务应用中，机器人还可为用户提供 FAQ 服务。它们甚至可以用于更复杂的目标，

比如追加问题。例如，如果用户要求跟进案件的法律文章，则机器人可能会询问有关案

件性质的特定问题，以找到更合适的匹配结果。

以下是 FAQ 机器人的一个更详尽的示例，这种机器人在许多服务平台中都很常见，它通

过提供常见问题的答案来帮助用户。

一个简单的FAQ机器人

一般而言，FAQ 机器人是基于搜索的系统，它根据给定的问题查找正确的答案，并将其提

供给用户。它本质上是一个机器人，支持用户以不同方式提问并获取响应。像这种对一系

列复杂问题提供对话界面的机器人是非常有用的。

聊天机器人 ｜ 141

142 ｜ 第 6 章

我们将采用一部分 Amazon Machine Learning 的常见问题作为示例。机器需要学习为类似

的问题提供正确答案，因此最好对每个问题进行一些阐述。关于这种聊天机器人的输入 –

输出示例，参见表 6-1。

表6-1：用于 FAQ 机器人的 Amazon ML 常见问题

问题 答案

What can I do with Amazon Machine Learning?

How can I use Amazon Machine Learning?

What can Amazon Machine Learning do?

You can use Amazon Machine Learning to create a wide 

variety of predictive applications. For example, you can use 

Amazon Machine Learning to help you build applications that 

flag suspicious transactions, detect fraudulent orders, forecast 

demand, etc.

What algorithm does Amazon Machine Learning 

use to generate models? How does Amazon 

Machine Learning build models?

Amazon Machine Learning currently uses an industry-standard 

logistic regression algorithm to generate models.

Are there limits to the size of the dataset I can 

use for training?

What is the maximum size of training dataset?

Amazon Machine Learning can train models on datasets up to 

100 GB in size.

图 6-1 是这种 FAQ 机器人的一个可用版本。在本章的后面，我们将逐步学习如何为各种应

用构建这种机器人。

图 6-1：FAQ 机器人

接下来我们将介绍到聊天机器人的分类，并根据它们的用法进行各种分类的讲解。

6.2　聊天机器人的分类

让我们通过各种用途以及各种领域的适用性展开了解聊天机器人。聊天机器人可以通过多

种方式进行分类，这会影响聊天机器人的构建方式和用处。根据与用户交互的方式，聊天

机器人分类如下。

用于有限对话的精准答案或 FAQ 机器人

这些聊天机器人关联一系列固定的响应，并基于对用户查询的理解检索出正确的响应。

例如，如果我们构建一个 FAQ 机器人，该机器人必须理解问题并为此检索出固定的正

确答案。通常，用户的前后响应是没有联系的。看一下图 6-2。在 FAQ 机器人的示例

中，我们看到在前两轮对话中，机器人会针对稍有变化的相似问题提供固定的答案。对

于不同的问题，它会给出不同的答案。

基于流的机器人

就响应的多样性而言，基于流的对话机器人通常比 FAQ 机器人更复杂。用户可以在对

话过程中逐句表达自己的意见或需求。例如，当订购比萨时，用户可以逐句表达他们想

要的馅料、尺寸和其他偏好。机器人每次都应该在完整的对话过程中理解并跟踪这些信

息，以成功生成响应。在图 6-2 中我们看到的基于流的机器人，该机器人提出了一组特

定的问题，以实现创建比萨订单的目标。这个流程是预定义的，并且机器人会询问相关

问题以完成订单。本章后面会更详细地讨论这种基于流的机器人。

开放式机器人

开放式机器人主要用于娱乐，这种机器人应该能与用户讨论各种话题，它无须维护特定

的引导或对话流。在图 6-2 中，开放式机器人在没有任何预存模板或固定问答组合的情

况下进行对话。它通过话题的灵活转换来维持有趣的对话。这个开放式机器人的示例是

一个热门数字助理平台的其中一位作者构建的。

FAQ机器人 基于流的机器人 开放式机器人

图 6-2：聊天机器人的分类

聊天机器人 ｜ 143

聊天机器人可分为两大类：目标导向对话式；闲聊式。FAQ 机器人和基于流的机器人属于

第一类，开放式机器人主要属于第二类。这两种类型的机器人都在行业中大量使用，并且

在学术界也处于活跃的研究领域。

6.2.1　目标导向对话式

对话自然而然是为了通过寻找相关信息来实现目标。按照类似的思路，就很容易针对已知

最终目标的特定用例设计任何聊天机器人或对话智能体。到目前为止，我们讨论的大多数

聊天机器人（通常是用于研究或工业领域的）是目标导向的聊天机器人。与聊天机器人进

行交互的用户应拥有他们希望在对话后实现的目标的完整信息。例如，通过聊天机器人 /

对话智能体获取电影推荐或预订航班是目标导向对话的示例，其中的目标是看电影或预订

航班。

现在，根据定义，目标导向的系统是领域特定的，这需要系统拥有领域特定的知识。这妨

碍了聊天机器人框架的通用性和扩展性。Facebook 的近期研究提出了一个端到端框架，用

于训练对话本身的所有组件以减轻这种限制。该研究提出了一种自动处理数据的方法——

例如，问答组合通过必需的 API 调用进行有意义的对话。这是研究人员和从业者开始关注

的新方法之一。

6.2.2　闲聊式

除了目标导向对话之外，人们还会进行没有特定目标的非结构化开放领域对话。这种人和

人之间的对话涉及各种主题的自由形式的讨论。由于缺乏客观目标，开发一个可以与人闲

聊的对话智能体是充满挑战的。对话智能体必须生成连贯、紧扣主题且事实正确的响应，

以创造更自然的对话。

闲聊式机器人的应用很超前，但潜力巨大。例如，在用于老人护理的紧急医疗情况下，这

些机器人可以获取有用的信息。例如，青少年和老年人的孤独和抑郁情绪是长期存在的社

会问题，这种形式自由的对话机器人可以用来缓解这种情绪。一些行业头部公司，如亚马

逊、Apple 和谷歌等，正在大力投资为全球客户构建这种机器人。

到目前为止，我们已经讨论了各种聊天机器人及其在各行各业的用途。这使我们能够根据

使用场景了解聊天机器人的各种组件，并帮助我们根据需求实现某些组件。现在，我们将

深入探讨聊天机器人的开发流水线，并讨论各种组件的细节。

6.3　构建对话系统的流水线

第 4 章和第 5 章讨论了各种自然语言处理任务，例如分类和实体检测。现在，我们将应用

其中一些任务来描述构建对话系统的示例流水线。图 6-3 描绘了一个具有各种组件的对话

系统的完整流水线。接下来将讨论每个组件的实用程序以及贯穿流水线的数据流。

144 ｜ 第 6 章

语音识别 自然语言理解

对话管理器 任务管理器

文本到语音合成 自然语言生成

图 6-3：对话系统的流水线

语音识别

对话系统通常以人机交互界面的形式出现，因此对话系统中的输入是人的语音。语音识

别算法将语音转录为自然语言文本。工业对话系统使用了最先进的语音 – 文本转换模

型，但这超出了本书的内容范畴。

自然语言理解（NLU）

转录之后，系统尝试分析和“理解”转录的文本。该模块包含各种自然语言理解任务。

此类任务的示例包括情感检测、命名实体提取、共指消解等。此模块主要负责聚合输入

文本中隐式（情感）或显式（命名实体）存在的所有可能信息。

对话和任务管理器

一旦我们从输入中获取信息，如图 6-3 所示的对话管理器就会收集并系统地鉴定信息的

重要性。对话管理器是控制和引导对话流程的模块。可以将其想象为一张表格，其中包

含在自然语言理解步骤中提取的信息，而且并发存储所有正在进行的对话。对话管理器

通过规则或其他复杂机制（例如强化学习）制定策略，以有效利用从输入中获取的信

息。对话管理器在目标导向对话中最为普遍，因为通过对话可以达成明确的目标。

自然语言生成

最后，当对话管理器决定响应策略时，自然语言生成模块根据对话管理器设计的策略，

以人类可读的形式生成响应。响应生成器可以是基于模板的，也可以是从数据中学到的

生成模型。此后，语音合成模块将文本转换回语音，并传递给终端用户。

任何聊天机器人都可以使用这样的流水线构建。对于基于文本的聊天机器

人，我们可以移除语音处理组件。尽管自然语言理解和生成组件可能很复

杂，但对话管理器可能只是将机器人路由到适当的响应生成器的规则。

尽管图 6-3 的流水线假定聊天机器人是基于语音的，但没有语音处理模块的类似流水线也

可用于基于文本的聊天机器人。但在所有的行业应用中，我们终将越来越多地使用基于语

音的系统，因此这里讨论的流水线更为通用，它适用于我们先前描述的各种应用（包括

第 1 章的案例研究）。现在，我们已经简要地讨论了聊天机器人的各个组件以及对话流程

是如何发生的，下面让我们深入了解这些组件的细节。

聊天机器人 ｜ 145

6.4　对话系统原理

对话系统或聊天机器人背后的主要思想是，理解用户的查询或输入，并提供合适的响应。

这有别于典型的问答系统——对于给定的问题必须有一个答案。在对话设置中，用户可以

“轮流”查询。在每轮对话中，用户都会根据机器人可能做出的响应来表明他们对主题的

兴趣。因此，对话系统最重要的工作是逐步理解用户输入的细微差别，并将其存储在上下

文中以生成响应。

在深入机器人和对话系统的原理之前，我们将更广泛地介绍对话系统和聊天机器人开发中

用到的术语。

对话行为或意图

这是用户命令的目的。在传统的系统中，意图是主要的描述符。通常，一些其他元素

（例如情绪）也可以与意图相关联。在某些文献中，意图也称为“对话行为”。在图 6-4

的第一个示例中，orderPizza（订购比萨）是用户命令的意图。类似地，在第二个示例

中，用户希望了解一只股票，因此意图是 getStockQuote。这些意图通常是根据聊天机

器人的工作范围预先定义的。

插槽或实体

这是一种固定本体结构，其中包含与意图相关的特定实体信息。每个插槽（slot）相

关的信息原语是“值”。插槽和值有时被合称为“实体”。图 6-4 显示了两个实体示例。

第一个示例是查找待订比萨的特定属性：“medium”（中号）和“extra cheese”（加奶

酪馅料）。第二个示例是查找 getStockQuote 的相关实体：聊天机器人询问的股票名称

和时间段。

对话状态或上下文

对话状态是一种包含有关对话行为的信息和“状态 – 值”对的本体结构。同样，上下文

可以看作一组捕获了历史对话状态的记录。

意图：orderPizza

实体 实体

意图：getStockQuote

实体 实体

图 6-4：聊天机器人中用到的不同术语示例

146 ｜ 第 6 章

聊天机器人 ｜ 147

现在使用一个名为 Dialogflow 的云 API 来完成一个虚拟比萨店的演练——使用户可以通过

与聊天机器人对话来订购比萨。这是一个目标导向系统，它的目标是适应用户的要求并订

购比萨。

PizzaStop聊天机器人

Dialogflow 是谷歌的对话智能体构建平台。通过提供理解和生成自然语言以及管理对话的

工具，Dialogflow 使我们能够轻松地创建对话体验。此外有许多其他可用的工具，我们选

择它是因为它很容易上手、成熟，并且正在不断改进。

想象有一家名为 PizzaStop 的虚拟比萨店，我们必须构建一个可以接收顾客订单的聊天

机器人。比萨可以有多种馅料（如洋葱、番茄和胡椒）和不同尺寸。订单还可以包含

菜单中的小吃、开胃菜与 / 或饮料类别中的一项或多项。理解了需求之后，就开始使用

Dialogflow 框架构建我们的机器人。

1. 构建我们的 Dialogflow 智能体

在开始创建智能体之前，需要创建一个账号并进行一些设置。打开 Dialogflow 的官方网

站，使用你的谷歌账号登录并授予所需权限。导航到 API 的 V2。单击“try it for free”，你

将被定向到谷歌云服务的免费层级，然后你就可以根据注册过程进行操作。

① 首先需要创建一个智能体。单击 Create Agent 按钮，然后输入智能体名称。你可以提供

任意名称，但最好提供一个有助于了解智能体用途的名称。我们的 PizzaStop 项目，就

将智能体命名为“Pizza”。现在，设置时区并单击 Create 按钮。

图 6-5 显示了创建智能体的用户界面。

图 6-5：使用 Dialogflow 创建智能体

② 然后，你将被重定向到另一个页面，其中有可以让你创建机器人的选项。图 6-6 显示了

Dialogflow 的用户界面，在创建智能体时将多次使用。默认情况下，我们已经拥有两个

意图：Default Fallback Intent（默认降级意图）和 Default Welcome Intent（默认欢迎意

图）。Default Fallback Intent 是内部 API 错误的默认响应，而 Default Welcome Intent 会

生成欢迎消息。

图 6-6：创建智能体后的 Dialogflow 用户界面

③ 现在需要将我们关心的意图和实体添加到智能体中。要添加意图，请将鼠标悬停在

“Intents”区块上，然后单击“+”按钮。你将看到类似图 6-7 的内容。这些意图和实体

是在本节前面定义的。

图 6-7：单击“+”按钮后的 Dialogflow 用户界面

148 ｜ 第 6 章

聊天机器人 ｜ 149

④ 现在将创建第一个意图：orderPizza。在创建新意图时，必须提供名为“training phrases”

（训练短语）的训练示例，使机器人能够检测到属于该意图的响应的变化。还需要提供

“上下文”：可以在整个对话范围内共享的一条信息，这些信息将用于后续的意图检测。

训练短语的示例是“I want to order a pizza”（我想订购比萨）或“medium with cheese 

please”（中号加奶酪馅料）。第一个表示订购比萨的简单意图，而第二个则由预定义的

有用实体组成，例如“中号”和“奶酪馅料”。

图 6-8 显示了添加到智能体的训练短语样本。

图 6-8：为意图添加训练短语

⑤ 由于引入了意图，因此需要添加对应的实体，以记住用户提供的重要信息。创建一个

名为 pizzaSize（比萨尺寸）的实体，启用“fuzzy matching”（模糊匹配，即使实体大致

相同，也可以匹配它们），并提供必要的值。同样，创建一个 pizzaTopping（比萨馅料）

实体，但这次还需要启用“Define synonyms”（定义同义词，同时允许我们将定义为同

义词的多个单词匹配到同一实体）。

这两个实体将帮助我们检测“medium size”（中号）和“cheese toppings”（奶酪馅料），

如图 6-9 和图 6-10 所示。

150 ｜ 第 6 章

图 6-9：创建 pizzaSize 实体

图 6-10：创建 pizzaTopping 实体

⑥ 现在回到 Intents 区块，向 Action and Parameters（行为与参数）部分添加其他信息。我

们需要馅料和尺寸来完成订单，因此需要在相关选项勾选“Required”（必选）复选框。

同一个比萨不能有多个尺寸，但同一个比萨可以有多种馅料。因此，为馅料启用 isList

选项，使其具有多个值。

用户可能只提及尺寸或只提及馅料。为了收集完整的信息，我们需要添加一个提示用于

询问后续问题，例如“What size of pizza would you like?”（您想要多大的比萨？）作为

pizzaSize 的提示，如图 6-11 所示。

图 6-11：orderPizza 意图的行为和参数

⑦ 还需要为智能体提供给用户的示例响应，如图 6-12 所示。可以询问用户是否需要饮料、

开胃菜或小食。如果要创建类似于支付意图的内容，则可以通过启用 Responses（响应）

区块中的“Set this intent as end of conversation”（将此意图设置为对话结束）滑块来结

束对话。

图 6-12：添加我们的智能体应该使用的恰当回复

⑧ 到目前为止，已经添加了一个简单的意图和实体。现在可以看看具有上下文的复杂实

体。思考以下语句，“I want to order 2 L of juice and 3 wings”（我要订购 2 升果汁和 3 个

鸡翅）。我们的智能体需要确认库存和订购商品的数量。这是通过在 Dialogflow 中添加

自定义实体来实现的。我们创建了一个名为 compositeSide 的实体，它可以处理所有这

些组合。例如，在“@sys.number-integer:number-integer @appetizer:appetizer”中，第一

个实体负责识别订购了多少开胃菜，而下一个实体处理开胃菜的类型，如图 6-13 和图

6-14 所示。正如你所见，这些实体的签名是作为正则表达式给出的。

聊天机器人 ｜ 151

图 6-13：创建 compositeSide 实体

图 6-14：具有多个实体和上下文的复杂语句的示例

⑨ 还可以添加更多意图和实体，使智能体变得稳健。请在图 6-15 和图 6-16 中查看我们添

加的其他意图和实体的示例，这些意图和实体可以丰富和增强用户的比萨订购体验。

152 ｜ 第 6 章

图 6-15：该智能体的所有意图

图 6-16：该智能体的所有实体

现在已经完成了为 PizzaStop 构建机器人的步骤，接下来将测试这个机器人，以了解它是

怎样在各种场景中工作的。

2. 测试我们的智能体

现在要在网站设置中测试我们的智能体。为此，需要以“Web Demo”模式打开它。单击

Integrations（集成）区块并向下滚动，直到出现 Web Demo。单击弹窗中的链接，仅此而

已。你可以随时测试智能体，图 6-17 显示了我们构建的片段。测试我们的机器人对于验证

其可行性至关重要，我们将分析一系列各种难度的用例。

聊天机器人 ｜ 153

图 6-17：使用我们的智能体下单

可以在图 6-17 中看到，我们的机器人能够处理简单的查询，以帮助用户订购比萨。对机器

人进行端到端测试之后，还可以分别测试它的各种组件。对单个组件进行测试，有助于在

端到端测试之前快速原型化并捕获边界用例。

现在来看一个更复杂的示例，该示例将对机器人与谷歌 Assistant 进行集成测试。在图 6-17

的示例中，我们的智能体确认了订购比萨的意图，并识别出我们订购的馅料。pizzaSize 实

体未被填充，因此它会询问有关比萨大小的问题，以满足实体要求。满足了 orderPizza 的

意图后，智能体便开始询问有关小吃和开胃菜的信息。根据我们提供的语句，智能体需要

满足 orderSize 的意图，并且应该能够识别果汁和开胃菜的数量。这表明智能体能够处理复

杂的实体。最后，继续对话以选择支付方式。图 6-18 和图 6-19 显示了内部状态和提取的

实体是怎么在另一个对话中奏效的。

图 6-18：输入包含多个实体的复杂文本语句

154 ｜ 第 6 章

图 6-19：测试包含复杂实体和上下文的文本语句

Dialogflow 允许我们构建目标导向的聊天机器人。在我们的领域中拥有广泛

的本体（可能的插槽和意图）很重要，因为这将使我们的机器人能够用丰富

的语言来响应各种用户查询。

本节中已经展示了如何使用 Dialogflow API 构建功能全面的聊天机器人。我们学习了意图

和实体——理解对话的两个主要组成部分。接下来将深入研究构建用于“意图 / 对话”行

为分类和“实体 / 插槽”识别的自定义模型。

6.5　深入对话系统的组件

到目前为止，我们已经了解了如何使用 Dialogflow 构建聊天机器人，以及如何添加各种功

能来处理复杂的实体和上下文。现在，我们想深入研究对话系统内部的机器学习部分。正

如我们在描述对话系统的流水线时所讨论的那样，根据对话历史理解上下文（即用户响

应）是构建对话系统最重要的任务之一。

理解上下文可以拆解成理解用户的意图并针对该特定意图检测相应的实体。这些内部组件

与聊天机器人流水线中的自然语言理解组件是相对应的。我们将通过一个关于餐馆预订的

对话样本，并描述如何为上下文理解建模不同的组件来说明这一点。

图 6-20 显示了用户预订餐馆的示例。可以看到，每个响应都有可用的标签。标签指示这些

响应的意图和实体。我们希望使用这些标注来训练我们的机器学习模型。

聊天机器人 ｜ 155

用户：

系统：

用户：

系统：

用户：

系统：

图 6-20：关于餐馆预订的对话

在建模之前，我们将正式定义两个与对话上下文理解相关的自然理解任务。由于这涉及理

解下面的语言的细微差别，因此这些也被称为自然语言理解（NLU）任务。

6.5.1　对话行为分类

对话行为分类是确定用户话语在对话上下文中如何发挥作用的任务。这告知用户正在执行

的“行为”。例如，对话行为的一个简单示例就是识别是非问题。如果用户问“你今天去

学校吗”，则将其归类为是非问题。另一方面，如果用户问“海洋有多深”，则可能不会归

类为是非问题。我们已经看到，即使在 Cloud API 中，意图或对话行为对于构建聊天机器

人也很重要。识别意图有助于理解用户的需求并采取相应的措施。

从头开始构建对话行为分类和识别插槽可能是一个复杂且消耗数据的过程。

当我们的对话行为和插槽本质上比 Cloud API 或现有框架的解决方案更加开

放时，这样做就很有意义。随着时间的流逝，对对话内部的完全控制可以在

这些问题上产生更好的结果。

这可以归类为分类问题：给定对话语音，将其归类为对话行为或标签。在图 6-20 的示例

中，我们定义了一个对话行为预估任务，其中的标签包括“通知”“请求”等。“它在哪

里”可以归类为“请求”对话行为。另一方面，“我正在寻找一家更便宜的餐馆”可以归类

为“通知”对话行为。利用在第 4 章中学到的知识，我们可以使用任何喜欢的分类器来解

决此任务。我们将在 6.5.4 节中以完整的数据集示例讨论与该任务有关的模型。

6.5.2　识别插槽

一旦提取意图后，就要继续提取实体。为了生成对用户输入的正确且适当的响应，提取实

体也很重要。在 Dialogflow 示例中，我们还看到实体和意图的提取可以完全理解用户的

输入。

156 ｜ 第 6 章

在图 6-20 的示例中——“我正在寻找一家更便宜的餐馆”（I’m looking for a cheaper 

restaurant）——我们希望将“更便宜的”（cheaper）识别为一个价值插槽，并逐字提取其

价格，即该插槽的价值为“更便宜的”。如果我们知道槽值对的本体，那么最终可以恢复

为更规范的形式，例如“更便宜的”（cheaper）->“便宜的”（cheap）。在第 5 章中，我们

已经看到了类似的任务，在那里我们学习了如何从句子中提取实体。这里也可以采用类似

的方法（即序列标注法）来提取这些实体。

在之前的 Dialogflow 示例中，插槽必须预定义。但是在这里，我们希望使用机器学习算法

自行构建该组件。回顾第 5 章在 NER 上下文中讨论的算法。我们将使用类似的算法进行

插槽检测和标记，并将使用在第 5 章中用到的名为 sklearn-crfsuite 的开源序列标注库来完

成此任务。后面的部分中会讨论这个实验的细节。

我们可以选择一系列用于标注实体的本体。想象我们正在构建一个旅行机器

人。目的地实体的选择可以是城市或机场。为了让它稳健，我们必须将机场

作为一个实体来检测，因为一个城市可以有多个机场。另一方面，在餐馆预

订机器人的用例中，将城市检测为实体可能是合适的。

这些方法的缺点之一是，它们都需要大量有标签数据才能进行意图和实体检测。此外，我

们需要用于这两个任务的专用模型。这会使系统的部署更慢。获取实体的细粒度标签的开

销也很昂贵。这些问题限制了这个流水线对于更多领域的可伸缩性。

关于口语理解的最新研究显示，联合理解和跟踪比单独的分类和序列标注部分要好。与单

个模型相比，此联合模型在部署时很轻巧。对于联合建模，我们可以利用对话状态，在图

6-20 的示例中为 inform(price=cheap)。我们可以通过对话行为（组合为对话状态）来对每

个候选对进行排序或评分，以联合确定状态。联合确定更为复杂，需要更好的表征学习技

术，这超出了本书的范畴。现在，我们已经讨论了自然语言理解组件，接下来继续讨论响

应生成。

6.5.3　生成响应

一旦识别出插槽和意图，最后一步就是让对话系统生成适当的响应。生成响应的方法有很

多：固定响应、使用模板和自动生成。

固定响应

FAQ 机器人主要使用固定响应。根据插槽的意图和值，在响应池中进行字典查找，并

检索最佳响应。一种简单的情况是丢弃插槽信息，并且每个意图都有一个响应。对于

更复杂的检索，可以构建一种排序机制，该机制根据检测到的意图和槽值对（或对话状

态）对响应池进行排序。

使用模板

要使响应变成动态的，通常采用基于模板的方法。当后续响应是一个明确的问题时，模

板非常有用。插槽的值可用于提出追加问题或给出事实驱动的答案。例如，可以使用模

板 <restaurant name> serves <price-value> <food-value> food 构建“The House serves 

cheap Thai food”。一旦识别出插槽及其值，就填充此模板以生成最终适当的响应。

聊天机器人 ｜ 157

158 ｜ 第 6 章

自动生成

可以使用数据驱动的方法来学习生成更自然和流畅的语言。获得对话状态后，可以构建

条件生成模型，该模型将对话状态作为输入并为智能体生成下一个响应。这些模型可以

是图形模型或基于深度学习的语言模型。稍后将简要地介绍与自动生成相似的、用于对

话的端到端方法。

尽管自动生成很强大，但模板相比之下更有优势。这两者可能很难区分，尤

其是当模板种类繁多时。基于模板的响应包含更少的语法错误，并且更易于

训练。

现在已经深入探讨了对话系统的各个组件，接下来逐步介绍对话行为分类和插槽预测的

示例。

6.5.4　带有代码演练的对话示例

这一节中将介绍可公开获得的各种现实世界的对话数据集的实例，并讨论它们在建模对话

系统各个部分时的用法。然后，我们将使用其中的两个数据集来展示，针对我们用于上下

文理解的两个任务，应如何实现模型：对话行为预估或意图分类，以及插槽识别或实体检

测。我们将为每个任务分别探索几个模型，并通过比较来演示如何逐步改进这些模型。所

有模型均源于第 4 章和第 5 章中讨论过的自然语言理解任务（分类和信息提取）。

1. 数据集

表 6-2 是各种数据集的摘要，这些数据集用于目标导向对话任务的基准测试算法。由于我

们对对话中的各种自然语言理解任务感兴趣，因此为目标导向的对话提供了 4 个数据集，

这些数据集充当基于对话的自然语言理解任务的基准。

表6-2：来自各个领域的目标导向的数据集及其用法

数据集 领域 用途

ATIS 机票预订 意图分类和插槽填充的基准。这是一个单领域数据集，限用于单领域实体和

意图

SNIPS 多领域 意图分类和插槽填充的基准。这是一个多领域数据集，限用于多领域实体。

多领域数据集由于其多样性而难以建模

DSTC 餐饮 对话状态追踪或意图和插槽联合确认的基准。这也是一个单领域数据集，但

实体多以标注的形式表达，并包含更多元的数据

MultiWoZ 多领域 对话状态追踪或跨领域意图和插槽联合确认的基准。出于类似的多样性原

因，这个数据集比单领域数据集更难以建模

除了这些数据集之外，对话流水线中各种其他子任务还可以使用几个不同规模的数据集

（即对话样本的数量）。本节稍后的内容将讨论如何收集这样的数据集，并将其应用于特定

领域的场景。目前，我们专注于目标导向的对话，因为它们可以直接在行业中使用，并且

已经有了最先进的研究。

尽管存在许多开源数据集，但只有少数数据集反映了人类对话的自然性。由

在线标注者（如亚马逊 Mechanical Turker）收集的数据集存在千篇一律且生

硬的对话，而这会影响对话的质量。此外，许多专业领域尚未具备该领域特

定的对话数据集，例如医疗保健、法律等。

2. 对话行为预估

对话行为分类或意图检测是上一节中描述的任务，它是对话系统中自然语言理解组件的一

部分。这是一项分类任务，我们将根据第 4 章中的分类流水线解决它。

加载数据集。我们将使用航班信息数据集（Airline Travel Information Systems, ATIS）来进

行意图检测任务。ATIS 数据集广泛用于口语理解和执行各种自然语言理解任务。该数据集

包含 4478 条训练语音和 893 条测试语音，共 21 个意图。我们挑选了 17 个意图，它们同

时出现在训练集和测试集中。因此，我们的任务是 17 类分类任务。数据集的实例类似于

以下代码：

查询文本：BOS please list the flights from charlotte to long beach arriving 

 after lunch time EOS 

意图标签：flight

建模。由于是分类任务，我们将直接使用第 4 章中出现的一种深度学习技术：CNN 模型。

在这里使用 CNN 很有用，因为它通过其密集表示法捕获 n-gram 特征。n-gram（例如“list 

of flights”）表示“flight”标签：

atis_cnnmodel = Sequential() 

atis_cnnmodel.add(embedding_layer) 

atis_cnnmodel.add(Conv1D(128, 5, activation='relu')) 

atis_cnnmodel.add(MaxPooling1D(5)) 

atis_cnnmodel.add(Conv1D(128, 5, activation='relu')) 

atis_cnnmodel.add(MaxPooling1D(5)) 

atis_cnnmodel.add(Conv1D(128, 5, activation='relu')) 

atis_cnnmodel.add(GlobalMaxPooling1D()) 

atis_cnnmodel.add(Dense(128, activation='relu')) 

atis_cnnmodel.add(Dense(num_classes), activation='softmax')) 

atis_cnnmodel.compile(loss='categorical_crossentropy', 

 optimizer='rmsprop', 

 metrics= ['acc'])

在测试中使用 CNN 得出的准确率为所有类别的平均水平：72％。如果使用 RNN 模型，则

准确率高达 96％。我们相信 RNN 能够捕获整个输入句子中单词的相互依赖性。RNN 抓住

了单词相对于之前所见上下文的重要性：

atis_rnnmodel = Sequential() 

atis_rnnmodel.add(Embedding(MAX_NUM_WORDS, 128)) 

atis_rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) 

atis_rnnmodel.add(Dense(num_classes), activation='sigmoid')) 

atis_rnnmodel.compile(loss='binary_crossentropy', 

 optimizer='adam', 

 metrics= ['accuracy'])

聊天机器人 ｜ 159

众所周知，最近的 Transformer 预训练模型（例如 BERT）功能更强大。因此，到目前为

止，我们将尝试使用 BERT 来改善获得的性能。BERT 可以更好地捕获上下文并具有更多

参数，因此更具表现力，并且可以对语言的复杂性进行建模。我们需要使用 BERT 风格的

分词方式：

# 数据：

sentence = " [CLS] " + query + " [SEP]" 

Tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', 

 do_lower_case= True) 

tokenizer.tokenize(sentence) 

# 模型：

model = BertForSequenceClassification.from_pretrained("bert-base-uncased", 

 num_labels=num_classes)

由于 BERT 是经过预训练的，因此内容的表示要比我们从零开始训练的任何模型（例如

CNN 或 RNN）要好得多。 我们看到 BERT 达到 98.8％的准确性，在对话行为预估任务上

击败了 CNN 和 RNN。

3. 插槽识别

插槽识别是上一节中描述的另一项任务，它是对话系统中自然语言理解组件的一部分。我

们描述了为什么可以将其当作序列标注任务。需要找到给定输入的槽值，然后根据第 5 章

中的序列标注流水线来处理此任务。

加载数据集。我们将使用 SNIPS 处理此插槽识别任务。SNIPS 是由 Snips（一个用于连接

设备的 AI 语音平台）组织的数据集。它包含 16 000 个众包查询，是插槽识别任务的流行

基准。我们将同时加载训练和测试示例，数据集的实例类似于以下代码：

Query text: [Play, Magic, Sam, from, the, thirties] # 已分词

Slots: [O, artist-1, artist-2, O, O, year-1]

正如第 5 章中所讨论的那样，我们正在使用 BIO 方案来标注插槽。在此，O 表示“其他”，

而 artist-1 和 artist-2 表示组成艺术家姓名的两个单词。year 的含义以此类推。

建模。由于可以将插槽识别任务视为序列标注任务，因此我们将使用在第 5 章中用到的一

种流行技术：sklearn 软件包中的 CRF++ 模型。我们还会使用词向量，而不是创建手动生

成的特征以灌入 CRF。CRF 是一种流行的序列标注技术，在信息提取中大量使用。

我们使用对这项特定任务有用的词特征。可以看到，除了单词本身的含义外，每个单词的

上下文都很重要。因此，对于给定的单词，使用它的前两个单词和后两个单词作为特征。

我们还使用从 GloVe 预训练的嵌入（在第 3 章中讨论过）中检索到的词嵌入向量作为附加

特征。在输入中，每个词的特征是在单词之间串联的。此输入表示法传递给 CRF 模型以进

行序列标注：

def sent2feats(sentence): 

 feats = [] 

 sen_tags = pos_tag(sentence) # 该格式特定于此词性标注

 for i in range(0,len(sentence)): 

 word = sentence [i] 

160 ｜ 第 6 章

 wordfeats = {} 

 # 词特征：给定的词本身，以及它在句子中的前两个单词和后两个单词

 wordfeats ['word'] = word 

 if i == 0: 

 wordfeats ["prevWord"] = wordfeats ["prevSecondWord"] = "<S>" 

 elif i==1: 

 wordfeats ["prevWord"] = sentence [0] 

 wordfeats ["prevSecondWord"] = "</S>" 

 else: 

 wordfeats ["prevWord"] = sentence [i-1] 

 wordfeats ["prevSecondWord"] = sentence [i-2] 

 # 后两个单词作为词特征

 if i == len(sentence)-2: 

 wordfeats ["nextWord"] = sentence [i+1] 

 wordfeats ["nextNextWord"] = "</S>" 

 elif i==len(sentence)-1: 

 wordfeats ["nextWord"] = "</S>" 

 wordfeats ["nextNextWord"] = "</S>" 

 else: 

 wordfeats ["nextWord"] = sentence [i+1] 

 wordfeats ["nextNextWord"] = sentence [i+2] 

 # 添加词嵌入向量

 vector = get_embeddings(word) 

 for iv,value in enumerate(vector): 

 wordfeats ['v{}'.format(iv)]=value 

 feats.append(wordfeats) 

 return feats 

# 训练

crf = CRF(algorithm='lbfgs', c1=0.1, c2=10, max_iterations=50) 

# 填充训练数据

crf.fit(X_train, Y_train)

使用 CRF++ 模型获得的 F1 分数为 85.5。与之前的分类任务类似，我们将尝试使用 BERT

来提升目前的模型性能。即使在执行序列标注任务的情况下，BERT 也可以更好地捕获上

下文。我们使用查询中所有单词的所有隐藏表示法来预测每个单词的标签。因此，最后

我们将词序列输入到模型中，并获得一系列标签（与输入长度相同）。可以将单词作为值，

将词序列推断为预估的插槽：

# 数据：

sentence = " [CLS] " + query + " [SEP]" 

Tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', 

 do_lower_case= True) 

tokenizer.tokenize(sentence) 

# 模型：

model = BertForTokenClassification.from_pretrained("bert-base-uncased", 

 num_labels=num_tags)

聊天机器人 ｜ 161

但是，BERT 的 F1 分数只能达到 73。这可能是由于输入中存在许多未由原始 BERT 参数

恰当表示的命名实体。然而我们为 CRF 获得的特征足以使该数据集捕获必要的模式。这是

一个有趣的示例，其中较简单的模型击败了 BERT。

正如我们之前和此处所看到的，经过预训练的模型比从零开始学习的其他深

度学习模型有更好的性能。但也可能会有例外，因为预训练的模型对数据大

小敏感。预训练的模型可能会在较小的数据集上过拟合，而在这些情况下手

动生成的特征可能会很好地泛化。

到目前为止，我们已经学习了如何使用流行的数据集，为目标导向对话构建各种自然语言

理解组件。我们已经看到了各种深度学习模型在这些任务中的表现如何。有了这些知识，

我们将能够在自己的数据集中运行此类自定义模型，并探索各种模型以选择最佳模型。这

一节中还介绍了 4 个数据集，它们是目标导向对话建模的流行基准，可用于对较新的模型

进行原型设计，以根据先进的模型验证其性能。下一节将讨论常用于目标导向设定以外用

途的其他对话模型，以及它们的优缺点。

6.6　其他对话流水线

到目前为止，图 6-3 中介绍的模块化流水线已经讨论完毕。但是，还有许多应用于各种场

景的流水线，尤其是在开放式聊天机器人的场景中。由于组件太多，图 6-3 中的初始流水

线有时缺乏可训练的能力，因为每个组件都必须单独进行训练，并且每个组件都需要独立

的、已标注的数据集。除此之外，在模块化流水线中，需要显式定义本体，并且不能从数

据中捕获潜在模式。这就是为什么接下来将简要介绍未来可能有前景的其他现有流水线。

6.6.1　端到端方法

序列转换模型（又称为 seq2seq 模型）已经在关键的自然语言处理任务（如神经机器翻译、

具名实体识别等）中得到了广泛的认可。seq2seq 模型通常将一个序列作为输入，并输出

新的序列。在翻译任务中，假设输入句子是一种语言，而输出的是我们想要翻译的语言。

和其他任务一样，聊天机器人可以使用 seq2seq 模型构建。想象模型的输入是用户的话语：

一个词序列。至于输出，它将生成另一个词序列，即机器人的响应。seq2seq 模型是端到

端可训练的，因此不需要维护多个模块，并且它们通常是基于 LSTM 的。近来，最先进的

Transformer 已经用于 seq2seq 任务，因此它们也可用于对话场景。

通常，我们使用分词创建词元并根据问题创建序列。seq2seq 能够捕获序列中词元的固有

顺序——这很重要，因为它可以确保我们捕获问题的正确含义以便正确地回答。有关谷歌

在这种端到端模型的一些实践示例，请参考图 6-21。他们将问题输入模型，模型生成相应

的输出。

162 ｜ 第 6 章

浏览器技术支持 哲学讨论

图 6-21：谷歌关于 seq2seq 模型的实践示例

6.6.2　用于对话生成的深度强化学习

很多人想知道机器是如何针对任何问题生成各种答案的。已有文献研究了经典 seq2seq 模

型的弊端，发现它们经常不断生成常用的输出“我不知道”。这些模型在生成话语时，并

不考虑如何响应才能进行好的对话。想要好的对话，就需要提前判断何为好的对话，而这

最终将帮助用户实现其目标。“好的对话”的概念是抽象的，因此这通常根据对话的目的

来定义。例如，在目标导向对话的设定下，我们有一个明确的目标要实现，而在闲聊的设

定下，好的定义是对话的有趣程度。

于是，两个想法的结合应运而生：目标导向对话和基于 seq2seq 的生成。强化学习在此有

用武之地。机器每次发出的响应都只不过是在执行特定的操作。可以通过某种方式进行一

系列此类操作，以确保目标最终通过对话实现。在基于探索和挖掘的强化学习中，机器会

尝试学习用户定义的成长激励机制，以生成最佳响应，这与当前响应达成最终目标的可能

性直接相关。图 6-22 显示了基于 seq2seq 的经典模型与基于强化学习的模型的性能对比。

在图 6-22 的右侧，可以看到基于强化学习的模型生成了更多样化的响应，而不是机械地持

续输出通用的默认响应。

聊天机器人 ｜ 163

图 6-22：seq2seq 模型（左）与深度强化学习（右）的对比

6.6.3　人工监督

机器在没有人工干预的情况下可以生成所提出问题的答案。如果人类干预机器学习过程并

根据响应的正确性进行奖励或惩罚，则机器可能会提高其性能。这些奖励或惩罚可作为模

型的反馈。

回答自然语言查询通常需要遵循三个步骤：理解查询、执行操作和响应话语。与此同时，

机器在各种情况下可能需要进行人工干预，例如问题超出了聊天机器人的能力范畴，聊天

机器人执行了错误的操作，或者对查询的理解有误。人类干预机器的学习过程通常称为

“人工监督”。

Facebook 在聊天机器人的上下文中进行了一个实践：当机器人在强化学习的设定下学习

时，人工注入部分奖励。正如上一节中讨论的那样，机器人的最终目标是满足用户需求。

如图 6-23 所示，在人工监督下探索各种动作的同时，该机器人从人类“老师”那里获得了

额外的输入，从而明显提升了响应的质量。

图 6-23：人类在对话学习中提供额外的信号

与完全自动化的对话生成系统相比，人工监督终究是一种更实用的系统。端

到端模型的训练很高效，但是在生成实际正确的输出时可能并不可靠。因

此，结合端到端对话生成框架与人力资源的混合系统将更可靠和稳健。

164 ｜ 第 6 章

目标导向对话以及各种各样的技术至此就讨论完了，其中许多方法是由行业构建的，可在

实际环境中使用。这些端到端模型会因为参数而变大（由于用了新的 Transformer 架构），

所以无法在小型应用程序中部署。可以看到，即便是 LSTM 模型也可以生成合理的输出。

人工监督同样也是一种可行的技术，无论可用的算力是怎样的。

6.7 Rasa NLU

到目前为止，关于如何构建对话系统的两个主要组件已经讨论完毕：对话行为预测和槽位

填充。除了这两个组件之外，还需要一些集成步骤将它们整合成一个完整的对话流水线。

此外，还可以围绕这些组件构建封装逻辑，并为用户创建全面的对话体验。

构建这样一个完整的对话系统需要大量的工程。但好消息是，有可用的框架用于将自然语

言处理模型定制为系统的各个组件，并且框架还提供脚手架工具和支持，以构建可用的机

器人。Rasa 就是这样的框架，它提供一系列功能，这些功能对于构建行业应用聊天机器人

至关重要。图 6-24 显示了 Rasa 聊天机器人界面，以及将在后面讨论的交互式学习框架。

图 6-24：Rasa 聊天机器人界面和交互式学习框架

本节将简要介绍 Rasa 的可用功能，并讨论如何将其用于改善聊天机器人的用户体验。

基于上下文的对话

Rasa 框架允许用户捕获和利用对话上下文或状态。Rasa 在内部执行自然语言理解任务，

并捕获用于生成响应所需的插槽及其值。

互动学习

Rasa 提供了两种用途的交互式界面，一种是通过与机器人聊天为内置模型创建更多训

练数据，另一种是在模型出错时提供反馈。该反馈可用作模型的负例，以提升复杂场景

下的表现。

聊天机器人 ｜ 165

数据标注

Rasa 提供了一个高度可交互且易用的界面，使得人们可以标注更多数据以改善模型训

练。数据标注既可以从零开始，也可以更改现有模型已预测标签的示例。Rasa 的数据

标注步骤示例参见图 6-25。封装框架是基于 Rasa NLU 构建的，这简化了数据标注处理

以生成大规模对话数据集。Chatette 就是这样的框架，它接受模板，然后使用这些模板

生成大规模对话实例。

API

后端

RPA

图 6-25：数据标注和 API 集成

166 ｜ 第 6 章

API 集成

最后，对话服务还可以与其他 API 及聊天平台（如 Slack、Facebook、谷歌 Home 和亚

马逊 Alexa）集成。下一节中包含一个通过对话生成食谱推荐的案例研究，该案例集成

了多面搜索 API 端点到机器人，以改进推荐过程。

在 Rasa 中定制模型

除了框架之外，Rasa 还允许从模型库中挑选模型来定制模型。例如，对于意图 / 对话行

为检测，可以选择“sklearn 分类器”或“mitie 分类器”，或者自行实现分类器并将其添

加到构建流水线中以供 Rasa 使用。框架提供丰富的嵌入选项，例如 spaCy 和 Rasa 的内

置嵌入。

当构建单个组件时，还可以利用 Transformer 模型的能力以提升性能。Rasa 为分类和序

列标签任务提供了 BERT（以及各种精简版本以改善延迟）。总而言之，这使 Rasa 成了

从零开始构建对话系统的利器。

Rasa 允许以模块化方式构建聊天机器人。例如，可以从现有的预训练模型开

始，然后按需使用基于特定数据集构建的自定义模型。同样，可以从默认的

API 集成和对话频道开始构建，然后按需更改。

接下来看一个完整的真实案例研究，该案例在行业设定下讨论了从零开始创建对话系统的

必要步骤，包括数据准备、模型构建和部署。

6.8　案例研究：食谱推荐

厨师经常寻找适合自己烹饪和饮食偏好的特定食谱。一个用户体验良好的对话界面允许厨

师通过与智能体对话完善自己的偏好，以找到自己心仪的食谱。这个案例研究将讨论本章

介绍的所有组件，以及构建它们所需的框架。我们将看到对业务问题的数据和建模复杂性

不断增长的需求，并通过本章学到的各种工具解决这些问题。

假设我们负责开发一个食谱和菜品汇总网站。我们的任务是构建一个聊天机器人。用户可

以谈论他们渴望或想要烹饪的食物。这是一个未知的业务问题，那么我们将如何构建它？

图 6-26 显示了针对各种用户偏好的一些食谱建议示例。

我们需要将此业务问题转换为具有目标和约束条件的技术问题。当用户与系统交互时，我

们的目标是创建一个定义完善的查询，以获取合适的食谱。食谱可以来自 API 端点或生成

模型。该查询由一组定义菜式的属性构成，例如配料、食材、热值、烹饪时间等。用户可

以通过多轮对话透露自己的偏好，因此我们需要追踪他们的喜好，并且在对话进行时更新

内部对话状态。

聊天机器人 ｜ 167

图 6-26：食谱推荐网站示例

6.8.1　利用现有框架

我们将从 Dialogflow（本章前面介绍的云 API，因为它易于构建）开始。在开始前，需要

像以前一样定义实体，例如配料、食材、热值、烹饪时间。我们可以为烹饪领域构建本

体，并确定希望聊天机器人支持的槽位数。

最好在一开始保留这些实体的详尽清单。以下是一些训练实例的示例，这些实例在构建机

器人的早期捕获了细微差别。

• I want a low calorie dessert that is vegan.

• I have peas, carrots, and chicken in my kitchen. What can I make with it in 30 minutes?

Dialogflow 能够处理用户偏好，并确定查找正确食谱所需的插槽和值。此外，由于用户互

动的对话性质，机器人会维持对话状态或上下文，以完全理解用户的输入。假设已经预定

义和填充了一个食谱的数据库。一旦实体被机器人捕获，就需要将其输入到 API 端点。该

168 ｜ 第 6 章

端点会在数据库上进行多面搜索并检索排名最高的食谱。

随着我们收集更多的数据，Dialogflow 将逐渐变得更好。但是由于缺少定制的模型，它无法

解决和任务相关的更复杂的对话。一些基于 Dialogflow 的机器人最终失败的示例如下所示。

• I have a chicken with me, what can I cook with it besides chicken lasagna?

• Give me a recipe for a chocolate dessert that can be made in just 10 mins instead of the 

regular half an hour.

这些示例显示了一个槽位对应多个值且只有一个正确值的情况，例如“10 mins”是正确

的，而“half an hour”是错误的。在这种情况下，Dialogflow 基于匹配的方法将失败。因

此，我们需要定制模型，以便于将这些示例作为对抗示例添加到它们的训练流水线中。在

Rasa 定制模型的流水线中，我们可以添加诸如此类的对抗示例，使模型学习识别正确的槽

位及其值。也可以使用数据增强技术从我们收集的数据中生成此类对抗示例，并通过 Rasa

框架的数据标注技术引入它们，如图 6-27 所示。

图 6-27：Rasa 如何改善复杂的标注

借助这些更新的训练数据，新定制的模型能够选择正确的值，以充分描述用户对食谱的要

求。一旦捕获插槽和值后，其余过程将和之前类似（即 API 端点可以使用此信息来查询合

适的食谱）。

6.8.2　开放式生成聊天机器人

我们的解决方案已经好到足以部署到一个拥有数百万活跃用户的真实网站上。现在，我们

可以专注于解决更具挑战性的任务，以进一步改善用户体验。到目前为止，我们一直在为

聊天机器人 ｜ 169

用户提供预存储在数据仓储中的特定食谱。如果我们想通过生成食谱——而不是从现有食

谱池中搜索——来使聊天机器人更加开放，该怎么办？这种系统的优势是能够处理未知的

属性值并定制适合用户个性化口味的食谱。

开放式聊天机器人通常更难评估，因为对于给定的上下文，许多响应的变体

都可能是正确的。人工评估似乎更有效，但它是不可复制的，因此很难与其

他系统进行比较。自动与人工评估混合是评估生成对话系统的正确方法。

在这里，可以利用强大的 seq2seq 生成模型，它可以根据用户关于食谱偏好描述的各种所

需属性来定制生成。相关研究表明，这些 seq2seq 模型能够基于偏好和先前的食谱交互生

成个性化的食谱。这些模型能够整合细微差别，并有可能生成有效且针对用户个人烹饪口

味的新颖食谱。图 6-28 显示了这样一个结合用户偏好新生成的食谱示例。用户的偏好可

以只是他们之前交互过的食谱列表。例如，图 6-28 中，用户先前交互过 mojito、martini

和 Bloody Mary。个性化模型增加了一个额外的装饰步骤（以灰色突出显示），使其更具

个性。

图 6-28：根据用户偏好生成个性化食谱

将这些生成模型与其他对话组件合并可以真正改善用户体验。尽管我们讨论的只是一个特

定食谱推荐的问题，但类似的方法可以用于开发类似的应用程序。我们已经讨论了根据当

前业务问题构建机器人的必要工具和模型。我们从使用 Dialogflow 的非常简单的方法开

始，逐渐增加了更多复杂性，以解决用户可能在对话的细微差别中表达其查询和选择的问

题。最后，我们付出了更多的努力来构建端到端个性化的聊天机器人。

6.9　小结

本章讨论了聊天机器人及其在各个领域中的适用性。我们详细了解了一种流水线方法，并

深入研究了它的各个组件；讨论了具有云 API 的完全基于流的机器人，然后实现了自然语

言理解模块的机器学习组件；最后，分析了一个业务问题，并提供了一些逐步解决该问题

的途径。

170 ｜ 第 6 章

但关于对话系统和聊天机器人，还有许多挑战尚未解决。因此，这是自然语言处理社区中

非常热门的研究领域。除了学术研究之外，行业研究组织还在寻找现有方法的扩展解决方

案，以便可靠地构建聊天机器人并将其交付给用户。时至今日，许多行业聊天机器人仍然

不够稳健，并且遭受自然语言理解和自然语言生成问题的困扰。本章中提及了这些挑战，

以便你更全面地了解聊天机器人这个领域。

眼下构建对话系统的主要问题是缺少反映自然对话的数据集。很多时候，出于隐私原因，

无法收集个人数据。有时，缺少一个这样的对话界面同样会阻碍数据的收集。而且，现有

的数据集缺乏自然性，尤其是自称来自真实世界的数据集。这些数据集主要由在线标注者

创建，并且在大多数情况下，由于客观数据收集的性质，它们看上去像脚本。这个问题与

其他自然语言处理任务大相径庭。例如，与通过众包在线标注者进行标注相比，在分类任

务中为数据点标注正确的类或在信息提取任务中指出相关信息会更加客观，而且更容易实

现。在对话的场景下，任务通常是主观的，因此数据收集过程变得复杂。

此外，当前的生成模型还不足以生成事实正确的语句，这成了聊天机器人场景中的一个关

键问题。在对话的短时间内，生成事实错误的语句可能会损害对话的质量。因此，未来的

研究和行业的努力方向应该是，既要收集更好的具有代表性的数据集，又要改善可用于聊

天机器人流水线的自然语言理解和生成模型。

总而言之，我们从整个流水线开始讨论了对话系统的基础，然后使用 Dialogflow（一个云

API）开发了一个对话系统，并深入研究了用于理解对话上下文的模型的构建。最后，利用

它们完成了一个案例研究。我们预计该领域将持续发展和改善，而本章将是你适应不断涌

现的新解决方案的一个良好开端。第 7 章将介绍一些其他常见的自然语言处理问题场景。

聊天机器人 ｜ 171

第 7 章

主题简介

解决问题的方法不是提供新的信息，而是梳理我们早已知晓的一切。

——路德维希 • 维特根斯坦，《哲学研究》

到目前为止，本书的第二部分讨论了自然语言处理一些常见的应用场景：文本分类、信

息提取和聊天机器人（第 4~6 章）。尽管这些可能是我们在行业项目中遇到的最常见的自

然语言处理用例，但还有其他许多涉及大量文档的、关于构建真实应用的自然语言处理任

务。本章将粗略讨论其中一些主题。接下来先从几个基本无关但工作项目中可能会遇到的

场景开始。本章将更详细地讨论它们。

如果有人问自然语言处理是什么，我们却毫无头绪，那该从哪里开始说起呢？在互联网出

现之前，我们会去附近的图书馆做一些研究。然而，现在我们会先问搜索引擎。搜索涉及

许多使用自然语言的人机交互，因此它为自然语言处理带来了非常有趣的用例。

我们的客户是一家大型律师事务所。当新案件出现时，他们有时需要研究大量案件相关的

文件，以了解案件的全貌。很多时候，并没有充足的时间来进行全面人工检查。客户希望

我们开发能够快速概览大量文件集中讨论的主题的软件。主题建模是一种用于在大量文件

中查找潜在主题的技术。

同一客户的公司还有另一个问题：他们收到的案件报告文件通常很长，即使是经验丰富的

律师也很难迅速抓住重点。因此，客户想要一种自动创建文档摘要的解决方案。文本摘要

方法用于处理行业中诸如此类的用例。

许多人每天上网看新闻。许多新闻站点有“相关文章”的功能，该功能显示与当前阅读文

章局部相关的文章。考虑一个相关的场景：基于给定职位的资料描述推荐相关的职位。使

用自然语言处理的推荐方法是为此类用例构建解决方案的关键所在。

172

我们生活在一个日益多元化的世界中，许多组织在全球拥有客户或消费者。这带来了为组

织所支持的语言翻译（大规模）文档的需求。机器翻译在这种场景下很有用。像亚马逊、

Netflix 和 YouTube 这样的流媒体服务广泛地使用了机器翻译，生成各种语言的字幕。而谷

歌翻译之类的工具可帮助全球游客用当地语言进行交流。

搜索引擎在日常生活中的用处很多。有时我们想知道问题的答案。尝试用你喜欢的搜索引

擎问一个事实性问题，例如“谁写了《远大前程》”。谷歌搜索将“查尔斯 • 狄更斯”列为

最佳搜索结果，并提供关于他的传记详情，紧接着是其他常规搜索结果。尝试问一个描述

性问题，例如“我该如何安抚哭泣的婴儿”。在搜索结果中，你还会看到一些网站的宣传

内容中列出了多种使婴儿平静的方法。这是一个问答的示例，其任务是为用户查找最合

适的答案，而不是显示相关文档集合。请注意，这与第 6 章的 FAQ 聊天机器人略有不同，

其答案的范围限于较小的数据集（即 FAQ），而不是大量的文档（如 Web）中。

以上是本章将要讨论的主题。尽管它们看起来各不相同，但随着深入阅读，你会发现它们

之间的共同点。这些主题的列表并不是一个详情清单，但都是为行业应用开发基于自然语

言处理的解决方案时会遇到的一些常见场景。前四个任务（搜索、主题建模、文本摘要和

推荐）在实际应用的自然语言处理场景中更为常见，因此本章将更详细地讨论它们。机器

翻译和问答要处理的数据规模庞大，你几乎不可能遇到需要从零开发解决方案的场景，因

此本章仅简要介绍它们，以便你知道应从哪里开始快速构建 MVP。表 7-1 总结了本章覆盖

的主题，以及示例使用场景及其关联的的数据类型。

表7-1：本章覆盖的主题列表

自然语言处理任务 用途 数据类型

搜索 查找给定用户查询的相关内容 万维网 / 海量文档

主题建模 在一组文档中查找主题和潜在模式 海量文档

文本摘要 提炼文本中的重要内容，生成较短的摘要 通常是单个文档

推荐 显示相关文章 海量文档

机器翻译 从一种语言翻译成另一种语言 单个文档

问答系统 直接根据问题查询答案而不是文档 单个文档或海量文档

接下来开始按此列表逐个详细介绍这些主题。第一个主题是搜索和信息检索。

7.1　搜索和信息检索

搜索引擎是人们在线活动的重要组成部分。人们通过搜索信息以决定买什么商品、去哪一

家餐厅，以及经常光顾哪一家商店——这里仅举几个例子。人们还严重依赖搜索来筛选电

子邮件、文档和交易记录。这些搜索交互大多是通过文本（或语音输入转换的文本）进行

的。这意味着搜索引擎内部会进行许多自然语言处理。因此，可以认为自然语言处理在现

代搜索引擎中起着重要的作用。

让我们快速看一下搜索时发生了什么。当用户输入查询进行搜索时，搜索引擎将收集与查

询匹配的排好序的文档列表。为此，应先为文档及其使用的词汇构建“索引”，然后将其

用于搜索和结果排序。第 3 章介绍过的 TF-IDF 是搜索引擎用于文本数据索引和搜索结果

主题简介 ｜ 173

排序的一种常用形式。自然语言处理最新研究的深度学习模型也可用于此目的。例如，谷

歌最近开始使用 BERT 模型对搜索结果进行排序，并显示搜索摘要。他们声称这提升了搜

索结果的质量和相关性。这是自然语言处理在现代搜索引擎中发挥作用的重要示例。

除了存储数据和对搜索结果进行排序这一主要功能外，现代搜索引擎中的一些功能还涉及

自然语言处理。例如，图 7-1 所示的谷歌搜索结果的屏幕截图，它指出了某些使用自然语

言处理的功能。

图 7-1：谷歌搜索查询的屏幕截图

1. 拼写更正：用户输入了错误的拼写，搜索引擎提供正确拼写的建议。

2. 相关查询：“People also ask”（人们还在问）功能显示了人们对玛丽 • 居里的其他相关搜

索问题。

3. 摘要提取：所有搜索结果均显示涉及查询的文本摘要。

4. 传记信息提取：图 7-1 右侧有一个小片段，显示了玛丽 • 居里的传记详情，以及从文本

中提取的一些特定信息。还有一些引言，以及某些方面与之相关的人员列表。

5. 搜索结果分类：搜索结构顶部有分类选项卡：“All”（全部）、“Images”（图片）、

“News”（新闻）、“Videos”（视频）等。

在此可以看到，我们在本书中学到的一系列概念都在投入使用。虽然这些绝不是自然语言

处理在搜索引擎中的唯一用武之地，但它们是自然语言处理在搜索的用户界面发挥作用的

示例。然而，搜索引擎包含的内容比自然语言处理还要多，并且构建搜索引擎似乎是一项

庞大的工程，需要大量的基础设施。这可能会让人产生疑问：什么时候需要构建搜索引

擎，以及如何构建？我们是否总要构建像谷歌一样庞大的搜索引擎？为了回答这些问题，

下面来看两种场景。

一种场景是，假设我们为 Broad Reader 这样的公司工作。公司希望开发一个爬取全网论坛

和讨论区的搜索引擎，并让用户查询这大量的内容。再来考虑另一种场景：假设我们的客

174 ｜ 第 7 章

主题简介 ｜ 175

户是一家律师事务所，每天都会上传来自客户和其他合法来源的大量法律文件。我们被要

求为客户定制搜索引擎，以通过其数据库进行搜索。这两种场景有何不同？

第一种场景要求我们构建一个所谓的通用搜索引擎，在此我们必须建立一种方法来抓取不

同的网站，不断寻找新内容和新网站，并不断构建和更新“索引”。第二种场景是企业搜

索引擎的示例，我们不必寻找内容以构建索引。因此，这两种搜索引擎的区别如下。

• 通用搜索引擎：例如谷歌和必应，它们会在网上抓取内容，并通过不断寻找新的网页以

尽可能覆盖更多内容。

• 企业搜索引擎：搜索空间仅限于组织中规模较小的一组现有文档。

根据我们的经验，第二种搜索引擎是你在工作中会遇到的最常见的用例。因此，接下来我

们只讨论一些与企业搜索相关的基本组件来简要介绍通用搜索引擎。

7.1.1　搜索引擎组件

搜索引擎如何工作？有哪些基础组件？图 7-2 简要介绍了它们，该图取自 1998 年著名的谷

歌架构研究论文“The Anatomy of a Large-Scale Hypertextual Web Search Engine”。

网络服务器

文档索引

链接

词典

网页排名 搜索器

桶

排序器

索引器

仓库

存储服务器

爬虫

锚点

域名解析服务器

搜索引

擎优化

图 7-2：谷歌搜索引擎的早期架构

万维网

如图 7-2 所示，搜索引擎内部有几个大大小小的组件。这些组件分别介绍如下，其中前三

个主要组件可以视为搜索引擎的根基（第四个组件现在也很常见）。

爬虫

为搜索引擎搜索所有内容。爬虫的工作是通过一堆种子 URL 遍历整个网络，并以广度

优先的方式通过它们构建 URL 集合。它每访问一个 URL 都会保存其文档副本，检测外

链，然后将它们添加到紧接着要访问的 URL 列表中。设计爬虫的几个经典问题包括：

识别爬取内容、何时停止爬取、何时重新爬取、需要重新爬取什么，以及如何确保不

爬取重复的内容。根据以往的经验，即使必须开发某种通用搜索引擎（例如博客搜索引

擎），也不太可能需要自行设计爬虫。可以定制类似于 Apache Nutch 和 Scrapy 这种可用

于生产环境的爬虫，并应用到你的项目中。

索引器

解析和存储爬虫收集的内容并构建“索引”，以便对其有效地搜索和检索。虽然可以为

音频、视频、图像等构建索引，但文本索引是现实世界项目中最常见的索引类型。在

开发搜索引擎索引的数据结构时，请牢记需要快速有效地搜索爬取内容，以响应用户

查询。“倒排索引”是 Web 搜索引擎中流行的一种索引算法，它存储与词库中每个单词

相关的文档列表。和爬虫一样，你不太可能需要自行开发索引器。诸如 Apache Solr 和

Elasticsearch 之类的软件在行业中广泛地用来构建索引并用于搜索。

搜索器

搜索索引，并根据结果与查询的相关性，对用户查询的搜索结果进行排序。在谷歌或

必应上进行常规的搜索查询可能会得到成千上万条结果。作为用户，我们无法通过遍

历以手动确定结果是否与查询相关。因此搜索结果的排序变得很重要。根据本书到目

前为止所涉及的内容，一种直观的排序方法是获取结果文档的向量表示法和用户查询，

并基于某种程度的相似性对文档进行排序。实际上，正如本章一开始提到的那样，第

3 章详细介绍了 TF-IDF，并在第 4 章中将其用于文本分类，它是搜索及排序结果的一

种常用方法。

反馈

第四个组件，如今在所有搜索引擎中都很常见，用于跟踪和分析用户与搜索引擎的交互

（例如点击次数、搜索耗时，以及每个点击结果的浏览时长等），并将其用于持续改进搜

索系统。

希望通过上述简短的讨论，可以帮助读者快速了解经典搜索引擎的构成。信息检索本身就

是一个主要的研究领域，而搜索引擎的开发是一项涉及大量算力和基础设施的艰巨工程。

以上讨论的所有主题目前还没有完美的解决方案。本节仅概述了搜索引擎的工作方式，进

而引申出对自然语言处理的用途，以及如何开发自定义搜索引擎的讨论。感兴趣的读者可

以参考克里斯托夫 • 曼宁等人的著作《信息检索导论》1，这本书更详细地讨论了搜索引擎开

发背后的算法和数据结构。

注 1：此书已有中文版修订版，请访问 ituring.cn/book/2601。——编者注

176 ｜ 第 7 章

接下来让我们继续了解在工作中可能会遇到的经典搜索引擎流水线，以及到目前为止我们

学到的自然语言处理方法有哪些可以在该流水线中使用。

7.1.2　常见企业搜索流水线

假设我们为一家大型报社工作，并负责为其网站开发搜索引擎。前面已经提及 Apache Solr

和 Elasticsearch 通常用于这种场景。我们将如何使用它们？下面会逐步介绍使用方法，并

讨论在此过程中需要哪些自然语言处理工具。

爬取 / 内容抓取

爬虫在这种情况下不适用了，因为不需要来自外部网站的数据。我们需要一种从所有新

闻文章的存储位置（例如本地数据库或某个云存储）读取数据的方法。

文本标准化

一旦收集了内容，由于内容具有不同格式，因此需要先提取正文并丢弃其他信息（例如

报纸标题）。在向量化之前通常还需要执行一些预处理步骤，例如分词、大小写转换、

停用词删除、词干提取等。

构建索引

为了构建索引，必须将文本向量化。正如前面所讨论的，TF-IDF 是一种流行的方案。

但也可以像谷歌一样改用 BERT。怎样使用 BERT 实现搜索？可以使用 BERT 获取查询

和文档的向量表示法，并根据向量距离生成与给定查询的最接近的文档的排序列表。

除了为文章的全文构建索引之外，还可以为每个文档的索引添加其他字段 / 标签，然后用

这些标签进行搜索。例如，报纸可以属于新闻类别，并且加上和所在州有关的标签（例

如，为美国某地的新闻加上“加利福尼亚州”标签）等。如果有必要的话，第 4 章的文本

分类方法可用于获取此类类别和标签。在显示搜索结果时，可以将其与日期之类的过滤条

件结合使用，以增强用户体验。第 9 章有这种分类搜索的示例。

假设我们按照上述过程构建了搜索引擎，接下来该干什么？当用户输入查询时会发生什

么？这时候，流水线通常包括以下步骤。

1. 处理查询与执行：搜索查询通过上述文本标准化步骤来传递。一旦查询被处理，它就被

执行完毕，并且检索出根据某种概念的相关性进行排序的结果。诸如 Elasticsearch 之类

的搜索引擎库甚至还提供自定义评分函数，用于修改给定查询的检索文档的排序。

2. 反馈和排序：记录并分析用户的行为以评估搜索结果，并使它们与用户更相关，同时使

用诸如点击结果行为和结果页停留时长之类的指标来改善排序算法。学习读者偏好并向

他们显示个性化排序的推荐文章可能是报社案例的一个用例（例如，读者更喜欢阅读来

自某区的本地新闻）。

希望这个报社案例能够展示经典企业搜索引擎开发流水线的全貌。与许多软件应用一样，

机器学习领域的最新研究也影响了企业搜索。我们已简要提及 BERT 和其他基于嵌入的文

本表示法如何与 Elasticsearch 结合使用。亚马逊 Kendra 是基于机器学习的企业搜索引擎，

也是该领域的一个新作。

主题简介 ｜ 177

7.1.3　一个配置搜索引擎的例子

在了解搜索引擎的组件及其在示例场景中的应用方式之后，让我们快速看看怎么使用

Elasticsearch 的 Python API 构建小型搜索引擎。我们将使用一个图书摘要数据集，包含 500

个文档。内容已准备就绪，因此我们不需要爬虫。以一个不涉及额外预处理（例如，没有

词干）的简单用例为例，以下代码片段显示了如何使用 Elasticsearch：

# 使用图书摘要数据集构建索引

path = "../booksummaries/booksummaries.txt" 

count = 1 

for line in open(path): 

 fields = line.split("\t") 

 doc = {'id' : fields[0], 

 'title': fields[2], 

 'author': fields[3], 

 'summary': fields[6] 

 } 

 # 索引命名为myindex 

 res = es.index(index="myindex", id=fields[0], body=doc) 

 count = count+1 

 if count%100 == 0: 

 print("indexed 100 documents") 

 if count == 501: 

 break 

res = es.search(index="myindex", body={"query": {"match_all": {}}}) 

print("Your index has %d entries" % res['hits']['total']['value'])

该代码片段构建了一个索引，每个文档有 4 个字段（id、title、author 和 summary），这

些字段在数据集中都是可用的。一旦索引构建完成，它将运行查询以检查索引的大小。

在这种情况下，输出将显示 500 个条目。构建索引后，我们必须弄清楚如何使用它执行

搜索。尽管我们不会讨论搜索过程的应用接口设计，但以下代码片段说明了如何使用

Elasticsearch 进行搜索：

# 当查询包含多个使用match_phrase精确匹配的单词时，match查询用作OR查询。用法如下

while True: 

 query = input("Enter your search query: ") 

 if query == "STOP": 

 break 

 res = es.search(index="myindex", body={"query": {"match_phrase": 

 {"summary": query}}}) 

 print("Your search returned %d results:" 

 %res['hits']['total']['value']) 

 for hit in res["hits"]["hits"]: 

 print(hit["_source"]["title"]) 

 # 获取匹配结果前后100个字符的片段

 loc = hit["_source"]["summary"].lower().index(query) 

 print(hit["_source"]["summary"][:100]) 

 print(hit["_source"]["summary"][loc-100:loc+100])

178 ｜ 第 7 章

该代码片段不断询问用户输入查询，直到用户输入单词“STOP”，它才会显示搜索结果，

以及包含该搜索词的简短代码片段。例如，如果用户搜索单词“countess”，则结果如下

所示：

Enter your search query: countess 

Your search returned 7 results: 

All's Well That Ends Well 

71 

 Helena, the orphan daughter of a famous physician, is the ward of the Countess 

 of Rousillon, and ho 

... 

... 

... 

Enter your search query: STOP

Elasticsearch 具有许多功能：更改评估函数、根据查询公式更改搜索过程（例如精确匹配

与模糊匹配）、添加预处理步骤（例如在索引过程中提取词干）等。此处留给读者作为进

一步练习。 接下来看一个从零开始构建和改进企业搜索引擎的案例研究。

7.1.4　案例研究：书店搜索

想象这样一个场景：我们需要为一家新开张的专卖图书的网店构建搜索流水线。我们拥有

诸如作者、标题和摘要之类的元数据。我们之前学过的搜索功能可以作为起步的基础。可

以设置自己的搜索引擎后端，或使用诸如 Elasticsearch 或 Azure Elastic 的在线服务。

该默认搜索输出可能有很多问题。例如，它可能会显示与标题或摘要精确匹配的结果，

而不是相关性更高的非精确匹配结果。某些精确匹配结果可能是质量和评价都很差的

书，我们在搜索排名中并未考虑到这点。例如，考虑有关居里夫人的这两本书：Marie 

Curie Biography 和 The Life of Marie Curie。后者是玛丽 • 居里的权威传记，而前者是一本

评价很差的新书。但是，在搜索“marie curie biography”时，相关性较低的 Marie Curie 

Biography 的排名高于流行的 The Life of Marie Curie。

我们可以将解决此问题的现实指标纳入搜索引擎。例如，图书的浏览次数、销量、评论数

以及评分都可以纳入搜索排序功能。在 Elasticsearch 中，这可以通过使用评分函数和手动

选择权重（评分数、销量和平均评分）实现。因此，我们可能希望给销量赋予比浏览次数

更多的权重。随着越来越多的图书被出售和评论，这些启发式算法将提供更多相关结果。

当没有数据或数据有限时，这种手动定义搜索相关权重的方法可能是一个很好的起点。

我们应该开始收集用户与搜索引擎的互动，以进一步改善它。这些交互可以包括搜索词、

用户类型及其关于图书的操作。记录这种细粒度的搜索信息时，可以找到各种模式，例

如，搜索“science books for children”（儿童科普书）时，即使排名较低，科学家传记也能

获得较高的销量。随着时间的推移，我们可以从海量日志中学习相关性排名。可以使用诸

如 Elasticsearch Learning to Rank 之类的工具来学习此信息并提高搜索相关性。随着时间的

流逝，可以将更高级的技术（例如神经嵌入）整合到搜索查询分析。

随着收集到更多的用户信息，搜索结果也可以根据用户过去的偏好变得个性化。通常，此

类系统被构建为从搜索引擎检索的初始排名的上一层。

主题简介 ｜ 179

在构建高级搜索引擎的过程中要考虑的另一点是，保持对系统和数据的完全控制极其重要。

如果这样的搜索引擎不是你提供服务的核心部分，并且组织对数据共享更感兴趣，那么其

中许多功能也可以作为托管服务来提供。这些托管搜索引擎服务包括 Algolia 和 Swiftype。

由于搜索引擎的实现涉及自然语言处理以外的许多其他因素，并且它通常是给大规模数据

集使用的，因此本书并未展示涵盖搜索引擎所有方面的运行示例。但是我们希望这段简短

的介绍能帮助你了解如何开始开发涉及文本数据的定制搜索引擎，并简要概述到目前为止

所学的自然语言处理技术可能在其中发挥的作用。接下来继续讨论本章的第二个话题：主

题建模。

7.2　主题建模

主题建模是自然语言处理在行业用例中最常见的应用之一。从新闻文章到推文，从可视化

词云（请参阅第 8 章）到创建主题和文档的关系图，要分析这些不同形式的文本，主题模

型对于一系列用例都大有用处。主题模型广泛用于文档聚类和组织大量文本数据，也可用

于文本分类。

但什么是主题建模？假设我们收到了大量文档，并且想通过分析这些文档得出一些见解。

我们会怎样做？显然，任务定义不明确。鉴于文档数量太多，手动检查每个文档并不可

行。一种解决方法是提取一些最能描述语料的单词，例如语料库中最常见的单词。这称

为词云。好词云的关键是删除停用词。如果我们采用任何英语文本语料库并列举出现

最频繁的 k 个单词，我们将不会获得任何有意义的见解，因为最常见的单词将是停用词

（the、is、are、am 等）。在进行了适当的预处理后，词云可能会根据文档集产生一些有

意义的见解。

另一种方法是将文档分解为单词和短语，根据它们之间的某种相似性，将这些单词和

短语分组。由此所得的单词和短语集合有助于我们建立对语料的理解。直观来讲，如

果我们从每一组中选择一个单词，那么所选单词的集合在语义层面上概括了语料的大

体内容。还有一种可能的方法是使用 TF-IDF（请参阅第 3 章）。考虑一类语料，其中一

些文本是关于农业的。于是，“farm”（农场）、“crops”（农作物）、“wheat”（小麦）和

“agriculture”（农业）等术语应构成农业文本中的“主题”。要找到这些经常在某些文档

中出现，但在语料库的其他文档中很少出现的术语，最简便的方法是什么？

主题建模实现了这种直觉。它尝试识别文本语料库中存在的“关键词”（称为“主题”），

而无须事先了解它，这与使用正则表达式或基于字典进行关键词搜索的基于规则的文本挖

掘方法不同。图 7-3 显示了人文语料库的主题模型的可视化结果。

180 ｜ 第 7 章

主题简介 ｜ 181

图 7-3：主题建模可视化插图

在图 7-3 中，我们看到了通过主题模型获得的各个人文学科的关键字集合，以及某些关键

字在学科之间的重叠方式。这是一个说明如何使用主题模型发现大型语料库中主题的示

例。需要注意的是，并没有单一的主题模型。主题模型通常是指无监督的统计学习方法的

集合，以发现大量文本文档中的潜在主题。一些流行的主题建模算法包括隐含狄利克雷分

布（LDA）、潜在语义分析（LSA）和概率潜在语义分析（PLSA）。在实践中，最常用的技

术是 LDA。

LDA 有什么作用？让我们从一个玩具语料库开始。假设我们有一个文档集合 D1~D5，其中

的每个文档都只包含一个句子，如下所示。

• D1：I like to eat broccoli and bananas.

• D2：I ate a banana and salad for breakfast.

• D3：Puppies and kittens are cute.

• D4：My sister adopted a kitten yesterday.

• D5：Look at this cute hamster munching on a piece of broccoli.

182 ｜ 第 7 章

使用 LDA 在此集合上学习主题模型，可能会产生如下输出。

• Topic A：30% broccoli, 15% bananas, 10% breakfast, 10% munching

• Topic B：20% puppies, 20% kittens, 20% cute, 15% hamster

• D1 和 D2：100% Topic A

• D3 和 D4：100% Topic B

• D5：60% Topic A, 40% Topic B

因此，主题不过是具有概率分布的关键字的混合体，而文档是具有概率分布的主题的混合

体。主题模型仅提供每个主题的关键字集合。在 LDA 模型中，主题的确切含义和应命名

的内容通常由人类解释。在此，我们可以说主题 A“与食物有关”。同样，我们也可以说

主题 B“与宠物有关”。

LDA 如何实现这一目标？ LDA 假设所涉及的文档是由多个主题组成的。然后，它进一

步假设通过以下过程生成了这些文档：首先，有一个带有概率分布的主题列表。对于每

个主题，都有一个带有概率分布的相关单词列表。从主题分布中抽取 k 个主题。对于所

选的 k 个主题中的每个主题，从相应的分布中抽取单词。这就是生成文档集合中的每个

文档的方式。

现在给定一组文档，LDA 尝试回溯生成过程，而且先要弄清楚哪些主题会生成这些文档。

这些主题被称为“latent”（隐含）的，因为它们是隐藏的，而且必须被发现。LDA 如何进

行回溯？它通过分解文档术语矩阵（M）来做到这一点，该矩阵可以在所有文档中保留词

频数。它具有 m 行，由 m 个文档 D1

, D2

, D3

, …, Dm 构成；它具有 n 列，由语料库词汇表中

的所有 n 个单词 W1

, W2

, …, Wn 构成。M[i, j] 是文档 Di 中单词 Wj 的频率计数。图 7-4 显示

了这样一个虚拟语料库的矩阵，该语料库由 5 个文档组成，词汇表包含 6 个单词。

W1

D1

D2

D3

D4

D5

W2 W3 W4 W5 W6

图 7-4：文档矩阵（M）示意图

请注意，如果词汇表中的每个单词都代表一个唯一的维度，而总词汇表的大小为 n，则此

矩阵的第 i 行是一个向量，代表该 n 维空间中的第 i 个文档。LDA 将 M 分解为两个子矩

阵：M1 和 M2。M1 是文档主题矩阵，M2 是主题术语矩阵，分别具有维度 (M, K) 和 (K, N)。

对于 4 个主题（K1~K4），M 的子矩阵可能如图 7-5 所示。在这里，k 是我们想要查找的主

题数。

主题简介 ｜ 183

W1

K1

K2

K3

K4

W2 W3 W4 W5 W6

K1

D1

D2

D3

D4

D5

K2 K3 K4

图 7-5：因式分解矩阵示意图

主题数 k 是一个超参数。k 的最优值通过反复试错得出。

然后，可以使用这些子矩阵来了解文档的主题结构，以及组成该主题的关键字。我们已经

了解了如何训练主题模型，接下来就让我们了解如何构建一个主题模型。

7.2.1　一个构建主题模型的例子

我们已经了解 LDA 背后的原理，那么如何构建自己的主题模型？以下代码片段使用了之

前介绍过的图书摘要数据集，显示了如何使用 LDA 训练主题模型：

from nltk.tokenize import word_tokenize 

from nltk.corpus import stopwords 

from gensim.models import LdaModel 

from gensim.corpora import Dictionary 

from pprint import pprint 

# 分词、移除停用词、非字典词及小写化

def preprocess(textstring): 

 stops = set(stopwords.words('english')) 

 tokens = word_tokenize(textstring) 

 return [token.lower() for token in tokens if token.isalpha() 

 and token not in stops] 

data_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),data) 

summaries = [] 

for line in open(data_path, encoding="utf-8"): 

 temp = line.split("\t") 

 summaries.append(preprocess(temp[6])) 

# 创建一个文档的字典表示

dictionary = Dictionary(summaries) 

# 过滤不常用的词和热词

dictionary.filter_extremes(no_below=10, no_above=0.5) 

corpus = [dictionary.doc2bow(summary) for summary in summaries] 

# 为词典添加一个索引

temp = dictionary[0] # 只是为了加载词典

id2word = dictionary.id2token 

# 训练主题模型

model = LdaModel(corpus=corpus, id2word=id2word,iterations=400, num_topics=10) 

top_topics = list(model.top_topics(corpus)) 

pprint(top_topics)

如果我们浏览主题，会发现其中一个显示诸如“警察”“案件”“侦探”“证人”“线

索”“指控”之类的词。虽然主题本身不会在主题模型中显示名称，但在查看关键词时，

可以推断出该主题与侦探小说有关。

如何评估结果？给定 LDA 的主题词矩阵，按术语权重从高到低对每个主题进行排序，然

后选取每个主题的前 n 个术语。然后，测量每个主题中术语的一致性，本质上说，就是衡

量这些词彼此之间的相似度。另外，在此示例中，我们挑选了一些模型参数，例如迭代次

数、主题数等，并且没有进行任何微调。

与任何实际项目一样，在选择部署最终模型之前，都需要试验不同的参数和主题模型。

Gensim 关于 LDA 的教程提供了有关如何构建，调优和评估主题模型的更多信息。

删除低频词或仅保留名词和动词是优化主题模型的一些方法。如果语料库很

大，请将其分成固定大小的批次，然后为每个批次运行主题建模。最好的输

出来自每个批次的主题交集。

7.2.2　下一步是什么

既然我们知道了如何构建主题模型，那么该如何使用它呢？根据以往的经验，主题模型的

一些用例如下所示：

• 根据学习到的主题分布，以关键词的形式概述文档、推文等；

• 发现一段时间内的社交媒体趋势；

• 设计文本推荐系统。

同样，给定文档的主题分布可以用作文本分类的特征向量。

尽管行业项目中主题模型的使用案例很多，但是与它们的实践相关的挑战也很多。主题模

型的评估和解释仍然具有挑战性，目前尚无共识。主题模型的参数优化也可能花费大量时

间。在以上示例中，我们手动提供了主题数。如前所述，没有可以直接获取主题数的程

序。我们基于对数据集中主题的估计，使用多个值进行探索。要记住的另一点是，像 LDA

这样的模型通常仅适用于长文档，而对短文档（如推文集）的处理效果较差。

184 ｜ 第 7 章

尽管诸如此类的挑战很多，主题模型仍然是任何自然语言处理工程师工具集中的重要工

具，并且使用场景也更具有普适性。我们希望为你提供足够的信息，以助你在工作中确定

合适的用例。有兴趣的读者可以从开始更深入地研究该主题。让我们继续本章的下一个主

题：文本摘要。

7.3　文本摘要

文本摘要是指创建长文本摘要的任务。此任务的目的是创建一个相关的摘要，以捕获文本

的关键思想。快速阅读大型文档，仅存储相关信息并促进信息检索非常有用。作为文档理

解会议（Document Understanding Conferences）系列的一部分，世界各地的不同研究小组

从 2000 年初就积极开展关于自动文本摘要问题的自然语言处理研究。这一系列会议举办

了一些竞赛，以处理更大范围的文本摘要中的几个子任务。下面列出了其中的一些。

提取摘要与抽象摘要

提取摘要是指从一段文本中挑选重要的句子，然后将它们组合为摘要。抽象摘要是指生

成文本摘要的任务；也就是说，不是从文本中挑选句子，而是生成新的摘要。

基于查询的摘要与独立于查询的摘要

基于查询的摘要是指根据用户查询创建文本摘要，而独立于查询的摘要则创建常规

摘要。

单文档摘要与多文档摘要

顾名思义，单文档摘要是从单个文档创建摘要的任务，而多文档摘要是从文档集合创建

摘要的任务。

接下来我们将研究一些用例，以帮你了解如何将其应用于实际任务。

7.3.1　摘要用例

根据以往经验，文本摘要最常见的用例是单文档、独立于查询的摘要提取。这通常用于

为人类读者或机器创建长文档的简短摘要（例如，在搜索引擎中检索摘要而不是全文）。

在现实世界产品中使用这种摘要器的一个著名示例是 Reddit 的 autotldr 机器人，其屏幕

截图如图 7-6 所示。autotldr 机器人通过选择和排序帖子中最重要的句子来总结 Reddit 的

长文章。

主题简介 ｜ 185

图 7-6：Reddit autotldr 机器人的屏幕截图

本书作者之一在过去的工作中实现过的另外两个用例：

• 用于新闻文章的自动高亮语句显示器，用于为“摘要”语句（即捕获文本要点的句子）

着色，而不是创建完整的摘要。

• 文本汇总程序，仅对文档摘要而不是全文构建索引，目的是减少搜索引擎索引的大小。

你可能会在工作中遇到类似的实现文本汇总器的方案。让我们看一个示例，说明如何利用

现有库来实现单文档、独立于查询的提取摘要器。

7.3.2　一个设置摘要器的示例

该领域的研究探索了基于规则的、有监督的和无监督的方法，以及最新的基于深度学习的

体系结构。但是，现实场景中应用的流行提取摘要算法使用基于图的句子排序方法。根据

文档中句子之间的相互关系给每个句子打分，这在不同算法中的表现会有所不同。然后将

前 n 个句子作为摘要返回。sumy 是一个 Python 库，其包含几种流行的独立于查询的提取

摘要算法的实现。该库负责给定 URL 的 HTML 解析和分词，然后使用 TextRank 算法选择

最重要的句子作为文本摘要。

sumy 不是唯一具有这种汇总算法实现的库。另一个流行的库是 gensim，它实现了 TextRank

的临时版本。以下代码片段显示如何使用 gensim 的摘要器来概括给定的文本：

from gensim.summarization import summarize 

text = "some text you want to summarize" 

print(summarize(text))

186 ｜ 第 7 章

请注意，与 sumy 不同，gensim 没有附带 HTML 解析器，因此如果要解析网页，就必须

纳入 HTML 解析步骤。gensim 的摘要器还可以让我们试验摘要的长度。我们将继续探讨

sumy 的其他摘要算法，并进一步研究 gensim，以供读者练习。

现在我们了解了怎样在项目中实现摘要器。但在使用这些库来部署工作摘要器时，需要

牢记一些注意事项。接下来我们会探讨其中的一些事项，基于各种应用场景构建摘要器的

经验。

7.3.3　实用建议

如果遇到必须将摘要器部署为产品功能的场景，有些事情需要铭记在心。你大概率会使用

以上示例中的一种现成摘要器，而不是从零开始实现摘要器。但是如果现有算法不适合你

的项目场景或性能不佳，则可能必须开发自己的摘要器。使用自己的摘要器的另一个常见

原因是：你处于一个致力于推进摘要系统的最新技术发展的研发组织。因此，假设要使用

现成的摘要器，怎么比较各种可用的摘要算法，并选择最适合你的用例的算法？

在研究中，摘要方法是使用人工参考摘要的通用数据集进行评估的。面向召回摘要评估

的基本研究（ROUGE）是基于用于评估自动摘要系统的 n-gram 重叠的一组通用指标。但

是，此类数据集可能并不适合你的实际用例。因此，比较不同方案的最佳方法是创建自己

的评估集，或要求人工标注者根据相关性、摘要准确性等指标，对不同算法生成的摘要进

行评分。

部署摘要器时，需要牢记一些实际问题。

• 诸如句子切分（或上例中的 HTML 解析）之类的预处理步骤在输出摘要中是至关重要的。

大多数库内置句子切分器，但那些库可能会对不同的输入数据进行错误的句子切分（例

如，如果新闻文章中间引用了一段话怎么办？）。据了解，目前没有针对此类问题的一

站式解决方案，你可能需要针对在项目中遇到的数据格式定制解决方案。

• 大多数摘要算法对输入的文本大小很敏感。例如，TextRank 会运行多次，因此它可以

轻松利用大量计算时间以生成较大文本的摘要。当使用适合大文本分区的摘要器时，你

需要意识到这一限制。一种解决方法是在大文本的分区上运行摘要器，然后将摘要语句

串连在一起。另一种方法是针对文本顶部的 M％和底部的 N％而不是全文运行摘要器（假

设这些部分包含长文档的重点内容）。

摘要器对文本长度敏感。因此，对文本的选定部分运行摘要器可能更合适。

到目前为止，我们仅看到了提取摘要的示例。相比之下，抽象摘要更多是一个学术研究主

题，而不是行业实际应用。抽象摘要研究中经常出现三个有趣的用例：新闻标题生成、新

闻摘要生成和问答。深度学习和强化学习方法近年来已展示出一些有前景的抽象摘要研究

成果。由于该主题长期处于研究壁垒，并且研究人员局限于学术界，以及拥有专门 AI 团

队的组织，因此本书将不再对其详细讨论。不过，我们希望上述这些讨论能帮助你对自动

主题简介 ｜ 187

生成摘要有所了解，当你需要时，可以从一个 MVP 开始构建。现在，让我们看看另一个

有趣的自然语言处理的相关问题：文本推荐。

7.4　文本推荐系统

我们都很熟悉日常生活中浏览各个网站时看到的相关搜索结果、相关新闻文章、相关职

位、相关产品推荐以及其他类似功能，并且这些用户需求并不罕见。这些“相关文本”功

能是如何工作的？

新闻文章、职位描述、产品描述和搜索查询均包含大量文本。因此，在开发文本推荐系统

时，必须考虑文本内容以及不同文本之间的相似性或相关性。构建推荐系统的常用方法是

一种称为协同过滤的方法。它根据用户过去的历史以及过去的偏好配置向用户推荐相关内

容。例如，Netflix 的推荐大规模使用了这种方法。

如何基于文本之间的内容相似性来构建这个功能？构建这样一个基于内容的推荐系统，一

种方法是使用主题模型，就像我们在本章前面看到的那样。就主题分布而言，与当前文本

相似的文本可以显示为“相关”的文本。但是，神经文本表示的出现改变了显示该推荐的

方式。让我们看看如何使用神经文本表示来显示相关文本推荐。

7.4.1　一个图书推荐系统示例

我们已经看到了一些基于神经网络的文本表示形式的示例（第 3 章），以及其中一些是如

何在文本分类发挥作用的（第 4 章）。我们看到的演示文稿之一是 Doc2vec。以下代码片段

显示如何使用 Doc2vec、Python 库 NLTK（用于分词）和 gensim（用于实现 Doc2vec）实

现相关图书推荐：

from nltk.tokenize import word_tokenize 

from gensim.models.doc2vec import Doc2Vec, TaggedDocument 

# 阅读数据集的README以理解数据格式

data_path = "/DATASET_FOLDER_PATH/booksummaries.txt" 

mydata = {} #“标题–摘要”字典对象

for line in open(data_path, encoding="utf-8"): 

 temp = line.split("\t") 

 mydata[temp[2]] = temp[6] 

# 为doc2vec准备数据，构建并保存一个doc2vec模型

d2vtrain = [TaggedDocument((word_tokenize(mydata[t])), tags=[t]) 

 for t in mydata.keys()] 

model = Doc2Vec(vector_size=50, alpha=0.025, min_count=10, dm =1, epochs=100) 

model.build_vocab(train_doc2vec) 

model.train(train_doc2vec, total_examples=model.corpus_count, 

 epochs=model.epochs) 

model.save("d2v.model") 

# 使用模型查找相似文本

model= Doc2Vec.load("d2v.model") 

sample = """ 

188 ｜ 第 7 章

My first most vivid and broad impression of the identity of things seems to me to 

have been gained on a memorable raw afternoon towards evening. 

 """ 

new_vector = model.infer_vector(word_tokenize(sample)) 

sims = model.docvecs.most_similar([new_vector]) # 给出10个最相似的标题

print(sims)

这只是一个如何开发推荐系统的例子，而不是详细的分析。实施此类系统的最新方法

是使用 BERT 或其他类似模型来计算文档相似度。在本节的前面，我们还简要介绍了

Elasticsearch 中基于文本相似性的搜索方式——这是针对实际用例实现推荐系统的另一种

选择。我们将继续探索它们，作为读者的练习。

现在我们有了一个关于如何构建文本推荐系统的想法，让我们基于以往经验来研究一些有

关构建这种推荐系统的实用建议。

7.4.2　实用建议

我们只是看到了文本推荐系统的一个简单示例。这种方法适用于某些用例，例如推荐相关

新闻文章。但是，在许多需要提供更个性化的推荐或需要考虑其他非文本方面的条目的应

用中，我们可能不得不考虑文本之外的方面。Airbnb 中类似的列表推荐是这样的一个示

例，其将基于嵌入的神经文本表示与其他信息（例如位置、价格等）结合起来，以提供个

性化的推荐。

我们怎么知道推荐系统正在发挥作用？在现实项目中，推荐的影响可以通过效果指标来衡

量，例如用户的点击率、购买转化率（如果相关）、网站上的客户参与度等。在 A/B 测试

中，不同的用户群体可以用来比较不同推荐的效果指标。第三种（可能是比较耗时的）方

法是进行精心设计的用户研究，向参与者显示特定的推荐并要求他们进行评分。最后，如

果我们有一个小型测试集，其针对给定条目给予合适的推荐，我们可以通过将推荐系统与

此测试集进行比较来评估推荐系统。根据以往经验，这些指标与谷歌 Analytics 之类的分析

平台结合在一起用于评估行业推荐系统是有用的。

最后但并非最不重要的一点是：预处理决策在系统所提供的建议中起着重要作用。因此，在

采取某种方法之前，我们需要知道我们想要什么。在以上示例中，我们只是进行了简单的分

词。在现实世界中，将小写字母，去除特殊字符等作为预处理流水线的一部分并不罕见。

到此，我们结束了对文本推荐系统的概述。我们希望这能为你提供足够的信息，以助你在

工作中确定合适的用例并为其构建推荐系统。让我们转到本章的下一个主题：机器翻译。

7.5　机器翻译

机器翻译（MT）——将文本从一种语言自动翻译为另一种语言，是自然语言处理研究的

原始问题之一。早期的机器翻译系统采用基于规则的方法，这些方法需要大量语言学知

识，包括源语言和目标语言的语法，并且必须根据双语词典之类的资源来明确地编码。此

后机器翻译经历了数年的研究和应用程序开发，使用的统计方法依赖于不同语言之间的海

量并行数据。此类数据集通常是从将文本翻译成多种语言的资源中收集的。在过去五年

主题简介 ｜ 189

中，基于深度学习的神经机器翻译方法取得了爆炸性增长，这已成为研究和生产规模机器

翻译系统的最新技术。谷歌翻译是一个热门示例。但是，受限于构建它们所需的数据和资

源的数量，这种系统的研究和开发主要是由大型组织主导。

显然，机器翻译是一个很广阔的研究领域，构建机器翻译系统似乎是一个大工程。机器翻

译在行业中有哪些用处？以下是可能依赖机器翻译开发解决方案的两个示例场景。

• 我们客户的产品被来自世界各地的人们使用，他们在社交媒体上以多种语言发表评论。

客户希望了解这些评论大体上是积极的还是消极的。为此，使用机器翻译系统是取代寻

找多种语言的情感分析工具的一种选择。可以将所有评论翻译为一种语言，然后对该语

言进行情感分析。

• 我们会定期处理大量社交媒体数据（例如推文），并且注意到，此类文本与常见文档中

的文本不同。例如，考虑这个句子，“am gud”。将其改为正式的、格式正确的英语，应

该是“I am good”。（有关社交媒体文本与正常格式文本的区别，详情参见第 8 章。）机

器翻译可以将从“am gud”到“I am good”的转换处理为句子间的映射，也就是将非正

式的英文句子翻译为语法正确的英文句子。

尽管我们可能并不会开发自己的机器翻译系统，但在许多情况下，我们可能需要在自然语

言处理项目中实现机器翻译解决方案。那么，如果遇到类似的情况该怎么办？接下来看一

个如何在项目中搭建机器翻译系统的示例。

7.5.1　一个使用机器翻译API的示例

从零开始构建机器翻译系统是一项费时且费力的工作。为项目搭建机器翻译系统的另一种

常见方法：使用由大型研究组织（例如谷歌或微软）提供的按量付费的翻译服务 API，这

些 API 由先进的神经机器翻译模型提供支持。以下代码片段显示了如何使用 Bing Translate 

API（在通过注册获取订阅密钥和端点 URL 后）将英语翻译成德语：

import os, requests, uuid, json 

subscription_key = "XXXXX" 

endpoint = "YYYYY" 

path = '/translate?api-version=3.0' 

params = '&to=de' # 从英语到德语

constructed_url = endpoint + path + params 

headers = { 

 'Ocp-Apim-Subscription-Key': subscription_key, 

 'Content-type': 'application/json', 

 'X-ClientTraceId': str(uuid.uuid4()) 

} 

body = [{'text' : 'How good is Machine Translation?'}] 

request = requests.post(constructed_url, headers=headers, json=body) 

response = request.json() 

print(json.dumps(response, sort_keys=True, indent=4, separators=(',', ': ')))

此示例请求将英语句子“How good is Machine Translation?”翻译为德语。JSON 格式的输

出如下所示：

190 ｜ 第 7 章

[ 

 { 

 "detectedLanguage": { 

 "language": "en", 

 "score": 1.0 

 }, 

 "translations": [ 

 { 

 "text": "Wie gut ist maschinelle Übersetzung?", 

 "to": "de" 

 } 

 ] 

 } 

]

翻译后的德语句子为“Wie gut ist maschinelle Übersetzung?”。通过调用 Bing Translate API，

可以按需使用该服务。来自其他供应商的此类服务也可按此操作。在结束这一主题之前，

我们为想要将机器翻译整合到自然语言处理项目中的读者提供一些实用建议。

7.5.2　实用建议

首先，正如前面所解释的，如果没有必要，就不要自己构建机器翻译系统。使用翻译 API

是更切合实际的选择。使用此类 API 时，请务必注意收费政策。考虑到所涉及的成本，最

好存储常用文本的翻译（称为“翻译记忆库”或“翻译缓存”）。

维护翻译记忆库，该记忆库可用于高频重复的翻译。

当我们面对一种全新的语言，或者一个现有翻译 API 表现不佳的新领域时，一个好办法是

从基于领域知识、基于规则的翻译系统开始解决我们正在处理的受限问题。另一个办法是

通过“回译”增强训练数据来解决这种数据稀缺的问题。假设我们想将英语文本翻译成纳

瓦霍语。英语是机器翻译的流行语言，而纳瓦霍语并不是，但我们确实有一些英语翻译成

纳瓦霍语的例子。在这种情况下，我们可以在纳瓦霍语和英语之间构建机器翻译模型，然

后使用该系统将少量的纳瓦霍语句子翻译成英语。此时，可以将这些机器翻译后的纳瓦霍

语 – 英语对作为附加训练数据添加到英语 – 纳瓦霍语的机器翻译系统。这会增加翻译系统

的训练示例（即使其中一些示例是合成的）。但通常来说，如果翻译的准确性至关重要，

那么构建一个混合机器翻译系统可能是合适的，该系统将神经模型、规则和某种形式的后

处理结合起来。

数据增强是收集更多训练数据以构建机器翻译系统的有效方法。

主题简介 ｜ 191

机器翻译是一个广阔的研究领域，有专门的年度会议、期刊和数据驱动的竞赛，参与机器

翻译研究的学者和行业组织可以比较和评估他们的系统。此处的内容只是较为简单的介

绍，目的是让读者对这一主题有大致的了解。了解机器翻译的概述后，让我们继续本章的

下一个主题：问答系统。

7.6　问答系统

在使用诸如谷歌或必应之类的搜索引擎进行在线搜索时，对于某些查询，我们会看到“答

案”以及一系列搜索结果。这些答案可能是几个字，也可能是列表，抑或是定义。第 5 章

有关于此类查询的一些示例，以说明命名实体识别在搜索中的作用。现在让我们继续展开

这一话题。思考一下图 7-7，其中展示了使用谷歌搜索查询“who invented penicillin”的屏

幕截图。

图 7-7：关于查询“who invented penicillin”的屏幕截图

在此，搜索引擎将执行附加的问答和信息检索任务。以回答此类问题为目标，如果遵循先

前所述的搜索引擎流水线，则处理步骤如图 7-8 所示。

显然，自然语言处理在理解用户查询、确定问题和答案类型，以及在检索文档后确认答案

是否在给定文档中起着重要作用。

虽然这是大型通用搜索引擎的示例，但我们也可能遇到必须使用公司数据，或其他自定义

设定来实现内部消耗的问答系统的场景。前面 7.1 节中提到的流水线方法，可以引导我们

寻找这种场景下的解决方案。

192 ｜ 第 7 章

主题简介 ｜ 193

问题（标题）：Who invented penicillin?

问题分析

生成搜索查询

候选结果页

对候选答案评分并

提取答案

答案类型（第一个图例）：

person

关键词（第一个图例）：

invented, penicillin

答案：

图 7-8：答案提取

工作中可能还存在其他相对简单的问答场景。常见的场景是 FAQ 解答系统。第 6 章介绍

了它的工作原理。让我们根据本书作者之一以往的工作经验，简要讨论另一种场景。

7.6.1　开发自定义问答系统

假设我们需要开发一个问答系统，以回答用户所有有关计算机的问题。我们确定了一些带

有问答讨论的网站（例如 Stack Overflow），并且已配置好爬虫。我们如何开始构建问答系

统的第一个版本？构建 MVP 的一种方法是先研究网站的标签结构。通常，问题和答案会

使用不同的 HTML 元素进行区分。收集这些信息并专门使用它们来构建问答对的索引，可

以让我们为此任务开始构建问答系统。接下来，可以使用文本嵌入和 Elasticsearch 基于相

似度的搜索。

7.6.2　寻找更有深度的答案

在上述方法中，我们仍然希望用户问题与索引的问题和答案有大量的精确重叠。但是到目

前为止，我们在本书的不同内容中已经看到了基于深度学习的文本嵌入，它可以进行超精

确的匹配并捕获语义相似性。这种神经问答方法将问题的嵌入与文本的子单元（单词、句

子和段落）的嵌入进行比较，从而在文本中找到答案范围。使用深度神经网络的问答是一

个非常活跃的研究领域，通常使用针对此任务设计的特定数据集作为有监督的机器学习问

题进行研究。DeepQA 是 Allen NLP 的一部分——使用深度学习架构开发实验性问答系统

的流行库。

基于知识的问答是另一种方法，它依赖庞大的知识库以及将用户查询映射到知识库的方

法。这通常用于回答简短的事实性问题。像 IBM 沃森（在流行的智力问答节目 Jeopardy!

中击败了人类选手）这样的现实世界中的问答系统，结合了以上两种方法。Bing Answer 

Search API（允许订阅的用户向系统查询答案）是使用了这种混合方法的研究系统示例。

开发任何可在线建模更深度的知识问答系统，都需要大量数据、计算资源以及大量实验。

这在一家从事自然语言处理项目的传统软件公司中还不是常见的场景，因此本书不做进

一步讨论。如果想获得有关问答系统的历史概述以及最新的研究进展，建议阅读 Daniel 

Jurafsky 和 James H. Martin 的著作 Speech and Language Processing (3rd ed. draft) 的第 25

章。如果想为自己的数据集（例如组织中的内部文档）实现基于深度学习的问答系统，则

CDQA-Suite 之类的库可作为入门框架。

从以上讨论可以看出，问答是一种具有广泛的解决方案的搜索领域——从简单而直接的方

案（例如提取标签）到复杂的基于深度学习的解决方案。希望我们提供的概述可以为你在

工作中开发问答系统时可能遇到的用例提供足够的示例。

7.7　小结

本章介绍了自然语言处理如何在从搜索引擎到问答的一系列场景中发挥作用。我们看到了

如何将本书前面学习的一些主题用于解决这些问题。这些主题乍一看互不相同，但其中一

些也彼此相关。例如，搜索、推荐系统和问答都是某种形式的信息检索。甚至自动生成摘

要也是如此，因为我们从给定的文本中检索相关的句子。此外，除机器翻译外，所有其他

工具通常都不需要大型的带标注的数据集。因此这些主题之间有一些相似之处。请注意，

我们讨论的每个主题在自然语言处理中仍然是活跃的研究领域，并且每天都有很多新的发

现，因此本章中对主题的介绍并不详尽。但是，希望本章的概述能给你足够的知识基础，

以便你在工作中遇到相关的用例时可以轻松上手。

至此，我们已经到达本书第二部分“核心”的结尾。在第三部分“应用”中，我们将研究

所有这些不同的主题如何在特定领域中结合使用。

194 ｜ 第 7 章

第三部分

应用

第 8 章

社交媒体

时至今日，由于社交媒体的存在，我们不再需要讲英语。

——维尔 • 达斯

社交媒体平台（Twitter、Facebook、Instagram、WhatsApp 等）彻底改变了我们与个人、团

体、社区、企业、媒体的交流方式。这也改变了我们对传统规范和礼节的看法，以及企业

如何进行销售、市场营销、公共关系和客户支持等日常工作。鉴于社交媒体平台每天产生

海量、多样化的数据，人们投入大量精力开展智能系统的构建，以理解这些平台上的交流

与交互。由于社交媒体平台上的交流大部分以文本形式进行，因此自然语言处理在构建诸

如此类的系统中起着根本性的作用。本章将重点介绍如何将自然语言处理应用于社交媒体

数据分析，以及如何构建此类系统。

要了解这些平台生成的数据规模，请参考以下信息。

容量：Twitter 的每月活跃用户有 1.52 亿，而 Facebook 有 25 亿。

生产速度：每秒会产生 6000 条推文，以及 57 000 条 Facebook 帖子。

种类：主题、语言、样式、脚本。

图 8-1 的信息图显示了 2019 年不同平台每分钟产生的数据。

197

图 8-1：2019 年各类社交平台 1 分钟（60 秒）内产生的数据

鉴于以上信息，社交平台必然是非结构化自然语言数据的最大生成者。即使是其中的一小

部分数据，也无法做到手动分析。由于其中的大量内容是文本，因此推进数据分析的唯一

方法是设计基于自然语言处理的智能系统，该系统可以处理社交数据并提供分析结果。这

就是本章的重点。我们将介绍一些重要的商业应用，例如话题检测、情感分析、客户支持

和虚假新闻检测等。本章的大部分内容将涉及社交平台的文本与其他数据源之间的差异，

以及如何设计子系统以处理这些差异。先来看一些使用自然语言处理从社交媒体数据提取

见解的重要应用。

8.1　应用

各种各样的自然语言处理应用都使用了社交平台的数据，包括情感检测、客户支持和观点挖

掘等。本节将简要讨论一些热门应用，以使你了解如何基于自己的需求开始应用这些技术。

198 ｜ 第 8 章

热门话题检测

确定社交网络上当前最受关注的话题。热门话题告诉我们，吸引人们的内容是什么，以

及人们认为值得关注的是什么。这些信息对于媒体公司、零售商、急救人员等具有极其

重要的意义。这有助于他们调整与外界互动的策略。想象一下和特定地理位置相关的社

交媒体热门话题能带来哪些见解。

观点挖掘

人们经常使用社交媒体发表对产品、服务或政策的看法。收集并理解这些信息对于品

牌和组织而言具有巨大的价值。手动浏览成千上万条推文和帖子以理解大部分人的主

流观点是不可能的。在这种场景下，能够汇总成千上万条帖子并提取关键见解是非常

有价值的。

情感检测

到目前为止，关于社交媒体数据的情感分析可以说是自然语言处理在社交数据上最热

门的应用之一。品牌重度依赖来自社交媒体的信号，以更好地了解用户对其产品和服

务的看法，以及他们对其竞争对手的产品和服务的看法。品牌利用这一点来更好地了

解他们的用户，从使用情感检测确定其应该吸引的客户群，到了解其客户群体的长期

情感变化。

谣言 / 虚假新闻检测

鉴于社交网络发布信息的影响快而广，它们也可能被滥用于传播虚假新闻。过去几年曾

经发生过使用社交网络进行虚假宣传以影响舆论的案例。目前有大量关于理解和识别虚

假新闻及谣言的工作。这是控制这种威胁的预防和纠正措施的一部分。

成人内容过滤

社交媒体还遭受人们使用社交网络传播不当内容的困扰。自然语言处理被广泛用于识别

和过滤不当内容，例如不适宜向未成年人展示的内容。

客户支持

由于社交媒体的广泛使用及其公众可见度，社交媒体上的客户支持已发展为来自世界

各地的每个品牌不可或缺的服务。用户可以通过社交媒体表达对品牌的诉求。自然语

言处理被广泛用于对用户投诉的理解、分类、过滤、排序，某些情况下甚至可以自动

答复投诉。

除此之外，还有许多其他没有深挖的应用，例如地理位置检测、讽刺检测、事件和话题

检测、紧急情况感知等。这里的目的是让你了解使用社交媒体文本数据（social media text 

data, SMTD）构建的应用概况。

现在，让我们了解一下为什么使用 SMTD 构建自然语言处理应用程序时，无法直接应用目

前为止你从本书中所学的知识，以及为什么 SMTD 需要特殊处理。

8.2　独特的挑战

到目前为止，我们（隐式地）假设输入文本（大多数情况下，或总是）遵循任一语言的基

本原则，即：

社交媒体 ｜ 199

• 单一语言；

• 单一文字；

• 格式规范；

• 语法正确；

• 很少或没有拼写错误；

• 大多为文本形式（很少出现非文本元素，例如表情符号、图像、笑脸等）。

这些假设基本源于输入文本数据所来自的领域特性和特征。标准自然语言处理系统假设它

们处理的语言是高度结构化和规范化的。当涉及来自社交平台的文本数据时，以上大多数

假设是不成立的。这是因为用户在社交媒体上发布的信息文本可能会非常简洁。如此简

洁明了是社交媒体的标志性特征。例如，用户可以用“r”表示“are”，“v”表示“we”，

“lol”表示“笑哭了”等。这种简洁性催生了一种新的语言组合：一种极度非正式的语言，

包括非标准的拼写、话题标签、表情符号、新单词和首字母缩写词、代码混合、音译等。

这些特征使社交平台上使用的语言如此独特，以至于它被认为是一种新语言，即“社交平

台语言”。

因此，为标准文本数据设计的自然语言处理工具和技术无法与 SMTD 很好地结合使用。为

了更好地说明这一点，接下来我们看一些示例推文，如图 8-2 和图 8-3 所示。请注意，此

处使用的语言与报纸、博客、电子邮件、图书等使用的语言大有不同。

图 8-2：词汇中引入新单词的示例

200 ｜ 第 8 章

图 8-3：语言的新组合：非标准拼写、表情符号、代码混合、音译

这些差异给标准的自然语言处理系统带来挑战。接下来让我们详细了解主要区别。

不遵循语法

众所周知，任何一门语言都严格遵循语法规则。但是，社交媒体上的交谈不遵循任何语

法规则，其特点是标点符号和大写不一致（或不存在）、夹杂表情符号、拼写不正确或

不规范、多次重复相同的字符以及缩写词。与标准语言的这种区别使得基本的预处理步

骤（例如分词、词性标注和分句）变得困难。完成这些任务需要专用于 SMTD 的模块。

非标准拼写

大多数语言的任一单词只有一种书写形式，因此以其他形式书写同一个单词就属于拼

写错误。在 SMTD 中，同一个单词可以具有许多拼写形式。例如，请参考社交网络中

英文单词“tomorrow”的下列拼写方式——tmw、tomarrow、2mrw、tommorw、2moz、

tomorro、tommarrow、tomarro、2m、tomorrw、tmmrw、tomoz、tommmow、tmrrw、

tommarow、2maro、tmrow、tommoro、tomolo、2mor、2moro、2mara、2mw、tomaro、

tomarow、tomoro、2morr、2mro、tmoz、tomo、2morro、2mar、2marrow、tmr、tomz、

tmorrow、2mr、tmo、tmro、tommorrow、tmrw、tmrrow、2mora、tommrow、tmoro、

2ma、2morrow、tommw、tomm、tmrww、2morow、2mrrw、tomorow。自然语言处理

系统若想正常工作，就需要理解所有这些单词都指代同一个单词。

多语言

报纸或书刊的文章大多是用同一种语言编写的。很少能看到文章中的大段篇幅采用多种

语言。但在社交媒体上，人们经常混合使用多种语言。请参考以下来自社交媒体网站的

示例：

社交媒体 ｜ 201

Yaar tu to, GOD hain. tui

JU te ki korchis? Hail u man!

这两句话的意思：“兄弟，你是上帝。你在 JU 做什么？嗨，兄弟！”文本中混合了三

种语言：英语（普通字体）、印地语（斜体）和孟加拉语（粗体）。对于孟加拉语和印地

语，已经使用了音译。

音译

每种语言均以自己的文字书写，文字是指字符的书写方式。但是，人们经常在社交媒体

上混用文字来书写字符。这称为“音译”。例如，印地语单词“आप”（德瓦那加里文，

发音为“aap”）。在英语中，它的意思是“you”（你）。但人们经常将其写成罗马文字

“aap”。音译在 SMTD 中很常见，通常是由于打字界面（键盘）为罗马文，但交流语言

为非英语。

特殊字符

SMTD 的特点是存在许多非文本实体，例如特殊字符、表情符号、话题标签、颜文字、

静态图像和动图、非 ASCII 字符等，如图 8-4 所示。从自然语言处理的角度看，人们需

要预处理流水线中的模块处理这些非文本实体。

图 8-4：社交媒体数据中的特殊字符

不断发展的词汇

每一年，大多数语言很少在词汇中添加新词，甚至没有新词。但在社交语言中，词汇数

量以非常快的速度增加，几乎每一天都会冒出新词。这意味着任何处理 SMTD 的自然

语言处理系统都会遇到很多新词，而这些词未被包含在训练数据的词汇表中。这对自然

202 ｜ 第 8 章

语言处理系统的性能有不利影响，通常被称为“未登录词”（OOV）问题。

为了进一步了解此问题的严重性，请看图 8-5 所示的信息图。几年前我们进行了一项实

验，收集了大量推文，并逐月量化了“新词”的数量。图 8-5 显示了每个月的新词占

比。可以明显看出，与前一个月的词汇数量相比，每个月会产生 10%~15％的新词。

每月新词占比（%）

2014年1月

2014年2月

2014年3月

2014年4月

2014年5月

2014年6月

2014年7月

2014年8月

2014年9月

2014年10月

2014年11月

2014年12月

2015年1月

2015年2月

2015年3月

2015年4月

2015年5月

2015年6月

2015年7月

2015年8月

2015年9月

2015年10月

2015年11月

2015年12月

2016年1月

2016年2月

2016年3月

2016年4月

新词

图 8-5：每月新词占比

社交媒体 ｜ 203

204 ｜ 第 8 章

文本长度

与其他交流渠道（如博客、产品评论、电子邮件等）相比，社交媒体平台上的平均文本

长度要短得多。原因是较短的文本可以在保留可读性的同时快速键入。这主要是由于

Twitter 的 140 个字符的限制。例如，“This is an example for texting language”可能写为

“dis is n eg 4 txtinlang”。两者含义相同，但前者长度为 39 个字符，后者长度只有 23 个

字符。随着 Twitter 的普及和用户的增加，在社交平台上言简意赅已成为一种规范。这

种简练的写法变得非常流行，以至于现在几乎可以在所有非正式交流中看到，例如短消

息和在线聊天。

噪声数据

社交媒体帖子中充斥着垃圾邮件、广告、促销内容，以及各种其他不请自来、无关或分

散的内容。因此不能直接使用从社交平台获取的原始数据。过滤噪声数据是至关重要的

一步。例如，假设我们正通过抓取或使用 Twitter API，从 Twitter 或 Facebook 为自然语

言处理任务（例如讽刺检测）收集数据。务必确保没有垃圾邮件、广告或不相关的内容

混入数据集。

简而言之，与来自博客、图书的文本数据相比，来自社交媒体的文本数据是高度非正式

的，这种规范性的缺乏可以在上述各种方面中体现出来。所有这些因素都会对没有内置相

应处理方式的自然语言处理系统的性能产生不利影响。图 8-6 显示了不同文本数据规范性

的程度，以及文本数据的不同来源。

低 高

随意交谈 推文 博客

在线聊天、短消息、

Facebook评论

电子邮件 印刷文本：

文学作品、新闻

文件：

法律文书

图 8-6：不同数据源的文本数据中的规范性程度

由于社交语言的非正式性，将标准的自然语言处理工具和技术应用于 SMTD 时会遇到困

难。这样做依赖于将社交平台文本转换为标准文本（即规范化）或构建专用于处理 SMTD

的系统。下一节将介绍在构建各种应用程序时如何执行此操作。

识别、理解和解决 SMTD 中发现的语言特性很重要。构建可以处理这些特性

的子模块，通常对提高用于 SMTD 的模型的性能大有帮助。

接下来重点介绍使用 SMTD 构建商业应用程序。

8.3　用于社交平台数据的自然语言处理

现在，我们将深入研究如何将自然语言处理应用于 SMTD，以构建一些可用于解决各种

问题的有趣应用程序。例如，我们可能需要知道客户对我们发布的某些公告或产品有何反

响，或者需要能够识别用户群体特征。我们将从词云之类的简单应用程序开始，然后逐步

扩展到更复杂的应用程序，例如理解诸如 Twitter 这样的社交媒体平台帖子的情绪。

8.3.1　词云

词云是以图形方式捕获给定文档或语料库中最重要的单词。它不过是一张由单词（大小

不同）组成的图像，单词的大小与其在语料库中的重要性（频率）成正比。词云是了解

语料库中关键词的快捷方式。如果运行本书的词云算法，很可能会得到类似图 8-7 所示

的词云。

图 8-7：本书第 4 章的词云

与第 4 章中的其他单词相比，诸如 classification、data 和 text 之类的单词出现了更多次，因

此它们在相应的词云中突出显示。那么如何从一系列推文中创建词云？这个自然语言处理

流水线应该是怎样的？

以下是构建词云的步骤：

1. 为给定的语料库或文档分词；

2. 移除停用词；

3. 按频率降序对剩余单词排序；

4. 取前 k 个单词并“美观”地绘制它们。

以下代码片段说明了如何在实践中实现此流水线。为此，我们将使用一个名为 wordcloud

的库，该库内置生成词云的函数：

社交媒体 ｜ 205

 from wordcloud import WordCloud 

document_file_path = './twitter_data.txt' 

text_from_file = open(document_file_path).read() 

stop_words = set(nltk.corpus.stopwords.words('english')) 

word_tokens = twokenize(text_from_file) 

filtered_sentence = [w for w in word_tokens if not w in stop_words] 

wl_space_split = " ".join(filtered_sentence) 

my_wordcloud = WordCloud().generate(wl_space_split) 

plt.imshow(my_wordcloud) 

plt.axis("off") 

plt.show()

根据不同的样式，我们可以按需生成各种形状的词云，如图 8-8 所示。

图 8-8：同一个词云的各种形状

8.3.2　用于SMTD的分词器

上述过程的关键步骤之一是正确地为文本数据分词。为此，我们使用 twokenize 为文本语

料库分词。这是一个用于从推文数据提取词元的特定函数。该函数是专为 SMTD 设计的一

系列自然语言处理工具的一部分。现在你可能会问：为什么需要一个专用的分词器，而不

使用 NLTK 中可用的标准分词器？本书的第 3 章和第 4 章对此进行了简要讨论，但这个问

题值得我们再多花点时间。答案在于，NLTK 中可用的分词器是为标准英语设计的。英语

的特点是两个单词之间用空格分隔。但 Twitter 上使用的英语不一定是这样的。

这表明使用空格识别单词边界的分词器在 SMTD 上可能效果不佳。下面通过一个例子来理

解这一点。请看这条推文，“Hey @NLPer! This is a #NLProc tweet :-D”。理想的分词应该是

这样的：['Hey', '@NLPer', '!', 'This', 'is', 'a', '#NLProc', 'tweet', ':-D']。而使用诸如 nltk.tokenize.

word_tokenize 为英语设计的分词器，会得到以下分词：[Hey', '@', 'NLPer', '!', 'This', 'is', 'a', 

'#', 'NLProc', 'tweet', ':', '-D']。显然，由 NLTK 的分词器得到的分词是不正确的，使用提供正

确分词的分词器很重要。twokenize 就是专为 SMTD 设计的。

206 ｜ 第 8 章

一旦有了正确的分词集，就可以直接进行频率计数。有许多专门用于 SMTD 的分词器，其

中比较有名的是 nltk.tokenize.TweetTokenizer、Twikenizer、卡内基 – 梅隆大学 ARK 机器学

习研究项目组出品的 Twokenizer 和 twokenize。对于给定的输入推文，每个分词器可以得

到略微不同的输出。根据你的语料库和用例，选择能给你最佳输出的分词器吧。

接下来将介绍下一个应用程序，我们将用它尝试提取热门话题。

8.3.3　热门话题

就在几年前，追踪最新热门话题非常简单——拿起当天的报纸，通读新闻标题就行了。社

交媒体改变了这一点。由于平台流量巨大，热点可能在几小时内发生变化（经常如此）。

追踪每小时的热点对于个人而言可能并不那么重要，但对于企业而言可能非常重要。

如何追踪热门话题？用社交媒体的话来讲，任何围绕某个话题的对话通常都与话题标签关

联。因此，查找热门话题就是在给定的时间窗口内查找最受欢迎的话题标签。图 8-9 显示

了纽约地区热门话题的快照。

图 8-9：Twitter 热门话题的快照

如何实现一个可以收集热门话题的系统？一个最简单的方法是使用 Tweepy 的 Python 

API。Tweepy 提供了一个获取热门话题的简单函数——trends_available。它以 WOEID

（地球位置标识符）作为输入，并返回该地理位置的热门话题。当给定 WOEID 的热门信

息可用时，trends_available 函数会返回给定 WOEID 的前 10 个热门话题。该函数调用

响应的是表示“热门话题”的对象数组。在响应体中，每个对象都对以下信息进行编码：

热门话题的名称、可用于 Twitter 搜索的相应查询参数，以及 Twitter 搜索的 URL。唯一

的问题是 Tweepy 会限流，因为它是免费的 API。Twitter 对应用程序在给定的时间窗口内

对任意给定 API 资源进行的请求数施加了速率限制——你不能发出数千个请求。Twitter

的速率限制有详细的文档说明。在你需要致电咨询速率限制之前，可以先查看 Gnip——

来自 Twitter 的付费数据托管商。

接下来看看如何实现另一个热门的自然语言处理应用程序：使用社交媒体数据进行情感分析。

8.3.4　理解Twitter的情绪

当讨论自然语言处理和社交媒体时，情感分析可以说是最热门的应用程序之一。对于全球

的企业和品牌来说，倾听人们对它们及其产品和服务的评价至关重要。更重要的是，要了

社交媒体 ｜ 207

解人们的意见所包含的情绪是正面的还是负面的，以及这种两种情绪是否随着时间改变。

在社交媒体尚未出现的时代，这是通过客户调查（包括登门拜访）完成的。而今天，研究

社交媒体是了解人们对品牌看法的一种好方法。更重要的是，还能了解这种情绪如何随着

时间而改变。图 8-10 显示了给定的某一组织的情绪如何随时间变化。这样的数据可视化为

营销团队和组织提供了深刻的见解——剖析受众对他们的营销活动和事件的反响，有助于

他们为未来的营销活动和推广内容进行战略规划。

积极

中性

消极

图 8-10：追踪情绪随时间的变化

本节将聚焦于使用公共数据集为 Twitter 数据构建情感分析。

Twitter 的情感分析与第 4 章中所构建的情感分析模型有何不同？关键区别在于数据集。第

4 章使用了 IMDB 数据集，该数据集由结构良好的句子组成。而 Twitter 情感语料库的数据

则包含非正式编写的推文。这也就引申出了 8.2 节中所讨论的各种问题。这些问题反过来

又影响了模型的性能。一个很好的实验是在 Twitter 语料库上运行第 4 章的情感分析流水

线，并深入研究模型犯下的各种错误。我们将其留作给读者的练习。

接着构建情感分析系统并设置基线。为此，我们将使用 TextBlob——在 NLTK 和 Pattern 之

上构建的、基于 Python 的自然语言处理工具集。它包含一系列用于文本处理、文本挖掘和

文本分析的模块。只需 5 行代码即可得到一个基本的情感分类器：

208 ｜ 第 8 章

from textblob import TextBlob 

for tweet_text in tweets_text_collection: 

 print(tweet_text) 

 analysis = TextBlob(tweet_text) 

 print(analysis.sentiment)

这将为我们提供语料库中每条推文的极性值和主观性值。极性是 [–1.0, 1.0] 范围内的值，

表示文本的情绪是积极的还是消极的。而主观性是 [0.0, 1.0] 范围内的值，其中 0.0 表示非

常客观，1.0 表示非常主观。

它的实现很简单：对推文进行分词，并为每个词元计算极性和主观性。然后整合极性和主

观性的值，得出整个句子的值。读者可以自行了解更详细的信息。这个简单的情感分类器

可能无法很好地工作，主要原因是 TextBlob 的分词器。数据来自社交媒体，因此很可能不

会遵循英语语法规则。因此，分词后得到的许多词元可能不是英语词典中的标准单词，我

们无法得到此类词元的极性和主观性。

假设需要改进分类器，可以尝试在第 4 章所学的各种技术和算法。由于数据存在噪声（8.2

节中讨论过），因此性能可能不会有显著的提升。因此，改进系统的关键在于更好地清洗

和预处理文本数据。这对于 SMTD 至关重要。接下来将讨论 SMTD 预处理的一些重要部

分。至于流水线的剩余部分，可以遵循第 4 章讨论的流水线。

当使用 SMTD 时，预处理和数据清洗至关重要。此步骤可最大限度地提升模

型性能。

8.3.5 SMTD的预处理

大多数用于 SMTD 的自然语言处理系统具有丰富的预处理流水线，其中包括许多步骤。本

节将介绍处理 SMTD 的一些常用步骤。

1. 移除标签元素

标签元素（HTML、XML、XHTML 等）在 SMTD 中随处可见，因此移除它们很重要。使

用一个名为 Beautiful Soup 的库是一个很好的实现方式：

from bs4 import BeautifulSoup 

markup = '<a href="">\nI love <i>nlp</i>\n</a>' 

soup = BeautifulSoup(markup) 

soup.get_text()

这会输出 \nI love nlp\n。

2. 处理非文本数据

SMTD 通常包含各种符号、特殊字符等，并且通常采用拉丁编码和 Unicode 编码。为了理

解它们，将数据中存在的符号转换为易于理解的字符非常重要。这通常是通过转换为标准

社交媒体 ｜ 209

210 ｜ 第 8 章

编码格式（如 UTF-8）来完成的。以下示例显示了如何将整个文本转换为机器可读形式：

text = 'I love Pizza ! Shall we book a cab to get pizza?' 

Text = text.encode("utf-8") 

print(Text) 

b'I love Pizza \xf0\x9f\x8d\x95! 

Shall we book a cab \xf0\x9f\x9a\x95 to get pizza?'

3. 处理撇号

SMTD 的另一个特点是撇号的使用。诸如 ‘s、‘re、‘r 之类的情况很常见。处理此问题的方

法是扩展撇号。这需要一个可以将撇号映射为完整形式的字典：

Apostrophes_expansion = { 

"'s" : " is", 

"'re" : " are", 

"'r" : " are", ...} ## 给定此字典

words = twokenize(tweet_text) 

processed_tweet_text = [Apostrophes_expansion[word] if word 

 in Apostrophes_expansion else word for word in words] 

processed_tweet_text = " ".join(processed_tweet_text)

根据以往的经验，并没有现成的撇号及其扩展的映射可用，因此我们需要手动创建。

4. 处理表情符号

表情符号是社交媒体平台沟通的核心。一张小图像可以完整地表达一种或多种人类情感。

但是这为机器带来了巨大的挑战。如何设计可以理解表情符号含义的子系统？在预处理过

程中移除所有表情符号是一件蠢事。这可能会导致严重的语义缺失。

一种好的实现方式是用解释该表情符号的相应文本替换该表情符号。例如，用“fire”替换

“ ”。为此，需要在表情符号及其对应的文字说明之间构建映射。 Demoji 是一个为此而

生的 Python 包。它有一个 findall() 函数——给出文本中所有表情符号的列表及其相应的

含义。

tweet = "#startspreadingthenews yankees win great start by going 5strong 

innings with 5k's solo homerun with 2 solo homeruns 

and 3run homerun... with rbi's ... and 

to close the game !!!....WHAT A GAME!! " 

demoji.findall(tweet) 

{ 

 " ": "fire", 

 " ": "volcano", 

 " ": "man judge: medium skin tone", 

 " ": "Santa Claus: medium-dark skin tone", 

社交媒体 ｜ 211

 " ": "flag: Mexico", 

 " ": "ogre", 

 " ": "clown face", 

 " ": "flag: Nicaragua", 

 " ": "person rowing boat: medium-light skin tone", 

 " ": "ox", 

}

我们可以使用 findall() 的输出，将文本中的所有表情符号替换为具有相应含义的单词。

5. 连词拆分

SMTD 的另一个特点是，用户有时会将多个单词组合为一个词，其中单词的歧义消除是通

过大写字母来完成的，例如，GoodMorning、RainyDay、PlayingInTheCold 等。这很容易

处理。以下代码片段可以完成这项工作：

processed_tweet_text = " ".join(re.findall('[A-Z][^A-Z]*', tweet_text))

对于 GoodMorning，它将返回“Good Morning”。

6. 链接的移除

SMTD 的另一个常见特征是链接的使用。取决于应用的目的，我们可能想要将 URL 一并删

除。以下代码片段将所有 URL 替换为一个常量——constant_url。对于大多数简单的场景，

可以使用诸如 http\S+ 的正则表达式，而大多数场景下，我们必须编写如以下代码片段所示

的自定义正则表达式。这些代码很复杂，因为某些帖子包含短链接而不是完整链接：

def process_URLs(tweet_text): 

 ''' 

 replace all URLs in the tweet text 

 ''' 

 UrlStart1 = regex_or('https?://', r'www\.') 

 CommonTLDs = regex_or( 'com','co\\.uk','org','net','info','ca','biz', 

 'info','edu','in','au') 

 UrlStart2 = r'[a-z0-9\.-]+?' + r'\.' + CommonTLDs + 

 pos_lookahead(r'[/ \W\b]') 

 # 为了去除用例的间隔，使用*而不是+ 

 UrlBody = r'[^ \t\r\n<>]*?' 

 UrlExtraCrapBeforeEnd = '%s+?' % regex_or(PunctChars, Entity) 

 UrlEnd = regex_or( r'\.\.+', r'[<>]', r'\s', '$



') 

 Url = (optional(r'\b')

+ 

 regex_or(UrlStart1, UrlStart2) +

UrlBody + 

 pos_lookahead(

optional(UrlExtraCrapBeforeEnd) + UrlEnd)) 

 Url_RE

= re.compile("(%s)" % Url, re.U|re.I)

tweet_text = re.sub(Url_RE, " constant_url ",

tweet_text) 

 # 处理URL中的Unicode

URL_regex2 = r'\b(htt)[p\:\/]*([\\x\\u][a-z0-9]*)*' 

 tweet_text

= re.sub(URL_regex2, " constant_url ", tweet_text)

return tweet_text

7. 非标准拼写

在

社交媒体上，人们使用的

单词严格来说通常是拼

写错误的。例如，人们经常

多次复写

一个或多个字

符，如“yessss”或“ssssh”（而不是“yes”或“ssh”）。这种字

符复写在

SMTD 中很常见。以下

是解决此问题的一个简

单方法。我们遵循这个事

实：在英语中，几

乎没有单

词拥有连续三个相同的

字符。因此，我们根据这个

事实进行修剪：

def prune_multple_consecutive_same_char(tweet_text):

''' 

 yesssssssss is

converted to yes 

 ssssssssssh

is converted to ssh

''' 

 tweet_text = re.sub(r'(.)\1+',

r'\1\1', tweet_text) 

 return tweet_text

这会输出

yes ssh。

另一种方式是使用拼写

校正库。这些库大多数使

用了某种形式的距离度

量标准，例如编辑距

离，也

称为莱文斯坦距离（Levenshtein distance）。TextBlob 本身

具有一些拼写校正的能

力：

from textblob import TextBlob 

data

= "His sellection is bery antresting"

output = TextBlob(data).correct() 

print(output)

这会输出：His

selection is very interesting。

我们希望这

可以使你很好地理解为

什么预处理在 SMTD

的场景下

如此重要，以及如何实现

它。此处并未包含预处理

的完整步骤。 接下来我们

将聚焦于自然语言处理

流水线的下一步

（回到图

2-1）：特征工程。

8.3.6 SMTD的文本表示

之

前我们看到了如何使用

TextBlob

为推文创建简单的情感

分类器。现在尝试构建一

个更复

杂的分类器。假设

我们已经实现了之前部

分讨论的所有预处理步

骤。接下来该做什么？需

要

将文本分词，然后用数学

方式表示它们。我们使用

twokenize 进行分词，这是一个专用

于处理 Twitter 数据的分词器。如

何表示得到的词元？可以

尝试在第

3 章所学的各种

技术。

根据以往的经验，诸

如 BoW 和 TF-IDF

这样的基本向量化

方法不适用于 SMTD，主要是由

于噪声和文本数据的变

体（例如，本章前面讨论的

“tomorrow”的多种变体）。噪声和变

体

导致向量极其稀疏。这时

嵌入就可以派上用场了

。正如第 3 章所讨论的，自行

训练嵌入

的开销是非常

大的。因此，可以通过使用

预训练的嵌入开始构建

。第

4 章介绍了如何使用

谷

歌的预训练词嵌入来构

建情感分类器。现在，如果

我们在从社交媒体平台

收集的数据集

上运行相

同的代码，可能不会得到

同等优秀的指标。原因之

一可能是所用数据集的

词汇表

与 Word2vec

模型的词汇表

明显不同。为了验证这一

点，将文本语料库进行分

词，并在所

有词元上构建

一个集合，然后将其与 Word2vec 的

词汇表进行比较。以下代

码片段可实现

此目的：

212

｜ 第

8 章

combined = tokenizer(train_test_X)

# 从数据集创建词汇集

的一种方法

flat_list = chain(*combined)

dataset_vocab = set(flat_list) 

len(dataset_vocab)

w2v_vocab = set(w2v_model.vocab.keys()) 

print(dataset_vocab -

w2v_vocab)

在此，train_test_X 是来自

我们的语料库的训练和

测试模块的评论组合集

合。现在，你可

能会问：为什

么当我们使用电影评论

数据集时，情况并非如此

？原因是谷歌的 Word2vec

是使用维

基百科和新闻文章的文

本训练的。这些文章中使

用的语言和词汇类似于

电影评论

数据集中使用

的语言和词汇。但对于来

自社交媒体的数据集，情

况并非如此。因此，对于

来

自社交媒体的数据集而

言，集合的差异会很大。

那

么如何解决这个问题？有

以下几种方法。

1. 使用来自

社交数据的预训练嵌入

，例如斯坦福大学自然语

言处理小组的 GloVe。他们在

20 亿

条推文上训练了词嵌入

。

2. 使用更好的分词器。强烈

推荐 Allen Ritter

开发的 twokenize 分词器。

3. 训练

自己的嵌入。这是万不得

已时的选择，而且仅当你

有海量数据（至少 100

万 ~150

万条

推文）时才可行。即使训练

了自己的嵌入，性能指标

上也可能不会有显著的

提升。

根据以往的经验，如

果要使用基于单词的嵌

入，则前两种方法可以为

你的工

作投入带来最佳

的回报。

即使你在性能指

标上获得了可观的提升

，但随着训练数据和生产

数据之间的时间间隔不

断

增加，性能可能会持续

下降。这是因为随着时间

间隔的增加，训练数据和

生产数据的词汇

之间的

重合会不断减少。造成这

种情况的主要原因之一

是社交媒体的词汇表总

是在不断引

入新词，并且

缩略词源源不断地被创

造和使用。你可能会认为

新词偶尔会被添加一次

，但

是令人惊讶的是，事实

并非如此。图 8-11 显示了社交

媒体词汇的发展速度。图

的左侧显

示了每月中新

词的占比。该分析是在 27 个

月的时间内基于大约 200 万

条推文完成的。图

的中间

以条形图显示每月总词

数与新词数。图的右侧是

累积条形图。平均而言，每

个月约

20％的词汇是新词。

社

交媒体 ｜ 213

214 ｜

第 8 章

新词

2014年1月

2014年

2月

2014年3月

2014年4月

2014年5月

2014年6月

2014年

7月

2014年8月

2014年9月

2014年10月

2014年11月

2014年

12月

2015年1月

2015年2月

2015年3月

2015年4月

2015年

5月

2015年6月

2015年7月

2015年8月

2015年9月

2015年

10月

2015年11月

2015年12月

2016年1月

2016年2月

2016年

3月

2016年4月

每月新词占比（%） 2014年

1月

2014年2月

2014年3月

2014年4月

2014年5月

2014年

6月

2014年7月

2014年8月

2014年9月

2014年10月

2014年

11月

2014年12月

2015年1月

2015年2月

2015年3月

2015年

4月

2015年5月

2015年6月

2015年7月

2015年8月

2015年

9月

2015年10月

2015年11月

2015年12月

2016年1月

2016年

2月

2016年3月

2016年4月

2014年1月

2014年2月

2014年

3月

2014年4月

2014年5月

2014年6月

2014年7月

2014年

8月

2014年9月

2014年10月

2014年11月

2014年12月

2015年

1月

2015年2月

2015年3月

2015年4月

2015年5月

2015年

6月

2015年7月

2015年8月

2015年9月

2015年10月

2015年

11月

2015年12月

2016年1月

2016年2月

2016年3月

2016年

4月

新词（2012～2016年）

新词（2012～2016年）

总数 新

增

总数

新增

图

8-11：社交媒体

词汇发展速度的数据可

视化

这对我们而言意味

着什么？无论我们的词嵌

入多么出色，由于社交媒

体词汇的不断发展，

它终

将在几个月内变得过时

（例如，我们的词汇大部分

不会出现在我们的词嵌

入中）。这

意味着，当通过单

词查询嵌入模型以获取

其嵌入时，由于在训练嵌

入时查询词未曾出现在

训练数据中，它将返回空

值。这等同于所有这些单

词都被完全忽略了。反过

来，随着时间

的流逝，这将

大大降低我们的情感分

类器的准确率，因为越来

越多的单词终将被忽略

。

词嵌入并不是表示

SMTD 最好

的方法，尤其是当你需要

使用它长达 4~6 个月

或更久

时。

该领域的研究人员很

早就发现了这个问题，并

尝试了各种方法来规避

它。使用

SMTD 时处

理此持久性

未登录词问题，更好的一

种方法是使用字符的 n-gram 嵌

入。第 3

章和第 4 章介

绍 fastText 时讨

论了这个想法。语料库中

每个字符的

n-gram 表示都有一

个对应的嵌入。现

在，如果

该词出现在嵌入词表中

，那么我们将直接使用嵌

入词。如果不是（例如这个

词是

未登录词），那么我们

将该词分解为字符的 n-gram 表

示，并结合所有这些嵌入

以得出该词

的嵌入。fastText 具有

预训练的字符 n-gram 嵌入，但它

们并非特定于 Twitter 或

SMTD。研

究人

员还尝试了字符嵌入。

8.3.7　社

交媒体渠道的客户支持

从诞生之日起，社交媒体

已经发展成为一种交流

渠道。它的主要目的是帮

助全球各地的人

们建立

联系并表达自己的观点

。但社交媒体的广泛采用

已迫使品牌和组织重新

审视其交流

策略。一个很

好的例子就是品牌在

Twitter 和

Facebook 等社交平台上提供客户

支持。不过

品牌并不是一

开始就打算这样做的。

在

21 世纪第一个十年的开始

，随着社交平台的普及，品

牌开始创建和拥有

Twitter 域名

和

Facebook 主页之类的财产和资

产，主要是为了触达其客

户和用户，并开展品牌推

广和营销

活动。但是随着

时间的流逝，品牌总会收

到客户及用户的投诉和

抱怨。投诉和问题的与日

俱增促使品牌创建专用

的域名和主页用于处理

客户服务支持。图 8-12

显示了

Apple 公司和

美国银行的客户

服务支持页面。Twitter 和 Facebook 已推出

了各种功能以支持品牌

，而且

大多数客户关系管

理（CRM）工具提供了社交媒体

渠道的客户服务支持。品

牌可以将其社

交媒体渠

道与 CRM 工具绑定，并使用该

工具来响应站内消息。

图

8-12：Twitter 上品牌支持页的示例

由

于对话的公开性质，品牌

有义务迅速做出回应。但

是品牌的服务支持页流

量很大：其中

一些是真正

的问题、不满和诉求，通常

被认为是“可处理的对话

”，客户服务支持团队应

尽

快处理；另一大部分流量

是无关紧要的内容——促销

广告、优惠券、招聘信息、个

人观

点、骚扰信息等，通常

称为“噪声”，客户服务支持

团队无法处理，并希望避

开所有此类

消息。理想情

况下，他们只希望将可处

理的消息转为 CRM

工具的工

单。图 8-13 显示了区

别可处理

的消息与噪声的示例。

社

交媒体 ｜

215

可处理的消息

噪

声

图 8-13：区别可处理的消息

与噪声的示例

假设我们

在

CRM 产品组织中工作，我们

的需求是构建一个模型

，将可处理的消息与噪声

分离。怎么处理呢？识别噪

声与可处理消息的问题

类似于垃圾邮件分类问

题或情感分类问

题。可以

构建一个查看站内消息

的模型。该流水线和之前

非常相似：

1. 收集有标签的

数据集；

2.

数据清洗；

3. 预处理

；

4. 分词；

5.

词元表示；

6. 训练模型

；

7. 模型测试；

8.

模型上线。

本章

已从很多方面讨论了该

流水线。正如对 SMTD 进行情感

分析一样，这里的关键点

也是

预处理步骤。在此基

础上，我们准备继续本章

的最后一个主题：在社交

平台上识别有争议

的内

容。

8.4　模因与虚假新闻

社交

平台的用户以各种方式

共享各种信息和想法。这

些平台最初是被设计为

自治的。但随

着时间的流

逝，用户的行为已经超越

了社区规范，也就是所谓

的“网络暴力”。社交平台

的

大部分帖子充满了争议

性内容，例如骚扰信息、模

因、网络用语和虚假新闻

，其中一些

216

｜ 第 8 章

可能是宣

传，也可能只是为了好玩

。无论情况如何，都需要对

这些内容进行监管和过

滤。

本节将讨论如何研究

此类内容的趋势，以及自

然语言处理在其中的作

用。

8.4.1　识别模因

模因（meme，中文也

称为“梗”）是社交媒体用户

策划的最有趣的元素之

一，目的是传达

有趣或讽

刺的消息。这些模因在形

式上进行最低程度的更

改就可以重复使用，例如

“暴躁

的猫”的图像（如图 8-14），该

图像在许多场合下被配

合不同的文本使用。这类

似于理查

德 • 道金斯提出

的“基因”的原始概念。来自

Facebook 的 Lada Adamic

通过 Facebook 中这

些模因研究

了信息流，她声称“……通过手

动复制和粘贴机制传播

的模因可能是准确的，

它

们或许会包含突变（偶然

的或有意的修改）”。图 8-14

显示

了你可能遇到的两个常

见模因

的示例。

图 8-14：模因的

示例

在介绍理解模因趋

势的关键方法之前，我们

先讨论一下为什么理解

这些趋势很重要。网络

暴

力模因在像领英这样的

专业网络平台的动态信

息中泛滥是不可取的。与

此类似的还有

Facebook 或谷歌上

旨在传播与官方流程或

团体活动有关的通知或

信息的小组（例如，用

于募

捐活动的 Facebook 主页，或用于帮

助学生申请研究生学校

的谷歌小组）。识别那些可

能是嘲讽、人身攻击或违

反了其他小组或平台规

则的模因很重要。识别模

因的主要方式有

两种。

基

于内容

基于内容的模因

识别使用内容与已经被

其他模因识别的类似模

式进行匹配。例如，在

一个

社区中，“This is Bill. Be

like Bill”（见图 8-14）已经被识别

为模因。为了确定新

帖子

是否与其属于同一模板

，可以提取文本，并使用相

似性指标（例如杰卡德距

离）

识别有问题的内容。通

过这种方式可以识别出

这种模式的模因，“This is

PersonX. Be 

like PersonX”。在我们

运行的示例中，甚至连正

则表达式也能够从新帖

子中识别出此类

模板。

社

交媒体 ｜ 217

基于行为

基于行

为的模因识别主要是使

用帖子上的活动来完成

的。研究表明，模因的共享

行为从

其开始到随后的

几个小时都会发生巨变

。通常，可以通过分析特定

帖子的分享、评论和

点赞

数以识别病毒式传播的

内容。这些数值通常会超

出其他非模因帖子的平

均指标。这

多用于异常检

测领域。

我们已经讨论了

社交媒体中模因的基本

定义，并简要介绍了如何

识别或衡量模因的影响

。

现在让我们转向社交媒

体中的另一个重要且紧

迫的问题：虚假新闻。

8.4.2　虚假

新闻

社交平台上的虚假

新闻在过去几年中已成

为一个大问题。随着社交

平台用户数量增长，与

虚

假新闻有关的事件也显

著增加。用户编造虚假内

容，并在社交网络上不断

分享，导致虚

假新闻呈病

毒式传播。本节将介绍如

何使用到目前为止所学

习的自然语言处理技术

检测虚

假新闻。

来看一个

虚假新闻的示例：“彩票获

奖者因在前老板的草坪

上倒了 20

万美元的粪便而

被

捕。”这在 2018 年的 Facebook 平台上获

得了超过

230 万次分享。

各种

媒体机构和内容审核人

都在积极工作，以检测和

清除此类虚假新闻。有一

些原则性的

方法可以用

于解决这种威胁。

1. 使用外

部数据源进行事实验证

：事实验证涉及验证新闻

文章中的各种事实。可以

将其视

为一种语言理解

任务——给定一个句子和一

组事实，系统需要找出这

组事实是否支持这

个句

子中的主张。

假设我们可

以访问外部数据源，例如

维基百科（假设它是事实

正确的）。现在给定一条

新

闻文本，例如“爱因斯坦生

于 2000 年”，我们应该能够使用

由事实组成的数据源进

行

验证。请注意，一开始我

们不知道哪一条信息可

能是错误的，因此仅通过

模式匹配无法

轻松解决

这一问题。

亚马逊研究院

创建了一个精选的数据

集，用于处理自然文本中

存在的此类错误信息案

例。数据集的构成示例如

下：

{

"id": 78526, 

 "label": "REFUTES",

"claim": "Lorelai Gilmore's father is

named Robert.", 

 "attack": "Entity

replacement", 

 "evidence": [

[ 

 [<annotation_id>, <evidence_id>, "Lorelai_Gilmore",

3] 

 ]

] 

}

如你所见，我们可以开

发一个模型，以 {claim, evidence}

作为输入

并产生标签 REFUTES。

这更像是具

有三个标签的分类任务

：AGREES、REFUTES 和 NONE。证据集包含句子相关

实体

的维基百科链接，而

“3”表示在相应的维基百科

文章中具有事实正确的

句子。

218 ｜ 第 8 章

各个媒体公司

可以构建一个类似的数

据集，以从与其领域相关

的现有文章中提取知识

。

例如，体育新闻公司可能

会构建一套主要包含体

育相关事实的新闻集。

我

们可以使用基于 BoW 的方法

以同时表示主张（claim）和证据

（evidence），然后将

它们成对通过逻

辑回归以获得分类标签

。更高级的技术包括使用

深度学习方法（例如

LSTM

或预

训练的 BERT）来获得这些输入

的编码。然后我们可以将

这些嵌入连接起

来，并将

其传递给神经网络以对

声明进行分类。

2. 将虚假新

闻与真实新闻区分开：解

决此问题的简单方法是

使用虚假新闻和真实新

闻摘录

实例，构建并行数

据语料库，并将其分类为

真实的或虚假的。尽管方

法很简单，但机器

很难合

理地完成此任务，因为人

们使用的各种语言上的

细微差别可能会妨碍机

器标记虚

假内容。

哈佛大

学的研究员最近开发了

一个系统 GLTR，该系统可以识

别文本是人类写的还是

由

机器生成的（因此可能

是伪造的）。该系统使用统

计方法理解事实，并基于

这样的理解：

在生成文本

时，机器倾向于使用常用

词；这与人类不同，人类倾

向于使用更具体的词语

并遵循个人的写作风格

。这些方法表明，单词用法

的统计属性对于不同文

本通常可能有

明显的差

别，这可用于区分伪造文

本和真实文本。

AllenNLP 团队使用

了类似的技术，开发了一

个名为 Grover 的工具，该工具使

用机器

学习模型生成看

起来像是人工书写的文

本。他们利用生成的文本

中存在的细微差别理

解

人类所写文本的特征，然

后可以利用其构建有助

于检测潜在的机器生成

的虚假文章

的系统。

至此

，我们讨论了社交媒体的

两个关键问题：模因与虚

假新闻，并提供了有关如

何检测它

们的快速调查

。我们还讨论了如何将这

些问题作为简单的自然

语言理解任务（例如分类

）

来解决，以及解决这些任

务的潜在数据集可能是

什么样的。本节为你提供

了一个良好的起

点，以构

建可以识别社交媒体中

存在的恶意或虚假内容

的系统。

8.5　小结

本章首先概

述了自然语言处理在社

交媒体上的各种应用，并

讨论了社交媒体文本数

据为传

统自然语言处理

方法带来的一些独特挑

战。然后详细探究了不同

的自然语言处理应用程

序，例如构建词云、在 Twitter 上检

测热门话题、理解推文情

感、社交媒体的客户服务

支

持，以及模因和虚假新

闻的检测。我们还看到了

在开发这些工具时可能

遇到的一系列文本

处理

问题，并讨论了如何解决

这些问题。希望通过学习

本章内容，你已经很好地

理解了如

何在 SMTD 上应用自

然语言处理技术，并有助

于你解决在工作中可能

遇到的社交媒体文本

数

据的自然语言处理问题

。让我们继续学习第

9 章，探

讨另一个自然语言处理

技术已得到

广泛应用的

行业：电子商务。

社交媒体

｜ 219

第

9 章

电子商务与零售

今

天的新市场必须培育并

鼓励良性竞争才能茁壮

成长。

——杰夫 •

乔丹，硅谷 Andreessen Horowitz 风险

投资公司

当今世界，电子

商务已经成为购物的代

名词。与实体零售店相比

，更加丰富的顾客体验推

动了电子商务的增长。相

关统计数据显示，2019 年全球

零售电子商务销售额为

3.5

万亿美

元，预计 2022 年将达到

6.5 万亿美元。机器学习和自

然语言处理的最新进展

在电子商务的

快速增长

中发挥了重要作用。

访问

任何一家电子商务网站

的主页，很容易发现大量

文本和图像形式的信息

。这些信息的

很大一部分

由产品描述、评论等形式

的文本组成。零售商正在

大力推动这些信息的智

能化

利用，从而为顾客带

来惊喜，并建立竞争优势

。电子商务门户网站面临

着一系列与文本相

关的

问题，这些问题可以使用

自然语言处理技术来解

决。本书第二部分（第 4~7 章）介

绍了不同类型的自然语

言处理问题和解决方案

。本章将概述如何利用本

书中的知识来解决

电子

商务领域中的自然语言

处理问题。本章将讨论这

个领域中的一些关键自

然语言处理任

务，包括搜

索、构建产品目录、收集评

论和提供推荐。

图 9-1 显示了

部分电子商务任务。下面

先从总体概述开始。

220

电子

商务与零售 ｜ 221

电子商务

目

录

评论

分析

产品

搜索

产

品

推荐 产品发现

产品信

息

图 9-1：自然语言处理在电

子商务中的应用

9.1　电子商

务目录

任何大型电子商

务企业都需要一个简单

明了的产品目录。产品目

录是指企业自身经营的

或

用户可以购买的产品

的数据库。它包含每个产

品的产品描述属性以及

图像。好的产品描述

提供

了相关的信息，有助于顾

客通过目录选择正确的

产品。不仅如此，这些信息

还有助于

产品搜索和推

荐。设想这样一个推荐引

擎：它能自动知道你喜欢

蓝色。这就需要推荐引擎

注意到你最近购买或搜

索的大部分服装是蓝色

的。要实现这一点，首先需

要识别出“蓝

色”是产品的

颜色属性。自动提取此类

信息叫作属性提取。从产

品描述中提取属性后，每

个产品的所有相关信息

才能正确索引和显示，从

而提高产品的可发现性

。

9.1.1　评论分析

在电子商务平

台中，最值得注意的部分

是每个产品的用户评论

区。用户评论提供了观察

产

品的不同视角，例如质

量、易用性、产品比较以及

物流反馈等，这些都不能

从产品属性中

直接获得

。但是并非所有的评论都

是有用的，也并非所有的

评论都来自可信用户。而

且，

如果产品有多个评论

，也很难手动处理。因此，利

用自然语言处理技术可

以执行情感分

析、评论摘

要、识别评论有用性等任

务，使我们能以整体视角

来看待各种评论。第 5

章在

讨论关键词提取时介绍

了一个使用自然语言处

理进行评论分析的例子

。本章后面还将介绍

其他

用例。

9.1.2　产品搜索

电子商务

中的搜索系统与谷歌、必

应和雅虎等通用搜索引

擎不同。电子商务搜索引

擎往往

和提供的产品及

其各种相关信息紧密绑

定。常规的搜索引擎主要

处理无结构的文本数据

，

如新闻文章或博客等，而

电子商务搜索引擎主要

处理结构化的销售数据

和评论数据。如果

搜索“红

色格子婚礼衬衫”，电子商

务搜索引擎应该能够找

到它。这类目标明确的搜

索也

可以在爱彼迎和 TripAdvisor 等

机票和酒店预订网站上

看到。不同类型的电子商

务业务具

有不同的信息

特性，因此信息处理、提取

和搜索的流水线需要定

制。

9.1.3　产品推荐

没有推荐引

擎，任何电子商务平台都

是不完整的。顾客喜欢智

能的平台：理解顾客的选

择，并给出产品购买建议

。实际上，这有助于顾客厘

清购物思绪，并更好地利

用平台来购

物。推荐打折

商品、同品牌的产品或具

有受欢迎属性的产品，可

以真正吸引顾客，让他们

花更多的时间在网站上

。这直接增加了顾客购买

这些产品的可能性。除了

基于事务的推荐

工具之

外，还有很多算法是基于

产品内容和产品评论等

文本信息开发的。可以使

用自然语

言处理技术来

构建这样的推荐系统。

以

上是各项任务的概述，下

面来详细探讨自然语言

处理在电子商务中扮演

的角色。先从如

何使用自

然语言处理构建电子商

务搜索引擎开始。

9.2　电子商

务中的搜索

顾客访问电

子商务网站的目的是快

速找到并购买他们想要

的产品。在理想情况下，搜

索功

能应该使顾客以最

少的点击次数找到正确

的产品。搜索必须快速、准

确，返回的结果必须

与顾

客的需求相吻合。好的搜

索机制会对转化率产生

积极的影响，而转化率将

直接影响零

售商的收入

。在全球范围内，平均只有

4.3% 的搜索尝试可以转换为

购买行为。据估计，

在排名

前 50 位的门户网站中，34%

的搜

索结果是没用的，因此这

里通常还有很大的改进

空间。

第 7 章讨论了通用搜

索引擎的工作原理，以及

自然语言处理在其中的

作用。然而，对于电

子商务

，搜索引擎需要根据业务

需求进行更精细的调整

。电子商务中的搜索是封

闭领域

的，即搜索引擎通

常从产品信息中获取结

果，而不是像谷歌或必应

那样从开放网络上的通

用文档或内容中获取结

果。隐含的产品信息可以

通过产品目录、属性和评

论构建。搜索则

是基于颜

色、款式或类别等产品信

息的不同方面进行的。电

子商务中的这种搜索通

常叫

“多面搜索”，也是本节

的重点。

多面搜索是搜索

的一种特殊变体，它允许

顾客使用筛选器进行流

畅的导航。例如，如果计

划

购买一台电视，那么顾客

可能会寻找品牌、价格和

尺寸等筛选器。在电子商

务网站中，

根据产品的不

同，用户可能会看到一组

搜索筛选器。图 9-2

和图 9-3 分别

展示了亚马逊和

沃尔玛

的电子商务搜索页面。

图

9-2 和图

9-3 的最左边都显示了

一组筛选器（亦称为“面”），这

样顾客就可以根据自己

的购买需求来进行搜索

。图 9-2 显示了电视产品的搜

索，因此筛选器包括分辨

率和显示尺

寸等方面。除

了这些自定义的筛选器

之外，很多产品搜索还用

到了一些通用的筛选器

，如

品牌、价格范围和送货

方式等，如图

9-3 所示。这些筛

选器是感知产品的显式

维度。这种

引导式搜索让

用户能够自行安排搜索

结果，从而对购物有更多

的掌控，而不是在大量搜

索

结果中逐条过滤出自

己想要的东西。

222 ｜

第 9 章

图 9-2：亚

马逊网站的多面搜索

图

9-3：沃尔玛网站的多面搜索

电子商务与零售

｜ 223

这些筛

选器是定义多面搜索的

关键。然而，并非所有的产

品都能轻易获得这些筛

选器。原

因如下。

• 卖家在电

子商务网站上架产品时

没有上传所有必需的信

息。特别是当一家新的电

子商务

企业迅速发展，并

积极推动各种卖家快速

加入时，通常会出现这种

情况。为了推动卖家

快速

加入，电子商务企业通常

允许卖家在没有对产品

元数据进行质量检查的

情况下就上

架产品。

• 有些

筛选器很难获得，或者卖

家无法提供完整的信息

。例如，食品的热值通常是

从产品

包装上提供的营

养信息中获得的。电子零

售商并不指望卖家能够

提供这些信息，但这些

信

息是至关重要的，因为这

些信息可能捕捉到产品

销售过程中的重要顾客

信号。

多面搜索可以使用

Solr、Elasticsearch 等常见的搜索引擎后端

来构建。除了常规的文本

搜

索之外，不同的面属性

也可以添加到搜索查询

中。Elasticsearch 的 DSL

还带有内置的多面

搜索接口。

在电子商务场

景中，除了“面”和文本的相

关性之外，还需要考虑业

务需求。

例如，促销或减价

产品可能会带来销量的

增加。这可以通过使用 Elasticsearch 

Boosting

等

功能来实现。

除了搜索算

法之外，多面搜索还有许

多其他相关的微妙之处

，本章后面将重点讨论。之

前

提到的问题与下一节

要讨论的问题有关：构建

电子商务目录。

9.3　构建电子

商务目录

正如本章前面

所介绍的，构建信息目录

是电子商务中的主要问

题之一。它可以分为几个

子

问题：

• 属性提取；

• 产品分

类和分类树创建；

•

产品浓

缩；

• 产品去重和匹配。

下面

来一一介绍。

9.3.1　属性提取

属

性是指那些能够定义产

品的特征。例如，图 9-2 所示的

品牌、分辨率、尺寸等都是

电视

的相关属性。在电子

商务网站上准确显示属

性，有助于提供产品的完

整概述，以便顾客能

够根

据了解的情况做出选择

。丰富的属性可以直接提

高点击量和点击率，进而

影响产品的

销量。图

9-4 显示

了一个例子：通过若干筛

选器或属性可以获得产

品描述。

224 ｜ 第 9

章

图 9-4：通过若干

筛选器或属性获得产品

描述

可以看出，对于顾客

而言，服装、颜色、尺码等属

性基本上定义了一件产

品。每个属性都

可以有多

个值，如图 9-4

所示。在本例中

，颜色有七个值。然而，直接

从卖家那里获得所

有产

品的属性是很困难的。而

且，属性的质量还应足够

一致，只有如此，顾客才能

获得产

品的相关正确信

息。

传统上，电子商务网站

采用人工标注或众包技

术来获取属性。这通常由

第三方公司或众包

平台

（如 Mechanical

Turk）来完成——平台提出关于

每种产品的具体问题，众

包人员需要

回答这些问

题。有时候，为了将答案限

定在一定范围内，问题需

要以多选题的方式设计

。

但是，这种方式往往成本

很高，而且不能随着产品

数量的增加而扩展。这时

就需要使用

机器学习技

术。由于属性提取需要理

解产品信息的上下文，因

此它是一项具有挑战性

的任

务。例如，图 9-5

显示了两

个产品描述。

“粉红”（Pink）既是年

轻女性中的流行品牌，也

是常见的服装颜色。因此

，在第一种情况

下，“粉红”是

品牌名称，而在第二种情

况下，“粉红”只是一种颜色

。如图 9-5 所示，背

包的品牌为

“粉红”，颜色为霓虹红，而运

动衫的颜色为“粉红”。像这

样的情况是普遍存

在的

，因此对计算机来说，这是

一项具有挑战性的任务

。

如果能以某种结构化数

据格式获得属性集，那么

搜索机制就可以根据顾

客需求准确地利用

属性

集来检索结果。从各种产

品描述中提取属性信息

的算法通常称为属性提

取算法。这些

算法将一组

文本数据作为输入，并生

成“属性 – 值”对作为输出。属

性提取算法分为直接

和

间接两种类型。

电子商务

与零售 ｜ 225

图 9-5：“粉红”（Pink）是两个不

同属性的属性值

直接属

性提取算法假定输入文

本中已经存在属性值。例

如，“索尼 XBR49X900E 49 英寸

4K 超高清智能

LED

电视（2017 款）”就包含“索尼”品牌

。在大多数情况下，品牌通

常

是产品名称中的一个

属性。相比之下，间接属性

提取算法则不会假定输

入文本中存在相关

属性

。算法需要从语境中获取

这些信息。性别就是这样

一种属性，通常不会出现

在产品标

题中，但算法可

以从输入文本中间接识

别出产品所针对的性别

。考虑这样一条产品描述

，

“YunJey

短袖圆领三色条纹 T 恤休

闲衬衫”。该产品是为女性

设计的，但产品描述或标

题中

没有明确提及“女性

”性别。在这种情况下，必须

从产品描述等文本中推

断性别。

226 ｜

第 9 章

1. 直接属性提

取

通常，直接属性提取可

以建模为序列到序列的

标注问题。序列标注模型

的输入是一个序

列，例如

词序列，输出也是一个相

同长度的序列。第 5 章简要

介绍了此类问题。这里沿

用

类似的方法，来看看直

接属性提取算法是如何

工作的。

图 9-6

显示了训练数

据的格式，例如某产品名

称为“The Green Pet Shop Self Cooling

Dog 

Pad”。

图 9-6：用于直接属性提

取的训练数据格式

这里

需要提取的是“The

Green Pet Shop”，它由“-attribute”标签

表示，其余部分由“O 

(Other)”标签表

示。无论何种直接属性提

取方法，都需要获得 BIO

格式

的标注数据。此

外，还应该

拥有代表各种类别（例如

，B-Attribute1、B-Attribute2 等）的数据。

收集这些数据

通常有两种方法。一种简

单的方法是在现有的文

本描述（含品牌和属性）中

使用正则表达式，并使用

该数据集。这类似于弱监

督。另外，也可以由人工标

注员标注部

分数据。有了

标注好的数据，就需要提

取丰富的特征集来训练

机器学习模型。在理想情

况

下，输入特征应能捕捉

属性特征以及位置信息

和上下文信息。下面列出

了可以捕获这三个

方面

的一些特征。不妨按照类

似的思路开发更复杂的

特征，并分析它们是否有

助于提高性

能。此任务的

一些常见特征如下。

字符

特征

字符特征通常是基

于词的特征，例如词的大

小写、词的长度及其字符

组成等。

位置特征

位置特

征用于捕捉输入序列中

词的位置方面的特征，例

如当前词之前的词的数

量，或词

的位置与序列总

长度的比值。

语境特征

语

境特征主要用于编码相

邻词的信息，例如前一个

词 / 后一个词的标识、词性

标注、前

一个词是否是连

词等。

一旦生成了特征并

对输出标记进行了正确

编码，就可以得到“序列对

”并用于训练模型。

训练过

程类似于命名实体识别

系统。虽然流水线看起来

比较简单，并且类似于命

名实体识

别系统，但由于

存在领域特定的知识，这

些特征生成方案和建模

技术仍然存在挑战。此

外

，获取足够大的数据集以

覆盖各种属性也是一个

挑战。

为了处理这种数据

稀疏性和特征不完整性

的问题，有些方法建议在

输入中使用词嵌入序

列

。输入序列将按原样直接

传递给模型，由模型预测

输出序列。最近，研究人员

尝试使

用 RNN 或 LSTM-CRF 等深度循环

结构，来执行 seq2seq

标注任务。第

3 章和第 4 章介绍

了词嵌入

和 RNN

在自然语言处理中的

效果。此处的例子再次证

明这种表示方法是有用

的。

图 9-7 所示的例子说明深

度学习模型比典型的机

器学习模型具有更好的

效果。

电子商务与零售 ｜

227

产

品名称 之前的最佳效果

当前的深度模型

图 9-7：LSTM 框架

显著提高了属性提取的

效果

2. 间接属性提取

间接

属性是指产品描述中未

直接提及的属性。但是，这

些间接属性可以从其他

直接属性或

整体描述中

推断出来。例如，从文本中

推断出性别或年龄相关

的词。像“适合 1~5 岁宝

宝”这样

的短语意味着该产品适

合幼儿。由于这一信息没

有明确提及，序列标注方

法将无

法发挥作用。

对于

间接属性分类任务，可以

使用文本分类方法，从整

体输入推断出较高层次

的类别（即

间接属性），而非

直接提取信息。回想一下

“YunJey 短袖圆领三色条纹 T

恤休

闲衬衫”的

例子。在本例中

，可以使用第 3 章中的任何

句子表示方法来表示整

个输入字符串。另外，

还可

以创建类别相关词存在

与否、字符 n-gram

和词 n-gram 等特征。然

后，训练一个模

型，将输入

分类为间接属性标签。在

本例中，对于“性别”属性，可

以使用“男性”“女

性”“男 /

女”和

“儿童”作为不同的类别标

签。

对于使用深度循环结

构的模型，所需的数据量

通常远远大于使用 CRF 和

HMM 等

相对简单的机器学习模

型。数据越多，深度模型学

习效果越好。正

如前面几

章中所介绍的，这是所有

深度学习模型的共同特

点。但是对于电子

商务来

说，获取包含合理样例的

大型标注数据集是非常

昂贵的。因此，在构

建任何

复杂模型之前，都需要考

虑这一点。

上面讨论了文

本数据的属性提取，以及

将其扩展到多模态属性

提取的各种最新方法，即

融

合产品的标题、描述、图

像、评论等各种模态。

接下

来讨论如何将产品属性

提取所用到的相关技术

扩展到电子商务和零售

的其他任务。

9.3.2　产品分类与

分类树

产品分类是指将

产品分组的过程。不同的

组可以根据相似性来定

义，例如，相同品牌的产

品

或相同类型的产品可以

分为一组。一般来说，电子

商务都有预先定义好的

产品大类，如

电子产品、个

人护理产品和食品等。当

新产品上市时，应先将其

在分类树上分类，然后放

入产品目录。图 9-8

显示了电

子产品这一类别下的分

类树，其中包含了细粒度

子类别的层

次结构。

228 ｜ 第 9

章

电子商务与零售 ｜ 229

连接线

配件 电池和充电器

相机

包

汽车音响

连接线及附

件

配件

数据存储

笔记本

计算机

网络

平板计算机

配件 包和保护套

袋和包

电池

充电器和适配器

笔

记本计算机配件

相机

汽

车

计算机

数码相机 傻瓜

相机

音频和视频

耳机

电

子产品

图 9-8：类别的层次结

构示例——产品分类树

当然

，也可以用更严格的产品

定义来进一步定义更细

的类别，例如计算机类别

可以进一步

分为笔记本

计算机和平板计算机。举

一个本书的例子：这本书

的一个类别是技术类图

书，

子类是人工智能或自

然语言处理。产品分类任

务与第

4 章中介绍的文本

分类非常相似。

好的分类

树和正确关联的产品有

助于电子商务网站完成

以下任务：

• 显示与所搜索

产品相似的产品；

•

提供更

好的推荐；

• 选择合适的配

套销售产品，为顾客提供

更好的优惠；

• 用新产品代

替旧产品；

•

显示同一类别

中不同产品的价格比较

。

在起始阶段，规模通常较

小，手动分类即可，但随着

产品种类的增加，手动处

理变得越来

越困难。数据

规模较大时，这种分类通

常被视为一项分类任务

，即算法利用各种来源获

取

信息，并应用分类技术

来求解。

具体来说，在某些

情况下，算法会采用标题

或描述作为输入，并在所

有类别都已知的情况

下

将产品分为合适的类别

。这也属于文本分类的典

型情况。通过这种方式，分

类过程可以

实现自动化

。类别确定好后，就可以直

接扩展到前面讨论过的

相关属性提取过程。只有

找

到产品的类别后，才可

让产品进入属性提取过

程，这也符合逻辑。

230 ｜ 第 9

章

当

同时使用图像和文本来

解决问题时，可以提高算

法的准确性。图像可以传

递到卷积神经

网络以生

成图像嵌入，文本序列可

以通过 LSTM 进行编码，而这两

个序列又可以拼接起

来

，并传递到任何分类器，以

获得最终的输出。

构建分

类树是一个广泛的过程

。通过层次型文本分类，可

以将产品置于分类树的

正确级别

上。这里的层次

型文本分类其实就是根

据分类树中的级别在层

次结构中应用分类模型

。

一般来说，简单的基于规

则的分类方法主要用于

较高层次的类别。在开始

阶段，不妨使用

基于字典

的匹配方法。对于复杂的

子类别，需要更深层的语

境信息，才能正确确定其

在分

类树中的层次，因此

需要使用支持向量机或

决策树等机器学习分类

技术来处理。图 9-9

以

某电子

商务网站为例，显示了分

类树的不同层次。

某电子

商务

网站 示例：

单元

产品

类别

产品组

珠宝、手表

及

配件

生活方式

手袋

产品

子组 小皮具

产品子子组

个人收纳

用品

图 9-9：分类树

的不同层次

对于一个新

成立的电子商务平台，通

过产品分类来创建分类

树可能是一项艰难的任

务。构

建丰富的内容需要

大量的相关数据、人工干

预以及类别专家的领域

知识。对于一个新生的

电

子商务平台来说，所有这

些都过于奢侈。不过，Semantics3、eBay 和 Lucidworks 提

供的

部分 API 可以帮助完成

这一过程。

这些 API 通常构建

在各大零售商的大型目

录内容之上，扫描唯一的

产品代码，就可通过其

内

部智能来对产品进行分

类。小型电子商务可以充

分利用云 API 的优势来创建

分类树并进

行分类。图 9-10 显

示了

Semantics3 的 API 快照。这些 API 可以根

据产品名称对产品进行

分类。

图 9-10：Semantics3 终端快照

如果收

集了大量的产品信息，那

么建议使用定制的基于

规则的系统。上述部分 API 还

支持

用户定义规则，以及

产品浓缩和去重。接下来

介绍产品浓缩和去重。

9.3.3　产

品浓缩

为了更好地搜索

和推荐产品，就要收集更

丰富的信息。这些信息可

能来源于长短标题、产

品

图片和产品描述。但这些

信息往往要么不正确，要

么不完整。一个具有误导

性的标题可

能会影响电

子商务平台的多面搜索

。而改进产品标题不仅可

以提高搜索后的点击率

，还可

以提高产品购买的

转化率。

电子商务与零售

｜ 231

在图 9-11 所示的例子中，产品

标题过长，包含

iPad、iPhone 和 Samsung 等词，这

很容易

误导搜索。完整的

标题是“自由牌手写笔 10

支

装粉紫黑绿银手写笔通

用触摸屏电容式手

写笔

，适用于 Kindle Touch ipad iphone

6/6s 6Plus 6s Plus 三星 S5

S6 S7 Edge S8 Plus Note”。

这段文字很

复杂，即使是人类也很难

解析和理解，更不用说机

器了。这样的情况非常适

合

产品浓缩。

图 9-11：产品标题

臃肿示例：适用于产品浓

缩的理想情况

先讨论图

9-11 所示的问题场景。当分类

树层次和浓缩层次填充

好，至少达到可接受的阈

值

（通常由零售平台本身

定义）后，可尝试改善产品

标题的表达力和准确性

。

该过程可以直接从字符

串匹配开始。当然，不属于

产品属性值的词也需要

过滤。在本例

中，产品是手

写笔，iPad 和 iPhone 并非属性值。这些

词具有误导性，可能会影

响多面搜索

的质量。因此

，这些词如果不是用于表

示特定领域的上下文，就

应该从产品标题中删掉

。

在理想情况下，预先定义

产品标题的模板有助于

保持产品之间的一致性

。一个好方法是

使用分类

树中的属性来构建模板

。产品类别或类型可以是

产品标题中的第一个词

，例如

“iPad”或“Macbook”。紧接着是分类树

中层次更低或粒度更细

的属性，如品牌、尺寸、

颜色

等。因此，合并后的标题是

“iPad 64GB

- 深空灰”。分类树中叶子节

点的属性可以省

略，以保

持产品标题的简洁。

在任

何在线零售场景中，产品

浓缩通常不仅仅是改进

产品名称，而是一个更广

义、更连

续的过程。除了使

用分类树中的层次之外

，还可以使用其他方法来

定义浓缩层次。这些

方法

大多基于属性信息的重

要性。R.

C. Trietsch 的硕士学位论文“Product Attribute Value

Classification from Unstructured Text in E-Commerce”定

义了这些分类树，如图

9-12 所

示，

其中“不可或缺”的属性

是每个产品必不可少的

，而“有则较好”的属性则提

供了非常详

细的细节，可

以省略。

232 ｜

第 9 章

电子商务与

零售 ｜ 233

浓缩层次 重要性 说

明

0 不可或缺 如果缺少这

一浓缩层次的属性，则产

品不会添加到产品数据

库中

1 至关重要 如果缺少

这一浓缩层次的属性，则

产品不会添加到网店上

2 较为重要 这些属性通常

描述产品特性，如果缺少

这些属性，则不会产生任

何后果

3

有则较好 这些属

性非常详细地描述了产

品特性，被认为是有则较

好

图 9-12：不同浓缩层次的分

类表

接下来把注意力转

向产品去重和匹配。

9.3.4

产品

去重和匹配

产品通常由

第三方卖家添加到平台

上。不同的卖家可能会使

用不同的名称来指代同

一产

品。这可能导致同一

产品出现多个不同标题

和产品图像。例如，“佳明 nuvi 2699 LMTHD

GPS 设

备”和“nuvi 2699 LMTHD 车载便携式 GPS

导航器

”指的是同一产品。

除了产

品分类和属性提取，产品

去重也是电子商务的一

个重要方面。识别重复产

品也

是一项具有挑战性

的任务，下面讨论如何通

过属性匹配、标题匹配和

图像匹配来处理此

问题

。

1. 属性匹配

如果两个产品

是相同的，那么它们各种

属性的值也一定是相同

的。因此，一旦属性被提取

出来，就可以比较两个产

品的属性值。在理想情况

下，属性会出现最大程度

的重叠，这表

明产品匹配

性很强。为了匹配属性值

，可以使用字符串匹配法

。两个字符串可以通过精

确

的字符匹配或使用字

符串相似性指标进行匹

配。字符串相似性指标通

常用于处理轻微的拼

写

错误、缩写等。

在产品的相

关数据中，缩略语是一个

大问题。同一个词可以用

多个公认的缩写来表示

。为

解决该问题，不同的缩

写应该映射成一致的形

式（见

9.3.3 节），或制定独立于形

式的规

则。匹配两个词时

，处理缩写的一个直观规

则是匹配第一个字符和

最后一个字符，并检查

这

些字符是否属于原词或

它的缩略语。

2. 标题匹配

一

个产品通常具有多个不

同的标题。以下是不同卖

家出售的同一 GPS 导航器的

标题。

• Garmin nuvi

2699LMTHD GPS Device

• nuvi 2699LMTHD

Automobile Portable GPS Navigator

• Garmin

nuvi 2699LMTHD — GPS navigator —

automotive 6.1 in

• Garmin Nuvi

2699lmthd Gps Device

• Garmin nuvi

2699LMT HD 6” GPS with Lifetime

Maps and HD Traffic (010–01188–00)

要检索所有这样的

实例，需要一种匹配机制

来将它们标识为相同的

实例。一个简单的方

法是

比较这些标题中的二元

语法（bigram）和三元语法（trigram）。当然，也

可以生成标

题级别的特

征（例如常见 bigram 和 trigram 的计数），然

后计算它们之间的欧氏

距离。另

外，还可以同时使

用“句子级嵌入”和“文本短

语对”来学习距离度量，从

而提高匹配

精度。这也可

以通过一种称为孪生网

络的神经网络结构来实

现。孪生网络同时获取两

个

序列，并学习以这样的

方式生成嵌入：如果序列

相似，则它们在嵌入空间

中的距离更近，

否则就更

远。

3. 图像匹配

最后，属性和

标题中仍然可能存在不

规则的地方，例如缩写，或

某些词有特定用法，导致

属性和标题很难相互对

齐。在这些情况下，产品图

像可以为产品匹配和去

重提供丰富的信

息。对于

图像匹配，像素级匹配、特

征图匹配，甚至是先进的

图像匹配技术（如孪生网

络）都是常见的方法，当应

用于这种场景时，可以减

少产品重复。大多数算法

是基于计算

机视觉原理

的，并依赖于图像质量和

尺寸等细节。

A/B 测试是衡量

电子商务中不同算法的

结果和有效性的一种好

方法。对于属

性提取、产品

浓缩和

A/B 测试等过程，不同

的模型会对直接或间接

销售、点

击率、在一个网页

上花费的时间等业务指

标产生影响，相关指标的

改进表明

模型工作得更

好。

在实际情况下，这些算

法都是联合使用的，它们

的结果需要结合起来进

行产品去重。接

下来几节

将讨论分析产品评论的

自然语言处理，产品评论

是任何在线购物体验的

基本组

成部分。

9.4　评论分析

评论是任何电子商务门

户网站不可缺少的组成

部分。评论能捕捉顾客对

产品的直接反馈，

因此需

要充分利用这些丰富的

信息，并提取出重要的信

号来向电子商务系统发

送反馈，以

便电子商务系

统能够利用这些信息来

进一步改善用户体验。此

外，所有顾客都可以查看

评

论，因此评论能直接影

响产品的销售。本节将从

不同方面深入探讨评论

的情感分析。

9.4.1　情感分析

第

4 章介绍了分类任务中的

通用情感分析。但是电子

商务评论的情感分析又

存在着各种细

微的差别

。图 9-13

显示了亚马逊网站上

iPhone X 的顾客评论截图。对于电

子商务网站出

现的针对

某一“方面”的评论，大多数

人都很熟悉。在这里，你可

以根据“方面”和“属

性”对评

论进行分析。

234

｜ 第 9 章

图 9-13：顾客

评论分析：评分、关键词和

情感

如图所示，67% 的评论为

最高的 5 星，22% 的评论为最低

的 1

星。对于一家电子商务

公司

来说，了解顾客给出

差评的原因是很重要的

。为了说明这一点，图 9-14 显示

了同一产品的

两个极端

评论示例。

图

9-14：好评和差评

当然，这两个评论都包含

了一定的产品信息，可以

让零售商了解顾客的想

法。尤其是负面

评论，更需

要理解。如图 9-14 所示，在第一

个评论中，顾客指出到货

的手机存在问题，主

要是

屏幕缺陷，零售商应该注

意这一点。相比之下，第二

个正面评论仅表达了一

般的正面

情绪，没有明确

指出用户真正喜欢的“方

面”。因此，对评论有充分的

理解是至关重要的。

从本

质上讲，评论存在于文本

中，并且大多是非结构化

的格式，充满了随意的错

误，例如

拼写错误、不正确

的句子结构、不完整的单

词和缩写等。这增加了评

论分析的难度。

电子商务

与零售 ｜ 235

通常，一条评论包

含不止一个句子。因此，建

议将评论切分成若干个

句子，

并将每个句子作为

一个数据点传入。这也有

助于句子级的方面标注

和方面级

的情感分析等

。

通常认为，评分与评论的

整体情感成正比。但有些

情况下，用户可能错误地

给产品打了低

分，却给出

了正面的评论。直接从文

本中理解情感将有助于

零售商在分析过程中纠

正这些

异常现象。但在大

多数情况下，评论不仅仅

谈论产品的一个方面，而

是试图涵盖产品的大

部

分方面，最终所有的内容

都反映在评论的评分中

。

再来看一下图 9-13 中的 iPhone X 评论

截图。看看这一部分：“阅读

提及的评论”（Read

reviews that mention）。这些是亚马

逊发现的重要关键词，可

以帮助顾客在浏览评论

时更好地

导航。很明显，顾

客在谈论产品的某些方

面。它可能是用户体验、制

造、价格或其他方面。

如何

得知顾客的情感或反馈

是什么？目前整个评论只

提供了一个高层次的情

感指数，但仅

凭这一点是

无法深入挖掘和理解评

论的。这就需要对评论进

行方面级的理解。方面可

以预

先定义，也可以从评

论数据中提取。然后可在

此基础上，采取相应的监

督或无监督方法。

9.4.2　方面级

情感分析

在开始讨论方

面级情感分析的各种技

术之前，需要先了解什么

是方面。一个“方面”

（aspect）是指以

某个概念为中心的具有

丰富语义的词汇集合，用

以表示产品的某些属性

或

特征。例如，在图

9-15 中，可以

看到一个旅游网站可能

具有的几个方面：位置、价

值和干

净度。

方面级情感

分析不仅限于产品的固

有属性，还包括产品供应

、展示、交付、退货和质量等

相关的所有方面。通常，这

些方面是很难区分清楚

的，除非已经提前做了假

设。

如果零售商对产品的

“方面”有清晰的理解，那么

寻找“方面”就属于有监督

的算法范

畴。一种常见的

方法是使用种子词或种

子词典，它本质上是某个

特定方面存在与否的关

键

词。例如，关于 iPhone X 的用户体

验方面，种子词可以是屏

幕分辨率、触感、响应时间

等。同样，这取决于零售商

希望在何种粒度级别上

操作。例如，屏幕质量本身

可以是一个

更细粒度的

“方面”。接下来介绍方面级

情感分析的监督方法和

无监督方法。

1.

监督方法

监

督方法主要依赖于种子

词。它试图识别这些种子

词在句子中存在与否。如

果在句子中识

别到了一

个特定的种子词，监督方

法就会用相应的“方面”来

标记这个句子。一旦所有

的

句子都被标记到了相

应的“方面”，情感分析就可

以在句子级别上进行。现

在，由于已经

为每个句子

添加了一个附加标记，因

此可以把具有同一个标

记的句子筛选出来，并聚

合这

些句子的情感，从而

了解顾客对该方面的反

馈。例如，评论中所有与屏

幕质量、触感和响

应时间

相关的句子都可以分成

一组。

下面切换到图 9-15 所示

的旅游网站例子，其中的

方面级情感分析是显而

易见的。如图 9-15

所示，位置、入

住、价值和干净度都有相

应的评分，这些都是从数

据中正确提取的语义概

念，为评论提供更加细致

的呈现方式。

236 ｜ 第 9 章

图

9-15：旅游

网站评论的方面级评分

2. 无监督方法

由于高质量

的种子词典很难获得，因

此可以使用无监督方法

来检测“方面”。而主题建模

恰恰是识别文档中潜在

主题的有用技术。在方面

级情感分析中，可以将“方

面”视为主

题，并将谈论同

一方面的句子进行分组

。这正是主题建模算法所

做的。主题建模的最常见

方法之一是隐含狄利克

雷分布（LDA）。第 7 章详细介绍了

LDA。

类似地，可以预先定义句

子集的“方面”的数量。主题

建模算法还会输出每个

词出现在

各个主题（这里

是“方面”）中的概率。因此，也

可以将那些很可能属于

某个“方面”的

电子商务与

零售 ｜ 237

238

｜ 第 9 章

词组合起来，并

将这些词称为该方面的

特征词。这有助于最终将

未标注的“方面”标注

出来

。

此外，与 LDA 相比，一种更无监

督的方法是创建句子表

示并执行聚类。根据经验

，当评

论句子较少时，后者

有时会产生更好的效果

。下一节会介绍如何预测

所有这些“方面”的

评分，并

提供用户偏好的细粒度

视图。

9.4.3

将总体评分与ì方面

î联系起来

前面介绍了如

何检测每个“方面”的情感

。但是用户通常还会给出

一个总体评分。因此，

这里

的想法是将评分与每个

方面级别的情感联系起

来。为此，这里使用了一种

称为潜在评

分回归分析

（LARA）的技术。LARA 实现的细节超出

了本书的范围，但这里有

一个为酒

店评论生成方

面级评分的系统示例。如

图

9-16 所示的表格给出了这

些基于方面的评分的一

些细节。

方面 摘要 评分

价

值

独具特色，位置不错，价

格合理。我们最近在西雅

图住了三晚，Max 酒店是绝佳

选择 3.1

总的来说，体验不算

很差，但考虑到酒店业是

一个给人留下深刻印象

的行业，所

以仍有很大的

改进空间 1.7

房间

我们选择

这家酒店是因为 Travelzoo 有优惠

，大床房 139.00 美元

/ 晚 3.7

供暖系统

使用的是窗式空调，必须

在晚上关闭，否则会被烤

焦 1.2

地点

酒店位置方便，步

行到市中心和派克市场

很短，是个很好的选择 3.5

当

你游览一座大城市时，听

到外面的一点交通噪声

是在所难免的 2.1

商业服务

可以按天支付无线网络

费用，也可以使用大堂后

面商务中心的免费互联

网 2.7

我唯一抱怨的是每天

的上网费太高了，这年头

大街上都能连上无线网

了 0.9

图 9-16：基于 LARA 的方面级情感

预测

可以假设，最终评分

就是各个方面级情感的

加权组合。目标是同时估

计权重和方面级情

感。也

可以顺序执行这两个操

作，即先确定方面级情感

，然后确定权重。

每个方面

不同情感的权重，本质上

表示的是评论者对特定

主题的重视程度。顾客可

能对某

个方面非常不满

意，但这个方面可能不是

他们的优先项。零售商在

采取任何行动之前，需

要

获得这些信息。

用户信息

也是处理评论的关键因

素。想象这样一个场景：一

名“网红”用

户，而不是一名

普通用户，写了一篇好的

评论。用户的重要性可想

而知。在

进行评论分析时

，可根据所有用户的评分

（通常由其他用户给出）为

其定义

“用户权重”，并在各

种计算中使用用户权重

，以降低评论者的偏见。

接

下来深入剖析一个示例

算法来帮助你理解“方面

”。

电子商务与零售 ｜

239

9.4.4　理解ì方

面î

零售商的一个商业目

标是分析产品的某个特

定“方面”，以及评论中反映

的各种情绪和观

点。类似

地，用户也可能对产品的

某个特定“方面”感兴趣，并

希望浏览所有关于该方

面

的评论。因此，一旦推导

出所有的“方面”并用这些

“方面”来标记每个句子，就

可以按

“方面”对句子进行

分组。但是考虑到一个电

子商务网站所遇到的大

量评论，在一个“方

面”下仍

然会有很多句子。这时，使

用摘要算法就可以节省

大量时间。考虑这样一种

情

况：需要就某个“方面”采

取行动，但又没有能力通

读有关该“方面”的所有句

子。这就

需要一种算法，能

自动挑选出这一“方面”最

具代表性的句子。

LexRank 是一种

类似于

PageRank 的算法，它假设每

个句子都是一个节点，句

子之间通过句

子相似性

来连接。连接完成后，算法

会从其中挑选出最核心

的若干句子，这些句子就

是某

个“方面”的摘要。图 9-17 显

示了评论分析的流水线

示例，包括总体情感和方

面级情感。

使用LexRank

提取某个

方面最

中心或最重要的

句子/评论

方面级

情感检

测

评论/句子的

方面级聚

合

方面级

情感聚合

以句

子为节点，

构建各个方面

的

句子图

评论集

评论级

方面检测

图 9-17：评论分析的

完整流程图：总体情感、方

面级情感和各个方面下

的重要评论

流水线的起

点是评论集。随后是评论

级方面检测。然后对每个

方面进行情感分析，并基

于方面对评论 /

句子进行

聚合。聚合后，可以使用 LexRank 等

摘要算法进行摘要提取

。最

后，可以得到产品某一

方面的总体情感，以及解

释该情感的观点摘要。

要

想完整地理解一个产品

，就只能通过用户评论和

主编评论。主编评论通常

由专家用户或领域专家

提供。这些评论具有较高

的可靠度，可以显示在评

论

区的顶部。但另一方面

，普通用户的评论则从各

个用户的角度揭露了真

实的

产品体验。因此，有必

要将主编评论与普通用

户评论结合起来。要做到

这一

点，可以将两种评论

混合在一起，适当排序后

，放在评论区的顶部。

以上

介绍了如何从方面、情感

和评分的角度进行评论

分析。下一节将简要介绍

个性化电子

商务的细微

之处。

9.5　电子商务推荐

第 7 章

讨论了使用文本数据进

行推荐的各种技术。与产

品搜索和评论分析一样

，产品推荐

也是电子商务

的一个主要支柱。图 9-18 展示

了不同算法的综合研究

，以及各种场景中推荐

所

需的数据使用情况。

推荐

技术

销量最好的产品

随

机选择的产品

手动选择

的产品

基于近邻的方法

矩阵分解模型

关联规则

挖掘

聚类

贝叶斯分类器

支持向量机

决策树

人工

神经网络

基于内容的推

荐

混合方法

用于推荐的

数据

交易

元数据

社区信

息/信任

人口特征

时间

领

域知识

推荐的属性

个性

化

自适应

环境敏感

不必

冷启动

商用平台 开源平

台

图 9-18：各种电子商务推荐

场景下的技术的综合研

究

240

｜ 第 9 章

在电子商务中，产

品是根据用户的购买者

特征（时尚达人、图书爱好

者、热门产品享受者

等）来

推荐的。这些购买者特征

可以从平台上的用户行

为中推断出来。不难想象

，用户与

平台产品集的交

互行为有查看、点击或购

买。这些交互行为包含的

信息有助于确定用户接

下来感兴趣的产品集。这

可以通过基于邻域的方

法实现，这类方法旨在寻

找（在属性、购

买历史、购买

顾客等方面）类似的产品

，并以推荐的形式提供。

点

击、购买历史等数据主要

是数值数据。除此之外，电

子商务也有大量的文本

数据可用于

产品推荐。推

荐算法可以综合利用数

值数据以及文本形式的

产品描述，来更好地理解

产

品，并提供相似度更高

的产品推荐（粒度更细的

属性匹配）。例如，产品描述

中提到的服

装材料（如

52% 棉

、48% 涤纶）可能是寻找类似服

装时需要考虑的重要文

本信息。

推荐引擎需要处

理不同来源的信息。因此

，需要保证各种数据表之

间的正确

匹配，以及各种

数据源之间信息的一致

性。例如，在整理产品属性

和产品交

易历史等信息

时，应仔细检查信息的一

致性。补充性数据和替代

性数据可以

显示出数据

的质量。在处理各种各样

的数据源时，应像电子商

务推荐一样，

检查是否存

在异常行为。

评论包含了

很多关于产品的微妙信

息和用户意见，这些信息

和意见可以用于指导产

品推

荐。例如，某个用户提

供了关于移动设备屏幕

大小的反馈，“我喜欢更小

的屏幕”。这种用

户对产品

某一属性的特定反馈是

一种强烈的信号，有助于

对相关的产品集进行筛

选，从而

使推荐对用户更

有用。下面来看一个相关

的详细案例研究，并了解

如何利用产品评论构建

电子商务推荐系统。评论

不仅有助于找到更好的

推荐产品，还可以通过顾

客的微妙反馈来

揭示各

种产品之间的相互关系

。

案例研究：替代品和补充

品

推荐系统的思想基础

是产品的相似性。相似性

的衡量可以基于内容，也

可以基于用户特

征。在电

子商务场景中，识别产品

之间的相互关系还有另

外一种方法。

一方面，补充

品是指用户同时购买的

补充产品。另一方面，有些

产品是用来代替其他产

品

的，称为替代品。尽管经

济学定义要严格得多，但

这些思路通常抓住了产

品购买的行为方

面。有时

，由于个人用户行为的巨

大差异，很难从中推断出

产品之间的相互关系。但

在聚

合中，这些用户交互

可以揭示产品之间替代

和互补的有趣特性。有几

种方法可以使用用户

交

互数据识别替代品和补

充品，但这里仅重点介绍

其中的一种方法，它主要

使用以文本信

息形式存

在的产品评论。

Julian McAuley

提出了一

种在一个框架中理解产

品相互关系的综合方法

，即给出查询产品，

并返回

排名产品，包括替代品和

补充品（见图 9-19）。下面来讨论

这个应用程序，作为电

子

商务背景下的一个案例

研究。

电子商务与零售 ｜

241

查

询产品

替代品 补充品

图

9-19：基于产品评论的替代品

和补充品（参见 Julian

McAuley 等人的论

文“Inferring Networks of 

Substitutable

and Complementary Products”）

1. 从评论中提取潜在属

性

通常，正如前面所讨论

的，评论包含关于产品属

性的特定信息。从评论中

显式提取属性在

表示上

可能有局限性，因为需要

定义一个显式的本体，所

以可以通过潜在向量表

示来学习

评论。潜在因素

模型的细节超出了本书

的范围，感兴趣的读者可

以在网上找到相关资料

。

每个产品都与一个评论

相关。评论可能会谈论或

提到产品不同“方面”的各

种意见。虽然

这些主题是

潜在的，无法明确识别，但

评论中所谈论的各种属

性的比例分布仍然可以

获

得。分布的建模方法是

使用常见的主题模型（如

LDA）对产品的所有相关评论

进行建模。

得到的向量表

示即“主题向量”，主题向量

反映了评论中所谈论的

特定产品。从通常的机

器

学习术语来看，这种表示

可以被认为是产品本身

的特征表示。

2. 产品链接

下

一个任务是理解两个产

品是如何链接在一起的

。之前获得的主题向量，可

以在潜在属

242 ｜

第 9 章

性空间

中捕捉产品的内在属性

。现在，对于给定的一对产

品，我们希望根据每个产

品的

主题向量创建一个

联合特征向量，然后预测

它们之间是否存在任何

关系。这可以看作一

个二

分类问题，其中的特征则

必须从两个产品的相应

主题向量中获得。这个过

程叫作

“链接预测”。

为了确

保主题向量具有足够的

表达力来预测“产品对”之

间的链接或关系，获取主

题向量

和链接预测的两

个目标可以联合解决，而

不是先后解决，即同时学

习每个产品的主题向量

和每个产品对的联合函

数。

图 9-20 描述了学到的主题

向量的解释。该图显示了

主题向量变得具有足够

表达力后，可以

捕获产品

的内在属性。这种表示还

会涌现出层次依赖，并在

某种程度上描述了产品

所属的

分类树。

(a) 

(b)

(c) 电子产品

计算机 笔记本计算机 配

件 充电器

图3：主题层次结

构演示。图中展示了产品

（左）及其相关主题（右）。(a)

类别

树；(b) 主题向量；

(c) 产品的实际

类别。产品在类别树中的

位置用红色突出显示，ì激

活î的主题集用灰色突出

显示。

图 9-20：主题向量和主题

层次结构表示可以在评

论中捕获不同的分类标

识和关系（参见

Julian 

McAuley 等人的论

文“Inferring Networks of

Substitutable and Complementary Products”）

本案例研究表明，评论

包含了有用的信息，可以

揭示产品之间的各种相

互关系。上述潜在

表示比

从评论中准确提取属性

具有更强的表现力，不仅

对链接预测任务有效，而

且对揭示

产品分类树中

有意义的概念也有效。这

样的表示可以改善产品

链接，获得相似度更高的

产

品，从而做出更好的产

品推荐。

9.6　小结

电子商务行

业之所以取得巨大成功

，背后的一个主要驱动力

是大规模的数据收集和

数据驱

动决策的使用。自

然语言处理技术在改善

用户体验和提高电子商

务和零售业收入方面发

挥

了重要作用。

本章讨论

了电子商务中自然语言

处理的方方面面。本章首

先介绍了多面搜索，然后

深入研

究了产品属性。这

些领域与产品浓缩和分

类密切相关。随后，本章讨

论了电子商务的评论

分

析和产品推荐。本章中的

大多数示例和场景是产

品商务，但同样的技术也

可以用于其他

领域，如旅

游和食品。希望这一章能

抛砖引玉，将自然语言处

理和智能融入你的领域

。

电子商务与零售

｜ 243

第 1 0 章

医

疗、金融和法律

软件正在

吞噬世界，而人工智能将

吞噬软件。

——黄仁勋，英伟达

CEO

自然语言处理正在影响

和改善各大行业和部门

。前两章介绍了自然语言

处理在电子商务、

零售和

社交媒体领域中的应用

。本章将介绍医疗、金融和

法律这三大行业，其中自

然语言

处理的影响正在

迅速增加，进而对全球经

济产生重大影响。选择这

些行业的目的是展示人

们在工作中可能遇到的

各种问题、解决方案和挑

战。

医疗一词包含了各种

保持健康、增进福祉的商

品和服务，据估计全球市

场价值超过 10 万亿

美元，就

业人口达数千万。金融业

是现代文明的基石之一

，据估计价值超过 26.5 万亿美

元。

而法律服务行业每年

的价值估计超过 8500 亿美元

，预计到 2021 年将超过 1

万亿美

元。

本章的第一部分先对

医疗行业做一个概述，然

后介绍医疗领域中的各

种应用程序，同时也

会详

细讨论具体的用例。

10.1　医疗

医疗作为一个行业，为了

治疗性、预防性、缓和性和

康复性护理的目的，为社

会提供药

品、设备等商品

，也提供咨询、诊断检测等

服务。

治疗性护理是为了

治愈患者的可治疾病。预

防性护理是为了预防人

们生病。

康复性护理是为

了帮助患者从疾病中恢

复，包括物理治疗等环节

。缓和性护

理的重点则是

改善晚期患者的生活质

量。

244

医疗、金融和法律 ｜

245

对于

大多数发达经济体来说

，医疗行业占了国内生产

总值的很大一部分，通常

超过 10%。

医疗行业如此庞大

，自动化和优化其中的过

程和系统有着巨大的好

处，这就是自然语言处

理

的价值所在。图 10-1（来自

Chilmark Research）显示

了一系列使用自然语言

处理的应用

程序。每一列

属于一个大类，如临床研

究或收入周期管理。蓝色

单元格表示当前正在使

用

的成熟应用程序，紫色

单元格表示处于测试阶

段的新兴应用程序，红色

单元格则表示下一

代的

应用程序，投入实际应用

需要较长的时间。1

研究

治

疗 采集 人口健康 收入周

期管理 分析/报告

数据挖

掘

联合发现 临床决策支

持 语音识别 药物监测 登

记册报告 计算机辅助

编

码

临床试验匹配 计算表

型 临床文档改进

（CDI）

人口监

测

描述性分析事先授权

药物发现 生物标志物

发

现

患者报告的

结果 不良

事件检测

预测性分析风

险调整

精准医疗 虚拟治

疗 环境虚拟

缮写员

健康

的社交

决定因素

分诊

下

一代 新兴 成熟

再入院

规

范性分析 付款人

提供者

融合

图 10-1：自然语言处理在

医疗中的用例：来自 Chilmark

Research

医疗

涉及大量的非结构化文

本，因此可以使用自然语

言处理来改善健康结果

。很多领域使

用了自然语

言处理，包括医疗记录分

析、账单开具和药物安全

保证等。接下来简要介绍

其

中的一些应用程序。

10.1.1　健

康和医疗记录

大部分健

康和医疗数据通常是以

非结构化文本格式收集

和存储的。这包括医疗记

录、处

方、音频记录，以及病

理报告和放射科报告。图

10-2 显示了电子医疗记录的

示例。

这使得数据难以以

原始形式进行搜索、组织

、研究和理解。而数据存储

方式缺乏标准化更

是加

剧了这种情况。不过，自然

语言处理可以帮助医生

更好地搜索和分析这些

数据，甚至

自动化一些工

作流程，例如通过构建自

动问答系统可以减少查

找相关患者信息的时间

。本

章后面会详细介绍其

中的一些内容。

注 1：本书部

分彩图请读者前往本书

图灵社区页面下载。—— 编者

注

图 10-2：电子医疗记录示例

10.1.2

患者优先级和计费

在医

生记录中使用自然语言

处理技术，有助于了解其

状态和紧急程度，从而确

定各种医疗程

序和检查

的优先级。这可以最大限

度地减少延迟和内部管

理错误，并使流程自动化

。同样

地，从非结构化的记

录中解析和提取信息，识

别医学编码，还可以提高

医疗计费的便捷性。

10.1.3　药物

安全监视

药物安全监视

是指为了确保药物安全

而采取的一切活动。这包

括收集、检测和监测药物

的不良反应。医疗程序或

药物可能会产生意外或

有害的影响，只有监测和

预防这些影响，

才能确保

药物发挥预期的作用。随

着社交媒体使用量的增

加，越来越多的药物副作

用出

现在社交媒体消息

中，监测和识别药物的副

作用已经成为解决方案

的一部分，其中一些

技术

在第 8 章中介绍过，这一章

的重点是通用社交媒体

分析。本章后面还会介绍

一些社

交媒体的相关案

例。除了社交媒体，在医疗

记录中使用自然语言处

理技术，也可以促进

药物

安全监视。

10.1.4　临床决策支持

系统

决策支持系统的作

用是协助医务人员做出

相关的医疗决策，包括筛

查、诊断、治疗和监测

等。电

子健康记录、表格式实验

结果和手术记录等各种

文本数据都可以用作决

策支持系统

246 ｜ 第 10 章

的输入

。使用自然语言处理的方

法，可以改善决策支持系

统。

10.1.5　健康助理

健康助理和

聊天机器人通过使用专

家系统和自然语言处理

技术，可以改善患者和护

理人员

的体验。例如，像 Woebot（见

图 10-3）这样的服务可以让患

有精神疾病或者抑郁症

的患

者保持良好的情绪

。Woebot 将自然语言处理和认知

疗法结合起来，通过询问

相关问题来强

化积极的

心态。

图 10-3：Woebot 的对话

同样，助理

还可以评估患者的症状

，对潜在的健康问题进行

诊断。聊天机器人根据诊

断的

紧迫性和危急性来

预约相关医生。Buoy 就是这类

系统的一个例子。另外，这

类系统也可以

利用现有

的诊断框架，根据用户的

特定需求来构建。这种框

架的一个例子是 Infermedica，

如图

10-4 所

示，机器人在聊天界面中

得知用户的症状，并给出

可能的疾病列表及其概

率。

医疗、金融和法律 ｜ 247

图

10-4：用

Infermedica API 制作诊断聊天机器人

以

上部分应用程序在接下

来的几节中还会有详细

的介绍。

10.1.6　电子健康记录

越

来越多的临床和医疗数

据采用电子方式存储，导

致医疗数据的爆炸式增

长，个人记录也

变得庞大

无比。随着电子存储数据

越来越多，文档大小和历

史记录都在增长，医生和

临床

人员使用这些数据

变得越来越困难，从而导

致信息过载。信息过载反

过来又会导致更多的

错

误、遗漏和延迟，进而影响

患者的安全。

接下来的内

容将从总体上介绍自然

语言处理在管理信息过

载、改善患者健康中的作

用。本

节先讨论电子健康

记录（EHR）。

1. HARVEST 工具：纵向报告理解

为了克服前面提到的信

息过载，人们构建了各种

各样的工具，其中哥伦比

亚大学（Columbia 

University）的 HARVEST

是一个值得注

意的工具。该工具已在纽

约市各医院广泛使用。不

过在介绍之前，下面先了

解一下标准的临床信息

系统是如何工作的。

图 10-5 显

示了纽约长老会医院（iNYP）使

用的标准临床信息审查

系统的截图。医院提供

的

报告以文字为主，内容密

集，读起来很耗时，而且往

往使用不便。虽然系统提

供了基本

的文本搜索功

能，但是文本密集型的信

息很容易被一眼带过，这

在分秒必争的医院环境

中

是个大问题。

248 ｜ 第 10 章

图 10-5：纽

约长老会医院标准临床

信息审查系统截图

相比

之下，HARVEST 工具则能解析所有

的医疗数据，使其易于分

析，并且可以集成在任

何

医疗系统之中。图 10-6

展示了

HARVEST 工具在 iNYP 系统中的效果：以

前文本密集型

的报告格

式转换成了可视化的描

述。

从图中可以看到患者

每次去诊所或医院就诊

的时间线。同时，它还附带

了给定时间范围内

患者

重大疾病的词云。如果需

要，用户还可以深入查看

详细记录和历史。除此之

外，系统

还给出了每个报

告的摘要，使得用户可以

快速了解患者病史的大

体情况。HARVEST 不仅

让报告的面

貌焕然一新，而且非常实

用，能为医生甚至普通医

务人员和护理人员提供

近乎

实时并且信息丰富

的患者病情快照。

医疗、金

融和法律

｜ 249

图 10-6：HARVEST 系统，患者同

图 10-5

医生、护士、营养学家等

对患者的所有观察记录

可以通过 HealthTermFinder 进行命名实体

识别。得到的所有医学术

语接着会映射到“统一医

学语言系统”（UMLS）语义组。这些

术

语以词云的方式可视

化。词云权重由 TF-IDF（详见第 7

章

）确定。字体大小表示患者

所患

各种疾病的程度和

频率。这种可视化模式还

有助于发现和探查其他

容易被忽略的问题。

HARVEST 能以

更加有效和易于理解的

方式，展示患者任何时间

范围内的病史。在这种情

况下，更有价值的是，它有

助于提高医生的分析能

力，让医生能够把注意力

集中在根本问

题上，而不

是“头痛医头，脚痛医脚”。纽

约长老会医院的医生对

HARVEST 系统进行了

测试。在测试

中，超过 75% 的参与者表示，尽

管 HARVEST 是一个全新的用户界

面，但

他们肯定会在未来

经常使用

HARVEST，而其他参与者

也表现出了一些使用该

系统的意向。

图 10-7 显示了这

些从业者当时提供的一

些反馈。

250 ｜

第 10 章

图 10-7：纽约长老

会医院对 HARVEST

的临床反馈

HARVEST 通

过整理患者在整个生命

历程中的医疗历史记录

，提供可理解的总结和结

论。

其独特的卖点在于，不

管患者在医院的何处就

诊，由谁接诊，它都可以根

据微观层面的详

细观察

，进行宏观层面的挖掘、提

取和可视化呈现。构建这

样的系统可以可视化和

分析大

量的信息。当底层

知识库是非结构化文本

时，就像电子健康记录一

样，自然语言处理技术

在

这些分析和信息可视化

工具中发挥着关键作用

。

医疗、金融和法律 ｜ 251

2. 健康问

答

前面研究了如何使用

基本的自然语言处理技

术（如命名实体识别）来提

升用户处理大规模

记录

和信息的体验。但是为了

让用户体验更上一层楼

，不妨考虑在这些记录的

基础上创建

一个问答系

统。

第 7 章介绍过问答系统

，但这里的重点是医疗场

景中的特定问题，举例如

下。

• 患者需要服用多少剂

量的药物？

• 服用的某种药

物是治疗什么病的？

• 化验

结果如何？

• 对于给定的测

试数据，化验结果超出正

常范围多少？

• 化验的哪一

项结果证实了某种疾病

的发生？

正如本书一贯讨

论的，为特定任务构建正

确的数据集通常是解决

任何自然语言处理问题

的关键。对于医疗领域中

问答系统，这里重点关注

emrQA 数据集，它由

IBM 研究中心、

麻

省理工学院和伊利诺伊

大学厄巴纳 – 香槟分校（UIUC）联

合创建。图 10-8

显示了此

类数

据集所含内容的示例。例

如，对于“患者是否曾经有

过异常的体重指数？”（Has the 

patient ever

had an abnormal BMI?）这个

问题，可以从过去的健康

记录中提取正确的答案

。

图 10-8

emrQA 中的“问题 – 答案”对示例

为了创建这样的问答数

据集并在此基础上构建

问答系统，一个通用的问

答数据集创建框架

包括

以下过程。

1.

收集特定领域

的问题，然后将其规范化

。患者的治疗情况可以通

过多种方式询问，例

如，“问

题是如何处理的？”或者“采

取了什么措施来纠正患

者的问题？”等。这些不

同的

问题都必须以相同的逻

辑形式进行规范化。

2. 用专

家领域知识映射问题模

板，并为其分配逻辑形式

。问题模板是一种抽象意

义上的

问题。例如，对于某

一类型的问题，人们期望

得到一个数值或一种药

物类型作为回

答。具体来

说，对于问题模板“药物的

剂量是多少？”，可以映射到

一个确切的问题，

比如“硝

酸甘油的剂量是多少？”。这

个问题是一个逻辑形式

，需要剂量作为回答，

详见

图 10-9。

252 ｜

第 10 章

医疗、金融和法律

｜ 253

数据的本体/

模式表示

问

题收集

规范化

药物的剂

量是多少？ 用药事件（|药物

|）

药物事件（硝酸甘油）[剂量

=x]

[剂量=x] <药物=硝酸甘油

剂量

=40mg>

答案=40mg

证据=硝酸甘油每日

40毫克，晚上服用

硝酸甘油

的剂量是多少？

实体占位

符

实体类型：药物

问题实

体占位符 答案实体

实体

类型=剂量

逻辑形式标注

问题模板

逻辑形式

模板

共指

药物

i2b2

数据集 关系

临

床记录

电子医疗记录

病

人1 2012年

病人1 2015年

病人1 2013年

病人

1 2013年

病人1 2013年

硝酸甘油每日

40毫克，

晚上服用。病人……

图 10-9：使

用现有标注生成问答数

据集

3. 使用现有的标注和

前两步收集的信息，创建

“问题

– 答案”对。在这里，可以

使用命名

实体标记等现

成的信息以及链接到逻

辑形式的答案类型进行

数据自举。这一步尤其重

要，因为可以减少创建问

答数据集所需的手动工

作。

具体来说，对于 emrQA，这一过

程始于美国退伍军人管

理局医生收集的典型问

题，这产生

了

2000 多个带有噪

声的模板，模板经过规范

化后减少到 600 个左右。然后

，这些典型问

题以逻辑形

式映射至 i2b2

数据集。i2b2 数据集

已经使用一系列细粒度

信息（如药物概念、

关系、断

言、共指消解等）进行了专

业标注。尽管 i2b2 数据集并非

出于问答目的而创建，

但

通过使用逻辑映射和现

有标注，可以从中生成问

题和答案。图

10-9 显示了该过

程的整体

概述。这个过程

由一系列医生密切监督

，以确保数据集的质量。

为

了创建一个基线问答系

统，emrQA 团队使用了序列到序

列的神经网络模型和基

于启发式

的模型。这些模

型在

emrQA 团队的工作成果中

有更详细的介绍。为了评

估模型性能，他

们将数据

集分为两组：emrQL-1 和 emrQL-2。emrQL-1 在测试和

训练数据中的词汇差异

较

大。对于 emrQL-1，启发式模型的

性能优于神经网络模型

；对于 emrQL-2，神经网络模型

的性

能更好。

从更广义的角度

来说，这是一个关于如何

使用启发式、映射和其他

简单标注数据集构建复

杂数据集的有趣用例。除

了处理健康记录，这些经

验还可以应用于其他需

要生成类似问答

数据集

的一系列问题。接下来介

绍如何使用健康记录来

预测健康结果。

3. 结果预测

和最佳实践

前面介绍了

自然语言处理如何帮助

医生研究患者病情，以及

医生如何根据患者健康

记录进

行提问。下面介绍

一个更前沿的应用程序

：使用健康记录预测健康

结果。健康结果相当于

一

组属性，可以解释疾病对

患者的影响，包括患者恢

复的速度和完整程度。健

康结果在衡

量不同治疗

的疗效方面也很重要。这

项工作由谷歌人工智能

、斯坦福医学院和加州大

学旧

金山分校共同合作

。

除了预测健康结果，利用

电子健康记录进行可扩

展和准确的深度学习的

另一个重点是，确

保能够

构建既可扩展又高度准

确的模型和系统。可扩展

性是必要的，因为医疗涉

及各式各

样的输入数据

，不同医院或部门收集的

数据可能是不同的。因此

，即使针对不同的结果或

不同的医院，系统的训练

应该很简单才行。为了不

引起过多的误报，还必须

做到准确。在

人命关天的

医疗行业，准确的必要性

是显而易见的。

电子健康

记录（EHR）尽管听起来很简单

，但实际上却远非如此。EHR

存

在着许多微妙之

处和复

杂性。即使是像体温这样

简单的记录也会有一系

列的诊断标准，这取决于

体温是通

过舌头、前额还

是身体其他部位测量的

。为了处理所有这些情况

，人们创建了一个开放式

快速医疗互用性资源（FHIR）标

准，该标准使用了具有唯

一定位符的标准化格式

，以确保

一致性和可靠性

。

数据格式一致后，就可以

输入基于 RNN

的模型中。从第

一条记录到最后一条记

录的所有

历史数据都输

入模型中。输出变量则是

期望预测的结果。

模型根

据一系列健康结果进行

评估。对于患者是否会在

医院停留更长时间，AUC 得分

（亦

称为曲线下面积）为 0.86；对

于意外再入院，AUC

得分为 0.77；对

于预测患者死亡率，

AUC 得分

为 0.95。AUC 得分是此类情况下经

常使用的指标，因为

AUC 是对

所有潜在阳性

诊断阈值

的汇总度量，而不是任何

特定阈值下的性能度量

。分数为 1.0 表示完全准确，而

0.5 则与随机无异。

在医疗领

域中，模型的可解释性很

重要。换句话说，对于给出

的具体结果，模型应该能

准

确解释其原因。如果没

有可解释性，医生很难在

诊断中参考模型的预测

结果。为了实现

可解释性

，可以使用深度学习中的

注意力来理解哪些数据

点和事件对结果最为重

要。图

10-10 显示了注意力图的

一个示例。

图

10-10：注意力应用

于健康记录的示例

254 ｜ 第 10 章

谷歌人工智能团队还提

出了一些最佳实践，概述

了机器学习生命周期各

个阶段（从定义问

题、收集

数据到验证结果）的思路

。在为医疗领域构建机器

学习模型时，人们应该记

住这

些实践。这些建议适

用于自然语言处理、计算

机视觉以及结构化数据

问题。

这些技术主要侧重

于管理人类的身体健康

。由于有各种可用的数值

指标，因此相对容易量

化

。但人的心理健康测量则

没有明显的可量化指标

来衡量。下面来看一些监

测个人心理健

康的技术

。

下一节中包含对心理健

康问题和自杀的讨论。

10.1.7　心

理健康监测

考虑到当今

世界经济和技术的快速

变迁以及生活节奏的加

快，大多数人，特别是 X、Y 和

Z

世

代人，在他们的一生中往

往会经历某种形式的心

理健康问题，这并不奇怪

。据估计，

全球有超过 7.9 亿人

受到心理健康问题的影

响，这意味着每 10 个人中就

有

1 个人受到影

响。美国国

立卫生研究院（National Institutes of Health）的一项研

究估计，四分之一的美国

人可能在一年中受到一

种或多种心理健康问题

的影响。2017

年，超过 47 000 名美国人

自

杀，而且这个数值一直

在快速增长。

随着社交媒

体的使用达到历史最高

水平，使用社交媒体发出

的信号来跟踪特定个人

和不同

群体的情绪状态

和心理平衡变得越来越

有可能。甚至洞察不同人

口群体（不同年龄、不同

性

别等）的情绪状态和心理

平衡也是可能的。本节将

简要介绍对 Twitter 用户公开数

据的探

索性分析，以及如

何将第 9

章学到的技术应

用于这个问题。

评估一个

人的心理健康涉及很多

方面。例如，格伦 • 库珀史密

斯（Glen Coppersmith）等

人的研究“Exploratory

Analysis of Social Media Prior to

a Suicide Attempt”的重点是

，利

用社交媒体识别有自

杀风险的个人。这项研究

的目标是构建早期预警

系统，并查明问题的

根源

。

研究识别出了

554 名声称试

图自杀的用户，并对他们

进行了评估。这些用户中

有 312 人明

确表示他们最近

有自杀企图。加有“隐私”标

签的个人资料不包括在

这项研究中。研究只

检查

了公开数据，不包括任何

私聊消息或已被删除的

帖子。

每一位用户的推文

都从以下角度进行了分

析。

• 用户试图自杀的声明

是否明显真实？

• 用户是否

在谈论自己的自杀企图

？

•

自杀企图能及时定位吗

？

请参见图 10-11 中的推文示例

。

医疗、金融和法律 ｜

255

我很高

兴我能活下来去参加今

天的婚礼。

我年轻的时候

太傻了，多次尝试自杀。

自

从上周自杀未遂住院以

来，我一直都与外界失去

联系。

我自杀未遂已经半

年了，我真希望我成功了

。

既然野马队赢了，我就要

自杀了……#囧

我会穷到自杀

，但我真的真的真的需要

那双鞋。

图 10-11：构建社交数据

集的微妙之处

前两条推

文涉及真正的自杀企图

，而最后两条则是讽刺或

虚假的陈述。中间两条提

到了尝

试自杀的确切日

期。

为了分析数据，遵循了

以下步骤。

1. 预处理：因为 Twitter 数

据经常有噪声，所以首先

对其进行规范化和清洗

。URL 和用户

名用同质标记表

示。第

9 章详细介绍了社交

媒体数据清洗。

2. 字符模型

：使用 n-gram 字符模型和逻辑回

归对各种推文进行分类

。性能使用

10 折交叉

验证法

来度量。

3. 情绪状态：为了估

计推文中的情绪内容，数

据集使用标签进行自举

。例如，所有包含

愤怒但不

包含“讽刺”（#sarcasm）和“玩笑”（#jk）标签的

推文都被贴上了“情感”标

签。没有情感内容的推文

也被归类为“无情感”。

然后

对这些模型进行测试，以

确定模型能在多大程度

上识别出潜在的自杀风

险。结果是，

对于那些极可

能自杀的人，模型能够识

别出其中的 70%，只有 10% 的误报

。图 10-12

中所

示的混淆矩阵，详

细描述了各种情感错误

分类的概率。

愤怒

焦虑

厌

恶

害怕

快乐

孤独

无情感

悲伤

愤怒 焦虑 厌恶

害怕

快乐 孤独 无情感 悲伤

图

10-12：情绪分类的混淆矩阵

256

｜ 第

10 章

识别潜在的心理健康

问题可用来干预标记的

病例。通过精确的监控和

警报，像 Woebot 这

样的自然语言

处理机器人也可以用来

提升高危人群的情绪。下

一节将深入研究从医疗

数据

中提取实体。

10.1.8　医疗信

息提取与分析

前面介绍

了一系列基于健康记录

和信息的应用程序。使用

健康记录构建应用程序

的第一

步是从健康记录

中提取医疗实体和关系

。医疗信息提取（信息提取

）有助于从健康记录、

放射

科报告、出院总结，以及护

理文档和医学教育文档

中识别临床症状、身体状

况、药

物、剂量、强度等常见

的生物医学概念。为此，可

以使用云 API，也可以使用预

先构建

的模型。

先来了解

亚马逊医学语言处理服

务——Amazon Comprehend

Medical。它隶属于亚马逊

云（AWS）的

自然语言处理服务——Amazon Comprehend。Amazon Comprehend 可用

于

在云端执行关键词提

取、情感和句法分析、语种

和实体识别等常见的自

然语言处理任务。

Amazon Comprehend Medical 可用于

处理医疗数据，包括医疗

命名实体和关系提取以

及医

疗本体链接。

可以使

用

Amazon Comprehend Medical 云 API 来处理医疗文本，这

里仅简要概述云

API

的功能

。首先以 FHIR 的健康记录作为

输入。注意，FHIR 是美国范围内

记录和共享医疗

信息的

标准。现在从虚构的“健康

诊所”取得一个电子健康

记录样本。为了有效地测

试

Comprehend Medical，需要删除其中的所有

格式和换行符，以便查看

系统的效果。在开始

阶段

，不妨只考虑医疗记录中

的一小段序列：

Good Health Clinic

Consultation Note Robert Dolin MD Robert

Dolin MD Good Health 

Clinic

Henry Levin the 7th Robert Dolin

MD History of Present Illness Henry

Levin, the 7th is a 67

year old male referred for further

asthma management. 

Onset of asthma

in his twenties teens. He was

hospitalized twice last year, and

already twice this year. He has

not been able to be weaned

off steroids for the 

past

several months. Past Medical History Asthma

Hypertension (see HTN.cda for 

details)

Osteoarthritis, right knee Medications Theodur 200mg

BID Proventil 

inhaler 2puffs QID

PRN Prednisone 20mg qd HCTZ 25mg

qd Theodur 200mg BID 

Proventil

inhaler 2puffs QID PRN Prednisone 20mg

qd HCTZ 25mg qd

当把上述

内容输入 Comprehend

Medical 后，得到的输出

如图 10-13 所示。

医疗、金融和法

律 ｜

257

图 10-13：FHIR 记录的 Comprehend Medical

输出

不难看

出，从诊所和医生细节，到

诊断和药物及其频率、剂

量和途径，所有的信息都

可以

提取。如果需要，还可

以将提取的信息链接到

标准医学本体，如 ICD-10-CM 或 RxNorm。

通过

AWS boto 库可以访问 Comprehend Medical 的所有功能

。

构建医疗信息提取可先

从云 API 和库开始，但如果有

特定的需求，并且愿意构

建自己的系

统，那么建议

从 BioBERT 开始。本书整本书都谈

到了

BERT，即双向编码器表示

。然而，

默认的 BERT 模型是在常

规网络文本上训练的，这

与医疗文本和记录非常

不同。例如，普

通英语文本

和医疗记录之间的单词

分布存在很大的差异。这

会影响 BERT

在医疗任务中的

表现。

为了构建更好的生

物医学数据模型，人们创

建了生物医学文本的 BERT（BioBERT）。

BioBERT 将

BERT 应用于生物医学文本以

获得更好的性能。在领域

适应阶段，我们使用标

准

的 BERT 模型和预训练的生物

医学文本（包括来自医学

搜索引擎 PubMed 的文本）初始

化

模型权重。图

10-14 显示了预训

练和微调 BioBERT 的过程。

258 ｜

第 10 章

医

疗、金融和法律 ｜ 259

命名实体

识别

关系提取

问答

BioBERT的微

调

特定于任务的数据集

BioBERT微调

BioBERT的预训练

预训练语

料库 BioBERT预训练

权重初始化

来自Devlin等人 利用生物医学

领域语料库

预训练BioBERT

45亿个

词

135亿个词

N

N

N

N

图

10-14：BioBERT 预训练和微

调

BioBERT 模型和权重已经开源

，可在 GitHub 上找到。它可以在一

系列特定的医学问题上

进行微调，如医学命名实

体识别和关系提取。BioBERT

还可

以应用于医疗文本的问

答，其

性能明显高于 BERT 和其

他最先进的技术。它也可

以根据医疗任务和数据

集进行调整。

前面讨论了

自然语言处理可以发挥

作用的一系列医疗应用

程序，涵盖了基于健康记

录构建

应用程序的方方

面面，讲述了社交媒体监

控如何应用于解决心理

健康问题，并在最后展示

了如何为医疗应用程序

奠定基础。下面深入金融

和法律领域来看自然语

言处理是如何发挥

作用

的。

10.2　金融与法律

金融是一

个多元化的领域，涵盖范

围很广，从上市公司监控

到投资银行交易流程，都

属于

金融的范畴。从全球

来看，到 2022

年，金融服务业预

计将增长到 26 万亿美元。由

于法律

和金融密切相关

，因此本节会一并介绍。考

虑到在金融框架、运营、报

告和评估中整合和

利用

自然语言处理，金融可以

从以下三个角度来看待

。

260

｜ 第 10 章

组织视角

不同类型

的组织需要考虑不同的

需求和视角。这些视角包

括：

• 私营公司；

• 上市公司；

• 非

营利企业；

• 政府组织。

行动

视角

组织可以采取不同

的行动，包括：

• 分配和重新

分配资金；

• 会计和审计，包

括识别反常现象和异常

值，以调查价值和风险；

• 优

先级和资源规划；

• 遵守法

律和政策规范。

金融背景

视角

这些行动可能有不

同的背景，包括：

• 预测和预

算编制；

• 零售银行业务；

• 投

资银行业务；

• 股票市场操

作。

为了在构建、查看、管理

和报告财务流程方面做

出有条不紊、深谋远虑的

实时决策，必须

持续关注

公司不断变化的性质，并

且必须相应地构建和设

计金融基础设施。机器学

习和自

然语言处理可以

帮助设计这样一个系统

。图 10-15 显示了根据英格兰银

行和英国金融市场

行为

监管局在 2019 年的一项联合

调查，英国银行家认为机

器学习和自然语言处理

可以改

善哪些经营的方

式和领域。

当前效益

预期

效益（三年内）

高效益

低效

益

中等效益

改进反欺诈

以及

反洗钱工作

提高

经

营效率

为客户

提供更好

的

个性化服务

改进

合规

性

产生新的

分析见解

提

供新的

产品类型

图 10-15：英国

机器学习效益评估调查

银行家估计，在运营效率

和分析洞察方面，机器学

习和自然语言处理能带

来很大的改进。

随着这些

技术的应用，反欺诈和反

洗钱工作也有望产生更

好的效益。

10.2.1　自然语言处理

在金融领域中的应用

这

一节介绍自然语言处理

在金融领域中的一些具

体应用，包括金融情感分

析、贷款风险评

估，以及审

计和会计问题。

1. 金融情感

股票市场交易依赖于特

定公司的一系列信息。这

些知识有助于创建买入

、持有或卖出股票

等一系

列的操作决定。这种分析

可以基于公司的季度财

务报告，也可以基于分析

师在报告

中对公司的评

论。评论也可能来自社交

媒体。

社交媒体分析（详见

第 8 章介绍）有助于监控社

交媒体帖子并指出潜在

的交易机会。例

如，如果 CEO 辞

职，则情感通常是负面的

，这可能会对公司的股价

产生负面影响。相反，

如果

CEO 表现不佳，则市场欢迎他

们辞职，这可能导致股价

上涨。为交易提供这些信

息

的公司包括 DataMinr 和 Bloomberg。图

10-16 显示

了 DataMinr 终端，它会向用户显示

与戴

尔（Dell）相关的警报和影

响营销的新闻。

图

10-16：Dataminr 社交终

端

金融情感分析不同于

一般的情感分析。金融情

感分析不仅在领域上不

同，而且在目的上也

不同

。一般来说，金融情感分析

的目的是猜测市场对一

条消息的反应，而不是猜

测消息本

身是否积极。正

如我们从前面医疗领域

的 BioBERT

中看到的那样，人们也

在微调 BERT，

使之适应金融领

域。FinBERT 是其中的一项成果。

2. 风

险评估

信用风险是一种

量化方法，用于衡量成功

偿还贷款的可能性。信用

风险通常根据个人过去

的支出和贷款偿还历史

来计算。然而，这些信息在

许多情况下是有限的，特

别是在贫困社

区。据估计

，世界上有超过一半的人

口被排除在金融服务之

外。不过，自然语言处理可

以

医疗、金融和法律 ｜ 261

帮助

缓解这个问题。通过自然

语言处理技术，可以新增

更多的数据点，用于评估

信用风

险。例如，在商业贷

款中，企业家的能力和态

度可以用自然语言处理

来衡量。网贷平台

Capital Float 和 Microbnk 就使

用了这种方法。同样，借款

人提供的数据中的不一

致性也可

能会暴露出来

，以便进行更多的审查。其

他更微妙的方面，如贷款

人和借款人申请贷款时

的情绪，也可以纳入其中

。

通常在个人贷款协议中

，必须从贷款文件中获取

各种信息，然后将这些信

息输入信用风险

模型。获

取的信息有助于识别信

用风险，如果从文档中提

取了错误的数据，则可能

导致评

估出现瑕疵。第 5 章

中详细介绍的命名实体

识别（NER），可用于改善这一点

。图

10-17

显示了上述贷款协议

的一个示例，其中展示了

一份贷款协议以及从中

提取的不同相关实

体。这

个例子摘自一篇关于金

融领域命名实体识别领

域适应的文献，“Domain Adaption of

Named Entity Recognition to Support Credit

Risk Assessment”。10.2.2 节将详细

介绍这种实

体提取。

图 10-17：带

标注实体的贷款协议

3. 会

计与审计

德勤、安永和普

华永道等国际公司现在

非常注重对公司的年度

业绩做出更有意义、更具

可

操作性和相关性的审

计结论和意见。在将自然

语言处理和机器学习应

用于合同文件审查和

262 ｜

第

10 章

长期采购协议等领域

时，德勤已将其“审计命令

语言”发展成为更高效的

自然语言处理应

用程序

。

此外，过去几十年间，日常

交易和发票纸样等数字

核对非常复杂，现在这些

公司终于意识

到自然语

言处理和机器学习在审

计过程中具有显著优势

。自然语言处理和机器学

习能对交

易类型中的异

常值进行直接识别、聚焦

、可视化和趋势分析。公司

从而可以集中精力来研

究这些异常值及其形成

原因，这样就能及早发现

潜在的重大风险和可能

的欺诈活动，比如

洗钱。这

可能帮助公司模拟和推

断各种价值创造活动，并

针对各种业务流程进行

定制。

接下来把注意力转

向自然语言处理在法律

事务中的使用。

10.2.2　自然语言

处理与法律行业

技术工

具在法律行业中的整合

和利用已经进行了几十

年。考虑到大量的研究、案

例参考、

简要准备、文件审

查、合同设计、背景分析和

意见起草，法律专业人士

，包括律师事务所

和法院

系统，长期以来一直在寻

找各种方式、手段和工具

来减少他们的人工工作

时间。这

里不会详细介绍

法律自然语言处理，因为

该领域的研究工作受到

专利保护，不向公众开放

或仅开放部分内容。因此

，下面仅从总体的角度来

讨论这些想法。

自然语言

处理在法律服务中的核

心任务概述如下。

法律研

究

法律研究包括查找具

体案件的相关信息，包括

搜索立法机构和案例法

律法规。ROSS

Intelligence 就是这样的一个

服务机构。它能匹配事实

和相关案例，并分析法律

文件。图

10-18 显示了它的实际

运转。

图 10-18：ROSS

匹配相关段落

合

同审查

合同审查是指审

查合同并确保合同遵循

相应的规范和条例。合同

审查包括对不同的条款

进行审查并给出编辑建

议。例如，人工智能法律助

手 SpotDraft 主要关注基于欧盟《通

用数据保护条例》的法规

。

合同生成

合同生成是指

基于问答设置生成合同

。在简单的情况下，可能只

需要简单的表单，而对

于

更复杂的情况，交互式聊

天机器人系统可能更适

合。在接收所有响应后，使

用槽填充

算法生成合同

。

医疗、金融和法律 ｜ 263

法律发

现

法律发现是指在电子

存储的信息中发现可用

于案件的异常和模式。在

某些情况下，法律

发现是

完全无监督学习的。在其

他情况下，法律发现可能

涉及主动学习（即提供初

始的

标注文档集）。例如，Siren 就

是这样一个产品，它有助

于情报、执法、网络安全和

金融

犯罪领域的发现。

基

于 LexNLP 的法律实体提取

在任

何类型的合同中，在构建

任何类型的智能应用程

序之前，需要提取大量的

法律条款

和实体。LexNLP 对此很

有帮助，因为它具有法律

词汇分词功能。这一点很

重要，因为像

LLC 或 F.3d 这样的法

律缩写是常规解析器无

法处理的。类似地，LexNLP 还有助

于将文档

分割成多个部

分，并提取重复出现的合

同日期或法规等事实。此

外，它还可以接入法律文

件分析平台

ContraxSuite，该平台具有

一系列其他法律功能，具

体将在后面介绍。

现在来

看这是如何工作的：

import lexnlp.extract.en.acts 

import

lexnlp.extract.en.definitions 

print("List of acts in

the document") 

data_contract = list(lexnlp.extract.en.acts.get_acts(text))

df = pd.DataFrame(data=data_contract,columns=data_contract[0].keys()) 

df['Act_annotations'] =

list(lexnlp.extract.en.acts.get_acts_annotations(text)) 

df.head(10) 

print("Different ACT

definitions in the contract") 

data_acts

= list(lexnlp.extract.en.definitions.get_definitions(text)) 

df = pd.DataFrame(data=data_acts,columns=["Acts"])

df.head(20)

图 10-19 显

示了使用 LexNLP 提取文档中的

法律列表。

如以上代码所

示，此处使用“未来股权简

单协议”（SAFE，用于投资的通用

文档）提取信

息，包括文档

中存在的所有法律及其

定义。同样，提取的信息还

可以扩展到公司、法律援

引、法律限制、法律期限、法

规等。

除了法律实体提取

，LexNLP 还提供不同国家及地区

的会计、金融信息、监管机

构，以及

法律和医疗领域

的法律词典和知识集。它

还与 ContraxSuite

集成，从而对文档进

行重复数

据消除，对法律

实体进行聚类（如图 10-20 所示

）等。在构建自定义应用程

序时，还可以

注入代码，并

在基线平台上进行构建

。

264

｜ 第 10 章

图 10-19：LexNLP

的输出

图 10-20：对文档

集的法律实体进行聚类

医疗、金融和法律 ｜ 265

10.3

小结

本

章介绍了自然语言处理

在医疗、金融和法律中的

应用，涵盖了模型构建、使

用在线 API

和数据集创建等

方面的内容。这些领域提

供了一系列不同的问题

和解决方案，因此，即使

你

从事的领域与此无关，你

在这里学到的技术也可

以用于解决任何非常规

问题。第 11

章

将介绍如何将

所有内容结合起来，构建

一个完整的自然语言处

理解决方案。

266 ｜ 第 10

章

第四部

分

综合

第 1 1

章

端到端自然

语言处理系统

过程比目

标更重要。人生路上，过程

远比结果更重要。

——安东尼

• 摩尔

从自然语言处理流

水线的基本组成到自然

语言处理在不同领域中

的应用，本书已经阐述了

一系列的自然语言处理

问题。有效运用所学知识

来构建端到端的自然语

言处理软件产品，

不仅需

要将自然语言处理中的

各个步骤拼接在一起，还

要考虑这个过程中的若

干决策点。

虽然这些知识

中有很多只来自经验，但

本章提炼了一些端到端

自然语言处理过程的知

识，

帮助读者更快更好地

进行实际操作。

第 2 章已经

介绍了自然语言处理系

统的典型流水线。那么这

一章与第

2 章有什么不同

呢？

第 2 章主要关注流水线

的技术方面，例如，如何表

示文本，应该做哪些预处

理步骤，如何

构建模型，以

及如何评估模型。虽然后

续内容深入研究了各种

自然语言处理任务的不

同算

法，并介绍了自然语

言处理在医疗保健、电子

商务和社交媒体等各个

行业中的应用，然

而，在所

有这些内容中，部署和维

护自然语言处理系统的

相关问题以及管理此类

项目要遵

循的流程则着

墨不多。而这些正是本章

的重点。这里讨论的大多

数要点不仅广泛适用于

自

然语言处理，而且也广

泛适用于数据科学、机器

学习、人工智能等其他领

域。在本章中，

这些术语是

交替使用的；但如果特指

自然语言处理任务，则会

明确提及。

本章先重温第

2

章中介绍的自然语言处

理流水线，特别是最后两

个步骤：(1) 部署；(2) 模

型监控和

更新。这在前面几章中没

有涉及。本章随后介绍如

何构建和维护成熟的自

然语言

处理系统，接着讨

论各种人工智能团队所

遵循的数据科学过程，特

别是构建自然语言处理

软件方面的数据科学过

程。最后以大量的建议、最

佳实践以及成功交付自

然语言处理项目

的注意

事项来结束本章。下面先

从自然语言处理软件的

部署开始。

269

11.1　重温自然语言

处理流水线：部署自然语

言

处理软件

如第 2

章所介

绍的，自然语言处理项目

的典型生产流水线包括

以下几个阶段：数据获取

、

文本清洗、文本预处理、文

本表示和特征工程、建模

、评估、部署、监控和模型更

新。在

工作中遇到自然语

言处理方面的新问题时

，必须首先考虑创建一个

涵盖这些阶段的自然语

言处理流水线。在这个过

程中，需要考虑以下几个

问题。

• 需要什么样的数据

来训练自然语言处理系

统？从哪里获得这些数据

？这些问题在开始阶

段很

重要，在模型成熟后也很

重要。

• 有多少数据可用？如

果这还不够，可以尝试哪

些数据增强技术？

• 如果有

必要，如何标注数据？

• 如何

量化模型的性能？使用什

么指标来量化？

• 如何部署

系统？使用云 API 调用、整体式

系统或边缘设备上的嵌

入式模块？

• 如何提供预测

：流式处理还是批处理？

• 需

要更新模型吗？如果需要

，更新频率是每天、每周还

是每月？

• 是否需要模型性

能的监控和警报机制？如

果是，需要什么样的机制

，如何构建这种机制？

厘清

这些关键决策点后，流水

线的总体设计也就大功

告成。接下来可专注于构

建具有强大

基线的第一

版模型、实现流水线、部署

模型，并在此基础上迭代

改进解决方案。第

2 章介

绍

了不同自然语言处理任

务在部署之前的各个阶

段。下面来看流水线的最

后阶段：部署、

监控和模型

更新。

部署意味着什么？构

建的任何自然语言处理

模型通常只是大型软件

系统的一部分。一旦

模型

能在隔离状态下运行良

好，就可以将其接入更大

的系统中，并确保一切正

常。将模

型集成到软件中

并使其具备生产条件的

所有相关任务称为部署

。模型部署的典型步骤列

举如下。

1. 模型打包：如果模

型很大，为了方便访问，可

能需要将模型保存在 AWS S3、Azure Blob

存

储或谷歌云存储等持久

化云存储中。当然，模型也

可以序列化并封装在库

调用中，以

便于访问。另外

，还有像 ONNX 这样的开放格式

，提供了跨越不同框架的

互通性。

2. 模型服务：模型可

以作为

Web 服务提供给其他

服务使用。但是，如果使用

紧密耦合的

系统和批处

理，则模型可以集成到 Airflow、Oozie 或

Chef 等任务流系统。此外，微软

还发布了

MLOps 和 Python 中 MLOps 的参考流

水线。

3. 模型扩展：作为 Web 服务

托管的模型应该能够根

据请求流量进行扩展。作

为批处理服

务运行的模

型也应该能够根据输入

批处理大小进行扩展。公

开云平台和内部云系统

都有

实现这一点的技术

。图

11-1 显示了 AWS 文本分类的流

水线。

270 ｜

第 11 章

端到端自然语

言处理系统 ｜ 271

AWS Batch

AWS云

S3模型存储

桶

自定义Python代码 Amazon

SageMaker

Amazon ECR

测试数据

训练数据

lambda函数

S3结果存储

桶

S3预测存储桶

图 11-1：AWS 云和 SageMaker 提

供文本分类服务

下面通

过一个例子来说明如何

将自然语言处理模型部

署到更大的系统中。

示例

场景

假设某社交媒体平

台需要构建一个分类器

来识别用户的恶意评论

。分类器的目标是标记任

何潜在的恶意内容，并将

其发送给人工审核，防止

恶意内容出现在平台上

。在收集相关数

据、设计一

组特征，并测试一系列算

法之后，终于建好了预测

模型，模型可将新评论作

为

输入，并将其分类为恶

意内容或安全内容。那么

接下来的步骤是什么？

模

型只是大型社交媒体平

台的一小部分。社交媒体

平台通常由若干组件构

成，包括动态渲

染内容的

组件，各种与用户交互的

模块，负责存储和检索数

据的组件，等等。平台的不

同

子系统可能用不同的

编程语言编写。分类器只

是产品的一个小组件，需

要集成到更大的

系统中

。那么该怎么做呢？要解决

这种问题，一种常见方法

是创建 Web 服务，而模型在

Web

服

务的背后运行。产品的其

余部分通过 Web 服务与模型

交互，例如使用新的评论

查

询服务，并获得返回的

预测。必要时，Web 服务的调用

可集成到产品中。Flask、Falcon 和

Django 等常

见的 Web 应用程序框架可用

于创建此类 Web 服务。

开发各

种自然语言处理解决方

案需要依赖一系列预先

存在的库。设置 Web 服务并托

管云

中或某些服务器中

构建的模型，需要确保各

种库之间不存在兼容性

问题。为了解决这个问

题

，有一系列的选项可供选

择。最常见的选择是将各

种库打包到 Docker

或 Kubernetes 容

器中。将

Web 服务用于生产需要解决

许多其他问题，如技术栈

、负载平衡、延迟、吞吐

量、可

用性和可靠性等。构建和

制作生产模型涉及大量

的工程任务，通常非常耗

时。AWS

SageMaker 和 Azure Cognitive Services 等云服务试图简化

这些工程任务。有时，整个

过程

直到最后一个细节

都是自动化的，只需单击

一下即可完成服务的设

置。这样做的目的是让

人

工智能团队专注于最重

要的部分：模型构建。

另一

个需要解决的重要问题

是模型尺寸。现代自然语

言处理模型可能相当庞

大。例如，谷

歌的 Word2vec 模型大小

为

4.8GB，仅加载到内存就需要

100 秒以上。同样，fastText 分类

模型的

大小通常超过 2GB。而像 BERT

这样

的深度学习模型则更为

庞大。在云中托管如此

庞

大的模型既具有挑战性

，也很昂贵。为了解决这些

问题，模型压缩领域有很

多工作正在

进行，其中一

些列举如下。

• “Compressing BERT

for Faster Prediction”，Rasa 自然语言处

理团队的博客文章。

• “A

Survey of Model Compression and Acceleration

for Deep Neural Networks”，微软

研究

院和清华大学一个

团队的合作报告。

•

“FastText.zip: Compressing text classification models”，Facebook 人工智

能研究团队的一

份报告

。

• “Awesome ML Model Compression”，Cedric

Chee 的 GitHub 存储库，包括相关的论

文、

视频、库和工具。

这些只

是自然语言处理模型各

种部署步骤的简要概述

。详细介绍见相关书籍和

材料。作为

开始，感兴趣的

读者可以阅读 Andriy Burkov 的《机器学

习工程实战》一书的后面

几章。

对于大多数行业用

例，模型构建很难一劳永

逸。随着部署系统的使用

越来越多，构建的模

型需

要适应新的场景和新的

数据点。因此，模型应定期

更新。下面讨论构建和维

护成熟自

然语言处理软

件时需要考虑的问题。

11.2　构

建和维护成熟的系统

在

大多数现实环境中，数据

中的基本模式会随着时

间的推移而变化。这意味

着很久以前训

练的模型

可能会过时，也就是说，用

于训练模型的数据与生

产环境中输入模型进行

预测的

数据非常不同。这

称为协变量偏移（covariate

shift），它会导

致模型的性能下降。模型

更新

是处理此类场景的

常用方法。类似地，在大多

数行业环境中，一旦模型

的第一个版本投入

使用

，改进模型就变得不可避

免。更新和改进现有的自

然语言处理模型，可能意

味着使用

新增的训练数

据进行重新训练，这有时

需要添加新的特征。在更

新模型时，需要确保新部

署系统的性能至少与现

有系统一样好。大多数模

型更新和改进会导致更

复杂的模型。随着

模型复

杂性的增加，需要确保系

统不会在不断增加的复

杂性下崩溃。这就需要管

理成熟自

然语言处理模

型的复杂性，同时确保它

也是可维护的。在这个过

程中，需要考虑以下几个

问题：

272 ｜ 第 11 章

•

寻找更好的特

征；

• 迭代现有模型；

• 代码和

模型再现性；

•

故障排除和

测试；

• 尽量减少技术债务

；

• 自动化机器学习过程。

本

节将逐一介绍这些问题

。下面先讨论如何找到更

好的特征。

11.2.1　寻找更好的特

征

本书反复强调了首先

构建简单模型的重要性

。第一版模型往往不是最

终的模型。可能需要

添加

新的特征，并定期对第一

版之后的模型进行重新

训练。其目标是找到最具

表现力的特

征，以捕捉数

据中对预测有用的规律

。那么如何开发这些特征

？第 3

章介绍了生成文本特

征表示的不同方法。为了

开发特定的特征，可以从

不需要问题域先验知识

的方法（例如，

基本向量化

、分布式表示和通用表示

）开始，或者使用问题域的

先验知识开发特征（例

如

，人工特征），也可以把两者

结合起来。

为给定的问题

设计特定的特征（即特征

工程）既困难又昂贵。因此

通常需要先从与问题无

关的文本表示开始。然而

，特定于领域的特征有其

自身的价值。例如，在情感

分类的任务

中，除了原始

文本的向量表示外，特定

于领域的指标，例如否定

词的计数、肯定词的计

数

，以及其他词和短语级别

的特征，都有助于更好地

提取情感。

假如现在已经

实现了一系列特征来构

建自然语言处理模型，那

么最好的模型是否需要

这

些特征中的每一个特

征？在实现的若干个特征

中，如何选择信息量最大

的特征？例如，

如果使用两

个特征，其中一个特征可

以从另一个特征中派生

出来，那么这个特征并没

有

向模型添加任何额外

的信息。特征选择是处理

此类情况并做出明智决

策的一项重要技术。

有很

多统计方法可以用来删

除冗余或不相关的特征

，从而微调特征集。这一广

泛领域称

为特征选择。

包

装方法和过滤方法是两

种常用的特征选择技术

。包装方法使用机器学习

模型对不同的特

征子集

进行评分。用每个新的子

集训练模型，并用保留集

测试模型，然后根据模型

的错误

率识别最佳特征

。包装方法在计算上很昂

贵，但通常可以提供最好

的特征集。过滤方法使

用

某种代理度量而不是错

误率对特征进行排序和

评分（例如，特征之间的相

关性以及特征

与输出预

测的相关性）。这样的度量

计算起来很快，同时仍然

能够捕获特征集的有用

性。

过滤方法的计算成本

通常低于包装方法，但过

滤方法生成的特征集并

没有针对特定类型的

预

测模型进行优化。在基于

深度学习的方法中，虽然

特征工程和特征选择是

自动化的，但

仍然需要对

各种模型结构进行实验

。

由于特征选择方法通常

是特定于任务的（即分类

任务的方法不同于机器

翻译任务的方

法），因此感

兴趣的读者可以阅读谷

歌人工智能的博客文章

“Wide & Deep

Learning: Better 

Together with TensorFlow”中的稀疏特征、稠密特征

和特征交互等内容。《精通

特征工程》1

注 1：此书已由人

民邮电出版社图灵公司

出版，参见：ituring.cn/book/2050。——编者注

端到端

自然语言处理系统 ｜ 273

一书

也很有用。但是，这里的概

述旨在说明特征选择在

构建成熟的生产级自然

语言处理系

统中的作用

。假如现在需要添加新的

特征并对其进行评估，那

么应该如何将这一过程

纳入

训练过程并更新自

然语言处理模型呢？现在

来看这个问题。

11.2.2　迭代现有

模型

如前所述，任何自然

语言处理模型都不是一

成不变的。即使在生产系

统中，也经常需要更

新模

型。这有以下几个原因。首

先，更多和更新的数据可

能会不同于以前的训练

数据。如

果不更新模型来

反映这一变化，模型很快

就会过时，并产生糟糕的

预测。其次，用户可能

会给

出一些模型预测出错的

反馈。这就需要对模型及

其特征进行反思，并做出

相应的修

改。无论何种情

况，都需要构建一个流程

，定期重新训练和更新现

有模型，并在生产中部

署

新模型。

当开发一个新的

模型时，为了了解新模型

所能带来的价值，直观地

说，将预测结果与以前

的

最佳模型进行比较总是

好的。那么如何判断新的

模型比现有的模型更好

？为了分析模型

性能，可以

比较两个模型的原始预

测，也可以比较基于预测

的派生性能。下面通过回

顾本

章前面的恶意评论

检测示例来解释这两种

方法。

假设现在有一个恶

意评论和非恶意评论的

黄金标准测试集，那么总

是可以用它来比较新旧

模型的分类准确度。另外

，也可以使用外部验证方

法，从其他方面来比较，例

如每天有多

少模型决策

被用户质疑。可以设置一

个仪表板来定期监控这

些指标，并为每个模型显

示这

些指标，这样就可以

在构建的各种模型中选

择相比原先的模型改进

效果最佳的模型。最

后，还

可以使用旧模型（或任何

基线系统）对新模型进行

A/B

测试，并测量业务 KPI，以

了解

新模型的性能。在上线新

模型时，最好先将其推广

到一小部分用户，监控其

性能，然

后逐步扩展到整

个用户群。

11.2.3　代码和模型再

现性

确保自然语言处理

模型在不同的环境中以

相同的方式工作，对于任

何项目的长期成功都是

至关重要的。通常认为可

再现的模型或结果更可

靠。在构建系统时，可以使

用一系列最佳

实践来实

现这种再现性。

保持代码

、数据和模型之间的分离

始终是一个好的策略。分

离代码和数据通常是软

件工程

中的最佳实践，但

对于人工智能系统来说

，这变得更加重要。虽然代

码有成熟的版本控制

系

统，如 Git，但模型和数据集的

版本控制可能会有所不

同。最近，“数据版本控制”（Data

Version Control）等

工具可以解决这个问题

。妥善命名模型和数据版

本始终是一种好的做

法

，这样就可以在需要时轻

松地还原回来。在存储模

型时，应尝试将所有模型

参数以及其

他变量放在

单独的文件中。同样，尽量

避免在模型中硬编码参

数值。如果在训练过程中

必

须使用随机数（例如种

子值），则在代码中以注释

的形式进行解释。

另一个

好的做法是经常在代码

和模型中创建检查点。应

该定期将学习到的模型

存储在库

中，或者在重要

节点时存储。在训练模型

时，使用相同的种子进行

随机初始化也是一个好

主意。这确保了每次使用

相同的参数和数据时，模

型都会生成类似的结果

和内部表示。

274 ｜ 第 11 章

提高再

现性的关键是要明确记

录所有步骤。这在数据分

析的探索阶段尤为必要

。同样，

它有助于记录尽可

能多的中间步骤和数据

输出。这有助于将实验模

型转换为生产模型，

而不

丢失任何信息。建议进一

步阅读关于人工智能再

现性的最新报告“State of the Art:

Reproducibility in Artificial Intelligence”，以及对

Facebook 再现性研究员 Joelle

Pineau 的采

访“This AI Researcher Is

Trying to Ward Off a Reproducibility

Crisis”。这

就引出了本节的下

一个

主题。在进行所有这些迭

代和构建多个模型后，如

何确保训练过程中没有

错误和漏

洞？如何确保数

据没有噪声？如何对代码

和模型进行故障排除和

测试？

11.2.4　故障排除和可解释

性

为了保证软件的质量

，测试是任何软件开发过

程中的关键步骤。然而，考

虑到机器学习模

型的概

率性质，如何对机器学习

模型进行测试并非显而

易见。图 11-2 和图 11-3 展示了测

试

人工智能系统的一些良

好实践。第

4 章已经介绍了

如何使用 Lime（见图 11-3）。

图 11-2：TensorFlow

模型分

析（TFMA）

端到端自然语言处理

系统 ｜ 275

预测概率

特征

值

图

11-3：用于自然语言处理模型

分析的 Lime

正如本章前面所

讨论的，模型只是任何人

工智能系统的一个小组

件。当涉及整个系统的测

试时，除了模型之外，大多

数软件工程的测试技术

都是适用的，并且效果不

错。在测试模

型时，以下步

骤非常有用。

•

在模型构建

阶段使用的训练、验证和

测试数据集上运行模型

。任何指标的结果都不应

存

在重大偏差。K 折交叉验

证法通常用于验证模型

性能。

• 用极端情况测试模

型。例如，对于情感分类，用

双重或三重否定的句子

进行测试。

•

分析模型所犯

的错误。分析的结果应该

与开发阶段模型所犯错

误的分析结果相似。对于

自然语言处理，TensorFlow 模型分析

、Lime、Shap 和注意力网络等软件包

和技术可以

用于深入理

解模型的所作所为。详见

图 11-2 和图

11-3。在开发阶段和生

产阶段，分析

的结果不应

该有太大的变化。

• 另一个

好的做法是构建一个子

系统来跟踪各个特征的

关键统计信息。由于所有

的特征都

是数值特征，因

此可以维护均值、中位数

、标准差、分布图等统计数

据。这些统计数据

中出现

任何偏差都是一个危险

信号，系统很可能会做出

错误的预测。原因可能简

单到流

水线中的错误，也

可能复杂到基础数据中

的协变量偏移。TensorFlow Model Analysis 等

软件包

可以跟踪这些指标。图 11-4

显

示了数据集各种特征的

指标分布，可用于跟踪发

现协变量偏移或错误。

276 ｜ 第

11 章

图

11-4：TensorFlow Extended 的特征统计

创建用

于跟踪模型指标的仪表

板，并在仪表板上创建警

报机制，以防指标出现任

何偏差。

下一节将详细讨

论这一点。

知道模型的内

部机制总是好的。这有助

于理解模型的工作方式

。人工智能的一个关键问

题

是如何创建这样的智

能系统：模型的所作所为

是可以解释的。这叫可解

释性。可解释性

是指人类

能够理解某种模型决策

背后原因的程度（参见 Tim Miller 的

文章“Explanation in

Artificial Intelligence: Insights from the Social

Sciences”）。虽然机器学习（如决

策树、随机森

林、XGboost 等）中的许

多算法以及计算机视觉

都具有很好的可解释性

，但对于自然语言

处理，尤

其是深度学习算法而言

，情况并非如此。随着注意

力网络、Lime 和 Shapley

等最

新技术的

出现，自然语言处理模型

有了更多的可解释性。感

兴趣的读者可以阅读 Christoph 

Molnar 的

Interpretable

Machine Learning: A Guide for Making

Black Box Models Explainable，

以进一步了解该主题。

11.2.5

监

控

一旦机器学习系统已

经部署并投入生产，就需

要确保模型持续正常工

作。如果每天都使用

新的

数据点自动训练模型，则

某些错误可能会潜入其

中，或者模型可能会出现

故障。为了

确保这些情况

不会发生，需要监控模型

的一系列指标，并在正确

的时间点触发警报。

• 必须

定期监控模型性能。对于

基于

Web 服务的模型，指标可

以是响应时间的平均值

和

各种百分位数，例如第

50（中位数）、第 90、第 95 和第

99（或更高

的）分位数。如果

模型部署

为批处理服务，则必须监

控批处理和任务时间的

统计信息。

• 同样，存储监控

模型参数、行为和关键性

能指标（KPI）也是有帮助的。在

恶意评论的

例子中，模型

的 KPI

可以是用户报告但未

被模型标记的评论的百

分比。对于文本分类

服务

，模型的 KPI 可以是每天所划

分的类别的分布。

• 对于正

在监控的所有指标，需要

定期运行异常检测系统

，提醒正常行为中出现的

异常变

化。这可能是 Web 服务

响应率的突然增加或重

新训练次数的突然减少

。在最坏的情况下，

当性能

大幅度下降时，可能还希

望触发断路器（即切换到

稳定的模型或默认方法

）。

端到端自然语言处理系

统 ｜

277

• 如果整个工程流水线

使用了日志框架，那么框

架很可能也支持对任何

指标出现的异常进行

监

控。例如，Elastic 的 ELK

Stack 提供了内置的

异常检测功能。日志管理

工具 Sumo Logic

也可以对异常值进

行标记，并根据需要查询

异常值。此外，微软也提供

异常检测服务。

随着项目

规模的扩大，监控机器学

习模型及其部署可以节

省大量时间。随着系统的

成熟和

模型的稳定，适当

的监控可以使机器学习

开发与运维团队能够在

很大程度上对其进行管

理，因此数据科学家可以

致力于解决其他更难的

问题。不过，随着系统的成

熟，越来越多

的技术债务

也开始积累。这将在下一

节中讨论。

11.2.6　尽量减少技术

债务

在本书中，特别是在

本章中，我们看到了自然

语言处理模型的训练，将

模型部署到更大的

系统

中，并对模型进行迭代和

改进。当系统从第一个版

本开始迭代时，系统和各

种组件

（包括模型）很容易

变得复杂。这就带来了系

统维护的挑战。我们可能

无法知道模型复杂

性的

增加是否必然带来模型

的改进。这种情况下可能

会产生技术债务。下面简

要介绍一下

如何解决人

工智能软件中的技术债

务问题。

任何软件系统都

需要为未来进行规划和

构建。在持续迭代和测试

之后，必须确保系统仍能

继续保持性能和易于维

护。未使用的和执行不当

的改进可能会产生技术

债务。如果不使用

某个特

征或特征组合，那么就需

要将其从流水线中删除

。不起作用的特征或代码

只会阻塞

基础设施，阻碍

快速迭代，并降低清晰度

。

一个好的经验法则是查

看特征的覆盖率。如果一

个特征只存在于几个数

据点中，比如说只

占数据

的 1%，那么这个特征可能不

值得保留。但即使是这样

的规则也不能盲目照搬

。例

如，如果该特征仅覆盖

1% 的数据，但仅基于该特征

就能提供 95%

的分类准确率

，那么该

特征就非常有效

，当然值得继续使用。从经

验来看，正如本书多次重

申的，如果想把技术

债务

降到最低，在性能相当的

情况下，应该选择简单的

模型。但是，如果没有等效

的简单

模型，可能还是需

要选择复杂的模型。

关于

构建成熟的机器学习系

统，除了上述建议外，下面

再分享一些具有里程碑

意义的工作。

•

“A Few Useful Things to Know

about Machine Learning”，作者是华盛

顿大学的 Pedro Domingoes。

•

“Machine Learning: The High Interest Credit

Card of Technical Debt”，作者来自谷歌

人工

智能的一个团队。

•

“Hidden Technical Debt in Machine Learning

Systems”，作

者来自谷歌人工智能的

一个团队。

• 《精通特征工程

》，作者是 Alice Zheng 和

Amanda Casari。

• “Ad Click Prediction:

A View from the Trenches”，谷歌搜索团队

对于大型在线机器学习

系

统面临的问题所做的

研究。

• “Rules of Machine Learning: Best

Practices for ML Engineering”， 谷 歌

Martin Zenkovich

创建的在线指

南。

• “The Unreasonable

Effectiveness of Data”，加州大学伯克利分校

著名研究员 Peter Norvig

和谷歌人工

智能团队的报告。

• “Revisiting Unreasonable Effectiveness of Data

in Deep Learning Era”，卡内基

– 梅隆大学

团队对上一份

报告的进一步探讨。

278 ｜ 第 11 章

上面讨论了构建成熟人

工智能系统的各种最佳

实践。但是，从寻找更好的

特征到数据集的

版本控

制，这些都是手动完成的

，而且需要耗费大量的精

力。为了构建智能机器、减

少手

动工作，在这一终极

目标的驱动下，最近的一

项有趣工作是使人工智

能系统的构建实现某

些

方面的自动化。下面来看

这个方向上的一些重要

工作。

11.2.7　自动化机器学习

机

器学习的一个终极追求

是使越来越多的特征工

程过程自动化。为此，人们

创造了自动机

器学习（AutoML）这

一子领域，其目的是使机

器学习变得更加容易。在

大多数情况下，

AutoML 可以生成

一个数据分析流水线，其

中包括数据预处理、特征

选择和特征工程方法。

对

于特定的问题和数据，这

个流水线本质上可以选

择优化的机器学习方法

和参数设置。对

于机器学

习专家来说，所有这些步

骤可能很耗时，而对于初

学者来说，这些甚至可能

难以

驾驭，因此 AutoML

成为机器

学习世界中一个不可或

缺的桥梁。AutoML 本质上是“使用

机器学习进行机器学习

”，因此那些希望利用大量

数据的人可以更广泛地

使用这种强大而

复杂的

机器学习技术。

例如，谷歌

的一个研究小组曾使用

AutoML 技术对宾州树库（Penn Treebank）数据集

进行

语言建模。宾州树库

是语言结构的基准数据

集。该研究小组发现，使用

AutoML 方法设

计出的模型可以

达到世界一流机器学习

专家设计的先进模型的

准确度。图 11-5 显示了由

AutoML

生成

的神经网络的示例。

图 11-5：由

AutoML 生成的网络

图 11-5

的左侧是

谷歌专家为解析文本而

创建的神经网络，右侧是

由谷歌 AutoML 自动创

建的神经

网络。AutoML 能自动探索各种神

经网络结构，其效果手动

制作的模型不相上下。

令

人着迷的是，AutoML

系统在设计

机器学习模型方面几乎

和人类一样出色。

不过，AutoML 仍

然是机器学习的前沿技

术。只有当传统的方法无

法进一步提升性能时，

才

应该自下而上构建模型

。如果从零开始，AutoML 通常需要

大量的计算和 GPU

资源和更

高的技术水平。

端到端自

然语言处理系统 ｜ 279

1. auto-sklearn

正如前

面提到的，在使用自动化

机器学习之前，最好先尝

试所有的其他方法。如果

确实需

要使用 AutoML，那么最好

的一个库是 auto-sklearn。它利用贝叶

斯优化和元学习的最新

进

展，在巨大的超参数空

间中搜索，自动找出一个

相当好的机器学习模型

。由于 auto-sklearn

集成了常见的机器

学习库 sklearn，因此使用起来非

常简单：

import autosklearn.classification 

import

sklearn.model_selection 

import sklearn.datasets 

import

sklearn.metrics 

X, y = sklearn.datasets.load_digits(return_X_y=True)

X_train, X_test, y_train, y_test =

sklearn.model_selection.train_test_split(X, y, random_state=1) 

automl =

autosklearn.classification.AutoSklearnClassifier() 

automl.fit(X_train, y_train) 

y_hat

= automl.predict(X_test) 

print("Accuracy", sklearn.metrics.accuracy_score(y_test, y_hat))

这段代码的作用

是为 MNIST 数字数据集构建一

个 autosklearn 分类器。它将数据集拆

分为

训练集和测试集。当

运行约一小时后，将自动

产生准确率超过

98% 的模型

。

可以看看内部发生了什

么。下面的代码片段显示

了 AutoML 的不同阶段：

[(0.080000,

SimpleClassificationPipeline({'balancing:strategy': 'none', 

'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:

__choice__': 

'lda', 

'imputation:strategy': 'mean',

'preprocessor:__choice__': 'polynomial', 

'rescaling:__choice__': 'minmax',

'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 

'classifier:lda:n_components': 151,

'classifier:lda:shrinkage': 'auto', 'classifier:lda:tol': 

0.02939556179271624,

'preprocessor:polynomial:degree': 2, 'preprocessor:polynomial:include_bias': 

'True',

'preprocessor:polynomial:interaction_only': 'True', 

'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0729529152649298},

dataset_properties={ 

 'task': 2,

'sparse': False, 

 'multilabel': False,

'multiclass': True, 

 'target_type':

'classification', 

 'signed': False})),

... 

... 

...

... 

(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'none',

'categorical_encoding:__choice__': 

'one_hot_encoding', 'classifier:__choice__': 'passive_aggressive',

'imputation:strategy': 'mean', 

'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__':

'minmax', 

'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 

280

｜ 第 11 章

'classifier:passive_aggressive:C':

0.03485276894122253, 'classifier:passive_aggressive:average': 'True', 

'classifier:passive_aggressive:fit_intercept': 'True',

'classifier:passive_aggressive:loss': 'hinge', 

'classifier:passive_aggressive:tol': 4.6384320611389e-05,

'preprocessor:polynomial:degree': 3, 

'preprocessor:polynomial:include_bias': 'True',

'preprocessor:polynomial:interaction_only': 'True', 

'categorical_encoding:one_hot_encoding:minimum_fraction': 0.11994577706637469},

dataset_properties={ 

 'task': 2,

'sparse': False, 

 'multilabel': False,

'multiclass': True, 

 'target_type':

'classification', 

 'signed': False})),

] 

auto-sklearn results:

Dataset name: d74860caaa557f473ce23908ff7ba369 

 Metric:

accuracy 

 Best validation score:

0.991011 

 Number of target

algorithm runs: 240 

 Number

of successful target algorithm runs: 226

Number of crashed target algorithm

runs: 1 

 Number of

target algorithms that exceeded the time

limit: 2 

 Number of

target algorithms that exceeded the memory

limit: 11

下面

来看谷歌云服务，以及其

他一些解决自然语言处

理问题的方法。

2. 谷歌云 AutoML

和

其他技术

谷歌云服务最

近也发布了 AutoML 服务。除了按

规定的格式提供训练数

据之外，不需要任

何技术

知识。谷歌专门为计算机

视觉、结构化表格数据以

及自然语言处理等人工

智能构建

了

AutoML 云服务。

对于

自然语言处理，训练以下

自定义模型时会自动应

用谷歌云 AutoML：

• 文本分类；

• 实体

提取；

• 情感分析；

• 机器翻译

。

对于所有这些任务，谷歌

云定义了 AutoML 模型所需的数

据格式。微软在其 Azure 机器学

习中也提供了 AutoML

工具。

另外

，Kaggle 竞赛顶级大师 Abhishek Thakur 创建的

AutoCompete 框

架可以更加自动化地

处

理自然语言处理问题。尽

管最初的方法针对的是

竞赛中的数据科学问题

，但现在该框架

已经发展

为解决此类问题的通用

框架。他还发布了名为“Approaching (Almost) Any

NLP 

Problem on Kaggle”的

详细笔记本，为自然语言

处理问题创建了通用的

建模框架（具有定

义良好

的数据集和目标）。虽然可

能无法完全解决特定的

自然语言处理任务，但这

是创建

基线模型的良好

开端。

端到端自然语言处

理系统 ｜ 281

282 ｜

第 11 章

到目前为止

，我们已经讨论了构建、部

署和维护自然语言处理

软件时可能出现的一系

列问

题。然而，遵循标准的

产品开发过程也同样重

要。虽然软件开发过程和

生命周期这一领域

的理

论已经很成熟，但如果项

目涉及本书讨论的各种

预测模型，仍然有一些重

要的事项需

要考虑。下面

来看这方面的内容。

11.3　数据

科学过程

数据科学是一

个宽泛的术语，描述的是

从各种形式的数据中提

取有意义的信息和可执

行的

见解的算法和过程

。因此，行业中所有的自然

语言处理工作都可以归

入数据科学的范畴。

虽然

数据科学是一个相对较

新的术语，但在过去几十

年中，它一直以某种其他

形式存在

着。多年来，人们

制定并正式确定了数据

处理的最佳过程和实践

。KDD 过程和微软 Team 

Data Science

Process（TDSP）是业内的两

种常见过程。

11.3.1 KDD过程

ACM SIGKDD 知识发

现和数据挖掘会议（KDD）是世

界上最古老、最著名的数

据挖掘会

议之一。该会议

的一些创始人在 1996 年创建

了 KDD 过程。如图 11-6

所示，KDD 过程由

一系列步骤组成，可用于

数据科学或数据挖掘问

题，以获得更好的结果。

解

释/评估

数据挖掘

转换

预

处理

选择

数据

转换后的

数据

预处理后的

数据

目

标

数据

模式

知识

图 11-6：KDD 过程

这些步骤的顺序如下。

1. 理

解领域：包括了解应用程

序和理解问题的目标。它

还涉及深入问题领域并

提取相关领

域知识。

2. 目标

数据集创建：包括选择特

定于问题的数据和变量

子集。可用的数据源可能

有很多，

但需要专注于特

定的子集。

3. 数据预处理：包

括为了确保数据一致性

所需的所有工作，包括填

充缺失值、降噪和删除

异

常值。

4. 数据简化：如果数据

具有较多维度，可以使用

此步骤来简化数据。这包

括降维和将数据

投影到

另一个空间等步骤。此步

骤是可选的，具体取决于

数据的情况。

5. 选择数据挖

掘任务：一个问题可以使

用各类算法，例如回归、分

类或聚类。需要根据第

一

步的理解，选择正确的任

务。

6. 选择数据挖掘算法：选

择数据挖掘任务后，需要

选择正确的算法。例如，对

于分类，可

以选择

SVM、随机森

林、CNN 等算法，如第 4 章所述。

7. 数

据挖掘：这是将第

6 步选择

的算法应用于给定数据

集并创建预测模型的核

心步骤。参

数和超参数的

调优也发生在这一步。

8. 解

释：应用算法后，用户需要

获得结果的解释。可以通

过结果的可视化来部分

地实现模

型解释。

9. 整合：这

是将构建的模型部署到

现有系统中、记录方法并

生成报告的最后一步。

如

图 11-6 所示，KDD 过程是高度迭代

的。在不同的步骤之间可

以有任意数量的循环。在

每一步中，都可以而且可

能需要回到前面的步骤

，并对其中的信息进行精

炼。在面对特定

的数据科

学问题时，这个过程是一

个很好的参考。本书中讨

论的流水线同样也是将

某种结

构引入自然语言

处理系统的构建，不过二

者并非完全相同。现在来

看第二个过程。

11.3.2　微软TDSP

KDD 过程

于

20 世纪 90 年代末引入。随着

机器学习和数据科学领

域的发展，专门从事此

类

数据科学项目的大型团

队开始出现。此外，在快速

发展的数据驱动开发领

域中，需要更

灵活和迭代

式的框架，因此其他数据

科学过程也开始出现。微

软

Team Data Science Process

（TDSP）解决了这一问题。它由

微软 Azure

团队于 2017 年发布，是一

种现代的机器学习和

数

据科学过程。

TDSP 是一个敏捷

的迭代式数据科学过程

，可用于执行和交付高级

分析解决方案。它旨在

提

高企业组织中数据科学

团队的协作和效率。TDSP 的主

要特点列举如下：

• 数据科

学生命周期定义；

• 标准化

的项目结构，包括项目文

档和报告模板；

• 项目执行

的基础设施；

• 用于数据科

学的工具，如版本控制、数

据探索和建模。

TDSP 文档对上

述这些方面进行了详细

的介绍，因此本节只做简

要介绍。TDSP

数据科学生

命周

期显示了数据项目的不

同阶段，如图 11-7 所示。

端到端

自然语言处理系统 ｜

283

284 ｜ 第 11 章

数据科学生命周期

开始

建模 数据获取

与理解

数

据源 特征

工程

变换、分箱

时间、文本、

图像特征选择

本地与云

数据库与文件

流水线 流处理与批处理

低频与高频

环境

整理、探

索

和清洁

本地与云

数据

库、数据湖、

小数据、中数据

、

大数据

结构化vs非结构化

数据验证和清洗可视化

模型

训练

算法

集成

参数

调优

重新训练

模型管理

模型

评估

交叉验证

模型

报告

A/B测试

业务理解

部署

模型

存储

智能

应用程序

Web

服务

评分、性能

监控等

结

束 客户

验收

图 11-7：微软 TDSP

生命

周期

虽然 TDSP 与 KDD 过程有一些

相似之处，但

TDSP 从业务和团

队管理的角度定义了数

据

科学项目的生命周期

。这包括以下几个阶段：

• 业

务理解；

•

数据获取和理解

；

• 建模；

• 部署；

•

客户验收。

数据

科学生命周期在较高层

次上展示了高效、敏捷的

数据科学团队的各个组

成部分应该如

何运作。TDSP 文

件中的“宪章”（Charter）和“退出报告

”（Exit Report）文件尤其重要。

它们有助

于在业务开始时定义项

目，并向客户提供最终报

告。

总的来说，这些过程的

作用是将本书中讨论过

的问题和解决方案从原

型开发转换为生产部

署

。当然，这些过程并不特定

于自然语言处理，任何涉

及机器学习方法的数据

驱动项目都

可以使用这

些通用建议。虽然随着该

领域的发展，数据科学也

出现了其他类似的项目

管理

过程，但这里的概述

有助于你了解软件开发

中管理自然语言处理项

目时应该注意的事项。

11.4　让

人工智能在组织中取得

成功

到目前为止，本书的

重点是成功构建和部署

各种人工智能问题的解

决方案。任何人工智能

项

目的成功不仅取决于解

决方案的技术优势，还涉

及许多其他因素。众所周

知，行业中大

量人工智能

项目失败的原因是模型

没有得到部署，或者部署

后无法达到目标。根据 Gartner

最

近的一项研究，超过 85%

的人

工智能项目均以失败告

终。为了使人工智能项目

取得成

功，下面讨论其中

的关键问题和经验法则

。许多观点来自于我们在

不同组织中的不同人工

智能领域的工作经验。

11.4.1　团

队

解决人工智能问题要

有合适的团队。理解问题

陈述、确定优先级、开发、部

署和使用，这

些在很大程

度上取决于团队的水平

。虽然团队组成没有固定

的配方，但根据经验，必须

配

备的有：(1) 构建模型的科

学家；(2) 运行和维护模型的

工程师；(3) 管理人工智能团

队和制

定战略的领导者

。最好配备的有：(4) 研究生毕

业后在业内工作的科学

家；(5)

了解规模扩

展和数据

流水线的工程师；(6) 曾是个

人贡献科学家的领导者

。(5) 是不言自明的，(4) 和

(6)

需要一

些解释。

先来看 (4)。科学家需

要理解机器学习的基本

原理并能够想出新的解

决方案。研究生，尤

其是博

士生，已经具备这样的条

件。但在行业中，解决人工

智能问题不仅仅是应用

新的算

法，还涉及收集和

清洗数据、使数据具备可

用条件并应用已知技术

。这与学术界大不相

同。学

术界的大多数工作是在

既容易获得又干净的已

知公开数据集上进行的

。学术界的大

多数研究人

员致力于设计新颖的方

法，来击败最先进的结果

。在许多情况下，刚刚走出

校

园参与工作的科学家

往往会采用复杂玄妙的

方法，结果却适得其反。人

们是为产品而构建

人工

智能的——人工智能只是一

种手段，而不是目的。因此

，团队需要曾在行业场景

中成

功构建和部署过模

型的高级科学家。

再来看

(6)。人工智能团队的领导力

与软件工程团队的领导

力非常不同。尽管任何人

工智

能系统在生产环境

中运行的都是代码，但人

工智能与软件工程有着

根本的不同。许多团队

领

导者和组织没有意识到

这种细微差别。他们相信

，因为都是代码，所以软件

工程的所有

原则都适用

于人工智能。从定义问题

陈述到规划项目时间表

，开发人工智能系统不同

于开

发传统的信息技术

系统。因此，建议组织中的

人工智能团队领导者具

备人工智能领域个人

贡

献者的经验。

11.4.2　正确的问题

和正确的期望

在许多情

况下，要么手头的问题定

义不清，要么人工智能团

队设定了错误的期望。下

面通

过一些例子来更好

地理解这一点。考虑这样

一个场景：给定顾客对某

一特定产品或品牌的

意

见，需要提出“有趣”的见解

。这一场景在行业中非常

常见；第 7 章 7.2

节中讨论了类

似的场景。那么现在可以

将主题建模应用于这个

特定场景吗？这取决于“有

趣”是什么意

思。它可能是

大多数顾客的意见，也可

能是特定地区一小部分

顾客的意见，还可能是顾

客

对产品特定功能的意

见。可能性有很多。首先要

与利益相关者一起明确

定义任务。一个很

好的方

法是使用各种各样的示

例输入，包括极端情况，并

要求利益相关者写出期

望的输

出。要记住，拥有大

量的现成数据并不直接

意味着这是一个人工智

能问题。许多问题可以

使

用工程方法、基于规则的

方法和人工介入的方法

来解决。

端到端自然语言

处理系统 ｜ 285

另一个常见问

题是利益相关者对人工

智能技术有错误的期望

。这通常是因为大众媒体

的文

章倾向于将人工智

能与人脑进行比较。虽然

这是人工智能领域背后

的一个动机，但事实远

非

如此。例如，考虑这样一个

场景，假设已经构建了一

个情感分析系统，并且对

于给定的

输入句子，系统

预测了错误的输出。该系

统虽然能提供非常高的

准确度，但也不是 100%。

软件工

程领域的大多数利益相

关者会将此视为漏洞，不

愿意接受任何不是 100% 正确

的东

西。他们不知道这样

一个事实，即任何人工智

能系统（截至今天）都可能

产生错误的输

出。另外，人

们还期望人工智能完全

取代人类的工作，从而节

省资金。但事实上很难做

到

这样。因此，最好将人工

智能视为协助人类工作

的增强智能，而不是取代

人类工作的人工

智能。此

外，当超过某个时间点后

，模型性能就会停滞不前

，不会随着时间的推移而

继续

上升。如图 11-8 所示，虽然

期望是持续上升，但现实

更像一条

S 形曲线。

人工智

能性能

期望

现实

时间

图

11-8：人工智能性能的期望与

现实

即使是非常成熟和

先进的人工智能系统，也

需要人类的监督。在许多

情况下，人工智能可

以减

少人类的工作，但开发这

样的产品需要很长一段

时间。同样，软件工程领域

的利益相

关者可能不理

解构建负责任的人工智

能的重要性。负责任的人

工智能可以确保公平、透

明

和负责任的可信解决

方案。谷歌和微软已经发

布了构建负责任的人工

智能系统的最佳实践。

11.4.3

数

据和时间

数据是任何人

工智能系统的核心。前面

的内容已经详细讨论了

数据的各个方面。现在来

看

另外一个方面：在许多

情况下，仅仅拥有 GB 级甚至

PB 级数据，并不意味着已经

具备了

开发人工智能的

条件，也不意味着很快就

能从人工智能中获益。拥

有数据不等于拥有正确

的数据。下面来逐一解释

。

数据质量

为了实现良好

的性能，任何人工智能系

统都需要使用高质量的

数据进行训练和预测。高

质量意味着什么？结构化

、同质、干净、无噪声和异常

值的数据。从嘈杂的数据

转换到

高质量的数据通

常是一个漫长的过程。思

考这个问题的最好方法

是下面这个类比：原始

数

据是原油，人工智能模型

是战斗机。战斗机不能依

靠原油飞行，它们需要航

空燃料才

286

｜ 第 11 章

能飞行。因

此，为了使战斗机能够正

常使用，必须有人建立炼

油厂，系统地从原油中提

取航空燃料。建立炼油厂

是一个漫长而昂贵的过

程。

还有一点很重要，就是

要有正确的代表性数据

，以便解决手头的问题。例

如，如果没有

关于要搜索

内容的元数据，就无法改

进搜索功能。因此，如果没

有“某品牌 10 码网球

鞋”，而只

有“某品牌 10 码”，就无法轻松

地通过搜索找到网球鞋

。

数据数量

大多数人工智

能模型是训练数据集的

压缩表示。没有足够的数

据来真实表示模型在生

产

中看到的数据，是模型

性能不佳的一个重要原

因。多少数据才够用？这是

一个很难回答

的问题，但

有一些经验法则。例如，对

于使用朴素贝叶斯或随

机森林等基线算法的句

子

分类，要构建一个令人

满意的分类器，每个类至

少要有两三千个数据点

。

数据标注

到目前为止，人

工智能行业的大部分成

功故事来自有监督的人

工智能。正如本书前面几

章中所讨论的，在有监督

的人工智能中，每个数据

点都有对应的真实值。对

于许多问

题，真实值来自

人工标注。这通常是一个

耗时且昂贵的过程。在许

多行业场景中，利益

相关

者没有意识到这一步骤

的重要性。

数据标注通常

是一个持续的过程。即使

一次性批量标注好数据

并构建第一版模型，模型

投入生产并稳定下来后

，标注生产数据仍然是一

个持续的过程。此外，还需

要定义标注

流程并实施

质量检查，提高人工标注

的准确性和一致性。可以

使用 kappa

等指标来衡量

标注

者之间的一致性。

目前，人

工智能的人才成本很高

。在没有正确数据的情况

下，聘请人工智能人才是

徒劳无

益的。拥有正确的

数据是人工智能团队快

速高效交付的前提。这并

不意味着引进人工智能

人才之前必须具备所有

的前提条件，但是必须充

分了解这些前提，并且在

不满足这些前提

的情况

下，设定符合实际的预期

。

11.4.4

好的流程

另外，不遵循正

确的流程也是人工智能

项目失败的重要原因。本

章已经讨论了 KDD 过程

和微

软 TDSP。两者都是很好的起点

。以下是开始阶段需要考

虑的一些其他要点。

设置

正确的指标

行业中大多

数人工智能项目的目的

是解决商业问题。在许多

情况下，人工智能团队将

精

度、召回率等指标作为

成功与否的标志。但是，除

了人工智能指标，还必须

设置正确的

业务指标。例

如，对于将顾客投诉自动

分配给相应客服团队的

文本分类器，正确的指标

应该是投诉被重新分配

给其他团队的次数。即使

F1 分数为 95%，但如果许多投诉

被多

次重新分配，那么这

样的分类器也是无用的

。另一个例子是聊天机器

人系统，即使它可

以正确

检测用户意图，但如果用

户流失率很高，那么这样

的聊天机器人系统也是

无用

的。有了用户交互和

流失率，反映的情况才是

完整的，仅仅使用人工智

能指标可能是片

面的。

端

到端自然语言处理系统

｜ 287

从简单开始，构建强有力

的基线

人工智能科学家

经常受到最新技术和最

先进（SOTA）模型的影响，并直接

将其应用到

工作中。大多

数最先进的技术是计算

密集型和数据密集型的

，这会导致成本超支和时

间

过长。最好是从简单的

方法开始，构建强有力的

基线。很多时候，与基于规

则的系统相

比，最先进的

技术可能只会带来微小

的改进。因此，在考虑复杂

的方法之前，先尝试各

种

简单的方法。

先完成，再完

善

构建模型通常只占大

多数人工智能项目的 5%~10%，而

从数据收集到部署、测试

、维

护、监控、集成、试点测试

等各种步骤占了剩余的

90%。快速构建一个可接受的

模型，

完成一个完整的项

目周期，而不是花费大量

时间构建一个惊人的模

型。这有助于所有利

益相

关者实现项目的价值主

张。

保持较短的周转周期

即使使用知名方法解决

标准问题，仍然需要将这

些方法应用到自己的数

据集，看看是

否有效。例如

，对于构建情感分析系统

，众所周知，朴素贝叶斯给

出了非常强的基线。

然而

，对于自己的数据集，朴素

贝叶斯很可能无法给出

好的结果。因此，构建人工

智

能系统需要进行大量

的实验，以确定哪些方法

有效，哪些方法无效。因此

，快速构建

模型并经常向

利益相关者展示结果非

常重要。这有助于提前发

出任何危险信号并获得

早期反馈。

还有一些其他

重要的事情需要考虑，下

面一一介绍。

11.4.5　其他方面

除

了前面讨论的各个要点

之外，还有一些关键的要

点需要考虑，包括计算成

本和投资回

报。现在来讨

论这些问题。

计算成本

许

多人工智能模型，尤其是

基于深度学习的模型，是

计算密集型的。云端

GPU 或物

理

硬件 GPU 相当昂贵。众所周

知，许多组织在 GPU

和其他云

服务上花费巨大，以至于

不

得不创建并行项目来

降低这些成本。

盲目追求

最先进

从业者通常热衷

于在工作中采用最先进

的模型。这往往被证明是

灾难性的。例如，谷歌

先进

的聊天机器人系统 Meena

虽然

效果惊人，但花费了 2048 块 TPU 训

练了 30

天。这

些计算时间价

值 140 万美元。虽然 Meena 已经展示

了一些令人印象深刻的

结果，但是

假设使用 Meena 技术

构建聊天机器人来提供

自动化的客户支持，每天

节省 1000 美元，

那么需要运行

聊天机器人

4 年以上，才能

在训练成本上做到收支

平衡。

投资回报率

人工智

能项目成本高昂。数据收

集、标注、聘用人工智能人

才和计算等各个阶段都

涉及

成本。因此，在项目开

始阶段估算收益是很重

要的。必须构建流程和明

确的指标，以在

项目的早

期阶段衡量投资回报。

288 ｜ 第

11 章

完全自动化很难

将工

作完全自动化可能永远

无法实现。对于任何具有

一定复杂度的人工智能

项目来说，

仍然需要一些

手动工作。图 11-9 用前面讨论

过的 S 形曲线表示了这一

点。完全自动化

和可接受

性能的程度可能会根据

项目的不同而有所变化

，但总体观点是成立的。

人

工智能性能

无监督的完

全自动化

节约成本，但性

能尚可

时间

图 11-9：完全自动

化可能很难

虽然本节已

经介绍了一些关键点，但

是让人工智能在商业上

取得成功是一个宽泛的

主题。

下面推荐几篇文章

供进一步阅读，其中一些

文章提出了软件工程和

人工智能之间的区别，

另

一些则讨论了构建人工

智能系统的经验法则。

• “Why is

Machine Learning ‘Hard’?”，斯

坦福大学研究员 S. Zayd Enam

的博客

文章。

• “Software 2.0”，特斯拉著名研究员

、教育家和科学家 Andrej Karpathy

的一篇

博客文章，

认为人工智能

是一种不同的软件编写

方式。

• “NLP’s Clever Hans

Moment has Arrived”，Benjamin Heinzerling 的一篇文章，论证了

在

某些流行的数据集上

得到最先进结果的有效

性

.

• “Closing the AI Accountability

Gap: Defining an End-to-End Framework for

Internal 

Algorithmic Auditing”，谷歌人工智能和非营

利组织“Partnership on AI”的一个团队的

联

合报告。

• “The Twelve Truths of

Machine Learning for the Real World”，Delip

Rao 的博客文章。

• “What I’ve Learned

Working with 12 Machine Learning Startups”，创业

老手兼机器学习顾

问 Daniel Shenfeld 的

一篇文章。

这些文章会让

你有一个更全面的认识

。图 11-10

展示了本节和本章所

讨论的内容。

端到端自然

语言处理系统 ｜ 289

290 ｜

第 11 章

跨项

目 项目工作

团队

和

招聘

基础

设施

和

过程

定义项

目

数据策略 数据清洗 数

据标注

正确的问题 正确

的期望 构建基线

规划

数

据

特征工程 构建模型 调

试模型 改进模型

模型

模

型服务 部署 监控 部署

图

11-10：人工智能项目的生命周

期

这些建议中，许多并不

是一成不变的硬性规则

。如何使用这些建议取决

于具体的项目、问

题、数据

和组织。希望本节的讨论

有助于你的人工智能项

目取得成功。

11.5　展望未来

本

章和本书的最后将从不

同的角度展望机器学习

的未来。未来几年，机器学

习将继续在前

沿领域不

断突破，其应用也将更加

贴近商业。著名科学家

C.P. Snow 在

1959 年举办的讲座，

其讲稿集

结为著作《两种文化》。Snow 指出

，知识世界可以从两个不

同的视角来看待，一

个是

科学和技术，另一个是艺

术和人文。随着时间的推

移，这两个视角似乎越来

越分裂。

他认为，只有当两

者拥有共同的核心时，整

个领域才能更好地发展

。人工智能也是如此。

在人

工智能界，同样也出现了

两个不同的视角。一方面

，研究人员和科学家在前

沿领域取

得进步。另一方

面，企业也在试图利用人

工智能，从财富 500 强公司到

早期创业公司皆是

如此

。人们越来越相信，只有当

两者交叉融合时，人工智

能才能在行业中取得成

功。

从研究员和科学家的

角度来看，人工智能有两

个宏观的趋势：一个是建

造真正智能的

机器，另一

个是应用人工智能促进

社会进步。例如，谷歌的 François Chollet 在

“On

the 

Measure of Intelligence”一文中强调了建立更好

的智能测量标准的重要

性。目前，大多数

人工智能

模型的评估本质上是狭

隘的，只测量特定的技能

，没有测量广泛的能力和

通用的

智能。受人类智力

测试的启发，Chollet 提出了若干

测量标准，包括获得新技

能的效率。他

们引入了“抽

象和推理语料库”（ARC）数据集

，该数据集的灵感来自经

典的智商测试：

雷文推理

测验。图 11-11 给出了一个这样

的例子，其中的任务是让

计算机查看整个输入矩

阵模式来推断缺失区域

。改进人工智能测量标准

的工作对于未来开发更

好、更稳健的人工

智能是

必要的。

图 11-11：抽象和推理语

料库通用智能任务示例

，摘自 Handbook of Nonverbal

Assessment

端到端自然语言处

理系统 ｜ 291

总的来说，人工智

能和技术可以成为造福

社会的力量。目前有很多

项目正在利用人工智能

赋能社会。Wadhwani AI

正在利用人工

智能改善产妇和幼儿健

康。谷歌“AI 助益社会”计

划拥

有一系列项目，包括使用

人工智能来预测和更好

地防范洪水灾害。类似地

，微软正在

使用人工智能

解决全球气候问题，提高

可访问性，并保护文化遗

产。Allen AI 一直在通过

WinoGrande 数据集改

进自然语言处理中的常

识推理。基金会和研究实

验室的这些工作有助

于

整合机器学习和自然语

言处理的前沿进展，进而

改善人类福祉。

商业世界

的视角则完全不同，它更

实际，关注的是业务影响

和业务模型。例如，若干咨

询

公司已经对各行各业

的组织进行了人工智能

用例和有效性的调查。麦

肯锡公司的全球人工

智

能调查就是这样一个例

子。他们讨论了人工智能

如何通过减少低效劳动

来帮助不同的垂

直行业

节约资金，并通过扩大市

场来赚更多的钱。他们还

评估了人工智能对劳动

力的影

响，以及人工智能

对组织的哪些部分影响

最大。另一个类似的研究

是麻省理工学院斯隆管

理学院和波士顿咨询公

司的报告。这对于企业领

导者学习如何在组织内

部构建和发展人工

智能

非常有用。

风险投资公司

一直在大力投资设有人

工智能业务的创业公司

。他们编写了人工智能新

业

务形成方式和成功方

式的报告和总结。例如，大

型风险投资公司 Andressen

Horowitz 根据

他

们在人工智能投资方面

的丰富经验，发表了报告

“The New Business of

AI (and How It’s 

Different

From Traditional Software)”。该报告着眼于人工智能

创业公司在光鲜亮丽的

宣传

背后所面临的真实

业务问题，如毛利率低和

产品规模难以扩展。他们

提供了切实可行的建

议

，从而帮助企业构建更好

扩展和更具竞争力的人

工智能业务。

这些观点的

应用取决于组织中人工

智能业务所处的阶段。首

先，当开始一项新的人工

智能

业务时，风险投资的

经验将帮助你决定构建

什么样的业务。其次，为了

在大型组织中制定

人工

智能战略，行业调查和报

告可以使你更好地调整

自己。最后，随着组织的成

熟，采用

最先进的技术可

以带来产品的显著改善

。

11.6　结语

本书到此结束。希望

你已经了解了自然语言

处理任务、流水线及其在

各个领域中的应用，

这些

知识将有助于你的日常

工作。自然语言处理的进

展才刚刚开始结出硕果

。自然语言处

理中的一些

基本问题，如语境和常识

，可能尚未完全解决。

真正

掌握任何技能都需要终

身学习，希望本书的内容

及其提供的参考资料对

你今后的研究

有所帮助

。

292 ｜

第 11 章

关于作者

索米亚 •

瓦

贾拉（Sowmya Vajjala）拥有德国图宾根大

学计算语言学博士学位

。她目前在

加拿大国家研

究院担任研究官员。她曾

是美国爱荷华州立大学

的教师，也在微软研究院

和

《环球邮报》工作过，工作

经历横跨学术界和工业

界。

博迪萨特瓦 •

马祖达尔

（Bodhisattwa Majumder）是加州大学圣迭戈分校

自然语言处理

和机器学

习专业的博士生。他曾求

学于印度理工学院卡哈

拉格普尔分校，并以优异

成绩

毕业。此前，他在谷歌

人工智能研究院和微软

研究院进行机器学习研

究，并构建了大规

模的自

然语言处理系统，为数百

万用户提供产品服务。他

带领他的大学团队挺进

2019 ～

2020 年亚马逊 Alexa Prize 大奖赛决赛轮

。他还荣获 2020

年高通全球创

新奖（Qualcomm 

Innovation Fellowship），以及 2022 年

Adobe 研究奖学金

。

阿努杰 • 古普塔（Anuj Gupta）作为《财富

》100

强公司和创业公司的高

级领导者，构建

了自然语

言处理和机器学习系统

。在他的职业生涯中，他培

养并领导了多个机器学

习团

队。他曾在印度理工

学院德里分校和印度理

工学院海得拉巴分校学

习计算机科学。他目前

是

Vahan 公司的机器学习和数据

科学负责人。最重要的是

，他还是一位父亲和一位

丈夫。

哈尔希特

• 苏拉纳（Harshit Surana）是

Chaos Genius 公司和 DeepFlux

公司的联合创始

人

和首席技术官。作为创

始人和顾问，他曾在硅谷

的几家创业公司构建和

扩展机器学习系统

和工

程流水线。他曾在卡内基

– 梅隆大学学习计算机科

学，并在那里与麻省理工

学院媒体

实验室合作研

究常识人工智能。他在自

然语言处理领域的研究

已被引用 200

多次。

关于封面

本书封面上的动物是折

中鹦鹉（Eclectus roratus）。折中鹦鹉原产于

大洋洲的低地雨林。从

澳

大利亚的东北部到印度

尼西亚的摩鹿加群岛，到

处都可以找到折中鹦鹉

。几个世纪以

来，折中鹦鹉

在印度尼西亚和新几内

亚被驯化，它们的羽毛被

用来制作精美的头饰，用

来

显示一个人的地位或

与鸟类的亲属关系。

折中

鹦鹉雄鸟的羽毛是亮绿

色的，翅膀下有红色和蓝

色的点缀，而雌鸟有红色

的头部和紫

蓝色的胸部

。这种鹦鹉的雄鸟和雌鸟

是鹦鹉家族中不同性别

外形差异最大的，早期生

物学

家甚至将它们归类

为不同的物种。折中鹦鹉

和其他鹦鹉的另一个区

别是实行多配偶制。这

使

得雌鸟可以安全筑巢长

达 11 个月而不用经常外出

觅食，因为它们可以依靠

多只雄鸟为

它们觅食。

O’Reilly 封

面上的许多动物都是濒

危物种，它们对世界都很

重要。目前，折中鹦鹉的数

量

仍然较多。

封面插图由

Karen Montgomery

根据 Shaw’s Zoology 的一幅黑白版画而

创作。

293
