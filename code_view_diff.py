from wxauto_old import WeChat
from openai import OpenAI
import time
import os
import base64
import glob
import pyautogui
import json
import re
from datetime import datetime
from collections import deque
import uiautomation as auto
from PIL import Image
import google.generativeai as genai

# é…ç½® Gemini
try:
    genai.configure(api_key=config.GOOGLE_API_KEY)
    gemini_model = genai.GenerativeModel(config.GEMINI_MODEL)
    print(f"ğŸ§  å·²åŠ è½½ Gemini å¤§è„‘ ({config.GEMINI_MODEL})")
except Exception as e:
    print(f"âŒ Gemini é…ç½®å¤±è´¥: {e}")

# å¯¼å…¥é…ç½®
try:
    import chat_config as config
except ImportError:
    print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° chat_config.py")
    exit()

# ==================== ğŸ› ï¸ åˆå§‹åŒ– ====================
print(f"ğŸ”„ è¿æ¥è±†åŒ… (Doubao)...")
client = OpenAI(api_key=config.VOLC_API_KEY, base_url=config.VOLC_BASE_URL)
wx = WeChat()
chat_memories = deque(maxlen=15)
chat_memories.append({"role": "system", "content": config.SYSTEM_PROMPT})

print(f"ğŸš€ {config.BOT_NAME} v18.0 (è§†è§‰Agentç‰ˆ) å·²å¯åŠ¨")

# ==================== ğŸ§  æ–°çš„å¤§è„‘é€»è¾‘ ====================
def generate_reply_with_gemini(text_history, image_descriptions):
    """
    ä½¿ç”¨ Gemini 1.5 Flash ç»¼åˆä¸Šä¸‹æ–‡ç”Ÿæˆåƒäººçš„å›å¤
    text_history: åˆ—è¡¨ï¼Œæœ€è¿‘çš„å‡ æ¡æ–‡å­—æ¶ˆæ¯
    image_descriptions: åˆ—è¡¨ï¼Œè§†è§‰æ¨¡å‹æå–çš„å›¾ç‰‡å†…å®¹
    """
    
    # 1. æ„å»ºä¸€ä¸ªæå…¶ä¸°å¯Œçš„ Prompt Context
    # æŠŠâ€œè§†è§‰æƒ…æŠ¥â€è½¬åŒ–æˆâ€œæ—ç™½â€ï¼Œè®© Gemini çŸ¥é“å‘ç”Ÿäº†ä»€ä¹ˆ
    context_str = "ã€å½“å‰çŠ¶å†µã€‘\n"
    
    if text_history:
        context_str += f"å¥¹åˆšæ‰å‘çš„æ¶ˆæ¯ï¼š{' '.join(text_history)}\n"
    else:
        context_str += "å¥¹åˆšæ‰æ²¡å‘æ–‡å­—ï¼Œç›´æ¥ç”©äº†å›¾ç‰‡è¿‡æ¥ã€‚\n"
        
    if image_descriptions:
        context_str += "\nã€å¥¹å‘çš„å›¾ç‰‡å†…å®¹ï¼ˆç”±è§†è§‰æ¨¡å—æå–ï¼‰ã€‘\n"
        for i, desc in enumerate(image_descriptions):
            context_str += f"---å›¾ç‰‡{i+1}---\n{desc}\n"
    
    context_str += "\nè¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œä»¥ç”·æœ‹å‹çš„å£å»å›å¤ã€‚å¦‚æœå›¾ç‰‡å†…å®¹å¾ˆæ— èŠï¼ˆæ¯”å¦‚æ™®é€šçš„UIæˆªå›¾ï¼‰ï¼Œå¯ä»¥æ•·è¡æˆ–è€…åªå›ä¸€ä¸ªè¡¨æƒ…ã€‚å¦‚æœæœ‰æ§½ç‚¹ï¼ˆæ¯”å¦‚é›¾éœ¾ä¸¥é‡ã€æ•°å­¦å¤ªéš¾ï¼‰ï¼Œè¯·ç‹ ç‹ åæ§½ã€‚"

    # 2. è°ƒç”¨ Gemini
    try:
        # å°†ç³»ç»Ÿäººè®¾ + å½“å‰è¯­å¢ƒ ç»“åˆ
        # Gemini çš„ chat session èƒ½å¤Ÿå¾ˆå¥½åœ°ä¿æŒäººè®¾
        chat = gemini_model.start_chat(history=[
            {"role": "user", "parts": config.SYSTEM_PROMPT},
            {"role": "model", "parts": "æ˜ç™½äº†ï¼Œæˆ‘æ˜¯å¥¹ç”·æœ‹å‹ï¼Œè¯´è¯ç›´ç™½ã€å¸¦ç‚¹æŸã€ä¸å¤è¯»å›¾ç‰‡å†…å®¹ã€‚"}
        ])
        
        response = chat.send_message(context_str)
        reply = response.text
        
        # æ¸…æ´— Gemini å¯èƒ½å¸¦å‡ºçš„å¤šä½™æ ¼å¼
        reply = reply.replace("\n", "||").replace("å›å¤ï¼š", "")
        return reply
        
    except Exception as e:
        print(f"âš ï¸ Gemini æ€è€ƒçŸ­è·¯: {e}")
        return "..."

# ==================== ğŸ–¼ï¸ è§†è§‰ä¸æ“ä½œæ¨¡å— ====================

def bring_wechat_to_front():
    """ å¼ºåˆ¶å”¤é†’å¾®ä¿¡çª—å£åˆ°æœ€å‰ """
    try:
        # ä½¿ç”¨ uiautomation æŸ¥æ‰¾çª—å£ï¼Œæ¯” pywin32 æ›´ç¨³å®š
        wechat_win = auto.WindowControl(ClassName='WeChatMainWndForPC')
        if wechat_win.Exists(0):
            wechat_win.SetActive()
            wechat_win.SetTopmost(True)
            time.sleep(0.1)
            wechat_win.SetTopmost(False) # å–æ¶ˆç½®é¡¶ï¼Œå…å¾—æŒ¡ä½æ“ä½œ
            print("ğŸ–¥ï¸ å¾®ä¿¡å·²å”¤å‡º")
            return True
        else:
            print("âŒ æœªæ‰¾åˆ°å¾®ä¿¡çª—å£")
            return False
    except Exception as e:
        print(f"âš ï¸ å”¤çª—å¤±è´¥: {e}")
        return False

def take_screenshot():
    """ æˆªå–å…¨å±å¹¶ä¿å­˜ """
    try:
        img_path = config.TEMP_SCREENSHOT_PATH
        # æˆªå–å…¨å±
        pyautogui.screenshot(img_path)
        return img_path
    except Exception as e:
        print(f"âŒ æˆªå›¾å¤±è´¥: {e}")
        return None

def get_click_coordinates_from_ai(screenshot_path):
    """ 
    ğŸ§  æ ¸å¿ƒé€»è¾‘ï¼šè®©è±†åŒ…VLçœ‹æˆªå›¾ï¼Œè¿”å›éœ€è¦ç‚¹å‡»çš„åæ ‡ 
    """
    print("ğŸ¤– AIæ­£åœ¨åˆ†æå±å¹•å¯»æ‰¾å›¾ç‰‡...")
    try:
        with open(screenshot_path, "rb") as f:
            b64 = base64.b64encode(f.read()).decode('utf-8')
        
        # æ„é€ ä¸€ä¸ªéå¸¸å…·ä½“çš„ Promptï¼Œè¦æ±‚è¿”å› JSON
        prompt = f"""
        è¿™æ˜¯ä¸€å¼ ç”µè„‘å…¨å±æˆªå›¾(åˆ†è¾¨ç‡{config.SCREEN_WIDTH}x{config.SCREEN_HEIGHT})ã€‚
        è¯·ä½ çš„ä»»åŠ¡æ˜¯æ‰¾åˆ°å¾®ä¿¡èŠå¤©çª—å£ä¸­ï¼Œ**å¯¹æ–¹å‘é€çš„å›¾ç‰‡ç¼©ç•¥å›¾**ï¼Œå¹¶è¿”å›å®ƒä»¬ä¸­å¿ƒç‚¹çš„ç‚¹å‡»åæ ‡ã€‚

        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œè§‚å¯Ÿå’Œç­›é€‰ï¼š
        1.  **å®šä½èŠå¤©åŒºåŸŸ**ï¼šé¦–å…ˆå¿½ç•¥å±å¹•æœ€å·¦ä¾§çš„å¾®ä¿¡è”ç³»äºº/åŠŸèƒ½åˆ—è¡¨æ ï¼ˆæ·±è‰²èƒŒæ™¯åŒºåŸŸï¼‰ã€‚å°†æ³¨æ„åŠ›é›†ä¸­åœ¨å³ä¾§çš„ç™½è‰²èŠå¤©æ¶ˆæ¯è¯¦æƒ…åŒºåŸŸã€‚
        2.  **è¯†åˆ«ç›®æ ‡**ï¼šåœ¨èŠå¤©åŒºåŸŸä¸­ï¼Œå¯»æ‰¾å¯¹æ–¹ï¼ˆæ˜¾ç¤ºåœ¨å·¦ä¾§ï¼‰å‘é€çš„æ¶ˆæ¯æ°”æ³¡ã€‚
        3.  **ç­›é€‰å›¾ç‰‡**ï¼šåœ¨è¿™äº›æ°”æ³¡ä¸­ï¼ŒæŒ‘å‡ºå†…å®¹æ˜¯å›¾ç‰‡ç¼©ç•¥å›¾çš„æ°”æ³¡ã€‚å®ƒä»¬é€šå¸¸æ˜¯çŸ©å½¢çš„ç…§ç‰‡æˆ–æˆªå›¾ã€‚
        4.  **æ’é™¤å¹²æ‰°**ï¼š
            * ä¸è¦åŒ…å«æˆ‘å‘é€çš„å›¾ç‰‡ï¼ˆæ˜¾ç¤ºåœ¨å³ä¾§ï¼Œç»¿åº•æ°”æ³¡ï¼‰ã€‚
            * ä¸è¦åŒ…å«å°çš„è¡¨æƒ…åŒ…ã€‚
            * **ç»å¯¹ä¸è¦**è¯†åˆ«æœ€å·¦ä¾§è”ç³»äººåˆ—è¡¨é‡Œçš„ä»»ä½•å…ƒç´ ã€‚
        5.  **åæ ‡è¦æ±‚**ï¼šè¿”å›çš„åæ ‡å¿…é¡»ä½äºèŠå¤©å†…å®¹åŒºåŸŸå†…ã€‚è¿™æ„å‘³ç€ **x åæ ‡é€šå¸¸åº”è¯¥å¤§äº 650**ï¼ˆè·³è¿‡å·¦ä¾§åˆ—è¡¨æ ï¼‰ã€‚

        è¯·ç›´æ¥è¿”å›ä¸€ä¸ªJSONæ ¼å¼çš„åæ ‡åˆ—è¡¨ï¼ŒåŒ…å«æ¯ä¸ªç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡æ°”æ³¡çš„ä¸­å¿ƒç‚¹åæ ‡ [x, y]ã€‚
        é¡ºåºä»ä¸Šåˆ°ä¸‹ã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡ï¼Œè¿”å›ç©ºåˆ—è¡¨ []ã€‚

        æ ¼å¼ç¤ºä¾‹ï¼ˆæ³¨æ„ x åæ ‡çš„å€¼ï¼‰ï¼š
        [[450, 500], [450, 800]]
        
        åªè¿”å›çº¯JSONæ•°æ®ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–åºŸè¯ã€‚
        """

        resp = client.chat.completions.create(
            model=config.VOLC_VL_ENDPOINT_ID,
            messages=[{"role": "user", "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
            ]}]
        )
        
        content = resp.choices[0].message.content
        print(f"ğŸ” AIè¿”å›: {content}")
        
        # æ¸…æ´—æ•°æ®ï¼Œæå–JSON
        json_match = re.search(r'\[.*\]', content, re.DOTALL)
        if json_match:
            coords = json.loads(json_match.group())
            return coords
        return []
    except Exception as e:
        print(f"âš ï¸ AIè§†è§‰åˆ†æå‡ºé”™: {e}")
        return []

def smart_click_images(coords):
    """ æ‰§è¡Œç‚¹å‡»æ“ä½œ """
    if not coords:
        print("ğŸ¤·â€â™‚ï¸ AIæ²¡çœ‹åˆ°éœ€è¦ç‚¹å‡»çš„å›¾ç‰‡")
        return

    print(f"ğŸ–±ï¸ å‡†å¤‡ç‚¹å‡» {len(coords)} å¼ å›¾ç‰‡...")
    original_pos = pyautogui.position()
    
    for i, (x, y) in enumerate(coords):
        # å®‰å…¨æ ¡éªŒ
        if x < 0 or x > config.SCREEN_WIDTH or y < 0 or y > config.SCREEN_HEIGHT:
            continue
            
        print(f"   -> ç‚¹å‡»ç¬¬ {i+1} å¼ : ({x}, {y})")
        pyautogui.click(x, y, clicks=2, interval=0.1) # åŒå‡»æŸ¥çœ‹åŸå›¾(è§¦å‘ç¼“å­˜)
        time.sleep(1.5) # ç­‰å¾…å¤§å›¾åŠ è½½
        pyautogui.press('esc') # å…³é—­å¤§å›¾æŸ¥çœ‹å™¨
        time.sleep(0.5) # ç­‰å¾…åŠ¨ç”»
        
    pyautogui.moveTo(original_pos) # å½’ä½

# ==================== ğŸ” DATä¸å›å¤æ¨¡å— (å¤ç”¨ä¼˜åŒ–) ====================

def decrypt_dat_file(dat_path):
    """ è§£å¯† DAT æ–‡ä»¶ """
    try:
        with open(dat_path, 'rb') as f: content = f.read()
        if not content: return None
        key = content[0] ^ 0xFF
        decrypted = bytearray([b ^ key for b in content])
        
        ext = ".jpg"
        if decrypted[0] == 0x89 and decrypted[1] == 0x50: ext = ".png"
        elif decrypted[0] == 0x47 and decrypted[1] == 0x49: ext = ".gif"
        
        save_dir = os.path.join(os.getcwd(), "temp_decoded")
        if not os.path.exists(save_dir): os.makedirs(save_dir)
        filename = f"dec_{int(time.time())}_{os.path.basename(dat_path)}{ext}"
        save_path = os.path.join(save_dir, filename)
        
        with open(save_path, "wb") as f_out: f_out.write(decrypted)
        return save_path
    except: return None

def find_latest_hd_images(since_time):
    """ æŸ¥æ‰¾æ—¶é—´æˆ³ä¹‹åç”Ÿæˆçš„å¤§çš„DATæ–‡ä»¶ """
    try:
        current_month = datetime.now().strftime("%Y-%m")
        search_pattern = os.path.join(config.WECHAT_IMAGE_ROOT, "MsgAttach", "**", "Image", current_month, "*.dat")
        files = glob.glob(search_pattern, recursive=True)
        
        valid_files = []
        for f in files:
            mtime = os.path.getmtime(f)
            if mtime > since_time:
                # è¿‡æ»¤æ‰å°äº20KBçš„æ–‡ä»¶ (é€šå¸¸æ˜¯ç¼©ç•¥å›¾)
                if os.path.getsize(f) > 20 * 1024:
                    valid_files.append((f, mtime))
        
        # æŒ‰æ—¶é—´æ’åº
        valid_files.sort(key=lambda x: x[1])
        return [f[0] for f in valid_files]
    except: return []

def get_doubao_vl_description(image_path):
    """ è±†åŒ…çœ‹å›¾æè¿° """
    try:
        with open(image_path, "rb") as f:
            b64 = base64.b64encode(f.read()).decode('utf-8')
        resp = client.chat.completions.create(
            model=config.VOLC_VL_ENDPOINT_ID,
            messages=[{"role": "user", "content": [
                {"type": "text", "text": "ç®€è¦ç›´ç™½æè¿°å›¾ç‰‡ï¼Œå¦‚æœæœ‰æ–‡å­—è¯·æå–ã€‚"},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
            ]}]
        )
        return resp.choices[0].message.content
    except: return "ï¼ˆå›¾ç‰‡è§£æå¤±è´¥ï¼‰"

def generate_reply(context, is_img=False):
    """ ç”Ÿæˆå›å¤ """
    if is_img: prompt = f"[ç”¨æˆ·å‘å›¾] è§†è§‰å†…å®¹ï¼š{context}ã€‚è¯·æ ¹æ®å†…å®¹å›å¤ã€‚"
    else: prompt = context
    
    chat_memories.append({"role": "user", "content": prompt})
    try:
        resp = client.chat.completions.create(
            model=config.VOLC_TEXT_ENDPOINT_ID,
            messages=list(chat_memories),
            temperature=0.8, max_tokens=200
        )
        reply = resp.choices[0].message.content
        chat_memories.append({"role": "assistant", "content": reply})
        return reply
    except: return None

# ==================== ğŸ”„ ä¸»é€»è¾‘ (é˜²æŠ–åŠ¨ç‰ˆ) ====================

def main():
    try: wx.ChatWith(config.TARGET_USER)
    except: pass
    
    last_processed_count = len(wx.GetAllMessage())
    last_msg_timestamp = time.time()
    
    # çŠ¶æ€æ ‡è®°ï¼šæ˜¯å¦æœ‰æœªå¤„ç†çš„æ–°æ¶ˆæ¯
    pending_new_msgs = False
    
    # è®°å½•ä¸Šä¸€æ¬¡æ‰«æå›¾ç‰‡çš„æ—¶é—´ï¼Œåªå¤„ç†è¿™ä¹‹åç”Ÿæˆçš„æ–°æ–‡ä»¶
    last_scan_time = time.time()

    print(f"â±ï¸ ç›‘æ§å·²å¯åŠ¨ | å“åº”å»¶è¿Ÿ: {config.BATCH_WAIT_SECONDS}ç§’")

    while True:
        try:
            current_msgs = wx.GetAllMessage()
            current_len = len(current_msgs)
            
            # 1. æ£€æµ‹æ˜¯å¦æœ‰æ–°æ¶ˆæ¯
            if current_len > last_processed_count:
                # åªè¦æœ‰æ–°æ¶ˆæ¯ï¼Œå°±é‡ç½®è®¡æ—¶å™¨
                last_msg_timestamp = time.time()
                pending_new_msgs = True
                
                # è·å–æœ€æ–°çš„ä¸€æ¡ç®€å•æ‰“å°ä¸€ä¸‹
                new_msg_content = current_msgs[-1].content
                print(f"\rğŸ“© æ”¶åˆ°æ–°æ¶ˆæ¯ ({datetime.now().strftime('%H:%M:%S')}): {new_msg_content} | ç­‰å¾…å‘é€ç»“æŸ...", end="")
                
                last_processed_count = current_len
            
            # 2. åˆ¤æ–­æ˜¯å¦æ»¡è¶³â€œé™é»˜æ—¶é—´â€ä¸”æœ‰å¾…å¤„ç†æ¶ˆæ¯
            # é€»è¾‘ï¼š(å½“å‰æ—¶é—´ - æœ€åæ¶ˆæ¯æ—¶é—´ > è®¾å®šé˜ˆå€¼) AND (æœ‰æœªå¤„ç†æ¶ˆæ¯)
            time_since_last_msg = time.time() - last_msg_timestamp
            
            if pending_new_msgs and time_since_last_msg > config.BATCH_WAIT_SECONDS:
                print(f"\n\nâš¡ å¯¹æ–¹å·²{config.BATCH_WAIT_SECONDS}ç§’æœªå‘æ¶ˆæ¯ï¼Œå¼€å§‹æ‰§è¡Œæ‰¹å¤„ç†...")
                
                # A. å”¤èµ·å¾®ä¿¡
                bring_wechat_to_front()
                time.sleep(0.5)
                
                # B. è§†è§‰å…¨å±è¯†åˆ« & ç‚¹å‡» (è¿™æ˜¯ä¸ºäº†è§¦å‘é«˜æ¸…å›¾ä¸‹è½½)
                # åªæœ‰å½“æœ€æ–°å‡ æ¡æ¶ˆæ¯é‡ŒåŒ…å« "[å›¾ç‰‡]" æ—¶æ‰æ‰§è¡Œè¿™ä¸ªæ˜‚è´µçš„æ“ä½œ
                recent_msgs = current_msgs[-5:] # æ£€æŸ¥æœ€è¿‘5æ¡
                has_image = any(msg.content == '[å›¾ç‰‡]' for msg in recent_msgs)
                
                if has_image:
                    print("ğŸ“¸ æ£€æµ‹åˆ°èŠå¤©è®°å½•å«å›¾ç‰‡ï¼Œå¯åŠ¨è§†è§‰ç‚¹å‡»...")
                    screenshot = take_screenshot()
                    if screenshot:
                        coords = get_click_coordinates_from_ai(screenshot)
                        smart_click_images(coords)
                
                # C. å¤„ç†å·²ä¸‹è½½çš„é«˜æ¸…å›¾
                # æŸ¥æ‰¾ä» last_scan_time åˆ°ç°åœ¨æ–°ç”Ÿæˆçš„DATæ–‡ä»¶
                new_dat_paths = find_latest_hd_images(last_scan_time)
                image_descriptions = []
                
                if new_dat_paths:
                    print(f"ğŸ“‚ å‘ç° {len(new_dat_paths)} å¼ é«˜æ¸…å¤§å›¾ï¼Œå¼€å§‹è§£æ...")
                    for dat in new_dat_paths:
                        decrypted = decrypt_dat_file(dat)
                        if decrypted:
                            desc = get_doubao_vl_description(decrypted)
                            print(f"   - å›¾ç‰‡å†…å®¹: {desc}")
                            image_descriptions.append(desc)
                
                # æ›´æ–°æ‰«ææ—¶é—´é”šç‚¹
                last_scan_time = time.time()
                
                # # D. ç»Ÿåˆå›å¤
                # # å°†æœ€åå‡ æ¡çº¯æ–‡æœ¬æ¶ˆæ¯å’Œå›¾ç‰‡æè¿°åˆå¹¶ç»™AI
                # text_context = [m.content for m in recent_msgs if m.content != '[å›¾ç‰‡]' and m.sender == config.TARGET_USER]
                
                # full_prompt = ""
                # if text_context:
                #     full_prompt += f"å¥¹å‘çš„æ–‡å­—: {','.join(text_context)}ã€‚\n"
                # if image_descriptions:
                #     full_prompt += f"å¥¹å‘çš„å›¾ç‰‡å†…å®¹: {'; '.join(image_descriptions)}ã€‚"
                
                # if full_prompt:
                #     print("ğŸ§  ç”Ÿæˆå›å¤ä¸­...")
                #     reply = generate_reply(full_prompt, is_img=bool(image_descriptions))
                    
                #     if reply:
                #         for part in reply.split("||"):
                #             if part.strip():
                #                 wx.SendMsg(part.strip())
                #                 print(f"ğŸ—£ï¸ å›å¤: {part.strip()}")
                #                 time.sleep(1)

                # D. ç»Ÿåˆå›å¤
                # è·å–æœ€è¿‘3æ¡çº¯æ–‡å­—æ¶ˆæ¯ä½œä¸ºèƒŒæ™¯
                recent_text_msgs = [m.content for m in recent_msgs if m.content != '[å›¾ç‰‡]' and m.sender == config.TARGET_USER]
                
                # åªæœ‰å½“æœ‰å›¾ç‰‡æè¿° æˆ–è€… æœ‰æ–‡å­—æ¶ˆæ¯æ—¶æ‰å›å¤
                if image_descriptions or recent_text_msgs:
                    print("ğŸ§  Gemini æ­£åœ¨æ„æ€éªšè¯...")
                    
                    # å…³é”®ä¿®æ”¹ï¼šä¼ å…¥æ–‡å­—å†å² + å›¾ç‰‡æè¿°
                    reply = generate_reply_with_gemini(recent_text_msgs, image_descriptions)
                    
                    if reply:
                        for part in reply.split("||"):
                            p = part.strip()
                            if p:
                                wx.SendMsg(p)
                                print(f"ğŸ—£ï¸ å›å¤: {p}")
                                time.sleep(random.uniform(1.0, 2.5)) # éšæœºå»¶è¿Ÿï¼Œæ›´åƒçœŸäºº

                # é‡ç½®çŠ¶æ€
                pending_new_msgs = False
                print(f"âœ… æ‰¹å¤„ç†å®Œæˆï¼Œç»§ç»­ç›‘æ§...")

            time.sleep(1) # å¾ªç¯å¿ƒè·³

        except KeyboardInterrupt: break
        except Exception as e:
            print(f"âš ï¸ ä¸»å¾ªç¯æŠ¥é”™: {e}")
            time.sleep(2)

if __name__ == "__main__":
    main()