import os
import re
import argparse
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==================== vLLMé…ç½®ï¼ˆé€‚é…4Bæ¨¡å‹ï¼‰====================
VLLM_BASE_URL = "http://localhost:8000/v1"
TARGET_MODEL = "/t9k/mnt/hjy/Qwenq/qwen3-4b-thinking-2507"  # ä¸å¯åŠ¨å‘½ä»¤çš„--modelè·¯å¾„ä¸€è‡´
MAX_TOKENS = 18000  
# ==========================================================
# è·¯å¾„é…ç½®ï¼ˆä¿æŒä¸ä½ çš„æœåŠ¡å™¨ä¸€è‡´ï¼‰
DEFAULT_INPUT_DIR = r"F:\åŒæ­¥æ–‡ä»¶å¤¹\è€ƒç ”pdf\ç”µè·¯å¤§åˆé›†"  # è¾“å…¥åŸå§‹txtæ–‡ä»¶ç›®å½•
DEFAULT_OUTPUT_DIR = r"F:\åŒæ­¥æ–‡ä»¶å¤¹\Ankiè¾“å‡ºæ–‡ä»¶å¤¹\ç”µè·¯å¤§åˆé›†\ä¼˜åŒ–æ–‡æœ¬"  # ä¼˜åŒ–æ–‡æœ¬è¾“å‡ºç›®å½•
# ==========================================================

# åˆå§‹åŒ–vLLMå®¢æˆ·ç«¯
client = OpenAI(
    base_url=VLLM_BASE_URL,
    api_key="EMPTY",
    timeout=1800  # è¶…æ—¶æ—¶é—´å»¶é•¿ï¼Œé€‚åº”é•¿æ–‡æœ¬å¤„ç†
)

def read_raw_text(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read().strip() or None  # è¯»å–å®Œæ•´æ–‡æœ¬ï¼Œä¸åšæˆªæ–­
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return None

def validate_generated_content(content, task_name, file_name):
    if not content or len(content.strip()) < 50:
        print(f"âŒ {file_name} - {task_name} å†…å®¹æ— æ•ˆ")
        return False
    return True

def optimize_text(raw_text, file_name):
    print(f"ğŸ“ {file_name} - ä¼˜åŒ–æ–‡æœ¬...")
    try:
        # ç§»é™¤é•¿åº¦é™åˆ¶ï¼Œä¼ å…¥å®Œæ•´æ–‡æœ¬
        prompt = f"""ä½ æ˜¯ç”µè·¯å­¦ç§‘ä¸“å®¶ï¼Œä¼˜åŒ–ä»¥ä¸‹æ–‡æœ¬ï¼š
1. è¡¥å……æ¨å¯¼è¿‡ç¨‹ï¼Œå…¬å¼ç”¨MathJaxï¼ˆå¦‚\(U=IR\)ï¼‰
2. æ‰©å±•æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€æ˜“é”™ç‚¹
3. æ®µè½æ¸…æ™°ï¼Œå…¬å¼å•ç‹¬æˆè¡Œ

åŸå§‹æ–‡æœ¬ï¼š{raw_text}"""

        response = client.chat.completions.create(
            model=TARGET_MODEL,
            messages=[
                {"role": "system", "content": "ä¼˜åŒ–ç†å·¥ç§‘æ–‡æœ¬ï¼Œç²¾å‡†ä¸“ä¸š"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=MAX_TOKENS,  # ä½¿ç”¨æ¨¡å‹æœ€å¤§æ”¯æŒçš„tokenæ•°
            temperature=0.4
        )
        optimized = response.choices[0].message.content
        return optimized if validate_generated_content(optimized, "æ–‡æœ¬ä¼˜åŒ–", file_name) else None
    except Exception as e:
        print(f"âŒ æ–‡æœ¬ä¼˜åŒ–å¤±è´¥: {e}")
        return None

def save_optimized_file(content, output_path):
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"ğŸ’¾ ä¼˜åŒ–æ–‡æœ¬ä¿å­˜è‡³ï¼š{output_path}")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        return False

def process_single_file(input_path, input_dir, output_dir):
    """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼šè¯»å–â†’ä¼˜åŒ–â†’ä¿å­˜â†’æ ‡è®°å·²å¤„ç†"""
    file_name = os.path.basename(input_path)
    print(f"\n===== å¼€å§‹å¤„ç†ï¼š{file_name} =====")
    
    # è·³è¿‡å·²å¤„ç†æ–‡ä»¶ï¼ˆåç¼€ä¸º.processed.txtï¼‰
    if file_name.endswith(".processed.txt"):
        print(f"â­ï¸ {file_name} å·²ä¼˜åŒ–å®Œæˆï¼Œè·³è¿‡")
        return True
        
    # è¯»å–åŸå§‹æ–‡æœ¬
    raw_text = read_raw_text(input_path)
    if not raw_text:
        return False
    
    optimized = optimize_text(raw_text, file_name)
    if not optimized:
        return False
    
    # ä¿æŒåŸå§‹ç›®å½•ç»“æ„
    relative_path = os.path.relpath(input_path, input_dir)
    relative_dir, orig_file_name = os.path.split(relative_path)
    output_subdir = os.path.join(output_dir, relative_dir)
    os.makedirs(output_subdir, exist_ok=True)
    
    base_name = os.path.splitext(orig_file_name)[0]
    output_file_name = f"{base_name}.ä¼˜åŒ–æ–‡æœ¬.txt"
    output_path = os.path.join(output_subdir, output_file_name)
    
    if save_optimized_file(optimized, output_path):
        # æˆåŠŸä¿å­˜åï¼Œç»™åŸæ–‡ä»¶æ·»åŠ .processedåç¼€
        processed_path = f"{input_path}.processed.txt"
        os.rename(input_path, processed_path)
        print(f"ğŸ”– åŸæ–‡ä»¶å·²æ ‡è®°ä¸ºå¤„ç†å®Œæˆï¼š{processed_path}")
        return True
    return False

def main():
    parser = argparse.ArgumentParser(description='vLLMç‰ˆç”µè·¯æ–‡æœ¬ä¼˜åŒ–å™¨')
    parser.add_argument('-n', '--num_workers', type=int, default=5, help='å¹¶è¡Œçº¿ç¨‹æ•°')
    parser.add_argument('-i', '--input_dir', default=DEFAULT_INPUT_DIR, help='åŸå§‹æ–‡æœ¬è¾“å…¥ç›®å½•')
    parser.add_argument('-o', '--output_dir', default=DEFAULT_OUTPUT_DIR, help='ä¼˜åŒ–æ–‡æœ¬è¾“å‡ºç›®å½•')
    
    args, unknown = parser.parse_known_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    txt_files = []
    for root, dirs, files in os.walk(args.input_dir):
        for file in files:
            # åªå¤„ç†txtæ–‡ä»¶ï¼Œä¸”æ’é™¤å·²æ·»åŠ .processedåç¼€çš„æ–‡ä»¶
            if file.endswith('.txt') and not file.endswith('.processed.txt'):
                txt_files.append(os.path.join(root, file))
    
    if not txt_files:
        print("ğŸ“­ æœªæ‰¾åˆ°å¾…ä¼˜åŒ–çš„txtæ–‡ä»¶ï¼ˆå·²æ’é™¤.processed.txtåç¼€çš„å·²å¤„ç†æ–‡ä»¶ï¼‰")
        return
    
    print(f"å‘ç° {len(txt_files)} ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ {args.num_workers} çº¿ç¨‹å¤„ç†")
    
    with ThreadPoolExecutor(max_workers=args.num_workers) as executor:
        futures = [executor.submit(process_single_file, f, args.input_dir, args.output_dir) for f in txt_files]
        success_count = sum(1 for future in as_completed(futures) if future.result())
    
    print(f"\n===== å¤„ç†å®Œæˆ =====")
    print(f"âœ… æˆåŠŸä¼˜åŒ–ï¼š{success_count} ä¸ªæ–‡ä»¶")
    print(f"âŒ ä¼˜åŒ–å¤±è´¥ï¼š{len(txt_files) - success_count} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“ ä¼˜åŒ–æ–‡æœ¬è¾“å‡ºæ ¹è·¯å¾„ï¼š{args.output_dir}")

if __name__ == "__main__":
    main()