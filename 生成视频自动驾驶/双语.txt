



































Metrics

about Quality and Controllability

of Generated Video. We

evaluate the quality of

the generated videos from

two aspects: quality and

controllability. Specifically, for quality,

we use Frechet Inception

Distance (FID) [7] to

assess the realism of

single-frame single-view images in

the generated videos, Frechet

Video Distance (FVD) [35]

to evaluate the temporal

consistency of

关于生

成视频的质

量和可控性

的指标。我们

从两个方面

评估生成视

频的质量:质

量和可控性

。具体来说，对

于质量，我们

使用弗雷歇

初始距离(FID) [7]来

评估生成的

视频中单帧

单视图图像

的真实性，弗

雷歇视频距

离(FVD)

[35]来评估





single-view

videos, and CLIP scores

(CLIP) [42] to assess

the spatial consistency of

single-frame multi-view images. For

controllability, we utilize the

popular BEV detection model

StreamPETR [37] and end-to-end

model [13] to evaluate

the generated data and

report the NDS score

and the Average Collision

Rate(Avg. Col. Rate) respectively,

which comprehensively reflects the

geometric alignment between the

generated images and the

BEV layout annotations. By

using these evaluation metrics,

we can ensure that

the generated results maintain

high standards in both

quality and controllability.

单

视图视频和

剪辑分数(CLIP)

[42]来

评估单帧多

视图图像的

空间一致性

。对于可控性

，我们利用流

行的BEV检测模

型StreamPETR [37]和端到端

模型[13]来评估

生成的数据

，并报告NDS分数

和平均碰撞

率(Avg。Col. Rate ),其全面反

映了所生成

的图像和BEV布

局注释之间

的几何对准

。通过使用这

些评估指标

，我们可以确

保生成的结

果在质量和

可控性方面

保持高标准

。

Metrics about Effectiveness

of the Generated Video

for End-to-End Model. To

evaluate the effectiveness of

our proposed failure-case driven

framework based upon the

Delphi for the end-to-end

model, we utilize the

generated diverse training data

to augment the end-to-end

model’s origin training data.

Specifically, we evaluate the

performance of the end-to-end

model by applying data

augmentation on the nuScenes

validation set and report

the average collision rate.

端到端模型

生成的视频

有效性的度

量。为了评估

我们提出的

基于德尔菲

法的端到端

模型的故障

案例驱动框

架的有效性

，我们利用生

成的不同训

练数据来扩

充端到端模

型的原始训

练数据。具体

来说，我们通

过在nuScenes验证集

上应用数据

扩充来评估

端到端模型

的性能，并报

告平均冲突

率。





D.3More

Experimental Details

D.4更多实验

细节

Experimental

Setting of the end-to-end

model. During the training

phase, we utilize the

model available on the

UniAD official repository as

our foundation for fine-tuning.

To enhance the training

process, we have decreased

the learning rate by

a factor of 10,

setting it to 2e-5.

Additionally, we maintain consistency

with the hyperparameters recommended

on the UniAD repository,

including the optimizer settings.

端到端

模型的实验

设置。在培训

阶段，我们利

用UniAD官方知识

库上的模型

作为微调的

基础。为了增

强训练过程

，我们将学习

率降低了10倍

，设置为2e-5。此外

，我们与UniAD存储

库上推荐的

超参数保持

一致，包括优

化器设置。





Computation

Efficiency and Hardware RequirementsWe

report the model complexity

of our two model

variants in Table 6.

We will further provide

the generated data on

the nuScenes training set

for the convenience of

data augmentation.

计

算效率和硬

件要求我们

在表6中报告

了两个模型

变体的模型

复杂性。我们

将进一步在

nuScenes训练集上提

供生成的数

据，以便于数

据扩充。

表6:模

型效率和硬

件要求。

Model	Parameter	Inference Memeory&GPU

Inference Time	Train config

模型

参数	推理存

储器和GPU	推理

时间	列车配

置

multi-view single-frame	0.5B

22GB(RTX3090)	4s / example

8×A100, 24 hours

multi-view

multi-frame	1.1B	39GB(A100 40G)

4s / example	8×A800,

72 hours

多视图单

帧	0.5亿

22GB(RTX3090)	4s /示例	8×A100，24小

时

多视图多

帧	1.1B	39GB(A100 40G)

4s /示例	8×A800，72小时



D.5Validating each components of

our failure-case driven framework

D.6验证我们的

失败案例驱

动框架的每

个组件

As in Table

2, we compare in

three aspects, data sampling

strategy, number of generating

cases and data engine

validation.

如表

2所示，我们从

三个方面进

行比较，数据

采样策略、生

成案例的数

量和数据引

擎验证。

Data Sampling Strategy. We

evaluated different data sampling

strategies, such as random

sampling and failure-case targeted

sampling. In the upper

part of Table 2,

we randomly selected various

proportions of data samples

from the training dataset

and used the corresponding

BEV layout and original

scene captions to generate

new data. In the

lower part of Table

2, we retrieved training

data with similar patterns

to failure cases from

the validation set and

generated diverse weather data

using the powerful control

capabilities of the generative

model. The newly generated

data was mixed with

the original data to

train the end-to-end model.

It was observed that

the end-to-end model, enhanced

through failure-case guided data

augmentation, achieved the best

performance. This demonstrates that

the end-to-end model is

under-trained in these failure

cases, and feeding it

more failure-case related training

data can achieve optimal

generalization performance with fewer

computational resources.

数据

采样策略。我

们评估了不

同的数据抽

样策略，如随

机抽样和失

败案例目标

抽样。在表2的

上半部分，我

们从训练数

据集中随机

选择各种比

例的数据样

本，并使用相

应的BEV布局和

原始场景字

幕来生成新

数据。在表2的

下半部分，我

们从验证集

中检索了与

故障案例模

式相似的训

练数据，并使

用生成模型

的强大控制

功能生成了

不同的天气

数据。新生成

的数据与原

始数据混合

，以训练端到

端模型。据观

察，通过故障

案例引导的

数据扩充增

强的端到端

模型实现了

最佳性能。这

表明，端到端

模型在这些

故障情况下

训练不足，向

其提供更多

故障情况相

关的训练数

据可以用更

少的计算资

源实现最佳

的泛化性能

。

Numbers of Cases. We

investigated the quantity of

data samples. We randomly

sampled 14,065 and 28,130

training samples (approximately 50%

and 100% of the

entire training set) from

the training set. The

results generated by the

configuration of the generative

model on these samples

were used for data

augmentation. As shown in

the upper part of

Table 2, the performance

of the end-to-end model

worsened as the number

of samples increased. This

indicates that using training

data with a style

similar to the original

training set can only

help the model to

a limited extent. Thus,

it prompted us to

consider increasing the diversity

of the training data.

案件数量。我

们调查了数

据样本的数

量。我们从训

练集中随机

抽取了14，065和28，130个

训练样本(大

约是整个训

练集的50%和100%)。由

生成模型在

这些样本上

的配置生成

的结果被用

于数据扩充

。如表2的上半

部分所示，端

到端模型的

性能随着样

本数量的增

加而恶化。这

表明使用与

原始训练集

风格相似的

训练数据只

能在有限的

程度上帮助

模型。因此，这

促使我们考

虑增加训练

数据的多样

性。





Data

Engine. We tested various

data generation engines, including

Delphi and other state-of-the-art

generative models Panacea [40],

to compare their effectiveness

in generating high-quality training

data for model enhancement.

From the three sets

of comparison experiments, it

can be seen that

the

数据引擎

。我们测试了

各种数据生

成引擎，包括

Delphi和其他最先

进的生成模

型万能药[40]，以

比较它们在

为模型增强

生成高质量

训练数据方

面的有效性

。从三组对比

实验可以看

出

data generated by Delphi

effectively improves the performance

of the end-to-end model

compared to other generative

models. This is due

to Delphi’s superior fine

control capabilities in scene

generation, leading to more

diverse training data for

model tuning.

与其他生

成模型相比

，Delphi生成的数据

有效地提高

了端到端模

型的性能。这

是由于Delphi在场

景生成方面

卓越的精细

控制能力，导

致模型调优

的训练数据

更加多样化

。

[28]

[29]
