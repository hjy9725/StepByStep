










模式，以期能

够识别图像

的内容。生成

器不是去识

别这些模式

，而是

要学会

从头开始学

习创建它们

，实际上，生成

器的输入通

常不过是一

个随机数向

量。



生成器通

过从鉴别器

的分类结果

中接收反馈

来不断学习

。鉴别器

的目

标是判断一

个特定的样

本是真的（来

自训练集）还

是假的（由生

成器生成）。因

此，每当鉴别

器“上当受骗

”将假的图像

错判为真实

图像时，生成

器就会知道

自己做得很

好；相反，每当

鉴别器正确

地将

生成器

生成的假图

像辨别出来

时，生成器就

会收到需要

继续改进的

反



馈。

鉴别器

也会不断地

改善，像其他

分类器一样

，它会从预测

标签与



真实

标签（真或假

）之间的偏差

中学习。所以

随着生成器

能更好地生

成更逼真的

数据，鉴别器

也能更好地

辨别真假数

据，两个网络

都在同

时不

断地改进着

。



表1.1总结了GAN的

两个子网络

的关键信息

。

表1.1 生成器和

鉴别器的关

键信息



生成

器

鉴别器



生

成器 鉴别器



输



入

一个随

机数向量



鉴

别器的输入

有两个来源

：来自训练集

的真实样

本

和来自生成

器的伪样本

输



出

尽可能

令人信服的

伪样本 预测

输入样本是

真实的概率

目

标



生成与

训练集中数

据别无

二致

的伪数据



区

分来自生成

器的伪样本

和来自训练

集的真实样

本

1.3 GAN实战



现在

，你已经对GAN及

其组成网络

有了一个大

致的了解，接

下来看

一下

系统的实际

运行情况。假

定我们的目

标是教GAN生成

逼真的手写

数



字（第3章将

实现这样一

个模型，并在

第4章中对其

进行扩展）。GAN的

核心结构如

图1.2所示。

让我

们看看其中

的细节。



（1）训练

数据集——包含

真实样本的

数据集，是我

们希望生成

器能以近乎

完美的质量

去学习模仿

的数据集。在

这个示例中

，数据集

由手

写数字的图

像组成。该数

据集用作鉴

别器网络的

输入 。



图1.2

两个

GAN子网及其输

入、输出和交

互



（2）随机噪声

向量——生成器

网络的初始

输入 。此输入

是一

个由随

机数组成的

向量，生成器

将其用作合

成伪样本的

起点。



（3）生成器

网络——生成器

接收随机数

向量 作为输

入并输出

伪

样本 。它的目

标是生成和

训练数据集

中的真实样

本别无二致

的伪



样本。

（4）鉴

别器网络——鉴

别器接收来

自训练集的

真实样本 或

生



成器生成

的伪样本

作

为输入。对每

个样本，鉴别

器会进行判

定并输



出其

为真实的概

率。

（5）迭代训练

/调优——对于每

个鉴别器的

预测，我们会

衡量它



效果

有多好——就像

对常规的分

类器一样——并

用结果反向

传播去迭

代

优化鉴别器

网络和生成

器网络。



更新

鉴别器的权

重和偏置，以

最大化其分

类的精确度

（最大化正

确

预测的概率

： 为真， 为假）。

更

新生成器的

权重和偏置

，以最大化鉴

别器将 误判

为真的概



率

。

1.3.1 GAN的训练



了解

各种GAN组件的

用途可能像

是在看搜索

引擎的快照

，除非我们

看

到它们是如

何运作的，否

则将无法完

全理解。这就

是本节的主

要内



容。我们

首先介绍GAN的

训练算法，其

次演示训练

过程，以便你

可以清

楚地

看到实际的

架构图。



GAN训练

算法

对于每

次训练迭代

，执行如下操

作。



（1）训练鉴别

器。

a. 从训练集

中随机抽取

真实样本 。

b. 获

取一个新的

随机噪声向

量 ，用生成器

网络合成一

个伪样本

。



c. 用

鉴别器网络

对

和 进行分

类。



d.

计算分类

误差并反向

传播总误差

以更新鉴别

器的可训



练

参数，寻求最

小化分类误

差。

（2）训练生成

器。



a. 获取一个

新的随机噪

声向量

，用生

成器网络合

成一



个伪样

本 。

b. 用鉴别器

网络对 进行

分类。

c. 计算分

类误差并反

向传播以更

新生成器的

可训练参



数

，寻求最大化

鉴别器误差

。

结束



GAN训练过

程可视化

GAN的

训练算法如

图1.3所示，其中

的字母表示

GAN训练算法中

的步



骤。

图1.3 GAN训

练算法有两

个主要部分

。训练鉴别器

和训练生成

器两部分，在

训练



过程的

对应阶段中

描绘了同一

个GAN网络在不

同时间点的

状态

子程序

图示说明



（1）训

练鉴别器。

a. 从

训练集中随

机抽取真实

样本 。

b. 获取一

个新的随机

噪声向量 ，用

生成器网络

合成一

个伪

样本 。



c.

用鉴别

器网络对 和

进行分类。



d.

计

算分类误差

并反向传播

总误差以更

新鉴别器的

权重



和偏置

，寻求最小化

分类误差。

（2）训

练生成器。



a. 获

取一个新的

随机噪声向

量

，用生成器

网络合成一

个伪样本 。

b. 用

鉴别器网络

对 进行分类

。

c. 计算分类误

差并反向传

播以更新生

成器的权重

和偏



差，寻求

最大化鉴别

器误差。

1.3.2 达到

平衡



你可能

想知道GAN训练

循环何时停

止，更准确地

说，如何知道

GAN

何时能被完

全训练好，以

便确定适当

的训练迭代

次数？对于一

般的神



经网

络，我们通常

有一个明确

的目标去实

现以及用来

衡量效果。例

如，当训练一

个分类器时

，我们度量在

训练集和验

证集上的分

类误

差，一旦

发现验证集

误差开始变

坏，就停止进

程（为了避免

过度拟



合）。在

GAN结构中，鉴别

器网络和生

成器网络有

两个互为竞

争对手的

目

标：一个网络

越好，另一个

就越差。那么

，我们如何决

定何时停止

进程呢？



熟悉

博弈论的人

可能会意识

到这是一个

零和博弈问

题，即一方的



收益等于另

一方的损失

。当一方提高

一定程度时

，另一方会恶

化同样



的程

度。零和博弈

都有一个纳

什均衡点，那

就是任何一

方无论怎么

努

力都不能

改善他们的

处境或者结

果。



当满足以

下条件时，GAN达

到纳什均衡

。

（1）生成器生成

的伪样本与

训练集中的

真实数据别

无二致。



（2）鉴别

器所能做的

只是随机猜

测一个特定

的样本是真

的还是假

的

（也就是说，猜

测一个示例

为真的概率

是50%）。



注意

纳什

均衡是以美

国经济学家

、数学家John Forbes Nash的名

字命

名的，他

的生平事迹

和职业生涯

被收录在一

本名为《美丽

心灵》（A



Beautiful Mind）的传记

中，并被翻拍

成同名电影

。

让我们来解

释为何会出

现这种情况

。当每一个伪

样本 与来自

训



练集的真

实样本无法

区分时，鉴别

器用任何手

段都无法区

分它们。因

为

鉴别器接收

到的样本有

一半是真的

，一半是假的

，所以它所能

做的



最有用

的事情就是

抛硬币，以50%的

概率把每个

样本分为真

和假。

同样，生

成器也处于

这样一个点

上，它不能从

进一步的调

优中获



得任

何提高了。因

为生成器生

成的样本早

已和真实样

本无法区分

了，

以至于对

随机噪声向

量 转换为伪

样本 的过程

做出哪怕一

丁点儿

改变

，也可能给鉴

别器提供从

真实样本中

辨别出伪样

本的机会，从

而



使生成器

变得更糟。

当

达到纳什均

衡时，GAN就被认

为是收敛的

。这是一个棘

手的问



题，在

实践中，由于

在非凸博弈

中实现收敛

所涉及的巨

大复杂性，几

乎不可能达

到GAN的纳什均

衡（在后续的

章节中，特别

是第5章中，有



更多关于收

敛的内容）。实

际上，GAN的收敛

仍是GAN研究中

最重要的



开

放性问题之

一。

幸而这并

没有妨碍到

GAN的研究，也没

有妨碍生成

对抗学习的

许多



创新应

用。即使在缺

乏严格数学

保证的情况

下，GAN也取得了

引人瞩目

的

实证结果——本

书涵盖了一

部分最具影

响力的工作

，下一节先介

绍



其中一些

示例。

1.4 为什么

要学GAN



自发明

以来，GAN一直被

学术界和工

业界的专家

们誉为“深度

学习

中最重

要的创新之

一”。Facebook的人工智

能研究主管

Yann LeCun甚



至表示，GAN及

其变体是“过

去20年来深度

学习中最酷

的想法”。[2]

这种

兴奋是合情

合理的。机器

学习领域的

其他进展可

能在科研人

员中人尽皆

知，但对于门

外汉来说，可

能疑惑多于

兴奋，GAN激起了

从



研究人员

到大众的极

大兴趣——包括

《纽约时报》、BBC、《科

学美国

人》以

及许多其他

知名媒体机

构，甚至可能

就是GAN的某项

成果驱使你

来购买这本

书的呢。（对吧

？）



最值得关注

的可能是GAN创

作超现实主

义意象的能

力。图1.4所示

的

人脸都不是

真人的，都是

假的，这展示

了 GAN 合成足以

和真实照片

以假乱真图

像的能力。这

些人脸是用

渐进式增长

生成对抗网

络生成

的，相

关内容参见

第6章。



（来源：Progressive Growing

of GAN



for

Improved Quality, Stability

and Variation，by Tero Karras

et al., 2017.）

图

1.4 这些逼真但

虚假的脸是

由在高分辨

率名人肖像

照片集上训

练过的渐进

GAN



生成的

GAN另一

个引人瞩目

的成就是图

像到图像的

转换（image-to￾image translation）。与把句

子从汉语翻

译成西班牙

语的方式类

似，



GAN可以将图

像从一种风

格转换为另

一种风格。如

图1.5所示，GAN可以



把马的图像

转换为斑马

的图像，把一

张照片变成

莫奈的画作

，而这几



乎不

需要任何监

督，也不需要

任何标签。使

这一切成为

可能GAN的变体

是循环一致

性生成对抗

网络（CycleGAN），相关内

容参见第9章

。

更实用些的

GAN应用同样令

人着迷。在线

零售的巨头

亚马逊



（Amazon）尝试

利用GAN提供时

尚建议：通过

分析无数的

搭配，系统能

学会生成符

合给定的任

意风格的新

产品。[3]

在医学

研究中，GAN通



过

合成样本增

强数据集，以

提高诊断准

确率。[4] 在掌握

了训练GAN及

其

变体的细节

之后，我们将

在第11章详细

地探讨这两

个应用。



（来源

：Unpaired Image-to-Image

Translation Using



Cycle-Consistent

Adversarial Networks, by Jun-Yan

Zhu et al., 2017.)

图1.5 通过使用

名为CycleGAN的GAN变体

，可以将莫奈

的画作变成

照片，或将图

片中的斑马

变成马；反之

亦然

GAN也被视

为实现通用

人工智能[5]的

重要基石。它

是一种能够

匹



敌人类认

知能力的人

工系统，能获

取几乎任何

领域的专业

知识——从

走路

所需的运动

技能到语言

表达技能，甚

至于写诗所

需的创作技

能。



然而，拥有

生成新数据

和新图像的

能力使得GAN有

时也会很危

险。

关于假新

闻的传播及

其危险性已

经是老生常

谈，GAN生成可信

假视频的



能

力也令人不

安。在2018年一篇

关于GAN的文章

的结尾处——这

篇文章

的标

题很贴切“如

何成为一个

人工智能”——《纽

约时报》记者

Cade



Metz和Keith Collins谈到了令

人担忧的前

景：GAN可能被用

来制造和

传

播易使人轻

信的错误信

息，比如虚假

的世界各国

领导人发表

声明的



视频

片段。《麻省理

工学院科技

评论》旧金山

分社社长Martin Giles

也

表达了他的

担忧，他在2018年

发表的《GAN之父

：赋予机器想

象力的



人》一

文中提到，在

技术娴熟的

黑客手中，GAN可

能会以前所

未有的规

模

被用来探索

和利用系统

漏洞。这些忧

虑促使我们

讨论GAN的应用

在道



德伦理

上的考量（第

12章）。

GAN可以为世

界带来许多

好处，但是任

何技术创新

都是一把双

刃



剑。对此，我

们必须怀有

一种哲学意

识：“除掉”一种

技术是不可

能

的，所以确

保像你这样

的人了解这

项技术的迅

速崛起及其

巨大的潜力

是很重要的

。



本书也仅能

触及应用GAN可

实现功能的

一些皮毛，但

是，我们希望



这本书能够

为你提供必

要的理论知

识和实践技

能，使你能够

继续从各



个

方面探索自

己最感兴趣

的领域。

事不

宜迟，让我们

开始吧！



1.5 小结



（1）GAN 是一种利用

两个神经网

络之间的动

态竞争来合

成真实数



据

样本的深度

学习技术，例

如能合成具

有照片级真

实感的虚假

图像。

构成一

个完整GAN的两

个网络如下

：



生成器，其目

标是通过生

成与训练数

据集别无二

致的数据来

欺骗

鉴别器

；



鉴别器，其目

标是正确区

分来自训练

数据集的真

实数据和由

生成

器生成

的伪数据。



（2）目

前，GAN在许多不

同的领域都

有着广泛的

应用，如时尚

、

医药和网络

安全等。



[1] 见Surpassing

Human-Level Face



Verification

Performance



on LFW

with GaussianFace,



by

Chaochao Lu and

Xiaoou Tang,



2014.

另

见《纽约时报

》文章GoogleTang, 2014Level Fs

Chinese Go



Master

in Win for

A.I.,by Paul Mozur, 2017.

[2] 见GoogleMozur, 2017Level Fs

Chinese Go Master in

Win f,



by

Cade Metz, Wired,

2017.



[3] Amazon

Has Developed



an

AI Fashion Designer,

by Will



Knight,

MIT Technology Review,

2017.



[4] Synthetic

Data Augmentation



Using

GAN for Improved

Liver



Lesion Classification,

by Maayan



Frid-Adar,

et al., 2018.

[5] OpenAI Founder: Short-Term

AGI Is a Serious

Possibility,



by Tony

Peng, Synced,



2018.

另见

A Path to

Unsupervised



Learning Through

Adversarial Networks,



by

Soumith Chintala,f



Code,

2016.



第2章 自编码

器生成模型

入门

本章主

要内容



将数

据编码到一

个潜在空间

（降维）以及后

续的维数扩

展

理解在变

分自编码器

环境下生成

建模的挑战

性



用Keras和自编

码器生成手

写数字

了解

自编码器的

局限性以及

GAN的应用动机

将本章献给

我的祖母Aurelie Langrova，她

在我们写完

这一章时

去

世了。我很想

念她！



——Jakub

你可能

想知道为什

么选择在书

中插入这一

章。主要原因

有以下3



个。

（1）生

成模型对大

多数人来说

是一个全新

的领域。大多

数人一



开始

接触到的往

往都是机器

学习中的分

类任务——也许

因为它们更

为

直观；而生

成模型试图

生成看起来

很逼真的新

样本，所以人

们对它了



解

甚少。考虑到

自编码器（最

接近GAN的前身

）丰富的资源

和研究，本

书

决定在探讨

GAN之前增加一

章，在一个更

简单的环境

介绍生成模

型。



如果你想

直奔令人兴

奋的新话题

，请略过这部

分内容。

（2）生成

模型非常具

有挑战性。由

于生成模型

代表性不足

，大



多数人不

知道典型的

生成模型的

结构是什么

样子的，也不

知道面临何

种挑战。尽管

自编码器在

许多方面与

最常用的模

型相近（例如

，有一

个明确

的目标函数

），但它们仍然

展现出许多

GAN也面临的挑

战，如评



估生

成样本质量

有多困难。我

们将在第5章

更深入地讨

论这一问题

。

（3）生成模型是

当前文献中

的研究热点

。正如我们将

在本章中



讨

论的，自编码

器本身有它

自己的用途

。自编码器也

是一个活跃

的研

究领域

，甚至在某些

领域是最前

沿的并且被

许多GAN模型显

式地采用。



其

他GAN架构也隐

式地受其启

发或者模型

包含自编码

器这种思维

——比

如我们将

在第9章中介

绍的CycleGAN。



2.1 生成模

型简介

你应

该对“深度学

习如何获取

图像中的原

始像素并将

其转化为类

别的预测”这

种操作并不

陌生。例如，可

以取包含图

像像素的3个

矩阵



（每个颜

色通道各1个

）在一个转换

系统中传递

，最后得到一

个数字。

如果

想反过来做

，该怎么办呢

？



从要生成内

容的描述指

令开始，最后

在转换系统

的另一端得

到图

像。这是

最简单、最非

正式的生成

模型，本书中

的内容会更

有深度。



更正

式一点，取一

个特定的描

述指令 ——简单

地假设它是

介于

0和9之间

的数字——并尝

试得到一个

生成的样本

。理想情况下

，



应该和另一

个真实的样

本 看起来一

样真实。描述

指令

是潜在

空间



（latent space）中的某

个激励，我们

不会总是得

到相同的输

出

。



这个潜在

空间是一个

习得的表征

——希望它按人

类思考方式

对人们有

意

义（“解离”）。不同

的模型将学

习相同数据

的不同潜在

表征。



第1章中

的随机噪声

向量通常被

称为来自潜

在空间的样

本。潜在

空间

是数据点的

一种更简单

的隐式表示

，它用 表示，简

单来说就是

维



度更低的

，例如，一个由

100个数字组成

的向量或数

组，而不是将

要使

用的768维

的样本。在许

多方面，一个

好的数据点

的潜在表示

会对该



空间

中相似的事

物进行分组

。在本章中，你

从图2.3中可以

理解在自编

码器的环境

中潜在的含

义，从图2.6和图

2.7中可以看到

潜在空间是

如

何影响生

成样本的。但

在此之前，我

们先来看看

自编码器的

功能描



述。

2.2 自

编码器如何

用于高级场

景



顾名思义

，自编码器可

以帮助我们

对数据进行

自动编码，它

由两

部分构

成：编码器和

解码器。为了

便于说明，我

们考虑这样

一个用



例：压

缩。

想象一下

，你正在给你

的祖父母写

信，讲述自己

作为机器学

习工



程师的

工作经历。他

们的认知水

平有限，而你

只有一页纸

的篇幅解释

自己所做的

一切，还要让

他们能够理

解。

再想象一

下，你的祖父

母还有严重

的健忘，根本

记不得你做

了什



么。这已

经感觉很难

了不是吗？可

能难在你必

须解释所有

术语。例

如，他

们仍可以阅

读并理解你

信中的基本

内容，比如你

的宠物猫做

了



什么，但是

可能对机器

学习工程师

的概念比较

陌生。换句话

说，他们

从潜

在空间 到输

出 的转换已

经被随机初

始化了。你必

须先在他们

的

头脑中重

新训练这些

“心理结构”才

能解释清楚

。通过传入概

念 并查



看他

们是否能成

功地以有意

义的方式重

现概念

，来训

练他们的“自

编码器”。这样

就可以测量

误差，这称为

重建损失 。

我

们每天都在

不知不觉地

压缩数据（或

者说是信息

），这样就不



会

花很长时间

解释已知的

概念。自编码

在人类的交

流中随处可

见，但

这取决

于具体情境

：向祖父母解

释的东西不

必向我们的

同事解释，比

如机器学习

模型是什么

。因此一些人

的潜在空间

比另一些人

更合适，



这取

决于具体情

境。我们可以

直接转到他

们的“自编码

器”已经理解



的简单表示

。



我们可以压

缩，因为将某

些重复出现

的概念简化

为已经得到

认同

的抽象

概念是很有

用的，例如一

个职位名称

。自编码器可

以系统地自

动发现这些

高效信息模

式，对其进行

定义，并将它

们用作快捷

方式来



提高

信息吞吐量

。结果就是我

们只需要传

输

即可——它通

常是低维度

的，从而节省

了带宽。



从信

息论的角度

来看，这就是

在不牺牲太

多理解的情

况下尝试通



过“信息瓶颈

”（信件或口头

交流）传递尽

可能多的信

息。



你几乎可

以把这想象

成一个只有

你和你的家

人理解的秘

密快捷方

式

，但是已经针

对你们经常

讨论的话题

进行了优化

。[1]为简单起见

并



把重点放

在压缩上，我

们选择忽略

词语是一个

显式模型的

事实，尽管

大

多数单词的

背后还具有

情境相关的

巨大复杂性

。



定义

潜在空

间是数据的

隐式表示。自

编码器不是

在未压缩的

版本中表



达

单词或图像

（例如机器学

习工程师，或

图像的JPEG编解

码器），而

是根

据对数据的

理解来对其

进行压缩和

聚类。



2.3 什么是

GAN的自编码器



自编码器与

GAN的一个关键

区分点是：我

们用一个损

失函数对整

个



自编码器

网络进行端

到端的训练

，而GAN的生成器

和鉴别器分

别有损失

函

数。现在看看

自编码器和

GAN所处的位置

，如图2.1所示，两

者都是



生成

模型，且都是

人工智能（AI）和

机器学习（ML）的

子集。

图2.1 在AI图

景中的GAN和自

编码器。不同

的研究人员

对此可能有

不同的结论

，



我们将这一

点留给学术

界人士去讨

论

在这种情

况下，对于自

编码器（或其

变分形式，VAE），我

们有一



个试

图优化的已

明确写出的

函数（一个代

价函数）；但在

GAN中没有像

均

方误差、准确

率或ROC曲线下

面积这样明

确的指标进

行优化。[2]GAN



有两

个不能写在

一个函数中

的相互竞争

的目标。

2.4 自编

码器的构成

在查看自编

码器的结构

时，我们将以

图像为例，但

此结构也适

用

于其他情

况（例如语言

，像前文给祖

父母写信的

示例）。与机器

学习



中的许

多进展一样

，自编码器的

高级理念很

直观，并遵循

以下简单步

骤，如图2.2所示

。

图2.2 在前文提

到的信件示

例中使用自

编码器遵循

以下步骤。（1）压

缩关于机



器

学习工程师

的所有知识

。（2）将其组合到

潜在空间（给

祖母的信）中

。当利用

对单

词的理解作

为解码器（步

骤3）重建一个

含义有损的

版本时，你就

得到了一个

与原始输入

（即你的想法

）在同一空间

的（祖母的头

脑中）想法的

表示



（1）编码器

网络：取一个

表示

（如一个

图像），然后用

学过的



编码

器（通常是一

个单层或多

层的神经网

络）将维数从

减小到 。

（2）潜在

空间 ：在训练

时，试图建立

具有一定意

义的潜在空

间。潜在空间

通常是有较

小维度的表

示，起着中间

步骤的作用

。在这

种数据

的表示中，自

编码器试图

“组织其思想

”。



（3）解码器网络

：用解码器将

原始对象重

建到原始的

维度，这通

常

由一个神经

网络完成。它

是编码器的

镜像，对应着

从 到 的步骤

。

我们可以应

用解码的逆

过程，从潜在

空间的256个像

素长的向量

中得到



784个像

素长的重构

向量（28×28大小的

图像）。

下面给

出一个自编

码器训练过

程的示例。



（1）将

图像 通过自

编码器输入

。

（2）得到 ，即重建

的图像。



（3）评估

重建损失，即

和

之间的差

异：



使用图像

和 的像素之

间的距离（如

MAE）完成；

给了一

个显式的目

标函数 ，以通

过梯度下降

的形式进行

优化。

因此我

们的任务就

是找到解码

器和编码器

的参数，这些

参数将最



小

化我们用梯

度下降法更

新的重构损

失。

现在你可

能想知道为

什么这很有

用或者很重

要，那就继续

看看



吧！

2.5 自编

码器的使用

尽管自编码

器很简单，但

是有很多理

由值得我们

关注它。

（1）首先

，我们可以自

由地压缩！这

是因为图2.2中

的中间步骤

（2）在潜在空间

的维度上变

成了一个智

能缩减的图

像或对象。从

理论



上讲，这

可能比原始

输入小几个

数量级，而且

显然不是无

损的，但是

如

果愿意的话

，我们可以随

意利用这种

副作用。



（2）仍使

用潜在空间

，我们可以联

想到许多实

际应用，如单

类

分类器（one-class classifier）——一

种异常检测

算法，可以在

缩



减的可更

快搜索的潜

在空间中查

看项目，以检

查和目标类

别的相似

性

。这就可以用

于搜索（信息

检索）或者异

常检测（比较

潜在空间中

的接近度）。



（3）另

一个用例是

黑白图像的

数据去噪或

彩色化。[3]如果

有旧

的/有噪

声的一张照

片或者一段

视频——例如第

二次世界大

战时期的影

像，那么可以

减少它们的

噪点并重新

着色。因此自

编码器与GAN的

相似



之处在

于，GAN在这类应

用程序中也

表现很出色

。

（4）有些GAN的架构

，例如BEGAN[4]，将自编

码器用作其

架构的



一部

分以帮助稳

定训练——后面

就会发现这

至关重要。

（5）训

练自编码器

不需要带标

签的数据。我

们将在下一

节说明到



为

什么无监督

学习如此重

要。这让我们

更轻松，因为

不需要我们

去寻

找标签

就可以自训

练。



（6）最后但同

样重要的是

，可以用自编

码器生成新

图像。自编码

器已应用于

生成从数字

到人脸到卧

室的任何事

物，但通常图

像的分辨

率

越高，性能就

越差，因为输

出往往看起

来很模糊。但

是对于MINST数



据

集和其他低

分辨率图像

来说，自编码

器的效果很

好。

定义



Modified National

Institute of



Standards

and



Technology（MNIST）数据

集是一个手

写数字的数

据集。维基百

科对这

一在

计算机视觉

领域的文献

中非常流行

的数据集有

一个很好的

概述。



这些都

可以做到，因

为我们找到

了已拥有数

据的新表示

。这种表

示很

有用，可以提

取出压缩信

息的核心信

息；基于隐式

表达，它也很

容易操作或

生成新的数

据。



2.6

无监督学

习



在第1章中

，我们讨论了

无监督学习

（尽管没怎么

用这个术语

）。

在本节中，我

们将进一步

探讨这一概

念。



定义

无监

督学习（unsupervised learning）是一

种从数据本

身学习



而不

需要关于这

些数据含义

的附加标签

的机器学习

。例如，聚类是

无

监督的，因

为只是试图

揭示数据的

底层表示；异

常检测是有

监督的，



因为

需要人工标

记的异常情

况。

从本章中

，我们可以了

解无监督机

器学习为何

与众不同，可

以使



用任何

数据而不必

为特定目的

对其进行标

记。我们可以

使用任何互

联

网上的数

据而不必为

关心的每一

种表示标记

每个样本，例

如，这张图



片

中有只狗吗

？有辆车吗？

在

监督学习中

，如果数据没

有针对确切

任务的标签

，那么别的



（几

乎）所有标签

都可能是没

用的。如果你

有一个可以

对谷歌街景

中

的汽车分

类的分类器

，想对动物进

行分类但是

没有这些动

物图像的标

签，这种情况

下使用相同

数据集训练

一个动物分

类器基本上

是不可能



的

。即使这些样

本中经常出

现动物，也需

要标注者重

新标注同样

的谷

歌街景

数据集中的

动物。



本质上

，我们需要在

了解具体用

例之前就考

虑到数据的

应用，这

很困

难！但是对于

许多压缩类

型的任务，你

总是有带标

记的数据，即

数据本身。François Chollet、Google的

研究科学家

、深度学习框

架

Keras的发明者

等研究人员

把这种类型

的机器学习

称为自监督

。在本



书的大

部分内容中

，唯一的标签

将是样本本

身或者数据

集中的任何

其

他样本。



由

于训练数据

也充当了标

签，从一个关

键的角度来

看，训练许多

这样的算法

会容易得多

——毕竟现在有

更多的数据

可以处理，不

需要

等待数

周时间，也不

需要为足够

的带标签的

数据支付数

百万美元。



2.6.1 吐

故纳新

自编

码器本身其

实是相当老

的想法——至少

将机器学习

视为一个



领

域时就已存

在。但是，鉴于

当今每个人

都在研究更

深奥的东西

，因

此人们成

功地将深度

学习应用于

编码器和解

码器的一部

分中，一点儿

也不会让人

感到惊讶。



自

编码器由两

个神经网络

组成：编码器

和解码器。在

本书示例

中

，两者都具有

激活函数[5]，且

只为每个函

数使用一个

中间层。这意

味着每个网

络中有两个

权重矩阵——对

于编码器网

络，一个从输

入到



中间层

，一个从中间

层到潜在空

间；对于解码

器网络，又有

一个从潜

在

空间到不同

的中间层和

一个从中间

层到输出的

权重矩阵。如

果每个



网络

都只有一个

权重矩阵，那

么过程将类

似于一种名

为主成分分

析

（Principal Component Analysis，PCA）的成熟分

析技术。如果

你掌

握了相

关的线性代

数知识，对这

些就会对此

非常熟悉。



注

意

在如何求

解上存在一

些技术差异

，例如PCA是数值

确定的，而自

编



码器通常

是使用随机

优化进行训

练的。解的最

终形式也有

所不同，但

本

书不会讲解

其中一种是

如何得出正

交基的以及

它们是如何

从根本上



处

于相同的向

量空间——如果

你碰巧知道

其中的原理

，就更好理解

了。

2.6.2 使用自编

码器生成



我

们在本章章

首提到可以

使用自编码

器生成数据

。可能有些人

已

经考虑到

潜在空间的

使用以及是

否可以将其

重新用于其

他用途。完全

可以！（如果你

也是这样认

为，请给自己

点一个赞！）



让

我们一起来

看一下如何

生成数据。回

到给祖父母

写信的例子

并

稍加改变

，使用自编码

器作为生成

模型可能开

始有意义。例

如，假设



你对

一种职业的

认知变成了

编码器的网

络输入，将写

在纸上的职

业的

词语看

作潜在空间

的输入，把祖

父母头脑中

关于职业的

认知看作输

出。



在这种情

况下，潜在空

间解码（一个

写在纸上的

单词结合祖

父母

阅读和

理解的能力

）成为一种在

他们头脑中

产生认知的

生成模型。文

字作为一种

激励或某种

潜在向量，而

输出的认知

和原始输入

处于同一



个

高维空间——祖

父母的想法

和你的想法

一样复杂，尽

管略有不同

。

现在把重点

放回图像域

——在一组图像

上训练自编

码器，调整编

码器和解码

器的参数，以

找到适合两

个网络的参

数。我们还可

以了解



样本

在潜在空间

中的表示方

式。为了生成

样本，我们切

断编码器部



分，仅使用潜

在空间和解

码器。生成过

程如图2.3所示

。



图2.3 从训练中

知道样本放

在潜在空间

中的位置，所

以可以轻松

生成与模型

所见

相似的

样本。即使不

能，也可以轻

松在潜在空

间中进行迭

代或网格搜

索来确定模

型可以生成

的表示类型

（图片改编自

Mat Leonard在Github上的简单

自编码器项

目）

2.6.3 变分自编

码器



变分自

编码器和“常

规”编码器有

何区别？这一

切都与神奇

的潜

在空间

有关。在变分

自编码器的

情况下，我们

将潜在空间

表示为一个

习得的平均

值和标准差

的分布，而不

仅仅是一组

数字。通常选

择多元



高斯

模型，但它是

什么或者为

什么选择这

个分布而不

是另一种的

原因

现在并

不重要。如果

想重新了解

一下这个分

布是什么样

子的，请参阅

图2.5。



如果你熟

悉统计学，那

么可能已经

意识到变分

自编码器是

一种基

于贝

叶斯机器学

习的技术。这

意味着必须

学习分布，所

以就增加了

更



多的限制

。换句话说，常

规自编码器

尝试将潜在

空间作为数

字数组来

学

习变分自编

码器——以贝叶

斯为例，尝试

找到定义分

布的正确参

数。



然后从潜

在分布中采

样得到一些

数字，把它们

输入到解码

器，就

返回一

个类似原始

数据集中的

样本，不过它

是由模型创

建的新样本

。



2.7 代码就是生

命

本书使用

了流行的深

度学习的高

级API——Keras，强烈建议

你熟



练掌握

它。网上有许

多提供优质

免费资源的

社区，如Towards Data

Science。如果

想从书本中

学习有关知

识，推荐另一

本曼宁出版

社不错



的书

——Deep Learning

with Python，这是Keras的发明

者和编写者

François Chollet写的。

Keras是用于

TensorFlow、Microsoft Cognitive



Toolkit（CNTK）和Theano这几个深

度学习框架

的高级API。它易

于使

用并允

许更高级别

的抽象，可让

用户专注于

概念和思路

，而不必记录

使用的每个

标准块的乘

法、偏置、激活

函数、池化[6]以

及担心变量

作



用域等。

为

了展示Keras的威

力和用它简

化编写神经

网络的过程

，这里看一



下

以最简单的

形式写的变

分自编码器

的示例。[7] 在本

教程中使用



Keras函数式API来编

写函数导向

的深度学习

代码，随着学

习更加深入

和复杂，我们

将在后续章

节介绍顺序

式API。



此示例的

目的是基于

潜在空间生

成手写数字

。我们将创建

一个对

象——generator或

decoder，给定一个是

潜在空间向

量的输入，



可

以用predict()的方法

生成新的手

写数字的样

本。我们当然

要使用

MINST数据

集，因为我们

可不想让任

何人思考是

否还有其他

数据集可用

（图2.4）。



（来源：Artificial

Intelligence Memes for

Artificial Intelligence



Teens

on Facebook．）



图2.4

关

于计算机视

觉研究人员

的想法，说得

够多了……



首先

导入所有依

赖项。清单2.1所

示的代码已

经在Keras的最新

版

本2.2.4和TensorFlow 1.12.0版本

中进行了验

证。



清单2.1

标准

导入



from keras.layers

import Input,



Dense,

Lambda



from keras.models

import Model



from

keras import backend

as K



from

keras import objectives

from keras.datasets import mnist

import numpy as np

下一步

设置全局变

量和超参数

，如清单2.2所示

。图像的原始

尺寸



为28×28，这是

标准尺寸，然

后将MINST数据集

中的图像展

平，获得

784（28×28）的向

量。



还有一个

包含256个节点

的中间层。但

是我们要尝

试其他的大

小

——这就是为

什么它是一

个超参数！



清

单2.2 设置超参

数

batch_size = 100

original_dim = 28*28 ←---

MNIST图像的高

×宽



latent_dim =

2



intermediate_dim =

256



nb_epoch =

5 ←---



epoch数

epsilon_std = 1.0

如清单

2.3所示，开始构

建编码器，使

用Keras的函数式

API实现。



注意

函

数式API使用Python中

的lambda函数返回

另一个函数

的构造，



该函

数接收另一

个输入，生成

最终结果。

简

单的用法是

先简单地声

明每个层，将

前面的层作

为常规参数

之



后的第二

组参数，例如

层h将x作为输

入。最后当编

译模型并指

出模型

的起

点 和终点（[z_mean, z_log_varand z]）时

，Keras将会

明白起

始输入和最

终列表输出

是如何连接

在一起的。 是

潜在空间，在

本示例中是

一个由均值

和方差定义

的正态分布

。

现在定义编

码器。[8]



清单2.3 构

建编码器

x = Input(shape=(original_dim,), name="input")

←--- 编

码器的输入

h =

Dense(intermediate_dim, activation='relu',



name="encoding")(x)

←--- 中间层



z_mean

= Dense(latent_dim, name="mean")(h)

←--- 定义

潜在空间的

均



值

z_log_var = Dense(latent_dim, name="log-variance")(h)

←--- 定



义潜

在空间的log

variance



z =

Lambda(sampling, output_shape=(latent_dim,))([z_mean,



z_log_var])

←--- 注

意，output_shape不是一定

要用TensorFlow后端



encoder

= Model(x, [z_mean,

z_log_var, z], name="encoder") ←---

将

编码器定义

为一个Keras模型

接下来是棘

手的部分，从

潜在空间采

样后将这些

信息传递给

解码



器。但是

请仔细考虑

一下z_mean和z_log_var是如

何连接的：它

们

都是由有

两个节点的

全连接层与

层h连接的，这

是正态分布

的定义特



征

——均值和方差

。清单2.4实现了

前述的采样

函数。

清单2.4 创

建采样辅助

函数



def

sampling(args):



z_mean, z_log_var

= args



epsilon

= K.random_normal(shape=(batch_size, latent_dim),

mean=0.)



return z_mean

+ K.exp(z_log_var



/

2) * epsilon

换句话

说，学习的是

均值（μ）和方差

（σ）。这个整体实

现



中，我们有

一个 通过采

样函数连接

z_mean和z_log_var，这样既可



以训练，又可

以接着有效

采样，以在最

后得到一些

看上去很优

雅的数



字。在

生成过程中

，我们将根据

这些学习到

的参数从此

分布中采样

，

然后把这些

值输入解码

器获得输出

。对分布或者

概率密度函

数有些陌



生

的读者，可以

参考图2.5所示

的单峰二维

高斯分布的

示例。

（a）



（b）

（c）



（d）

（e）



（f）

图2.5 二维

高斯分布概

率密度函数

。它们是不相

关的二维正

态分布，具有

不同的



方差

（a）方差0.5，（b）方差1，（c）方

差2。（d）、（e）和（f）的分布

与

（a）、（b）和（c）的完全

相同，但以![{z}]



(http://private.codecogs.com/gif.latex?{z})轴

最大值为0.7绘

制。直观地

讲

，这只是一个

函数，它表示

每一点发生

的可能性。因

此（a）和（d）更加集

中，而（c）和（f）使远

离原点的值

有可能出现

，但每个给定

值的可能性

都不大



现在

我们已经了

解了定义潜

在空间的内

容以及这些

分布的外观

，

接下来编写

解码器，如清

单2.5所示。首先

将之前的层

写为变量，以

便



稍后生成

时重新使用

。

清单2.5 编写解

码器



input_decoder

= Input(shape=(latent_dim,), name="decoder_input")

←--- 解码器

的输入



decoder_h

= Dense(intermediate_dim, activation='relu',

←---



潜在

空间转化为

中间维度

name="decoder_h")(input_decoder)



x_decoded =

Dense(original_dim, activation='sigmoid',



name="flat_decoded")(decoder_h)

←--- 得

到原始维度

的平均值



decoder

= Model(input_decoder, x_decoded,

name="decoder") ←---



将

解码器定义

为一个Keras模型



现在把编码

器和解码器

组合为一个

VAE模型，如清单

2.6所示。



清单2.6 组

合模型

output_combined = decoder(encoder(x)[2]) ←---

抓取

输出需要获

取第



三个元

素，即采样z

vae = Model(x, output_combined)

←--- 连

接输入和总

输出



vae.summary()

←--- 输出模

型的整体结

构



接下来定

义损失函数

，这样自编码

器就可以训

练了，如清单

2.7所

示。



清单2.7 定

义损失函数



def vae_loss(x, x_decoded_mean, z_log_var,

z_mean,



original_dim=original_dim):

xent_loss = original_dim *

objectives.binary_crossentropy(x,



x_decoded_mean)

kl_loss = - 0.5

* K.sum(



1

+ z_log_var -

K.square(z_mean) - K.exp(z_log_var),

axis=-1)



return xent_loss

+ kl_loss



vae.compile(optimizer='rmsprop',

loss=vae_loss) ←--- 编译模型

可

以看到，二元

交叉熵和KL散

度加在一起

组成整体损

失。KL散度



衡量

分布之间的

差异：假设有

图2.5中的两个

分布，然后测

量它们重叠

的体积。二元

交叉熵是二

分类常见的

损失函数之

一：这里简单

定义为

将x的

每个像素灰

度值与x_decoded_mean进行

比较。如果你

在读完



下面

的定义后仍

感困惑，请参

考第5章中关

于测量分布

之间差异的

更多

详细信

息。



定义

对熟

悉信息论的

人来说，KL散度

（Kullback–Leibler



divergence, KL

divergence）又名相对熵

，是两个分布

的交叉熵与

其自身熵的

差异。对此不

熟悉的读者

可以这样理

解，假设绘制

出两个



分布

，二者不重叠

的任何地方

的面积都将

与KL散度成比

例。

接下来我

们定义模型

，从x开始到x_decoded_mean结

束。该模



型使

用RMSprop编译，也可

以使用Adam或者

随机梯度下

降

（Stochastic Gradient Descent，SGD）。与任何深

度学习系统

一

样，我们使

用反向传播

误差来定位

参数空间。我

们总是使用

某种类型



的

梯度下降，但

一般来说，除

了Adam、SGD和RMSprop这3种方

法，人们

很少

尝试其他的

方法。



定义

随

机梯度下降

是一种优化

技术。通过计

算某权重对

误差的贡献

，



我们可以更

新权重值。如

果预测100%正确

，则不会更新

，这就是模型

训练的过程

。建议参考如

Deep

Learning with Python的相关图书

深入

学习SGD。



我

们使用拆分

训练集/测试

集和输入归

一化的标准

操作对模型

进行

训练，如

清单2.8所示。



清

单2.8 拆分训练

集/测试集

(x_train, y_train), (x_test, y_test)

= mnist.load_data()



x_train

= x_train.astype('float32') /

255.



x_test =

x_test.astype('float32') /



255.

x_train = x_train.reshape((len(x_train),

np.prod(x_train.shape[1:])))



x_test =

x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))



我

们对数据进

行归一化操

作，并将训练

集和测试集

中的样本从



28×28的矩阵调整

大小为784位长

的数组。



接下

来，应用fit函数

，使用shuffle获得一

个真实的无

序数据

集。在

训练过程中

，用验证集数

据加以监测

：



vae.fit(x_train, x_train,

shuffle=True,



nb_epoch=nb_epoch,

batch_size=batch_size,



validation_data=(x_test, x_test),verbose=1)

完整版代码

提供了对潜

在空间的有

趣可视化，请

查看配套资

源中



本章的

Jupyter Notebook或者Google

Colaboratory Notebook。训练



完

成后，我们甚

至可以在二

维平面上可

视化潜在空

间的值，如图

2.6所

示。



图2.6 测试

集中所有点

到潜在空间

及其类的二

维投影。图上

显示的是二

维潜在空

间

。我们映射出

这些生成样

本的类别，并

根据右侧的

图例相应地

为它们着色

。可



以看到同

一类样本倾

向于整齐地

分组在一起

，这说明是一

个很好的表

示

我们还可

以用固定增

量网格化枚

举潜在空间

的所有值，以

查看生



成的

输出。例如，在

两个维度上

以0.15的线性增

量从0.05增加到

0.95，就得到了图

2.7所示的可视

化结果。这种

情况下使用

的是二元高



斯函数，因此

有两个轴可

以迭代。有关

此可视化的

代码，参见配

套资



源中本

章的Jupyter Notebook或者Google

Colaboratory Notebook。



图

2.7

网格化枚举

潜在空间子

集的值，并将

每个潜在空

间值输入以

生成样本，最

后组成了本

图。由此可以

了解到随着

的变化最终

生成的图像

变化了多少

2.8 为什么要尝

试使用GAN

看起

来本书到这

里似乎就可

以结束了，毕

竟我们已经

生成了MINST



数据

集的图像—— 这

将是后续几

个程序的测

试用例。请允

许我们解释



一下为什么

还要介绍后

续章节的动

机。



为了理解

面临的挑战

，假设我们有

一个简单的

一维双峰分

布，如

图2.8所示

（和之前一样

，只需要将其

视为一个简

单的数学函

数。它介



于0和

1之间，表示任

何给定点的

概率。该函数

的值越高，在

该精确点

上

采样的点就

越多）。



假设从

这个真实分

布中抽取了

一堆样本，但

是不知道底

层的模

型。现

在试图推断

产生这些样

本的分布是

什么，但是由

于某种原因

，



我们假设真

实分布是简

单的高斯分

布，而且只需

要估计均值

和方差即

可

。由于没有正

确指定模型

（在这种情况

下对这些样

本的模态做

出了



错误的

假设），因此陷

入了巨大的

麻烦。例如，如

果应用最大

似然估

计（maximum likelihood estimation）这

一传统统计

技术来估计

此分

布，则为

单峰分布——在

某种程度上

，这就是VAE在努

力做的——我们

得到了错误

的估计。由于

没有正确指

定模型，[9] 它将

估计出一个

大

约是两个

分布平均值

的正态分布

，称为点估计

（point estimate）。



最大似然是

一种不会预

测出也无法

计算出两个

不同分布的

技术。因此

为

了使误差最

小，它会在点

估计值周围

建立一个“厚

尾”的正态分

布。这看似微

不足道，但请

牢记，我们正

尝试在非常

高维的空间

中确



定模型

，所以这并不

容易！

图2.8 最大

似然、点估计

和真实分布

。灰色（理论上

）的分布是双

峰而不是单

峰。但如果假

设是单峰，就

会导致灾难

性错误，而且

会导致模式

崩溃（第5章）。

尤

其在使用KL散

度时，这经常

会发生，例如

VAE或早期GAN



定义

双峰（bimodal）是指有

两个峰或者

两个模式。这

个概念在第

5章

中会很有

用。在此处，我

们令总体分

布由均值为

0和5的两个正

态分布



组成

。

有趣的是，点

估计也将是

错误的，甚至

生成的样本

在真实值中

从



未出现过

。查看样本（黑

色十字图标

）会发现在我

们估计为均

值的地

方没

有实际样本

出现。这会产

生大麻烦。将

它与自编码

器联系起来

，



看看在图2.6中

我们如何在

以原点为中

心的潜在空

间中学习二

维正态分

布

？但是如果将

人脸放入训

练数据中会

怎样呢？这将

不再有一个

容易



估计的

中心，因为两

个数据分布

会有比想象

中更多的模

式。结果是，

即

使在分布的

中心附近，VAE也

会产生两个

数据集的奇

怪混合，因为

它



会试图以

某种方式分

离两个数据

集。

到目前为

止，我们仅讨

论了统计上

的错误假设

的影响。要将

这一



方面与

自编码器生

成的图像联

系起来，应该

考虑高斯潜

在空间 允许

我

们做什么

。VAE使用高斯分

布来构建它

所见的数据

的表示。但是

因为高



斯分

布有99.7%的概率

质量落在中

间的3个标准

差内，VAE也会选

择“安

全中间

地带”。VAE在某种

程度上是在

试图直接提

出基于高斯

分布的基



础

模型，但现实

可能非常复

杂，所以VAE不能

像GAN那样进行

扩展——

GAN可以提

取“场景”。



由图

2.9可以看到，当

VAE选择“安全中

间地带”时会

发生什么。

在

CelebA数据集上——其

特征是经过

对齐和裁剪

的人脸，VAE很好

地模



拟出了

始终存在的

面部特征（如

眼睛或嘴巴

），却在背景部

分出错

了。



（来

源：VAE-TensorFlow by

Zhenliang He,



GitHub）

图2.9 这些由

VAE生成的假人

脸边缘非常

模糊并融合

到了背景中

。因为CelebA数



据集

的图像居中

且对齐，使眼

睛和嘴巴周

围的特征保

持一致，但是

背景往往会

有

所不同。VAE选

择稳妥的方

法，通过选择

“安全”像素值

使背景模糊

，这样可以最

大限度地减

少损失，但不

能生成质量

良好的图像

此外，GAN对真实

数据的分布

具有隐式且

难以分析的

理解。正如你

将在第5章中

发现的那样

，VAE属于直接估

计极大似然

模型的那一

族。

希望本节

能使你理解

目标数据的

分布以及在

训练过程中

如何体现



分

布的影响。这

些假设将在

第10章中得到

进一步研究

：模型假设了

如

何填充分

布，这就产生

了一个致命

问题——对抗样

本能利用它

使机器



学习

模型失败。

2.9 小

结



（1）高级自编

码器由编码

器、潜在空间

和解码器组

成。使用常用



目标函数来

训练自编码

器，该目标函

数可以测量

再现数据和

原始数据



之

间的距离。

（2）自

编码器有许

多应用，也可

以用作生成

模型。在实践

中这往



往不

是其主要用

途，因为其他

方法（尤其是

GAN）对生成任务

更为擅

长。



（3）可

以使用Keras编写

简单的变分

自编码器生

成手写数字

。

（4）VAE的局限性促

使我们的研

究向GAN迈进。



[1] 实

际上，著名的

欧洲金融家

族Rothschilds在他们的

交流中就这



样做了，这也

是他们在金

融领域如此

成功的原因

。



[2] 代价函数（也

称为损失函

数或目标函

数）是试图优

化/最小化的



函数。例如，在

统计学中，这

可能是均方

根误差（RMSE）。均方

根误



差（RMSE）是一

个数学函数

，通过获取样

本的真实值

和预测值之

间差

的平方

根来给出误

差。在统计学

中，我们通常

希望通过假

阳性和假阴

性的几种组

合来评估分

类器，ROC曲线下

面积（AUC）可以帮

助我们做



到

这一点。因为

这个概念超

出了本书的

范围，更多详

细信息可以

查阅

维基百

科上的解释

。



[3] 有关黑白图

像着色的更

多信息,

请参

阅Emil Wallner在GitHub上



的项

目Coloring

Greyscale Images.



[4]

BEGAN是边界均

衡生成对抗

网络（Boundary Equilibrium



Generative

Adversarial Network）的缩写

。这种有趣的

GAN架构率先



使

用自编码器

作为网络其

架构的一部

分。

[5] 通过激活

函数将前一

层计算的任

何输出馈入

，再传递给下

一层。



人们通

常会选择一

个线性整流

函数（Rectified

Linear Unit，ReLU）



又称修

正线性单元

，定义为max(0,

x)。本书

不会过多阐

述激活函数

。



[6] 池化（pooling

block）是在层

上的操作，它

将多个输入

合并为



更少

的输入，例如

有4个数字的

矩阵将其最

大值作为一

个数字输入

。这

是计算机

视觉中一种

降低复杂度

的常见操作

。



[7] 为简单起见

，作者已经对

此例进行了

修改。

[8] 这个想

法受到本书

论坛用户Branko Blagojevic的

启发，笔者在

此表示感谢

。

[9] 参见 Pattern Recognition

and Machine Learning一书，作

者

Christopher Bishop (Springer, 2011)。

第3章 你的

第一个GAN模型

：生成手写



数

字

本章主要

内容



探索GAN与

对抗训练背

后的理论

了

解GAN与传统神

经网络的区

别



Keras中实现GAN并

训练它，以生

成手写数字

本章将探讨

GAN背后的基础

理论，然后介

绍一些如果

深入研究这

个

领域可能

会遇到的常

用数学表示

。这些描述要

么是你在更

侧重于理论

的出版物中

看到的，要么

是在关于这

个主题的许

多学术论文

中看到



的。本

章也为后续

章节提供了

背景知识，特

别是第5章。

但

从严格的实

用角度来看

，你不必为这

些形式担心

，就像不需要

知道发动机

如何运转就

可以驾车一

样。用如Keras和TensorFlow这

样的



机器学

习库提取出

基础数学知

识，并巧妙地

把它们打包

成可导入的

代

码行。



这将

是本书中反

复出现的主

题，在机器学

习和深度学

习中也是如

此。如果你愿

意直接进入

实践部分，也

可以粗略浏

览理论部分

并跳到

代码

教程部分（3.4节

）。



3.1 GAN的基础：对抗

训练

形式上

，生成器和鉴

别器由可微

函数表示如

神经网络，它

们都有



自己

的代价函数

。这两个网络

是利用鉴别

器的损失进

行反向传播

训

练。鉴别器

努力使真实

样本输入和

伪样本输入

带来的损失

最小化，而



生

成器努力使

它生成的伪

样本造成的

鉴别器损失

最大化。

图3.1总

结了这一动

态过程。它是

第1章中GAN结构

图的一个更

通用



的版本

——第一次解释

了什么是GAN以

及它们是如

何工作的。与

第1章

中手写

数字的示例

不同，在图3.1中

，训练数据集

理论上可以

是任何东



西

，具有普遍性

。

图3.1 在这个GAN结

构图中，生成

器和鉴别器

都利用鉴别

器损失进行

训练。鉴别



器

努力使损失

最小化，生成

器则努力使

它产生的伪

样本对应的

损失最大化



训练数据集

决定了生成

器要学习模

拟的样本类

型，例如，目标

是



生成猫的

逼真图像，我

们就会给GAN提

供一组猫的

图像。

用更专

业的术语来

说，生成器的

目标是生成

符合训练数

据集数据



分

布的样本。[1] 对

计算机来说

，图像只是矩

阵：灰度图像

是二维

的，彩

色图像是三

维的。当在屏

幕上呈现时

，这些矩阵中

的像素值将

显示为图像

线条、边缘、轮

廓等的所有

视觉元素。这

些值在数据

集中



的每个

图像上遵循

复杂的分布

，如果没有分

布规律，图像

将不过是些



随机噪声。目

标识别模型

学习图像中

的模式以识

别图像的内

容，生成



器所

做的可以认

为是相反的

过程：它学习

合成这些模

式，而不是识

别

这些模式

。



3.1.1 代价函数

遵

循标准的表

示形式，用 表

示生成器的

代价函数，用

表示



鉴别器

的代价函数

。两个网络的

训练参数（权

重和偏置）用

希腊字母

表

示： 表示生成

器， 表示鉴别

器。

GAN在两个关

键方面不同

于传统的神

经网络。第一

，代价函数 ，



传

统神经网络

的代价函数

仅根据其自

身可训练的

参数定义，数

学表示

为 。相

比之下，GAN由两

个网络组成

，其代价函数

依赖于两个

网络



的参数

。也就是说，生

成器的代价

函数是

( , )，而鉴

别器的

成本

函数是 ( , )。[2]

第二

，在训练过程

中，传统的神

经网络可以

调整它的所

有参数



θ。在GAN中

，每个网络只

能调整自己

的权重和偏

置。也就是说

，在训

练过程

中，生成器只

能调整 ，鉴别

器只能调整

。因此，每个网

络只控制了

决定损失的

部分参量。

为

了使上述内

容不那么抽

象，考虑下面

这个类比。想

象一下我们

正在选择下

班开车回家

的路线，如果

交通不堵塞

，最快的选择

是高速



公路

，但在交通高

峰期，优选是

走一条小路

。尽管小路更

长更曲折，

但

当高速公路

上交通堵塞

时，走小路可

能会更快地

回家。



让我们

把它当作一

道数学题—— 作

为代价函数

，并定义为回

家

所需的时

间。我们的目

标是尽量减

小 。为简单起

见，假设离开

办公



室的时

间是固定的

，既不能提前

离开，也不能

为了避开高

峰时间而晚



走。所以唯一

能改变的参

数是路线θ。



如

果我们所拥

有的是路上

唯一的车，代

价将类似于

一个常规的

神

经网络：它

将只取决于

路线，且优化

)完全在我们

的能力范围

内。



然而，一旦

将其他驾驶

员引入方程

式，情况就会

变得更加复

杂。突然

之间

，我们回家的

时间不仅取

决于自己的

决定，还取决

于其他驾驶

员



的行路方

案，即 (θ

我们, θ



其

他驾驶员)。就

像生成器网

络和鉴别器



网络一样，“代

价函数”将取

决于各种因

素的相互作

用，其中一些

因



素在我们

的掌控之下

，而另一些因

素则不在。

3.1.2 训

练过程



上面

所描述的两

个差异对GAN的

训练过程有

着深远的影

响。传统神

经

网络的训练

是一个优化

问题，通过寻

找一组参数

来最小化代

价函



数，移动

到参数空间

中的任何相

邻点都会增

加代价。这可

能是参数空

间中的局部

或全局最小

值，由寻求最

小化使用的

代价函数所

决定。最

小化

代价函数的

优化过程如

图3.2所示。



（来源

：Adversarial Machine

Learning, by



Ian

Goodfellow, ICLR



Keynote,

2019.）



图3.2 碗形网格

表示参数空

间θ1和θ2中的损

失

。黑色点线

表示通过优

化使



参数空

间中的损失

最小化

因为

生成器和鉴

别器只能调

整自己的参

数而不能相

互调整对方

的



参数，所以

GAN训练可以用

一个博弈过

程来更好地

描述，而非优

化。

[3] 该博弈中

的对手是GAN所

包含的两个

网络。



回顾第

1章，当两个网

络达到纳什

均衡时GAN训练

结束，在纳什

均

衡点上，双

方都不能通

过改变策略

来改善自己

的情况。从数

学角度来



说

，发生在这样

的情况下——生

成器的可训

练参数 对应

的生成器的



代价函数 ( , )最

小化；同时，对

应该网络参

数

下的鉴别

器的代价函

数 ( ,

)也得到最

小化。[4]



图3.3说明

了二者零

和

博弈的建立

和达到纳什

均衡的过程

。



图3.3 玩家1（左）试

图通过调整

来最小化

。玩

家2（中间）试图

通过调整



来

（最大化 ）最小

化

。鞍形网格

（右）显示了参

数空间 中的

组合



损失。虚

线表示在鞍

形中心收敛

到纳什均衡



回到我们的

类比，对于我

们和可能在

路上遇到的

所有其他驾

驶员



来说，当

每一条回家

的路线所花

费的时间都

完全相同时

，纳什均衡将

会发生。任何

更快的路线

都会被交通

拥堵量的成

比例增长所

抵消，从

而减

缓了每个人

的速度。而这

种状态在现

实生活中几

乎是无法实

现



的，即便使

用像谷歌地

图这样提供

实时流量更

新的工具，也

不可能完

美

地评估出回

家的最佳路

径。



这同样适

用于训练GAN网

络时的高维

、非凸情况。即

使是像MNIST

数据

集中的那些

小到只有28×28像

素的灰度图

像，也有28×28=784



维。如

果它们被着

色（RGB），它们的维

数将增加到

3倍变成2352。在

训

练数据集中

的所有图像

上捕获这种

分布非常困

难，特别是当

最好的



学习

方法是从对

手（鉴别器）那

里学习时。

成

功地训练GAN需

要反复试验

，尽管有最优

方法，但它是

一门科学



的

同时也是一

门艺术。第5章

详细讨论了

GAN的收敛问题

。现在大可放

心，情况并没

有听起来那

么糟。正如在

第1章中预告

的那样，也正

如本

书将展

示的那样，无

论是近似生

成分布的巨

大复杂性，还

是对GAN收敛



条

件理解的缺

乏，都没有阻

碍GAN的实际可

用性和生成

真实数据样

本的

能力。



3.2 生

成器和鉴别

器

现在通过

引入更多的

表示概括所

学的内容。生

成器 接收随

机噪



声向量

并生成一个

伪样本

。数学

上来说， 。鉴别

器



的

输入要

么是真实样

本 ，要么是伪

样本 ；对于每

个输入，它输

出一个

介于

0和1之间的值

，表示输入是

真实样本的

概率。图 3.4用刚

才介绍



的术

语和符号描

述了GAN架构。

图

3.4 生成器网络

将随机向量

转换为伪样

本



：

。鉴别器网

络 对



输入样

本是否真实

进行分类并

输出。对于真

实样本

，鉴别

器力求输出

尽可能接近

1的值；对于伪

样本 ，鉴别器

力求输出尽

可能接近0的

值。相反，生成

器希望

尽可

能接近1，这表

明鉴别器被

欺骗，将伪样

本分类为真

实样本



3.2.1 对抗

的目标

鉴别

器的目标是

尽可能精确

。对于真实样

本 ， )力求尽可

能

接近1（正的

标签）；对于伪

样本 ， 力求尽

可能接近0（负

的标

签）。



生成

器的目标正

好相反，它试

图通过生成

与训练数据

集中的真实

数据别无二

致的伪样本

来欺骗鉴别

器。从数学角

度讲，即生成

器试

图生成

假样本 ，使得

尽可能接近

1。



3.2.2

混淆矩阵



鉴

别器的分类

可以用混淆

矩阵来表示

，混淆矩阵是

二元分类中

所

有可能结

果的表格表

示（表3.1）。鉴别器

的分类结果

如下：



（1）真阳性

（true positive）——真实样本正

确分类为真



；



（2）假阴性（false negative）——真实

样本错误分

类为假

；



（3）真阴

性（true negative）——伪样本正

确分类为假



；



（4）假阳性（false positive）——伪样

本错误分类

为真

。



表3.1 鉴别

器结果的混

淆矩阵

输入

鉴别器输出

接近1（真） 接近

0（假）

真



真阳性

假阴性

假阳

性 真阴性



假



使用混淆矩

阵的术语，鉴

别器试图最

大化真阳性

和真阴性分

类，



这等同于

最小化假阳

性和假阴性

分类。相反，生

成器的目标

是最大化

鉴

别器的假阳

性分类，这样

生成器才能

成功地欺骗

鉴别器，使其

相信



伪样本

是真的。生成

器不关心鉴

别器对真实

样本的分类

效果如何，只

关心对伪样

本的分类。

3.3 GAN训

练算法



回顾

一下第1章中

的GAN训练算法

，并使用本章

介绍的符号

将其规

范化

。与第1章中的

算法不同，这

里介绍的算

法使用小批

量（mini￾batch）而不是一

次使用一个

样本。



GAN训练算

法

对于每次

训练迭代，执

行



（1）训练鉴别

器。

a. 取随机的

小批量的真

实样本 。

b. 取随

机的小批量

的随机噪声

，并生成一小

批量伪样



本

：

。



c. 计算

和 的分

类损失，并反

向传播总误

差以



更新

来

最小化分类

损失。



（2）训练生

成器。

a. 取随机

的小批量的

随机噪声 生

成一小批量

伪样本：

。



b. 用鉴

别器网络对

进行分类。

c. 计

算 的分类损

失，并反向传

播总误差以

更新

来最大

化分类损失

。



结束

注意，在

步骤1中训练

鉴别器时，生

成器的参数

保持不变；同

样，



在步骤2中

，在训练生成

器时保持鉴

别器的参数

不变。之所以

只允许更

新

被训练网络

的权重和偏

置，是因为要

将所有更改

隔离到仅受

该网络



控制

的参数中。这

可以确保每

个网络都能

获得如何进

行更新的相

关信

号，而不

受其他网络

更新的干扰

。你可以把这

想象成两个

对手在轮流

比赛。



当然，你

还可以想象

这样一种场

景，如果每个

玩家只不过

是在撤

销对

方的进度，那

么即使是回

合制游戏，也

不能保证产

生有用的结

果。（前面有没

有说过GAN训练

起来非常棘

手？）第5章还将

讨论最大



限

度地提高成

功机会的技

术。

理论就是

这些，现在把

学到的付诸

实践，实现我

们的第一个

GAN



吧！

3.4 教程：生成

手写数字



本

节将实现一

个GAN，它将学习

生成外观逼

真的手写数

字，用的是

带

有TensorFlow后端的Python神

经网络库Keras。图

3.5显示了将实

现



的GAN的高级

架构。

本教程

中使用的大

部分代码，特

别是训练循

环中使用的

样板，都



是Erik Linder

Norén创

建的开源Github存

储库Keras-GAN改编而

来



的。存储库

还包括几个

高级的GAN变体

，其中一些将

在本书后面

介绍。

在代码

和网络架构

方面，我们对

其进行了很

大的修改和

简化并重命

名



了变量，使

它们与本书

中使用的表

示方法一致

。

Jupyter Notebook版的完整实

现，包括对训

练进度的可

视化，可



在配

套资源的第

3章文件夹中

找到。代码用

Python

3.6.0、Keras



2.1.6和TensorFlow 1.8.0版本测试

过。

图3.5 在训练

迭代过程中

，生成器学习

将输入的随

机噪声转换

为看起来像

训练数



据集

（MNIST手写数字数

据集）中的图

像；同时，鉴别

器学习区分

由生成器生

成的

伪图像

和来自训练

数据集的真

实图像



3.4.1 导入

模块并指定

模型输入维

度

首先导入

运行模型所

需的所有包

和库，如清单

3.1所示。注意：此

处还直接从

keras.datasets导入了MNIST手写

数字数据集

。



清单3.1

Import statements



%matplotlib

inline



import matplotlib.pyplot

as plt



import

numpy as np

from keras.datasets import mnist

from keras.layers import Dense,

Flatten, Reshape



from

keras.layers.advanced_activations import LeakyReLU

from keras.models import Sequential

from keras.optimizers import Adam

然后指

定模型和数

据集的输入

维度，如清单

3.2所示。MNIST中的



每

个图像都是

28×28像素的单通

道图像（灰度

图）。变量z_dim设置

了噪声向量

的大小。

清单

3.2 模型输入维

度



img_rows

= 28



img_cols

= 28



channels

= 1



img_shape

= (img_rows, img_cols,

channels) ←--- 输入图片

的维度

z_dim = 100 ←---

噪声

向量的大小

用作生成器

的输入



接下

来实现生成

器和鉴别器

网络。

3.4.2 构造生

成器



简而言

之，生成器是

一个只有一

个隐藏层的

神经网络。如

清单3.3

所示，生

成器以 为输

入，生成28×28×1的图

像。在隐藏层

中使用



LeakyReLU激活

函数。与将任

何负输入映

射到0的常规

ReLU函数不同，

LeakyReLU函

数允许存在

一个小的正

梯度，这样可

以防止梯度

在训练



过程

中消失，从而

产生更好的

训练效果。

在

输出层使用

tanh激活函数，它

将输出值缩

放到范围[–1, 1]。



之

所以使用tanh（与

sigmoid不同，sigmoid会输出

更为典型的

0到1范

围内的

值），是因为它

有助于生成

更清晰的图

像。



清单3.3 生成

器

def build_generator(img_shape, z_dim):

model = Sequential()

model.add(Dense(128, input_dim=z_dim)) ←--- 全连接层



model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激活函数

model.add(Dense(28 * 28 *

1, activation='tanh')) ←--- 带



tanh激活函数的

输出层



model.add(Reshape(img_shape)) ←---

生成

器的输出改

变为图像尺

寸



return

model



3.4.3 构造鉴别

器

鉴别器接

收28×28×1的图像，并

输出表示输

入是否被视

为真而不



是

假的概率。鉴

别器由一个

两层神经网

络表示，其隐

藏层有128个隐

藏

单元及激

活函数为LeakyReLU。



为

简单起见，我

们构造的鉴

别器网络看

起来与生成

器几乎相同

，

但并非必须

如此。实际上

，在大多数GAN的

实现中，生成

器和鉴别器

网



络体系结

构的大小和

复杂性都相

差很大。

注意

，与生成器不

同的是，清单

3.4中鉴别器的

输出层应用

了



sigmoid激活函数

。这确保了输

出值将介于

0和1之间，可以

将其解释

为

生成器将输

入认定为真

的概率。



清单

3.4 鉴别器

def build_discriminator(img_shape):



model

= Sequential()



model.add(Flatten(input_shape=img_shape))

←--- 输入

图像展



平

model.add(Dense(128)) ←--- 全

连接层

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激活

函数

model.add(Dense(1, activation='sigmoid')) ←--- 带sigmoid

激活

函数的输出

层



return model

3.4.4 搭建整个

模型



在清单

3.5中构建并编

译先前实现

的生成器模

型和鉴别器

模型。注

意：在

用于训练生

成器的组合

模型中，通过

将



discriminator.trainable设置为False来

固定鉴别器

参数。还要

注

意的是，组合

模型（其中鉴

别器设置为

不可训练）仅

用于训练生

成



器。鉴别器

将用单独编

译的模型训

练。（当回顾训

练循环时，这

一点

会变得

很明显。）



使用

二元交叉熵

作为在训练

中寻求最小

化的损失函

数。二元交叉

熵（binary

cross-entropy）用于度量

二分类预测

计算的概率

和实际



概率

之间的差异

；交叉熵损失

越大，预测离

真值就越远

。

优化每个网

络使用的是

Adam优化算法。该

算法名字源

于adaptive



moment estimation，这是一种

先进的基于

梯度下降的

优化算法，对



其工作原理

的阐释超出

了本书的范

围，但可以说

Adam凭借其通常

优异



的性能

已经成为大

多数GAN的首选

优化器。

清单

3.5 构建并编译

GAN



def

build_gan(generator, discriminator):



model

= Sequential()



model.add(generator)

←--- 生成器模型

和鉴别器模

型结合到一

起



model.add(discriminator)

return model



discriminator

= build_discriminator(img_shape) ←---

构建并编

译



鉴别器

discriminator.compile(loss='binary_crossentropy',



optimizer=Adam(),

metrics=['accuracy'])



generator =

build_generator(img_shape, z_dim)



←---

构

建生成器



discriminator.trainable =

False ←---



训

练生成器时

保持鉴别器

的参数固

定

gan = build_gan(generator,

discriminator)



←--- 构建并编译

鉴别器

固定

的GAN模型，以训

练生成器



gan.compile(loss='binary_crossentropy', optimizer=Adam())

3.4.5 训

练



清单3.6实现

了GAN训练算法

。首先，取随机

小批量的MNIST图

像为

真实样

本，从随机噪

声向量 中生

成小批量伪

样本，然后在

保持生成器

参数不变的

情况下，利用

这些伪样本

训练鉴别器

网络。其次，生

成一

小批伪

样本，使用这

些图像训练

生成器网络

，同时保持鉴

别器的参数

不变。算法在

每次迭代中

都重复这个

过程。



我们使

用独热编码

（one-hot-encoded）标签：1代表真

实图像，0

代表

伪图像。 从标

准正态分布

（平均值为0、标

准差为1的钟

形曲线）



中取

样得到。训练

鉴别器使得

假标签分配

给伪图像，真

标签分配给

真

图像。对生

成器进行训

练时，生成器

要使鉴别器

能将真实的

标签分配



给

它生成的伪

样本。

注意：训

练数据集中

的真实图像

被重新缩放

到了−1到1。如前

例



所示，生成

器在输出层

使用tanh激活函

数，因此伪样

本同样将在

范围

(−1，1)内。相应

地，就得将鉴

别器的所有

输入重新缩

放到同一范

围。



清单3.6

GAN训练

循环



losses =

[]



accuracies =

[]



iteration_checkpoints =

[]



def train(iterations,

batch_size, sample_interval):



(X_train,

_), (_, _)

= mnist.load_data() ←--- 加载MINST数



据集



X_train =

X_train /



127.5

- 1.0 ←---

灰度像

素值[0, 255]缩放



到

[−1,1]

X_train = np.expand_dims(X_train, axis=3)

real = np.ones((batch_size, 1))

←--- 真实图像的

标签都是1



fake

= np.zeros((batch_size, 1))

←--- 伪

图像的标签

都是0



for

iteration in range(iterations):

idx = np.random.randint(0, X_train.shape[0],

batch_size)



←--- 随机噪

声采样

imgs = X_train[idx]

z = np.random.normal(0, 1,

(batch_size, 100)) ←---

获取

随机的一批

真实图像



gen_imgs =

generator.predict(z)



d_loss_real =

discriminator.train_on_batch(imgs, real)



←---

图

像像素缩放

到[0,1]



d_loss_fake =

discriminator.train_on_batch(gen_imgs,



fake)

d_loss, accuracy = 0.5

* np.add(d_loss_real,



d_loss_fake)

z = np.random.normal(0, 1,

(batch_size, 100)) ←---

生成一批

伪图像



gen_imgs =

generator.predict(z)



g_loss =

gan.train_on_batch(z, real)



←---

训练

鉴别器



if (iteration

+ 1)



%

sample_interval == 0:

losses.append((d_loss, g_loss))



accuracies.append(100.0

* accuracy) ←---

生成

一



批伪图像

训练生成器

iteration_checkpoints.append(iteration

+ 1)



print("%d

[D loss: %f,

acc.: %.2f%%] [G loss:

%f]"



% ←---

输出训练过

程



(iteration +

1, d_loss,



100.0

* accuracy,



g_loss))

sample_images(generator) ←--- 输出生成

图像的采样

3.4.6

输出样本图

像



在生成器

训练代码中

，你可能注意

到调用了 sample_images()

函

数。该函数在

每次sample_interval迭代中

调用，并输出

由生成



器在

给定迭代中

合成的含有

4×4幅合成图像

的网格，如清

单3.7所示。

运行

模型后，你可

以使用这些

图像检查临

时和最终的

输出情况。



清

单3.7 显示合成

图像

def sample_images(generator, image_grid_rows=4,

image_grid_columns=4):



z =

np.random.normal(0, 1,



(image_grid_rows

*



image_grid_columns, z_dim))

←--- 样本随

机噪声



gen_imgs

= generator.predict(z) ←---

从随

机噪声生成

图像



gen_imgs =

0.5 *



gen_imgs

+ 0.5 ←---

将图像

像素值重缩

放至[0,



1]内

fig, axs = plt.subplots(image_grid_rows,

←--- 设置

图像网格



image_grid_columns,

figsize=(4, 4),



sharey=True,

sharex=True)



cnt =

0



for i

in range(image_grid_rows):



for

j in range(image_grid_columns):

axs[i, j].imshow(gen_imgs[cnt, :, :,

0],



cmap='gray') ←---

输

出一个图像

网格



axs[i, j].axis('off')

cnt += 1

3.4.7 运行模

型



这是最后

一步，如清单

3.8所示，设置训

练超参数——迭

代次数和

批

量大小，然后

训练模型。目

前没有一种

行之有效的

方法来确定

正确



的迭代

次数或正确

的批量大小

，只能观察训

练进度，通过

反复试验来

确定。

也就是

说，对这些数

有一些重要

的实际限制

：每个小批量

必须足



够小

，以适合内存

器处理（典型

使用的批量

大小是2的幂

：32、64、

128、256和512）。迭代次数

也有一个实

际的限制：拥

有的迭代次

数越



多，训练

过程花费的

时间就越长

。像GAN这样复杂

的深度学习

模型，即

使有

了强大的计

算能力，训练

时长也很容

易变得难以

控制。



为了确

定合适的迭

代次数，你需

要监控训练

损失，并在损

失达到

平稳

状态（这意味

着我们从进

一步的训练

中得到的改

进增量很少

，甚



至没有）的

次数附近设

置迭代次数

。（因为这是一

个生成模型

，像有

监督的

学习算法一

样，也需要担

心过拟合问

题。）



清单3.8 运行

模型

iterations = 20000 ←---

设置训

练超参数



batch_size =

128



sample_interval =

1000



train(iterations, batch_size,

sample_interval) ←---



训

练GAN直

到指定

迭代次数



3.4.8 检

查结果

经过

训练迭代后

由生成器生

成的样本图

像，按照时间

先后排列，



如

图3.6所示。可以

看到，生成器

起初只会产

生随机噪声

。在训练迭代

的过程中，它

越来越擅长

模拟训练数

据的特性，每

次鉴别器判

断生成

的图

像为假或判

断生成的图

像为真时，生

成器都会稍

有改进。生成

器



经过充分

训练后可以

合成的图像

样本，如图3.7所

示。

图3.6 起初看

上去不过是

随机噪声，生

成器逐渐学

习模拟训练

数据集的特

征——



本例中是

手写数字的

图像

为了进

行比较，我们

给出从MNIST数据

集中随机选

择的真实图

像样



本，如图

3.8所示。

图3.7 虽远

非完美，但简

单的双层生

成器学会了

生成逼真的

数字，如数字

9和1



图3.8

MNIST数据集

中用于训练

GAN的真实手写

数字样本。尽

管生成器在

模拟训练



数

据方面取得

了惊人的进

展，但它生成

的数字与真

实的由人类

书写的数字

之间的

区别

仍然很明显

3.5 结论

尽管GAN产

生的图像还

远不完美，但

是其中许多

图像很容易

被识别



为真

实的数字。考

虑到生成器

和鉴别器只

用了简单的

双层网络结

构，

这已经是

一个惊人的

成就了！我们

将在第4章介

绍如何在生

成器和鉴别

器中使用更

加复杂和强

大的神经网

络结构——卷积

神经网络，以

提高



生成图

像的质量。

3.6 小

结



（1）GAN是由两个

网络组成的

：生成器

和鉴

别器 。它们各

自有自己的

损失函数： (

, )和

( ,

)。



（2）在训练过程

中，生成器和

鉴别器只能

调整自己的

参数，即

和 。



（3）两

个网络通过

一个类似博

弈的动态过

程同时训练

：生成器试

图

最大化鉴别

器的假阳性

分类（将生成

的图像分类

为真图像），而

鉴



别器试图

最小化它的

假阳性和假

阴性分类。

[1] Generative Adversarial Networks,

Network, by Ian J.

Goodfellow et al., 2014.

[2] NIPS 2016 Tutorial:

Generative Adversarial Networks, by

Ian Goodfellow, 2016.

[3] Generative Adversarial Networks,

Network, by Ian J.

Goodfellow et al., 2014.

[4] 同

上。



第4章

深度

卷积生成对

抗网络



（DCGAN）

本章

主要内容



理

解卷积神经

网络背后的

关键概念

批

归一化的使

用



实现深度

卷积生成对

抗网络，一种

先进的GAN架构

我们在第3章

实现了一个

GAN，其生成器和

鉴别器是具

有单个隐藏



层的简单前

馈神经网络

。尽管很简单

，但GAN的生成器

充分训练后

得到



的手写

数字图像的

真实性有些

还是很具说

服力的。即使

是那些无法

被

识别为人

类手写数字

的字符，也具

有许多手写

符号的特征

，例如可辨



认

的线条边缘

和形状，特别

是与用作生

成器原始输

入的随机噪

声相

比，更是

如此。



想象一

下，如果使用

更强大的网

络架构可以

实现什么？本

章中的

生成

器和鉴别器

都将使用卷

积神经网络

（CNN，或ConvNet），而不再



是

简单的双层

前馈网络。这

种GAN架构称为

深度卷积生

成对抗网络

（Deep

Convolutional GAN，DCGAN）。



在深入探讨

DCGAN实现的细节

之前，我们先

在本章介绍

ConvNet的

关键概念

，回顾开发DCGAN背

后的历史，并

介绍使DCGAN这样

复杂的架



构

在实践中变

为可行的关

键性突破之

一：批归一化

（batch

normalization）。



4.1 卷积神经网

络

你应接触

过卷积网络

的相关知识

，如果不熟悉

，也不用担心

，因



为本节将

复习本章和

本书其余部

分需要了解

的所有关键

概念。

4.1.1 卷积滤

波器



常规前

馈神经网络

的神经元排

列在平面的

全连接层中

，而ConvNet

中的层排

列在三维（宽

×高×深）中。卷积

是通过在输

入层上滑动

一



个或多个

滤波器（filter）来执

行的。每个滤

波器都有一

个相对较小

的感受野（宽

×高），但它贯穿

输入图像的

全部深度。

每

个滤波器在

输入图像上

滑动每一步

，都会输出一

个激活值：它

是输入值和

过滤器值之

间的点积。此

过程将为每

个滤波器生

成一个二



维

的激活图（activation

map）。将

每个滤波器

生成的激活

图堆叠在



一

起可以形成

一个三维输

出层，其输出

深度等于所

用滤波器的

数量。

4.1.2 参数共

享



重要的是

，给定滤波器

参数被其所

有输入值共

享，这具有直

观和

实用的

优点。直观地

讲，参数共享

能够有效地

学习视觉特

征和形状



（如

线条和边缘

），无论它们在

输入图像中

位于何处。从

实际的角度

来看，参数共

享可以大大

减少可训练

参数的数量

。这降低了过

拟合的

风险

，并允许该技

术在不增加

可训练参数

的情况下扩

展到更高分

辨率



的图像

中，而在同样

情况下，传统

全连接网络

却要指数爆

炸一样增加

可训练参数

才可以做到

。

4.1.3 卷积神经网

络可视化



如

果这样解释

听起来有些

令人困惑，那

么通过可视

化这些概念

可

以使它们

不那么抽象

。图示能使大

多数人更容

易理解所有

内容。图4.1



展示

了单个卷积

操作，图4.2说明

了输入层和

输出层都是

卷积层情况

下

的卷积操

作。



图4.1描述了

二维输入上

单个滤波器

的卷积运算

。实际上，输入

图

像通常是

三维的而且

几个滤波器

堆叠在一起

使用。但基本

机制是不变

的：不管输入

体积的深度

如何，每个滤

波器每一步

产生一个值

。使用



的滤波

器数量决定

了输出图像

的深度，因为

它们生成的

激活图相互

叠

加，如图4.2所

示。



（来源: A

Guide to



Convolution

Arithmetic for Deep

Learning, by



Vincent

Dumoulin and Francesco

Visin, 2016.）



图4.1

一

个3×3的卷积滤

波器在一个

5×5的输入上滑

动——从左到右

，从上到



下。过

滤器滑动步

长为2，因此一

共滑动4次，得

到一个2×2的激

活图。注意，每

次滑动，整个

过滤器会生

成一个激活

值

（来源：Convolutional Neural Network, by

Nameer Hirschkind et al.,

Brilliant.org, retrieved November 1,

2018.）



图4.2 在

激活图（特征

图）、整体输入

和输出图像

中展示的单

次卷积步骤

的激活

值注

意：卷积滤波

器会贯穿输

入图像的整

个深度，输出

图像的深度

是通过激活

图



堆叠来确

定的。

注意



如

果想深入了

解卷积网络

及其基本概

念，建议你阅

读François

Chollet所著的Deep Learning with Python（曼

宁出版社，2017年

）

一书中的相

关章节，其中

提供了深度

学习中所有

关键概念和

技术优秀



而

详实的介绍

，包括ConvNet。如果你

对学术有更

高的要求，可

以参考

Andrej Karpathy在斯

坦福大学“视

觉识别卷积

神经网络”课

程中的精



彩

讲义。

4.2 DCGAN简史



DCGAN由

Alec

Radford、Luke Metz和Soumith Chintala于2016年

提出

，自问世以来

，便成了GAN领域

最重要的早

期创新之一

。[1] 这并



不是研

究人员第一

次在GAN中使用

ConvNet的尝试，却是

第一次成功

将

ConvNet直接整合

到完整的GAN模

型中。



ConvNet的使用

加剧了困扰

GAN训练的许多

困难，包括训

练不稳定

和

梯度饱和。的

确，这些挑战

是如此艰巨

，以至于有些

研究人员求

助



于其他方

法，如拉普拉

斯生成对抗

网络（LAPGAN）——它使用

拉普拉

斯金

字塔式的级

联卷积网络

，也就是说，在

每一层使用

GAN框架对单独

的卷积神经

网络进行训

练。[2] 由于被更

优越的方法

所取代，LAPGAN

在很

大程度上已

经被扔进了

历史的垃圾

筒，因此了解

它的内部原

理并



不重要

。

尽管LAPGAN笨拙复

杂且计算烦

琐，但在其发

布时仍提供

了当时质



量

最高的图像

，与原始GAN相比

改进了4倍（LAPGAN有

40%，原始GAN有

10%的生

成图像被人

工评估者误

认为是真实

的）。因此，LAPGAN展示

了



将GAN与ConvNet结合

的巨大潜力

。

在DCGAN中，Radford和他的

合作者引入

了一些技术

和优化方法

，



使ConvNet可以扩展

到完整的GAN框

架，而无须修

改底层的GAN架

构，也

不需要

将GAN简化为更

复杂的模型

框架的子结

构（如LAPGAN）。



Radford等人引

入的关键技

术之一就是

使用了批归

一化——通过归

一化

应用它

的每一层的

输入来帮助

稳定训练过

程。下面仔细

看看什么是

批



归一化以

及它又是怎

么起作用的

。

4.3 批归一化



批

归一化是由

谷歌科学家

Sergey

Ioffe和Christian Szegedy于



2015年提出

的。[3]

这一想法

既简单又具

有开创性。就

像对网络输

入



进行归一

化一样，他们

建议在每个

小批量训练

数据通过网

络时，对每

个

层的输入进

行归一化。



4.3.1 理

解归一化

本

节的内容有

助于提醒我

们什么是归

一化以及为

什么先要对

输入



特征值

进行归一化

。归一化（normalization）是数

据的缩放，使

它

具有零均

值和单位方

差。这是通过

取每个数据

点 减去平均

值µ，然后



除以

标准偏差得

到的，如式4.1所

示。

式4.1



归一化

有几个优点

。最重要的一

点或许是使

得具有巨大

尺度差异

的

特征之间的

比较变得更

容易，进而使

训练过程对

特征的尺度

不那么



敏感

。下面考虑一

个（虚构的）例

子，假设我们

尝试基于两

个特征来

预

测一个家庭

的每月支出

：家庭的年收

入和家庭成

员数。一般而

言，



一个家庭

的收入越多

，家庭成员越

多，支出就越

多。

但是这两

个特征的尺

度截然不同

：年收入增加

10美元可能不

会影



响一个

家庭的支出

，但增加10个成

员可能会严

重影响任何

一个家庭的

预算。归一化

通过将每个

特征值缩放

到一个标准

化的尺度上

解决了这

个

问题，这样一

来每个数据

点都不表示

为其实际值

，而是以一个

相对



的“分数

”表示给定数

据点与平均

值的标准偏

差。

批归一化

背后所体现

的理念是，在

处理具有多

层的深度神

经网络



时，仅

规范化输入

可能还远远

不够。当输入

值经过一层

又一层网络

时，它们将被

每一层中的

可训练参数

进行缩放。当

参数通过反

向传播

得到

调整时，每一

层输入的分

布在随后的

训练迭代中

都容易发生

变



化，从而影

响学习过程

的稳定性。在

学术界，这个

问题称为协

变量偏

移（covariate shift）。批

归一化通过

按每个小批

量的均值和

方差缩



放每

个小批量中

的值来解决

该问题。

4.3.2 计算

批归一化



批

归一化的计

算方式与之

前介绍的简

单归一化方

程在几个方

面有

所不同

。我们将在本

节一一进行

介绍。



令 为小

批量

的平均

值， 为小批量

的方差（均方

误差）。归

一化

值 的计算如

式4.2所示。



式4.2

增

加ε 项是为了

保持数值稳

定性，主要是

为了避免被

零除，一般



设

置为一较小

的正常数，例

如0.001。

在批归一

化中不直接

使用这些归

一化值，而是

将它们乘以

γ 并加



上β后，再

作为输入传

递到下一层

，如式4.3所示。

式

4.3



重要的是，γ 和

β

项是可训练

的参数，就像

权重和偏置

一样在



网络

训练期间进

行调整。这样

做有助于将

中间的输入

值标准化，使

其

均值在0附

近（但非0）。方差

也不是1。γ 和β 是

可训练的，因

此网

络可以

学习哪些值

最有效。



幸运

的是，我们不

必操心这些

。Keras中的函数

Keras.layers.BatchNormalization可

以处理所有

小批量计算

并在后台进

行更新。



批归

一化限制了

更新前一层

中的参数对

当前层接收

的输入分布

可

能的影响

。这减少了跨

层参数之间

不必要的相

互依赖，从而

有助于加



快

网络训练并

增强鲁棒性

，特别是在网

络参数初始

化方面。

批归

一化已被证

明对包括DCGAN在

内的许多深

度学习架构

是否可行



至

关重要，我们

将在4.4节看到

它的作用。

4.4 教

程：用DCGAN生成手

写数字



我们

将在本节回

顾第3章中的

生成MNIST手写数

字。这次将使

用

DCGAN架构，并将

生成器和鉴

别器都换成

卷积网络，如

图4.3所示。除



此

更改外，其余

网络结构保

持不变。在本

教程的最后

，我们将比较

两

个GAN（传统GAN与

DCGAN）生成的手写

数字的质量

，以展示更高

级的网



络结

构带来的改

进。

图4.3 本章教

程的总体模

型架构与第

3章中实现的

GAN相同。唯一的

区别（在此概

要图中不能

体现）是生成

器和鉴别器

网络的内部

表示形式，将

在本教程的

后面加

以详

细介绍



与第

3章一样，本教

程中的许多

代码均改编

自Erik Linder

Norén



在Github仓库Keras- GAN中

建立的开源

GAN模型，我们在

实现细节和

网

络架构方

面进行了大

量的修改和

改进。本书的

配套资源提

供了完整实

现的 Jupyter Notebook实现，包

括训练进度

的可视化等

信息。代码是



用Python 3.6.0、Keras 2.1.6和Tensor Flow

1.8.0版本测

试的。为



了加

快训练时间

，我们建议在

GPU上运行模型

。

4.4.1 导入模块并

指定模型输

入维度



首先

导入训练和

运行模型所

需的所有包

、模块以及库

。直接从

keras.datasets导入

MNIST手写数字数

据集，如清单

4.1所示。



清单4.1 导

入声明

%matplotlib inline



import

matplotlib.pyplot as plt

import numpy as np

from keras.datasets import mnist

from keras.layers import (

Activation, BatchNormalization, Dense, Dropout,

Flatten,



Reshape)

from keras.layers.advanced_activations import LeakyReLU

from keras.layers.convolutional import Conv2D,

Conv2DTranspose



from keras.models

import Sequential



from

keras.optimizers import Adam

指定

模型输入维

度：图像尺寸

和噪声向量

的长度，如清

单4.2所



示。

清单

4.2 模型输入维

度



img_rows

= 28



img_cols

= 28



channels

= 1



img_shape

= (img_rows, img_cols,

channels) ←--- 输入图像

的维度

z_dim = 100 ←---

用于

输入生成器

的噪声向量

的大小



4.4.2 构造

生成器

ConvNet传统

上用于图像

分类任务，图

像以尺寸——高

度×宽度



×彩色

通道数作为

输入，并通过

一系列卷积

层输出一个

维数为1 ×

的类

别得分向量

， 是类别标签

数。要使用ConvNet结

构生成图像

，则



是上述过

程的逆过程

：并非获取图

像再将其处

理为向量，而

是获取向

量

并调整其大

小以使之变

为图像。



这一

过程的关键

是转置卷积

（transposed convolution）。我们

通常使

用卷积减小

输入的宽度

和高度，同时

增加其深度

。转置卷积与

其相反，用于

增加宽度和

高度，同时减

小深度，如图

4.4的生成器网

络



图所示。

图

4.4 生成器将随

机噪声向量

作为输入并

生成28×28×1的图像

。这一过程通

过



多层转置

卷积实现，在

卷积层之间

应用批归一

化来稳定训

练过程（图像

未按比例

绘

制）



生成器从

噪声向量 开

始，使用一个

全连接层将

向量重塑为

具有

小的宽

×高和大的深

度的三维隐

藏层。使用转

置卷积对输

入进行逐步

重塑，以使其

宽×高增大而

深度减小，直

到具有想要

合成的图像

大小



28×28×1。

在每个

转置卷积层

之后，应用批

归一化和LeakyReLU激

活函数；



在最

后一层不应

用批归一化

，并且使用tanh激

活函数代替

ReLU。

综合所有步

骤如下。



（1）取一

个随机噪声

向量 ，通过全

连接层将其

重塑为7×7×256

张量

。



（2）使用转置卷

积，将7×7×256张量转

换为14×14×128张量。

（3）应

用批归一化

和LeakyReLU激活函数

。



（4）使用转置卷

积，将14×14×128张量转

换为14×14×64张

量。注

意：宽度和高

度尺寸保持

不变。可以通

过将



Conv2DTranspose中的stride参

数设置为1来

实现。

（5）应用批

归一化和LeakyReLU激

活函数。



（6）使用

转置卷积，将

14×14×64张量转换为

输出图像大

小

28×28×1。



（7）应用tanh激活

函数。

在Keras中实

现生成器网

络的代码如

清单4.3所示。



清

单4.3 DCGAN生成器

def build_generator(z_dim):



model

= Sequential()



model.add(Dense(256

* 7 *

7, input_dim=z_dim))←--- 通

过全连接

层

将输入重新

调整大小为

7×7×256的张量



model.add(Reshape((7, 7,

256)))



model.add(Conv2DTranspose(128, kernel_size=3,

strides=2,



padding='same')) ←---

转置

卷积层从大

小为7×7×256的张量

到14×14×128的



张量

model.add(BatchNormalization()) ←--- 批

归一化

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激活

model.add(Conv2DTranspose(64,

kernel_size=3, strides=1,



padding='same'))

←--- 转置卷积层

从大小为14×14×128的

张量到14×14×64



的张

量

model.add(BatchNormalization()) ←--- 批归一化

model.add(LeakyReLU(alpha=0.01))

←--- LeakyReLU激活函数



model.add(Conv2DTranspose(1,

kernel_size=3, strides=2,



padding='same'))

←--- 转

置卷积层从

大小为14×14×64的张

量到28×28×1的张



量



model.add(Activation('tanh')) ←--- 带tanh激活函数

的输出层

return model



4.4.3

构

造鉴别器



鉴

别器是一种

我们熟悉的

ConvNet，它接收图像

并输出预测

向量：

在这种

情况下，它是

一种二值分

类，表明输入

的图像是否

被认为是真

实的而不是

假的。图 4.5 所示

的是我们将

要实现的鉴

别器网络。

图

4.5 鉴别器将28×28×1图

像作为输入

经过多个卷

积层，使用sigmoid激

活函



数σ输出

/输入图像是

真实的概率

。在卷积层之

间应用批归

一化来稳定

训练过程

（图

像未按比例

绘制）



鉴别器

的输入是28×28×1的

图像。应用卷

积可以对图

像进行变

换

，使其宽×高逐

渐变小，深度

逐渐变深。在

所有卷积层

中使用



LeakyReLU激活

函数；批归一

化用于除第

一层以外的

所有卷积层

；输

出使用全

连接层和sigmoid激

活函数。



综合

所有步骤如

下。

（1）使用卷积

层将28×28×1的输入

图像转换为

14×14×32的张



量。

（2）应用

LeakyReLU激活函数。



（3）使

用卷积层将

14×14×32的张量转换

为7×7×64的张量。

（4）应

用批归一化

和LeakyReLU激活函数

。



（5）使用卷积层

将7×7×64的张量转

换为3×3×128的张量

。

（6）应用批归一

化和LeakyReLU激活函

数。



（7）将3×3×128张量展

成大小为3×3×128=1152的

向量。

（8）使用全

连接层，输入

sigmoid激活函数计

算输入图像

是否真



实的

概率。

用Keras实现

鉴别器，代码

如清单4.4所示

。



清单4.4 DCGAN鉴别器



def build_discriminator(img_shape):



model

= Sequential()



model.add(

Conv2D(32, ←--- 卷积层，从大

小为28 ×

28× 1的张量

到



14×14×32的张量

kernel_size=3,



strides=2,

input_shape=img_shape,



padding='same'))

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激

活函数

model.add( ←--- 卷积

层，从大小为

14×14×32的张量到7×7×64的

张量

Conv2D(64,



kernel_size=3,

strides=2,



input_shape=img_shape,

padding='same'))



model.add(BatchNormalization()) ←---

批归一

化



model.add(LeakyReLU(alpha=0.01)) ←---

LeakyReLU激活函数

model.add( ←--- 卷积层，从大

小为7×7×64的张量

到3×3×128的张量

Conv2D(128,



kernel_size=3,

strides=2,



input_shape=img_shape,

padding='same'))



model.add(BatchNormalization()) ←---

批

归一化



model.add(LeakyReLU(alpha=0.01)) ←---

LeakyReLU激活

函数



model.add(Flatten())

model.add(Dense(1, activation='sigmoid')) ←--- 带sigmoid激

活

函数的输出

层



return model

4.4.4 构建并运

行DCGAN



除了生成

器和鉴别器

的网络结构

，DCGAN的其他设置

和实现与第

3

章中简单GAN的

网络相同。这

体现了GAN架构

的通用性。构

建并编译



DCGAN的

代码如清单

4.5所示，对模型

进行训练的

代码如清单

4.6所示。

清单4.5 构

建并编译DCGAN



def

build_gan(generator, discriminator):



model

= Sequential()



model.add(generator)

←--- 生

成器和鉴别

器结合为一

个模型



model.add(discriminator)

return model



discriminator

= build_discriminator(img_shape) ←---

构建

并编译



鉴别

器

discriminator.compile(loss='binary_crossentropy',



optimizer=Adam(),

metrics=['accuracy'])



generator =

build_generator(z_dim) ←---



构建生成

器

discriminator.trainable = False ←---

生成器训

练时鉴别器

参数保持不

变



gan =

build_gan(generator, discriminator)



gan.compile(loss='binary_crossentropy',

optimizer=Adam()) ←---



构建并编

译鉴别器固

定的GAN模型来

训练生成器



清单4.6 训练DCGAN



losses

= []



accuracies

= []



iteration_checkpoints

= []



def

train(iterations, batch_size, sample_interval):

(X_train, _), (_, _)

= mnist.load_data() ←--- 加

载MNIST数

据集



X_train =

X_train /



127.5

- 1.0 ←---

灰

度像素值从

[0, 255]缩



放到[1,

1]



X_train =

np.expand_dims(X_train, axis=3)



real

= np.ones((batch_size, 1))

←--- 真实

图像标签为

1



fake

= np.zeros((batch_size, 1))

←--- 伪图像标签

为0



for

iteration in range(iterations):

idx = np.random.randint(0, X_train.shape[0],

batch_size)



←--- 获取一批

真实图像

imgs = X_train[idx]

z = np.random.normal(0, 1,

(batch_size, 100)) ←---

生

成一批伪图

像



gen_imgs =

generator.predict(z)



d_loss_real =

discriminator.train_on_batch(imgs, real)



←---

训练鉴别

器



d_loss_fake =

discriminator.train_on_batch(gen_imgs,



fake)

d_loss, accuracy = 0.5

* np.add(d_loss_real,



d_loss_fake)

z = np.random.normal(0, 1,

(batch_size, 100)) ←---

生成一批

伪图像



gen_imgs =

generator.predict(z)



g_loss =

gan.train_on_batch(z, real)



←---

训练

生成器



if (iteration

+ 1)



%

sample_interval == 0:

losses.append((d_loss, g_loss)) ←---

accuracies.append(100.0 * accuracy)

iteration_checkpoints.append(iteration + 1) ←--

- 保存

损失和准确

率以便训练

后绘图



print("%d

[D loss: %f,

acc.: %.2f%%] [G loss:

%f]"



% ←---

输出

训练过程



(iteration +

1, d_loss,



100.0

* accuracy,



g_loss))

sample_images(generator) ←--- 输

出生成图像

的采样

为完

整起见，清单

4.7包含了sample_images()函数

，它在指定的

训练迭代中

输出一个4×4的

图像网格。



清

单4.7

显示生成

图像



def sample_images(generator,

image_grid_rows=4,



image_grid_columns=4):

z = np.random.normal(0, 1,

(image_grid_rows *



image_grid_columns,

z_dim)) ←--- 随机噪

声采样

gen_imgs = generator.predict(z) ←---

从随

机噪声生成

图像



gen_imgs =

0.5 *



gen_imgs

+ 0.5 ←---

图像像

素缩放到[0,1]



fig, axs

= plt.subplots(image_grid_rows,



←---

设

置图像网格

image_grid_columns,



figsize=(4,

4),



sharey=True,

sharex=True)



cnt =

0



for i

in range(image_grid_rows):



for

j in range(image_grid_columns):

axs[i, j].imshow(gen_imgs[cnt, :, :,

0],



cmap='gray') ←---

输出一个图

像网格



axs[i, j].axis('off')

cnt += 1

接下

来，使用清单

4.8所示的代码

运行模型。



清

单4.8 运行模型



iterations = 20000 ←---

设置超参数

batch_size = 128

sample_interval = 1000

train(iterations, batch_size, sample_interval) ←---

训练DCGAN



直到指

定的迭代次

数

4.4.5 模型输出

充分训练后

的DCGAN的生成器

生成的手写

数字如图4.6所

示。为便

于同

时比较，图4.7显

示了第3章中

GAN生成的数字

样本，图4.8显示

了



MNIST数据集中

真实的手写

数字样本。

图

4.6 充分训练的

DCGAN生成的手写

数字



图4.7

第3章

中实现的GAN生

成的手写数

字



图4.8 从用于

训练DCGAN的MNIST数据

集中随机选

择的真实手

写数字。与第

3章中

简单GAN生

成的图像不

同，充分训练

的DCGAN生成的许

多手写数字

与训练数据

几乎



没有区

别

可以看出

，为实现DCGAN而做

的所有额外

工作都得到

了丰厚的回

报



——网络经过

充分训练后

产生的许多

手写数字图

和人手所写

的真实图

像

别无二致。



4.5 结

论

DCGAN展示了GAN框

架的通用性

。理论上来说

，鉴别器和生

成器可



以用

任何可微函

数表示，甚至

可以用多层

卷积网络这

样复杂的函

数表

示。但是

DCGAN也表明，要使

更复杂的实

现在实践中

真正起作用

，还存



在很大

的障碍。没有

批归一化等

突破性技术

，DCGAN将无法正确

训练。

我们将

在第5章探讨

使GAN训练变得

具有挑战性

的一些理论

和实践



方面

的局限性，以

及克服这些

局限性的方

法。

4.6 小结



（1）卷积

神经网络（ConvNet）使

用一个或多

个在输入图

像上滑

动的

卷积滤波器

。在输入图像

上滑动的每

一步，滤波器

都会使用一

组



参数来产

生一个激活

值。来自所有

滤波器的所

有激活值共

同生成输出

层。

（2）批归一化

是指在将每

一层的输出

作为输入传

递到下一层

之



前，对其进

行归一化，以

减小神经网

络中协变量

偏移（训练期

间各层

之间

输入值分布

的变化）。



（3）深度

卷积生成对

抗网络（DCGAN）以卷

积神经网络

为生成器

和

鉴别器。本章

的代码教程

中实现了这

种架构，它在

图像处理任

务



（如手写数

字生成）中实

现了优异的

性能。

[1] Unsupervised Representation Learning

with Deep



Convolutional

Generative Adversarial Networks,

by Alec



Radford

et al., 2015.

[2] Deep Generative Image

Models Using a Laplacian

Pyramid



of Adversarial

Networks, by



Emily

Denton et al.,

2015.



[3] Batch

Normalization: Accelerating



Deep

Network Training



by

Reducing Internal Covariate

Shift, by Sergey Ioffe

and



Christian Szegedy,

2015.



第二部

分 GAN的前沿主

题

第二部分

探讨了GAN中的

一些前沿主

题。以第一部

分的基本概

念为



基础，这

部分旨在加

深对GAN的理论

解释，并扩展

实现GAN的实用

工具

包。



第5章

涉及训练GAN的

诸多理论，并

介绍了实践

上的障碍以

及克服

这些

障碍的方法

。



第6章介绍一

种开创性的

训练方法——渐

进式增长

GAN（Progressive GAN），它

使GAN以前所未

有的分辨率

合成高质



量

图像。

第7章介

绍GAN在半监督

学习（只用一

小部分带标

签样本训练

分类



器的方

法）中的应用

，这在实践中

具有重要意

义。

第8章介绍

条件GAN（conditional GAN），这是一

种在训练生

成器



和鉴别

器时，使用标

签（或其他条

件信息）来引

导生成目标

数据

的技术

。



第9章探讨CycleGAN，这

是一种用于

图像到图像

转换的通用

技术，

可以将

一个图像（如

苹果）转换为

另一个图像

（如橙子）。



第5章

训练与普遍

挑战：为成功

而GAN

本章主要

内容



评估GAN时

遇到的挑战

最小-最大（Min-Max）GAN、非

饱和（Non-Saturating）GAN以及

沃

瑟斯坦（Wasserstein）GAN（即WGAN）



使

用要诀和技

巧实现最优

训练

注意



阅

读本章时请

记住，GAN难以训

练又难以评

估是众所周

知的。与其

他

任何前沿领

域一样，关于

什么是最优

方法的观点

也在不断变

化。



像“如何训

练你的DRAGAN”这样

的论文既证

明了机器学

习研究人

员

的恶搞能力

越来越强，也

体现了很好

地训练生成

对抗网络是

非常困



难的

。专注于改进

GAN 训练的arXiv论文

多达几十篇

，并且在顶级

学术

会议上

（包括NIPS[1]，著名的

机器学习会

议之一），针对

GAN训练的



各个

方面举办了

无数场研讨

会。

但是，GAN的训

练是一个不

断发展的挑

战，因此许多

资源（包括论

文和会议发

表的）现已需

要进行一定

程度的更新

。本章提供了

最全



面、最新

的训练技术

概述，其中有

很多涉及数

学理论的内

容，但是没

有

超出必要要

求。



作为本书

第二部分的

第1章，本章内

容相当丰富

。建议你尝试

一些

带有多

个参数的模

型后再回到

本章，那样不

仅对GAN每个部

分的功能有

了深刻的理

解，还切身体

验了训练它

们所面临的

挑战。



本章不

但教读者如

何去训练，而

且提供了至

少在未来几

年内都有

用

的参考。这里

总结了人们

的经验、博客

文章以及相

关论文中的

训练



技巧和

窍门。（如果你

以后不会选

择学术道路

，现在可以拿

出涂鸦笔

在

脚注上乱涂

乱画了。）我们

将本章视为

一个短暂的

学术中场休

息，



它将清晰

地描绘出现

在和未来GAN所

有令人惊叹

的发展。

我们

希望以一些

基本工具武

装你的头脑

，以帮助你理

解今后可能

出现的新论

文。在许多书

中，训练技巧

会以利弊清

单的形式出

现，这



样并不

能使你有全

面而高层次

的理解。由于

GAN是一个新兴

领域，学术

文

献尚未就某

些方面给出

结论，就更不

可能有简单

的技巧清单

。GAN领



域的发展

如此之快，我

们更希望授

人以渔而不

是授人以鱼

——授予你

找到

正确方法的

能力，而不是

简单提供很

快就过时的

信息。



解释完

本章目的后

，你需要再次

明确GAN所处的

位置。图5.1在第

2

章的图上进

行了扩展并

展示了模型

的分类，让你

可以了解到

有哪些其



他

生成技术以

及它们之间

的不同与相

似之处。

（来源

：Generative Adversarial Network (GAN),

by Ian Goodfellow,

NIPS 2016 tutorial.）

图5.1 GAN应置于何

处



图5.1有如下

两个关键要

点。

（1）所有这些

生成模型最

终都源自最

大似然（maximum



likelihood），至少

隐式地是这

样。 （2）第2章介绍

的变分自编

码器

位于树

的显式部分

。还记得有一

个明确的损

失函数（重建

损失）吗？



有了

GAN就没有这个

函数了，不过

现在有两个

相互竞争的

损失函数，稍

后我们将更

深入地讨论

。但这样系统

就没有了单

一的解析解

。

如果你了解

一些图中其

他技术，那就

太好了。图中

展示的关键

在



于训练正

在从显式和

易驾驭的方

法转向隐式

的方法。如果

没有显式的

损失函数（尽

管在3.2.1节中含

蓄地提到了

两种不同的

损失），如何去



评估GAN呢？如果

正在进行并

行的大规模

的实验，那又

该怎么办呢

？



为了消除可

能的混乱，我

们在此说明

图5.1中的技术

并非都来自

深

度学习，当

然你也不需

要了解除VAE和

GAN之外的技术

。



5.1 评估

回顾一

下第1章中伪

造达•芬奇画

作的类比。假

设一个伪造

者（生



成器）正

在试图模仿

达•芬奇，想使

这幅伪造的

画被展览接

收。伪造者

要

与艺术评论

家（鉴别器）竞

争，后者试图

只接收真正

的作品进入

展



览。如果你

是那位伪造

者，目的是伪

造这位伟大

艺术家的“遗

失的作

品”，以

对达•芬奇风

格的完美模

仿欺骗艺术

评论家，要如

何评价自己

的做得有多

好呢？



GAN试图解

决伪造者与

艺术评论家

之间永无止

境的竞争问

题。考虑

到生

成器通常比

鉴别器更受

关注，考虑它

的评估时应

该格外仔细

。但



是要如何

量化一个伟

大画家的风

格，或者说如

何模仿他呢

？以及如何

才

能量化生成

作品的整体

质量？



5.1.1 评估框

架

首选解决

方案是拥有

达•芬奇用他

的风格画出

的所有可能

的作



品，然后

看看用GAN生成

的图像会不

会在这个收

藏集中。可以

将此过程

视

为最大化最

大似然的非

近似版本。事

实上，我们已

经知道一个

图像



是否在

该集合中，因

此不涉及任

何可能性。这

种解决方案

在实际中是

永远不可能

实现的。

次优

的解决方案

是评估图像

并指出对应

要检查的地

方，然后合计

所有错误或

伪造的画的

数量。这样局

限性很大，而

且最终总是

需要人



类评

论家来审查

作品。从根本

上讲，这种解

决方案尽管

可能是次优



的，但也是不

可大规模使

用的。



要用一

种统计方法

来评估生成

样本的质量

，这样可以扩

大评估规

模

并可在实验

中使用。如果

没有一个易

于计算的度

量标准，也就

无法



监控进

展。想象一下

，循环中每次

超参数初始

化时，测量或

者反向传

播

都需要人为

调整——这对于

评估不同的

实验尤其是

一个问题。GAN对

超参数非常

敏感，从而让

这个问题更

为致命。因此

，如果没有统

计指



标会非

常困难，每次

要评估训练

质量时都必

须人为核对

。

那为什么不

能直接用已

经了解的方

法（如最大似

然）作为指标

呢？最大似然

是统计的方

法，可以度量

一些模糊的

期望，而且不

管怎



样都能

从中得到隐

式的结果。尽

管如此，最大

似然还是很

难使用，因

为

要对基础分

布及其可能

性进行正确

的估计，这可

能意味着要

处理数



十亿

图像。[2] 即使只

有一个好的

样本——我们从

训练集中获

得的有

效内

容，也有理由

想要得到超

越最大似然

的效果。



最大

似然还存在

什么问题呢

？它可是许多

机器学习研

究中固定使

用的指标。最

大似然具有

许多期望性

质，但正如上

文所说，将其

用于

GAN的评估

并不容易。



此

外，实际中，最

大似然近似

容易过度泛

化，因此生成

的样本由

于

太过多样化

而显得不真

实。[3] 使用最大

似然可能会

生成在现实

世



界中永远

不会出现的

样本，例如有

多个头的狗

或者一只长

着几十只眼



睛却没有身

体的长颈鹿

。因为不希望

GAN的“暴力生成

”给任何人带

来



噩梦，所以

应该使用损

失函数和/或

评估方法，淘

汰“过于泛化

”的样

本。



考虑

过度泛化的

另一种方法

是从伪数据

和真实数据

的概率分布

开

始，看看距

离函数（一种

测量真假图

像分布之间

距离的方法

）在概率



质量

为0的情况下

的作用。如果

这些样本之

间没有太大

的差异，那么

因

这些样本

过度泛化而

造成的额外

损失可能很

小，例如，除了

几个关键



问

题（如多个头

），这些模式都

接近真实数

据。根据真实

数据生成的

不应该有一

头牛有多个

头的样本，但

是一个过度

泛化的度量

标准允许

创

建这样的样

本。



这就是为

什么研究人

员认为需要

不同的评估

原则，即使我

们切实

在做

的事一直是

使可能性最

大化，只是以

不同的方式

对其进行衡

量而



已。稍后

讲到的KL散度

和JS散度也是

基于最大似

然的，因此这

里可以

将它

们视为可互

换的。



我们必

须评估样本

，但是又不能

简单地使用

最大似然。接

下来将

讨论

用于统计评

估生成样本

质量的两个

最常用且公

认的度量标

准：



Inception Score（IS）和Fréchet

Inception Distance（FID）。



这两个

指标的优点

在于，它们已

被广泛证实

与至少某些

期望性质（如



图像的视觉

吸引力或真

实感）高度相

关。IS完全是基

于“样本应该

是



可识别的

”这一理念设

计的，但也被

证明与人类

对真实图像

构成的直

觉

有关，这一点

已经过Amazon Mechanical Turk[4]的验

证。

5.1.2 IS



显然，我们

需要一种好

的统计评估

方法。让我们

从理想的评

估方

法所要

达到的高层

次要求开始

。



（1）生成的样本

要看起来像

真实的可分

辨的东西，如

桶或奶牛。

样

本不但要看

起来逼真，而

且要是数据

集中的物品

。此外，分类器

确



信它看到

的就是它识

别成的物品

。幸运的是，我

们已经有了

计算机视

觉

分类器，它能

够将图像分

类为某个特

定类别，并具

有一定的可

信



度。IS本身就

是以其中的

一个分类器

——以Inception网络命名

的。

（2）生成的样

本是多种多

样的，并且理

想情况下应

该包含原始

数



据集中表

示的所有类

别。这一点也

很重要，生成

的样本应该

是训练数

据

集的代表。如

果生成MNIST数据

集的GAN始终不

能生成数字

8，则说明



它不

是一个好的

生成模型。不

应该存在类

间模式崩溃

（interclass

mode collapse）[5]。



虽然我们可

能会对生成

模型还有更

多的要求，但

这是一个良

好的

开端。



IS最

初出现在2016年

的一篇论文

中，该论文对

IS进行了全面

的验

证，证实

它确实与人

类对高质量

样品构成的

直觉有关。[6] 此

后，这



个指标

在GAN研究界流

行起来。

我们

已经解释了

为什么要使

用这一指标

。现在深入了

解一下技术

细节，计算IS的

过程很简单

：



（1）采用真实分

布和生成分

布之间的Kullback-Leibler（KL）差



异。[7]



（2）对第1步的

结果求指数

。

举个例子：辅

助分类器生

成对抗网络

（Auxiliary Classifier



GAN，ACGAN）[8]

的失效模式

，我们试图从

ImageNet数据集中生

成雏



菊样本

。当在以下ACGAN失

效模式下运

行Inception网络时，会

看到图

5.2所示

的内容。你得

到的结果可

能会与此有

些差异，这取

决于操作系

统、TensorFlow版本和实

施细节。



（来源

：Odena,

2017, https://arxiv.org/pdf/1610.09585.pdf.）



图5.2

ACGAN的失效模

式，右边的分

数表示softmax的输

出



这里要注

意的重点是

，Inception分类器不确

定它在看什

么，尤其

是在

前3个类别中

。人们会觉得

它可能是一

朵花，但就连

我们也不确

定。对预测的

总体信心（指

数）也很低（分

数总和应为

1.00）。这是



一个IS较

低的例子，它

符合本节开

始的两个要

求。因此这一

探索指标

的

过程是成功

的，因为它符

合我们的直

觉。



5.1.3 FID

下一个要

解决的问题

是样本多样

性的缺乏。通

常，GAN只能学习

到



每个类别

中的一小部

分图像。2017年，有

人提出了一

个新的解决

方

案：Fréchet Inception Distance（FID）。[9] FID通过提

高对噪声

的

鲁棒性并检

测类内（intraclass）样本

遗漏来改进

IS。



这是很重要

的，如果接受

IS基准，那么仅

生成一种类

型的图像。

从

技术上来说

，这已经满足

了能生成此

类别的要求

。但是，假如想

创



建猫咪生

成算法，这实

际上并不是

我们想要的

（比如，有多个

品种的

猫的

样本）。此外，我

们还希望GAN可

以从不同角

度输出代表

猫的样



本，并

且通常是明

显不同的图

像。

我们同样

不希望GAN只是

简单地记住

图像。幸运的

是，这个问题

容



易检测——查

看像素空间

中图像之间

的距离即可

，如图 5.3

所示。



FID的

技术实现也

很复杂，但背

后的高级想

法是我们正

在寻找一个

样本

的生成

分布，使得为

了确保生成

分布与真实

分布相似而

必须进行的

修



改最小化

。

FID是通过Inception网络

运行图像来

计算的。在实

际应用中，我

们比较的是

中间表示（特

征图或层）而

不是最终输

出（换句话说

，是



嵌入它们

）。更具体地说

，计算嵌入均

值的距离、方

差和两个分

布

（真实分布

和生成分布

）的协方差。



（来

源：Do GAN

Actually Learn



the

Distribution? An Empirical

Study,by Sanjeev Arora and

Yi Zhang, 2017.）

图5.3 GAN主要通

过记忆样本

获取模式，这

也产生了不

良结果；表明

GAN并未学到



很

多有用的信

息，很可能不

会泛化。证据

就在图中：前

两排是重复

的样本；最后



一排是中间

那排在训练

集中最近邻

的样本。请注

意，由于GAN设置

的分辨率较

低，



显示这些

样本的分辨

率非常低

为

了从图像中

抽象出来，如

果我们有一

个包含一些

容易理解的

分



类器的域

，就可以使用

它们的预测

来衡量特定

样本看起来

是否真实。

总

而言之，FID是一

种从人类评

估者那里抽

象出来的方

法，它可以根

据



分布进行

统计推理，甚

至可以用于

诸如图像的

真实感这样

难以量化的

事物。

这一指

标实在是太

新了，因此我

们仍然有必

要拭目以待

，看看以



后的

论文会不会

发现它的缺

陷。但考虑到

已经有很多

知名的学者

开始

使用这

个指标，本章

便将其包括

在内了。[10]



5.2 训练

中的挑战

训

练GAN可能很复

杂，我们将在

本节介绍最

优方法，但仅

给出高级



的

、易于理解的

解释，而不会

深究那些证

明定理或数

学依据，因为

这

些细节超

出了本书的

范围。你可以

寻找参考资

料并自行尝

试，这些资



料

通常会提供

一些代码示

例来帮助入

门。

下面列举

了一些训练

中的主要问

题。



（1）模式崩溃

。在模式崩溃

中，某些模式

（如某些类）在

生成

的样本

中没有很好

地表示出来

。即使真实数

据分布中有

样本分布在

这



一部分，该

模式也崩溃

了。例如，MNIST数据

集没有生成

数字8。注

意，即

使网络已经

收敛，模式崩

溃也可能发

生。我们在解

释IS时已经



讨

论了类间模

式崩溃，在解

释FID时讨论了

类内模式崩

溃。

（2）收敛速度

慢。这是GAN在GAN和

无监督场景

下的一个大

问



题。在这种

情况下，收敛

速度和可用

的计算资源

是主要的限

制；而在

监督

学习中，可用

的标记数据

通常是首要

障碍。有些人

认为，未来的

人工智能竞

赛的决定因

素将会是计

算力，而不是

数据。此外，每

个人



都希望

不出几天的

训练就能快

速得到模型

。

（3）过度泛化。我

们特别讨论

一下不应该

得到支持（不

应该存



在）的

模式（潜在数

据样本），例如

，一头牛有多

个身体但只

有一个

头，或

者只有一个

身体但有多

个头。当GAN过度

泛化并学习

到基于真实

数据不应该

存在的事物

时，这种情况

就会发生。



注

意，模式崩溃

和过度泛化

有时可以通

过重新初始

化算法来简

单

地解决，但

这样的算法

是脆弱的。上

面列出的问

题大致提出

了两个关



键

指标：速度和

质量。即便是

两个指标，它

们也是相似

的，许多训练

最终都专注

于更快地消

除真实分布

和生成分布

之间的差距

。

那么该如何

解决呢？在GAN训

练方面，下列

几种技术可

用于改善训

练过程。



（1）增加

网络深度。

（2）更

改网络设置

。



原始论文提

出的最小-最

大（Min-Max）设计和停

止判则。

原始

论文提出的

非饱和（Non-Saturating）设计

和停止判则

[11]。



最近的改进

——沃瑟斯坦生

成对抗网络

（Wasserstein

GAN）。



（3）其他一些的

训练技巧。

归

一化输入。



梯

度惩罚。

多训

练鉴别器。



避

免稀疏梯度

。

使用平滑和

带噪声的标

签。



5.2.1 增加网络

深度

与许多

机器学习算

法一样，最简

单的使学习

更稳定的方

法是降低



复

杂性。如果可

以从简单的

算法开始并

逐步地增加

复杂性，则训

练过

程可以

更稳定，收敛

更快，并且还

有潜在的其

他好处（第6章

）。



我们可以使

用简单的生

成器和鉴别

器来快速实

现稳定性，然

后在

训练时

增加复杂性

，正如在最令

人兴奋的GAN论

文中所解释

的那样。



[12] 论文

中提到，NVIDIA的研

究者逐步扩

大这两个网

络，在每个训

练

周期结束

时将生成器

的输出大小

加倍，鉴别器

的输入也加

倍。我们从



两

个简单的网

络开始训练

，直到获得良

好的性能。

这

样可确保不

是从一个比

初始输入大

几个数量级

的巨大参数

空间



开始，而

是从生成一

个4像素×4像素

的图像开始

，在将输出大

小加倍

之前

操控这个参

数空间。重复

此操作，直到

获得大小为

1024像素



×1024像素的

图像。

看看效

果多么令人

印象深刻——图

5.4中的两幅图

都是生成的

。现



在，我们已

经超越了自

编码器生成

的64像素×64像素

的模糊图像

。

（来源：Karras et al., 2017,

https://arxiv.org/abs/1710.10196.）



图5.4 GAN生成

的全高清图

像，可以把这

当作第6章的

预告

这种方

法具有以下

优点：稳定、训

练速度快，最

重要的是生

成样



本的质

量好、尺寸大

。我们希望越

来越多的论

文可以使用

这种新的范

例。在实验中

一定要用这

种方法的原

因还包括这

种技术几乎

可以应用

于

任何类型的

GAN。



5.2.2 游戏设置

思

考GAN的双方博

弈本质的一

种方法是，想

象正在玩围

棋游戏或其

他可能在任

何时候结束

的棋盘游戏

，比如国际象

棋（实际上，这

是借



鉴了DeepMind团

队创造AlphaGo的方

法，并将其分

为策略网络

和价值网

络

）。作为一名玩

家，你不仅需

要了解游戏

的目的和两

个玩家都想

达



成的目标

，还需要了解

你离胜利有

多近。因此，要

有规则并且

有距离

（胜利

）指标，如丢失

的棋子数量

。



但正如并非

每一个棋盘

游戏的胜利

指标都适用

于其他游戏

一样，

某些GAN胜

利指标——距离

或散度——往往

用于特定的

游戏设置。我

们



有必要分

别研究每个

损失函数（胜

利指标）和玩

家动态（游戏

设

置）。



这里引

入一些描述

GAN问题的数学

表示，这些方

程式很重要

，但不

会用到

任何不必要

的复杂数学

。之所以介绍

它们，是想给

你提供一个

高层次的解

释，并提供一

些工具去理

解许多 GAN 的研

究人员似乎

仍然

无法区

分的东西。（好

吧，也许他们

应该在头脑

中也训练一

个鉴别



器。）

5.2.3 最

小-最大GAN



正如

在本书前面

所解释的那

样，我们可以

从游戏理论

的角度思考



GAN的设置，这种

假设下有两

个玩家都在

试图超越对

手。2014年的原始

论文也提到

游戏有两个

版本。原则上

，更易理解且

理论上更有

根据的



方法

正是现在所

描述的：仅将

GAN问题视为一

个最小-最大

（min￾max）博弈。式5.1描述

了鉴别器的

损失函数。

式

5.1



s代表对 （真实

数据分布）或

（潜在空间）的

期望，

代表鉴

别器的函数

（将图像映射

到概率）， 代表

生成器的函

数（将潜在向

量映射到图

像）。任何二元

分类问题都

应该熟悉这

第一个方程

。如果

给一定

的自由并摆

脱复杂性，则

可以把这个

方程改写为

这说明鉴别

器正在尝试

最大程度地

减少将真实

样本误认为

是伪样



本（第

一部分）或将

伪样本误认

为是真实样

本（第二部分

）的可能

性。



现

在我们将注

意力转向式

5.2中生成器的

损失函数。

式

5.2



因为只有两

方起作用且

它们彼此竞

争，所以有理

由认为生成

器的

损失对

鉴别器来说

是负损失。



将

它们放在一

起：有两个损

失函数，而且

一个是另一

个的负值。

这

样对抗性就

很明显了，生

成器试图比

鉴别器更聪

明。至于鉴别

器，



请记住它

是一个二元

分类器，只输

出一个数字

（而不是两类

），因此

它会因

其可信度或

缺乏可信度

而受到惩罚

。剩下的只是

一些花哨的

数



学运算，这

些运算证明

了一些很好

的性质，例如

JS散度的渐近

一致

性。



前面

已经解释了

通常不用最

大似然的原

因。我们使用

如KL散度和

JS散

度以及最近

的推土机距

离（也称为Wasserstein距

离）来代替。所

有这些散度

均有助于理

解真实分布

与生成分布

之间的差异

。JS散度度



量了

两个概率分

布的相似度

，它是基于KL散

度的变体，解

决了KL散度

非

对称的问题

。一般来说，JS散

度是对称的

。



定义

JS散度（JSD）是

KL散度的对称

版本。若 ，则



有

。

KL散度和JS散度

通常被视为

GAN最终在试图

最小化的东

西。这两种



都

是距离指标

，有助于理解

高维空间中

两种分布的

差异。一些精

巧的

证明将

这些散度与

GAN的min-max版本联系

起来了，但是

对于本书而

言，这些问题

太学术化了

。如果你没有

理解这段话

，也不要担心

，这



只是统计

学家的事情

。

最小-最大GAN（MM-GAN）用

于给出良好

的理论解释

，除此之外通

常不在实际

中使用。它是

理解GAN的一个

简洁的理论

框架：既是一

个博



弈论的

概念（源于两

个网络/玩家

之间的竞争

本质），又是一

个信息论

的

概念。除此之

外，MM-GAN通常没有

任何优势，接

下来的两种

结构更



为典

型。

5.2.4 非饱和GAN



在

实际应用中

，我们经常发

现MM-GAN会带来很

多问题，例如

鉴别

器收敛

缓慢。GAN的原始

论文提出了

一种替代方

法：非饱和GAN（Non￾Saturating GAN，NS-GAN）。在

这一版本中

，没有让两个

损失函数成

为彼此的直

接竞争对手

，而是使两个

损失函数相

互独立，如式

5.3所

示，但在方

向上与原始

公式（式5.2）一致

。



同样让我们

专注于一个

一般性的解

释：这两个损

失函数不再

直接

相互抵

消。但是在式

5.3中，可以看到

生成器正在

试图最小化

方程式



5.4中鉴

别器第二项

的相反项，它

试图让它所

生成的样本

不被发现（是

假的）。

式5.3



式5.4

从

直观上看，鉴

别器与之前

完全相同——式

5.1和式5.4相同，但

是式5.2的等价

形式已经变

了。使用NS-GAN的主

要原因是在

MM-GAN的情



况下，梯

度很容易饱

和到接近0，这

种情况下，反

向传播的权

重更新为

0或

很小，从而导

致收敛缓慢

。也许图示能

更清晰地展

示这一点（图

5.5）。



（来源:

Understanding Generative Adversarial

Networks,by Daniel



Seita,

2017.）



图5.5 这些

假设的关系

在理论上应

该是什么样

子的。

轴是生

成器的损失

函



数，而 是鉴

别器对生成

样本可能性

的“猜测”。可以

看到，

Minimax（MM）保持平

坦状态的时

间过长，给生

成器的信息

太少——梯度消

失了



可以看

到在0.0附近，最

大似然和MM-GAN的

梯度都接近

于0，这是

很多

早期训练发

生的地方；而

NS-GAN在0.0附近的梯

度要高得多

，所以



训练在

一开始就进

行得更快。

对

NS变体为什么

会收敛到纳

什均衡，没有

很好的理论

解释。实际



上

，由于NS-GAN是启发

性的，因此使

用这种形式

不再提供过

去获得的

简

洁的数学保

证，如图5.6所示

。由于GAN问题的

复杂性，即使

用NS￾GAN训练，也有

可能完全不

收敛，尽管经

验证明它表

现得比MM-GAN更



好

。

图5.6 请默哀



但

是这种可怕

的牺牲带来

了性能的显

著提升。NS方法

的优点不但



在于初始训

练更快，而且

由于生成器

学习得更快

，鉴别器也学

习得更



快。这

正是我们所

期待的，（几乎

）所有人在计

算和时间上

的预算都

很

紧，当然学习

得越快越好

。有人认为，在

使用固定的

计算力时，NS￾GAN仍

没有被超越

，甚至Wasserstein GAN也不能

说是一个比

它更好的



架

构。[13]

5.2.5 何时停止

训练



严格地

说，NS-GAN不再与JS散

度渐近一致

，且具有理论

上更加难

以

解释的平衡

状态。



第一点

很重要，因为

JS散度是一个

有意义的工

具，它可以解

释为

什么隐

式生成分布

应该完全收

敛到真实分

布，并从原则

上给出了停

止



训练的标

准。但是在实

际中，这几乎

毫无意义，因

为永远无法

验证真

实分

布和生成分

布何时收敛

。人们一般通

过每隔几次

迭代查看生

成的



样本来

决定何时停

止。最近，有些

人开始考虑

通过FID、IS或不太

流行

的分段

Wasserstein距离来定义

停止标准。



第

二点也很重

要，因为不稳

定显然会导

致训练出现

问题。一个更

重要的问题

是知道何时

停止。GAN问题的

两个原始公

式从来没有

给出在

实际

中完成训练

的明确条件

。原则上总是

说一旦达到

纳什均衡训

练就



完成了

，但实践中这

又很难验证

，因为高维性

使得均衡难

以证明。

如果

绘制生成器

和鉴别器的

损失函数，它

们通常会随

处乱跳。这



很

容易解释，因

为它们互相

竞争，如果一

个变得更好

，另一个损失

就

会更大。因

此，仅通过观

察两个损失

函数还不能

知道何时真

正完成了



训

练。

NS-GAN的拥护者

们声称，NS-GAN仍然

比Wasserstein GAN快得多。



因

此，NS-GAN或许可以

通过更快地

运行来克服

这些限制。

5.2.6 WGAN



最

近，GAN训练的新

发展迅速在

学术界流行

起来：Wasserstein

GAN（WGAN）。[14] 现在几

乎所有主要

学术论文和

从业人员都

会提到



它。归

根结底，WGAN之所

以重要，有以

下3个原因。

（1）它

显著改进了

损失函数，使

得损失函数

现在可以解

释并提供



了

更清晰的停

止标准。

（2）根据

经验，WGAN往往可

以得到更好

的结果。



（3）与许

多对GAN的研究

不同，WGAN从损失

开始就有明

确的理论

支

持，还表明我

们试图估计

的KL散度在理

论上和实践

上最终都是

不合



理的，并

在此基础上

提出了一种

较好的损失

函数来解决

这一问题。

第

一点的重要

性在5.2.5节中已

经相当明显

。由于生成器

和鉴别器



之

间的竞争性

质，没有一个

明确的停止

训练的时间

点。WGAN使用推土

机距离（earth

mover’s distance）作为

损失函数，该

函数与生成

样本的视觉

质量明显相

关。第二点和

第三点的好

处是显而易

见的——

我们当

然希望拥有

更高质量的

样本和更好

的理论基础

。



这个魔法是

怎么实现的

？让我们先来

详细看看鉴

别器或者说

批评

家（critic）的Wasserstein损

失，如式5.5所示

。



式5.5

该方程式

与之前看到

的类似（作为

方程式5.1的高

级简化），但有

一些重要的

区别。公式中

有函数 ，它充

当鉴别器。鉴

别器试图估

计

推土机距

离，并在 函数

的不同（有效

）参数下，寻求

真实分布（第

一项）与生成

分布（第二项

）之间的最大

差异。现在只

是简单地测

量

差异。鉴别

器试图让生

成器的处境

变得最困难

——通过查看在

共享空



间中

使用 的不同

投影，来最大

化生成器必

须移动的概

率量。

式5.6展示

了生成器，它

现在必须包

括推土机距

离。



式5.6

在此公

式中，我们试

图最小化真

实分布的期

望与生成分

布的期望



之

间的距离。介

绍WGAN的论文很

复杂，但它的

要点是 是满

足技术约

束

的函数。



注意

满足的技术

约束为1-Lipschitz：对于

所有

， ：



。

生成器

试图解决的

问题与之前

类似，在这里

更详细地介

绍一下：



（1）从真

实分布 或生

成分布［

，其中

～



( )］中

提取 ；



（2）生成

样本是从

（潜

在空间）中采

样，通过 进行

变换以在



同

一空间中获

得样本

，然后

使用 进行评

估；



（3）试图最小

化损失函数

或距离函数

，本例中是推

土机距离。实



际的数是用

推土机距离

计算出来的

，我们稍后会

加以解释。



设

置也很好，因

为有一个更

容易理解的

损失（例如，没

有对

数）。我们

还有更多可

调的训练，因

为在WGAN中必须

设置一个裁

剪常



数（clipping constant），其作

用类似于标

准机器学习

中的学习率

。

这为我们提

供了一个额

外的参数来

调参，但是如

果GAN架构对它

非常敏



感的

话，就可能是

一把双刃剑

。在不深入研

究数学的情

况下，WGAN有

如下

两个实际意

义。



（1）有更清晰

的停止标准

，因为该GAN已被

后来许多论

文所验

证，它

们显示了鉴

别器损失与

感知质量之

间的相关性

。可以简单地

测



量Wasserstein距离，这

有助于告知

何时停止训

练。

（2）可以训练

WGAN直至收敛。这

是相关的，因

为有meta-review



论文[15]表

明，使用JS损失

和真实分布

中生成器之

间的差异来

衡量训

练进

度通常是没

有意义的。[16] 换

言之，在国际

象棋中有时

需要输掉



几

个回合，暂时

表现变差，以

便在几次迭

代中学习并

最终做得更

好。

这听起来

像魔术，部分

是因为WGAN使用

的距离指标

与迄今为止

遇



到的任何

指标都不同

。这个距离指

标被称为推

土机距离或

Wasserstein距离，其背后

的想法很聪

明。这一次不

会再用数学

来折

磨你了

，让我们来谈

谈这个想法

。



有两种高维

分布：真实的

数据分布（我

们从未完全

看到）和来自

生成器的样

本分布（假的

）。试想一下，即

使是32×32

RGB（×3×256像素值

）图像的样本

空间会有多

巨大。现在把

这两个分



布

的概率质量

都想象成两

组山丘。我们

将在第10章对

此进行更详

细的

讨论。图

5.7可以作为参

考，但基于与

第2章相同的

思想。



图5.7 图（a）与

第2章中的类

似。为了更加

清楚，图（b）提供

了从相同分

布中

得出数

据的高斯分

布的另一个

视图，在顶部

仅显示第一

个分布的切

片，在右侧仅

显示第二个

分布的切片

。图（a）是该数据

的概率密度

抽象，其中 轴

表示该点被

采样的概率

。即使其中一

个只是另一

个的抽象，如

何比较两者

？即使我们告

诉你

（如何比

较），你如何确

保它们是一

样的？如果这

一分布具有

3072个可能的维

度



怎么办？而

在这个例子

中，仅只有两

个维度而已

！我们正在建

立如何比较

如图

（b）中两个

像沙堆一样

的分布的方

法，但随着分

布变得越来

越复杂，正确

匹配也



越来

越困难

想象

一下，我们必

须把代表概

率质量的所

有土从假分

布中移走，



以

使它看起来

与真实分布

完全相同，或

者至少与我

们所看到的

类似。

就好比

你的邻居有

一个超酷的

沙堡，而你有

很多沙子，并

试图做出完

全一样的沙

堡。需要花费

多少工夫才

能做得惟妙

惟肖？嘿，没关

系，



我们都经

历过这样的

事，有时候你

只是希望自

己的沙堡能

更酷更闪亮



一点。



使用Wasserstein距

离的近似形

式，我们可以

评估离生成

看起来像

来

自真实分布

的样本有多

近。为什么是

近似？因为从

来没有看到

过真



实的数

据分布，所以

很难计算出

确切的推土

机距离。

推土

机距离具有

比JS散度或KL散

度更好的性

能，并且已经

在WGAN



的基础上

有了重要的

贡献，同时也

验证了它的

卓越性能。[17] 尽

管在

某些情

况下，WGAN并没有

完全胜过其

他所有GAN，但它

至少在任何

情况



下都表

现得一样好

（应该指出，有

些人可能不

同意这种解

释）。

总的来说

，WGAN（或其梯度惩

罚版本，WGAN-GP）得到

了广泛的



使

用，并已经成

为GAN的研究和

实际应用中

的行业标准

——尽管NS-GAN

不应那

么快被遗忘

。如果你看到

一篇新论文

没有将WGAN作为

比较的基



准

之一并且没

有充分理由

时，那就要当

心了！

5.3 总结游

戏设置



我们

已经介绍了

GAN结构的3个核

心版本：最小

-最大GAN、非饱和



GAN和WGAN。每篇论文

的开头都会

提到其中一

个版本，你至

少应该知道

论文是使用

原始的版本

（更容易解释

，但在实践中

效果不佳），还

是



非饱和版

本（失去了很

多数学上的

保证，但效果

要好得多），还

是更

新的Wasserstein版

本（既具有理

论基础，又具

有出色的性

能）。



表5.1列出了

本书用到的

NS-GAN、WGAN甚至改进的

WGAN-GP的公

式。为完

整起见，我们

将WGAN-GP也列入表

中，因为这3个

都是学术和

行业的首选

。



表5.1

损失函数

总结a



名

称



公

式 注

释



名

称

公 式 注

释



NS-GAN

这

是原始公式

之



一，除非作

为基

础模块

或比较，



通常

不在实践中

使用。这是一

个

和上文介

绍的



NS-GAN等价的

公式，只是没

有

常数，它们

实际



上是等

价的b

WGAN



这是有

着简化损

失

的WGAN，它



似乎为

GAN创造

了一个

新的范



例，上

文把这个

方

程更详细地

解



释为方程

5.5

名



称

公 式 注

释

WGAN￾GP



c

这是具有

梯度惩



罚（GP）GAN的

例子。WGAN￾GP通常有

最好

的结果

。在本章



中还

没有详细讨

论WGAN-GP；为

了完整

起见，我



们将

其包含在这

里

a. 来源：Collection of Generative

Models in TensorFlow,

by Hwalsuk Lee.

b. 我们

倾向于在书

面代码中使

用常数，而在

论文中使用

更简洁的



数

学公式。

c. 这是

一个带有梯

度惩罚的WGAN版

本，通常在新

的学术论文

中使



用（Gulrajani

et al., 2017.）。

5.4 训练

技巧



我们现

在要将注意

力从有充分

根据的学术

成果转向学

者或从业人



员刚刚“摸索

出来”的领域

。这些仅仅是

技巧，通常只

需要尝试一

下，看看它们

是否对你有

用。本节中的

技巧列表受

Soumith Chintala

在2016年发布的

帖子“How to Train a

GAN: Tips and Tricks

to



Make GAN

Work”的启发

，但此后发生

了一些变化

。



发生变化的

一个例子是

一些架构上

的建议，例如

DCGAN是一切的基

准。目前大多

数人都是从

WGAN开始的；将来

，自注意力（Self￾Attention）GAN（第

12章）可能会成

为焦点。此外

，有些事情仍

然是

正确且

公认的，例如

使用Adam优化器

而不是随机

梯度下降。[18] 我

们



鼓励你查

看上文提到

的帖子，因为

它的创建是

GAN历史上的重

要时刻。

5.4.1 输入

的归一化



根

据几乎所有

机器学习资

源，包括Chintala的清

单，将图像归

一

化在–1和1之

间通常情况

下是一个好

主意。之所以

进行归一化

操作，



是因为

计算更容易

处理，机器学

习的其余情

况也是如此

。考虑到对输

入的这种限

制，最好使用

tanh激活函数来

限制生成器

的最终输出

。

5.4.2 批归一化



我

们就批归一

化在第4章中

进行了详细

讨论，为完整

起见，故将其



包括在此。对

批归一化的

看法变化为

：最初批归一

化被认为是

一种非



常成

功的技术；但

最近研究表

明，它有时会

产生不好的

结果，特别是

在生成器中

，但在鉴别器

中，大多对提

升结果有帮

助。[19]

5.4.3 梯度惩罚

此训练技巧

基于Chintala列表中

的第10点，根据

直觉，如果梯

度

的范数过

高，就会出现

问题。即使在

今天，如第12章

中所述，BigGAN



之类

的网络也在

这一领域进

行创新。[20]

但技

术问题仍然

存在，简单的

加权裁剪可

能会产生其

他深度学习

中已知的梯

度消失或爆

炸问题。我们

可以限制鉴

别器输出相

对于其输



入

的梯度范数

。换言之，如果

稍微改变输

入内容，更新

后的权重也

不

应该会有

太大变化。深

度学习充满

了这样的魔

法。这在WGAN结构

中尤



其重要

，也可以应用

在其他地方

。[21] 许多论文都

以某种形式

使用了

这一

技巧。[22]



在这里

，我们可以简

单地使用你

喜欢的深度

学习框架的

原生实现

来

惩罚梯度，而

不必关注过

多的实现细

节。更聪明的

方法最近已

经由



研究人

员发表并在

ICML 2018上发布，但尚

未得到广泛

的学术认可

。

[23] 为了使GAN更稳

定，人们正在

进行大量研

究，例如Jacobian



clamping，这也

是有待于在

新的研究中

复现的——所以

需要等待，看



看有哪些方

法会成功。



5.4.4 对

鉴别器进行

更多的训练



最近，对鉴别

器进行更多

的训练是一

种成功的方

法。在Chintala



的原始

列表中，这种

方法被标记

为效果不确

定，因此请谨

慎使用。这

里

主要有两种

方法：



（1）在生成

器有机会生

成任何样本

之前对鉴别

器进行预训

练；

（2）每个训练

周期更多次

地更新鉴别

器，通常，鉴别

器权重更新

5次，生成器才

更新1次。



用深

度学习研究

员兼教师Jeremy

Howard的

话说，之所以

对鉴别器



进

行更多的训

练有用，是因

为这是“外行

指导外行”，这

首先需要你

不断地注入

关于真实数

据的信息。

5.4.5 避

免稀疏梯度

从直觉上讲

，稀疏梯度（如

ReLU或MaxPool生成的梯

度）会增加训

练难度是有

道理的。原因

如下。

（1）直觉，尤

其是平均池

化，这样说可

能会令人困

惑，但请这样

思考：如果使

用标准的最

大池化，那么

将会失去除

了卷积的感

受野中



的最

大值以外的

所有值，这使

得在DCGAN的情况

下使用转置

卷积来恢

复

信息变得更

加困难。使用

平均池化至

少可以知道

平均值是多

少，但



它仍然

不是完美——我

们仍在丢失

信息，但至少

比以前少了

，因为平

均值

比简单的最

大值更具代

表性。



（2）如果使

用ReLU激活，则会

导致另一个

问题——信息损

失。解

决此问

题的一种方

法是应用此

操作时考虑

丢失了多少

信息，因为稍

后



可能需要

恢复它。回想

一下，ReLU( )只是max(0,

)，这

意味着对于

所有负值来

说所有信息

都会永远丢

失。如果能确

保把负数区

域的信息



留

到以后处理

并标记这些

信息是不同

的，就可以保

留所有这些

信息。

幸运的

是，对于这两

种问题，都有

简单的解决

方案：可以使

用



LeakyReLU激活函数

（例如对于 而

言是0.1

，对于 而

言是



），平均池

化也可以解

决很多这些

问题。还有其

他激活函数

（例如

sigmoid、ELU和tanh），但是

人们最常用

的是LeakyReLU激活函

数。



注意

LeakyReLU函数

的值可以是

任何实数，通

常为 。



总的来

说，我们试图

最小化信息

损失，并使信

息流尽可能

地合乎

逻辑

，而不是要求

GAN以某种奇怪

的方式反向

传播错误，在

这种情况



下

，它还必须学

习映射。

5.4.6 平滑

和带噪声的

标签



研究人

员使用多种

方法来给标

签添加噪声

或使其平滑

。Ian

Goodfellow推荐使用单

边标签平滑

（例如，以0和0.9作

为二元标



签

），但一般来说

，增加噪声或

裁剪似乎是

个好主意。

5.5 小

结



（1）通过学习

本章内容，你

应能了解“评

估对于生成

模型而言是



一个如此困

难的主题”的

原因，以及能

够在有明确

停止标准的

情况下



训练

GAN的方法。

（2）各种

评估技术超

越了对分布

的简单统计

评估，并提供

了与样



本视

觉质量相关

的更有用的

信息。

（3）训练分

为3种结构设

置：博弈论的

最小-最大GAN、启

发性的



非饱

和GAN和最新的

以及理论上

有据可查的

沃瑟斯坦GAN。

（4）能

够使训练更

快的技巧如

下。



归一化输

入，这是机器

学习中的标

准做法。

使用

梯度惩罚令

训练更具稳

定性。



预训练

鉴别器可以

提供良好的

生成器，这样

会为生成的

样本设置

更

高的标准。



避

免稀疏梯度

，因为它们会

丢失太多信

息。

使用平滑

和带有噪声

的标签，而不

是典型的二

分类标签。



[1] NIPS

2016举

办了一个GAN训

练研讨会，与

会者都是该

领域的重要

研究人员，本

章就是以此

次会议为基

础编写的。NIPS最

近将其缩写

改



为NeurIPS。

[2] 解决维

数问题更好

的处理方法

参见第10章。



[3]

How (Not) to

Train your Generative Model:

Scheduled



Sampling, Likelihood,

Adversary?, by



Ferenc

Huszár, 2015.



[4]

Amazon Mechanical Turk

是

一种服务，它

允许按小时

计算地购



买

人们的时间

来完成预先

指定的任务

。它有点像按

需自由职业

者或

Task Rabbit，不过是

以在线形式

实现的。



[5]

An Introduction to

Image Synthesis with Generative

Adversarial Nets, by He

Huang et al., 2018.

[6] Improved Techniques for

Training GANs, by Tim

Salimans



et al.,

2016.



[7] KL散度

的相关内容

参见第2章。

[8] Conditional Image Synthesis

with Auxiliary Classifier

GANs, by Augustus Odena

et al., 2017.

[9] GANs Trained by

a Two Time-Scale Update

Rule Converge to

a Local Nash Equilibrium,

by Martin Heusel et

al., 2017.



[10]

Is Generator Conditioning

Causally Related to GAN

Performance?, by Augustus Odena

et al., 2018, talk

at UCL,



February

10, 2018.



[11]

Generative Adversarial Networks,

Network, by Ian

Goodfellow et al., 2014.

[12] Progressive Growing of

GANs for Improved Quality,

Stability, and Variation, by

Tero Karras et al.,

2017.



[13] Are

GANs Created



Equal?

A Large-Scale Study,

by Mario



Lucic

et al., 2017.

[14] Wasserstein GAN ,

by Martin Arjovsky et

al., 2017.



[15]

meta-review是

综述类文献

的综述，它有

助于研究人

员汇集来自

几篇论文的

发现。



[16]

Many Paths to

Equilibrium: GANs Do Not

Need to Decrease

a Divergence at Every

Step, by William Fedus

et al., 2018.

[17] Improved Training of

Wasserstein GANs, by Ishaan

Gulrajani et al., 2017.

[18] 为什么

Adam比SGD更好? 因为

Adam是SGD的延伸，实

际应用往往

效果更好。Adam将

几种训练技

巧和SGD组合成

一个易于使

用的程序包

。

[19] Tutorial on Generative

Adversarial Networks—GANs in

the Wild, by Soumith

Chintala, 2017.



[20]

Large-Scale GAN Training

for High-Fidelity Natural

Image Synthesis, by Andrew

Brock et al., 2019.

[21] 尽管作者在

这里借用了

强化学习的

概念，称鉴别

器为“批评



家

”，但那篇论文

的大部分灵

感都来自于

它。

[22] Least Squares Generative

Adversarial Networks, by

Xudong Mao et al.,

2016. 另见BEGAN: Boundary Equilibrium

Generative Adversarial Networks, by

David Berthelot et al.,

2017.



[23] Odena

et al.,



2018,

http://arxiv.org/abs/1802.08768.



第6章

渐进式增长

生成对抗网

络

（PGGAN）



本章主要

内容

在整个

训练过程中

渐进式增长

鉴别器网络

和生成器网

络



让训练更

稳定，输出更

多样化，质量

和分辨率更

高

使用TFHub —— 一个

用于模型和

TensorFlow代码的中央

仓库

在本章

中，我们提供

了一个实践

教程，使用TensorFlow和

TensorFlow Hub（TFHub）构建渐进式

增长生成对

抗网络

（Progressive GAN，PGGAN或ProGAN）——一

种能够生成

全高清的具

有照片级真

实感图像的

前沿技术。这

项技术在顶

级机器学习

会议ICLR

2018上提出

时引起了轰

动，以至于谷

歌立即将其

整合为TensorFlow



Hub中的

几个模型之

一。这项技术

被深度学习

的鼻祖之一

Yoshua

Bengio称赞为“好得

令人难以置

信”，在其发布

后，立即成为

学术报



告和

实验项目的

最爱。

建议使

用TensorFlow 1.7或更高版

本来完成本

章。本书使用

的版



本是1.8+。

建

议使用不高

于0.4.0版本的TensorFlow Hub，以

后的版本因

与



TensorFlow

1.x的兼容性

问题无法导

入。阅读本章

后，你将能够

实现



PGGAN的所有

关键改进。本

章涉及4个创

新点，它们分

别为高分辨

率层

的渐进

式增长和平

滑、小批量标

准偏差、均衡

学习率和像

素级特征归

一化。



本章将

给出如下两

个主要例子

。

（1）PGGAN的关键创新

部分的代码

，具体来说，就

是平滑地增

大



高分辨率

层以及前面

列出的其他

3个创新点。PGGAN其

余部分的实

现所

需篇幅

实在太长，无

法在本书中

展示。



（2）谷歌在

TFHub上提供了一

个预训练好

的且易于下

载的实现。

TFHub是

一个用于机

器学习模型

的新的集中

式仓库，类似

于Docker Hub



或Conda以及PyPI。此

复现能够进

行潜在空间

插值以控制

生成样本的

特

征。这会简

要涉及生成

器潜在空间

中的种子向

量，以便获得

想要的图



片

（第2章和第4章

）。

这里使用TFHub而

不是像其他

章那样从头

开始实现PGGAN，原

因有



如下3个

。

（1）尤其是对于

从业人员，我

们希望确保

你（至少从一

章里）了



解到

可以加快工

作流程的软

件工程最佳

实践。想尝试

快速用GAN解决

问

题吗？使用

TFHub上的其中一

种实现即可

。与最初编写

本章时相比

，



TFHub现在有更多

的实现，包括

许多参考实

现（如第12章中

的BigGAN和

第5章中

的NS-GAN）。希望你能

接触到易于

使用的最先

进的例子，因

为



这就是机

器学习的发

展方式——尽可

能地使机器

学习自动化

，这样我

们就

可以专注于

最重要的事

情：产生影响

。谷歌的Cloud AutoML和亚

马逊的SageMaker是这

种趋势的主

要例子，甚至

Facebook最近都推出

了

PyTorch Hub，所以两种

主要机器学

习框架现在

都有一个仓

库了。



（2）NVIDIA研究人

员花了一到

两个月的时

间来运行最

初的

PGGAN。任何人

想独自运行

它都是不切

实际的，特别

是在进行实

验或出



现错

误情况下。[1] TFHub也

提供了一个

完全可训练

的PGGAN，因此，

如果

想利用做计

算的日子来

做其他事，你

也可以从头

训练！



（3）我们仍

然想在这里

展示PGGAN最重要

的创新。但是

要很好地

解

释这些内容

（包括代码），即

使是用Keras编写

的，也无法将

所有实



现细

节都放在一

章中，因为太

过庞大了。TFHub使

我们可以跳

过无关紧

要

的样板代码

，而专注于实

现重要的想

法。



6.1 潜在空间

插值

第2章中

有一个较低

分辨率的空

间（潜在空间

），可以为输出

提



供随机初

始值。对于第

4章中的DCGAN以及

PGGAN，初始训练的

潜在空间

具

有语义上有

意义的性质

。这意味着可

以找到向量

偏移量，例如

，将



眼镜引入

人脸图像，相

同的偏移量

会在新的图

像中引入眼

镜。还可以

选

择两个随机

向量，然后在

它们之间每

次移动相等

的增量，从而

逐渐



平滑地

获得与第二

个向量匹配

的图像。

上述

方法称为插

值，如图6.1所示

。正如BigGAN论文的

作者所



说，从

一个向量到

另一个向量

的有意义的

转换表明GAN已

经学习到了

一

些底层结

构。



图6.1 我们可

以进行潜在

空间插值，因

为发送给生

成器的潜在

向量会产生

一致的

结果

，这种结果在

某些方面是

可以预测的

。如果考虑潜

在向量的变

化，不仅生成

过程是可预

测的，输出也

不是参差不

齐的，对微小

的变化也不

会做出剧烈

的反



应。例如

，想要一幅由

两张脸混合

生成的图像

，在两个向量

的平均值附

近搜索即

可

6.2 它们发展如

此之快

在前

面的章节中

，我们已经了

解到使用GAN可

以轻松实现

哪些结



果，难

以实现哪些

结果，还对模

式崩溃（只展

示了总体分

布的几个样

本）和缺乏收

敛性（导致结

果质量较差

的原因之一

）有了一定的

了

解。



最近，芬

兰NVIDIA的一个团

队发表了一

篇论文，这篇

论文成功击

败了之前的

许多前沿论

文，这就是Tero

Karras等

人所撰写的

Progressive Growing of

GAN



for Improved

Quality, Stability,



and

Variation。该论文有4个

基本的创新

点，让我们依

次来看看。



6.2.1 高

分辨率层的

渐进增长和

平滑

在深入

研究PGGAN的作用

之前，我们先

来看一个简

单的类比！想

象



一下，俯瞰

某处山区：山

区有许多山

谷，那里有漂

亮的小溪和

村庄，

非常宜

居。但是其间

也会有许多

山坡，它们崎

岖不平，而且

由于天气



原

因，通常不宜

居住。我们用

山谷和山坡

类比损失函

数，希望沿着

山

坡进入更

好的山谷，以

最小化损失

。



我们可以把

训练想象成

将登山者放

到这处山区

的任意地方

，让他

顺着山

坡往下的路

进入山谷——这

就是随机梯

度下降所做

的（第10



章）。但是

，假设从一处

非常复杂的

山脉开始，登

山者不知道

该往哪

个方

向走。他周围

的地势是崎

岖不平的，以

至于他很难

弄清楚哪里

是



有宜居地

的最宜人、最

低的山谷。假

如我们拉远

画面并降低

山脉的复

杂

度，使登山者

对这一特定

区域有一个

高层次的了

解。



随着登山

者越来越接

近山谷，我们

再通过放大

地形增加复

杂性。

这样不

再只看到粗

糙/像素化的

构造，而是可

以看到更精

细的细节。这

种方法的优

势在于，当登

山者沿着斜

坡下山时，他

可以很容易

地进行



一些

小的优化以

使旅行更加

轻松，例如，他

可以沿着一

条干涸的小

溪

行走以更

快地到达山

谷。这就是渐

进式增长（progressive



growing）：随

着登山者的

行进，提高地

形的分辨率

。

然而，如果你

玩过一款沙

箱类游戏，或

者带着3D眼镜

在谷歌地图

上快速移动

，就会知道快

速增加周围

地形的分辨

率是惊心动

魄且不愉



快

的——所有物体

突然映入眼

帘。因此，随着

登山者越来

越接近目

标

，我们渐进式

地、平滑地并

慢慢地引入

更多的复杂

性。



用专业术

语来说，就是

训练过程正

在从几个低

分辨率的卷

积层发

展到

多个高分辨

率的层。先训

练早期的层

，再引入更高

分辨率的层

——高分辨率层

中的损失空

间很难应对

。从简单的（如

经过几步训

练



得到的4×4）开

始，最后到更

复杂的（如经

过多个时期

训练的

1024×1024），如图

6.2所示。



这种情

况下的问题

是，即便一次

增加一个层

（例如，从4×4到

8×8），也

会给训练带

来巨大的影

响。PGGAN所做的就

是平滑地增

加这



些层，如

图6.3所示，以给

系统适应更

高的分辨率

的时间。

但不

是立即跳到

该分辨率，而

是在通过参

数α（介于0和1之

间，



从0到1线性

缩放）平滑地

增加高分辨

率的新层。α 会

影响旧的但

扩大

规模的

层和新生成

的更大的层

的利用程度

。虚线下方的

D部分，只是简

单地缩小至

1/2，再平滑地注

入训练过的

层以用于鉴

别，如图6.3（b）



所示

。如果我们对

这一新层有

信心，保持在

32×32（图6.3(c)），然

后在恰

当地训练好

32×32分辨率的层

之后，就准备

再次增长。



图

6.2 能看到如何

从平滑的山

脉开始，通过

放大逐渐增

加复杂性吗

？实际上这就



是添加额外

层对损失函

数的影响。这

很方便，因为

山区（损失函

数）在平坦的

情



况下更容

易导航。可以

这样认为：当

结构更复杂

时（b），损失函数

凹凸不平且

难

以导航（d），因

为参数太多

（尤其是在早

期层中）会产

生巨大的影

响——通常会



增

加问题的维

数。但是，如果

最初删除部

分复杂度（a），就

可以在早期

获得更容

易

导航的损失

函数（c），并且只

有我们确信

自己处于损

失空间近似

正确的部分

，



才会增加复

杂性。只有这

样，才能从（a）和

（c）转变为（b）和（d）

图

6.3 训练了足够

迭代次数的

16×16分辨率后（a），在

生成器（G）中引

入了另



一个

转置卷积，在

鉴别器（D）中引

入了另一个

卷积，使G和D之

间的“接口”为



32×32。生成32×32层有两

条路径：（1−α）乘以

简单地以最

近邻插值增

加尺度



的层

，这没有任何

经过训练的

参数，比较直

接；（α）乘以额外

的转置卷积

的输

出层，这

需要训练，但

最后会表现

得更好。二者

相连，以形成

新的32×32的生成

图像，α 从0到1线

性缩放，当α 达

到1时，从16×16开始

的最近邻插

值将完全为



零。这种平滑

的过渡机制

极大地稳定

了PGGAN架构



6.2.2 示例

实现

针对以

上详细介绍

的所有创新

，我们将在本

节分别给出

可以运行



的

版本，以便讨

论代码。你可

以尝试将此

作为练习，把

这些创新构

建

到一个GAN网

络中，或通过

使用现有的

架构来实现

。如果准备好

了，请



赶紧动

手加载值得

信赖的机器

学习库：

import tensorflow as tf

import keras as K

渐进

式平滑增长

的代码如清

单6.1所示。



清单

6.1 渐进式平滑

增长

def upscale_layer(layer, upscale_factor):

'''



Upscales layer

(tensor) by



the

factor (int) where

the tensor is [group,

height, width, channels]

'''



height =

layer.get_shape()[1]



width =

layer.get_shape()[2]



size =

(upscale_factor *



height,

upscale_factor * width)

upscaled_layer = tf.image.resize_nearest_neighbor(layer,

size)



return upscaled_layer

def smoothly_merge_last_layer(list_of_layers, alpha):

'''



Smoothly merges

in a



layer

based on a

threshold value alpha.

This function assumes: that

all layers are already

in RGB.



This

is the function

for the Generator.

:list_of_layers : items should

be tensors ordered by

resolution



:alpha :

float \in



(0,1)

'''



last_fully_trained_layer =

list_of_layers[-2] ←---



如果使



用的是Tensor Flow而不

是Keras，要记得scope



last_layer_upscaled

= upscale_layer(last_fully_trained_layer,



2)

←--- 现

在有了最初

训练过的层

larger_native_layer =

list_of_layers[-1] ←---



新加的层还

没

有完全训

练



assert larger_native_layer.get_shape()

==



last_layer_upscaled.get_shape() ←---

这确保可

以运行合并

代码



new_layer =

(1-alpha) *



upscaled_layer

+ larger_native_layer



*

alpha ←--- 此代码

块应该利用

广播（broadcasting）功能

return new_layer



我

们已经了解

了在不增加

复杂度的情

况下实现渐

进式平滑增

长的

底层细

节，希望你能

体会到这个

想法的普遍

性。虽然Karras等人

绝对



不是最

先提出在训

练过程中增

加模型复杂

性的，但PGGAN似乎

是迄今为

止

最有发展前

途的方法，它

确实是振奋

人心的创新

。截至2019年6月，



他

们撰写的论

文被引用多

达730余次。在这

样的背景下

，我们继续来

看

第二个重

大创新点。



6.2.3 小

批量标准偏

差

Karras等人在论

文中引入的

下一个创新

点是小批量

标准偏差



（mini-batch standard

deviation）。在

深入探讨之

前，我们先回

顾



模式崩溃

的问题——当GAN学

习如何创建

一些好的样

本或者只是

稍微置

换一

下它们时，这

种情况就会

发生。



人们通

常希望能够

生成真实数

据集中所有

人的脸，而不

是只能生

成

某个女人的

一张照片。为

此，Karras等人创造

了一种方法

，使鉴别



器可

以辨别所获

取的样本是

否足够多样

。这种方法本

质上是为鉴

别器

计算了

一个额外的

标量统计量

。此统计量是

生成器生成

的或来自真

实



数据的小

批量中所有

像素的标准

偏差。

这是一

个非常简单

而优雅的解

决方案：现在

鉴别器需要

学习的



是，如

果正在评估

的批量中图

像的标准偏

差很低，则该

图像很可能

是

伪造的——因

为真实数据

所具有的偏

差较大。[2] 生成

器别无选择

，



只能增加生

成样本的偏

差，才有机会

欺骗鉴别器

。

上述内容理

解起来很直

观，技术实现

起来也非常

简单，因为它

只



应用在鉴

别器中。考虑

到我们还想

最小化可训

练参数的数

量，只添加

一

个额外的数

字似乎就够

了。该数字作

为特征图附

加到鉴别器

上——



维度或tf.shape列

表中的最后

一个数字。

具

体步骤如下

，程序如清单

6.2所示。



（1）[4D→3D] 计算批

次中所有图

像和所有通

道（高度、宽度

和

颜色）的标

准偏差，然后

得到关于每

个像素和每

个通道的标

准偏差的



一

个图像。

（2）[3D→2D] 对所

有通道的标

准差取均值

，得到像素的

一个特



征图

或标准差矩

阵，但是颜色

通道折叠了

。

（3）[2D→标量/0D] 对前一

个矩阵内所

有像素的标

准偏差取均

值，以获得一

个标量值。

清

单6.2 小批量标

准偏差



def

minibatch_std_layer(layer, group_size=4):



'''

Will calculate minibatch standard

deviation for a layer.

Will do so under

a prespecified tf-scope with

Keras.



Assumes layer

is a



float32

data type. Else

needs



validation/casting.

NOTE: there is a

more efficient way to

do this in Keras,

but



just for

clarity and alignment with

major implementations (for

understanding)



this was

done more



explicitly.

Try this as

an exercise.



'''

group_size = K.backend.minimum(group_size, tf.shape(layer)

[0]) ←--- 如果

使用的是TensorFlow而

不是Keras，那么scope一

个小批量组

必须能够被

group_size整除（或<=）

shape = list(K.int_shape(input)) ←---

获取

一些形状信

息，以便



快速

调用和确保

默认值。从tf.shape中

得到输入，因

为pre-image维度通常

在图形执行

之前转换为

None

shape[0] = tf.shape(input)[0]

minibatch = K.backend.reshape(layer,

(group_size, -1, shape[1], shape[2],

shape[3])) ←---



改变形状，以

便在小批量

水平上操作

。在这段代码

中，假设层是

[Group

(G), Mini￾batch (M),Width

(W), Height (H), Channel

(C)]，注意：不同的

实现有的使

用了特定的

Theano顺序



minibatch

-= tf.reduce_mean(minibatch, axis=0,

keepdims=True)



←--- 将均值

集中于组[M,W,H,C]

minibatch = tf.reduce_mean(K.backend.square(minibatch), axis

= 0) ←--- 计

算组[M,W,H,C]的方差



minibatch = K.backend.square(minibatch +

1e8) ←--- 计算组

[M,W,H,C]的标

准偏差



minibatch =

tf.reduce_mean(minibatch, axis=[1,2,4],



keepdims=True)

←--- 取特

征图和像素

的平均值[M,1,1,1]



minibatch

= K.backend.tile(minibatch,



[group_size,

1, shape[2], shape[3]])

←--- 转

换标量



值以

适应组和像

素

return K.backend.concatenate([layer, minibatch], axis=1)

←---



附加一个

特征图

6.2.4 均衡

学习率



均衡

学习率（equalized

learning rate）可能

是一种谁都

不清



楚的深

度学习黑魔

法。尽管研究

人员确实在

PGGAN论文中给出

了简短的

解

释，但他们在

口头报告中

回避了这个

话题，这表明

这可能只是

一个



“看起来

可行”的技巧

。在深度学习

中，这种情况

时有发生。

此

外，关于均衡

学习率的许

多细微差别

，需要你对RMSProp或

Adam



的实现以及

权重初始化

有充分的理

解。所以，即便

你不理解，也

不用

担心，因

为这可能对

谁都没有意

义。



但是如果

你非常好奇

，大概的解释

是这样的：需

要确保将所

有权

重 归一

化（ ）在一定范

围内，这样 =

/ 就

需要一个常

数 ，

这个常数

对于每一层

都是不同的

，具体取决于

权重矩阵的

形状。这也



确

保了如果任

何参数需要

采取更大的

操作来达到

最优（因为它

们往往

变化

更大），那么使

用相关参数

可以很容易

做到。



RMSProp等人使

用简单的标

准正态初始

化，然后在运

行时缩放每

层

的权重。有

些人可能以

为Adam已经做到

了这一点。是

的，Adam允许不



同

参数的学习

率不同，但它

有一个陷阱

。Adam通过参数的

估计标准偏

差来调整反

向传播的梯

度，从而确保

该参数的大

小与更新无

关。Adam

在不同的

方向上有不

同的学习率

，但并不总是

考虑动态范

围——在给



定的

小批量中，维

度或特征的

变化有多大

。有人指出这

似乎解决了

一

个类似于

权重初始化

的问题。[3]



如果

你还是不明

白，请不要担

心，可以参考

我们强烈推

荐的两个

出

色资源：Andrew Karpathy在2016年

的一次计算

机科学讲座

中介绍了



权

重初始化[4]；一

篇关于Adam工作

原理的文章

。[5]

均衡学习率

的代



码见清

单6.3。

清单6.3 均衡

学习率



def

equalize_learning_rate(shape, gain, fan_in=None):

'''



This adjusts

the weights



of

every layer by

the constant from

He's initializer so that

we adjust for the

variance in the

dynamic



range in

different features



shape

: shape of

tensor (layer): these are

the dimensions



of

each layer.



For

example, [4,4,48,3]. In

this case, [kernel_size,

kernel_size,



number_of_filters, feature_maps].

But this



will

depend



slightly on

your implementation.



gain

: typically sqrt(2)

fan_in : adjustment for

the number of incoming

connections



as per

Xavier's /



He's

initialization



'''

if fan_in is None:

fan_in = np.prod(shape[:-1]) ←---

默认

为所有形状

维数减去特

征图维数的

乘积，这给出

了每个神经

元传入连接

的数量



std

= gain /

K.sqrt(fan_in) ←--- 此处

使用了初始

化常量[6]

wscale = K.constant(std, name='wscale',

dtype=np.float32)



←--- 在调

整之外创建

一个常量

adjusted_weights = K.get_value('layer', shape=shape,

←---



获

取权重使用

广播机制应

用调整

initializer=tf.initializers.random_normal()) * wscale

return adjusted_weights



如果

你仍然感到

困惑，请放心

，无论是学术

界还是工业

界，这些

初始

化技巧和复

杂的学习率

调整都很少

有区别。同样

，将权重值限

制



在1和1之间

，就在大多数

次重新运行

中取得了更

好的效果，但

并不意

味着

此技巧适用

于其他情况

。所以让我们

来看看更成

熟的技术。



6.2.5 生

成器中的像

素级特征归

一化

我们从

为什么想要

归一化特征

的动机——训练

的稳定性开

始说



起。根据

经验，来自NVIDIA的

作者发现，训

练发散的早

期迹象之一

是

特征的爆

炸式增长。BigGAN的

发明者在第

12章中也有类

似的观察结

果。所以Karras等人

引入了一种

技术来解决

这个问题。从

更广泛的意

义上说，这是

训练GAN的常见

方式：在训练

中观察到一

个特定的问

题，

于是引入

了防止该问

题发生的机

制。



注意，大多

数网络都使

用了某种形

式的归一化

。通常使用的

是批

归一化

或其虚拟版

本。表6.1概述了

本书迄今为

止在GAN中使用

的归一



化技

术。第4章和第

5章提到了这

些内容，并介

绍了其他的

GAN和梯度惩

罚

。为了使批归

一化及其虚

拟版本能够

等效工作，我

们必须拥有

大量



的小批

处理，以便求

各个样本的

平均值。

表6.1 GAN中

使用的归一

化技术



方法

提出者及提

出时间

生成

器归



一化

鉴

别器归



一化

方法

提出者

及提出时间

生成器归



一

化

鉴别器归

一化



DCGAN

Radford等人, 2015,



https://arxiv.org/abs/1511.06434.pdf

批

归一化 批归

一化



改进的



GAN



Salimans等人, 2016,

https://arxiv.org/pdf/1606.03498.pdf



虚拟批

归一

化



虚拟

批归一

化



WGAN

Arjovsky等

人, 2017,



https://arxiv.org/pdf/1701.07875.pdf

— 批归一化

WGAN-GP

Gulrajani等人, 2017,



http://arxiv.org/abs/1704.00028

批归一

化 层归一化

基于“所有主

要的实现使

用了归一化

”这一事实，我

们可以断定

它显然很重

要，但是为什

么不直接使

用标准的批

归一化呢？这

是因为

在想

要达到的分

辨率下，批归

一化过于占

用内存。我们

必须想出使

用



少量样本

（适用于使用

并行网络图

的GPU显存内存

）仍然可以正

常工作

的一

些办法。至此

，我们了解了

像素级特征

归一化的需

求从何而来

以



及为什么

要进行像素

级特征归一

化。

如果从算

法角度说，像

素级归一化

将在输入被

送到下一层

之前在



每一

层获得激活

幅度。

像素级

特征归一化

对每个特征

图，执行



（1）在位

置

上获取该

特征图 的像

素值。



（2）为每个

构造一个向

量，其中

a． = [ 的（0，0）值

，

的（0，0）值，...，



的（0，0）值]。

b． = [ 的

（0，1）值，

的（0，1）值，...，



的（0，1）值

]。

…



c． =

[ 的



值，

的 值，…， 的

值）]。

（3）将步骤2中

定义的每个

向量 归一化

得到单位标

准值，称



之为

。

（4）将原来的张

量形状传递

到下一层。



结

束

像素级特

征归一化的

过程如图6.4所

示。步骤3的准

确描述如式

6.1



所示。

图6.4 将图

像中的所有

点（步骤1）映射

到一组向量

（步骤2），然后对

其进行归



一

化，以使它们

都在同一范

围内（通常在

高维空间中

介于0和1之间

），这就是步

骤

3



式6.1

式6.1将图6.4步

骤2中构造的

每个向量归

一化（除以根

号下的表



达

式）。该表达式

只是特定 像

素每个平方

值的平均值

。有一件事

可

能会让你吃

惊，那就是增

加了一个小

的噪声项（ε）。这

只是确保



不

被零除的一

种方法。Alex Krizhevsky等人

在2012年的论文

ImageNet

Clas-sification with Deep Convolutional

Neural Networks中对整



个过

程进行了更

详细的说明

。像素级特征

归一化的代

码见清单6.4。

最

后要注意的

是，像素级特

征归一化这

一技巧仅用

于生成器，因

为两个网络

都使用时，激

活幅度的爆

炸会导致军

备竞赛（arms race）

[7]。



清单

6.4 像素级特征

归一化

def pixelwise_feat_norm(inputs, **kwargs):

'''



Uses pixelwise

feature normalization



as

proposed by



Krizhevsky

et al. 2012.

Returns the input normalized

:inputs : Keras /

TF Layers



'''

normalization_constant = K.backend.sqrt(K.backend.mean(

inputs**2, axis=-1, keepdims=True) +

1.0e-8)



return inputs

/ normalization_constant



6.3

主要

创新点总结

我们已经就

“如何改善GAN训

练”提出了4个

聪明的想法

，如果不



让它

们在训练中

发挥作用，就

很难分辨出

它们各自的

效果，好在PGGAN

论

文的作者们

给出了一个

有用的表格

，以帮助你理

解这一点（图

6.5）。



图6.5

各项技术

对提高得分

的贡献。可以

看到，均衡学

习率起到了

很大作用，像

素级归一化

也增强了这

一点；尽管作

者没有说明

如果仅进行

像素级归一

化但不引



入

均衡学习率

，那么该技术

的有效性如

何。我们把这

个表格仅作

为一个例子

来说

明可以

从这些变化

中得到的改

进大致有多

少，后面会有

更详细的讨

论



PGGAN论文的作

者使用了分

段Wasserstein距离（Sliced

Wasserstein distance，SWD）——其值

越小越好。回

顾一下第5章

，



Wasserstein（推土机）距离

越小意味着

结果越好，可

以用为了使

两个

分布相

似而必须移

动的概率质

量来量化。SWD意

味着真实数

据和生成的

样本的patches会最

小化此距离

。PGGAN解释了这种

技术的细节

，但是



正如作

者在ICLR的演讲

中所说的那

样，已经有了

更好的度量

标准，如

Fréchet inception distance（FID），在第

5章中已经深

入介绍过。

图

6.5的一个关键

结论是，小批

处理并不能

很好地工作

。因为在百



万

像素分辨率

下，我们没有

足够的虚拟

内存来将许

多图像加载

到GPU。

我们必须

使用更小的

小批处理（总

的来说这可

能会更差），并

且必须



进一

步减小小批

处理的大小

，这会使训练

变得困难。

6.4 TensorFlow Hub库

及其实践

谷

歌最近宣布

，作为TensorFlow Extended（TFX）平台的

一部



分，以及

实现从软件

工程到机器

学习领域的

最优方法，他

们创建了一



个名为TensorFlow Hub或TFHub的

中心模型和

代码库。使用

TFHub非常



容易，特

别是调用他

们已经储存

在其中的模

型。

导入hub模块

并调用正确

的URL后，TensorFlow会自行

下载并导入

模型，然后就

可以开始使

用了。这些模

型在用于下

载模型的同

一个URL



中有很

好的文档记

录，只需将它

们输入浏览

器中即可。实

际上，要获

得

经过预训练

的PGGAN，输入一个

import语句和一行

代码即可。



清

单6.5给出的是

一个完整的

代码示例，该

代码根据

latent_vector中

指定的随机

种子生成一

张人脸。[8] 输出

如图6.6



所示。

清

单6.5 使用TFHub



import

matplotlib.pyplot as plt

import tensorflow as tf

import tensorflow_hub as hub

with tf.Graph().as_default():



module

= hub.Module("https://tfhub.dev/google/progan-128/1")



←---

从TFHub导

入PGGAN



latent_dim =

512 ←---



运行时采

样的潜在维

度

latent_vector = tf.random_normal([1, latent_dim],

seed=1337)



←--- 改变种子

得到不同人

脸

interpolated_images = module(latent_vector) ←---

使用该模

块



从潜在空

间生成图像

with

tf.Session() as session:

←--- 运行TensorFlow session

得到(1, 128, 128, 3)的

图像

session.run(tf.global_variables_initializer())



image_out =

session.run(interpolated_images)



plt.imshow(image_out.reshape(128,128,3))

plt.show()



图6.6 清单

6.5的输出。尝试

更改latent_vector定义中

的种子以获

得不同的输



出。警告：即使

这个随机种

子参数定义

输出时是一

致的，但我们

发现有时在

重新



运行时

会得到不同

的结果，这取

决于TensorFlow的版本

。该图像是用

1.9.0-rc1

获得的



希望

这足以让你

开始使用PGGAN！你

可以随意修

改并扩展代

码。注

意，PGGAN的TFHub版

本未使用完

整的1024×1024分辨率

，而是



128×128。这可能

是因为运行

完整版本的

计算成本很

昂贵，并且在

计

算机视觉

领域中模型

的大小可能

会迅速增大

。



6.5 PGGAN的实际应用



人们对PGGAN的实

际应用和通

用性很感兴

趣是可以理

解的。下面介

绍的一个很

好的例子是

来自在英国

伦敦一家医

疗科技初创

公司Kheiron



Medical

Technologies。最近，他

们发表了一

篇论文，充分

证明了



PGGAN的通

用性和实际

应用性。[9]

利用

庞大的医学

乳腺X线数据

集[10]，这些研究

人员成功生

成了



1280×1024逼真的

全数字化乳

腺X线摄影（Full-Field Digital

Mammography，FFDM），如

图6.7所示。这在

以下两个层

面上都是非

凡



的成就。

图

6.7 FFDM的渐进式增

长。不仅显示

了这些乳腺

X线照片的分

辨率逐渐提

高（图



e），还展示

了一些训练

统计数据（图

a～图d），说明训练

这些GAN对谁来

说都是

一件

麻烦事



（1）它显

示了该技术

的可推广性

。考虑一下乳

腺X线照片与

人脸

图像有

何不同，特别

是结构上。前

者对组织结

构是否合理

的标准非常

高，然而PGGAN以迄

今为止最高

的分辨率成

功生成了样

本，这足以骗

过



专业医务

人员。

（2）它展示

了如何将这

些技术应用

于多个领域

和多种用途

。例



如，我们可

以以半监督

方式使用这

个新数据集

（第7章），也可以

将合

成数据

集开源，用于

医学研究，而

不必担心受

通用数据保

护条例



（GDPR）或其

他法律影响

，因为这些X片

不属于任何

人。

图6.8显示了

这些乳腺X线

照片的真实

感。这些都是

随机挑选的

（不是只挑最

好的），然后与

数据集中与

它最接近的

图像之一加

以比



较。

图6.8 在

比较真实数

据集和生成

数据集时，这

些数据看起

来非常真实

，并且很接



近

训练集中的

样本。在随后

的工作（MammoGAN）中，Kheiron表

明，这些图像

骗

过了受过

训练和认证

的放射线医

师。[11] 这是一个

好兆头，尤其

是在高分辨

率的



情况下

。当然，原则上

我们更希望

用统计方法

来衡量生成

样本的质量

。正如我们

从

第5章了解到

的那样，这对

于普通图像

已经够困难

了，更不用说

对于任意的

GAN



了

GAN不仅可以

用于对抗乳

腺癌或生成

人脸，在其他

应用中也有

涉



及。截至2018年

7月底，已经有

62篇GAN的医学应

用论文发表

。[12] 我

们强烈建

议你研读这

些论文，当然

，并非所有论

文使用了PGGAN。一

般



来说，GAN在许

多研究领域

都能实现巨

大的飞跃，但

它的应用往

往不那

么直

观。我们希望

它们能更容

易理解，以便

更多的研究

人员能使用

它



们。

本章介

绍的技术都

代表了解决

GAN问题的一类

一般方法 —— 使

用

了一个渐

进复杂的模

型。我们希望

这一范例能

在GAN中有所应

用。对



TensorFlow Hub也是如

此，因为它对

于TensorFlow就像PyPI/Conda对

于

Python一样重要 —— 大

多数Python程序员

每周都会用

到这些软件

库！

我们希望

这项新的PGGAN技

术能让你了

解到GAN可以做

什么以及人

们为什么对

这篇论文如

此感兴趣，也

希望PGGAN可以生

成的不只是

猫咪



表情包

。[13]

我们会在第

7章给出一些

工具，以便你

可以开始自

己的



研究。

6.6 小

结



（1）借助最先

进的PGGAN技术，我

们可以实现

百万像素的

合成图

像。



（2）PGGAN技

术具有4个关

键的训练创

新。

渐进式和

平滑地增大

高分辨率的

层。



小批处理

标准偏差，以

强制所生成

的样本多样

化。

均衡学习

率，确保在每

个方向上采

取适当大小

的学习步骤

。



像素特征向

量归一化，确

保生成器和

鉴别器在竞

争中不会失

控。

（3）实现了一

个使用新发

布的TensorFlow Hub的实践

教程，并使



用

PGGAN的低分辨率

版本来生成

图像！

（4）了解了

GAN如何有助于

对抗癌症。



[1] Progressive

Growing of



GANs

for Improved Quality,

Stability, and Variation, by

Tero Karras, 2018.

[2] 有

些人可能会

反驳说，如果

采样的真实

数据包含大

量非常相似

的



图片，也会

发生这种情

况。从技术上

来说，这是正

确的，但在实

际中

这种情

况很容易修

复，请记住这

里所说的“相

似性”可是非

常高的，



以至

于简单的最

近邻聚类的

一次传递就

可以揭示它

。

[3] Progressive Growing of

GANs.md, by Alexander Jung,

2017.



[4] Lecture

5: Training



Neural

Networks, Part I,by

Fei-Fei



Li et

al. 2016.



[5]

Delving Deep into

Rectifiers: Surpassing Human-Level

Performance on ImageNet Classification,

by Kaiming He et

al..



[6] Delving

Deep into



Rectifiers:

Surpassing Human-Level



Performance

on ImageNet Classification,by

Kaiming He et al..

[7] 这里借喻预

防式的对抗

。——编辑注



[8]

此样

本是用TFHub生成

的，基于http://mng.bz/nvEa提供

的Colab



示例。

[9] High-Resolution Mammogram Synthesis

Using Progressive



Generative

Adversarial Networks, by

Dimitrios Korkinof et

al., 2018.



[10]

用于

乳腺癌筛查

的X射线扫描

。



[11] MammoGAN:

High-Resolution Synthesis



of

Realistic



Mammograms, by

Dimitrios Korkinof



et

al., 2019.



[12]

GANs for Medical

Image Analysis,by Salome Kazeminia

et



al., 2018.

[13] Gene Kogan’s Twitter

image, 2018.



第7章

半监督

生成对抗网

络（SGAN）



本章主要

内容

基于原

始GAN模型蓬勃

发展的创新

领域



半监督

学习及其巨

大的实践意

义

半监督生

成对抗网络

（SGAN）



SGAN模型的实现

到现在为止

，我们不仅了

解了GAN定义和

功能，还运行

了两个最典



型的实现：原

始GAN和奠定大

多数高级GAN变

体（包括第6章

介绍的



PGGAN）基础

的DCGAN。

但和很多

领域一样，当

你认为开始

真正掌握它

的时候，你会

发现



这个领

域比最初想

象的要大得

多，也复杂得

多，看似很透

彻的理解也

不过是冰山

一角。

GAN也不例

外，自发明以

来，它一直是

一个活跃的

研究领域，每

年



都有无数

的变化。被很

贴切地命名

为“The GAN

Zoo”的非官方

列表，



试图囊

括所有已有

命名的GAN变体

（每种GAN实现有

不同的名称

，由创

造它们

的研究人员

命名）——在编写

本书时已经

增至300余个。原

始



GAN论文被引

用了9000余次（截

至2019年7月），成为

近年来深度

学习

领域被

引用最多的

研究论文之

一，由此可以

推测研究人

员发明的GAN变

体的真实数

量可能远远

不止于此[1]，如

图7.1所示。



（来源

:

The GAN Zoo,

Avinash Hindupur, 2017.）

图7.1 此图大致

描述了从2014年

GAN的发明到2018年

的前几个月

，研究人员发

布



的GAN数目的

逐月累积统

计。生成对抗

学习领域自

诞生以来呈

指数级增长

，而且这

种兴

趣和流行的

增长简直看

不到尽头



值

得注意的是

，并非GAN变体都

与原始GAN截然

不同。它们中

的许

多与原

始GAN模型在很

大程度上非

常相似（如第

4章中的DCGAN），甚至

许多复杂的

创新，如Wasserstein GAN（第5章

），也主要关注

于如何

提高

原始GAN模型或

其类似模型

的性能和稳

定性。



本章和

接下来的两

章将重点讨

论与原始GAN模

型非常不同

的GAN变

体模型

——不同之处不

仅表现在模

型实现的架

构和基础数

学描述上，



还

表现在动机

和目标上。特

别要说明的

是，我们将介

绍3种GAN模型：

SGAN（本

章）、CGAN（第8章）和CycleGAN（第

9章）。



通过本章

给出的概念

和具体示例

，你会了解到

每一个GAN变体

的目

标、动机

、模型架构以

及它们的网

络如何训练

和工作。这些

主题将通



过

概念和具体

例子进行介

绍。我们将提

供教程，提供

这些模型的

完整

工作实

现，以便你可

以亲自上手

体验。



事不宜

迟，让我们开

始吧！

7.1 SGAN简介



半

监督学习（semi-supervised

learning）是

GAN在实际应用

中



最有前途

的领域之一

。与监督学习

（数据集中的

每个样本有

一个标

签）和

无监督学习

（不使用任何

标签）不同，半

监督学习只

为训练数



据

集的一小部

分提供类别

标签。通过内

化数据中的

隐藏结构，半

监督

学习努

力从标注数

据点的小子

集中归纳，以

有效地对从

未见过的新

样



本进行分

类。要使半监

督学习有效

，标签数据和

无标签数据

必须来自

相

同的基本分

布。



缺少标签

数据集是机

器学习研究

和实际应用

中的主要瓶

颈之一。

尽管

无标签数据

非常丰富（互

联网实际上

就是无标签

图像、视频和

文



本的无限

来源），但为它

们分配类别

标签通常非

常昂贵、不切

实际且

耗时

。在 ImageNet 中手工标

注 320

万张图像

用了两年半

的时间。



ImageNet是一

个标签图像

的数据库，在

过去的十年

中对于图像

处理和

计算

机视觉取得

的许多进步

均有帮助。[2]



深

度学习先驱

、美国斯坦福

大学教授、百

度前首席科

学家Andrew

Ng认为，训

练需要大量

标签数据是

监督学习的

致命弱点。目

前，工业



中的

人工智能应

用绝大多数

使用监督学

习。[3] 缺乏大型

标签数据集



的一个领域

是医学，医学

上获取数据

（如来自临床

试验的结果

）通常



需要耗

费大量的精

力和开支，更

别说会面临

道德伦理和

隐私等更严

重

的问题了

。[4] 因此，提高算

法从越来越

少的标注样

本中学习的

能力



具有巨

大的实际意

义。

有趣的是

，半监督学习

可能也是最

接近人类学

习方式的机

器学习



方式

之一。小学生

学习阅读和

书写时，老师

不必带他们

出门旅行，让

他们在路上

看到成千上

万个字母和

数字的样本

以后，再根据

需要纠正

他

们——就像监督

学习算法的

运作方式一

样。相反，只需

要一组样本

可供孩子学

习字母和数

字，然后不管

何种字体、大

小、角度、照明

条



件和许多

其他条件下

，他们能够识

别出来。半监

督学习旨在

按照这种

有

效的方式教

会机器。



作为

可用于训练

的附加信息

的来源，生成

模型已被证

明有助于提

高半监督模

型的准确性

。不出所料，GAN是

最有前途的

。2016年，Tim

Salimans、Ian Goodfellow和他们在

OpenAI的同事仅使

用2000个带标



签

的样本就在

街景房屋号

码数据集（Street

View House Numbers，

SVHN）上

获得了近94%的

准确率。[5] 相比

之下，当时在

SVHN训练集中



对

所有73257张图像

使用带标签

的最佳全监

督算法的准

确率约为

98.40%。[6] 换

句话说，半监

督GAN的总体准

确率与全监

督的基准测

试



非常接近

，而训练时使

用的标签不

到3%。

下面我们

来看看Salimans和他

的同事是如

何在如此短

的时间内取

得如此大的

成就的。



7.1.1

什么

是SGAN



半监督生

成对抗网络

（Semi-Supervised GAN，SGAN）是一种生

成

对抗网络，其

鉴别器是多

分类器。这里

的鉴别器不

只是区分两

个类



（真和假

），而是学会区

分 类，其中

是

训练数据集

中的类数，



生

成器生成的

伪样本增加

了一个类。

例

如，MNIST手写数字

数据集有10个

标签（每个数

字一个标签

，从



0到9），因此在

此数据集上

训练的SGAN鉴别

器将预测10+1=11个

类。在

我们的

实现中，SGAN鉴别

器的输出将

表示为10个类

别的概率（之

和为



1.0）加上另

一个表示图

像是真还是

假的概率的

向量。

将鉴别

器从二分类

器转变为多

分类器看似

是一个微不

足道的变



化

，但其含义比

乍看之下更

为深远。我们

从一个图7.2所

示的SGAN架构

开

始解释。



图7.2 此

SGAN中，生成器输

入随机噪声

向量

并生成

伪样本 。鉴别

器接收3种



数

据输入：来自

生成器的伪

数据、真实的

无标签数据

样本

和真实

的标签数据

样本



，其中 是

给定样本对

应的标签；然

后鉴别器输

出分类，以区

分伪样本与

真实

样本区

，并为真实样

本确定正确

的类别。注意

，标签数据比

无标签数据

少得多。



实际

情况中，这一

对比甚至比

本图所显示

的更明显，标

签数据仅占

训练数据的

一

小部分（通

常低至1%～2%）



如图

7.2所示，与传统

GAN相比，区分多

个类的任务

不仅影响了

鉴

别器本身

，还增加了SGAN架

构、训练过程

和训练目标

的复杂性。



7.1.2 结

构

SGAN生成器的

目的与原始

GAN相同：接收一

个随机数向

量并生成伪

样本，力求使

伪样本与训

练数据集别

无二致。



但是

，SGAN鉴别器与原

始GAN实现有很

大不同。它接

收3种输入：

生

成器生成的

伪样本 、训练

数据集中无

标签的真实

样本 和有标

签的真实样

本

。其中 表示

给定样本 的

标签。

SGAN鉴别器

的目标不是

二分类，而是

在输入样本

为真的情况

下，



将其正确

分类到相应

的类中，或将

样本作为假

的（可以认为

是特殊的

附

加类）排除。



有

关这两个SGAN子

网络的要点

见表7.1。

表7.1 SGAN的生

成器网络和

鉴别器网络

生成器 鉴别

器

生成器 鉴

别器



输

入



一

个随机数向

量

鉴别器接

收3种输入；



训

练数据集中

无标签的真

实样

本



训练

数据集中有

标签的真实

样

本



生成器

生成的伪样

本

输



出

尽可

能令人相信

的伪样本



表

示输入样本

属于 个真实

类别中的

某

一个或属于

伪样本类别

的可能性



目

标

生成与训

练数据集数

据别无二致

的伪样



本，以

欺骗鉴别器

，使之将伪样

本分到

真实

类别



学会将

正确的类别

标签分配给

真实的

样本

，同时将来自

生成器的所

有样本



判别

为假

7.1.3 训练过

程



回想一下

，常规GAN通过计

算

)和 的损失

并反向传播

总损



失来更

新鉴别器的

可训练参数

，以使损失最

小，从而训练

鉴别器。生

成

器通过反向

传播鉴别器

损失 并寻求

使其最大化

来进行训练

，以



便让鉴别

器将合成的

伪样本错误

地分类为真

。

为了训练SGAN，除

了 )和 ，我们还

必须计算有

监督训练样

本的损失：

。这

些损失与SGAN鉴

别器必须达

到的双重目

标相对



应：区

分真伪样本

；学习将真实

样本正确分

类。用原论文

中的术语来

说，双重目标

对应于两种

损失：有监督

损失（supervised

loss）和



无监

督损失（unsupervised loss）。[7]

7.1.4 训练

目标



到目前

为止，你看到

的GAN变体都是

生成模型。它

们的目标是

生成

逼真的

数据样本。正

因如此，人们

最感兴趣的

一直是生成

器。鉴别器



网

络的主要目

的是帮助生

成器提高生

成图像的质

量。在训练结

束时，

我们通

常会忽略鉴

别器，仅使用

训练好的生

成器来创建

逼真的合成

数



据。

在SGAN中主

要关心的反

而是鉴别器

。训练过程的

目标是使该

网络



成为仅

使用一小部

分标签数据

的半监督分

类器，其准确

率尽可能接

近

全监督的

分类器（其训

练数据集中

的每个样本

都有标签）。生

成器的



目标

是通过提供

附加信息（它

生成的伪数

据）来帮助鉴

别器学习数

据

中的相关

模式，从而提

高其分类准

确率。训练结

束时，生成器

将被丢



弃，而

训练有素的

鉴别器将被

用作分类器

。

至此，我们已

经介绍了是

什么推动了

SGAN的诞生以及

它是如何工

作的，接下来

通过模型的

实现来了解

它的实际应

用。



7.2

教程：SGAN的实

现



本教程实

现了一个SGAN模

型。该模型仅

使用100个训练

样本即可对

MNIST数据集中的

手写数字进

行分类。在教

程的最后，我

们将模型的

分

类准确率

与其对应的

全监督模型

进行了比较

，看看半监督

学习所取得

的进步。



7.2.1

架构

图



本教程中

实现的SGAN模型

的高级示意

如图7.3所示，它

比本章开头

介绍的一般

概念图要复

杂一些。关键

在于（实现）细

节。

为了解决

区分真实标

签的多分类

问题，鉴别器

使用了softmax函



数

，该函数给出

了在给定数

量的类别（本

例中为10类）上

的概率分

布

。给一个给定

类别标签分

配的概率越

高，鉴别器就

越确信该样

本属



于这一

给定的类。为

了计算分类

误差，我们使

用了交叉熵

损失，以测

量

输出概率与

目标独热编

码标签之间

的差异。



图7.3 本

章教程中实

现的SGAN的高级

示意。生成器

将随机噪声

转换为伪样

本；鉴

别器输

入有标签的

真实图像 、无

标签的真实

图像 和生成

器生成的伪

图像

。为了区

分真实样本

和伪样本，鉴

别器使用了

sigmoid函数；为了区

分真实标



签

的分类，鉴别

器使用了softmax函

数

为了输出

样本是真还

是假的概率

，鉴别器使用

了sigmoid激活函



数

，并通过反向

传播二元交

叉熵损失来

训练其参数

，这与第3章和

第4

章中实现

的GAN相同。



7.2.2 实现



你可能会注

意到，本书许

多SGAN实现都是

从第4章的DCGAN模

型改



编而来

的。这并不是

出于懒惰（嗯

，也许是有一

点……），而是为了

更好地了解

SGAN所需的不同

修改，且不会

干扰到网络

无关部分中

的实

现细节

。



本书Github仓库（https://Github.com/ GAN-in-Action/GAN-in￾action）中

的第7章文件

夹提供了完

整实现的Jupyter

Notebook，其

中



包括训练

进度的可视

化等信息。代

码是用Python3.6.0、Keras2.1.6和

TensorFlow1.8.0版

本测试的。为

了加快训练

时间，我们建

议你在GPU



上运

行模型。

7.2.3 设置

首先导入运

行模型需要

的所有模块

和库，如清单

7.1所示。

清单7.1 导

入声明



%matplotlib

inline



import matplotlib.pyplot

as plt



import

numpy as np

from keras import backend

as K



from

keras.datasets import mnist

from keras.layers import (Activation,

BatchNormalization,



Concatenate, Dense,

Dropout, Flatten, Input, Lambda,

Reshape)



from keras.layers.advanced_activations

import LeakyReLU



from

keras.layers.convolutional import Conv2D,

Conv2DTranspose



from keras.models

import Model,



Sequential

from keras.optimizers import Adam

from keras.utils import to_categorical

指定

输入图像的

大小、噪声向

量 的大小以

及半监督分

类的真实类

别的数量（鉴

别器将学习

识别每个数

字对应的类

），如清单7.2所示

。

清单7.2 模型输

入维度



img_rows

= 28



img_cols

= 28



channels

= 1



img_shape

= (img_rows, img_cols,

channels) ←--- 输入

图像的维度

z_dim

= 100 ←---

噪声向量的

大小，用作生

成器的输入

num_classes = 10

←---



数据集中类

别的数量

7.2.4 数

据集



尽管MNIST训

练数据集里

有50000个有标签

的训练图像

，但我们仅

将

其中的一小

部分（由num_labeled参数

决定）用于训

练，并假设



其

余图像都是

无标签的。我

们这样来实

现这一点：取

批量有标签

数据

时仅从

前num_labeled个图像采

样，而在取批

量无标签数

据时从其



余

（50000 –

num_labeled）个图像中采

样。



Dataset对象（清单

7.3）提供了返回

所有num_labeled训练样

本及其标签

的函数，以及

能返回MNIST数据

集中所有10000个

带标签的

测

试图像的函

数。训练后，我

们将使用测

试集来评估

模型的分类

在多



大程度

上可以推广

到以前未见

过的样本。

清

单7.3 用于训练

和测试的数

据集



class

Dataset:



def __init__(self,

num_labeled):



self.num_labeled =

num_labeled ←---



训练中

使用的有标

签

图像的数

量



(self.x_train, self.y_train),

(self.x_test, ←---



加

载MINST数据

集



self.y_test) =

mnist.load_data()



def preprocess_imgs(x):

x = (x.astype(np.float32) -

127.5) / 127.5 ←---

灰度像素

值从[0, 255]缩放到

[–1, 1]

x = np.expand_dims(x, axis=3)

←--- 将图像尺寸

扩



展到宽×高

×通道数

return x



def

preprocess_labels(y):



return y.reshape(-1,

1)



self.x_train =

preprocess_imgs(self.x_train) ←---



训练



self.y_train = preprocess_labels(self.y_train)

self.x_test = preprocess_imgs(self.x_test) ←---

测试



self.y_test =

preprocess_labels(self.y_test)



def batch_labeled(self,

batch_size):



idx =

np.random.randint(0, self.num_labeled,



batch_size)

←--- 获取随

机批量的有

标签图像及

其标签



imgs

= self.x_train[idx]



labels

= self.y_train[idx]



return

imgs, labels



def

batch_unlabeled(self, batch_size):



idx

= np.random.randint(self.num_labeled,



self.x_train.shape[0],

←--- 获取

随机批量的

无标签图像

batch_size)

imgs = self.x_train[idx]

return imgs



def

training_set(self):



x_train =

self.x_train[range(self.num_labeled)]



y_train =

self.y_train[range(self.num_labeled)]



return x_train,

y_train



def test_set(self):

return self.x_test, self.y_test

在本教程中

，我们假设只

有100个有标签

的MNIST图像用于

训练：



num_labeled =

100 ←---



要使用

的有标签样

本的数量（其

余将作为无

标签样本

使

用）



dataset =

Dataset(num_labeled)



7.2.5 生成器

SGAN的

生成器网络

与第4章中DCGAN的

相同，如清单

7.4所示。生成



器

使用转置卷

积层将输入

的随机噪声

向量转换为

28×28×1图像。

清单7.4 SGAN生

成器



def

build_generator(z_dim):



model =

Sequential()



model.add(Dense(256 *

7 *



7,

input_dim=z_dim)) ←--- 通过一

个全连接层

改变输入为

一个7×7×256的张量



model.add(Reshape((7, 7, 256)))

model.add(Conv2DTranspose(128, kernel_size=3, strides=2,

padding='same')) ←--- 转置卷积层

，张量从7×7×256变为

14×14×128

model.add(BatchNormalization()) ←--- 批归一化

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激

活

model.add(Conv2DTranspose(64, kernel_size=3, strides=1,

padding='same')) ←--- 转置卷积

层，张量从14×14×128变

为14×14×64

model.add(BatchNormalization()) ←--- 批归一化

model.add(LeakyReLU(alpha=0.01))

←--- LeakyReLU激活



model.add(Conv2DTranspose(1,

kernel_size=3, strides=2,



padding='same'))

←--- 转置卷

积层，张量从

14×14×64变为28×28×1



model.add(Activation('tanh'))

←--- 带tanh激活

函数的输出

层



return

model



7.2.6 鉴别器

鉴

别器是SGAN模型

中最复杂的

部分，它有如

下双重目标

。



（1）区分真实样

本和伪样本

。为此，SGAN鉴别器

使用了sigmoid

函数

，输出用于二

元分类的概

率。



（2）对于真实

样本，还要对

其标签准确

分类。为此，SGAN鉴

别器

使用了

softmax函数，输出概

率向量——每个

目标类别对

应一个。



1．核心

鉴别器网络

我们先来定

义核心鉴别

器网络。清单

7.5中的模型与

第4章中实现



的基于ConvNet的鉴

别器相似。实

际上，直到3×3×128卷

积层，它的



批

归一化和LeakyReLU激

活与之前的

一直是完全

相同的。

在该

层之后添加

了一个Dropout，这是

一种正则化

技术，通过在

训练过程中

随机丢弃神

经元及其与

网络的连接

来防止过拟

合。[8] 这

就迫使

剩余的神经

元减少它们

之间的相互

依赖，并得到

对基础数据

更



一般的表

示形式。随机

丢弃的神经

元比例由比

例参数指定

，在本实现

中

将其设置为

0.5，即model.add(Dropout(0.5))。由于SGAN分类

任务的复杂

性增加，我们

使用了Dropout，以提

高模型从只

有100个有



标签

的样本中归

纳的能力。

清

单7.5 SGAN鉴别器



def

build_discriminator_net(img_shape):



model =

Sequential()



model.add( ←---

卷

积层，张量从

14×14×64变为14×14×32



Conv2D(32,

kernel_size=3,



strides=2,

input_shape=img_shape,



padding='same'))

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激活函

数

model.add( ←--- 卷积层，张

量从14×14×32变为7×7×64

Conv2D(64,



kernel_size=3,

strides=2,



input_shape=img_shape,

padding='same'))



model.add(BatchNormalization()) ←---

批

归一化



model.add(LeakyReLU(alpha=0.01)) ←---

LeakyReLU激活

函数



model.add( ←---

卷积层

，张量从7×7×64变为

3×3×128



Conv2D(128,

kernel_size=3,



strides=2,

input_shape=img_shape,



padding='same'))

model.add(BatchNormalization()) ←--- 批归一化

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激

活函数

model.add(Dropout(0.5)) ←--- Dropout

model.add(Flatten()) ←--- 将张

量展平

model.add(Dense(num_classes)) ←--- 与num_classes神

经元完全

连

接的层



return model

注意

，Dropout层是在批归

一化之后添

加的。出于这

两种技术之

间



的相互作

用，这种方法

已显示出优

越的性能。[9]

另

外，请注意前

面的网络以

一个具有10个

神经元的全

连接层结



束

。接下来，我们

需要定义从

这些神经元

计算出的两

个鉴别器输

出：

一个用于

有监督的多

分类（使用softmax），另

一个用于无

监督的二



分

类（使用sigmoid）。

2．有监

督的鉴别器

清单 7.6 的代码

采用了之前

实现的核心

鉴别器网络

，并用于构建



鉴别器模型

的有监督部

分。



清单7.6 SGAN有监

督的鉴别器



def build_discriminator_supervised(discriminator_net):



model

= Sequential()



model.add(discriminator_net)

model.add(Activation('softmax')) ←--- softmax激活函数输

出

真实类别

的预测概率

分布



return model

3．无监督

的鉴别器



清

单7.7在核心鉴

别器网络的

顶上实现了

模型的无监

督部分。注

意

，predict(x)这个函数将

10个神经元（来

自核心鉴别

器网络）的



输

出转换成一

个二分类的

真假预测。

清

单7.7 SGAN鉴别器无

监督部分



def

build_discriminator_unsupervised(discriminator_net):



model =

Sequential()



model.add(discriminator_net)

def predict(x):



prediction

= 1.0 -

(1.0 / ←--- 将

真实类别的

分布转换为

二

元真-假概

率



(K.sum(K.exp(x), axis=-1,

keepdims=True) + 1.0))

return prediction



model.add(Lambda(predict))

←--- 之前定义

的真-假输出

神经元



return

model



7.2.7 搭建

整个模型

接

下来，我们将

构建并编译

鉴别器模型

和生成器模

型（清单



7.8）。注意

，有监督损失

和无监督损

失分别使用

categorical_crossentropy和binary_crossentropy损失函

数

。



清单7.8 构建模

型

def build_gan(generator, discriminator):

model = Sequential()

model.add(generator) ←--- 合并生成

器模型和鉴

别器模型

model.add(discriminator)



return model

discriminator_net = build_discriminator_net(img_shape) ←---

核

心鉴别器网

络：这些层在

有监督和无

监督训练中

共享



discriminator_supervised =

build_discriminator_supervised(discriminator_net) ←---



discriminator_supervised.compile(loss='categorical_crossentropy',

metrics=['accuracy'],



optimizer=Adam()) ←---

构建并

编译有监督

训练鉴别器

discriminator_unsupervised = build_discriminator_unsupervised(

←---



discriminator_net)

discriminator_unsupervised.compile(loss='binary_crossentropy',



optimizer=Adam()) ←--

- 构建并编译

无监督训练

鉴别器



generator

= build_generator(z_dim) ←---

构建

生成器



discriminator_unsupervised.trainable =

False ←---



生成

器训练时，

鉴

别器参数保

持不变



gan =

build_gan(generator, discriminator_unsupervised)



←---

gan.compile(loss='binary_crossentropy', optimizer=Adam()) ←---

构建

并编译鉴别

器固定的GAN模

型，以训练生

成器。注意：鉴

别器使用无

监督版本



7.2.8 训

练

以下伪代

码概述了SGAN的

训练算法。



SGAN训

练算法

对每

次训练迭代

，执行以下操

作。



（1）训练鉴别

器（有监督）。

a．随

机取小批量

有标签的真

实样本 。



b．计算

给定小批量

的

并反向传

播多分类损

失更



新 ，以使

损失最小化

。

（2）训练鉴别器

（无监督）。



a．随机

取小批量无

标签的真实

样本 。

b．计算给

定小批量的

)并反向传播

二元分类损

失更



新 ，以使

损失最小化

。

c．随机取小批

量的随机噪

声 生成一小

批量伪样本

：



。

d．计算给定小

批量的 并反

向传播二元

分类损失更

新 以使损失

最小化。

（3）训练

生成器。



a．随机

取小批量的

随机噪声 生

成一小批量

伪样本：

。



b．计算

给定小批量

的 并反向传

播二元分类

损失更

新 以

使损失最大

化。



结束

清单

7.9实现了SGAN的训

练算法。



清单

7.9 SGAN的训练算法



supervised_losses = []

iteration_checkpoints = []

def train(iterations, batch_size, sample_interval):

real = np.ones((batch_size, 1))

←--- 真实图像的

标签：全为1



fake

= np.zeros((batch_size, 1))

←--- 伪

图像的标签

：全为0



for

iteration in range(iterations):

imgs, labels = dataset.batch_labeled(batch_size)

←--



- 获取有

标签样本

labels = to_categorical(labels, num_classes=num_classes)

←--- 独

热编码标签

imgs_unlabeled =

dataset.batch_unlabeled(batch_size)



←--- 获取无标签

样本

z = np.random.normal(0, 1,

(batch_size, z_dim)) ←---

生成一

批伪图像



gen_imgs =

generator.predict(z)



d_loss_supervised,

accuracy =



discriminator_supervised.train_on_batch(imgs,

labels) ←--- 训

练有标签的

真实样本

d_loss_real = discriminator_unsupervised.train_on_batch(

←--- 训

练无标签的

真实样本



imgs_unlabeled,

real)



d_loss_fake =

discriminator_unsupervised.train_on_batch(gen_imgs, fake) ←---

训

练伪样本



d_loss_unsupervised =

0.5 *



np.add(d_loss_real,

d_loss_fake)



z =

np.random.normal(0, 1,



(batch_size,

z_dim)) ←---



生

成一批伪样

本

gen_imgs = generator.predict(z)

g_loss = gan.train_on_batch(z, np.ones((batch_size,

1)))



←--- 训练生成

器

if (iteration + 1)

% sample_interval == 0:

supervised_losses.append(d_loss_supervised) ←--



-

iteration_checkpoints.append(iteration + 1) ←--

- 保存鉴别

器的有监督

分类损失，以

便绘制损失

曲线



print(

←--- 输出训

练过程



"%d

[D loss supervised:

%.4f, acc.: %.2f%%] [D

loss" +



"

unsupervised: %.4f] [G

loss: %f]"



%

(iteration + 1,

d_loss_supervised, 100 *

accuracy,



(d_loss_unsupervised, g_loss))

1．训练

模型



之所以

使用较小的

批量，是因为

只有100个有标

签的训练样

本。我

们通过

反复试验确

定迭代次数

：不断增加次

数，直到鉴别

器的有监督

损失趋于平

稳，但不要超

过稳定点太

远（以降低过

拟合的风险

）。训



练模型的

代码如清单

7.10所示。

清单7.10 训

练模型



iterations

= 8000 ←---

设置

超参数



batch_size =

32



sample_interval =

800



train(iterations, batch_size,

sample_interval) ←---



按照

指定的

迭代

次数训练SGAN



2．模

型训练和测

试准确率

现

在，让我们看

看SGAN作为分类

器的表现吧

！在训练过程

中，



SGAN达到了100%的

有监督准确

率。尽管这看

似很好，但请

记住只有100

个

有标签的样

本用于有监

督训练——也许

模型只是记

住了训练数

据



集。分类器

能在多大程

度上泛化到

训练集中未

见过的数据

上才是重要

的，如清单7.11所

示。

清单7.11 测试

准确率



x,

y = dataset.test_set()

y = to_categorical(y, num_classes=num_classes)

_, accuracy = discriminator_supervised.evaluate(x,

y) ←--- 在

测

试集上计算

分类准确率

print("Test Accuracy: %.2f%%"

%



(100 *

accuracy))



请尽情欢呼

吧！SGAN能够准确

分类测试集

中大约89%的样

本。为了

解这

有多了不起

，我们对比一

下SGAN和全监督

分类器的性

能。



7.3 与全监督

分类器的对

比

为了使比

较尽可能公

平，我们让全

监督分类器

使用与训练

有监督



鉴别

器相同的网

络结构，如清

单7.12所示。这样

做的意图在

于，这将

能突

显出半监督

学习GAN对分类

器泛化能力

的提高。



清单

7.12 全监督分类

器

mnist_classifier = build_discriminator_supervised(

build_discriminator_net(img_shape))



←--- 有着与SGAN鉴

别器相同网

络结构的全

监督分类器



mnist_classifier.compile(loss='categorical_crossentropy',



metrics=['accuracy'],

optimizer=Adam())



我们用和训

练SGAN相同的100个

样本来训练

全监督分类

器。为简洁

起

见，此处不显

示训练代码

和输出训练

和测试准确

率的代码。你

可以



在Github仓库

中第7章文件

夹下的SGAN Jupyter

Notebook中找

到相关



代码

。

与SGAN的鉴别器

一样，全监督

分类器在训

练数据集上

达到了100%



的准

确率。但是在

测试集上它

只能正确分

类大约70%的样

本，比SGAN差

了约

20个百分点。换

句话说，SGAN将训

练准确率提

高了近30个百

分



点！

随着训

练数据的增

加，全监督分

类器的泛化

能力显著提

高。使用



相同

的设置和训

练，使用10000个有

标签样本（是

最初使用样

本的100

倍）训练

的全监督分

类器，可以达

到约98%的准确

率，不过这不

是半



监督学

习。

7.4 结论



在本

章中，我们通

过教鉴别器

输出真实样

本的类别标

签，来探索

如

何把GAN用于半

监督学习。你

可以看到，经

过SGAN训练的分

类器从少



量

训练样本中

泛化的能力

明显优于全

监督分类器

。

从GAN创新的角

度来看，SGAN的主

要特点是在

鉴别器训练

中使用标



签

。你可能想知

道标签是否

也可以用于

生成器训练

，那就应该问

问第

8 章中的

GAN 变体（条件GAN）了

。

7.5 小结



（1）半监督

生成对抗网

络（SGAN）的鉴别器

可用来：区分

真实样

本与

伪样本；给真

实样本分配

正确的类别

标签。



（2）SGAN 的目的

是将鉴别器

训练成一个

分类器，使之

可以从尽

可

能少的有标

签样本中获

得更高的分

类精度，从而

减少分类任

务对大



量标

注数据的依

赖性。

（3）在本章

的实现中，我

们将 softmax 和多元

交叉熵损失

用于

分配真

实标签的有

监督任务，将

sigmoid和二元交叉

熵用于区分

真实



样本和

伪样本。

（4）我们

证明了SGAN对没

见过的测试

集数据的分

类准确率远

远优



于在相

同数量的有

标签样本上

训练的全监

督分类器。

[1] 引

自微软学术

（MA）搜索引擎的

一份跟踪报

告，另见 Top 20

Research Papers on Machine

Learning and Deep Learning,

by



Thuy T.

Pham, 2017.



[2]

The Data That

Transformed AI Research—and Possibly

the



World, by

Dave Gershgorn,



2017.

[3] What Artificial Intelligence

Can and Can’t Do

Right



Now, by

Andrew Ng,



2016.

[4] What AI Can

and Can’t Do (Yet)

for Your Business, by

Michael Chui et al.,

2018.



[5] Improved

Techniques for



Training

GANs, by Ian

Goodfellow



et al.,

2016.



[6] Densely

Connected Convolutional



Networks,

by Gao Huang

et al., 2016.

[7] Improved Techniques for

Training GANs, by Tim

Salimans



et al.,

2016.



[8] Improving

Neural Networks



by

Preventing Co-Adaptation of

Feature Detectors,by Geoffrey E.

Hinton et al., 2012.

另见

Dropout: A Simple

Way



to Prevent

Neural Networks



from

Overfitting,by Nitish Srivastava et

al., 2014, Journal of

Machine Learning Research 15,

1929–1958.



[9] Understanding

the Disharmony



between

Dropout and Batch

Normalization by Variance Shift,

by Xiang Li et

al., 2018.



第8章

条件生

成对抗网络

（CGAN）



本章主要内

容

使用标签

训练生成器

和鉴别器



教

GAN生成与指定

标签匹配的

样本

训练条

件生成对抗

网络（CGAN）生成手

写数字



我们

在第7章介绍

了SGAN，由此引入

了在GAN训练中

使用标签的

想

法。GAN使用标

签将鉴别器

训练为功能

强大的半监

督分类器。本

章将介



绍条

件生成对抗

网络（Conditional GAN，CGAN）——它使用

标签来训

练

生成器和鉴

别器。正是由

于这项创新

，CGAN才能够引导

生成器合成

我们想要的

伪样本。



8.1

动机

无论是简单

的手写数字

还是逼真的

人脸，GAN都可以

生成其样本

图



像。虽然可

以通过选择

训练数据集

来控制GAN模拟

的样本的域

，但我们

不能

指定所GAN生成

样本的任何

特征。比如，在

第4章中实现

的DCGAN可



以合成

逼真的手写

数字，但我们

无法控制它

是否会在任

何给定时间

生

成数字7而

不是9。



对于MNIST这

样的简单数

据集，样本只

可能属于10个

类中的一个

，

这种担心可

能影响甚微

。如果目标是

生成数字9，则

可以继续生

成样本



直至

得到想要的

数字。但在更

复杂的数据

生成任务上

，可能的答案

范

围太大，这

种蛮力解决

的方案不太

实用。以生成

人脸的任务

为例，尽



管第

6章中的PGGAN生成

的图像令人

印象深刻，但

无法控制要

生成什么

样

的人脸——无法

指导生成器

合成男性面

孔还是女性

面孔，更不用

说



年龄或面

部表情等其

他特征了。

决

定将生成何

种数据的能

力为众多应

用打开了大

门。举个有点

刻



意的例子

，假设有一个

侦探正在破

解一桩神秘

谋杀案，根据

目击者描

述

凶手是一个

有着红色长

发和绿色眼

睛的中年妇

女。如果不雇

用素描



画家

（一次只能画

一幅素描），而

是将描述性

特征输入计

算机程序并

使之输出一

系列符合条

件的人脸图

像，证人可以

指出里面最

像罪犯的

那

一个，这样将

大大加快破

案过程。



你可

能会想到许

多其他的实

际应用，对于

这些应用，能

生成符合

选

择标准的图

像的能力将

颠覆行业规

则：在医学研

究中，可以指

导新



药的开

发；在电影制

作和计算机

图像合成（CGI）中

，可以用最少

的人

工动画

输入来创建

想要的精确

场景……这样的

例子不胜枚

举。



CGAN是最早使

目标数据生

成成为可能

的GAN创新之一

，可以说是最

具影响力的

一种。接下来

，我们将介绍

CGAN的工作方式

以及如何用



MNIST数据集实现

它的小规模

版本。



8.2 什么是

CGAN

CGAN是由加拿大

蒙特利尔大

学的博士生

Mehdi Mirza和Flickr的AI



架构师

Simon

Osindero于2014年推出的

一个生成对

抗网络，其生

成器



和鉴别

器在训练过

程中受到一

些附加信息

的制约。[1] 从理

论上讲，

这里

所谓的“附加

信息”可以是

任何东西，例

如一个类标

签、一组标



签

甚至是书面

描述。为简单

起见，我们在

解释CGAN的工作

原理时将标

签用作条件

信息。

在CGAN训练

期间，生成器

学习为训练

数据集中的

每个标签生

成逼



真的样

本，而鉴别器

则学习区分

真的样本-标

签对与假的

样本-标签

对

。半监督GAN的鉴

别器除了区

分真实样本

与伪样本，还

为每个真实

样



本分配正

确的标签；而

CGAN中的鉴别器

不会学习识

别哪个样本

是哪个

类。它

只学习接受

真实的且样

本-标签匹配

正确的对，拒

绝不匹配的

对



和样本为

假的对。

例如

，无论样本（手

写数字3）是真

还是假，CGAN鉴别

器都应拒绝

该样本-标签

对( ，4)，因为样本

与标签4不匹

配。CGAN鉴别器还

应该

拒绝所

有图像为假

的样本-标签

对，即使标签

与图像匹配

。



因此，为了欺

骗鉴别器，CGAN生

成器仅生成

逼真的数据

是不够

的，生

成的样本还

需要与标签

相匹配。在对

生成器进行

充分训练之

后，就可以通

过传递所需

的标签来指

定希望CGAN合成

的样本。



8.2.1

CGAN的生

成器



为规范

起见，我们把

条件标签称

为 ，生成器使

用噪声向量

和标

签 合成

一个伪样本

（读作“给定 或

以

为条件时

的



”）。这个伪样

本的目的是

（在鉴别器的

眼中）看起来

尽可能接近

给

定标签的

真实样本。CGAN的

生成器的架

构如图8.1所示

。



图8.1 CGAN生成器：

。生

成器输入随

机噪声向量

和标签



，生

成

一个与标签

匹配的逼真

伪样本



8.2.2 CGAN的鉴

别器

鉴别器

接收带标签

的真实样本

，以及带有（用

于生成自己

的）标签的伪

样本 。在真实

样本-标签对

上，鉴别器学

习如何

识别

真实数据以

及如何识别

匹配对。在生

成器生成的

样本中，鉴别

器



学习识别

伪样本-标签

对，以将它们

与真实样本

-标签对区分

开来。

鉴别器

输出表明输

入是真实的

匹配对的概

率。它的目标

是学会接



收

所有真实样

本-标签对，并

拒绝所有伪

样本和所有

与标签不匹

配的样

本，如

图8.2所示。



图8.2 CGAN的

鉴别器输入

真实样本和

它们的标签

，以及伪样本

和用于合成



它们的标签

。鉴别器输出

一个表示输

入真伪的概

率（σ 由sigmoid激活



函

数计算）

8.2.3 汇总

表



表8.1总结了

CGAN的两个子网

络的输入、输

出和目标。

表

8.1 CGAN的生成器和

鉴别器网络

生成器 鉴别

器

输



入

一个

随机数向量

和一个标签

：



鉴别器的输

入：

训练数据

集中带标签

的真实样本

为与给定标

签匹配，生成

器生成的带

标



签的伪样

本

输



出

力求

与标签匹配

的伪样本： 表

示输入样本

是否为匹配

的真实样本

-标签对



的概

率

目



标

生成

与标签匹配

的逼真的伪

样



本

区分来

自生成器的

伪样本-标签

对和来自训

练



数据集的

真实样本-标

签对

8.2.4 架构图

CGAN的高层次架

构图示意如

图8.3所示。注意

，对于每个伪

样本，

相同的

标签 同时被

传递给生成

器和鉴别器

。另外，通过在

带有不匹配

标签的真实

样本上训练

鉴别器来拒

绝不匹配的

对；它识别不

匹配对的

能

力是被训练

成只接收真

实匹配对时

的副产品。



图

8.3 CGAN生成器使用

随机噪声向

量

和标签 （



个

可能的标签

之一）作为输



入，并力图生

成既逼真又

能匹配标签

的伪样本



注

意

读者可能

已经注意到

了，本书对于

每种GAN变体，几

乎都会提供

一



个汇总了

鉴别器网络

和生成器网

络的输入、输

出和目标的

表格，以及

网

络架构图。这

不是偶然的

，实际上，这些

章节的主要

目标之一是

为



读者提供

一种思考的

模板——或者说

可重用的框

架。当遇到与

原始GAN

不同的

GAN实现时，读者

可以按框架

来探索。最好

的第一步通

常是分析



生

成器和鉴别

器网络以及

整个模型架

构。

CGAN鉴别器接

收生成器生

成的假的带

标签的样本

和真的



带标

签的样本 ，并

学会分辨给

定样本-标签

对的真假。

理

论足够了，现

在是时候将

所学的知识

付诸实践，实

现自己的



CGAN模

型了！

8.3 教程：CGAN的

实现



我们将

实现一个CGAN模

型，使之学习

生成想要的

手写数字。在

教

程最后，我

们将为每类

数字生成图

像样本，以了

解模型学习

生成目标



数

据的能力。

8.3.1 实

现



本实现受

到Keras-GAN模型的开

源Github仓库中CGAN的

启发（和在

第

3和第4章中使

用的相同）。[2] 特

别要说明，我

们用了开源

模型中



利用

Embedding层将样本和

标签合并到

联合隐藏表

示中的方法

（稍后

会对此

进行更多介

绍）。



但是CGAN模型

的其他部分

与Keras-GAN仓库中的

有所不同。我

们对

嵌入实

现进行了重

构，使其更具

可读性，还添

加了详细的

解释性注



释

。还有一个关

键点是在CGAN中

用了卷积神

经网络，以生

成更为逼真

的样本——回顾

第3章中的GAN和

第4章中的DCGAN生

成的图像之

间的区

别！



配

套资料第8章

文件夹下的

Jupyter Notebook有完整的代

码实现，

包括

训练进度等

可视化信息

。代码是用Python3.6.0、Keras2.1.6和

TensorFlow1.8.0版本测试的

。要缩短训练

时间，读者应

在GPU上运行



模

型。

8.3.2 设置



首先

导入模型需

要的所有模

块和库，如清

单8.1所示。

清单

8.1 导入声明



%matplotlib

inline



import matplotlib.pyplot

as plt



import

numpy as np

from keras.datasets import mnist

from keras.layers import (

Activation, BatchNormalization, Concatenate, Dense,

Embedding, Flatten, Input, Multiply,

Reshape)



from keras.layers.advanced_activations

import LeakyReLU



from

keras.layers.convolutional import Conv2D,

Conv2DTranspose



from keras.models

import Model,



Sequential

from keras.optimizers import Adam

指

定输入图像

的大小，噪声

向量 的大小

以及数据集

中类的数量

，



如清单8.2所示

。

清单8.2 模型的

输入维度



img_rows

= 28



img_cols

= 28



channels

= 1



img_shape

= (img_rows, img_cols,

channels) ←--- 输

入图像维度

z_dim

= 100 ←---

噪声向量的

大小，用作生

成器的输入

num_classes = 10

←---



数据集中的

类别数

8.3.3 CGAN的生

成器



我们在

本节实现CGAN的

生成器。读者

应该已经从

第4章和第7章

熟

悉了关于

生成器的大

部分内容。对

于CGAN的修改围

绕输入处理

进行，



这里我

们使用嵌入

和逐元素乘

法（element-wise multiplication）将

随机噪

声向量 和标

签 组合成一

个联合表示

，具体如下。

（1）使

用Keras的Embedding层将标

签 （0到9的整数

）转换为



大小

为z_dim（随机噪声

向量的长度

）的稠密向量

。

（2）使用Keras的Multiply层将

标签与噪声

向量 嵌入联

合表示



中。顾

名思义，该层

将两个等长

向量的对应

项相乘，并输

出作为结果



乘积的单个

向量。



（3）将得到

的向量作为

输入，保留CGAN生

成器网络的

其余部分以

合成图像。

图

8.4以标签7为例

说明了这个

过程。



图8.4 将条

件标签（在此

例中为7）和随

机噪声向量

合并为一个

联合表示的

过程

首先，将

标签嵌入与

大小相同的

向量中；其次

，将嵌入标签

和



的对应元

素相乘（符号

表示按元素

相乘）；最后，将

所得的联合

表

示用作CGAN生

成器网络的

输入。



清单8.3展

示了Python /

Keras代码中

的所有内容

。



清单8.3 CGAN的生成

器

def build_generator(z_dim):



model

= Sequential()



model.add(Dense(256

* 7 *

7, input_dim=z_dim)) ←--- 通过

全连

接层将输入

变为7×7×256的张量

model.add(Reshape((7, 7, 256)))

model.add(Conv2DTranspose(128, kernel_size=3, strides=2,

padding='same')) ←--- 转置卷积层

，张量从7×7×256变为

14×14×128

model.add(BatchNormalization()) ←--- 批归一化

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激

活

model.add(Conv2DTranspose(64, kernel_size=3, strides=1,

padding='same')) ←--- 转置卷积

层，张量从14×14×128变

为14×14×64

model.add(BatchNormalization()) ←--- 批归一化

model.add(LeakyReLU(alpha=0.01))

←--- LeakyReLU激活



model.add(Conv2DTranspose(1,

kernel_size=3, strides=2,



padding='same'))

←--- 转置卷

积层，张量从

14×14×64变为28×28×1



model.add(Activation('tanh'))

←--- 带tanh激活

的输出层



return

model



def build_cgan_generator(z_dim):

z = Input(shape=(z_dim, ))

←--- 随

机噪声z



label

= Input(shape=(1, ),

dtype='int32') ←--- 条件

标签：G

应该生

成的指定数

字，整数0～9



label_embedding =

Embedding(num_classes, z_dim,



input_length=1)(label)

←--- 标签

嵌入：将标签

转化为大小

为z_dim的稠密



向

量；生成形状

为(z_dim,

batch_size, 1)的三维张

量



label_embedding

= Flatten()(label_embedding) ←---

将嵌入



的

三维张量展

平成形状为

(batch_size，z_dim)的二维张量

joined_representation

= Multiply()([z, label_embedding])

←--- 向量z和嵌入

标签的元素

级乘积



generator

= build_generator(z_dim)



conditioned_img

= generator(joined_representation) ←---

为给

定的标签生

成图像



return Model([z,

label], conditioned_img)



8.3.4

CGAN的鉴

别器



接下来

，我们实现CGAN的

鉴别器。就像

在8.3.3节中所做

的一样，

除了

要处理输入

图像及其标

签的那部分

内容，网络架

构应该看起

来很



熟悉。这

里也使用Keras的

Embedding层将输入标

签转换为稠

密向

量。但与

生成器输入

是平面向量

不同，鉴别器

输入是三维

图像。这需



要

用到特定的

处理方法，步

骤如下。

（1）取一

个标签（0到9的

整数），使用Keras的

Embedding层将



标签变

成大小为28 ×

28 ×



1

= 784（扁

平化图像的

长度）的稠密

向



量。

（2）将嵌入

标签调整为

图像尺寸（28 × 28 ×

1）。



（3）将

重塑后的嵌

入标签连接

到对应图像

上，生成形状

（28 ×

28 × 2）的联合表示

。可以将其视

为在顶部“贴

有”嵌入标签

的图

像。



（4）将图

像-标签的联

合表示输入

CGAN的鉴别器网

络中。注意，

为

了训练正常

进行，必须将

模型输入尺

寸调整为（28 × 28 ×

2）来

对应新的输

入形状。



以标

签7为例展示

该过程，如图

8.5所示。

图8.5 将标

签（此例中为

7）和输入图像

组合成一个

联合表示的

过程



综上所

述，首先，将标

签嵌入具有

扁平化图像

大小的向量

中（28

× 28 × 1

= 784）；其次，将嵌

入标签调整

为与输入图

像形状相同

的张量（28 ×

28 ×



1）；再次

，将重塑后的

嵌入标签和

对应的图像



连接到一起

。最后，将这个

联合表示输

入CGAN的鉴别器

网络中。



除了

预处理，与第

4章相比，我们

还需要对鉴

别器网络进

行一些其

他

的调整。（与第

7章一样，基于

DCGAN的实现会更

容易看到变

为CGAN



模型要特

定更改的部

分，而不会受

不相关部分

实现细节的

干扰。）首

先，将

模式输入尺

寸调整为（28 × 28 ×

2），以

对应新的输

入形



状；其次

，将第一个卷

积层的深度

从32增加到64，之

所以发生这

一变

化，是因

为嵌入了联

合标签，有更

多的信息要

编码。这种网

络架构在



实

验中确实产

生了更好的

结果。

输出层

使用sigmoid激活函

数来得到输

入图像-标签

对是真的而

不



是假的概

率（此处没有

变化）。清单8.4实

现了CGAN的鉴别

器。

清单8.4 CGAN的鉴

别器



def

build_discriminator(img_shape):



model =

Sequential()



model.add( ←---

卷积层

，从28×28×2变为14×14×64的张

量



Conv2D(64,

kernel_size=3,



strides=2,

input_shape=(img_shape[0], img_shape[1],



img_shape[2]

+ 1),



padding='same'))

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激活函数

model.add(

←--- 卷积层，从14×14×64变

为7×7×64的张量



Conv2D(64,

kernel_size=3,



strides=2,

input_shape=img_shape,



padding='same'))

model.add(BatchNormalization()) ←--- 批

归一化

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激活

函数

model.add( ←--- 卷积层

，从7×7×64变为3×3×128的张

量

Conv2D(128,



kernel_size=3,

strides=2,



input_shape=img_shape,

padding='same'))



model.add(BatchNormalization()) ←---

批归一化

model.add(LeakyReLU(alpha=0.01)) ←--- LeakyReLU激活函数

model.add(Flatten()) ←--- 带

sigmoid激活函数的

输出层

model.add(Dense(1, activation='sigmoid'))



return

model



def build_cgan_discriminator(img_shape):

img = Input(shape=img_shape) ←---

输入

图像



label =

Input(shape=(1, ),



dtype='int32')

←--- 为输入

图像



加标签



label_embedding = Embedding(num_classes, ←---

标签嵌入：将

标签转化为

大小为z_dim的稠

密向量;生成

形状为(batch_size, 1, 28×28×1)的三

维

张量



np.prod(img_shape),

input_length=1)(label)



label_embedding =

Flatten()(label_embedding) ←---



将嵌

入

的三维张

量展平成形

状为(batch_size, 28×28×1)的二维

张量



label_embedding

= Reshape(img_shape)(label_embedding) ←--

- 将嵌入

标签调整为

和输入图像

一样的维度

concatenated =

Concatenate(axis=-1)([img, label_embedding])



←---

将图像与其

嵌入标签连

接



discriminator =

build_discriminator(img_shape)



classification =

discriminator(concatenated) ←---



对图像-

标

签对进行分

类



return Model([img,

label], classification)



8.3.5

搭建整个

模型



接下来

，我们构建并

编译CGAN的鉴别

器和生成器

模型，如清单

8.5

所示。注意，在

用于训练生

成器的组合

模型中，相同

的输入标签

将同



时传递

到生成器（生

成样本）和鉴

别器（进行预

测）。

清单8.5 构建

并编译CGAN的鉴

别器和生成

器模型



def

build_cgan(generator, discriminator):



z

= Input(shape=(z_dim, ))

←--- 随机

噪声向量z



label

= Input(shape=(1, ))

←--- 图

像标签



img

= generator([z, label])

←--- 为指

定标签生成

图像



classification

= discriminator([img, label])

model = Model([z, label],

classification) ←--- 结合生

成器

- >鉴别器

模型G([z, label]) =

x*D(x*) = 类别

return model



discriminator

= build_cgan_discriminator(img_shape) ←---

构

建



并编译鉴

别器

discriminator.compile(loss='binary_crossentropy',



optimizer=Adam(),

metrics=['accuracy'])



generator =

build_cgan_generator(z_dim) ←---



构建生

成器

discriminator.trainable = False ←---

生成器

训练时鉴别

器参数保持

不变



cgan =

build_cgan(generator, discriminator)



←---

构建并

编译鉴别



器

固定的CGAN模型

来训练生成

器（鉴别器权

重固定）

cgan.compile(loss='binary_crossentropy', optimizer=Adam())



8.3.6

训练

对于CGAN训练算

法，每次迭代

的细节如下

。



CGAN训练算法

对

每次训练迭

代，执行如下

操作。



（1）训练鉴

别器。

a．随机取

小批量有标

签的真实样

本及其标签

。



b．计算给定小

批量的 并反

向传播二分

类损失更

新

，以使损失最

小化。



c．随机取

小批量的随

机噪声向量

和类别标签

并生成

小批

量伪样本： 。



d．计

算小批量的

并反向传播

二分类损失

更新

，以使损

失最小化。



（2）训

练生成器。

a．随

机取小批量

的随机噪声

和类别标签

生成小批量

伪样本： 。

b．计算

给定小批量

的 并反向传

播二分类损

失



更新

，以使

损失最大化

。



结束

清单8.6实

现了CGAN的训练

算法。



清单8.6 CGAN的

训练算法

accuracies = []

losses = []

def train(iterations, batch_size, sample_interval):

(X_train, y_train), (_, _)

= mnist.load_data() ←--- 加

载

MINST数据集



X_train =

X_train /



127.5

- 1. ←---

灰

度像素值从

[0, 255]缩



放到[1,

1]



X_train =

np.expand_dims(X_train, axis=3)



real

= np.ones((batch_size, 1))

←--- 真实

图像的标签

：全为1



fake

= np.zeros((batch_size, 1))

←--- 伪图像

的标签：全为

0



for

iteration in range(iterations):

idx = np.random.randint(0, X_train.shape[0],

batch_size)



←--- 生成一批量

伪样本及其

标签

imgs, labels = X_train[idx],

y_train[idx]



z =

np.random.normal(0, 1,



(batch_size,

z_dim)) ←---



生成一

批伪图像

gen_imgs = generator.predict([z, labels])

d_loss_real = discriminator.train_on_batch([imgs,

labels], real) ←--- 训

练鉴别器

d_loss_fake = discriminator.train_on_batch([gen_imgs,

labels], fake)



d_loss

= 0.5 *

np.add(d_loss_real, d_loss_fake)



z

= np.random.normal(0, 1,

(batch_size, z_dim)) ←---

生

成一批噪声

向量



labels =

np.random.randint(0, num_classes,



batch_size).reshape(-1,

1) ←--- 得到一

批随机标签

g_loss

= cgan.train_on_batch([z, labels],

real) ←---



训练生成器



if (iteration + 1)

% sample_interval == 0:

print("%d [D loss: %f,

acc.: %.2f%%] [G loss:

%f]"



% ←---

输出训练过

程



(iteration +

1, d_loss[0],



100

* d_loss[1],



g_loss))

losses.append((d_loss[0], g_loss)) ←--- 保存鉴

别

器的有监督

分类损失以

便绘制损失

曲线



accuracies.append(100 *

d_loss[1])



sample_images() ←---

输出生

成图像样本

8.3.7 输出样本图

像

你可能觉

得在第3章和

第4章中见过

下一个函数

。它被用来检

查生



成器生

成的图像的

质量是如何

随着训练的

进行而提高

的。清单8.7中的

函数确实与

此相似，但存

在一些重要

差异。

首先，它

生成的不是

随机手写数

字组成的4×4的

网格，而是2×5



的

数字网格，第

一行是1到5，第

二行是6到9。这

可以用来检

查CGAN在

学习生

成特定数字

方面的表现

。其次，使用set_title()方

法显示



每个

样本的标签

。

清单8.7 显示生

成的图像



def

sample_images(image_grid_rows=2, image_grid_columns=5):



z

= np.random.normal(0, 1,

(image_grid_rows *



image_grid_columns,

z_dim)) ←--- 随

机噪声采样

labels

= np.arange(0, 10).reshape(-1,

1) ←--- 得到图像标

签

0-9



gen_imgs =

generator.predict([z, labels])



←---

从随机噪

声



生成图像

gen_imgs

= 0.5 *

gen_imgs + 0.5 ←---

图像像素值

缩放到[0, 1]



fig,

axs = plt.subplots(image_grid_rows,

←--- 设置

图像网格



image_grid_columns,

figsize=(10, 4),



sharey=True,

sharex=True)



cnt =

0



for i

in range(image_grid_rows):



for

j in range(image_grid_columns):

axs[i, j].imshow(gen_imgs[cnt, :, :,

0],



cmap='gray') ←---

输

出图像网格

axs[i, j].axis('off')

axs[i, j].set_title("Digit: %d" %

labels[cnt])



cnt +=

1



图8.6显示了此

函数的输出

示例，说明了

在训练过程

中CGAN生成的

数

字的改进。



图

8.6 从随机噪声

开始，GCAN学习为

训练数据集

中的每个标

签生成逼真

的数字

8.3.8 训练

模型



最后让

我们运行一

下刚刚实现

的模型：

iterations = 12000 ←---

设置

超参数



batch_size =

32



sample_interval =

1000



train(iterations, batch_size,

sample_interval) ←---



训练

CGAN直

到指定迭

代次数



8.3.9 检查

输出：生成目

标数据

图8.7显

示了充分训

练后的CGAN的生

成器生成的

手写数字。在

每一



行，命令

生成器合成

一个从0到9的

不同数字。

图

8.7 每行显示为

匹配给定数

字（0到9）而生成

的图像样本

。CGAN生成器成功

学



会了生成

数据集中的

每个类

注意

，每个数字以

不同的书写

方式呈现，这

证明CGAN不仅能

生成



与训练

数据集中的

每个标签匹

配的样本，还

能捕捉到训

练数据的多

样

性。



8.4 结论

本

章介绍了如

何使用标签

来指导生成

器和鉴别器

的训练，使GAN能

生成想要的

伪样本。与DCGAN一

样，CGAN是最具影

响力的早期

GAN变体



之一，催

生了无数新

的研究方向

。

其中最具影

响力和发展

前景的也许

是使用条件

对抗网络作

为图像



到图

像转换（image- to-image

translation）问题

的通用解决

方案。



这是一

类试图将图

像从一种模

态转换为另

一种模态的

问题。图像到

图

像转换的

应用范围包

括黑白照片

着色、白天-黑

夜场景转换

以及从地图

视图合成卫

星视图。



基于

CGAN最成功的早

期实现之一

是pix2pix，它使用成

对图像（一

个

作为输入，另

一个作为标

签）来学习将

图像从一个

域转换到另

一个



域。回想

一下，无论在

理论上还是

在实践中，用

于训练CGAN的条

件信

息可能

远不止为更

复杂的用例

和场景提供

标签。例如，就

着色任务



言

，成对图像将

是黑白照片

（输入）和同一

照片的彩色

版本（标

签）。读

者会在第9章

中看到这些

示例。



这里没

有详细介绍

pix2pix，因为它发布

仅一年后就

被另一种GAN

变

体所取代，后

者不但在图

像到图像的

转换任务上

优于pix2pix的性



能

，而且不需要

成对图像。循

环一致性对

抗网络（Cycle-Consistent

Adversarial Network，CycleGAN）只需

要代表两个

域的两组图

像（例



如一组

黑白照片和

一组彩色照

片）。第8章会介

绍有关此出

色GAN变体

的内

容。



8.5 小结

（1）CGAN是GAN的

一种变体，在

训练过程中

，生成器和鉴

别器都



以附

加数据（如类

别标签）为条

件。

（2）附加信息

约束生成器

去合成特定

类型的输出

，鉴别器则仅

接



收与给定

附加信息匹

配的真实样

本。

（3）本章中的

教程实现了

一个CGAN，它用MNIST数

据集的类别

标



签作为条

件信息来生

成想要的逼

真的手写数

字。

（4）嵌入把整

数映射到具

有期望尺寸

的稠密向量

中。我们使用

嵌



入层从随

机噪声向量

和标签（用于

CGAN生成器训练

）以及从输入

图像

和标签

（用于CGAN鉴别器

训练）创建联

合隐藏表示

。



[1] Conditional

Generative Adversarial



Nets,

by Mehdi Mirza

and Simon Osindero, 2014.

[2] Erik Linder-Norén’s Keras-GAN

GitHub repository, 2017.

第9章 循环一

致性生成对

抗网络



（CycleGAN）

本章

主要内容



通

过在整个图

像上设置条

件来扩展条

件GAN

探索最强

大、最复杂的

GAN架构之一：循

环一致性生

成对抗网络

（CycleGAN）



介绍面向对

象的GAN设计及

其4个主要组

件的架构

用

CycleGAN将苹果转换

为橙子



这是

一项具有普

遍吸引力的

技术突破，似

乎谁都喜欢

把苹果变作

橙子，我们在

本章中将学

会如何实现

它！但这不是

一件容易的

事，所

以需要

至少两个鉴

别器和两个

生成器来实

现。这显然使

架构变得复

杂



了，因此本

章不得不花

更多的时间

去讨论，但至

少这是一个

开始以面

向

对象的编程

（OOP）方式思考的

好时机。



9.1 图像

到图像的转

换

第8章的结

尾涉及了GAN应

用的一个有

趣领域，即图

像到图像的

转



换。在此应

用中，GAN在视频

、静态图像甚

至风格迁移

方面都取得

了巨

大的成

功。事实上，由

于GAN几乎可以

实现一种新

的用途，它已

经走在



了许

多此类应用

的最前沿。因

其视觉特性

，较为成功的

GAN变体通常会

在YouTube和Twitter上亮相

，如果读者还

没有看过这

些视频，建议

搜

索pix2pix、CycleGAN或vid2vid来看

一下。



这种类

型的转换意

味着生成器

的输入是一

幅图片，因为

我们需要

生

成器（转换器

）从这个图像

开始——换句话

说，是将图像

从一个域



映

射到另一个

域。在此之前

，生成的潜在

向量通常是

某种程度上

有些

难以理

解的向量。现

在，我们把它

换成输入图

像。



一种很好

的思考图像

到图像转换

的方式是把

它作为特殊

情况下的

条

件GAN。在这种情

况下，我们是

以完整的图

像（而不只是

一个类）为



条

件，而这一图

像通常与输

出图像的维

数相同），然后

将其作为一

个

标签提供

给网络（第8章

）。如图9.1所示，这

一领域最早

的著名例子

之一是来自

加州大学伯

克利分校的

图像转换作

品。



（来源：Image-to-Image

Translation with Conditional

Adversarial



Networks, by

Phillip Isola.）



图9.1

条

件GAN为图像转

换提供了一

个强大的框

架，该框架应

用到许多领

域都表



现得

很好

如图9.1所

示，我们可以

进行以下任

意一种情况

的映射。



从语

义标签（例如

，原彩色图中

，在汽车应该

出现的地方

画为蓝

色，在

道路应该在

的地方上画

为紫色）到真

实街景图。



从

卫星图像到

类似于Google地图

的视图。

从白

天图像到夜

晚图像。



从黑

白照片到彩

色照片。

从轮

廓到合成的

时尚单品。



这

个想法显然

是强大且通

用的，但问题

是需要成对

的数据。从第

8

章可知，CGAN需要

标签。因为这

种情况是用

另一个图像

作为标签，



除

非映射到对

应的图像（除

了是在另一

个域，其他一

模一样），否则

映射就没有

意义。

因此，夜

晚图像需要

从与白天图

像完全相同

的位置拍摄

。时尚单



品的

轮廓需要与

训练集中另

一个域的全

彩色/合成的

单品精确匹

配。换

句话说

，在训练期间

，GAN需要访问原

始域中单品

的对应标签

。



例如，在黑白

图像转换的

例子中，通常

首先要获取

大量彩色图

像

并对所有

图像应用黑

白滤波器，这

样以后将未

修改的图像

用作一个



域

，将经过黑白

滤波器的图

像用作另一

个域。这确保

了在两个域

中有

对应的

图像。然后我

们就可以随

意使用训练

好的GAN了，但如

果没有生



成

这些“完美”配

对的简便方

法，那就不走

运了！

9.2 循环一

致性损失：再

GAN一次



加州大

学伯克利分

校团队认为

，实际上并不

需要完美的

配对。[1]

相反，只

需要完成一

个循环：从一

个域转换到

另一个域，然

后再转换



回

来。例如从一

个公园的夏

天图像（域A）转

到一个冬天

的图像（域

B），然

后又回到夏

天（域A）。现在我

们基本上创

建了一个循

环，理



想情况

下原始图像

和重构的图

像（ ）是相同的

。如果不同，则

可以

测量它

们像素级别

的损失，这样

就获得了CycleGAN的

第一个损失

：循



环一致性

损失（cycle-consistency loss），如图9.2所

示。

（来源：Jun-Yan Zhu et al.,

2017.）



图9.2 损

失是双向的

，因此不仅可

以从夏季生

成冬季的图

像，还从冬季

生成夏季

的

图像。如果G是

从A到B的生成

器，F是从B到A的

生成器，则



一

个常见的类

比是反译的

过程，将中文

句子翻译成

英文，然后再

翻译回中文

时应返回相

同的句子。如

果不同，就可

以通过第一

句话和

第三

句话的差别

来衡量循环

一致性损失

。



为了能够使

用循环一致

性损失，我们

需要有两个

生成器：一个

生

成器，从A转

换为B，称为 ，有

时简称为 ；另

一个生成器

，从B转

换为A，称

为 ，简洁起见

以 表示。从技

术上讲，有两

种损失——

前向

循环一致性

损失和后向

循环一致性

损失，由于它

们表示



和 ，你

可能会认为

它们基本相

同，但其

实是

差1的（off by one）。

9.3 对抗损

失



除了循环

一致性损失

，还有对抗损

失。生成器

的

生成每个转

换都有对应

的鉴别器 ， 有

鉴别器

。应该

这样想，在转

换到域



A时始

终在测试图

片是否看起

来真实，因此

使用 ；反之亦

然。

这和简单

架构的想法

是一样的，但

是现在由于

这两个损失

，我们



有了两

个鉴别器。不

仅要确保从

苹果到橙子

的转换看起

来真实，还要

确保从估计

的橙子到重

构的苹果的

转换看起来

也真实。回想

一下，对

抗损

失确保图像

看起来真实

，因此它仍然

是CycleGAN起作用的

关键所



在。由

此，我们把对

抗损失列为

第二位。循环

中的第一个

鉴别器尤为

重要——否则只

会得到帮助

GAN记忆重建内

容的噪声。[2]

9.4 恒

等损失



恒等

损失（identity

loss）的思路

很简单：强制

CycleGAN保留



图片的

整体颜色结

构（或温度）。为

此，我们引入

一个正则化

项，以

使图像

的色调与原

始图像保持

一致。这是一

种确保即使

在图像上应

用



了许多过

滤器仍然可

以恢复原始

图像的方法

。

这是通过将

已经在域A中

的图像输入

从B生成A的生

成器（ ）做



到的

，因为CycleGAN应该知

道它们已经

在正确的域

中。换句话说

，就

是惩罚对

图像不必要

的修改：如果

输入一个斑

马图并试图

“斑马化”



图像

，则会返回与

输入相同的

斑马图，因为

没什么需要

改变的。[3]图

9.3展

示了恒等损

失的影响。



即

使恒等损失

不是CycleGAN工作所

必需的，出于

完整性考虑

，也

应将其包

括在内。本章

的实现和CycleGAN作

者的最新实

现都包含了

它，因为根据

经验这种调

整通常会带

来更好的结

果，并且强制

实施了



看起

来合理的约

束。但即使是

CycleGAN论文本身也

只是简单地

提到这

一点

——似乎是事后

证明，因此这

里不再赘述

。



输入 没有恒

等损失

有恒

等损失



图9.3 一

个图像胜过

千言万语——此

图展示了恒

等损失的影

响：在没有恒

等损失

时有

明显的色调

改变，而且似

乎找不到发

生这种变化

的原因，因此

应该惩罚这

种



行为。即使

图为黑白的

，也能够看出

区别

表9.1总结

了本章中提

到的损失。



表

9.1 损失

计算 测

量 确保

计算

测量 确保



对

抗

损失



（这就

是第5章中介

绍的NS-GAN）

损失包

括两个方面

：一



是给定图

像是真实图

像

而不是转

换图像的可

能



性；二是生

成器可能欺

骗鉴别器的

部分。注

意，该

公式仅适用

于



，等价的 进

入最

终损失

转换后的



图

像看起

来真

实、



清晰，与

真

实图像



别无

二致

循环



一

致

性损



失：

前

向



传播

和 间

的差异



（定义

为

）



原始域图

像 与两次转



换后的图像

的差异



原始

图像

和两次

转



换后的图

是相同

的。如

果



失败，可

能

没有连



贯的

映射

A-B-A



计算 测

量

确保



循环

一致

性损



失

：

后向



传播

原

始域图像 与

两次转



换后

的图像

的差

异



原始图像

和两次转

换

后的图



是相

同

的。如果



失

败，可

能没有

连



贯的映射

B-A-B

总损



失

所有

4个损失结合

在一



起：对抗

损失×2（因

为有

两个生成器

），加



上循环一

致性损失（前

向和后向合

为一项）

整个

转换



是逼真

且

有意义的

（提供匹



配的

图

片）



恒等

损

失



B中图像与

)之间

的差异

，反之亦然



CycleGAN

只

修改图



像需

要改

变的部

分



a. 有些人可

能不熟悉这

个符号，它代

表两个项之

间的L1范数。为



简单起见，我

们可以将其

视为每个像

素与重构图

像上对应像

素之间的



绝

对差异。

9.5 架构

CycleGAN直接基于CGAN架

构构建，本质

上是两个CGAN结

合在一

起，或

者正如CycleGAN作者

指出的那样

，是一个自编

码器。回顾第

2



章，有一个输

入图像 和重

建图像

，这是

通过潜在空

间 重建的结

果



（图9.4）。

为了将

图9.4转化为CycleGAN的

示意图，我们

令 是域A中的

图像，



是域B中

的图像，

是重

构域 A 中的图

像。但是，在CycleGAN中

处理

的是等

维的潜在空

间（步骤2），它恰

好是CycleGAN必须找

到的另一个

有意义的域

（B）。即便使用自

编码器，潜在

空间也只是

另一个域，尽

管这不太容

易解释。

图9.4 在

这幅来自第

2章的自编码

器的图中，我

们使用了这

样的类比：将

人类概



念压

缩（步骤1）成更

紧凑的书面

形式的字母

（步骤2），然后把

这一概念扩

展成

其他人

头脑中相同

概念的（不完

美）理解（步骤

3）



与第2章相比

，主要的新概

念是引入了

对抗损失。这

些与许多其

他

自编码器

和GAN的混合模

型本身就是

一个活跃的

研究领域！因

此对于感



兴

趣的研究人

员来说，这也

是一个不错

的领域。但是

现在，我们将

这

两个映射

视为两个自

编码器： 和 。我

们采用自编

码器的

基本

思想（包括一

种用循环一

致性损失代

替的显式损

失函数），并在

此基础上增

加鉴别器。这

两个鉴别器

，每一步使用

一个，确保两

个转



换（包括

到潜在空间

的）在各自的

域中看起来

像真实图像

。

9.5.1 CycleGAN架构：构建网

络



在进入CycleGAN的

实现之前，我

们先简要地

看一下图9.5

所

示的



整体简

化实现，其中

有两个流程

——上半部分，流

程A-B-A从域A中的

图像开始；下

半部分，流程

B-A-B从域B中的图

像开始。

（来源

：Understanding and Implementing CycleGAN

in TensorFlow, by

Hardik Bansal and Archit

Rathore, 2017.）



图9.5

CycleGAN的简化架

构中，输入图

像要么进入

鉴别器进行

评估，要么转

换到



一个域

，并由另一个

鉴别器评估

后再转换回

来

图像遵循

两条路径：其

一，输入图像

进入鉴别器

，以判断是否

真



实；其二，输

入图像进入

生成器，转换

为B，然后由鉴

别器B评估，看

它在域B中看

起来是否真

实，并最终转

换回A来测量

循环一致性

损失。

下半部

分基本是上

半部分图像

的一个差1（off-by-one）循

环，



并且遵循

所有相同的

基本步骤。我

们将使用apple2orange数

据集，也

可以

使用其他的

，比如著名的

horse2zebra数据集，对代

码稍作修改

并



使用提供

的bash脚本下载

数据，即可轻

松使用。

为了

更清楚地总

结图9.5，我们在

表9.2中给出了

所有4个主要

的网



络。

表9.2 网

络



输入

输出

目标



生成

器

：



从A到B

真实的

A或从B到A的转

换 转换到域

B



生成在域B中

逼真的图

像

生成



器：

从B到

A



真实的B或从

B到A的转换 转

换到域A

生成

在域A中逼真

的图



像

鉴别

器



A

域A中的图

像，转换的或

者是真



实的

图像是真实

的概

率



不被

从B到A的生成

器

欺骗



鉴别

器

B



域B中的图

像，转换的或

者是真

实的

图像是真实

的概



率

不被

从A到B的生成

器



欺骗

9.5.2 生成

器架构



图

9.6 显

示了生成器

的架构。通过

使用代码中

的变量名重

新创建



了这

个关系图，并

包含了形状

。这是一个U-Net架

构的例子，其

特征图

在网

络结构中的

形状像U。



图9.6 生

成器的架构

。生成器本身

具有收缩路

径（d0至d3）和扩展

路径（u1至

u4）。收缩

路径和扩展

路径有时分

别称为编码

器和解码器

这里有几点

需要注意：在

编码器中使

用标准卷积

层；在以上这

些



层中创建

跳跃连接（skip

connection），以

使信息更容

易通过网络

传播。在图中

，这分别由d0至

d4和u1至u4之间的

轮廓和颜色

深浅表



示。可

以看到，解码

器中有一半

的块来自那

些跳过连接

（注意，特性

映

射的数量是

原来的两倍

！）[4]；解码器使用

带最终卷积

层的反卷积

层将图像放

大到原始图

像的大小。



自

编码器也是

单独用于生

成器架构的

有用的教学

工具，因为生

成

器具有编

码器-解码器

架构。



（1）编码器

——图9.4中的步骤

1：这些是降低

每个特征图

（层

或切片）分

辨率的卷积

层。此为收缩

路径（d0至d4）；



（2）解码

器——图9.4中的步

骤3：这些是将

图像放大至

128×128的反卷积层

（转置的卷积

）；此为扩展路

径（u1至u4）。

还要明

确一点，这里

的自编码器

模型在两个

方面很有用

：第一，



整个CycleGAN架

构可以看作

训练了两个

自编码器。[5] 第

二，U-Net本

身具有

称为编码器

和解码器的

部分。



读者可

能还会对缩

小和随后的

放大感到困

惑，但这只是

为了将图

像

压缩为最有

意义的表示

，同时能重新

添加所有细

节。这与自编

码器



的原理

相同，只是现

在有了一条

记住细微差

别的路径。U-Net架

构在

多个领

域中已经得

到了经验证

明——它在各种

分割任务上

的表现更



好

。其关键思想

是，在下采样

过程中，我们

可以专注于

大区域的分

类

和理解，同

时高分辨率

的跳跃连接

保留了可以

精确分割的

细节。



在实现

CycleGAN时，我们将使

用具有跳跃

连接的U-Net架构

，它更

具可读

性，如图9.6所示

。但许多CycleGAN实现

使用ResNet架构，读

者



也可自己

进行尝试。

注

意



ResNet的主要优

点是它使用

较少的参数

，并在中间引

入称为

transformer的步

骤，它用残差

连接来代替

编码器-解码

器跳跃连接

。



根据我们的

测试，至少在

apple2orange数据集上结

果保持不变

。

我们没有显

式定义transformer，而是

用了从卷积

层到反卷积

层的跳跃



连

接。我们在代

码部分会再

次提及这些

相似之处，现

在读者只要

记住

这一点

就好。



9.5.3 鉴别器

架构

CycleGAN的鉴别

器基于PatchGAN架构

——我们在代码

部分会深入

讨论技术细

节。有一点可

能令人困惑

，那就是没有

得到单一的

浮点数



作为

鉴别器的输

出，而是得到

一组单通道

值。我们可以

把这些值看

作

一组小鉴

别器，然后将

其平均。



最终

，这使CycleGAN的设计

是全卷积的

，意味着它扩

展到更高的

分辨率会相

对容易。在视

频游戏和现

实场景互相

转换的例子

中，得益

于全

卷积设计，CycleGAN作

者仅做了少

量修改就得

到了CycleGAN的升



级

版。除此之外

，鉴别器应该

只是之前见

过的鉴别器

的相对简单

的实

现，只不

过现在有两

个。



9.6 GAN的面向对

象设计

我们

一直在TensorFlow中和

面向对象的

编程（Object-Oriented



Programming，OOP）中使用

对象，但是通

常会用更加

函数化的方

式处

理架构

，因为它们一

般比较简单

。CycleGAN的架构很复

杂，因此需要

一种允许我

们继续访问

已定义的原

始属性和方

法的结构。于

是我们在



教

程中将把CycleGAN编

写为一个它

自己的Python类，并

用方法构建

生

成器和鉴

别器，然后进

行训练。



9.7 教程

：CycleGAN

在本教程中

，我们将使用

Keras-GAN实现，而且使

用基于



TensorFlow后端

的Keras。[6] 我们在Keras

2.2.4和

TensorFlow



1.12.0的版本进行

了测试，并从

hash 46fcdb9384b3bc9399c6

51b2b43640aa54098e64安装了Keras_contrib。这次

必须使用不

同



的数据集

（尽管在第2章

中开了个玩

笑，但我们确

实知道其他

数据

集）。但出

于教学目的

，我们将继续

使用较简单

的apple2orange数据



集。直

接完成所有

常规导入，如

清单9.1所示。

清

单9.1 导入



from

__future__ import print_function,

division



import scipy

from keras.datasets import mnist

from keras_contrib.layers.normalization import

InstanceNormalization



from keras.layers

import Input,



Dense,

Reshape, Flatten, Dropout,

Concatenate



from keras.layers

import BatchNormalization,



Activation,

ZeroPadding2D



from keras.layers.advanced_activations

import LeakyReLU



from

keras.layers.convolutional import UpSampling2D,

Conv2D



from keras.models

import Sequential,



Model

from keras.optimizers import Adam

import datetime



import

matplotlib.pyplot as plt

import sys



from

data_loader import DataLoader

import numpy as np

import os



按照

承诺，我们将

使用面向对

象的编程风

格。在清单9.2中

，创建

一个包

含所有初始

化参数的CycleGAN类

，同时包含data_loader。



data_loader在

本书GitHub仓库中

有定义，用来

加载预处理

的数据。

清单

9.2 启动CycleGAN类



class

CycleGAN():



def __init__(self):

self.img_rows = 128 ←---

self.img_cols = 128

self.channels = 3 ←---

输入

形状



self.img_shape =

(self.img_rows, self.img_cols,



self.channels)

self.dataset_name = 'apple2orange' ←---

配置



data_loader

self.data_loader =



DataLoader(dataset_name=self.dataset_name,

←--- 使

用



data_loader对象导入

预处理的数

据集

img_res=



(self.img_rows, self.img_cols))

patch = int(self.img_rows /

2**4) ←--- 计算D的

输出大小

（PatchGAN）



self.disc_patch =

(patch, patch,



1)

self.gf = 32 ←---

G的

第一层的滤

波器的数量

self.df = 64

←---



D的第一层的

滤波器的数

量

self.lambda_cycle = 10.0 ←---

循环一致

性损失的权

重



self.lambda_id =

0.9 *



self.lambda_cycle

←--- 恒等损失

的权重

optimizer = Adam(0.0002, 0.5)

两个

新参数是lambda_cycle和

lambda_id。第二个超参

数影



响恒等

损失。CycleGAN作者自

己也注意到

这个值会影

响变化的剧

烈程

度，尤其

是在训练的

早期。[7] 设置一

个较低的值

会导致不必

要的变



化，例

如完全反转

颜色。基于多

次重新运行

apple2orange的训练过

程

，我们选择了

现在的值——这

一过程通常

是理论指导

的炼丹术！



第

一个超参数

lambda_cycle控制实施循

环一致性损

失的严格程

度。将此值设

置得较高，可

确保原始图

像和重建图

像尽可能地

接近。

9.7.1 构建网

络



现在我们

有了基本参

数，可以构建

基本网络了

，如清单9.3所示

。

我们将从高

层次的视角

开始向下探

索，这包括以

下内容。



（1）构建

两个鉴别器

和 并编译。

（2）构

建两个生成

器。



a．实例化 和

。

b．为两个方向

的图像输入

创建占位符

。



c．将它们都连

接到另一个

域中的图像

。

d．为原始域中

的重构图像

创建占位符

。



e．为两个方向

创建恒等损

失约束。

f．现在

鉴别器的参

数暂时不可

训练。



g．编译两

个生成器。

清

单9.3 构建网络

self.d_A =

self.build_discriminator() ←---



self.d_B

= self.build_discriminator()



self.d_A.compile(loss='mse',

optimizer=optimizer,



metrics=['accuracy'])

self.d_B.compile(loss='mse',



optimizer=optimizer,

metrics=['accuracy']) ←--- 构建并编译

鉴别器

self.g_AB = self.build_generator() ←---

self.g_BA = self.build_generator() ←---

从这

里开始构造

生成器的计

算



图前两行

代码构建生

成器

img_A = Input(shape=self.img_shape) ←---

img_B = Input(shape=self.img_shape) ←---

从两个

域中输入图

像



fake_B =

self.g_AB(img_A) ←---



fake_A

= self.g_BA(img_B) ←---

转换图像

到另一个域

中



reconstr_A =

self.g_BA(fake_B) ←---



reconstr_B

= self.g_AB(fake_A) ←---

转换回原

来的域



img_A_id =

self.g_BA(img_A) ←---



img_B_id

= self.g_AB(img_B) ←---

图像

的恒等映射

self.d_A.trainable = False

←---



self.d_B.trainable =

False ←---



组合模型只

训练生成器



valid_A = self.d_A(fake_A) ←---

valid_B = self.d_B(fake_B) ←---

鉴别器决定

转换图像的

正确性



self.combined =

Model(inputs=[img_A, img_B],



←---

outputs=[valid_A, valid_B,



reconstr_A,

reconstr_B,



img_A_id, img_B_id])

self.combined.compile(loss=['mse', 'mse',



'mae',

'mae',



'mae', 'mae'],

loss_weights=[1, 1, ←--- 组合

模型训练

生

成器来欺骗

鉴别器



self.lambda_cycle,

self.lambda_cycle,



self.lambda_id,

self.lambda_id],



optimizer=optimizer)

在上

述代码中，还

要澄清的一

点是：combined模型的

输出共有6



个

。这是因为总

是要获得正

确性（从鉴别

器中）、重建损

失和恒等损

失——分别用于

A-B-A和B-A-B循环。前两

个是平方误

差，其余的是

平

均绝对误

差。各损失的

相对权重受

前面提到的

lambda因子的影响

。



9.7.2 构建生成器



接下来我们

构建生成器

，这里用了9.5.2节

中描述的跳

跃连接，即



使

用U-Net架构。与某

些实现用的

ResNet架构相比，U-Net架

构更易于

编

写。在生成器

函数中，我们

首先定义辅

助函数，具体

步骤如下。



（1）定

义conv2d()函数。

a．标准

2D卷积层。



b．Leaky ReLU激活

函数。

c．实例归

一化[8]。



（2）将deconv2d()函数

定义为执行

以下操作的

转置卷积（又

称

反卷积）[9]层

。



a．对input_layer进行上采

样。

b．如果有设

置dropout率，可能会

应用dropout。



c．始终应

用Instance Normalization。

d．更重要的

是，在输出层

与来自图9.6下

采样部分的

对应维



度的

层之间创建

跳跃连接。

注

意



在步骤（2）的

d中使用一个

简单的UpSampling2D，它没

有可学

习参

数而是使用

最近邻法插

值。



然后创建

实际的生成

器，具体步骤

如下。

（3）取输入

（128×128×3）并将其分配

给d0。



（4）通过卷积

层d1，到达64×64×32层。

（5）取

d1（64×64×32）应用conv2d得到32×32×64（d2）。



（6）取

d2（32×32×64）应用conv2d得到

16×16×128（d3）。



（7）取

d3（16×16×128）应用conv2d得到8×8×256（d4）。

（8）u1：对

d4上采样，并在

d3和u1之间创建

一个跳跃连

接。



（9）u2：对u1上采样

，并在d2和u2之间

创建一个跳

跃连接。

（10）u3：对u2上

采样，并在d1和

u3之间创建一

个跳跃连接

。



（11）u4：使用常规的

上采样获得

128×128×64的图像。

（12）使用

常规的2D卷积

除去多余的

特征图，获得

128×128×3（高度×宽度×颜

色通道）的图

像。



构建生成

器的代码如

清单9.4所示。

清

单9.4 构建鉴别

器



def

build_generator(self):



"""U-Net Generator"""

def conv2d(layer_input, filters, f_size=4):

"""Layers used during downsampling"""

d = Conv2D(filters, kernel_size=f_size,

strides=2, padding='same')(layer_input)



d

= LeakyReLU(alpha=0.2)(d)



d

= InstanceNormalization()(d)



return

d



def deconv2d(layer_input,

skip_input, filters,



f_size=4,

dropout_rate=0):



"""Layers used

during upsampling"""



u

= UpSampling2D(size=2)(layer_input)



u

= Conv2D(filters, kernel_size=f_size,

strides=1,



padding='same', activation='relu')(u)

if dropout_rate:



u

= Dropout(dropout_rate)(u)



u

= InstanceNormalization()(u)



u

= Concatenate()([u, skip_input])

return u



d0

= Input(shape=self.img_shape) ←---

输入图像

d1 = conv2d(d0,

self.gf)



←---

d2 = conv2d(d1, self.gf

* 2)



d3

= conv2d(d2, self.gf

* 4)



d4

= conv2d(d3, self.gf

* 8) ←--- 下采样

u1 = deconv2d(d4, d3,

self.gf * 4) ←---

u2 = deconv2d(u1, d2,

self.gf * 2)

u3 = deconv2d(u2, d1,

self.gf) ←--- 上采

样

u4 = UpSampling2D(size=2)(u3)

output_img = Conv2D(self.channels, kernel_size=4,

strides=1, padding='same',



activation='tanh')(u4)

return Model(d0, output_img)

9.7.3 构建鉴别

器



现在我们

来构建鉴别

器，这里使用

了一个辅助

函数来创建

由2D卷

积、LeakyReLU和InstanceNormalization（可

选）组成的层

。



按照以下方

式应用这些

层，如清单9.5所

示。

（1）取输入图

像（128×128×3）并指定给

d1（64×64×64）。



（2）取d1（64×64×64）并指定给

d2（32×32×128）。

（3）取d2（32×32×128）并指定给

d3（16×16×256）。



（4）取d3（16×16×256）并指定给

d4（8×8×512）。

（5）取d4（8×8×512）并通过conv2d将

其展平为8×8×1。



清

单9.5 构建鉴别

器

def build_discriminator(self):



def

d_layer(layer_input, filters, f_size=4,

normalization=True):



"""Discriminator layer"""

d = Conv2D(filters, kernel_size=f_size,

strides=2, padding='same')(layer_input)



d

= LeakyReLU(alpha=0.2)(d)



if

normalization:



d =

InstanceNormalization()(d)



return d

img = Input(shape=self.img_shape)

d1 = d_layer(img, self.df,

normalization=False)



d2 =

d_layer(d1, self.df



*

2)



d3 =

d_layer(d2, self.df



*

4)



d4 =

d_layer(d3, self.df



*

8)



validity =

Conv2D(1, kernel_size=4,



strides=1,

padding='same')(d4)



return Model(img,

validity)



9.7.4 训练CycleGAN

构建

完所有网络

后，现在我们

来实现创建

训练循环的

方法。对于



CycleGAN训

练算法，每个

训练迭代的

细节如下。

CycleGAN训

练算法



对每

次训练迭代

，执行如下操

作。

（1）训练鉴别

器。



a．从每个域

中抽取一小

批随机图像

和

。



b．使用生成

器 将

转换为

域B，反之使用

。



c．计算 (

, 1)和



(

( ), 0)，分别

得

到A中真实

图像和从B转

换的图像的

损失，然后将

这两个损失

相加；



中的1和

0用作标签。

d．计

算 ( , 1)和

( ( ), 0)，分别获



得B中的真实

图像和从A转

换的图像的

损失，然后将

这两个损失

相加；



中的1和

0用作标签。

e．将

步骤c和d的损

失相加，得到

鉴别器总损

失。



（2）训练生成

器。

a．使用组合

模型执行如

下操作。



输入

来自域 和域

的图像。

输出

以下项。



A的正

确性： 。

B的正确

性： 。



重构的A：

。



重

构的B： 。

A的恒等

映射： 。



B的恒等

映射：

。



b．使用循

环一致性损

失、恒等损失

和对抗性损

失更新两

个

生成器的参

数。



标量的均

方误差（MSE）（鉴别

器概率）。

图像

的均方绝对

误差（MAE）（重建的

或恒等映射

的）。



结束

清单

9.6实现了此CycleGAN的

训练算法。



清

单9.6 CycleGAN的训练算

法

def train(self, epochs, batch_size=1,

sample_interval=50):



start_time =

datetime.datetime.now()



valid =

np.ones((batch_size,) +



self.disc_patch)

←--- 对



抗损失

的ground

truths



fake =

np.zeros((batch_size,) +



self.disc_patch)

for epoch in range(epochs):

for batch_i, (imgs_A, imgs_B)

in enumerate(



self.data_loader.load_batch(batch_size)):

fake_B = self.g_AB.predict(imgs_A) ←---

fake_A = self.g_BA.predict(imgs_B) ←---

开始训练

鉴别器将图

像转换到另

外的域



dA_loss_real

= self.d_A.train_on_batch(imgs_A,



valid)

←---



dA_loss_fake =

self.d_A.train_on_batch(fake_A,



fake)

dA_loss = 0.5 *

np.add(dA_loss_real, dA_loss_fake)



dB_loss_real

= self.d_B.train_on_batch(imgs_B,



valid)

dB_loss_fake = self.d_B.train_on_batch(fake_B,

fake)



dB_loss =

0.5 *



np.add(dB_loss_real,

dB_loss_fake)



←--- 训练

鉴别器（原图

=真/转换=假）

d_loss = 0.5 *

np.add(dA_loss, dB_loss) ←---

鉴

别器总损失

g_loss = self.combined.train_on_batch([imgs_A,

imgs_B], ←--- 训练生成器



[valid, valid,

imgs_A, imgs_B,

imgs_A, imgs_B])



if

batch_i % sample_interval

== 0: ←--- 如果是

保存

间隔=>保存生

成的图像样

本



self.sample_images(epoch, batch_i)

←--- 该



函数与

之前遇到的

类似

9.7.5 运行CycleGAN



我

们完成了所

有复杂的代

码，现在可以

实例化一个

CycleGAN对

象，并从采

样图像中看

一看结果（图

9.7）：



gan =

CycleGAN()



gan.train(epochs=100, batch_size=64,

sample_interval=10)



图9.7 苹果变成

了橙子，橙子

变成了苹果

——这些就是出

现在Jupyter

Notebook中的结

果



（根据随机

种子、TensorFlow和Keras的实

现以及超参

数的不同，结

果可能会略

有不同）

9.8 扩展

、增强和应用

由于CycleGAN的结果

着实惊人，许

多研究人员

对这项技术

进行了

改进

。在本节中，我

们将详细介

绍CycleGAN的扩展，然

后讨论它的

一



些应用。

9.8.1 增

强CycleGAN



“增强CycleGAN：从未

配对数据中

学习多对多

映射”是对标

准

CycleGAN的巧妙扩

展，它在两次

转换过程都

注入了潜在

空间信息。在

斯德哥尔摩

召开的 ICML 2018

大会

上，增强CycleGAN利用

额外的变量

来驱动生成

过程。[10] 与CGAN使用

潜在空间的

方式相同，我

们可以在

CycleGAN设

置中使用它

，可以得到比

CycleGAN已经做到的

更好的结



果

。

例如，如果在

域A中有鞋子

的轮廓，则可

以在域B中生

成样本，其



中

相同类型的

鞋子是蓝色

的。在传统的

CycleGAN情况下，鞋子

总是蓝

色的

，但现在有了

可以利用的

潜在变量，它

可以是橙色

的、黄色的，



抑

或是可以选

择的任何颜

色。

这也是一

个用于思考

原始CycleGAN局限性

的有用框架

：我们没有



获

得任何额外

的种子参数

（例如额外的

潜在向量 ），因

此无法控制

或

更改另一

端的结果。如

果从一个特

定的手提包

轮廓中得到

的图像是橙

色的，则它将

始终是橙色

的。如图9.8所示

，增强CycleGAN使我们

能够



更好地

控制结果。

（来

源：Augmented CycleGAN: Learning Many-to-Many

Mappings from



Unpaired

Data, by Amjad

Almahairi et al., 2018.）

图9.8 在增强

CycleGAN的信息流中

，潜在向量 和

将与图像输

入一起作

为

生成器的种

子，有效地将

问题归结为

两个CGAN的连接

，从而使得我

们能够控制

生成



9.8.2

应用



在

很短时间内

，CycleGAN（或受CycleGAN启发）的

应用如雨后

春

笋般涌现

。人们通常会

先创建模拟

的虚拟环境

，然后让它们

变得逼



真。例

如，假设要为

一家自动驾

驶汽车公司

提供更多的

训练数据，只

需在Unity或GTA

5图形

引擎中对其

进行仿真，然

后使用CycleGAN转换

数据即可。



如

果在数据集

中需要特定

危险场景，但

是重新创建

这些场景是

成

本昂贵或

者耗时的（例

如，车祸或消

防车加速赶

往目的地的

场景），



那么这

种方法尤其

有效。对于无

人驾驶汽车

公司来说，这

对于平衡数

据集与风险

情况非常有

用，风险情况

很少见，但正

确的行为更

重要。

这种框

架的一个例

子是循环一

致的对抗域

自适应（Cycle



Consistent Adversarial

Domain Adaptation，CyCADA），[11]



但对



其工作方式

的完整解释

超出了本章

的范围。这是

因为还有很

多这样的



框

架，有些甚至

在语言、音乐

或其他形式

的域适应方

面尝试使用

CycleGAN。图9.9显示了CyCADA的

架构和设计

，可供读者从

中一窥其复



杂性。



图9.9 这种

结构要求读

者对前面的

内容有所熟

悉。还有一件

事需要指出

：现在有

了一

个额外的步

骤来处理标

签和语义理

解，即任务损

失（task loss）。它可以检

查生成图像

的语义

9.9 小结

（1）由于需要完

美的配对，图

像到图像的

转换框架通

常很难训

练

。CycleGAN通过使其成

为一个不成

对的域转换

来解决这个

问题。



（2）CycleGAN有如下

个损失。

循环

一致性损失

，用于测量原

始图像与转

换到不同域

并再次转回

原域的图像

之间的差异

。



对抗损失，可

以确保生成

逼真的图像

。

恒等损失，可

以保留图像

的色彩空间

。



（3）两个生成器

使用U-Net架构，两

个鉴别器使

用基于PatchGAN

的架

构。



（4）本章实现

了CycleGAN的面向对

象设计，并用

它将苹果转

换为

橙子。



（5）CCycleGAN的

实际应用包

括自动驾驶

汽车的训练

和能够在转

换过程中创

建不同风格

图像的扩展

。

[1] Unpaired Image-to-Image Translation

Using Cycle￾Consistent Adversarial Networks,

by Jun-Yan Zhu et

al., 2017.



[2]

实际中要复

杂一点，例如

这取决于是

否同时考虑

了正向和反

向的



循环一

致性损失。但

可以用它作

为一个思维

模式来思考

对抗损失重

要

性——记住有

两个映射A-B-A和

B-A-B，所以两个鉴

别器在某种

程度上



都是

第一个。

[3] Jun Yan Zhu

et al., 2017.

[4] 正如

读者将看到

的，这只是意

味着我们把

整个块/张量

恒等连接



到

生成器解码

部分的上色

等价彩色的

张量上。

[5] Jun-Yan Zhu 等人

的论文（2017）。

[6] the Keras-GAN GitHub

repository by Erik Linder-Norén,

2017.



[7] pytorch-CycleGAN-and-pix2pix

Frequently Asked



Questions,by

Jun-Yan Zhu, April

2019.



[8] 实例

归一化（Instance

Normalization，IN）与第

4章中的批归

一化类似，只

是没有基于

整个批量的

信息进行归

一化，而是分

别对每



个通

道中的每个

特征图进行

归一化。实例

归一化通常

会为风格迁

移或

图像到

图像的转换

等任务带来

更好的图像

质量，这正是

CycleGAN所需



要的！

[9] 这

里，转置卷积

是一个更准

确的术语。可

以把它看作

卷积的反过

程或反卷积

。

[10] Augmented Cyclic Adversarial

Learning for Low Resource

Domain Adaptation,by Ehsan Hosseini-Asl,

2019.



[11] CyCADA:

Cycle-Consistent Adversarial



Domain

Adaptation,



by Judy

Hoffman et



al.,

2017.



第三部分 何

去何从

第三

部分探讨了

一些实际应

用案例，并探

索了一些可

以应用第



一

、二部分中关

于GAN及其实现

相关知识的

领域。

第10章讨

论对抗样本

（通过故意欺

骗来使分类

器犯错误），这

是



一个具有

重要实践和

理论意义的

领域。

第11章探

讨GAN在医学和

时尚领域中

的实际应用

，其实现用到

了本



书中介

绍的GAN变体。

第

12章概述GAN及其

应用的道德

伦理考量，还

提到了一些

新兴的



GAN技术

，以供想继续

探索本书以

外知识的读

者参考。

第10章

对抗样本



本

章主要内容

这是一个先

于GAN的迷人的

研究领域，有

着错综复杂

的历史

计算

机视觉中的

深度学习方

法



带有真实

图像和噪声

的对抗样本

在学习本书

的过程中，读

者已经把GAN理

解为一个直

观的概念。但



是在2014年，对于

那些不熟悉

对抗样本这

个新兴领域

的人，GAN以及



Ian Goodfellow和

其他人在该

领域的工作

[1]，似乎可以看

作一次信仰



上的飞跃。本

章将深入探

讨对抗样本

，尤其是那些

使用其他分

类算法



会灾

难性地失败

的特殊构造

的样本。

本章

还讨论了对

抗样本与GAN的

联系，以及对

抗学习为何

和如何成



为

机器学习中

仍未能解决

的难题——现有

方法的一个

重要但很少

被讨

论的缺

陷。即使对抗

样本在机器

学习的鲁棒

性、公平性和

（网络）安



全性

中起着重要

作用，这也是

毋庸置疑的

事实。

在过去

5年中，机器学

习的确在赶

上和超越人

类表现的能

力上取得



了

长足进步，例

如在计算机

视觉分类任

务以及游戏

上。[2] 但是，仅看



指标和ROC曲线

[3]不足以了解

神经网络做

出的决定的

依据（如何起

作用



的）以及

容易犯哪些

错误。本章将

略微提及前

者，然后深入

研究后

者。尽

管本章几乎

只涉及计算

机视觉领域

的问题，但是

在诸如文本

处



理以及其

他领域中也

可以找到对

抗样本。[4]

当谈

论神经网络

的性能时，我

们经常看到

它们在大型

ImageNet数



据集上的

错误率低于

人类。这种经

常被引用的

统计数据（最

开始是学

术

上的玩笑）掩

盖了隐藏在

该平均值背

后的性能差

异。人类的错

误率



通常是

由于他们无

法辨认在此

数据集中的

不同品种的

狗，机器学习

的

犯错的原

因则更为不

详。经过进一

步研究，对抗

样本就产生

了。



与人类不

同，CV（计算机视

觉）算法会纠

结于性质非

常不同的问

题，这个问题

可能更倾向

于是训练数

据导致的。因

为算法必须

为任何

可能

出现的图像

做出预测，所

以即使有很

多训练数据

，它也必须为

完



全不同于

已经在训练

数据中见过

的个别样本

进行推断。

当

训练了如Inception V3和

VGG-19之类的网络

后，我们发现

了一



种效果

惊人的图像

分类方法，它

在与训练数

据接近的细

流形（thin

manifold）上有很

好的效果。但

是人们试图

在这些算法

的分类能力

找



漏洞时，发

现了一个巨

大缺陷——当前

的机器学习

算法很容易

被很微

小的

失真所愚弄

。迄今为止，几

乎所有成功

的主流机器

学习算法在

一



定程度上

受到该缺陷

的影响，于是

有人开始质

疑机器学习

究竟能不能

起作用。

注意

在监督学习

条件下，请考

虑我们的训

练集。我们有

一个训练流

形



（manifold）——这只是一

个描述有样

本存在的高

维分布的花

哨的

词。例如

，300像素×300像素图

像处在270000维空

间（300×300×3



色）中，这使

得训练非常

复杂。

10.1 对抗样

本的背景



我

们之所以在

本书最后一

部分设立本

章，是出于以

下考虑。

（1）借助

对抗样本，我

们可以尝试

生成新样本

来愚弄现有

的系



统，使它

错误地对输

入进行分类

。我们通常以

邪恶的攻击

者的身份或

以研究人员

的身份这样

做，以了解系

统的鲁棒性

。尽管对抗样

本与GAN

存在重

大差异，但它

们密切相关

。



（2）这将使读者

了解为什么

GAN如此难训练

以及为什么

现有的系

统

如此不堪一

击。



（3）对抗样本

考虑了与 GAN

不

同的一组应

用，而我们希

望读者



能够

了解对抗样

本功能的基

础知识。

对抗

样本的应用

之所以如此

有趣，原因有

如下几个。



（1）如

上讨论，对抗

样本可用于

恶意目的，因

此测试关键

系统的

鲁棒

性非常重要

。试想如果攻

击者可以轻

易地欺骗面

部识别系统

来访



问手机

，那该怎么办

？

（2）对抗样本使

机器学习的

过程更加清

晰——这是一个

日益重要



的

主题。对抗性

学习的表示

法对于分类

很有用，但是

它不允许攻

击者

找到受

保护的事物

，这可能是确

保机器学习

不歧视任一

类的最佳方

法



之一。

（3）同样

可以使用对

抗性学习来

保护涉及隐

私的敏感信

息（可能



是医

疗或财务信

息），在这种情

况下，我们仅

关注无法恢

复的个人信

息。

就目前的

研究而言，学

习对抗样本

是开始理解

防御对抗样

本的唯



一方

法，因为大多

数论文会先

描述它所防

御的攻击类

型，然后才是

尝

试怎么解

决。截至本书

撰写时，还没

有针对所有

攻击类型的

通用的防



御

措施——这是否

是去研究它

的一个好的

理由，还得取

决于读者对

对

抗样本的

看法。本节不

详细介绍防

御措施，因为

它超过了本

章最后的



更

高层次的思

想，超出此范

围的所有内

容均不属于

本书的范畴

。

10.2 谎言，该死的

谎言及分布

为了真正理

解对抗样本

，我们必须回

到CV分类任务

的领域，去一

定程度地了

解这项任务

的难度。从原

始像素到最

终能够对图

像集进行

分

类是颇具挑

战性的。



这一

定程度上是

因为，为了得

到一个真正

可泛化的算

法，我们必

须

能够对一点

也不像训练

集中的数据

做出合理的

预测。此外，即

使只



是稍微

改变拍摄照

片的角度，得

到的图像和

训练集中同

一类的与它

最

相近的图

像之间也存

在巨大的像

素级差异。



当

RGB空间中拥有

100000个300×300图像样本

的训练集时

，算法必

须以

某种方式处

理一个270000维的

数据。当考虑

所有可能的

图像（不



是实

际观察到的

图像，而是可

能存在的图

像）时，每个维

度的像素值

都与其他维

度无关，因为

通过270000次掷256面

的骰子始终

可以生成不



同的有效图

像。因此，理论

上在8位颜色

空间中有256270000（一

个长达



650225位的

数字）个样本

。

这将需要大

量样本来覆

盖此空间，即

使只覆盖它

的1%。当然，这



些

图像大多数

没有任何意

义。通常的训

练集比这稀

疏得多，因此

需要

训练算

法能够用相

对有限的数

据去推断它

们还没有见

过的数据分

布区



域。这是

因为大多数

实际情况下

，算法可能不

会看到任何

东西与在训

练集中看到

的类似。

注意

100000个样本常被

引作深度学

习算法能真

正奏效的最

低标准。



算法

必须有意义

地泛化，即必

须能够有意

义地填充大

部分空间但



却从未见过

其中任何样

本。计算机视

觉算法之所

以起作用，主

要是因



为它

们可以对大

量的未见过

的样本做出

很好的推测

，但它们的优

势同

时也是

最大的弱点

。



10.3 训练的使用

与滥用

本节

介绍两种关

于对抗样本

的思考方式

，一种基于第

一原理，另



一

种是通过类

推得到的。思

考对抗样本

的第一种方

式是从训练

机器学

习进

行分类的方

法入手。记住

，这里讨论的

都是有数千

万参数的网

络。在整个训

练过程中，我

们会更新其

中的一些参

数，以使分类

结果



与训练

集中提供的

标签匹配。我

们需要找到

正确的参数

更新的方式

，

而这恰恰是

随机梯度下

降所能做到

的。



回想一下

在了解GAN之前

的简单分类

。这是某种可

学习的分类

函数

（例如，深

度神经网络

，或者DNN），它是以

θ 作为参数（DNN的

参数）将 （例如

图像）作为输

入并产生分

类

。在训练时

，我们取 作



为

预测值并将

其与真实

进

行比较，就是

得到损失 的

方式。然后，我

们更新 的参

数，以使损失

最小化。式10.1～式

10.3总结了上述

过

程[5]。



式10.1

式10.2



使

得 式10.3

本质上

，我们把预测

定义为输入

一个示例后

神经网络的

输出（式



10.1）。损失

是权衡真实

标签和预测

标签之间的

差异的某种

形式（式

10.2）。这样

就可以将整

个问题表述

为通过调整

DNN参数来最小

化真实



标签

和预测标签

之间的差异

，然后对于给

定样本构成

预测值（式

10.3）。



这

些都很有效

，那实际上如

何使分类损

失最小化呢

？如何解决式

10.3中所述的优

化问题？通常

使用基于SGD的

方法来成批

次地获取

，



然

后用损失函

数关于当前

参数 求导并

乘以学习率

α，去构成新参

数

，参见式10.4。



式

10.4

上述内容一

定是最简洁

的深度学习

入门介绍了

。掌握了这些

基本



原理后

，读者不妨思

考一下，是否

可以将功能

如此强大的

工具（SGD）

用于其

他目的？例如

，当增大而不

是减小损失

空间时会发

生什么？事



实

证明，最大化

比最小化误

差要容易得

多——虽然容易

，但也很重

要

。正如许多重

大发现一样

，它最初是个

表面上的小

漏洞，后来发

展



成了致命

的缺陷：如果

我们开始更

新像素而不

是更新权重

，会发生什

么

事情呢？如果

蓄意更新像

素，对抗样本

便产生了。



经

过简单的回

顾，读者可能

仍旧对SGD感到

困惑，那么我

们在图

10.1中回

想一下典型

的损失空间

是什么样子

的。



（a） （b）

（来源：Visualizing the Loss Landscape

of Neural Nets, by

Tom



Goldstein et

al., 2018.）



图10.1

在

典型的损失

空间中，这是

可以通过深

度学习算法

切实获得的

损失值的类

型。图（a）为2D的等

损失轮廓线

，图（b）为损失空

间的3D渲染（还

记得第6章中

的登山类比

吗？）

第二种有

用的（尽管是

不完美的）思

维模型也有

助于理解对

抗样



本。读者

可能会将对

抗样本视为

CGAN，就像在前两

章中遇到的

那样。

借助对

抗样本，我们

可以调整整

个图像并尝

试生成一个

域转换



（domain transferred）或相

似的图像（除

了欺骗分类

器的域）。

“生成

器”可以简单

地用随机梯

度上升去轻

微地调整图

像，就可以骗

过一些分类

器。



先不论哪

种解释对读

者来说容易

理解，我们直

接来看对抗

样本，

来看一

看它们是什

么样子的。通

过观察到改

变后的图像

很容易被错

误



分类发现

，我们发现了

对抗样本。首

个实现对抗

样本的方法

是快速梯

度

符号法（Fast Sign Gradient Method，FSGM），它与

之前的描述

一

样简单。



从

梯度更新开

始（式10.4），查看一

下符号，使它

朝相反的方

向

迈出一小

步。在大多数

情况下，这样

产生的图像

看起来和原

图几乎是



相

同的！图像胜

却千言万语

，图10.2展示了只

需要很少的

噪声就可以

达到的效果

。

（a） （b）



（c）

图10.2 一点噪声

会产生很大

的不同，图（b）施

加了图（c）所示

的噪声（差



异

）。图（c）被放大了

大约300倍并进

行了移位，以

便可以生成

有意义的图

像

在未经修

改的图像上

运行经过预

训练的ResNet-50分类

器后查看预

测值最大的

前3个类，如表

10.1所示。



表10.1

预测

值最大的前

3个类



排名 类

别

置信度



第

一 mountain_tent

0.6873



第二 promontory

0.0736



排名

类别 置信度



第三 valley 0.0717

前三名

看起来都很

合乎情理，山

坡mountain_tent排在第一

位。



表10.2显示了

对于对抗样

本的预测，前

三名完全没

有山坡

mountain_tent，虽然

至少匹配了

“是户外景色

”这一点，但即

使是



经过修

改的图像，也

显然不会是

吊桥suspension_bridge。

表10.2 对于

对抗样本的

预测



排名

分

类 置信度



第

一

volcano 0.5914



第二

suspension_bridge 0.1685



第三

valley

0.0869



这就是可以

扭曲预测的

程度，只有大

约200个像素值

的变化（相当

于把单个几

乎是黑色的

像素变成几

乎是白色的

像素）分配在

整个图像

上

。



另外，令人震

惊的是，生成

整个样本所

需的代码甚

少。本章将使

用一个名为

foolbox的库，该库效

果惊人，提供

了许多用于

生成对抗

样

本的简便方

法。从众所周

知的导入开

始，再加上foolbox——它

是



一个专门

设计用来更

容易地实现

对抗性攻击

的代码库，如

清单10.1所

示。



清

单10.1 导入声明



import numpy as np

from keras.applications.resnet50 import ResNet50

from foolbox.criteria import Misclassification,

ConfidentMisclassification



from keras.preprocessing

import image



as

img



from keras.applications.resnet50

import preprocess_input,



decode_predictions

import matplotlib.pyplot as plt

import foolbox



import

pprint as pp

Import keras



%matplotlib

inline



然后定义一

个可以方便

加载更多图

像的函数，如

清单10.2所示。

清

单10.2 辅助函数

def load_image(img_path:

str):



image =

img.load_img(img_path, target_size=(224,



224))

plt.imshow(image)



x =

img.img_to_array(image)



return x

image = load_image('DSC_0897.jpg')

接下来，设置

Keras以注册模型

，并从Keras提供的

函数中下载

ResNet-50，如清单10.3所示

。



清单10.3

创建表

10.1和表10.2



keras.backend.set_learning_phase(0) ←---

实例化

模型



kmodel =

ResNet50(weights='ImageNet')



preprocessing =

(np.array([104, 116,



123]),

1)



fmodel =

foolbox.models.KerasModel(kmodel, bounds=(0,



255),

preprocessing=preprocessing) ←--- 通过Keras模

型生成foolbox

模型

对象



to_classify =

np.expand_dims(image, axis=0)



←---

图像维

度变为（1,



224, 224,

3）符合

ResNet-50的输入要求

（批量输入图

像以生成预

测）



preds =

kmodel.predict(to_classify) ←---



生成预测

并打印结果



print('Predicted:', pp.pprint(decode_predictions(preds, top=20)

[0]))



label =

np.argmax(preds) ←---



得到最高值

的索引值稍

后作为标签

输入

image = image[:, :,

::-1] ←--- ::1 反转颜

色通道,

因为

Keras-ResNet-



50输入要求BGR

attack = foolbox.attacks.FGSM(fmodel, threshold=.9,

←--- 创

建攻



击对象

设置高的错

误分类标准



criterion=ConfidentMisclassification(.9))



adversarial =

attack(image, label)



←---

对源图像施

加攻击



new_preds =

kmodel.predict(np.expand_dims(adversarial, axis=0))



←---

对抗

样本上得到

新的预测



print('Predicted:', pp.pprint(decode_predictions(new_preds,

top=20)



[0]))

使

用这些例子

非常简单！读

者可能会觉

得也许只有

ResNet-50会受



这些样

本的影响。但

是，我们在测

试本章的各

种代码时发

现ResNet不

但被证

明是最难破

解的分类器

，而且在每个

ImageNet类别中，ResNet



在DAWNBench上

都是无可争

议的赢家（这

是DAWNBench的CV类别中

最具

挑战性

的任务），如图

10.3所示。[6]



图10.3 至少

截至2019年7月上

旬，DAWNBench是一个查

看当前最新

模型和ResNet-

50的主

导地位的好

地方



对抗样

本的最大问

题是它们的

普遍性。对抗

样本不仅限

于深度学

习

，还可以推广

到不同的机

器学习技术

。如果针对一

种技术生成

一个



对抗样

本，那么它很

有可能也可

以攻击另一

种模型，如图

10.4所示。

（来源：Transferability in Machine Learning:

from Phenomena to Black￾Box

Attacks Using Adversarial Samples,

by Nicolas Papernot et

al.,



2016.)

图

10.4 数字表示为

了欺骗该行

中的分类器

而精心设计

的对抗样本

的百分比，这

些



样本也欺

骗了该列的

分类器。方法

有深度神经

网络（DNN）、逻辑回

归（LR）、支

持向量

机（SVM）、决策树（DT）、k近

邻（kNN）和集成学

习（Ens.）



10.4 信号与噪

声

更糟糕的

是，许多对抗

样本非常容

易构建，以至

于可以轻松

地通



过高斯

噪声来欺骗

分类器。高斯

噪声可以从

np.random.normal中采

样获得

。为了证明ResNet-50 是

一个颇具鲁

棒性的体系

结构，我们将

展示其他体

系结构为此

受到的更大

的影响。

图10.5显

示了在纯高

斯噪声下运

行ResNet-50的结果。但

是，我们



可以

对噪声本身

进行对抗性

攻击，以查看

图像可以被

错误分类到

什么

程度。



清

单10.4将使用投

影梯度下降

（Projected Gradient

Descent，



PGD）进行攻击，如

图10.6所示。尽管

是一种简单

的攻击，但它

证实了

一种

更高层次的

解释。与以前

的攻击不同

，不管它会将

我们带向何

方



——甚至是“无

效”的像素值

——都会前进一

步后将其投

射回可行域

空间。现在我

们将PGD攻击应

用到图10.7中的

高斯噪声上

，并运行

ResNet-50去看

看是如何做

的。



图10.5 显然在

大多数情况

下，只单纯地

用采样获得

的噪声无法

得到作为错

误类别

的确

切分类，这就

是ResNet-50的优点。左

侧归纳了使

用的均值和

方差，我们可

以



看到它们

的影响

图10.6 投

影梯度下降

朝着最佳方

向迈出的一

步，然后使用

投影找到最

近的点集中

的等价点。在

这种情况下

，我们试图确

保最终得到

的仍然是一

个有效图：以

为

例采取最

佳步骤到 ，然

后将其投影

到一个有效

的图像集



图

10.7

在对抗性噪

声下运行ResNet-50时

，得到了一个

不同的结果

：应用PGD攻



击后

，大多数对象

被错误分类

了，即使PGD是很

简单的攻击

为了证明大

多数网络结

构更更糟，我

们将研究Inception

V3——



该

架构已在CV领

域中声名鹊

起。实际上，Inception V3已

经被认为是



非常可靠的

了——本书第5章

中已经对其

进行了介绍

。图10.8展示了即

使是用于定

义Inception分数（Inception分数

用于评价生

成模型的好

坏）的Inception V3网络，在

简单的样本

中仍然会失

败。为了消除

疑

问，我们可

以认为Inception V3仍然

是目前最好

的预训练网

络之一，



并且

确实具有超

高的准确率

。

注意



这里只

是常规的高

斯噪声。你可

以在代码中

看到目前没

有加入对

抗

的步骤。诚然

，你可能会说

噪声可能是

得到了更好

的预处理，但

这



仍是一个

很大的对抗

性弱点。

为了

让读者想亲

眼看看这些

结果，我们会

提供可以重

现上述内容

的代码。因为

代码都很类

似，所以我们

只提供一遍

，下次将使用

DRY化



的代码。

注

意



有关不要

重复你自己

代码原则（Don’t Repeat

Yourself，DRY）



的

说明，参见维

基百科的相

关词条。

图10.8 应

用于高斯噪

声的Inception V3模型，注

意，没有使用

任何攻击，这

些

噪声只是

从分布中采

样得到的



清

单10.4 高斯噪声



fig = plt.figure(figsize=(20,20))

sigma_list = list(max_vals.sigma) ←---

均值和方差

的列表（浮点

数形



式）

mu_list = list(max_vals.mu)

conf_list = []

def make_subplot(x, y, z,

new_row=False): ←--- 生成

绘制图10.8的核

心函数

rand_noise = np.random.normal(loc=mu, scale=sigma,

size=



(224,224, 3))

←--- 每个

均值和方差

的样本噪声

rand_noise =

np.clip(rand_noise, 0,



255.)

←--- 只允许0～255



的像

素值

noise_preds = kmodel.predict(np.expand_dims(rand_noise,

axis=0)) ←--- 获得第

一个预测

prediction, num = decode_predictions(noise_preds,

top=20)[0]



[0][1:3] ←---

分

别获取预测

的类别和置

信度



num =

round(num *



100,

2)



conf_list.append(num)

ax = fig.add_subplot(x,y,z) ←---

为图10.8设

置注释代码

并添加注



释

文字

ax.annotate(prediction, xy=(0.1, 0.6),

xycoords=ax.transAxes, fontsize=16, color=’yellow’)

ax.annotate(f’{num}%’ , xy=(0.1, 0.4),

xycoords=ax.transAxes, fontsize=20, color=’orange’)

if new_row:



ax.annotate(f’



$\mu$



:{mu},



$\sigma$



:{sigma}’ ,



xy=(-.2,

0.8), xycoords=ax.transAxes,



rotation=90,

fontsize=16,



color=’black’)

ax.imshow(rand_noise / 255) ←---

除以255，[0, 25]变为[0, 1]

ax.axis(’off’)



for i

in range(1,101):



←---

主

程序中的for循

环，是为了允

许图中插入

子图



if (i-1)

% 10==0:



mu

= mu_list.pop(0)



sigma

= sigma_list.pop(0)



make_subplot(10,10,

i, new_row=True)



else:

make_subplot(10,10, i)



plt.show()

10.5 柳暗花

明又一村



现

在有些人开

始担心对抗

样本的安全

性，但保持对

假想攻击者

的

清醒而有

意义的认识

是很重要的

。如果攻击者

可以对每个

像素稍加更

改，那么为什

么不能更改

整幅图？[7] 为什

么不输入一

幅完全不同

的

图？为什么

传入的样本

有着不可觉

察的不同，而

不是明显的

不同？



有些人

举了无人驾

驶汽车和停

车标志的对

抗性例子。但

是如果我

们

能够做到这

一点，为什么

攻击者不会

将喷漆涂在

停车标志上

，或者



干脆用

高速限速标

志遮挡停车

标志呢？因为

与对抗样本

不同，这些

“传

统攻击”是100%能

起作用的，而

对抗性攻击

只有在被更

好地转换



且

不会被预处

理破坏的情

况下才起作

用。

这并不意

味着当你有

关键任务的

机器学习应

用程序时，你

就可以



忽略

此问题。在大

多数情况下

，对抗性攻击

比常见的攻

击需要更多

的

精力，因此

记住这一点

是值得的。



不

过，与大多数

安全隐患一

样，对抗攻击

也具有对抗

防御，即试

图

防御多种类

型的攻击。本

章介绍的攻

击是一些较

简单的攻击

，但是



其实也

存在更简单

的攻击，例如

通过MNIST绘制一

条直线——即使

这

样，也足以

欺骗大多数

分类器。



对抗

防御是一个

不断发展的

“游戏”，其中针

对某些（但不

是全

部）类型

的攻击提供

了许多良好

的防御。但转

变真的可以

如此之快，



以

至于ICLR 2018交稿截

止日期后仅

3天，8个提出的

并经过检验

的防御

机制

中，7个都被攻

破了。[8]



10.6 GAN的对手



为了使GAN之间

的联系更加

清晰，我们假

设有一个生

成对抗样本

的



系统，然后

另一个系统

用于说明该

样本有多有

效——有效程度

取决于

样本

是否成功地

欺骗了系统

。是不是想起

了生成器（敌

对者）和鉴别

器（分类算法

）？这两种算法

又在竞争：敌

对者试图用

轻微的图像

干



扰来欺骗

分类器，而分

类器则努力

不被愚弄。事

实上，可以这

样来

想，GAN几乎

就是循环机

器学习的对

抗样本，最终

生成了图像

。



你还可以把

迭代的对抗

攻击看作使

用的是GAN，而且

要明确目标

并

不是去生

成最现实的

样本，而是生

成可以愚弄

分类器的样

本。当然，



我们

必须始终记

住二者仍存

在重要的区

别，而且通常

在已部署的

系统

中具有

固定的分类

器。但这并不

妨碍在对抗

训练中使用

此思想，对抗

训练的一些

实现甚至包

括用欺骗分

类器的对抗

样本去重复

训练分类



器

。这些技术越

来越接近典

型的GAN的设定

。

下面介绍一

种技术，它作

为可行的防

御技术而占

有一席之地

。在



Robust Manifold

Defense一文中，我

们采取以下

步骤来防御

对抗样



本。[9]

（1）获

取图像 （对抗

性的或常规

的），然后将其

投影回潜在

空



间

，再用生

成器 生成与

相似的样本

，称



为

*。



（2）使用分

类器 对此样

本进行分类

，结果为

，与直

接在



上运行

分类相比，该

样本已经很

少被分错类

了。

但是这种

防御机制的

作者发现，仍

然存在一些

模棱两可的

情况。



在这种

情况下，分类

器确实会受

到微小干扰

的愚弄。不过

还是鼓励读

者去阅读这

篇论文，因为

这些模棱两

可的情况对

于人类来说

往往也不

明

确，这是模型

具有鲁棒性

的标志。为了

解决这个问

题，我们在流

形



上进行对

抗训练：将一

些对抗样本

纳入训练集

中，以便分类

器学会将

它

们与真实数

据相区分。



这

篇文章证明

了使用GAN可以

提供一种分

类器，这种分

类器在受到

轻微扰动（即

使扰动是复

杂方法产生

的）后也不会

完全崩溃。与

大多

数防御

一样，下游分

类器的性能

确实会下降

，因为必须对

分类器进行

训练，以使其

隐式地处理

这些对抗样

本。但即便没

有这一缺点

，它也



不是一

种通用的防

御。

对抗训练

也有一些有

趣的应用，例

如，在一段时

间内，对抗训

练



在半监督

学习中取得

了最好的成

绩。[10] 随后，对抗

训练受到了



GAN（第7章）和其他

方法的挑战

，但这并不意

味着现在对

抗训练不再

是最新技术

了。



希望这给

了你研究GAN和

对抗样本的

另一个理由

，部分是因为

在关

键任务

的分类工作

中，GAN可能是最

先进的防御

方法，抑或是

由于本书



未

涵盖其他应

用[11]——那些最好

留到Adversarial Examples

in



Action一书中

再去讲吧。

综

上所述，本章

已经提出了

对抗样本的

概念，并使其

与GAN的联系



更

加具体。这是

一种未被重

视过的联系

，但这可以帮

助你巩固对

这一

具有挑

战性的主题

的理解。此外

，对抗样本的

一种防御措

施就是GAN本



身

！[12] 因此，GAN也具有

弥补这一差

距的潜力——这

种差距可能

正是

它们存

在的理由。



10.7 结

论

对抗样本

是一个重要

领域，因为即

使是已经商

用的计算机

视觉产



品，也

会受其困扰

，很容易被学

者们愚弄。[13] 除

了安全性和

机器学

习的

可解释性应

用，许多实际

用途仍需有

公平性和鲁

棒性。



此外，对

抗样本是巩

固对深度学

习和GAN的理解

的绝佳方法

。对抗

样本利

用了“一般情

况下训练分

类器存在困

难”以及“在某

种情况下



欺

骗分类器相

对容易”这两

点。分类器必

须对许多图

像进行预测

，并

且由于存

在多个自由

度，可以轻松

加一个特殊

的偏移量来

愚弄分类



器

。结果是可以

在不会明显

改变图像的

情况下很容

易地获得对

抗噪声

而完

全改变图像

的标签。



对抗

样本可以在

AI的许多领域

中找到，不仅

是在深度学

习和计算

机

视觉这两个

领域中。但正

如你从代码

中看到的，在

计算机视觉

领域



中创建

对抗样本的

代码并不困

难。针对这些

示例的防御

措施是存在

的，同时本章

也展示了使

用GAN进行防御

的示例，但对

抗样本的问

题还

远未完

全解决。



10.8 小结



（1）因滥用问题

空间的维度

而产生的对

抗样本是机

器学习的一

个



重要层面

，因为它们展

示了GAN能起作

用以及某些

分类器很容

易被破坏

的

原因。



（2）我们可

以轻松生成

带有真实图

像和噪声的

对抗样本。

（3）很

少有有意义

的攻击向量

可用于对抗

样本。



（4）可以使

用GAN来抵御对

抗样本的应

用，包括网络

安全和机器

学习公平性

等。

[1] Intriguing Properties of

Neural Networks, by Christian

Szegedy et al., 2014.

[2] 视觉分类

任务中人类

表现的构成

原因是一个

复杂的话题

，但是至



少在

如Dota

2和Go中，AI以极

大的优势击

败了人类专

家。



[3] 特征（ROC）曲线

说明了假阳

性和假阴性

之间的权衡

，第2章中也

提

到过，更多详

细信息可查

阅维基百科

。



[4] Adversarial

Attacks on



Deep

Learning Models in

Natural



Language Processing:

A Survey,



by

Wei Emma Zhang

et al.,



2019.

另见Adversarial Examples That

Fool Both ComputerVision

and Time-Limited Humans, by

Gamaleldin F. Elsayed et

al.,



2018.

[5] 这只是

简要的总结

，囿于篇幅所

限，我们必须

省略一些详

细信



息，希望

读者已经理

解背后隐藏

的细节了。如

果不了解的

话，建议选

择

选一本书去

详细地学习

这些细节，例

如Francois Chollet撰写的



Deep

Learning with Python（曼

宁出版社，2017年

）。

[6] Image Classification on

ImageNet, at DAWNBench.

[7] Motivating the Rules

of the Game for

Adversarial Example



Research,by

Justin Gilmer et

al., 2018.



[8]

ICLR是指International Conference on

Learning



Representation，这是规

模较小但很

出色的机器

学习会议之

一。请查

看2018年

Anish Athalye的Twitter。应当指出

的是，作者还

没有审查



另

外3项对抗防

御。

[9] The Robust Manifold

Defense: Adversarial Training Using

Generative Models,by Ajil Jalal

et al., 2019.

[10] Virtual Adversarial Training:

A Regularization Method

for Supervised and Semi-Supervised

Learning,by Takeru Miyato

et al., 2018.

[11] 这在ICLR 2019上是

一个激烈争

论的话题。尽

管大多数的

此类对

话都

是非正式的

，但使用（伪）可

逆生成模型

作为对图像

的“样本



外”性

质进行分类

的方法似乎

是一条卓有

成效的途径

。

[12] Jalal et al.,

2019,



https://arxiv.org/pdf/1712.09196.pdf.

[13] Black-Box Adversarial Attacks

with Limited Queries and

Information, by Andrew Ilyas

et al., 2018.

第11章 GAN的实际

应用



本章主

要内容

GAN在医

学领域的应

用



GAN在时尚领

域的应用

除

了生成手写

数字和把苹

果变橙子这

些吸引人的

应用，GAN还可以

用于更多领

域。本章将探

索一些实际

应用。毫无疑

问，本章重点

讨论



现实中

已经使用过

GAN的领域，因为

本书主要目

标之一是提

供必要的知



识和工具，不

仅希望让读

者了解迄今

为止GAN在各个

领域所取得

的成



就，更希

望帮读者找

到自己感兴

趣的新应用

场景。要开始

这段旅程，

没

有比看看几

个成功的例

子是更好的

起点了。



读者

已经看到了

几个创新用

例——Progressive GAN不仅能创

造出

逼真的

人脸图像，还

能创造出更

具实用价值

的数据样本

（如乳腺X线图

像），CycleGAN通过将视

频游戏中的

片段转换成

电影般的场

景来创建



逼

真的模拟虚

拟环境，然后

将其用于自

动驾驶汽车

的训练。

我们

在本章详细

回顾了GAN的已

有应用，并将

探讨促成这

些应用的



动

机，是什么使

它们恰恰从

GAN所带来的进

步中受益，以

及它们是如

何

实现的。



具

体来说，我们

将着眼于GAN在

医学和时尚

领域的应用

。选择这两

个

领域的原因

如下。



（1）它们不

仅展示了GAN的

学术价值，更

展示了其商

业价值，体

现

了GAN的研究者

如何利用学

术进展解决

现实世界的

问题。



（2）它们使

用了可以通

过本书中涉

及的工具和

技术来理解

的GAN

模型。我们

不会引入新

的概念，而是

着重介绍如

何将前面已

经实现的



模

型用于MNIST以外

的应用。

（3）它们

是不需要专

业知识即可

理解的，例如

GAN在化学和物

理



领域的应

用对于没有

相关专业背

景的人来说

，是很难完全

明白的。

此外

，所选场景和

示例说明了

GAN的通用性。医

学领域展示

了GAN



如何在数

据有限的情

况下发挥作

用，时尚领域

展示了另一

个极端——

在有

大量数据集

可用的场景

中探索GAN的应

用。即使读者

对医学或时

尚



不感兴趣

，你在本章中

了解到的工

具和方法也

适用于无数

其他场景。

遗

憾的是，由于

训练数据往

往是专有的

或难以获得

的，将要回顾

的实际应用

几乎无法在

代码教程中

再现，本书只

能提供GAN模型

及选择



此模

型原因的详

细说明，而无

法像其他章

节那样提供

完整的代码

。到

本章结束

时，你应该完

全有能力实

现本章中的

任何应用——只

需对我



们在

前面实现的

GAN模型进行小

小的修改，并

提供给定例

子或类似的

数

据集即可

。好了，让我们

开始吧！



11.1 医学

领域的GAN

在本

节中，我们介

绍GAN在医学上

的应用，看看

如何使用GAN生

成



的合成数

据来增大训

练数据集，以

帮助提高诊

断的准确率

。

11.1.1 利用GAN提高诊

断准确率



机

器学习在医

学领域的应

用面临着一

系列的挑战

，而这恰恰使

得

该领域能

够很好地受

益于GAN。因为收

集医疗数据

十分困难，很

难获得



足够

大的训练数

据集来满足

监督学习的

需求。[1] 获取医

疗场景的样



本往往是成

本高昂且不

切实际的。



与

任何人都能

获得的用于

光学字符识

别（OCR）的手写字

母数据集

或

用于自动驾

驶汽车训练

的路况录像

不同，医疗场

景的样本更

难获



得，而且

通常需要用

专门的设备

来收集，更别

提还要着重

考虑病人隐

私——这限制了

医疗数据的

收集和使用

。

除了获取医

疗数据集存

在困难，正确

地标注这些

数据也是一

个挑



战，这一

过程通常需

要专家针对

特定情况进

行标注。[2] 因此

，许多

医学应

用无法从深

度学习和人

工智能的进

步中受益。



目

前，人们已经

开发了许多

技术，用于帮

助解决标记

数据集小的

问题。我们在

第7章介绍了

如何在半监

督情况下使

用GAN来增强分

类算

法的性

能，展示了SGAN如

何在仅使用

一小部分标

签进行训练

的情况下



获

得较高的准

确率。但这仅

仅解决了医

学研究者所

面临问题的

一半，

半监督

学习在有一

个大数据集

但只有一小

部分被标记

的情况下很

有帮



助。在许

多医疗应用

中，为数据集

的一小部分

添加标签只

是问题的一

部分——这一小

部分通常是

仅有的数据

！换句话说，根

本没有同一

领

域的成千

上万的额外

样本在等着

被标记或在

半监督情况

下使用。



医学

研究人员试

图使用数据

增强技术克

服数据集不

足的挑战。就

图像来说，通

常是小的调

整和转换，如

改变尺寸（放

大和缩小）、平



移（左右移动

和上下移动

）和旋转。[3] 这些

策略允许通

过单个样本

来创建许多

其他样本，从

而扩展数据

集的大小。图

11.1显示了计算

机

视觉领域

常用的数据

增强示例。



（来

源：Data Augmentation:

How to



Use

Deep Learning When

You Have



Limited

Data, by Bharath

Raj, 2018.）



图11.1

通过改

变现有数据

来增强数据

集的技术，包

括改变尺寸

（放大和缩



小

）、平移（左右移

动和上下移

动）和旋转。尽

管传统的数

据增强技术

可以有效

地

增加数据集

的大小，但它

只能带来有

限的多样性

增加



可以想

象，标准数据

增强有很多

限制——首先，小

的修改产生

的

样本不会

与原始图像

有太大差别

。因此，增加的

样本并没有

增加太多



的

变化来帮助

算法学习泛

化，[4] 例如，手写

数字数据集

希望包含更



多不同的书

写风格呈现

的数字6，而不

仅是同一个

基础图像的

不同排



列。

在

医学诊断中

，我们需要同

一基本病理

的不同样本

，使用合成样

本（如GAN生成的

样本）增强数

据集，可能会

进一步丰富

可用数据，使

其超越传统

的增强技术

——这正是以色

列研究人员

Maayan Frid￾Adar、Eyal

Klang、Michal Amitai、Jacob



Goldberger和Hayit

Greenspan着手研究

的。



鉴于GAN可以

在几乎任何

领域合成高

质量的图像

，Frid-Adar和他

的同事

决定探索GAN在

医学数据增

强方面的应

用。他们选择

将重点放在

提升肝脏病

变分类的准

确率上。他们

关注肝脏病

变的一个主

要动机是



肝

脏作为转移

性癌症最常

见的3个部位

之一，仅2012年就

造成74.5万余

人

死亡。[5] 因此，能

帮助医生诊

断高危患者

的机器学习

工具和模



型

，有可能挽救

无数患者的

生命并改善

无数患者的

预后结果。

11.1.2 方

法



Frid-Adar和他的团

队进退维谷

：他们的目标

是通过训练

GAN来扩

充一个

小的数据集

，但是GAN本身需

要大量的数

据来训练。也

就是说，



若想

要使用GAN来创

建一个大的

数据集，首先

需要一个大

的数据集来

训

练GAN。



他们想

到了巧妙的

解决办法：第

1步，使用标准

的数据增强

技术来

创建

更大的数据

集；第2步，使用

该数据集来

训练GAN来生成

合成样



本；第

3步，他们使用

第1步的增强

数据集和第

2步的GAN生成的

合成样

本来

训练肝脏病

变分类器。



研

究人员使用

的GAN模型是第

4章涉及的DCGAN的

变体。为了证

明

GAN在广泛的

数据集和场

景中的适用

性，Frid-Adar等人只需

稍作调整



和

自定义，就可

以把DCGAN用于他

们的案例。如

图11.2所示，模型

中唯

一需要

调整的部分

是隐藏层的

尺寸，以及生

成器网络输

出和鉴别器

网



络输入的

尺寸。

与MNIST数据

集中尺寸为

28×28×1的图像不同

，此处GAN处理的

是



尺寸为64×64×1的

图像，Frid-Adar等人在

论文中指出

，他们使用了

5×5的卷积核，但

这只是对网

络超参数的

一个小小改

变。除了训练

数

据给定的

图像大小，这

些调整都是

通过反复试

验确定的，研

究人员不



断

调整参数直

到模型产生

令人满意的

图像。

（来源：Frid-Adar et al., 2018.）

图

11.2 Frid-Adar等人采用DCGAN模

型生成肝脏

病变的合成

图像来扩充

数据集，



以提

高分类准确

率。模型结构

类似于第4章

中的DCGAN，强调了

GAN在广泛的数

据集

和场景

中的适用性

（注意，图中只

显示了伪样

本的GAN流程图

）



在回顾由Frid-Adar和

他的团队设

计的方法多

有效之前，我

们先停

下来

看看自己对

GAN的理解有多

大的进步吧

。我们在本书

的第4章了解

了足够多的

GAN知识，并将其

应用于实际

场景中。



11.1.3

结果

Frid-Adar和他的团队

使用DCGAN进行数

据增强，与基

准（仅使用



传

统的数据增

强）相比，在分

类准确率方

面取得了显

著提高。结果

总

结在图11.3中

，其中显示了

分类准确率

（ 轴）随着训练

样本数量（



轴

）的增加而增

加。

线状虚线

展示了通过

使用GAN生成的

合成样本来

增强数据集

所实现



的额

外的准确率

增加。Frid-Adar等人从

增加传统增

强样本不再

提高准

确率

的点开始，加

入DCGAN生成的合

成数据，分类

的性能从0.8左

右提



高到0.85以

上，证明了GAN的

有效性。

肝脏

病变分类的

改进只是众

多数据受限

的医学应用

场景之一，它

们可以从GAN生

成的合成样

本来进行数

据增强中获

益。例如，由伦

敦帝



国理工

学院的Christopher

Bowles带领

的研究组利

用GAN（第6章中讨

论的Progressive GAN）来提高

脑分割任务

的表现。[6] 性能

的提高可

以

解锁模型在

实践中的应

用，特别是在

医学这样的

领域，准确率

可能



意味着

生与死的区

别。

（来源：Frid-Adar et al., 2018.）

图11.3 图

显示了使用

两种数据增

强策略添加

新样本时的

分类准确率

：标准/传统



数

据增强；用DCGAN合

成的样本增

强。使用传统

增强（点状虚

线），分类性能

峰值

在0.8左右

。使用GAN生成样

本（线状虚线

）可以将准确

率提高到0.85以

上。点状



虚线

表示使用传

统数据增强

的分类性能

，随着新的（增

强的）训练样

本数量的增

加，性能也会

提高，但是准

确率的提高

停滞在0.8左右

，超过这个范

围，再增加样



本也不能改

进准确率了

接下来让我

们转换思路

，探索GAN在一个

风险更低、考

虑的因素和

面临的挑战

完全不同的

领域中的应

用：时尚。

11.2 时尚

领域的GAN



与很

难获得数据

的医学领域

不同，在时尚

领域，研究人

员幸运地

拥

有庞大的数

据集。诸如Instagram和

Pinterest之类的网站

上有不计



其

数的服装和

衣物的图片

，亚马逊和eBay等

零售巨头则

有数百万商

品

的购买数

据，从袜子到

裙子，无所不

包。



除了数据

可用性，许多

其他特性使

得时尚领域

非常适合AI的

应

用。时尚品

位因客户而

异，个性化内

容的能力有

可能带来巨

大的商业



利

益。此外，时尚

潮流变化频

繁，对于品牌

和零售商来

说，快速反应

并适应顾客

不断变化的

偏好至关重

要。

在本节中

，我们将探索

GAN在时尚领域

的一些创新

应用。



11.2.1 利用GAN设

计服装

从无

人机送货到

无收银员的

杂货店，亚马

逊有关“未来

主义”的



努力

频上头条。2017年

，亚马逊利用

GAN技术培养AI时

装设计师的

雄心

壮志使

他们又获得

了一次头条

报道。[7] 令人遗

憾的是，这篇

发表在



《麻省

理工学院科

技评论》上的

文章仅提到

使用GAN设计符

合特定风格



的新产品，但

缺乏必要的

细节。



幸运的

是，来自Adobe和加

州大学圣地

亚哥分校的

研究人员发

表了

一篇有

着同样目标

的论文[8]。他们

的方法揭开

了亚马逊AI研

究实验室



试

图重塑时尚

的神秘面纱

。使用从亚马

逊搜集来的

一个包含成

千上万

的用

户、商品和评

论的数据集

，文章的第一

作者康望程

和他的合作

者



训练了两

个独立的模

型：推荐和创

造模型。[9]

我们

可以将推荐

模型视为一

个黑匣子，我

们唯一需要

知道的是它

的功能：对于

任何用户-商

品对，它都返

回一个偏好

得分，分数越

高，



越符合该

用户的品味

。这并无与众

不同之处。

创

造模型更加

新颖和有趣

——不仅因为使

用了 GAN，还得益

于康



望程的

团队设计了

两个创造性

的应用：一是

创造一个符

合给定用户

时

尚品位的

新时尚单品

；二是基于用

户的时尚偏

好给出对现

有时尚单品

的个性化修

改。



下面我们

将探讨他们

是如何实现

这些目标的

。

11.2.2 方法



首先是

模型，他们使

用的是CGAN，并将

商品的类别

作为条件标



签。数据集分

为6类：上衣（男

式和女式）、裤

子（男式和女

式）和鞋



子（男

式和女式）。

在

第8章中，我们

使用MNIST的标签

来教CGAN生成所

需的任何手

写



数字。康望

程等人以类

似的方式使

用类别标签

训练CGAN来生成

属于给

定类

别的时尚单

品。即使要分

类的是衬衫

和裤子而不

是数字3和4，



CGAN模

型的设置几

乎与第8章中

实现的相同

，生成器利用

随机噪声 和



条件信息（标

签/类别 ）来合

成图像，鉴别

器输出给定

的图像-类别

对



是真实的

概率。图11.4详细

展示了他们

使用的网络

结构。

（来源：Kang et al., 2017,

https://arxiv.org/abs/1711.02231.）



图

11.4 康等人在他

们的研究中

使用的CGAN生成

器和鉴别器

网络的结构

。标签

代表服

装的种类，研

究人员使用

它作为条件

标签来指导

生成器合成

符合给定类

别的图像，并

使用鉴别器

来识别出真

实的图像-类

别对



每个框

表示一个层

；fc代表全连接

层；st为卷积核

的步长，其尺



寸（宽×高）为conv/deconv层

前两个数字

；conv表示使用常

规卷积



层，deconv表

示使用转置

卷积层。conv/deconv之后

的数字决定

层的深

度，等

效地来说是

使用的卷积

滤波器的数

量；BN意为给定

层的输出上

使用了批归

一化处理；还

要注意使用

的是最小二

乘损失而不

是交叉熵



损

失。

他们用CGAN为

数据集中的

每个顶级类

别生成逼真

的服装单品

，并



在两个具

有重大实用

潜力的应用

上进行了测

试：创造新的

个性化单品

以及对现有

单品进行个

性化更改。

11.2.3 创

造新单品以

符合个人偏

好



为了确保

生成的单品

图像符合个

人的时尚偏

好，他们想出

了一个

巧妙

的方法：考虑

到推荐模型

是根据个体

对给定商品

的喜爱程度

来给



现有商

品打分的，因

此如果生成

的新单品能

够最大化这

个偏好得分

，

那么很可能

会生成符合

个人风格和

时尚品位的

单品。



康望程

等人借用经

济学和选择

理论中的一

个术语，[10] 将此

过程

称为偏

好最大化（preference maximization）。这

一方法的独

特之



处在于

，可能生成单

品的范围没

有仅限于训

练数据的语

料库，或者整



个亚马逊商

品目录，由于

使用了CGAN，他们

可以将生成

的新单品微

调



到几乎无

限的粒度（对

于域对象来

说，也就是实

体分得越细

，则粒度

越细

）。



他们要解决

的下一个问

题是确保CGAN的

生成器能够

创造出能最

大

限度地满

足个人喜好

的时尚单品

，毕竟CGAN所接受

的训练是只

能为给



定类

别而不是给

定的人去生

成逼真的图

像。一种可能

的选择是继

续生

成图像

并检查偏好

得分，直到遇

到一个得分

足够高的图

像。然而，考



虑

到生成的图

像千变万化

，这种方法将

非常低效且

耗时。

康望程

的团队把此

问题框架化

成一个优化

问题来解决

——约束最



大化

。约束（算法必

须在其中运

行的边界）是

由向量 的大

小给出的潜



在空间的大

小，他们使用

标准大小（100维

向量），每个数

字在



[−1,1]范围内

；而且为了使

这些值可微

（以便在优化

算法中使用

），

将向量 中的

每个元素设

置为tanh函数，并

随机初始化

。



随后他们采

用了梯度上

升法——梯度上

升（gradient

ascent）。与梯度下

降类似，梯度

下降是在最

陡下降方向

上迭代地移

动，以最小化

代价函数；而

梯度上升是

在增幅最大

地方向迭代

地移



动，以最

大化奖励函

数（在本例中

，奖励函数是

由推荐模型

给出的得

分

）。



结果如图11.5所

示，将来自数

据集的前3张

单品图与6个

不同用户

的

前3张合成单

品图进行了

比较。能证明

此解决方案

独创性的点

在于生



成的

单品具有更

高的偏好得

分，这表明它

们更适合用

户的风格和

偏

好。



（来源：Kang et

al., 2017,



https://arxiv.org/abs/1711.02231.）

图

11.5 康望程等人

在文中给出

的结果，每个

单品图像都

用其偏好得

分进行了注

释。每行显示

不同用户和

单品类别（男

式和女式上

装、男式和女

式下装、男式

和

女式鞋）的

结果



左边的

3列显示来自

数据集的得

分最高的单

品，右边的3列

显示合

成的

得分最高的

单品，根据偏

好得分，生成

的单品更符

合用户的品

位。



研究者们

并没有就此

止步，除了创

造新单品，他

们还探索了

开发

的模型

是否可以用

于对现有单

品进行修改

，以适应用户

的风格。鉴于

时尚先锋们

品味的高度

主观性，拥有

改变一件衣

服直到它“恰

到好



处”地符

合消费者偏

好的能力，具

有巨大的潜

在商业利益

。接下来看

看

他们是如何

解决这个挑

战的。



11.2.4 修改现

有单品以更

符合个人偏

好

潜在空间

中的数字（由

输入向量 表

示）具有现实

意义，并且在

数



学上彼此

接近的向量

（由它们在高

维空间中的

距离度量）往

往会产生

内

容和风格相

似的图像。因

此，正如康望

程等人指出

的那样，为了

生



成某些图

像A的变体，需

要做的就是

找到生成器

用来创造图

像的潜在向

量

，然后就可

以从相邻的

向量来生成

相似的图像

。



为了避免抽

象，我们来看

一个使用MNIST数

据集的具体

示例。假设

输

入向量 输入

生成器，会产

生数字9的图

像，如果我们

输入向量 ，

数

学层面来说

在向量占据

的100维潜在空

间中非常接

近 ，那么 会产

生另一个稍

微不同的数

字8的图像，如

图11.6所示。在变

分自编码器

的

环境中，中

间/压缩表示

的工作方式

就像GAN中的 一

样。



图11.6

在潜在

空间内移动

得到的数字

9的变化（图像

来自第2章），附

近向量在



同

一个数字上

产生变化。例

如，当在第1行

中从左向右

移动时，数字

9一开始稍微

向右倾斜，最

终完全竖直

；当移动到足

够远的地方

时，数字9会变

形为另一个

在视

觉上相

似的数字。类

似这样的渐

进式变化同

样适用于更

复杂的数据

集，其中的变

化往往更微

妙



当然，在时

尚领域，事情

就更微妙了

——毕竟，裙子的

图片比数

字

的灰度图像

要复杂得多

。在一个向量

周围的潜在

空间中移动

，比如



创建T恤

的图像，可以

生成不同颜

色、图案和样

式（如V领T恤和

圆领T

恤）。这完

全取决于编

码的类型和

生成器在训

练中内化的

含义，而最



好

的办法就是

尝试。

这就带

来了康望程

的团队必须

克服的下一

个挑战。要使

上述方法



奏

效，我们需要

改变图像的

向量 。想修改

合成的图像

是很简单的

：可

以在每次

生成图像时

记录向量 ，以

便以后参考

。使场景变得

复杂的是



想

要修改真实

的图像。

根据

定义，真实的

图像不能由

生成器生成

，所以没有向

量 。我们



能做

的最好的事

情就是找到

尽可能接近

要修改成图

像的合成图

像的潜

在空

间表示。换句

话说，我们必

须找到一个

向量 ，以供生

成器合成



接

近真实图像

的图像，并用

它来代替会

产生真实图

像的假设的

。

这正是康望

程等人所做

的。和前面一

样，先将场景

描述为一个

优



化问题，然

后根据所谓

的重建损失

（两幅图像之

间差异的一

种衡量，

损失

越大，给定的

一对图像之

间的差异就

越大）定义损

失函数。以这

种方式表述

了问题以后

，再使用梯度

下降法（最小

化重建损失

）迭代



地为任

何真实图像

寻找最接近

的合成图像

。一旦有了一

个与真实图

像

相似的伪

图像（因此也

有了生成真

实图像的向

量 ），就可以通

过潜在



空间

的操作来修

改过来。

这就

是康望程的

团队设计的

方法充分展

示其潜力的

地方。我们可

以在潜在空

间中移动，直

到生成类似

想要修改成

的图像的图

像点，同



时还

可以针对给

定用户的偏

好进行优化

。我们可以在

图11.7中看到这



个过程：当我

们在每一行

中从左到右

移动时，衬衫

和裤子逐渐

变得更



加个

性化。

（来源: Kang et al.,

2017, https://arxiv.org/abs/1711.02231.）



图

11.7

6名购物者（3男

3女）使用相同

的初始图像

的个性化流

程：男性为polo



衫

，女性为裤子

例如他们观

察到，第1行的

人想要更多

样的颜色，第

5行的人似乎



更喜欢明亮

的颜色和模

特忧郁的表

情，最后一个

人似乎更喜

欢裙子而



不

是牛仔裤。这

是超个性化

定制的表现

，难怪亚马逊

会注意到这

一

点。



最左边

的照片展示

了来自训练

数据集的真

实单品；左边

的第2张照

片

展示了生成

的最接近真

实的图像——它

被用作个性

化过程的起

点。



每个图像

都用其偏好

得分进行了

注释，当从左

到右移动时

，单品会针

对

给定的用户

逐步进行优

化。随着得分

的增加，个性

化过程提高

了单



品与给

定用户的风

格和品味相

匹配的可能

性。

11.3 结论



本章

所涉及的应

用仅触及了

GAN所能实现的

功能的皮毛

。仅在医学

领

域和时尚领

域就存在无

数其他用例

，更不必说其

他领域了。可

以肯



定的是

，GAN已经扩展到

了学术界以

外的领域，无

数的应用都

在利用

GAN合成

逼真数据的

功能。



11.4 小结

（1）由

于GAN的通用性

，它们可以用

于广泛的非

学术应用，并

且



很容易用

于MNIST以外的场

景。

（2）在医学领

域，GAN生成的合

成样本可以

提高分类的

准确率，



并能

超出传统数

据集增强技

术所能达到

的水平。

（3）在时

尚领域，GAN可用

于创造新单

品和修改现

有单品，以更

好地符合消

费者的个人

风格。这是通

过生成能使

推荐算法的

偏好得分



最

大化的单品

图像实现的

。

[1] Synthetic Data Augmentation

Using GAN for Improved

Liver



Lesion Classification,

by Maayan



Frid-Adar

et al., 2018.

[2] Synthetic Data Augmentation

Using GAN for Improved

Liver



Lesion Classification,

by Maayan



Frid-Adar

et al., 2018.

[3] 同上。



[4]

Synthetic Data Augmentation

Using GAN for Improved

Liver



Lesion Classification,

by Maayan



Frid-Adar

et al., 2018.

[5] Cancer Incidence and

Mortality Worldwide: Sources,

Methods, and Major Patterns

in GLOBOCAN 2012,by J.

Ferlay et



al.,

2015, International Journal

of Cancer.



[6]

GAN Augmentation: Augmenting

Training Data Using

Generative Adversarial Networks,by Christopher

Bowles et al.,

2018.



[7] Amazon

Has Developed



an

AI Fashion Designer,

by Will



Knight,

2017, MIT Technology

Review.



[8] This

AI Learns



Your

Fashion Sense and

Invents Your Next

Outfit, by Jackie Snow,

2017, MIT Technology Review.

[9] Visually-Aware Fashion Recommendation

and Design with

Generative Image Models, by

Wang-Cheng Kang et al.,

2017.



[10] Introduction

to Choice



Theory,

by Jonathan Levin

and



Paul Milgrom,

2004.



第12章 展

望未来

本章

主要内容



生

成模型的伦

理问题

预计

未来几年内

将占主导地

位的3项最新

改进：RGAN、SAGAN和



BigGAN

关于

以上3种前沿

技术的更多

阅读材料



关

于本书主题

和要点的总

结

在最后一

章，我们想简

单阐述一下

对GAN伦理问题

的看法，还会

讨



论一些有

可能在未来

变得更重要

的创新。我们

会谈到期望

能够定义GAN

未

来发展的一

些最新思路

，但不会给出

代码。我们希

望你已准备

好迎



接即将

到来的GAN之旅

——即使是撰写

本书时尚未

发表的进展

。最后，

请允许

我们总结全

书并做个依

依不舍的道

别吧！



12.1 伦理问

题

全世界都

开始意识到

人工智能的

伦理——包括GAN的

伦理——是一



个

重要的问题

。一些机构已

决定不发布

其昂贵的、经

过预先培训

的模

型，以防

被作为生成

假新闻的工

具滥用[1]。许多

文章提到GAN可

能有



潜在的

恶意用途。[2]

我

们都知道，错

误的信息可

能是一个严

重的问题，因

此可以生成

照片般逼真

的合成图像

的GAN可能会带

来危险。



这不

是一本关于

人工智能伦

理的书，我们

因此只是简

单地谈谈这



个话题。但我

们坚信，所有

人必须思考

自己所做工

作的道德规

范，以



及可能

带来的风险

和意外后果

。鉴于人工智

能是一种可

扩展升级的

技

术，考虑我

们所做的是

否有助于创

造一个理想

中生活的世

界是十分重

要的。



你应该

思考自己的

原则，并至少

完成一项更

加完善的道

德准则的

学

习。本书不打

算讨论哪项

准则更好——毕

竟，人们还没

有就更具现

世意义的问

题达成道德

准则上的共

识——但是如果

你还没有读

过任何



其中

一个，至少去

了解一项完

善的关于此

方面的道德

准则。

注意



你

可以阅读谷

歌的人工智

能准则。人工

智能与深度

学习伦理道

德

研究所详

细介绍了这

一准则。另见

Larry Dignan在2017年撰写的

IBM’s Rometty

Lays Out



AI

Con-siderations, Ethical



Principles。

例如，被称为

DeepFakes的技术虽然

最初不是基

于GAN，但已经被

许多人作为

谈论道德担

忧时的例子

提及。[3] DeepFakes——一个深

度

学习和伪

图像的宝库

——由于生成虚

假的政治视

频和合成非

自愿的情



色

内容，已经引

起了争议。这

项技术可能

很快会发展

到无法判断

视频

或图像

是否真实的

地步，而且鉴

于GAN合成新图

像的能力，它

可能很快



就

会主导这一

领域。

仅仅是

说每个人都

应该考虑他

们的研究和

代码的后果

似乎是不够

的，但现实是

没有哪种灵

丹妙药能够

解决所有问

题。不管是在

学术研



究还

是在工业领

域，我们都应

该考虑这些

影响，即使最

初的关注点

完

全是出于

道德考虑。我

们不想沉闷

地说教，也不

想给一个毫

无根据的



媒

体博人眼球

的预测，但这

的的确确是

本书深切关

心的问题。

人

工智能的伦

理俨然已成

为一个真正

的问题，前面

已经提出了

人



工智能生

成虚假新闻

、合成虚假的

政治视频和

非自愿的情

色内容这3个

实际问题。实

际的情况很

复杂——有些人

认为在人脸

生成中GAN有青

睐

女性面孔

的倾向。换另

一个角度，GAN也

有帮助人工

智能更符合

伦理的



潜力

，例如，在半监

督环境中，通

过合成面部

识别问题中

代表性不足

的类来提高

在占席位较

少群体中的

分类质量。

编

写本书的部

分目的是让

每个人都能

更加了解GAN的

能力和可能

造



成的滥用

。我们对GAN未来

的学术和实

际应用以及

正在进行的

研究感到

兴

奋，但也意识

到一些应用

可能有消极

作用，因为不

可能“取消发

明”这样一项

技术，所以必

须意识到其

能力。这绝不

是说，如果GAN不

存在，世界将

变得更好。GAN只

是一种工具

，众所周知，工

具可能会被

滥用。

出于道

义，我们必须

谈论这种技

术的前景和

危险，否则一

旦被一



小部

分人滥用，就

会一发不可

收拾。尽管本

书不是写给

大众看的，但

我们希望除

了目前在GAN领

域占主导地

位的学术界

，这是迈向更

广泛大

众认

识的踏脚石

。同样，我们正

在进行的许

多公众宣传

活动，希望有

助于促进人

们对该主题

的更多了解

和讨论。



随着

越来越多的

人意识到这

项技术，即使

是现在仍存

在恶意破坏



分子，也将无

法再欺骗任

何人了。我们

希望GAN永远不

会成为恶意

行为



的源头

，虽然可能过

于理想化。接

下来最好的

办法是人人

都能了解

GAN，而

不仅是学术

界和恶意破

坏团伙。我们

也希望（目前

所有证据似

乎指向了这

一现实）GAN可以

对艺术、科学

和工程做出

积极的贡献

。人



们也在致

力于DeepFake的检测

，并借鉴了来

自GAN和对抗样

本的想法，

但

必须谨慎，因

为任何能够

准确检测到

这些DeepFake的分类

器，同样



会为

那些设法骗

过它的虚假

样本增添更

多的可信度

。

在许多方面

，我们也希望

开始更彻底

的对话，而不

是哗众取宠

——其实这是一

个通过图书

论坛或推特

账户与我们

联系的邀请

。我们



意识到

需要从不同

的角度继续

审视道德准

则，也知道这

些事情会随

着

时间的推

移而发展，特

别是随着GAN的

应用案例的

增加而更加

清晰。事



实上

，有些人——比如

硅谷著名风

投公司安德

森•霍洛维兹

基金

（Andreessen Horowitz Fund）的Benedict Evans——认为

规范或谈

论

人工智能的

伦理，并没有

比谈论数据

库的伦理更

有意义，真正

重要



的是使

用方法，而不

是技术本身

。

12.2 GAN的创新



说到

使用案例，我

们知道GAN是一

个不断发展

的领域，因此

想快速

介绍

一些可能目

前在学术界

还没有先前

章节中的一

些主题那么

成熟的



内容

，但期望这些

内容在未来

会具有重要

意义。秉承实

用性的精神

，

我们挑选了

3个有趣且实

用的GAN创新：一

篇实用论文

（RGAN）、一个



Github项目（SAGAN）和

一项艺术应

用（BigGAN）。

12.2.1 相对生成

对抗网络（RGAN）



我

们很少在论

文原稿中看

到如此简单

和优雅但功

能强大到足

以击

败许多

最先进算法

的报道——相对

生成对抗网

络（Relativistic



GAN，RGAN）就是这样

一个例子。RGAN的

核心思想是

，除了原始的

GAN（特别是在第

5章中提到的

NS-GAN），在生成器中

添加了一个

额外

的项，迫

使生成器生

成的数据看

起来比实际

数据更真实

。



换言之，除了

使伪数据看

起来更真实

，生成器还应

使真实数据

看

起来相对

不太真实，从

而可以提高

训练的稳定

性。当然，生成

器能控



制的

唯一数据是

合成数据，因

此只能相对

地实现此目

的。

RGAN的作者将

其描述为WGAN的

一个通用版

本。我们从表

5.1中的简



化损

失函数开始

。式 12.1

描述了鉴

别器的损失

函数，该函数

衡量了



实际

数据（ )）和生成

数据

之间的

差异；式12.2描述

了生



成器的

损失函数，该

函数试图使

鉴别器相信

所看到的样

本是真实的

。

式12.1



式12.2

回到RGAN最

接近的一种

GAN——WGAN。要使生成的

分布看起来

真



实，必须移

动一定的概

率质量，WGAN要使

这一概率质

量最小化。从

这

个意义上

讲，RGAN和WGAN有许多

相似之处（例

如，鉴别器通

常被称为



批

评者，而WGAN在本

文中是作为

RGAN的一个特例

展示）。归根结

底，

这两种方

法都是用唯

一的数字来

衡量所处的

现状，还记得

推土机距离

吗？



RGAN的创新之

处在于不用

再获得以前

那种生成器

总是在扮演

追赶

者角色

的无用动力

了，换句话说

，生成器正试

图生成比实

际数据更真

实的数据，这

样它就不会

总是处于防

御状态。因此

， )可以解释为

实际数据比

生成数据更

真实的概率

。

在深入探讨

差异之前，我

们先引入一

种略有不同

的表示，以近

似



原论文中

所用的表示

方法，但更加

简化。在式12.3和

式12.4中， )

充当类

似于WGAN中的批

评者角色，[4] 可

以将其视为

鉴别器， ()定义

为log(sigmoid(

))。原论文中

用 代替 )表示

伪样本，用带

下标

的 表示

真样本，但我

们将遵循前

几章中更简

单的表示法

。



式12.3

式12.4



以上等

式只体现生

成器中的一

个关键区别

：真实数据现

在被添加

到

损失函数中

了，这个看似

简单的技巧

使生成器不

再永久处于

劣势。



为了在

理想化的环

境中理解这

一点和另外

两个观点，图

12.1绘制出了

不

同的鉴别器

输出。



（来源：The Relativistic

Discriminator: A



Key

Element Missing from

Standard GAN, by Alexia

Jolicoeur-Martineau, 2018.)



图

12.1

在散度最小

化情况下（图

（a）），生成器总是

在追赶鉴别

器（因为散度

总是0）。图（b）中展

示了“好的”NS-GAN训

练的过程，同

样，生成器也

不可能



赢。在

图（c）中可以看

到，现在生成

器能够获胜

，但更重要的

是无论在哪

个训练

阶段

，生成器总是

有一些要争

取的东西（因

此要恢复有

用的梯度）



你

可能会想，为

什么仅增加

这样一个项

就值得关注

呢？因为这个

简单的增加

仅需很少额

外的计算成

本就能使得

训练更加稳

定。这一点

很

重要，尤其是

第5章中提及

的Are GAN Created Equal?一文的作

者认

为，迄今

为止所有主

要的GAN模型结

构在针对额

外的处理需

求进行调整

时，比原始GAN仅

有有限的改

进。这是因为

许多新的GAN模

型架构只有

消耗巨大的

计算成本才

会更好，这使

得它们的用

处更小，但是

RGAN有

可能全面

改变GAN架构。



注

意，即使一个

方法可能只

需要较少的

更新步骤，但

若是每个步

骤由于额外

的计算花费

而需要两倍

的时间，这样

做真的值得

吗？大多

数会

议的同行评

议过程并不

能避免这种

弱点，所以你

必须小心。



应

用

你可能会

问为什么这

在实践中十

分重要？在不

到一年的时

间里，



RGAN的论文

已被引用了

50多次，这对一

位名不见经

传的作者来

说已经

是很

高的引用量

了。此外，人们

已经使用RGAN发

表了应用方

向的文



章，例

如用RGAN实现了

最先进的语

音增强（有史

以来最佳性

能），击

败了其

他基于GAN和非

GAN的方法。[5]



详细

解释这篇论

文已经超出

了本书的范

围，此处不再

赘述。

12.2.2 自注意

力生成对抗

网络（SAGAN）



下一个

将改变当前

GAN

发展格局的

创新是自注

意力生成对

抗网络



（Self-Attention GAN，SAGAN）。注意

力是建立在

一个非常人

性化

的观点

之上的，即人

是如何看待

这个世界的

——一次只能聚

焦在有限



的

地方[6]。GAN的注意

力也是如此

：人的意识只

能有意地关

注桌子的

一

小部分，但是

大脑能够通

过快速微小

的眼球运动

（即扫视）将整

张



桌子拼接

在一起，同时

仍然只聚焦

于图像的一

部分。

类似的

原理在自然

语言处理和

计算机视觉

等领域已有

广泛的应



用

。注意力可以

帮助解决卷

积神经网络

（CNN）忽略图片大

部分的问

题

。众所周知，CNN依

赖于由卷积

大小决定的

小的感受野

。第5章中，



在GAN中

感受野的大

小很可能会

导致问题出

现——例如生成

有多个头部

或身体的奶

牛，但GAN并不会

认为它们奇

怪。

当生成或

评估图像的

子部分时，程

序可能会看

到一条腿出

现在一



个区

域，但无法看

到其他的腿

已经存在于

另一个区域

。这可能是因

为

卷积忽略

了物体的结

构，或者因为

腿或腿的旋

转是由不同

的、更高层



次

的神经元来

表示的——这些

神经元彼此

没有通信。经

验丰富的数

据

科学家会

记得这是Hinton的

CapsuleNets试图解决的

问题，但并没

有真



正奏效

。没有人能绝

对肯定地说

出为什么注

意力可以解

决这个问题

，

一种好的解

释方式是它

可以创建一

个具有灵活

感受野（形状

）的特征



检测

器聚焦在给

定图片的几

个关键区域

（图12.2）。

当图像大

小为512×512时，这个

问题尤为明

显——因为常用

的最



大卷积

大小是7，所以

这是大量特

征被忽略的

关键所在！即

使在更高层

次的节点中

，神经网络也

可能无法检

查是否合适

，例如处在正

确位置

的头

部。因此，只要

奶牛有一个

头挨着身体

，网络就不关

心任何其他

的头，但这种

结构是错误

的！



（来源：Convolution

Arithmetic, by vdmoulin,

2016.）



图12.2 输

出像素（2×2块）会

忽略除突出

显示地小区

域之外的其

他内容，注意



力帮助解决

此问题



这些

更高层次的

表现更难解

释，研究人员

还没有就这

种情况发生

的确切原因

达成共识，但

从经验上看

，网络确实没

有学到这些

信息。

注意力

使我们能够

选择任何形

状或大小的

相关区域，并

恰当地考虑

它



们。参考图

12.3来观察注意

力可以灵活

关注的区域

类型。

（来源：Self-Attention Generative Adversarial Networks,by

Han Zhang,



2018.）

图

12.3 在给定具有

代表性的查

询定位的情

况下，注意机

制最关注的

图像区域。



可

以看到注意

力机制通常

关心不同形

状和大小的

区域，这是一

个好兆头，因

为我

们希望

它能挑出图

像决定对象

类型的区域

应用



DeOldify是Jeremy

Howard教授

的fast.ai课程的学

生Jason Antic



制作的流

行的SAGAN应用之

一。DeOldify使用SAGAN为老

旧的图像和

绘

画着色，并

达到了一个

惊人的准确

水平。图12.4展示

将著名的历

史照



片和绘

画变成全彩

色版本。

（a） （b）



图12.4

Deadwood, South Dakota，1877年

。这是一本黑

白印刷书中

的插图，图

（b）中

的图像实际

上已经着色

了



12.2.3 BigGAN

另一个让

世界瞩目的

网络是BigGAN。[7] BigGAN在ImageNet的

所



有1000类图像

上实现了高

度逼真的512×512图

像生成，在此

之前，这

一壮

举被认为在

现有的GAN中几

乎是不可能

实现的。BigGAN取得

了3倍



于之前

最佳算法的

视觉得分。简

而言之，建立

在SAGAN和频谱归

一化的

基础

上的BigGAN在5个方

向上进行了

进一步创新

。



（1）把GAN扩展到以

前难以置信

的计算规模

。BigGAN的作者们使

用了8倍于之

前的批处理

大小来训练

，这是他们成

功的一部分

原因——

此举已

经能使性能

提高46%。理论上

，训练BigGAN所需的

资源总计价

值



5.9万美元。[8]

（2）BigGAN的

结构与SAGAN相比

，每层中的通

道（特征图）数

量



是后者的

1.5倍——这可能要

归因于所用

数据集的复

杂性。

（3）如果通

过控制对抗

过程来提高

生成器和鉴

别器的稳定

性，可



以带来

总体上更好

的效果。这一

方法背后的

数学知识超

出了本书讨

论

的范围，如

果你对此感

兴趣，可以从

了解频谱归

一化开始。不

感兴趣



的人

则大可放心

，因为即使是

文章作者，在

后面的训练

中也放弃了

这

种策略，而

且由于计算

成本过高而

使模式崩溃

。



（4）引入截断技

巧（truncation trick），给出了一

种控制多

样

性与保真度

之间平衡的

方法。如果在

接近分布中

心的位置采

样（截



断），截断

技巧可以获

得更好的等

效结果。这是

有意义的——因

为将

产生更

好的样本，这

也是BigGAN拥有“最

丰富经验”之

处。



（5）作者还介

绍了另外3个

理论进展，但

是根据作者

自己的结

果

，这些操作似

乎只对分数

产生轻微的

影响，还常导

致稳定性降

低。



实际上它

们对提高计

算效率很有

用，但此处不

予讨论。

应用

BigGAN一个迷人的

艺术应用是

Ganbreeder App，这得益于预

先训

练的模

型和Joel Simon的辛勤

工作。Ganbreeder是一个

基于网页的

交



互式（免费

的）探索BigGAN潜在

空间的方法

，作为一种创

造新图像的



技术，已被广

泛应用于艺

术领域。



你既

可以探索两

个相邻的潜

在空间，也可

以在两个不

同图像域的

两个样本之

间使用线性

插值来创建

新图像。图12.5显

示了一个在



Ganbreeder上进行创作

的例子。



（来源

：Ganbreeder）

图12.5 每次单击

Make Children按钮，Ganbreer都会提

供附近潜在

空间中的一

系列突变，从

而生成下面

的3幅图像。可

以从自己的

样本或他人

的样本开始

，从而

使之成

为一个合作

的练习。这就

是Crossbreed部分用途

，可以从潜在

空间的其他

部分选择另

一个有趣的

样本并混合

。最后在Edit-Genes中可

以编辑参数

（在本例



中为

城堡和石墙

），并将更多或

更少的特征

添加到图片

中

BigGAN值得进一

步关注，因为

DeepMind免费提供了

所有这些计

算，并将预训

练模型上传

到了TensorFlow Hub上（TensorFlow Hub是

在

第6章中使用

的机器学习

代码仓库）。



12.3 拓

展阅读

碍于

篇幅，我们无

法涵盖许多

在学术界和

工业界的工

作中日益风

靡的其他主

题。我们将列

出至少3个主

题，并希望已

经为你准备

好了理



解这

些文章所需

的知识和工

具。之所以只

选了3个，是因

为预计这一

部

分会随GAN的

发展变化得

很快。



（1）Style GAN。Style

GAN将GAN和“传

统的”风格迁

移相结



合，让

用户可以更

好地控制生

成的输出。NVIDIA的

CGAN已经成功产

生

了惊人的

全高清结果

，并具有从更

精细的细节

到整体图像

的多个控制

级别。这项工

作建立在第

6章的基础上

，所以在深入

研究此文之

前，你



可能需

要重新阅读

一下。

（2）谱归一

化（spectral normalization）。这是一种

复杂的



正则

化技术，需要

用到高级的

线性代数原

理。现在只需

记住它的用



途，即通过规

范化网络中

的权重来满

足特定的属

性来稳定训

练，这正



是WGAN（第

5章）所要求的

。谱规归一化

的作用和梯

度惩罚相似

。

（3）SPADE。SPADE又名GauGAN，是于2019年

发布的最新

成果。



就像第

9章一开始叙

述的那样，SPADE旨

在基于图像

的语义图合

成真实

图像

。图像分辨率

可以达到512×256像

素。这可能是

3项技术中最

具挑



战性的

一项，但也是

最吸引媒体

关注的一项

——该技术的演

示令人印

象

深刻！



GAN的领域

中有太多的

事情在更新

换代，所以本

节涉及的内

容不可

能一

直保持最前

沿，但是希望

就道德伦理

和最新的有

趣论文而言

，我



们已经提

供了研究这

个不断发展

的领域中问

题的所需资

源，更希望你

能很好地理

解本章提出

的GAN背后的创

新。这些方法

是否都会成

为人们

惯用

技术的一部

分还是未知

数，但我们觉

得很有可能

，也希望本节

所



列的最新

创新同样能

实现这一愿

景。

12.4 回顾与总

结



我们希望

书中所讨论

的前沿技术

能为你提供

继续探索GAN足

够的背

景材

料，即使本书

已接近尾声

。在旅程结束

之前，值得回

顾一下我们

所学到的一

切。



我们首先

对GAN是什么以

及它们是如

何工作的进

行了基本的

解释

（第1章），并

实现了GAN的一

个简单版本

（第3章）；使用一

个简单版



本

的自编码器

介绍了生成

模型（第2章）；介

绍了GAN的理论

（第3章和

第5章

）及其缺陷，还

有克服缺陷

一些方法（第

5章），这为后续

章节



提供了

基础知识和

工具。

我们实

现了几个最

典型和最有

影响力的GAN变

体——DCGAN（第4



章）和CGAN（第

8章），以及一些

最先进和最

复杂的——PGGAN（第6

章

）和CycleGAN（第9章）；实现

了SGAN（第7章），这是

一个旨在解

决机器学习

中最严重的

缺点之一——缺

少大量标记

数据集的GAN变

体；



还探讨了

GAN的许多实际

和创新应用

（第11章），并给出

了对抗样本



（第10章）——这些样

本对所有机

器学习都是

一个挑战。



一

路上，我们不

断扩展理论

和实践的工

具箱。从IS和FID（第

5

章）到像素级

特征归一化

（第6章）、批归一

化（第4章）和



dropout（第

7章），我们学习

了能很好地

为GAN和其他领

域服务的一

些

概念和技

术。



回顾全书

，值得强调的

是探索GAN时一

次又一次出

现的几个主

题。

（1）就实际应

用的要求和

应对理论上

的约束而言

，GAN 非常通



用。这

在第

9 章中的

CycleGAN案例中最显

而易见。这项

技术不但不

受



前人需要

成对数据的

限制，而且几

乎可以在任

何域的样本

之间进行转



换——从苹果到

橙子，从马到

斑马。GAN的多功

能性在第6章

中也很明



显

，PGGAN可以学习生

成与人脸和

医学乳腺X线

照片一样真

实的图像；

在

第7章中只需

要做一些调

整，就可以将

鉴别器变成

一个多分类

器。



（2）GAN既是一门

科学，也是一

门艺术。对于

GAN——一般来说乃

至是深度学

习——的瑰丽和

缺陷，我们对

它们为何在

实践中如此

有效

的理解

是有限的。很

少有已知的

数学证明，大

多数成就只

是实验中获

得的。这使得

GAN容易受到许

多训练陷阱

的困扰，例如

第5章中讨论

过



的模式崩

溃。幸运的是

，研究人员发

现了许多技

巧，可以极大

地缓解

这些

挑战，从输入

预处理到优

化器和激活

函数的选择

，其中许多已

经



在本书代

码教程中学

习实践过。正

如本章所述

的GAN变体所示

，改进

GAN的技术

正发展得如

火如荼。



除了

训练上的困

难，即使像GAN这

样强大又通

用的技术，也

有重要

的局

限。GAN被许多人

誉为赋予机

器创造力的

技术，这种说

法在某种程

度上是正确

的。在短短的

几年内，GAN已经

无可争议地

成为合成伪

数据



方面最

先进的技术

，但是还达不

到与人类的

创造力相匹

敌的地步。

事

实上，正如本

书中一次又

一次地展示

的那样，GAN几乎

可以模仿



任

何现有数据

集的特征并

生成看起来

像来自该数

据集的样本

。然而由

于其

本身的性质

，GAN不会偏离训

练数据太远

。例如，如果有

一个古典



艺

术杰作的训

练数据集，GAN生

成的样本将

更像米开朗

琪罗而不是

杰克

逊•波洛

克（美国画家

，抽象表现主

义绘画大师

）。在一个新的

能给予



机器

真正自主性

的人工智能

模式出现之

前，在赋予机

器真正的自

主性

之前，终

究还是要由

人类研究人

员来引导GAN达

到预期目标

。



在尝试使用

GAN及其应用时

，你不仅要记

住书中涵盖

的实用技术

、

提示和技巧

，还要牢记本

章中讨论的

道德伦理方

面的考量。借

此，祝



你在未

来的旅途中

一切顺利！

12.5 小

结



（1）本章谈到

了AI和GAN的伦理

问题，并讨论

了道德准则

、提高

认识和

开放讨论的

重要性。



（2）本章

提供了将推

动GAN未来发展

的创新，以及

隐藏在结构

背

后更高层

次的理念。



RGAN可

以确保生成

器考虑到真

实数据和生

成数据的相

对似然。

SAGAN的注

意力机制能

与人类的感

知起到类似

的作用。



BigGAN能够

以前所未有

的高质量生

成ImageNet所有1000个类

别的

图片。



（3）本

章强调了书

中两个反复

出现的主题

：一是GAN用途广

泛，

二是实验

的必要性——因

为与其他深

度学习技术

一样，GAN既是一

门科



学，也是

一门艺术。

[1] An AI That

Writes Convincing Prose Risks

Mass-Producing



Fake News,

by Will



Knight,

MIT Technology Review,

2019.



[2] Inside

the World



of

AI that Forges

Beautiful Art and

Terrifying Deepfakes, by Karen

Hao, MIT Technology Review,

2019. 另

见 AI Gets

Creative Thanks to GANs

Innovations, by



Jakub

Langr, Forbes, 2019.

[3] The Liar’s Dividend,

and Other Challenges of

Deep-Fake



News,by Paul

Chadwick, The



Guardian,

2018. 另见If You

Thought



Fake News

Was a



Problem,

Wait for DeepFakes,

by Roula Khalaf,

2018, Financial Times.

[4] 此处

跳过了一些

细节，我们希

望给出高屋

建瓴的观点

并且保持表

示法前后一

致，这样你就

能自己领悟

并补齐细节

。

[5] SERGAN: Speech Enhancement

Using Relativistic Generative

Adversarial Networks with Gradient

Penalty,by Deepak Baby and

Sarah Verhulst, 2019, IEEE-ICASSP.

[6] The Mind Is

Flat: The Illusion of

Mental Depth and the

Improvised Mind by Nick

Chater (Penguin, 2018).

[7] Large Scale GAN

Training for High Fidelity

Natural Image



Synthesis,

by Andrew Brock

et al., 2019.

[8] 参见Mario Klingemann发表的

Twitter.
